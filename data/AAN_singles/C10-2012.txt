Coling 2010: Poster Volume, pages 99?107,Beijing, August 2010Toward Qualitative Evaluation of Textual Entailment SystemsElena CabrioFBK-Irst, University of Trentocabrio@fbk.euBernardo MagniniFBK-Irstmagnini@fbk.euAbstractThis paper presents a methodology for aquantitative and qualitative evaluation ofTextual Entailment systems.
We take ad-vantage of the decomposition of Text Hy-pothesis pairs into monothematic pairs,i.e.
pairs where only one linguistic phe-nomenon at a time is responsible for en-tailment judgment, and propose to run TEsystems over such datasets.
We showthat several behaviours of a system canbe explained in terms of the correlationbetween the accuracy on monothematicpairs and the accuracy on the correspond-ing original pairs.1 IntroductionSince 2005, Recognizing Textual Entailment(RTE) has been proposed as a task whose aim isto capture major semantic inference needs acrossapplications in Computational Linguistics (Daganet al, 2009).
Systems are asked to automaticallyjudge whether the meaning of a portion of text, re-ferred as Text (T), entails the meaning of anothertext, referred as Hypothesis (H).
This evaluationprovides useful cues for researchers and develop-ers aiming at the integration of TE components inlarger applications (see, for instance, the use of aTE engine in the QALL-ME project system1, theuse in relation extraction (Romano et al, 2006),and in reading comprehension systems (Nielsenet al, 2009)).Although the RTE evaluations showed pro-gresses in TE technologies, we think that there is1http://qallme.fbk.eu/still large room for improving qualitative analysisof both the RTE datasets and the system results.In particular, we intend to focus this paper on thefollowing aspects:1.
There is relatively poor analysis of the lin-guistic phenomena that are relevant for theRTE datasets, and very little is known aboutthe distribution of such phenomena, andabout the ability of participating systems tocorrectly detect and judge them in T,H pairs.Experiments like the ablation tests attemptedin the last RTE-5 campaign on lexical andlexical-syntactic resources go in this direc-tion, although the degree of comprehensionis still far from being optimal.2.
We are interested in the correlations amongthe capability of a system to address singlelinguistic phenomena in a pair and the abilityto correctly judge the pair itself.
Despite thestrong intuition about such correlation (i.e.the more the phenomena for which a systemis trained, the better the final judgment), noempirical evidences support it.3.
Although the ability to detect and managesingle phenomena seems to be a crucial fea-ture of high performing systems, very little isknown about how systems manage to com-bine such results in a global score for a pair.The mechanism underlying such composi-tion may shed light on meaning compositionrelated to TE tasks.4.
Finally, we are interested in the relation be-tween the above mentioned items over thedifferent kinds of pairs represented in RTE99datasets, specifically entailment, contradic-tion and unknown pairs.
In this case the in-tuition is that some phenomena are more rel-evant for a certain judgment rather than foranother.To address the issues above, we propose anevaluation methodology aiming at providing anumber of quantitative and qualitative indicatorsabout a TE system.
The method is based onthe decomposition of T,H pairs into monothematicpairs, each representing one single linguistic phe-nomenon relevant for entailment judgment.
Eval-uation is carried out both on the original T,H pairand on the monothematic pairs originated from it.We define a correlation index between the accu-racy of the system on the original T,H pairs andthe accuracy on the corresponding monothematicpairs.
We investigate the use of such correlationson different subsets of the evaluation dataset (i.e.positive vs negative pairs) and we try to induceregular patterns of evaluation.The method we propose has been tested on asample of 60 pairs, each decomposed in the corre-sponding monothematic pairs, and using two sys-tems that obtained similar performances in RTE-5.
We show that the main features and differencesof these systems come to light when evaluated us-ing qualitative criteria.
Futhermore, we comparesuch systems with two different baseline systems,the first one performing Word Overlap, while thesecond one is an ideal system that knows a priorithe probability of a linguistic phenomenon to beassociated with a certain entailment judgement.The paper is structured as follows.
Sec-tion 2 explains the procedure for the creation ofmonothematic pairs starting from RTE pairs.
Sec-tion 3 presents the evaluation methodology wepropose, while Section 4 describes our pilot study.Section 5 concludes the paper and proposes futuredevelopments.2 Decomposing RTE pairsOur proposal on qualitative evaluation takes ad-vantage of previous work on specialized entail-ment engines and monothematic datasets.
Amonothematic pair is defined (Magnini andCabrio, 2009) as a T,H pair in which a certainphenomenon relevant to the entailment relation ishighlighted and isolated.
The main idea is to cre-ate the monothematic pairs basing on the phenom-ena that are actually present in the original RTEpairs, so that the actual distribution of the linguis-tic phenomena involved in the entailment relationemerges.For the decomposition procedure, we refer tothe methodology described in (Bentivogli et al,2010), consisting of a number of steps carried outmanually.
The starting point is a [T,H] pair takenfrom one of the RTE data sets, that should bedecomposed in a number of monothematic pairs[T,Hi], where T is the original Text and Hi arethe Hypotheses created for each linguistic phe-nomenon relevant for judging the entailment re-lation in [T,H].
In details, the procedure for thecreation of monothematic pairs is composed of thefollowing steps:1.
Individuate the phenomena contributing tothe entailment decision in [T,H].2.
For each linguistic phenomenon i:(a) Detect a general entailment rule ri fori, and instantiate it using the part of Texpressing i as the left hand side (LHS)of the rule, and information from H on ias the right side (RHS).
(b) substitute the portion of T that matchesthe LHS of ri with the RHS of ri.
(c) consider the result of the previous stepas Hi, and compose the monothematicpair [T,Hi].
Mark the pair with phe-nomenon i.3.
Assign an entailment judgment to eachmonothematic pair.Relevant linguistic phenomena are grouped us-ing both fine-grained categories and broader cate-gories, defined referring to widely accepted clas-sifications in the literature (e.g.
(Garoufi, 2007))and to the inference types typically addressed inRTE systems: lexical, syntactic, lexical-syntactic,discourse and reasoning.
Each macro category in-cludes fine-grained phenomena (Table 2 lists thephenomena detected in RTE-5 datasets).100Text snippet (pair 125) Phenomena Judg.T Mexico?s new president, Felipe Calderon, seems to be doingall the right things in cracking down on Mexico?s drug traffickers.
[...]H Felipe Calderon is the outgoing President of Mexico.
lexical:semantic-opposition Csyntactic:argument-realization, syntactic:appositionH1 Mexico?s outgoing president, Felipe Calderon, seems to be doing all lexical:semantic-opposition Call the right things in cracking down on Mexico?s drug traffickers.
[...]H2 The new president of Mexico, Felipe Calderon, seems to be doing syntactic:argument-realization Eall the right things in cracking down on Mexico?s drug traffickers.
.
[...]H3 Felipe Calderon is Mexico?s new president.
syntactic:apposition ETable 1: Application of the decomposition methodology to an original RTE pairTable 1 shows an example of the decompo-sition of a RTE pair (marked as contradiction)into monothematic pairs.
At step 1 of themethodology both the phenomena that preservethe entailment and those that break the entailmentrules causing a contradiction in the pair aredetected, i.e.
argument realization, appositionand semantic opposition (column phenomena inthe table).
While the monothematic pairs createdbasing on the first two phenomena preserve theentailment, the semantic opposition generates acontradiction (column judgment).
As an example,let?s apply step by step the procedure to thephenomenon of semantic opposition.
At step 2aof the methodology the general rule:Pattern: x?
/ ?
yConstraint: semantic opposition(y,x)is instantiated (new?
/ ?outgoing), and at step2b the substitution in T is carried out (Mexico?soutgoing president, Felipe Calderon [...]).
Atstep 2c a negative monothematic pair T,H1 iscomposed (column text snippet in the table) andmarked as semantic opposition (macro-categorylexical), and the pair is judged as contradiction.3 Evaluation methodologyAim of the evaluation methodology we propose isto provide quantitative and qualitative indicatorsabout the behaviours of actual TE systems.3.1 General MethodThe basic assumption of the evaluation methodol-ogy is that the more a system is able to correctlysolve the linguistic phenomena underlying the en-tailment relation separately, the more the systemshould be able to correctly judge more complexpairs, in which different phenomena are presentand interact in a complex way.
Such assumption ismotivated by the notion of meaning composition-ality, according to which the meaning of a com-plex expression e in a language L is determinedby the structure of e in L and the meaning of theconstituents of e in L (Frege, 1892).
In a parallelway, we assume that it is possible to understandthe entailment relation of a T,H pair (i.e.
to cor-rectly judge the entailment/contradiction relation)only if all the phenomena contributing to such re-lation are solved.According to such assumption, we expect thatthe higher the accuracy of a system on themonothematic pairs and the compositional strat-egy, the better its performances on the originalRTE pairs.
Furthermore, the precision a systemgains on single phenomena should be maintainedover the general dataset, thanks to suitable mech-anisms of meaning combination.Given a dataset composed of original RTE pairs[T,H], a dataset composed of all the monothe-matic pairs derived from it [T,H]mono, and a TEsystem S, the evaluation methodology we proposeconsists of the following steps:1.
Run S both on [T,H] and on [T,H]mono, toobtain the accuracies of S both on the RTEoriginal and on monothematic pairs;2.
Extract data concerning the behaviour of S oneach phenomenon or on categories of phe-nomena, and calculate separate accuracies.This way it is possible to evaluate how mucha system is able to correctly deal with singleor with categories of phenomena;3.
Calculate the correlation between the abilityof the system to correctly judge the monothe-matic pairs of [T,H]mono with respect to the101ability to correctly judge the original onesin [T,H].
Such correlation is expressedthrough a Correlation Index (CI), as definedin Section 3.2;4.
In order to check if the same CI is main-tained over both entailment and contradictionpairs (i.e.
to verify if the system has peculiarstrategies to correctly assign both judgments,and if the high similarity of monothematicpairs does not bias its behaviour), we calcu-late a Deviation Index (DI) as the differencebetween the CIs on entailment and on con-tradiction pairs, as explained in more detailsin Section 3.3.3.2 Correlation Index (CI)As introduced before, we assume that the ac-curacy obtained on [T,H]mono should positivelycorrelate with the accuracy obtained on [T,H].We define aCorrelation Index as the ratio betweenthe accuracy of the system on the original RTEdataset and the accuracy obtained on the monothe-matic dataset, as follows:CI = acc[T,H]acc[T,H]mono(1)We expect the correlation index of an optimalideal system (or the human goldstandard) to beequal to 1, i.e.
100% accuracy on the monothe-matic dataset should correspond to 100% accu-racy on the original RTE dataset.
For this reason,we consider CI = 1 as the ideal correlation, andwe calculate the difference between such ideal CIand the correlation obtained for a system S.Given such expectations, CIS can assume threedifferent configurations with respect to the upper-bound (i.e.
the ideal correlation):?
CIS ?= 1 (ideal correlation): When CIS ap-proaches to 1, the system shows high corre-lation with the ideal behaviour assumed bythe compositionality principle.
As a conse-quence, we can predict that improving sin-gle modules will correspondingly affect theglobal performance.?
CIS < 1 (missing correlation): The systemis not able to exploit the ability in solving sin-gle phenomena to correctly judge the origi-nal RTE pairs.
This may be due to the factthat the system does not adopt suitable com-bination mechanisms and loses the potential-ity shown by its performances on monothe-matic pairs.?
CIS > 1 (over correlation): The system doesnot exploit the ability to solve single linguis-tic components to solve the whole pairs, andhas different mechanisms to evaluate the en-tailment.
Probably, such a system is not in-tended to be modularized.Beside this ?global?
correlation index calcu-lated on the complete RTE data and on all themonothematic pairs created from it, the CI canalso be calculated i) on categories of phenomena,to verify which phenomena a system is more ableto solve both when isolated and when interactingwith other phenomena, e.g.
:CIlex =acc[T,H]lexacc[T,H]mono?lex(2)including in [T,H]lex all the pairs in which atleast one lexical phenomenon is present and con-tribute to the entailment/contradiction judgments,and in [T,H]mono?lex all the monothematic pairsin which a lexical phenomenon is isolated; or ii)on kind of judgment (entailment, contradiction,unknown), allowing deeper qualitative analysis ofthe performances of a system.3.3 Deviation Index (DI)We explained that a low CI (i.e.
< 1) of a systemreflects the inability to correctly exploit the poten-tially promising results obtained on monothematicpairs to correctly judge RTE pairs.
Actually, itcould also be the case that the system does notperform a correct combination because even theresults got on the monothematic pairs were due tochance (e.g.
a word overlap system performs wellon monothematic pairs because of the high sim-ilarity between T and H, and not because it haslinguistic strategies).We detect such cases by decomposing the eval-uation datasets, separating positive (i.e.
entail-ment) from negative (i.e.
contradiction, unknown)examples both in [T,H] and in [T,H]mono, and102independently run S on the new datasets.
Then,we have more fine grained evaluation patternsthrough which we can analyze the system be-haviour.In the ideal case, we expect to have good cor-relation between the accuracy obtained on themonothematic pairs and the accuracy obtained onthe original ones (0 < CIpos ?
1 and 0 <CIneg ?
1).
On the contrary, we expect that sys-tems either without a clear composition strategy orwithout strong components on specific linguisticphenomena (e.g.
a word overlap system), wouldshow a significant difference of correlation on thedifferent datasets.
More specifically, situations ofinverse correlation on the entailment and contra-diction pairs (e.g.
over correlation on contradic-tion pairs and missing correlation on entailmentpairs) may reveal that the system itself is affectedby the nature of the dataset (i.e.
its behaviouris biased by the high similarity of [T,H]mono),and weaknesses in the ability of solving phenom-ena that more frequently contribute to the assign-ment of a contradiction (or an entailment) judg-ment come to light.We formalize such intuition defining a Devia-tion Index (DI) as the difference between the cor-relation indexes, respectively, on entailment andcontradiction/unknown pairs, as follows:|DI| = CIpos ?
CIneg (3)For instance, an high Deviation Index due toa missing correlation on positive entailment pairsand an over correlation for negative pairs, is in-terpreted as an evidence that the system has lowaccuracy on [T,H]mono - T and H are very sim-ilar and the system has no strategies to under-stand that the phenomenon that is present has tobe judged as contradictory -, and a higher accu-racy on [T,H], probably due to chance.
In theideal case DIS ?= 0, since we assumed the idealCIs on both positive and negative examples to beas close as possible to 1 (see Section 3.2).4 Experiments and discussionThis Section describes the experimental setup ofour pilot study, carried out using two systems thattook part in RTE-5 i.e EDITS and VENSES.
Weshow the results obtained and the qualitative anal-ysis performed basing on the proposed evaluationmethodology.
Their respective CIs and DIs arecompared with two baselines: a word overlap sys-tem, and a system biased by the knowledge ofthe probability that a linguistic phenomenon con-tributes to the assignment of a certain entailmentjudgment.4.1 DatasetThe evaluation method has been tested on adataset composed of 60 pairs from RTE-5 test set([T,H]RTE5?sample, composed of 30 entailment,and 30 contradiction randomly extracted exam-ples), and a dataset composed of all the monothe-matic pairs derived by the first one followingthe procedure described in Section 2.
The sec-ond dataset [T,H]RTE5?mono is composed of 167pairs (135 entailment, 32 contradiction examples,considering 35 different linguistic phenomena)2.On average, 2.78 monothematic pairs have beencreated from the original pairs.
In this pilot studywe decided to limit our analysis to entailment andcontradiction pairs since, as observed in (Ben-tivogli et al, 2010), in most of the unknown pairsno linguistic phenomena relating T to H could bedetected.4.2 TE systemsEDITS The EDITS system (Edit Distance Tex-tual Entailment Suite)3 (Negri et al, 2009) as-sumes that the distance between T and H is acharacteristic that separates the positive pairs, forwhich entailment holds, from the negative pairs,for which entailment does not hold (two waytask).
It is based on edit distance algorithms, andcomputes the [T,H] distance as the overall cost ofthe edit operations (i.e.
insertion, deletion andsubstitution) required to transform T into H. Forour experiments we applied the model that pro-duced EDITS best run at RTE-5 (acc.
on test set:60.2%).
The main features are: Tree Edit Dis-tance algorithm on the parsed trees of T and H,Wikipedia lexical entailment rules, and PSO opti-mized operation costs (Mehdad et al, 2009).2http://hlt.fbk.eu/en/Technology/TE- Specialized Data3Available as open source at http://edits.fbk.eu/103VENSES The other system used in our ex-periments is VENSES4 (Delmonte et al, 2009),that obtained performances similar to EDITS atRTE-5 (acc.
on test set: 61.5%).
It applies alinguistically-based approach for semantic infer-ence, and is composed of two main components:i) a grammatically-driven subsystem validates thewell-formedness of the predicate-argument struc-ture and works on the output of a deep parser pro-ducing augmented head-dependency structures;and ii) a subsystem detects allowed logical andlexical inferences basing on different kind ofstructural transformations intended to produce asemantically valid meaning correspondence.
Alsoin this case, we applied the best configuration ofthe system used in RTE-5.Baseline system 1: Word Overlap algorithmThe first baseline applies a Word Overlap (WO)algorithm on tokenized text.
The threshold to sep-arate positive from negative pairs has been learnton the whole RTE-5 training dataset.Baseline system 2: Linguistic biased systemThe second baseline is produced by a more so-phisticated but biased system.
It exploits theprobability of linguistic phenomena to contributemore to the assignment of a certain judgment thanto another.
Such probabilities are learnt on the[T,H]RTE5?mono goldstandard: given the list ofthe phenomena with their frequency in monothe-matic positive and negative pairs (columns 1,2,3of Table 2), we calculate the probability P of phe-nomenon i to appear in a positive (or in a negative)pair as follows:P (i|[T,H]positive) = #(i|[T,H]RTE5?positive?mono)#(i|[T,H]RTE5?mono)(4)For instance, if the phenomenon apposition ap-pears in 11 monothematic positive pairs and in 6negative pairs, it has a probability of 64.7% to ap-pear in positive examples and 35.3% to appear innegative ones.
Such knowledge is then stored inthe system, and is used in the classification phase,assigning the most probable judgment associatedto a certain phenomenon.4http://project.cgm.unive.it/venses en.htmlWhen applied to [T,H]RTE5?sample, this sys-tem uses a simple combination strategy: if phe-nomena associated with different judgments arepresent in a pair, and one phenomenon is associ-ated with a contradiction judgment with a proba-bility > 50%, the pair is marked as contradiction,otherwise it is marked as entailment.4.3 ResultsFollowing the methodology described in Sec-tion 3, at step 1 we run EDITS and VENSESon [T,H]RTE5?sample, and on [T,H]RTE5?mono(Table 3 reports the accuracies obtained).At step 2, we calculate the accuracy of ED-ITS and VENSES on each single linguistic phe-nomenon, and on categories of phenomena.
Ta-ble 2 shows the distribution of the phenomena onthe dataset, reflected in the number of positive andnegative monothematic pairs created for each phe-nomenon.
As can be seen, some phenomena ap-pear more frequently than others (e.g.
corefer-ence, general inference).
Furthermore, some lin-guistic phenomena allow only the creation of pos-itive or negative examples, while others can con-tribute to the assignment of both judgments.
Dueto the small datasets we used, some phenomenaappear rarely; the accuracy on them cannot beconsidered completely reliable.Nevertheless, from these data the main featuresof the systems can be identified.
For instance,EDITS obtains the highest accuracy on positivemonothematic pairs, while it seems it has no pe-culiar strategies to deal with phenomena caus-ing contradiction (e.g.
semantic opposition, andquantity mismatching).
On the contrary, VENSESshows an opposite behaviour, obtaining the bestresults on the negative cases.At step 3 of the proposed evaluation methodol-ogy, we calculate the correlation index betweenthe ability of the system to correctly judge themonothematic pairs of [T,H]RTE5?mono with re-spect to the ability to correctly judge the originalones in [T,H]RTE5?sample.Table 3 compares EDITS and VENSES CI withthe two baseline systems described before.
As canbe noticed, even if EDITS CI outperforms theWOsystem, they show a similar behaviour (high ac-curacy on monothematic pairs, and much lower104phenomena # [T,H] EDITS VENSESRTE5?mono % acc.
% acc.pos.
neg.
pos.
neg.
pos.
neg.lex:identity 1 3 100 0 100 33.3lex:format 2 - 100 - 100 -lex:acronymy 3 - 100 - 33.3 -lex:demonymy 1 - 100 - 100 -lex:synonymy 11 - 90.9 - 90.9 -lex:semantic-opp.
- 3 - 0 - 100lex:hypernymy 3 - 100 - 66.6 -lex:geo-knowledge 1 - 100 - 100 -TOT lexical 22 6 95.4 0 77.2 66.6lexsynt:transp-head 2 - 100 - 50 -lexsynt:verb-nom.
8 - 87.5 - 25 -lexsynt:causative 1 - 100 - 100 -lexsynt:paraphrase 3 - 100 - 66.6 -TOT lex-syntactic 14 - 92.8 - 42.8 -synt:negation - 1 - 0 - 0synt:modifier 3 1 100 0 33.3 100synt:arg-realization 5 - 100 - 40 -synt:apposition 11 6 100 33.3 54.5 83.3synt:list 1 - 100 - 100 -synt:coordination 3 - 100 - 33.3 -synt:actpass-altern.
4 2 100 0 25 50TOT syntactic 28 9 96.4 22.2 42.8 77.7disc:coreference 20 - 95 - 50 -disc:apposition 3 - 100 - 0 -disc:anaphora-zero 5 - 80 - 20 -disc:ellipsis 4 - 100 - 25 -disc:statements 1 - 100 - 0 -TOT discourse 33 - 93.9 - 36.3 -reas:apposition 2 1 100 0 50 100reas:modifier 3 - 66.6 - 100 -reas:genitive 1 - 100 - 100 -reas:relative-clause 1 - 100 - 0 -reas:elliptic-expr.
1 - 100 - 0 -reas:meronymy 1 1 100 0 100 0reas:metonymy 3 - 100 - 33.3 -reas:representat.
1 - 100 - 0 -reas:quantity - 5 - 0 - 80reas:spatial 1 - 100 - 0 -reas:gen-inference 24 10 87.5 50 37.5 90TOT reasoning 38 17 89.4 35.2 42.1 82.3TOT (all phenom) 135 32 93.3 25 45.9 81.2Table 2: Systems?
accuracy on phenomenaon the RTE sample).
According to our defini-tion, their CIs (0 < CI < 1) show a good abilityof the systems to deal with linguistic phenomenawhen isolated, but a scarce ability in combiningthem to assign the final judgment.
EDITS CI isnot far from the CI of the linguistic biased base-line system, even if we were expecting a higherCI for the latter system.
The reason is that besidethe linguistic phenomena that allow only the cre-ation of negative monothematic pairs, all the phe-nomena that allow both judgments have a higherprobability to contribute to the creation of positivemonothematic pairs.Comparing the CI of the four analyzed systemswith the ideal correlation (CIS ?= 1, see Section3.2), VENSES is the closest one (?
= 0.15), evenif it shows a light over correlation (probably dueto the nature of the dataset).
The second closestacc.
% acc.
% CIRTE5?sample RTE5?monoEDITS 58.3 80.8 0.72VENSES 60 52.6 1.15Word Overlap 38.3 77.24 0.49ling baseline 68.3 86.8 0.79Table 3: Evaluation on RTE pairs and onmonothematic pairscategories of linguistic phenomenaRTE5 data lex.
lex-synt.
synt.
disc.
reas.EDITS sample 47.8 64.3 51.7 75 62.5mono 75 92.8 78.3 93.9 72.7CI 0.63 0.69 0.66 0.79 0.
85VENSES sample 47.2 42.8 62 46.4 67.5mono 75 42.8 51.3 33 54.5CI 0.62 1 1.2 1.4 1.23WO sample 36.3 57.1 34.4 50 35baseline mono 78.5 71.4 72.9 96.9 69CI 0.46 0.79 0.47 0.51 0.5ling- sample 82.6 92.8 58.6 82.1 70biased mono 96.4 100 75.6 96.9 80baseline CI 0.85 0.92 0.77 0.84 0.87Table 4: Evaluation on categories of phenomenaone is the linguistic biased system (?
= 0.21),showing that the knowledge of the most probablejudgment assigned to a certain phenomenon canbe a useful information.Table 4 reports an evaluation of the four sys-tems on categories of linguistic phenomena.To check if the same CI is maintained overboth entailment and contradiction pairs, we cal-culate a Deviation Index as the difference be-tween the CIs on entailment and on contradictionpairs (step 4 of our methodology).
As describedin Section 3, we created four datasets dividingboth [T,H]RTE5?sample and [T,H]RTE5?monointo positive (i.e.
entailment) and negative (i.e.contradiction) examples.
We run EDITS andVENSES on the datasets and we calculate theCI on positive and on negative examples sepa-rately.
If we obtained missing correlation be-tween the accuracy on the monothematic pairsand the accuracy on RTE original ones, it wouldmean that the potentiality that the systems showon monothematic pairs is not exploited to cor-rectly judge more complex pairs, therefore com-positional mechanisms should be improved.Table 5 shows that the DIs of the linguistic bi-ased system and of VENSES are close to the idealcase (DIS ?= 0), indicating a good capacity tocorrectly differentiate entailment from contradic-tion cases.
EDITS results demonstrate that the105Figure 1: Correlation Index on entailment and contradiction pairs for EDITS and VENSES% acc.
RTE5 % acc.
RTE5 CI DIsample monoEDITS E 83.3 94.7 0.88 0.5C 33.3 24 1.38VENSES E 50 47.01 1.08 0.16C 70 75.7 0.92WO E 50 88 0.56 0.24baseline C 26.6 33 0.80ling-biased E 96.6 98.5 0.98 0.03baseline C 40 39.4 1.01Table 5: Evaluation on entail.
and contr.
pairsshallow approach implemented by the system hasno strategies to correctly judge negative examples(similarly to the WO system), therefore should bemainly improved with this respect.We also calculated the CI for every pair of thedataset, putting into relation each original pairwith all the monothematic pairs derived from it.Figure 1 shows EDITS and VENSES?s CI on eachpair of our sample.5 Even if the systems obtainedsimilar performances in the challenge, the secondsystem seems to behave in an opposite way withrespect to EDITS, showing higher CI for negativecases than for the positive ones.5The ideal case CI=1 corresponds to 0 on the logarithmicscale.5 Conclusion and Future workWe have proposed a methodology for the evalu-ation of TE systems based on the analysis of thesystem behaviour on monothematic pairs with re-spect to the behaviour on corresponding originalpairs.
Through the definition of two indicators,a Correlation Index and a Deviation Index, weinfer evaluation patterns which indicate strengthand weaknesses of the system.
As a pilot study,we have compared two systems that took part inRTE-5.
We discovered that, although the two sys-tems have similar accuracy on RTE-5 datasets,they show significant differences in their respec-tive abilities to manage different linguistic phe-nomena and to properly combine them.
We hopethat the analysis provided by our methodologymay bring interesting elements both to TE systemdevelopers and for deep discussion on the natureof TE itself.As future work, we plan to refine the evaluationmethodology introducing the possibility to assigndifferent relevance to the phenomena.6 AcknowledgementsThanks to Professor Rodolfo Delmonte and toSara Tonelli for running the VENSES system onour data sets.106ReferencesBentivogli, Luisa, Bernardo Magnini, Ido Dagan,Hoa Trang Dang, and Danilo Giampiccolo.
2009.The Fifth PASCAL Recognizing Textual EntailmentChallenge.
Proceedings of the TAC 2009 Workshopon Textual Entailment.
Gaithersburg, Maryland.
17November.Bentivogli, Luisa, Elena Cabrio, Ido Dagan,Danilo Giampiccolo, Medea Lo Leggio, andBernardo Magnini.
2010.
Building Textual En-tailment Specialized Data Sets: a Methodologyfor Isolating Linguistic Phenomena Relevant toInference.
Proceedings of the 7th InternationalConference on Language Resources and Evaluation(LREC) .
Valletta, Malta.
19-21 May.Dagan, Ido, Bill Dolan, Bernardo Magnini, andDan Roth.
2009.
Recognizing textual entailment:Rational, evaluation and approaches.
Natural Lan-guage Engineering (JNLE), Volume 15, Special Is-sue 04, October 2009, pp i-xvii.
Cambridge Univer-sity Press.Delmonte, Rodolfo, Sara Tonelli, Rocco Tripodi.2009.
Semantic Processing for Text Entailmentwith VENSES.
Proceedings of the TAC 2009 Work-shop on Textual Entailment.
To appear.
Gaithers-burg, Maryland.
17 November.Garoufi, Konstantina.
2007.
Towards a Better Un-derstanding of Applied Textual Entailment.
Mas-ter Thesis.
Saarland University.
Saarbru?cken, Ger-many.Gottlob, Frege.
1892.
U?ber Sinn und Bedeutung.Zeitschrift fu?r Philosophie und philosophische Kri-tik.
100.25-50.Magnini, Bernardo, and Elena Cabrio.
2009.
Combin-ing Specialized Entailment Engines.
Proceedings ofthe 4th Language & Technology Conference (LTC?09).
Poznan, Poland.
6-8 November.Mehdad, Yashar, Matteo Negri, Elena Cabrio,Milen Kouylekov, and Bernardo Magnini.
2009.Using Lexical Resources in a Distance-Based Ap-proach to RTE.
Proceedings of the TAC 2009 Work-shop on Textual Entailment.
Gaithersburg, Mary-land.
17 November.Negri, Matteo, Milen Kouylekov, Bernardo Magnini,Yashar Mehdad, and Elena Cabrio.
2009.
TowardsExtensible Textual Entailment Engines: The EDITSPackage.
AI*IA 2009: Emergent Perspectives inArtificial Intelligence, Lecture Notes in ComputerScience.
Volume 5883.
ISBN 978-3-642-10290-5.Springer-Verlag Berlin Heidelberg, p. 314.Nielsen, Rodney D., Wayne Ward, and James H. Mar-tin.
2009.
Recognizing entailment in intelligent tu-toring systems.
In Ido Dagan, Bill Dolan, BernardoMagnini and Dan Roth (Eds.)
The Journal of Nat-ural Language Engineering, (JNLE).
, 15, pp 479-501.
Copyright Cambridge University Press, Cam-bridge, United Kingdom.Romano, Lorenza, Milen Ognianov Kouylekov,Idan Szpektor, Ido Kalman Dagan, and Al-berto Lavelli, 2006.
Investigating a GenericParaphrase-Based Approach for Relation Extrac-tion.
Proceedings of the 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics (EACL 2006).
Trento, Italy.
3-7April.107
