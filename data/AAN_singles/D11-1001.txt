Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1?12,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsFast and Robust Joint Models for Biomedical Event ExtractionSebastian Riedel Andrew McCallumDepartment of Computer ScienceUniversity of Massachusetts, Amherst{riedel,mccallum}@cs.umass.eduAbstractExtracting biomedical events from literaturehas attracted much recent attention.
The best-performing systems so far have been pipelinesof simple subtask-specific local classifiers.
Anatural drawback of such approaches are cas-cading errors introduced in early stages of thepipeline.
We present three joint models ofincreasing complexity designed to overcomethis problem.
The first model performs jointtrigger and argument extraction, and lends it-self to a simple, efficient and exact infer-ence algorithm.
The second model capturescorrelations between events, while the thirdmodel ensures consistency between argumentsof the same event.
Inference in these modelsis kept tractable through dual decomposition.The first two models outperform the previousbest joint approaches and are very competi-tive with respect to the current state-of-the-art.
The third model yields the best results re-ported so far on the BioNLP 2009 shared task,the BioNLP 2011 Genia task and the BioNLP2011 Infectious Diseases task.1 IntroductionWhenever we advance our scientific understandingof the world, we seek to publish our findings.
Theresult is a vast and ever-expanding body of naturallanguage text that is becoming increasingly difficultto leverage.
This is particularly true in the contextof life sciences, where large quantities of biomedi-cal articles are published on a daily basis.
To sup-port tasks such data mining, search and visualiza-tion, there is a clear need for structured representa-tions of the knowledge these articles convey.
This isindicated by a large number of public databases withcontent ranging from simple protein-protein interac-tions to complex pathways.
To increase coverage ofsuch databases, and to keep up with the rate of pub-lishing, we need to automatically extract structuredrepresentations from biomedical text?a process of-ten referred to as biomedical text mining.One major focus of biomedical text mining hasbeen the extraction of named entities, such genesor gene products, and of flat binary relations be-tween such entities, such as protein-protein interac-tions.
However, in recent years there has also beenan increasing interest in the extraction of biomedi-cal events and their causal relations.
This gave riseto the BioNLP 2009 and 2011 shared tasks whichchallenged participants to gather such events frombiomedical text (Kim et al, 2009; Kim et al, 2011).Notably, these events can be complex and recursive:they may have several arguments, and some of thearguments may be events themselves.Current state-of-the-art event extractors fol-low the same architectural blueprint and dividethe extraction process into a pipeline of threestages (Bj?rne et al, 2009; Miwa et al, 2010c).
Firstthey predict a set of candidate event trigger words(say, tokens 2, 5 and 6 in figure 1), then argumentmentions are attached to these triggers (say, token4 for trigger 2).
The final stage decides how ar-guments are shared between events?compare howone event subsumes all arguments of trigger 6 in fig-ure 1, while two events share the three argumentsof trigger 4 in figure 2.
This architecture is proneto cascading errors: If we miss a trigger in the firststage, we will never be able to extract the full event1... the phosphorylation of TRAF2 inhibits binding to the CD40 cytoplasmic domain ...E1:PhosphorylationE2:RegulationE3:BindingThemeCauseThemeThemeThemeRegulation BindingPhosphorylationThemeCauseThemeThemeThemeSame Binding1 2 345 6 7 8 9 10 11b4,9e2,Phos.a6,9,Theme(a)(b)Figure 1: (a) sentence with target event structure to extract; (b) projection to a set of labelled graph over tokens.it concerns.
Current systems attempt to tackle thisproblem by passing several candidates to the nextstage.
However, this tends to increase the false pos-itive rate.
In fact, Miwa et al (2010c) observe that30% of their errors stem from this type of ad-hocmodule communication.Joint models have been proposed to overcome thisproblem (Poon and Vanderwende, 2010; Riedel etal., 2009).
However, besides not being as accurateas their pipelined competitors, mostly because theydo not yet exploit the rich set of features used byMiwa et al (2010b) and Bj?rne et al (2009), theyalso suffer from the complexity of inference.
Forexample, to remain tractable, the best joint systemso far (Poon and Vanderwende, 2010) works witha simplified representation of the problem in whichcertain features are harder to capture, employs localsearch without certificates of optimality, and further-more requires a 32-core cluster for quick train-testcycles.
Existing joint models also rely on heuristicswhen it comes to deciding which arguments sharethe same event.
Contrast this with the best currentpipeline (Miwa et al, 2010c; Miwa et al, 2010b)which uses a classifier for this task.We present a family of event extraction mod-els that address the aforementioned problems.
Thefirst model jointly predicts triggers and arguments.Notably, the highest scoring event structure underthis model can be found efficiently in O (mn) timewhere m is the number of trigger candidates, andn the number of argument candidates.
This isonly slightly slower than the O (m?n) runtime of apipeline, where m?
is the number of trigger candi-dates as filtered by the first stage.
We achieve theseguarantees through a novel algorithm that jointlypicks best trigger label and arguments on a per-tokenbasis.
Remarkably, it takes roughly as much time totrain this model on one core as the model of Poonand Vanderwende (2010) on 32 cores, and leads tobetter results.The second model enforces additional constraintsthat ensure consistency between events in hierarchi-cal regulation structures.
While inference in thismodel is more complicated, we show how dual de-composition (Komodakis et al, 2007; Rush et al,2010) can be used to efficiently find exact solutionsfor a large fraction of problems.Our third model includes the first two, and explic-itly captures which arguments are part in the sameevent?the third stage of existing pipelines.
Due toa complex coupling between this model and the firsttwo, inference here requires a projected version ofthe sub-gradient technique demonstrated by Rush etal.
(2010).When evaluated on the BioNLP 2009 shared task,the first two models outperform the previous bestjoint approaches and are competitive when com-pared to current state-of-the-art.
With 57.4 F1 onthe test set, the third model yields the best resultsreported so far with a 1.1 F1 margin to the resultsof Miwa et al (2010b).
For the BioNLP 2011 Ge-nia task 1 and the BioNLP 2011 Infectious Diseasestask, Model 3 yields the second-best and best resultsreported so far.
The second-best results are achievedwith Model 3 as is (Riedel and McCallum, 2011),the best results when using Stanford event predic-tions as input features (Riedel et al, 2011).
Themargins between Model 3 and the best runner-upsrange from 1.9 F1 to 2.8 F1.In the following we will first introduce biomedicalevent extraction and our notation.
Then we go on topresent our models and their inference routines.
Wepresent related work, show our empirical evaluation,and conclude.2Grb2 can be coimmunoprecipitated with Sos1 and Sos2Binding BindingThemeThemeThemeThemeThemeThemeTheme12 3 4 5 6 7 8Figure 2: Two binding events with identical trigger.
Theprojection graph does not change even if both events aremerged.2 Biomedical Event ExtractionBy bio-molecular event we mean a change of stateof one or more bio-molecules.
Our task is to extractstructured information about such events from nat-ural language text.
More concretely, let us considerpart (a) of figure 1.
We see a snippet of text from abiomedical abstract, and the three events that can beextracted from it.
We will use these to characterizethe types of events we ought to extract, as definedby the 2009 BioNLP shared task.
Note that for theshared task, protein mentions are given by the taskorganizers and hence do not need to be extracted.The event E1 in the figure refers to a Phosphory-lation of the TRAF2 protein.
It is an instance of aset of simple events that describe changes to a sin-gle gene or gene product.
Other members of thisset are: Expression, Transcription, Localization, andCatabolism.
Each of these events has to have exactlyone theme, the protein of which a state change is de-scribed.
A labelled edge in figure 1a) shows thatTRAF2 is the theme of E1.Event E3 is a Binding of TRAF2 and CD40.Binding events are particular in that they may havemore than one theme, as there can be several bio-molecules associated in a binding structure.
This isin fact the case for E3.In the top-center of figure 1a) we see the Regu-lation event E2.
Such events describe regulatory orcausal relations between events.
Other instances ofthis type of events are: Positive Regulation and Neg-ative Regulation.
Regulations have to have exactlyone theme; this theme can a be protein or, as in ourcase, another event.
Regulations may also have zeroor one cause arguments that denote events or pro-teins which trigger the regulation.In the BioNLP shared task, we are also asked tofind a trigger (or clue) token for each event.
Thistoken grounds the event in text and allows users toquickly validate extracted events.
For example, thetrigger for event E2 is ?inhibit?, as indicated by adashed line.2.1 Event ProjectionTo formulate the search for event structures of theform shown in figure 1a) as an optimization prob-lem, it will be convenient to represent them througha set of binary variables.
We introduce such a rep-resentation, inspired by previous work (Riedel et al,2009; Bj?rne et al, 2009) and based on a projectionof events to a graph structure over tokens, as seenfigure 1b).Consider sentence x and a set of candidate trig-ger tokens, denoted by Trig (x).
We label each can-didate i with the event type it is a trigger for, orNone if it is not a trigger.
This decision is rep-resented through a set of binary variables ei,t, onefor each possible event type t. In our example wehave e6,Binding = 1.
The set of possible event typeswill be denoted as T , the regulation event types asTReg def= {PosReg, NegReg, Reg} and its complementas T?reg def= T \ TReg.For each candidate trigger i we consider the argu-ments of all events that have i as trigger.
Each ar-gument a will either be an event itself, or a protein.For events we add a labelled edge between i and thetrigger j of a.
For proteins we add an edge betweeni and the syntactic head j of the protein mention.
Inboth cases we label the edge i ?
j with the roleof the argument a.
The edge is represented througha binary variable ai,j,r, where r ?
R is the argu-ment role and R def= {Theme, Cause, None}.
Therole None is active whenever no Theme or Causerole is present.
In our example we get, among oth-ers, a2,4,Theme = 1.So far our representation is equivalent to map-pings in previous work (Riedel et al, 2009; Bj?rne etal., 2009) and hence shares their main shortcoming:we cannot differentiate between two (or more) bind-ing events with the same trigger but different argu-ments, or one binding event with several arguments.Consider, for example, the arguments of trigger 6 infigure 1b) that are all subsumed in a single event.
Bycontrast, the arguments of trigger 4 shown in figure2 are split between two events.Previous work has resolved this ambiguity3through ad-hoc rules (Bj?rne et al, 2009) or witha post-processing classifier (Miwa et al, 2010c).We propose to augment the graph representationthrough edges between pairs of proteins that arethemes in the same binding event.
For two proteintokens p and q we represent this edge through thebinary variable bp,q.
Hence, in figure 1b) we haveb4,9 = 1, whereas for figure 2 we get b1,6 = b1,8 = 1but b6,8 = 0.
By explicitly modeling such ?sib-ling?
edges we not only minimize the need for post-processing.
We can also improve attachment deci-sions akin to second order models in dependencyparsing (McDonald and Pereira, 2006).
Note thatwhile merely introducing such variables is easy, en-forcing consistency between them and the ei,t andai,j,r variables is not.
We address this in section3.3.1.Reconstruction of events from solutions (e,a,b)can be done almost exactly as described by Bj?rneet al (2009).
However, while they group bindingarguments according to ad-hoc rules based on de-pendency paths from trigger to argument, we simplyquery the variables bp,q.To simplify our exposition we introduce addi-tional notation.
We denote the set of protein headtokens with Prot (x); the set of a possible targetsfor outgoing edges from a trigger is Cand(x) def=Trig (x) ?
Prot (x).
We will often omit the do-mains of indices and instead assign them a fixed do-main in advance: i, l ?
Trig (x), j, k ?
Cand (x),p, q ?
Prot (x), r ?
R and t ?
T .
Bold faceletters are used to denote composite vectors e, aand b of variables ei,t, ai,j,r and bp,q.
The vectory is the joint vector of e,a and b.
The short-formei ?
t will mean ?t?
: ei,t?
?
?t,t?
where ?t,t?
isthe Kronecker Delta.
Likewise, ai,j ?
r means?r?
: ai,j,r?
?
?r,r?
.3 ModelsIn this section we will present three structured pre-diction models of increasing complexity and expres-siveness, as well as their corresponding MAP infer-ence algorithms.
Each model m can be representedby a mapping from sentence x to a set of legal struc-tures Ym (x), and a linear scoring functionsm (y;x,w) = ?w, f (y,x)?
.
(1)Here f is a feature function on structures y and inputx, and w is a weight vector for these features.We can use the scoring function sm and the set oflegal structures Ym (x) to predict the event hm (x)for a given sentence x according tohm (x) def= arg maxy?Ym(x)sm (y;x,w) .
(2)For brevity we will from now on omit observations xand weights w when they are clear from the context.3.1 Model 1Model 1 performs a simple version of joint triggerand argument extraction.
It independently scorestrigger labels and argument roles:s1 (e,a) def=?ei,t=1sT (i, t) +?ai,j,r=1sR (i, j, r) .
(3)Here sT (i, t) = ?wT, fT (i, t)?
is a per-trigger scor-ing function that measures how well the event la-bel t fits to token i.
Likewise, sR (i, j, r) =?wR, fR (i, j, r)?
measures the compatibility of roler as label for the edge i?
j.The jointness of Model 1 stems from enforcingconsistency between the trigger label of i and its out-going edges.
By consistency we mean that: (a) thereis at least one Theme whenever there is an event at i;(b) only regulation events are allowed to have Causearguments; (c) all arguments of a None trigger musthave the None role.
We will denote the set assign-ments that fulfill these constraints by O and hencehave Y1 def= O.Enforcing (e,a) ?
O guarantees that we neverpredict triggers i for which no sensible, high-scoring, argument j can be found.
It also ensuresthat when we see an ?obvious?
argument edge i r?
jwith high score sR (i, j, r) there is pressure to extracta trigger at i, even if the fact that i is a trigger maynot be as obvious.3.1.1 InferenceAs it turns out, the maximizer of equation 2 can befound very efficiently in O (mn) time where m =|Trig (x)| and n = |Cand (x)|.
The correspondingprocedure, bestOut(?
), is shown in algorithm 1.
Ittakes as input a vector of trigger and edge penaltiesc that are added to the local scores of the sT andsR functions.
For Model 2 and 3 we will use these4penalties to enforce agreement with predictions ofother inference subroutines.
When using Model 1by itself we set them to 0.
We point out that thescoring function s1 is multiplied with 12 throughoutthe algorithm.
For doing inference in Model 1 and2 this has no effect, but when we use bestOut(?)
forModel 3 inference, it is required.The bestOut (c) routine exploits the fact that theconstraints of Model 1 only act on the label fortrigger i and its outgoing edges.
In particular, en-forcing consistency between ei,t and outgoing edgesai,j,r has no effect on consistency between el,t andai?,j?,r?
for any other trigger i?
6= i. Moreover,for a given trigger the constraints only differenti-ate between three cases: (a) regulation event, (b)non-regulation event and (c) no event.
This meansthat we can extract events on a per-trigger basis,and find the best per-trigger structure by compar-ing cases (a), (b) and (c).
Note that bestOut (c)uses the shorthand emptyOut (i) to denote the par-tial assignment ei ?
None and ?j : ai,j ?
None.The function sc1 (i,y) def=?t ei,t(ci,t + 12sT (i, t))+?j,r ai,j,r(ci,j,r + 12sR (i, j, r)) is a per-triggerframe score with penalties c.3.2 Model 2Model 1 may still predict structures that cannot bemapped to events.
For example, in figure 1b) wemay label token 5 as Regulation, add the edge5 Cause?
2 but fail to label token 2 as an event.
Whileconsistent with (e,a) ?
O, this violates the con-straint that every active edge must either end at aprotein, or at an active event trigger.
This is a re-quirement on the label of a trigger and the assign-ment of roles for its incoming edges.Model 2 enforces the above constraint in additionto (e,a) ?
O, while inheriting the scoring functionfromModel 1.
Hence, using I to denote the set of as-signments with consistent trigger labels and incom-ing edges, we get Y2 def= Y1 ?
I and s2 (y) def= s1 (y).3.2.1 InferenceInference in Model 2 amounts to optimizings2 (e,a) over O ?
I.
This is more involved, as wenow have to ensure that when predicting an outgoingedge from trigger i to trigger l there is a high-scoringevent at l. We follow Rush et al (2010) and solvethis problem in the framework of dual decomposi-Algorithm 1 Sub-procedures for inference in Model1, 2 and 3.best label and outgoing edges for all triggers under penalties cbestOut (c) :?i y0 ?
emptyOut (i)y1 ?
out (i, c, Treg,R)y2 ?
out (i, c, T?reg,R \ {Cause})yi ?
argmaxy?
{y0,y1,y2} sc1(i,y)return (yi)ibest label and incoming edges for all triggers under penalties cbestIn (c) :?l y0 ?
emptyIn (l)y1 ?
in (l, c, T ,R \ {None})yl ?
argmaxy?
{y0,y1} sc2 (l,y)return (yl)lpick best binding pairs p, q and trigger i for each using penalties cbestBind (c) :?p, q bp,q ?
[sB (p, q) + maxi ci,p,q > 0]Ip,q ?
{i|ci,p,q = maxi?
ci?,p,q}if bp,q = 1 or maxi?
ci?,p,q > 0?i : ti,p,q ?
[i ?
Ip,q] |Ip,q|?1else?i : ti,p,q ?
0return (b, t)best label in T and outgoing edge roles in R for i, using penalties cout (i, c, T,R) :ei ?
argmaxt?T 12sT (i, t) + ci,tai,bestTheme(i,c) ?
Theme?j ai,j ?
argmaxr?R 12sR (i, j, r) + ci,j,rreturn (ei,ai)best label in T , incoming edge roles in Rand outgoing protein roles, using costs cin (l, c, T,R) :el ?
argmaxt?T 12sT (l, t) + cl,t?i ai,l ?
argmaxr?R 12sR (i, l, r) + ci,l,r?p al,p ?
argmaxr?R 12sR (l, p, r) + cl,p,rreturn (ei,ai)best Theme argument for ibestTheme (i, c) :s (j) def= maxj,r 12sR (i, j, r) + ci,j,r?
(j) def= 12sR (i, j, Theme) + ci,j,Theme ?
s (j)return argmaxj ?(j)5tion.
To this end we write our optimization problemasmaximizee,a,e?,a?12s2 (e,a) +12s2 (e?, a?
)subject to (e,a) ?
O ?
(e?, a?)
?
I?e = e?
?
a = a?
(M2)and note that this problem could be solved separatelyfor e,a and e?, a?
if the coupling constraints e = e?and a = a?
were removed.M2 is an Integer Linear Program, as variables arebinary and both objective and constraints can be rep-resented through linear constraints.1 Dual decompo-sition solves a Linear Programming (LP) relaxationof M2 (that allows fractional values for all binaryvariables) through subgradient descent on a particu-lar dual of M2.
This dual can be derived by intro-ducing Lagrange multipliers for the coupling con-straints.
Its attractiveness stems from the fact thatcalculating the subgradient amounts to solving thedecoupled problems in isolation.
If, by design, thesedecoupled problems can be solved efficiently, wecan often quickly find the optimal solution to an LPrelaxation of our original problem.Dual decomposition applied to Model 2 is shownin algorithm 2.
It maintains the dual variables ?that will appear as local penalties in the subprob-lems to be solved.
The algorithm will try to tunethese variables such that at convergence the couplingconstraints will be fulfilled.
This is done by first op-timizing s2 (e,a) over O and s2 (e?, a?)
over I. Now,whenever there is disagreement between two vari-ables to be coupled, the corresponding dual param-eter is shifted, increasing the chance that next timeboth models will agree.
For example, if in the firstiteration we predict e6,Bind = 1 but e?6,Bind = 0, weset ?6,Bind = ??
where ?
is some stepsize (chosenaccording to Koo et al (2010)).
This will decreasethe coefficient for e6,Bind, and increase the coeffi-cient for e?6,Bind.
Hence, we have a higher chance ofagreement for this variable in the next iteration.The algorithm repeats the process describedabove until all variables agree, or some predefinednumberR of iterations is reached.
In the former casewe in fact have the exact solution to the original ILP.1The ILP representation could be taken from the MLNs ofRiedel et al (2009) and the mapping to ILPs of Riedel (2008).Algorithm 2 Subgradient descent for Model 2, andprojected subgradient descent for Model 3.require:R: max.
iteration, ?t: stepsizest?
0 [model 2,3] ??
0 [model 2,3] ??
0 [model 3]repeatmodel2 (e,a)?
bestOut (?
)2,3 (e?, a?)?
bestIn (??
)3 (e,a)?
bestOut (cout (?,?
))3 (b, t)?
bestBind (cbind (?
))2,3 ?i,t ?
?i,t ?
?t (ei,t ?
e?i,t)2,3 ?i,j,r ?
?i,j,r ?
?t (ai,j,r ?
a?i,j,r)3 ?trigi,p,q ?
[?trigi,p,q ?
?t (ei,Bind ?
ti,p,q)]+3 ?arg1i,j,k ?
[?arg1i,p,q ?
?t (ai,p,Theme ?
ti,p,q)]+3 ?arg2i,p,q ?
[?arg2i,p,q ?
?t (ai,q,Theme ?
ti,p,q)]+2,3 t ?
t + 1until no ?, ?
changed or t > Rreturn (e,a)[model 2] or (e,a,b) [model 3]In the later case we have no such guarantee, but findthat in practice the solutions are still of high qual-ity.
Notice that we could still assess the quality ofthis approximation by measuring the duality gap be-tween primal score and the final dual score.Algorithm 2 for Model 2 requires us to opti-mize s2 (e,a) over O and s2 (e?, a?)
over I. Theformer, with added penalties, can be done withbestOut(c).
As the constraint set for I againdecomposes on a per-token basis, solving thelatter problem requires a very similar procedure,and again O (mn) time.
Algorithm 1 shows thisprocedure under bestIn(c).
It chooses, for eachtrigger candidate, the best label and incomingset of arguments together with the best outgoingedges to proteins.
Adding edges to proteins isnot strictly required, but simplifies our exposition.Algorithm bestIn(c) requires a per-trigger incomingscore: sc2 (l,yl) def=?t el,t(cl,t + 12sT (l, t))+?i,r ai,l,r(ci,l,r + 12sR (i, l, r))+?p,r al,p,r(cl,p,r + 12sR (l, p, r)).
Finally, notethat emptyIn (i) not only assigns None as trigger la-bel of i and to all incoming edges, but also greedilypicks outgoing protein edges (as done within in(?
)).63.3 Model 3Model 2 does not predict the bp,q variables that rep-resent protein pairs p, q in bindings.
Model 3 fixesthis by (a) adding binding variables bp,q into the ob-jective, and (b) enforcing that the binding assign-ment b is consistent with the trigger and argumentassignments e and a.
We will also enforce that thesame pair of entities p, q cannot be arguments inmore than one event together.The scoring function for Model 3 is simplys3 (e,a,b) def= s2 (e,a,b) +?bp,q=1sB (p, q) .
(4)Here sB (p, q) = ?wB, fB (p, q)?
is a per-protein-pairscore based on a feature representation of the lexicaland syntactic relation between both protein heads.Our strategy will be based on enforcing consis-tency partly through linear constraints which we du-alize, and partly within our search algorithm.
Tothis end we first introduce a set of auxiliary binaryvariables ti,p,q .
When a ti,p,q is active, we enforcethat there is a binding trigger at i with proteins pand q as Theme arguments.
A set of linear con-straints can be used for this: ei,Bind ?
ti,p,q ?
0,ai,p,Theme ?
ti,p,q ?
0 and ai,q,Theme ?
ti,p,q ?
0 forall suitable i, p and q.
We denote the set of assign-ments (e,a, t) that fulfill these constraints by T.Consistency between e, a and b can now be en-forced by making sure that t is consistent with e anda, and that b is consistent with this t. The lattermeans that an active bp,q requires a trigger i to pointto p and q.
Or in other words, ti,p,q = 1 for exactlyone trigger i.With the set of consistent assignments (b, t) re-ferred to as B, and a slight abuse of notation, thisgives us Y3 def= Y2?T?B.
Note that it is (e,a, t) ?
Tthat will be enforced by dualizing constraints, and(b, t) ?
B that will be enforced within search.3.3.1 InferenceWe note that inference in Model 3 can be per-formed by solving the following problem:maximizee,a,e?,a?,b,t12s1 (e,a) +12s2 (e?, a?)
+?bp,q=1sB (p, q)subject to (e,a) ?
O ?
(e?, a?)
?
I ?
(b, t) ?
B?e = e?
?
a = a?
?
(e,a, t) ?
T.(M3)Again, without the final row, M3 would be separa-ble.
We exploit this by performing dual decompo-sition with a dual objective that has multipliers ?for the coupling constraints and multipliers?
for theconstraints which enforce (e,a, t) ?
T. The result-ing subgradient descent method is also shown in al-gorithm 2.
Notably, since the constraints for T areinequalities, we require a projected version of thedescent algorithm which enforces ?
?
0.
This man-ifests itself when ?
is updated using the [?
]+ projec-tion.We have already described how to find the beste,a and e?, a?
assignments.
What changes for Model3 is the derivation of the penalties for e and athat now come from both ?
and ?.
We setcouti,t (?,?
)def= ?i,t + ?t,Bind?p,q ?trigi,p,q.
For j /?Prot (x) we set couti,j,r (?,?)
def= ?i,j,r; otherwise weuse couti,j,r (?,?)
def= ?i,j,r +?p ?arg1i,j,p +?q ?arg2i,q,j .For finding a (b, t) ?
B that maximizes?bp,q=1 sB (p, q) we use bestBind (c), as shown inalgorithm 1.
It groups together two proteins p, q iftheir score plus the penalty of the best possible trig-ger i exceeds 0.
In this case, or if there is at least onetrigger with positive penalty ci,p,q > 0 , we activatethe set of triggers I (p, q) with maximal score.Note that when several triggers i maximize thescore, we assign them all the same fractional value|I (p, q)|?1.
This enforces the constraint that at mostone binding event can point to both p and q and alsomeans that we are solving an LP relaxation.
Wecould enforce integer solutions and pick arbitrarytriggers at a tie, but this would lower the chancesof matching against predictions of other routines.The penalties for bestBind (c) are derived fromthe dual ?
by setting cbindi,p,q (?)
= ?
?trigi,p,q ?
?arg1i,p,q ?
?arg2i,,p,q.3.4 TrainingWe choose prediction-based passive-aggressive (PA)online learning (Crammer and Singer, 2003) withaveraging to estimate the weights w for each of ourmodels.
PA is an error-driven learner that shiftsweights towards features of the gold solution, andaway from features of the current guess, wheneverthe current model makes a mistake.PA learning takes into account a user-definedloss function for which we use a weighted sum7of false positives and false negatives: l (y,y?)
def=FP (y,y?)
+ ?FN (y,y?).
We set ?
= 3.8 by op-timizing on the BioNLP 2009 development set.4 Related WorkRiedel et al (2009) use Integer Linear Programmingand cutting planes (Riedel, 2008) for inference ina model similar to Model 2.
By using dual de-composition instead, we can exploit tractable sub-structure and achieve quadratic (Model 2) and cu-bic (Model 3) runtime guarantees.
An advantage ofILP inference are guaranteed certificates of optimal-ity.
However, in practice we also gain certificatesof optimality for a large fraction of the instanceswe process.
Poon and Vanderwende (2010) use lo-cal search and hence provide no such certificates.Their problem formulation also makes n-gram de-pendency path features harder to incorporate.
Mc-Closky et al (2011b) cast event extraction as depen-dency parsing task.
Their model assumes that eventstructures are trees, an assumption that is frequentlyviolated in practice.
Finally, all previous joint ap-proaches use heuristics to decide whether bindingarguments are part of the same event, while we cap-ture these decisions in the joint model.We follow a long line of research in NLP that ad-dresses search problems using (Integer) Linear Pro-grams (Germann et al, 2001; Roth and Yih, 2004;Riedel and Clarke, 2006).
However, instead of us-ing off-the-shelf solvers, we work in the frameworkof dual decomposition.
Here we extend the approachof Rush et al (2010) in that in addition to equalityconstraints we dualize more complex coupling con-straints between models.
This requires us to workwith a projected version of subgradient descent.While tailored towards (biomedical) event extrac-tion, we believe that our models can also be ef-fective in a more general Semantic Role Label-ing (SRL) context.
Using variants of Model 1,we can enforce many of the SRL constraints?suchas ?unique agent?
constraints (Punyakanok et al,2004)?without having to call out to ILP optimiz-ers.
Meza-Ruiz and Riedel (2009) showed that in-ducing pressure on arguments to be attached to atleast one predicate is helpful; this is a soft incomingedge constraint.
Finally, Model 3 can be used to effi-ciently capture compatibilities between semantic ar-guments; such compatibilities have also been shownto be helpful in SRL (Toutanova et al, 2005).5 ExperimentsWe evaluate our models on several tracks of the 2009and 2011 BioNLP shared tasks, using the official?Approximate Span Matching/Approximate Recur-sive Matching?
F1 metric for each.
We also investi-gate the runtime behavior of our algorithms.5.1 PreprocessingEach document is first processed by the StanfordCoreNLP2 tokenizer and sentence splitter.
Parsetrees come from the Charniak-Johnson parser (Char-niak and Johnson, 2005) with a self-trained biomed-ical parsing model (McClosky and Charniak, 2008),and are converted to dependency structures again us-ing Stanford CoreNLP.
Based on trigger words col-lected from the training set, a set of candidate triggertokens Trig (x) is generated for each sentence x.5.2 FeaturesThe feature function fT (i, t) extracts a per-triggerfeature vector for trigger i and type t ?
T .It creates one active feature for each element in{t, t ?
TReg}?
feats (i).
Here feats (i) denotes acollection of representations for the token i: word-form, lemma, POS tag, syntactic heads, syntacticchildren, and membership in two dictionaries takenfrom Riedel et al (2009).For fR (i, j, r) we create active features for eachelement of {r} ?
feats (i, j).
Here feats (i, j) isa collection of representations of the token pair(i, j) taken from Miwa et al (2010c) and contains:labelled and unlabeled n-gram dependency paths;edge and vertex walk features, argument and triggermodifiers and heads, words in between.For fB (p, q) we re-use the token pair representa-tions from fR.
In particular, we create one activefeature for each element in feats (p, q).5.3 Shared Task 2009We first evaluate our models on the Bionlp 2009 task1.
The training, development and test sets for this2http://nlp.stanford.edu/software/corenlp.shtml8SVT BIND REG TOTMcClosky 75.4 48.4 40.4 53.5Poon 77.5 47.9 44.1 55.5Bjoerne 77.9 42.2 45.5 55.7Miwa 78.6 46.9 47.7 57.8M1 77.2 43.0 45.8 56.2M2 77.9 42.4 47.6 57.2M3 78.4 48.0 49.1 58.7Table 1: F1 scores for the development set of Task 1 ofthe BioNLP 2009 shared task.task consist of 797, 150 and 250 documents, respec-tively.Table 1 shows our results for the development set.We compare our three models (M1, M2 andM3) andprevious state-of-the-art systems: McClosky (Mc-Closky et al, 2011a), Poon (Poon and Vander-wende, 2010), Bjoerne (Bj?rne et al, 2009) andMiwa (Miwa et al, 2010b; Miwa et al, 2010a).
Pre-sented is F1 score for all events (TOT), regulationevents (REG), binding events (BIND) and simpleevents (SVT).Model 1 is outperforming the previous best jointmodels of Poon and Vanderwende (2010), as well asthe best entry of the 2009 task (Bj?rne et al, 2009).This is achieved without careful tuning of thresh-olds that control flow of information between triggerand argument extraction.
Notably, training Model 1takes approximately 20 minutes using a single coreimplementation.
Contrast this with 20 minutes on 32cores reported by Poon and Vanderwende (2010).Model 2 focuses on regulation structures and re-sults demonstrate this: F1 for regulations goes up bynearly 2 points.
While the impact of joint modelingrelative to weaker local baselines has been shownshown by Poon and Vanderwende (2010) and Riedelet al (2009), our findings here provide evidence thatit remains effective even when the baseline systemis very competitive.With Model 3 our focus is extended to bindingevents, improving F1 for such events by at least 5 F1.This also has a positive effect on regulation events,as regulations of binding events can now be moreaccurately extracted.
In total we see a 1.1 F1 in-crease over the best results reported so far (Miwa etal., 2010b).
Crucially, this is achieved using only asingle parse tree per sentence, as opposed to threeSVT BIND REG TOTMcClosky 68.3 46.9 33.3 48.6Poon 69.5 42.5 37.5 50.0Bjoerne 70.2 44.4 40.1 52.0Miwa 72.1 50.6 45.3 56.3M1 71.0 42.1 41.9 53.4M2 70.5 41.3 43.6 53.7M3 71.1 52.9 45.2 55.8M3+enju 72.6 52.6 46.9 57.4Table 2: F1 scores for the test set of Task 1 of the BioNLP2009 shared task.used by Miwa et al (2010a).Table 2 shows results for the test set.
Here withModel 1 we again already outperform all but the re-sults of Miwa et al (2010a).
Model 2 improves F1for regulations, while Model 3 again increases F1for both regulations and binding events.
This yieldsthe best binding event results reported so far.
No-tably, not only are we able to resolve binding am-biguity better.
Binding attachments themselves alsoimprove, as we increase attachment F1 from 61.4 to62.7 when going from Model 2 to Model 3.Miwa et al (2010b) use two parsers to generatetheir input features.
For fairer comparison we aug-ment Model 3 with syntactic features based on theenju parser (Miyao et al, 2009).
With these features(M3+enju) we achieve the best results on this datasetreported so far, and outperform Miwa et al (2010b)by 1.1 F1 in total, 1.6 F1 on regulation events and2.0 F1 on binding events.We also apply Model 3, with slight modifications,to the BioNLP 2009 task 2 which requires cellu-lar locations to be extracted as well.
With 53.0 F1we fall 2 points short of the results of Miwa et al(2010b) but still substantially outperform any otherreported results on the dataset.
More parse trees mayagain substantially improve results, as well as task-specific constraint and feature sets.5.4 Shared Task 2011We entered the Shared Task 2011 with Model 3,primarily focusing on Genia track (task 1), and theInfectious Diseases track.
The Genia track differsfrom the 2009 task by including both abstracts andfull text articles.
In total 908 training, 259 develop-ment and 347 test documents are provided.9Genia Task 1 Infectious DiseasesSystem TOT System TOTM3+Stanford 56.0 M3+Stanford 55.6M3 55.2 M3 53.4UTurku 53.3 Stanford 50.6MSR-NLP 51.5 UTurku 44.2ConcordU 50.3 PNNL 42.6Table 3: F1 scores for the test sets of two tracks in theBioNLP 2011 Shared Task.The top five entries are shown in table 3.
Model3 is the best-performing system that does not usemodel combination, only outperformed by a versionof Model 3 that includes Stanford predictions (Mc-Closky et al, 2011b) as input features (Riedel et al,2011).
Not shown in the table are results for full pa-pers only.
Here M3 ranks first with 53.1 F1, whileM3+Stanford comes in second with 52.7 F1.The Infectious Diseases (ID) track of the 2011task has 152 train, 46 development and 118 testdocuments.
Relative to Genia it provides less dataand introduces more types of entities as well asthe biological process event type.
Incorporatingthese changes into our models is straightforward,and hence we omit details for brevity.Table 3 shows the top five entries for the Infec-tious Diseases track.
Again Model 3 is the best-performing system that does not use model combi-nation, outperformed only by Model 3 with Stanfordpredictions as features.
We should point out thatthe feature sets and learning parameters were keptconstant when moving from Genia to ID data.
Thestrong results we observe without any tuning to thedomain indicate the robustness of joint modeling.5.5 Runtime BehaviorTable 4 shows the asymptotic complexity of ourthree models with respect to m = |Trig (x)|, n =|Cand (x)| and p = |Prot (x)|.
We also show thenumber of iterations needed on average, the averagetime in milliseconds per sentence,3 and the fractionof sentences we get certificates of optimality for.As expected, Model 1 is most efficient, bothasymptotically and on average.
Given that its ac-curacy is already good, it can serve as a basis for3Measured without preprocessing and feature extraction.Complexity Iter.
Time ExactM1 O (nm) 1.0 60ms 100%M2 O (Rnm) 10.4 183ms 96%M3 O (Rnm + Rp2m) 11.7 297ms 94%Table 4: Complexity and Runtime Behavior.large-scale extraction tasks.
Models 2 and 3 re-quire several iterations and more time, while pro-viding slightly less certificates.
However, given theimprovement in F1 they deliver, and the fact prepro-cessing steps such as parsing would still dominatethe average time, this seems like a reasonable priceto pay.6 ConclusionWe presented three joint models for biomedicalevent extraction.
Model 1 reaches near-state-of-the-art results, outperforms all previous joint modelsand has quadratic runtime guarantees.
By explicitlycapturing regulation events (Model 2), and bindingevents (Model 3) we achieve the best results reportedso far on several event extraction tasks.
The runtimepenalty we pay is kept minimal by using dual de-composition.
We also show how dual decompositioncan be used for constraints that go beyond couplingequalities.We use joint models, a decomposition techniqueand supervised online learning.
This recipe can besuccessful in many settings, but requires expensivemanual annotation.
In the future we want to inte-grate weak supervision techniques to train extractorswith existing biomedical databases, such as KEGG,and only minimal amounts of annotated text.AcknowledgementsThis work was supported in part by the Centerfor Intelligent Information Retrieval.
The Univer-sity of Massachusetts gratefully acknowledges thesupport of Defense Advanced Research ProjectsAgency (DARPA) Machine Reading Program underAir Force Research Laboratory (AFRL) prime con-tract no.
FA8750-09-C-0181.
Any opinions, find-ings, and conclusion or recommendations expressedin this material are those of the authors and do notnecessarily reflect the view of the DARPA, AFRL,or the US government.10ReferencesJari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Extract-ing complex biological events with rich graph-basedfeature sets.
In Proceedings of the Natural LanguageProcessing in Biomedicine NAACL 2009 Workshop(BioNLP ?09), pages 10?18, Morristown, NJ, USA.Association for Computational Linguistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL ?05),pages 173?180.Koby Crammer and Yoram Singer.
2003.
Ultraconserva-tive online algorithms for multiclass problems.
Jour-nal of Machine Learning Research, 3:951?991.Ulrich Germann, Michael Jahr, Kevin Knight, DanielMarcu, and Kenji Yamada.
2001.
Fast decoding andoptimal decoding for machine translation.
In Proceed-ings of the 39th Annual Meeting of the Association forComputational Linguistics (ACL ?01), pages 228?235.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overviewof bionlp?09 shared task on event extraction.
InProceedings of the Natural Language Processing inBiomedicine NAACL 2009 Workshop (BioNLP ?09).Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011.
Overview ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Nikos Komodakis, Nikos Paragios, and Georgios Tziri-tas.
2007.
Mrf optimization via dual decomposition:Message-passing revisited.
In Proceedings of the 11stIEEE International Conference on Computer Vision(ICCV ?07).Terry Koo, Alexander M. Rush, Michael Collins, TommiJaakkola, and David Sontag.
2010.
Dual decomposi-tion for parsing with nonprojective head automata.
InProceedings of the Conference on Empirical methodsin natural language processing (EMNLP ?10).David McClosky and Eugene Charniak.
2008.
Self-training for biomedical parsing.
In Proceedings of the46th Annual Meeting of the Association for Computa-tional Linguistics (ACL ?08).David McClosky, Mihai Surdeanu, and Chris Manning.2011a.
Event extraction as dependency parsing.
InProceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics (ACL ?11), Port-land, Oregon, June.David McClosky, Mihai Surdeanu, and Christopher D.Manning.
2011b.
Event extraction as dependencyparsing in bionlp 2011.
In BioNLP 2011 Shared Task.R.
McDonald and F. Pereira.
2006.
Online learningof approximate dependency parsing algorithms.
InProceedings of the 11th Conference of the EuropeanChapter of the ACL (EACL ?06), pages 81?88.Ivan Meza-Ruiz and Sebastian Riedel.
2009.
Jointlyidentifying predicates, arguments and senses usingmarkov logic.
In Joint Human Language Technol-ogy Conference/Annual Meeting of the North Ameri-can Chapter of the Association for Computational Lin-guistics (HLT-NAACL ?09).Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, andJun?ichi Tsujii.
2010a.
A comparative study of syn-tactic parsers for event extraction.
In Proceedings ofthe 2010 Workshop on Biomedical Natural LanguageProcessing, BioNLP ?10, pages 37?45, Stroudsburg,PA, USA.
Association for Computational Linguistics.Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, andJun?ichi Tsujii.
2010b.
Evaluating dependency rep-resentation for event extraction.
In Proceedings of the23rd International Conference on Computational Lin-guistics, COLING ?10, pages 779?787, Stroudsburg,PA, USA.
Association for Computational Linguistics.Makoto Miwa, Rune Saetre, Jin-Dong D. Kim, andJun?ichi Tsujii.
2010c.
Event extraction with com-plex event classification using rich features.
Journal ofbioinformatics and computational biology, 8(1):131?146, February.Yusuke Miyao, Kenji Sagae, Rune S?tre, Takuya Mat-suzaki, and Jun ichi Tsujii.
2009.
Evaluating contribu-tions of natural language parsers to protein-protein in-teraction extraction.
Bioinformatics/computer Appli-cations in The Biosciences, 25:394?400.Hoifung Poon and Lucy Vanderwende.
2010.
Joint Infer-ence for Knowledge Extraction from Biomedical Lit-erature.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages813?821, Los Angeles, California, June.
Associationfor Computational Linguistics.Vasin Punyakanok, Dan Roth, Wen tau Yih, and Dav Zi-mak.
2004.
Semantic role labeling via integer linearprogramming inference.
In Proceedings of the 20th in-ternational conference on Computational Linguistics(COLING ?04), pages 1346?1352, Morristown, NJ,USA.
Association for Computational Linguistics.Sebastian Riedel and James Clarke.
2006.
Incremen-tal integer linear programming for non-projective de-pendency parsing.
In Proceedings of the Conferenceon Empirical methods in natural language processing(EMNLP ?06), pages 129?137.Sebastian Riedel and Andrew McCallum.
2011.
Robustbiomedical event extraction with dual decompositionand minimal domain adaptation.
In Proceedings of the11Natural Language Processing in Biomedicine NAACL2011 Workshop (BioNLP ?11), June.Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi,and Jun?ichi Tsujii.
2009.
A markov logic approach tobio-molecular event extraction.
In Proceedings of theNatural Language Processing in Biomedicine NAACL2009 Workshop (BioNLP ?09), pages 41?49.Sebastian Riedel, David McClosky, Mihai Surdeanu,Christopher D. Manning, and Andrew McCallum.2011.
Model combination for event extraction inBioNLP 2011.
In Proceedings of the Natural Lan-guage Processing in Biomedicine NAACL 2011 Work-shop (BioNLP ?11), June.Sebastian Riedel.
2008.
Improving the accuracy and ef-ficiency of MAP inference for markov logic.
In Pro-ceedings of the 24th Annual Conference on Uncer-tainty in AI (UAI ?08), pages 468?475.D.
Roth andW.
Yih.
2004.
A linear programming formu-lation for global inference in natural language tasks.
InProceedings of the 8th Conference on ComputationalNatural Language Learning (CoNLL?
04), pages 1?8.Alexander M. Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decompositionand linear programming relaxations for natural lan-guage processing.
In Proceedings of the Conferenceon Empirical methods in natural language processing(EMNLP ?10).Kristina Toutanova, Aria Haghighi, and Christopher D.Manning.
2005.
Joint learning improves semantic rolelabeling.
In Proceedings of the 43rd Annual Meetingof the Association for Computational Linguistics (ACL?05), pages 589?596, Morristown, NJ, USA.
Associa-tion for Computational Linguistics.12
