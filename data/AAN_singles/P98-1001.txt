A Quasi-Dependency Model for Structural Analysisof Chinese BaseNPs*Zhao Jun Huang ChangningDepartment ofComputer Science & Technology,The State Key Lab of Intelligent Technology & Systems,Tsinghua University, Beijing, China, 100084Email: zj@sl000e.cs.tsinghua.edu.cn, Hcn@tsinghua.edu.cnAbstract: The paper puts forward a quasi-dependency model for structural analysis of ChinesebaseNPs and a MDL-based algorithm for quasi-dependency-strength acquisition.
The experimentsshow that the proposed model is more suitable forChinese baseNP analysis and the proposed MDL-based algorithm is superior to the traditional ML-based algorithm.
The paper also discusses theproblem of incorporating the linguistic knowledgeinto the above statistical model.1.
IntroductionThe concept of baseNP is initially put forwardby Church.
In English, baseNP is defined as'simple non-recursive noun phrases', which meansthat there is no sub-noun-phrases contained in abaseNP\[1\].
B~t the definition can not meet theneeds in Chinese information retrieval.
The nounphrases such as "1~ ~(natural) ~-~(language)~(process ) " ,  "~-IF~b~l(Asian) ~;-'~!\]~(finance) ~f~~(crisis)" and " i~(pol i t ical)  /?~k$1J(system)~(reformation) ~.~(process)" are critical forinformation retrieval, but they are not non-recursive noun phrases.TypeIn Chinese, the attribute of noun phrases can beclassified into three types, that is restrictiveattributes, distinctive attributes and descriptiveattributes, among which the restrictive attributeshave agglutinative relation with the heads.
Theusing the paper defines the Chinese baseNPrestrictive attributes.\[ Definition 1 \] Chinese baseNP (hereafterabbreviated asbaseNP)-baseNP -- baseNP + baseNPbaseNP --- baseNP + N I VNbaseNP -- restrictive-attribute + baseNPbaseNP --- restrictive-attribute + N I VNrestrictive-attribute --- A I B I V IN \] S I X I(M+Q)Where, the terminal symbols A, B, V, N, VN, S, X,M, Q stand for respectively adjective, distinctives,verbs, nouns, norminalized verbs, locatives, non-Chinese string, numerals and quantifiers.According to the definition, noun phrasesfalls into baseNPs and non-baseNPs (abbreviatedas ~baseNP).
Table-1 gives some examples.Table- 1 : Examples of baseNP and -baseNPExamplesBaseNP ~ q~/air z-I~/eorridorBaseNP i~'~/politics/t~k$1J/system ~/ re formBaseNP ,W, D/export ~ h/commodity ffl'~/price ~/ indexbaseNP ~,/compl icated I~/de ~fi~q-'/feature- baseNP ~i)~/research -~/and ~J~/development-baseNP ~i~l~/teacher q/write t~/de i ,~/eommentBoth baseNP recognition and baseNP structuralanalysis are basic tasks in Chinese informationretrieval.
The paper mainly discusses the problemsin structural analysis of baseNPs, which isessential for generating the compositionalindexing units from a baseNP.
The task of baseNP?
The research is supported bythe key project of the National Natural Science Foundation1structural analysis is to determine the syntacticstructure of a baseNP.
In this paper, we usedichotomy for baseNP analysis.
For example, thestructure of "I~1 ~/natural ~/ ianguage ~J~/process" is "( ~ ~/natural i,~'/language) ~/process".
Obviously, a baseNP composed of threeor more than three words has syntactic ambiguities.For example, baseNP "x y z" has two possiblestructures, that is "(x y) z" and "x (y z)".
The taskof baseNP structural analysis is to select thecorrect structure from the possible structures.The paper mainly discusses the problemsrelated to Chinese baseNP structural analysis.Section 2 puts forward a quasi-dependency modelfor structure analysis of Chinese baseNPs.
Section3 gives an unsupervised quasi-dependency-strength estimation algorithm based on theminimum description length (MDL) principle.Section 4 analyzes the performance of theproposed model and the algorithm.
Section 5discusses ome issues in the implementation ofbaseNP structure analysis and quasi-dependency-strength estimation.
Section 6 is the conclusion.2.
The quasi-dependency modelThere are two kinds of structural analysismodels for Eng!ish noun phrase, that is adjacencymodel and dependency model.
The research ofLauer shows that the dependency model issuperior to the adjacency model for structuralanalysis of English noun phrase\[2\].
However,there is no model for structural nalysis of ChinesebaseNP till now.According to the dependency grammar, twoconstituents can be bound together they aredetermined to be dependent.
The determination fy z ythe dependency relation between two constituentsis composed of two steps.
The first step is todetermine whether they have the possibility toconstituent dependency relation.
The second stepis to determine whether they have dependencyrelation in the given context.
The former is calledthe quasi-dependency-relation, which can beacquired from collocation dictionaries or corpora.The determination f the latter is difficult, becausemultiple information in the given context shouldbe taken into consideration, such as syntax Orsemantics information, etc.\[ Definition 2 \] Quasi-Dependency-Relation: Iftwo words x and y have the possibility toconstituent dependency relation, then we say thatthey have quasi-dependency-relation in the givenbaseNP, formulated as x--"y (where y is called thehead) or y- -x  (where x is called the head);Otherwise, we say that they have no quasidependency relation, formulated as x ~ y andy--/~x.\[Assumption 1\] In a Chinese baseNP, if twowords x and y can constituent dependency relation,then the head is always the post-positon word y,that is x' -y .According to the Definition 1, there is nopreposition phrase, verb phrase, locality phrase or(l~)-structure in a baseNP, so assumption-1 isreasonable.On the basis of assumption-l, we put forwardthe quasi-dependency model for structural analysisof Chinese baseNPs.There are the following 3 kinds of quasi-dependency-pattern for a tri-word-composedbaseNP xyz.z X gXYWhere, pattern s3t means x~y,  y -"z  andx ~ z,which corresponds to structure (x y) z; pattern s3~means x-"z, y~z  and x ~ y,  which correspondsto the structure x (y z); However, the quasi-dependency-strength must be used to determinethe corresponding structure for pattern s33, whichmeans x--*y, y-"z  and x---z.
For example, as forbaseNP " i~ ~/polit ics ~ ~tJ/system La~J ,/ x x J x ,/ x J ,/ J 4 Jv y y I Is3, =(x y) z s==x O' z)/reform", there are quasi-dependency-relations "~~/politics--- ~k~U/system", "~ ~/politics-" ~/reform" and "~k~lJ/system--- ~/ re form" .
If weknow that the quasi-dependency-relations " i~/politics--- ~iJ/system" and "/~k~lJ/system-- ~/reform" are stronger than " i~/po l i t i cs~/reform", the structure of the baseNP can bedetermined to "( i~/pol i t ics  ~qk~lJ/system) ~2/reform".In the following, we give the definition ofquasi-dependency-strength and the formula fordetermining the syntactic structure of baseNPsbased on the quasi-dependency-strengths.\[Definition 3 \]quasi-dependency-strength: Givena baseNP set NP={npt,np2,...,npM} and lexiconW={W~,...,WM} , VW~, Wj E W , the quasi-dependency-strength of w~wj  is defined as:~_a dep( w i --~ w.i , nP t )npt ~ NPdsCwi --~ w~) = Z co(w~ --~ w j, rip, )npt ~ NPwhere dep(w i ~ w j ,npk) i s  the count ofdependent word pair w~'w~ contained in np,,co(w~, w~,np,) is the count of cooccurent wordpair (w~, wj) contained in np,.The formula for determining the syntacticx y z x y z  Uw, lx xx J x X JY Y 4S41 = ((wx)y)z S42 = (wx)(yz)structure of baseNP based on the quasi-dependency-strengths is a  follows.ds(u ~ v)(u..-~v)eD(np~ ,s j )belief(sj I np, ) = Z ds(u ~ v) + Z ds(u ~ v)(u---~v)aD(np i ,s I ) (u-~v)~D(npi ,.vI )Where, bel ief(s j  \]nPi) represents he belief inwhich the structure of np~ is sj.
D(npi,sj) representsthe set of quasi-dependency-relations included inthe quasi-dependency-pattern corresponding tostructure sj.A tri-word-composed baseNP has two possiblesyntactic structures, that is s3t and s32.
Similarly, afour-word-composed baseNP has the followingfive possible structures.x y zx J xY Ys43 ; (~) )zIn summary, we can compute the belief inwhich the structure of npi is sj using thecorrespondence between the quasi-dependency-pattern and the baseNP structure.
The acquisitionof quasi-dependency-strength be ween words isthe critical problem.3.
The acquisition of quasi-dependency-strength between wordsIf we have a large scale baseNP annotatedcorpus in which the baseNPs have been assignedthe syntactic structures, the quasi-dependency-strength between words can be acquired through asimple statistics.
However, such an annotatedcorpus is not available.
We only have a baseNPcorpus which has no structural information.
Howto acquire the quasi-dependency-strength fromsuch a corpus is the main task of the section.Given a baseNP set NP={npi,np2,...,npM} and alexicon W={wl,w2 ..... WM}, the problem can bedescribed as learning a quasi-dependency-strengthset G (abbreviated asmodel) from the training set.Where, G = {asO.
Id.sj --- d4w  wjx y z x y zJ X x X4 Y$44 = W((Xy)Z) $45 = W(X(yT))Zhai Chengxiang puts forward an unsupervisedalgorithm for acquiring quasi-dependency-strengthfrom noun phrase set\[3\].
The algorithm is derivedfrom the EM algorithm.
Because the algorithm isbased on the maximum likelihood (ML) principle,it usually leads to overfitness between the data andthe model\[4\].
For example, given a simple baseNPset NP={i~/pol i t ics ~k~lJ/system ~/ re form,_t~:/economics ~k~lJ/system ~i~/reform, i~/politics ~ f~lJ/system ~ ~/revolute , ~/economics/t~lJ/system ~/ revo lu te} ,  there aresixteen possible models for the training set, amongthem (34, GT, G~0 and Gt3 have the best fitness toNP, that is Num(NPIG)=6.
However, in thelinguistic view, G~ is the correct model, though ithas lower fitness to NP, that is Num(NPIG)=4 (seethe appendix).3.1 The estimation of the quasi-dependency-strength under Bayesian frameworkIn Bayesian framework, the task of acquiringthe quasi-dependency-strength can be described asthe problem of selecting G which has the highestposterior probability p( G \[NP).G = arg max p(G I We)GAccording to Bayesian theorem, we have thefollowing inference.G = arg  max p(Ne I G)p(G)G p(NP)-- a rg  max p(Ne I G)p(G)GBesides using conditional probability p(NP\[G)to measure the fitness between the training set andthe model G, Bayesian modeling ives additionalconsideration to the generality of the modelthrough the prior probability p(G), that is simplermodel has higher probability.
The central idea ofBayesian modeling is to find a compromisebetween the goodness of fit and the simplicity ofthe model.3.2 Defining the evaluation function of Bayesianmodeling using MDL principleThe difficulty in Bayesian modeling is theestimation of the prior probability p(G).
Accordingto the coding theory, the lower bound of thecoding length (bit-string) of an information withprobability p is log 2 l/p\[5\].
The theoremconnects Bayesian modeling with the MDLprinciple in the coding theory.G = arg  max p(NPIG)p(G)G-- arg min  {-log2 \[p(NPIG)p(G)\]}G= arg min  {log2 1 + log 2 1G p(NPIG) -~-~}= arg  min  {L(NP \[ G) + L(G)}GWhere, L(a)  is the optimal coding length ofinformation a.
Specially, L(NPIG) is called thedata description length and L(G) is called themodel description length.Therefore, the problem of estimating the priorprobability p(G) and the conditional probabilityp(NPIG) is converted to the problem of estimatingthe model description length L(G) and the datadescription length L(NPIG).3_3 The MDL-based quasi-dependency-strengthestimation algorithmIn MDL principle, the modeling problem can heviewed as a problem of finding a model G whichhas the smallest sum of the data description lengthand the model description length.
Because thesearch space is huge, we can not find the optimalmodel in a transversal manner.
The model must beimproved in an iterative manner in order to arriveat a minimum description length.In the research, the model is composed of thequasi-dependency-strength ds(wi ~ wj ), whereeach ds(w i ~ w j)  can be decomposed into twoparts: Othe structure part: the quasi-dependency-relation (w i ~ w j ) ;  (~)the parameter part: thequasi-dependency-strength ds.
Therefore, thelearning process is divided into two steps: (!
)Keeping the structure part fixed, optimize theparameter part; (g)Keeping the parameter partfixed, optimize the structure part.
The two steps goon alternately until the process arrives at aconvergent point.Algorithm 1: The MDL-based algorithm for quasi-dependency-strength estimation(!
)Initialize model G;(~Let L = L( NP \[ G) + L( G), G = ( G s , G e ) ,where Gs and Gp represent respectively the structure part and theparameter part.
Execute the following two steps alternately, until L converged.?
Keeping Gs fixed, optimize Gp, until L(NP I G) converges, that is L converges;?
Keeping Gp fixed, optimize Gs, until L(G) converges, that is L converges.On condition that the structure part of the modelis fixed, the parameter optimization means to findthe optimal sets of quasi-dependency-strength iorder that the data description length minimized,4that isC -- a rg  min  LCNP I G)GWhere L(NPIG ) is the optimal coding length of NPwhen G is known.The parameter optimization step can beimplemented using EM algorithm\[3\].
In theprocess of parameter optimization, the structurepart of the model is kept fixed.
The optimumestimates of the parameters are obtained throughAlgorithm 2: The structure optimization algorithmthe gradual reduction of data description length.In MDL principle, the model description lengthcan be gradually reduced through the modificationof the structure part of the model, therefore theoverall description length of the model is reduced.Let the model after the parameter optimization process is G, which is composed of the quasi-dependency-strength ds(w~  wj).QSort the quasi-dependency-strengths of model G in ascending order, that is ds tzl, ds \[21, ds I3\], .
..... ;(g) Repeat the following steps, until \[L(NP I G'} + L(G')\]- \[L(NP I G} + L(G)\] <= Th L (The.
is the selectedthreshold).
Let i= 1,?
Delete the quasi-dependency-strength ds til from model G;?
Construct the newmodel G';?
If \[L(NPIG')+L(G')\]-\[L(NPIG)+L(G)\]<=Th L Then the cycle ends Else let G=G' ,  i=i+1 andcontinue the next cycle.4.
The performance analysisThis section takes the N2+N2+N2-type (where N2represents bi-syllable noun) baseNPs as the testingdata in order to discuss the performance ofthe quasi-dependency-based model for structural analysis ofbaseNPs and the MDL-based algorithm for quasi-dependency-strength acquisition.
The training setincludes 7,500 N2+N2+N2-type baseNPs.
The closetesting set is the 500 baseNPs included in thetraining set.
The open testing set is the 500 baseNPsoutside the training set.
The testing target is theprecision of baseNP structural analysis, that isaprec is ion = -- ?
100%;bWhere a is the count of the baseNPs which arecorrectly analyzed, b is the count of the baseNPs inthe tesing set.4.1 The performance of the quasi-dependencymodelThe experiments shows: (~)In the N2+N2+N2-type baseNPs, the left-binding structure is about wotimes of the right-binding structure; (~)The analysisprecision of the quasi-dependency model is about7% higher than that of the adjacency model.
Thisconclusion can be explained intuitively through thefollowing example.
The structure of baseNP "~d::/doctor J~3~/dissertation ~/out l ine"  can not becorrectly determined through the adjacency model,because we can not find that he dependency strengthof "~:~/doctor ~3~/dissertation" is stronger thanthat of"J~3~/dissertation ~/out l ine" .
In the otherhand, the structure of the above baseNP can bedetermined to " (~/doctor  J~3~/dissertation)fl~/outline" through the quasi-dependency model,because both " t~/doctor  J~3~/dissertation" and ""~3~/dissertation ~_~/outline" are dependent wordpairs, while "~ ~/doctor ~.
~/outline" is anindependent word pair.
Table 2 is the testing result.Table-2: The analysis precision ofN2+N2+N2-type baseNPTesting type Right-binding Left-binding Adjacency model Quasi-dependency modelClose test 31.5% 68.5% 84.6% 91.5%Open test 32.7% 67.3% 81.5% 88.7%54.2 The performance of the MDL-basedalgorithm for quasi-dependency-strengthacquisitionThe ML algorithm is equivalent o the firstparameter optimization process of the MDLalgorithm.
The MDL process is composed of twoiterative optimization steps.
In the iterative process,the parameters are optimized gradually and themodel is simplified gradually as well.
Therefore, theoverfitness problem inherent in the ML algorithm issolved to a great extent.
In the following, theperformance of the ML algorithm and the MDLalgorithm are compared through comparing thebaseNP analysis precision of the models constructedusing the above two algorithms.
The precision islisted in Table-3.
The experiment shows that theMDL algorithm is superior to the ML algorithm.Table-3: The performance of ML algorithm and MDL algorithmBaseNP analysis precisionClose testML algorithm MDL algorithm89.0% 91.5%5.
Implementation issuesThe most difficult problem related to thestructural analysis of baseNPs is the acquisition ofthe quasi-dependency-strength.
T e proposedalgorithm(Algorithm 2) is an unsupervisedalgorithm, that is the parameters are estimatedover the baseNP corpus which has no  structuralinformation.
In order to improve the estimationresults and speed up the iteration process, somemeasures are taken during the implementation.5.1 The pre-assignment of the baseNP structureThe structures of some baseNPs can bedetermined using the linguistic knowledge.
Suchknowledge includes:(~) In a baseNP, a word pair which has thefollowing syntactic omposition is independent.?
Noun+Adjective: for example, " ~/ground/Noun :~/eomplicated/Adjective :~,~,/condition", \]~\]tll/glass/Noun ~\[/curved/AdjectiveOpen test~/pipe";?
Noun+Distinctive: for/elementary-school/Nounage/Distinctive } L~-~/child";example, " zJ~ ~:J\[~ I~ /of-the-right-?
Distinctive+Verb: for example, " ~/large/Distinctive ~ ~1~/fight/Verb -~ ~l\],/plane","~l~\[/elementary/Distinetive /l~Fj:/ereepNerbS/animal".
(g) If two verbs cooccur in a baseNP, then they aredependent.
For example," (lgJJ~/prospeet/Verb "~/design/Verb ) ~ ~./group ", " ( ~ \[\]/Anti-Japanese/Verb ~\[\[~i/save-the-nationNerb) J~/campaign".If we preproeess the baseNP corpus using theML algorithm \[ MDL algorithm82.5% I 88.7%above knowledge, it is beneficial for the estimationprocess.5.2 The complex-feature-based modelingIf the lexicon size is \ ]~, then the parameternumber of the above word-based acquisitionalgorithm amounts to \[~2.
The enormous parameterspace will lead to the data sparseness problem duringthe estimation.
Therefore, the paper puts forward thecomplex-feature-based acquisition algorithm.
First,map each word to a complex-feature-set according tothe multiple feature of the words; Then, acquire thequasi-dependency-strength between the complex-feature-sets.
During analyzing the structure of abaseNP, the strength between the complex-feature-sets is used instead of that between the words.
In theresearch, the multiple features include part-of-speech,number of syllables and word sense categories.6.
ConclusionsThe paper put forward a quasi-dependency modelfor structural analysis of Chinese baseNPs, and aMDL-based algorithm for the quasi-dependency-strength acquisition.
The experiments show that theproposed model is more suitable for Chinese baseNPanalysis and the proposed MDL-based algorithm issuperior to the traditional ML-based algorithm.
Thefurther research will focus on incorporating morelinguistic knowledge into the above statistical model.References\[1\] Church K., A stochastic parts program andnoun phrase parser for unrestricted text, In:Proceedings of the Second Conference on AppliedNatural Language Processing, 1988.6\[2\] Lauer M. Conceptual association for compoundnoun analysis, In: Proceedings of the 32 "d AnnualMeeting of the Association for ComputationalLinguistics, Student Session, Las Cruces, NM,1994.\[3\] Zhai Chengxiang, Fast Statistical Parsing ofNoun Phrases for Document Indexing, In:Proceedings of the 35 th Annual Meeting of theAssociation for Computational Linguistics, USA.
:Association for Computational Linguistics.
1997.311-318.\[4\] Stoicke A. Bayesian learning of probabilisticlanguage models, Dissertation for Ph.D. Degree,Berkeley, California: University of California,1994.\[5\] Solomonoff R. The mechanization f linguisticlearning, In: Proceedings of the 2nd InternationalConference on Cybernetics.Append ix :  An example for quasi-dependency-relation acquisitionFitness between G and NP I No.
Model G IGI~3~  ~$\[J(l ), ~$~J ( l  ) (~k~J)~(1) ,l #f$,J~(~), ~,$,l~(\]) 4 (~{,$~l)~(\]),~(o) ,  ~(o)  (~*$~)~@0),~(o) ,  ~@(o)  (@-i~*$~J)~O),~$~J(~), -~{*~J(~) (~{*$0)~(\]),4 ~$0~(\]), ~$~@(\]) 6 (~*$0)~0),~(o) ,  ~(o)  (~$~)~@(~),~(1) ,  _~F~(\]) (~*$,J)~(~),~*$0(~), ~$~J(\]) (~$~J)~(\]),7 ~$~J~(\]), {,$~/~(i) 6 (~$~J)~(t),~(o) ,  ~(~)  (~t~$,J)~(\]),~( i ) ,  ~(o)  (~:~$~)~@(\]),~{*$,J(1), ~{,$~J(~) (~t~$~J)~(~),lO ~$~J~(\]), ~$~J~(l) 6 (~{t$~)~O) ,~(~) ,  ~(o)  (~ ,$~J )~( \ ] ) ,~'~ ~(0), ~.~J~: ~ ~'(I ) (~ ~/:~J)~( l ),~(~J~)  (o)~(~$~J~)(o)~(~,~J~@) (o)~(~J~s) (o )~(~$~J~)  (o)~(~,~J~) (o )~(~$~J~) ( \ ] )~t~(~,$~J~) (o)~(~$~J~) ( \ ] )~(~$~J~#~)(o)~(~*$,J~) (I)~F(~$~J~)(o)~(~*$,~) (o)~(~*$~J~)(1)(~*$~l)~(\]),(~{*~J)~(~),(~*$~)~(\]),~(~$~J~) (I)~:(~$~J~)(o)~(~$, J~) (I)~$JJ(~), ~$,J(~)13 ~$~J~(~), ~J~(1)  6~t~,  ~(o), ~es(o)Num( NPIG )47
