Sha l t2  - a Symmetr i c  Mach ine  Trans la t ion  Sys tem wi thABSTRACTShal l2 is a knowledge-based machine translation sys-tem with a symmetric architecture.
The grammarrules, mapping rules between syntactic and conceptual(semantic) representations, and transfer ules for con-ceptual paraphrasing are all bi-directional knowledgesources used by both a parser and a generator.1.
IntroductionShalt2 is a research prototype of a knowledge-based,multi-domain/multi-lingual MT system.
It has twopredecessors, SHALT  \[~31 (1982-90) and KBMT-89131(1987-89), which brought us valuable lessons we re-flected in the design and implementation f Shalt2.
Asa result, Shal l2 has been designed and implementedas a symmetric MT system with frame-based concep-tual representation.
The advantages of a symmetric ar-chitecture coupled with a conceptual representation areobvious.
First, it allows us to maintain single knowl-edge sources for both parsing and generation.
We canautomatically control the coverage and reversibility ofthese processes.
Second, conceptual structures are adesirable interface for representing the meaning of sen-tences, machine-generated output (such as diagnosis byan expert system), and expressions in graphical lan-guages.
AI-baeed approaches can provide powerful in-ference methods for identification ofa (semi-)equivalentclass of conceptual representations, which correspondsto a paraphrasing capability.
Unlike interlingual MTsystems, our approach relieves the parser of the bur-den of generating a unique meaning representation fall equivalent sentences, which becomes harder in pro-portion to the number of languages the system has totranslate.2.
Sha l t2  Arch i tec ture  and  Knowl -edge  SourcesShalt2 has five types of knowledge sources: a setG of syntactic grammar ules (including dictionaries),a set C of hierarchically defined conceptual primitivescalled concept definitions, a set M of mapping rules be-tween syntactic and conceptual structures, a set P ofconceptual paraphrasing rules, and a set E of cases (astructurally and conceptually disambiguated set of sam-ple sentences).
These knowledge sources are shared bythree major processes: a parser, a concept mapper, anda generator.
G should be provided for each language,whereas the set C should be defined for each applica-tion domain.
M, P, and E should be provided for eachpair of a language and a domain.t Figure 1 shows anoverview of the Shall2 architecture.
*fOur theory of multi-domaln translation aims to compose a setof mapping rules efilclelxtly when Mever~l doma.lnn are combined.It it expected thffit wo ~tJ of mapping rules for ?
,ingle languagewill differ m~nly is lexieal mipping rules.Conceptual TransferKoichi TAKEDA Naohiko URAMOTOTetsuya NASUKAWA TMjiro TSUTSUMITokyo l~esearch Laboratory, IBM Research5-19 Sanban-cho, Chiyoda-ku, Tokyo 102, Japan{takeda,uramoto,nasukawa,tsutsumi} ~ rl.vnet.ibm.com| ....~ p ~Figure h Shalt2 Architecture2.1 Syntact ic  GrammarShalt2 currently has two English grammars (PEGand a less competent English grammar) and a Japanesegrammar.
The last two grammars are bi-directionaigrammars written in an LFG-llke formalism called apseudo-unification grammar (PUG)\[ x?\], and were orig-inally employed in KBMT-89.tt PEG is not bi-directional, since it has too many destructive opera-tions to build or encode record structures, but it isour primary English grammar for three reasons: (1)broad coverage, (2) ability to encapsulate structural am-biguities in a compact parse tree, and (3) compatibil-ity with other NLP programs that use PEG to analyzeEnglish sentences.
Our bi-directional English gram-mar is following up PEG and will be able to replaceit.
The symmetric architecture of Shalt2, however, al-lows uni-directional knowledge sources and processes tobe hooked into the system.
Their coverage and abil-ity to parse or generate sentences can be measured interms of a set of conceptual representations that theycan relate to syntactic structures.Although the syntactic structures of PEG and PUGgrammars differ, they are integrated into a singlesyntactic representation called Dependency Structures(DSs) \[s\].
Roughly speaking, a DS is a tree-like structurewith a set of nodes and a set of ares, which correspond tomaximal projections of syntactic onstituents and gram-t-f The Eagfish version was originally written by GLteg et al 12lbut wan notbi-directional.
The Jap~mese gr~.nmax was originallywritten by Mitamura and T~keda\[2\].
The Shall2 verlions ofthese PUG graxama~ have been modified conBiderably to allowthem to handle coordinations, compaxativ~, and so on.ACIES DE COLING-92.
NANTES.
23-28 AOLrT 1992 I 0 3 4 PROC.
OF COLING-92.
NANTES.
AUG. 23-28.
1992tactical relationships, respectively.
Some grammaticalformalisms such as Constraint Dependency Grammar 14\]postulate DSs as syntactic representations to which aconstraint satisfaction algorithm \[~1 can be applied in or-der to resolve syntactic/semantic ambiguities efficiently.In the following, we show a PEG parse tree and a PUGf-structure, which will have the same DS, for the simplesentence "Insert a diskette into the drive.""
PEG Parse Tree:(IMPR (VERB* 'Insert' (insert PS))(NP (DET (ADJ* 'a' (a BS)))(NOUN* 'diskette' (diskette SG)))(PP (PREP ~into')(DET (ADJ* 'the' (the BS)))(NOUN 'drive' (drive SG)))(PUNC ' . '
) )F-structure in the PUG English grammar:((ROOT insert) (CAT v) (SUBCAT trans)(FORM inf) (MOOD imp) (TENSE pros)(0BJ ((ROOT diskette) (CAT n)(DET indef) (NUM sg)))(PPADJUNCT (((ROOT drive) (CAT n)(DET def) (NUM sg)))))DS:insert (CAT v, SUBCAT traus,MOOD imp, TENSE pros)DOBJECTdiskette (CAT n, DET indof, NUM sg)PPADJUNCTdrive (CAT n, PREP into, DET def, NUM ag)The reader *nay no*lee that the above sentenceshould really have ambiguities in prepositional phraseattachment, which result in two conflicting depen-dencies "insert -PPADJUNCT- drive" and "diskette -PPADJUNCT- drkve" in a single DS.
We will discussthe handling of such ambiguities in Section 3.2.2 Concept  Def in i t ionsA set of conceptual primitives is called a Natural Lan-guage (NL) class system\[hi, and is maintained as ane It 171 object-oriented knowledge base under l~ram K' .
TheNL class system consists of a set of constant classes,three meta-classes, and virtual classeo with an exclusiveinheritance mechanism discussed below.Each class represcnts a concept in the real world.
Aclass hms zero or more slots, which describe the fillers itmay use to represent a compound concept.
NL objectsare particular instances of NL classes.
There are is-aand parl-of relationships defined over the NL classes.For example,(deTclass *insert(is-a (value *action))(:agent (sem *human *system))(:theme (sem *physical-object))(:goal (sem *location *physical-object)))defines a class *insert with an is-a link to a class *action,and three slots - :agent, :theme, and :goal.
The (value...) facet shows an actual filler of the slot, while the(see ...) facet shows the selectional restrictions on theslot.A class inherits each slot definition from its super-class(on), that is, the fillers of the is-a slot, uuless theslot is redefined.
A class can have more than one im-mediate superclass, but we restrict its inheritance tobe exclusive rather than general multiple inheritance.Tilat is, au instance of a claim c~s inherit slot definitionsfrom only one of its imraediate superclaaqes.
The ideabehind exclusive inheritance is to realize certain iden-tity of verbal and nominal word senses without mixingthe slot definitions of both.
For example, most verbshave nominal counterparts in a natural anguage, suchas '~insert" and "insertion."
Such a pair usually sharesslot definitions (:agent, :tlmmc, and :goal) and selec-tional restrictions, except that "insert" inherits tense,aspect, and modality from its "verbal" superclazs butnot cardinality, ordinal, and definiteness (that is, thequality of being indefinite or definite) from its "nom-inal" superclazs, although these features are inheritedby "insertion."
The following class definitions(defclass *physical-action(is-a (value *predicate)))(defclass *mental-object(is-a (value *object)))(defclass *action(in-u (value *physical-action*mental-object) ) )allow every instance of subclasses of *action to inheritslot definitions from either *physical-action or *mental-object.
Exclusive inheritance also contributes to per-formance improvement of the parser since it allows usto reduce the number of possible superclasses from anexponential number to a linear number.There are three recta-classes in NL classes - *vat,*set, and *fun - to represent concepts that are not in-eluded in the normal class hierarchy.
The first, *vat, isa variable that ranges over a set of NL classes, whichare constants.
Pronouns and question words in naturallanguages usually carry this kind of incomplete concept.The second, *set, is a set constructor that can representa coordinated structure in natural languages.
The third,*fun, is a function from NL objects to NL objects.
Itcaptures the meaning of a so-called sentiofunction word.For example, in some usages, the verb "take" does notreally indicate any specific action until it gets an argu-ment such as "a walk," "a rest," "a look."
It is thereforewell characterized as a function.Since we allow only exclusive inheritance, the NLclass system certainly lacks the ability to organizeclasse~ front various viewpoints, unlike ordinary multi-pie inheritance.
Virtual classes are therefore introducedto compensate for this inability.
I~br example,(de~velass *option(dsf (*math-coprocessor*hard-disk *software)))(ds?vclass *male-thing(dsf (equal :sex *male)))shows two types of virtual classe, *option and *male-thing.
The *option consists of the classes *math-coprocessor, *hard-disk, and *software.
The *male-thing is a class that includes instances of any class withthe :sex slot filled with *male.
Note that the main-tainability of a class hierarchy drastically declines if weallow classes uch as *option to be "actual" rather thanvirtual, as we will have many is-a links from anythingthat  could be an option.
The second type of virtualclass helps incorporate an-called semantic features intothe NL class system.
Existin~ machine-readable dictio-naries (for example, LDOCEt el) often have entries withsemantic features uch as HUMAN, LIQUID, and VF~HICLE that may not fit into a given ontological classhierarchy.
A virtual class definitionAcrEs DE COL1NG-92, NAlVtES, 23-28 ^ OUr 1992 1 0 3 5 PRec.
ol.
COLING-92, NAIVrES, Auo.
23-28.
1992(de:f vc laos  *haman(def (equal :haman * t rue) ) )with semantic restrictions (:agent (sere *human)) makeit possible to integrate such entries into the NL classsystem.The NL class system currently includes a few thou-sand concepts extracted from the personal-computerdomain.
The word senses in the SHALT dictionary(about 100,000 entries) and the LDOCE (about 55,000entries) have been gradually incorporated into the NLclass system.2.3 Mapp ing  RulesMapping rules define lexlcal and structural correspon-dences between syntactic and conceptual representa-tions.
A lexical mapping rule has the form(emap *insert<=i=> insert ((CAT v) (SUBCAT trans))(role =sQm (*physical-action))(:agent =syn (SUBJECT))(:theme =syn (DOBJECT))(:goal =syn (PPADJUNCT((PREP into) (CAT n)))))where a transitive verb "insert" maps to or from an in-stance of*insert with its exclusive superclass *physical-action.
The three slots for st,'uctural mapping betweenconcepts (:agent, :theme, and :goal) and grammaticalroles (SUBJECT, DOBJECT, and PPADJUNCT) arealso defined in this rule.
The :agent filler, for exam-ple, should be an instance that is mapped from a syn-tactic SUBJECT of the verb "insert."
The :goal fillermust be a prepositional phrase consisting of a noun withthe preposition "into."
The fragments of syntactic fea-ture structures following a lexical word or a grammat-ical function in a mapping rule specify the minimumstructures that subsume feature structures of candidatesyntactic onstituents.
These structural mappings arespecific to this instance.The structural mapping rule(emap *physical-action <=s=>(:mood =syn (MOOD))(:time =syn (TENSE)))specifies that the conceptual s ots :mood and :time mapto or from the grammatical roles MOOD and TENSE,respectively.
Unlike the structural mapping in a lexi-cal mapping rule, these slot mappings can be inheritedby any instance of a subclass of *physical-action.
The*insert instance defined above, for example, can inheritthese :mood and :time mappings.
Given a dependencystructure (DS), mapping rules work as distributed con-straints on the nodes and arcs in the DS in such a waythat a conceptual representation R is au image of the DSiff R is the minimal representation satisfying all the lex-ical and structural mappings associated with each nodeand arc.
On the other hand, given a conceptual repre-sentation K, mapping rules work inversely as constraintson 1% to define a minimal DS that can be mapped to 1%.Thus, assuming that lexieal mapping rules are similarlyprovided for nouns (diskette and drive) and feature val-ues (imp, pros, and so on), we will have the conceptualrepresentation~~Conceptual representation f a sentence consists of instancesof classes.
We use a hyphen and a number following ~ c|a~s name(*insert-l, *imp-l, ...) when it is necessaxy to show instaJlcesexplicitly.
Otherwise, we idtntlfy class na~nes and instance names.
(*insert-I(:mood (*imp-l))(:time (*pros-l))(:theme (*diskette-I (:def (*indef-l))(:ham (*sg-l))))(:goal (*drive-i (:dof (*def-l))(:hUm ( *sg -2) ) ) ) )for tile sample sentence and its DS shown earlier in thissection.2.4 Conceptua l  Paraphras ing  RulesWe assume that a source language sentence andits translation into a target language frequently haveslightly different conceptual representations.
An adjec-tive in English might be a eonjugable verb in trans-lation.
These differences result in added/missing in-formation in the corresponding representations.
Theconceptual paraphrasing rules describe such equiva-lence and seml-equivalence among conceptual represen-tations.
These rules are sensitive to the target language,but not to the source language, since the definition ofequivalence among conceptual representations dependson the cultural and pragmatic background of the lan-guage in which a translation has to be expressed.
Anexample of a paraphrasing rule is(oquiv (*equal (:agent (*X (:hUm (*V))))(:theme (*Y/*porson(:def *indef)(:sum (*W)))))(*Z/*ac%ion ( :agent  (*X) (:num (*V))))( such- that  (humanizat ion *Z *Y)(sibling *V *W)))where *Y/*person specifies *Y to be an instance of anysubclass of *person, *equal is roughly the verb "be,"humanization is a relation that holds for pairs such ms(*singer, *sing) and (*swimmer, *swim), and siblingholds for two instances of the same class.
Intuitively,this rule specifies an equivalence relationship betweensentences uch as "Tom is a good singer" and "Tomsings well," as the following bindings hold:(*equal (:mood (*dec)) (:time (*pros))(:agent (*tom (:num (*sg))))(:theme (*singer (:property (*good))(:dof (*indof))(:aura ( *sg) ) ) ) )(*s ing (:mood (*dec)) ( : t ime (*pros))( :agent  (*tom (:num (*sg) ) ) )( :p roper ty  (*good)))whore *X = *tom, *Y = *s inger ,  *Z = *s ing,*V = *sg, and *W = *sgAll the instances that have no binding in a rule mustremain unchanged as the same slot fillers (e.g., *dec and*pros), while some fillers that have bindings in a rulemay be missing from a counterpart instance (e.g., *indefand *W above).
Note that *good has lexical mappingsto the adjective "good" and the adverb "well.
"2.5 Case BaseA case base is a set of DSs with no syntactic/semanticambiguities.
A conceptual representation for a DS canbe computed by a top-down algorithm that recursivelytries to combine an instance mapped from the root nodeof a DS with an instance of each of its subtrees.
The arcfrom the node to a subtree deternfiues the conceptualslot name.We have already built a case base that includesabout 30,000 sentences from the IBM Dictionary ofACRES DE COLING-92.
NANTES, 23-28 AOUl 1992 1 0 3 6 PrisE, oF COLING-92, NANTES.
AUG. 23-28, 1992teAT v ,  keteBPc~theme OBJECT " : l ocat ion - - ln  -- theme ECT ~ PPADJONCT?
"*'-... / " (CAT  n) disket te  ......ICAT  n) : iocat lon -{n  ~ - ~  - - ~Only relevant hfformation is slmwn.
Mapping constraints(e.g.
:Umme =DOBJECT) are actually associated for eachpall" of instances.Figure 2: SamI)le DS with Mapping ConstraintsComputing \[x\].
Selected sentences in the \],DOCE havealso been added to the case base.
The sentences inthe LDOCE define word senses or show sample usagesof each entry.
Though composed of a limited vocabu-lary, they are often syntactically/semantically ambigu-ous and it is time-consuming for users to build thecase base completely manually.
Therefore, the Shalt2parser is used to develop the case base.
Starting witha small, manually crafted "core" ease base, e~ch newsentence is analyzed and disambiguated by the parserto generate a DS, which is corrected or otodified by theuser and then added to the case base.
As the size ofthe case base grows, tim prot)ortion of human correc-tions/modifications decreases, ince the output of theparser becomes more and more accurate.
Wise processis called knowledge bootstrapping and is discussed byNagao \[6\] in more detail.
Mapping coustraints, howevcr,are associated with only a part of the case base, becausethe NL class system and the mapping rules arc not yetcomplete.3.
Pm'serThe Shall2 parser first generates a DS with packedstructural ambiguities for a given inlmt sentence.
Itactually calls a PEG parser or 'lbmita's LR-parser \[12\]for PUG, and then calls a DS converter to map a PEGparse tree or a PUG feature structurc~ to a DS.
Next,mapping rules arc applied to the DS so that lexicaland structural mappings are associated with each nodeand arc in the DS.
Figure 2 shows a DS with map-ping constraints for the sentence "Keep the diskette inthe drive," where the verb "keep" has tive word senses:*execute, *guard, *hold, *employ, and *own.
It is clearthat we will end up with ten distinct conceptual repre-sentations if we evaluate all tim mapping rules, and ingeneral, combinatorial explosion could easily make theparser impractical.
Viewing the mapping rules as coo-stralnts rather titan procedural rules is the key to ourparser, and is called delayed composition of conceptualrepresentation.A sentence analyzer called SENA \[x41 disambiguatesthe DS by using a constraint solver JAUNT\[S\] and a"~Tomlta~s lucid amhigulty packing \[12\] isused to obtain a fea-ture structure with packed atructurM ambiguities.case base.
JAUNT applies grammatical constraints (forinstance, nlodifier-modifiee links between odes do notcross one another) and semantic onstraints (such asselectional restrictions,t~ functional control, and otherNL object identity constraints detected by the contextanalyzer) uniformly to a DS that has ambiguities, andcalculates pairwise consistency efficiently for each com-bination of nodes.
Finally, the case base provides prefoerential knowledge to favor one pair of nodes over allother consistent pairs.
The disambiguation process callbe summarized as follows:1.
For each conflicting arc in the DS, calculate the"dlstauce" \[6\] between the two nodes in the arc byusing a case base.2.
Leave tile ,xrc with the minimal distance and elimi-nate all the other conflicting arcs.
Each NL objectassociated with a matching node in the case basealso gives a higher preference to the same class ofinstance over the other instances in a node.3.
Propagate the deletion of arcs to other nodes andarcs in the DS.
Eliminate nodes and arcs that areno longer valid in the DS.4.
Apply the above steps until there are no conflictingarc~ in the DS.The resulting 1)S has 11o structural ambiguity.
B.e-madling lexical ambiguities are similarly resolved, be-cause we can also determine which pair of NL objectsconnected with an arc has the minimal distance in thecase base.
Our case base for cmnputer manuals wouldsupport the "diskette -PPADJUNCT- drive" arc andthe *hold-1 instance with diskette as its DOBJECT.Therefore, the parser will eventually return(*hold-1( : ~cheme (*diske~;t e( : l ocat ion - in  ( *dr ive) )  ) )as a disambiguated result.
Nagao \[e} discusses nore so-phisticated techniques such as scheduling sets of arcs tobc disambiguated, backtracking, and relaaation of casebase matching by means of an is-a hierarchy.Finally, a context analyzer is called to resolveauaphora, identity of definitc nouns, and implicit iden-tity between NL objects.
It stores the DS in the workingspace, where references to preceding instances are repre-sented by the links between instances in the DSs.
Theseinter-sentential links are used to determine the scopesof adverbs uch as "also" and "only".For example, if the phrase "role of an operator" ap-pears in a text, the word "operator" could be a personwho operates a machine or a logical operator for com-putation, but no sufficient information is available toresolve this ambiguity at this moment.
In such cases,creating referential links in a forest of DSs could leadus to find evidence for disamblguating these two mean-ings.
The scope of an adverb, such as "also," is de-termined by identifying repeated NL objects and newlyintroduced NL objects, where the latter are more likelyto fall within the scope of the adverb.The context analyzer uses a similar method to deter-mine lexical ambiguities that were not resolved by thesentence analyzer wlmn the case base failed to provideenough information.
?~We use about 20 of the semantic features described in theLDOCE.
The restrictions imposed by the features are rather"loose," and are used to eliminate only unlikely combinations ofword senses,Aches DE COL1NG-92.
NANII~S, 23-28 AO~r\[ 1992 l 03 '7 PRO{:, O1: COLING-92.
NANTES, AUO.
23-280 19924.
Concept MapperGiven a conceptual representation, which is an out-put from the parser, and a target language, the conceptmapper  tries to discover another conceptual represea-tation that has a well-defined mapping to a DS whilekeeping the semantic ontent as intact as possible.
Thisprocess is called conceptua l  t ransfer .
If the given con-eeptual representation already has a well-defined map-ping to a DS, the concept mapper does nothing andShalt2 works like an interlingual MT system.
It is im-portant hat conceptual transfer should be related withthe mapping to a DS, because there are generally manyconceptual representations with a similar semantic on-tent.
The existence of well-defined mapping not onlyguarantees that the generator can produce a sentencein the target language, but also effectively eliminatesunsuccessful paraphrasing.111 addition to the paraphrasing rules mentioned ear-lier, the concept mapper uses the following genera\] rulesfor conceptual transferJ The paraphrasing rules arecomposed to make a complex mapping.
* Projection: Map an NL object w i tha  filled slot sto an instance of the same class with the unfilledslot s. Projection corresponds to deletion of a slot8.s Generalization: Map an NL object of a class X toan instance of one of the superclasses of X.e Specialization: Map an NL object of a class X toan instance of one of the subclasses of X.As an example, a projection rule is frequently used whenwe translate English nouns into Japanese ones, as in thefollowing examp:diskette (*d isket te  (:sum (*s t ) ) )d i sket tes  (*d isket te  (:num (*pl)))a d isket te  (*d iskette  (:num (*s t ) )( :def  (*indeX)))the d isket tes  (*d isket te  (:num (*pl))(:def (*def)))~4A~r  7 ~ (*d isket te)Here, the four English noun phrases above are usuallytranslated by the same Japanese noun phasef~ (the fifthone), which does not carry any information on mumand :def.
We provide a paraphrasing rule for trans-lation in the opposite direction such that for any in-stance of the *object can obtain appropriate :sum and:def fillers.
The parser, however, is responsible for de-termining these fillers in most cases.
In general, thedesigner of semi-equivalent rules for translation in onedirection has to provide a way of inferring missing infor-mation for translation in the opposite direction.
Gen-eralization and specialization rules are complementaryand can be paired to become quivalent rules when aspecialization rule for any instance of a class z is un-ambiguous.
That is, without losing any fillers, one canalways choose an instance of a subclas~ Vto which z canbe uniquely mapped.
A generalization from e~ch ~ to zprovides the opposite mapping.~Theee are ~emi-equivMent rules.
Equivalent rules have higherpriority when the tulsa axe to be applied.~fOne exception is that deictic noun phrases are translatedwhen we use the ~apanme counterpart "-~?3 ~for the determiner"the".5.
Grammar-Based Sentence Genera-torRecent investigation of unification grammars andtheir bi-direetionality Its, 9, \]0\] has enabled us to designand implement a grammar-based generator.
Our gen~crater uses a PUG grammar, which is also used by theparser, to traverse or decompose a feature structure ob-tained from a D$ in order to find a sequence of grammarrule applications, which eventually lead to lexical rulesfor generating a sentence.
The generation algorithm isbased primarily on Wedekind's algorithm, but h merit-tied for PUG.The current implementation of our generator lackssubtle control of word ordering, honorific expressions,and style preference.
We are developing a set of dis-course  parameters  to a~ociate preferences with gram-mar rules to be tried, so that specific expressions arefavored by the parameter settings.AcknowledgmentYutaka Tsutsumi built an initial version of concep-tual definitions.
Katashi Nagao originally designed andimplemented the disambiguation algorighm of the sen-tence analyzer.
His continuous efforts to build a large-scale ease base and to improve the disambiguation al-gorithm have been continued by the Shalt2 group.
Hi-roshi Maruyama enhanced his constraint solver for ourproject, which has led us to a constraint propagationmethod with delayed composition of conceptual repre-sentations.
Michael McDonald read through an earlydraft of this paper and gave us many suggestions ontechnical writing.
We thank them all.References1) IBM Corp. "Dictionary off Computing" (gth Edition).
SC20-1999-07, 1987.2) D. Gates, K. Takeda, T. Mitamur&, L. LevLn, and M. Kee.
"Anaby=i, and Generation Grammar".
M~ehine T~,n=latio,, 4(1)153-9S t March 1989.3) K. Goodman and S. Nirenburg, editors.
"The KBMT Project: ACoze Study in Kno~ledse-B~#ed Me, chine ~an#|allon n. Mor-gan Kaufmann Pubi~herw, San Matzo, California, 1991.4) H. Maruyama.
"Structural Disambiguation with ConstraintPropagationS.
In Prec.
el the ?8th Anntml Meetin 9 of ACL,volume 31 pages 31-38, June 1990.5) H. Maruyama.
"JAUNT: A Constraint Solver for DisjunctiveFeature Structures".
Technical Report PDfOO59, Tokyo ~archLab., IBM Reaearchj 1991.6) K. Nagao.
"Dependency Analyzer: A Knowledge-Baaed Ap-proach to Structural Dmambiguation".
In prec.
of Ihe 13thlnlern?tlonal Con\]erence on Comput?tional Ling,lille*, pagen484-489, Aug. 1990.7) E. Nyberg.
"The FrameKit Uler% Guide Version 2.0".
TechnicalReport CMU-CMT-88-MEMO, Center for Machine Translation,Carnegie Mellon Univereity, March 1988.8) Procter P. Lo,t#man Dictionarp el Contemporar~ 1English.Longman Group Limited, Harlow and London~ England, I978.9) S.M.
Shieher, F. C. I"4.
Pereira, G. van Noord, and R. C.
Moore.
"Semantle-Head-Driven Generation".
Computational Linsni#-|icJ, 19(1):30-42, March 1990.1O) K. Takeda.
=Bi-DireetlonalGrammarlfor MachineTranalation".In Pros.
of Seoul International Conference on Natural Lan.guase Proce,Jin~, page~ 1~2~197, Seoul, Korea, 1November I990.11) K. Takeda.
UD~ign~ng Natural Language Objects n. In Prec.oJ ?nd lnlernationgl SFmpo*i~m on Databame S~/Jtem* for Ad.vaneed Appllcationlt pagem 444-448, Tokyo, Japan, April 1991.12) M. Tomlta.
"Effleienl Parsln 9 for N?tural Language: A FtstAlgor~th~ \]or Practical Sp*leml n. Kluwer Academic Publi0here,Beaten, MA, 198S.13) T. Ttutgurnl.
"A Prototype Engllsh-Japanene Machine Tr~nsi~-tips System for Tranalatln 8 IBM Computer Minuals".
In prec.of the l l th  lnternation?l ConJerenee on Computation?l Ligtt.i/tieJ, Auguut 1986.14) N, Uramoto.
"I~xical and Structural Disarnbiguation Using anExample*Brute".
In Prec.
of the Sad Ja~n-A~Jtml ia Joint.qytnpo#iu~t on NLP, pages 1nO-160, Oct. 1991.15) J, Wedekind, =Generation as Structure Driven Derivatlon".
InP~e.
of the l?th International Conference on ComputationalLigui*iiem , page= 732-737 t August 1988.ACRES DE COLING-92, NANTES, 23-28 AOt~T 1992 i 0 3 8 PROC.
OV COLING-92, NANTES, AUG. 23-28, 1992
