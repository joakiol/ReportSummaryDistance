Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 65?69,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsGenre Independent Subgroup Detection in Online Discussion Threads: APilot Study of Implicit Attitude using Latent Textual SemanticsPradeep Dasigipd2359@columbia.eduWeiwei Guoweiwei@cs.columbia.eduCenter for Computational Learning Systems, Columbia UniversityMona Diabmdiab@ccls.columbia.eduAbstractWe describe an unsupervised approach tothe problem of automatically detecting sub-groups of people holding similar opinions ina discussion thread.
An intuitive way of iden-tifying this is to detect the attitudes of discus-sants towards each other or named entities ortopics mentioned in the discussion.
Sentimenttags play an important role in this detection,but we also note another dimension to the de-tection of people?s attitudes in a discussion: iftwo persons share the same opinion, they tendto use similar language content.
We considerthe latter to be an implicit attitude.
In this pa-per, we investigate the impact of implicit andexplicit attitude in two genres of social mediadiscussion data, more formal wikipedia dis-cussions and a debate discussion forum thatis much more informal.
Experimental resultsstrongly suggest that implicit attitude is an im-portant complement for explicit attitudes (ex-pressed via sentiment) and it can improve thesub-group detection performance independentof genre.1 IntroductionThere has been a significant increase in discus-sion forum data in online media recently.
Most ofsuch discussion threads have a clear debate compo-nent in them with varying levels of formality.
Auto-matically identifying the groups of discussants withsimilar attitudes, or subgroup detection, is an inter-esting problem which allows for a better understand-ing of the data in this genre in a manner that coulddirectly benefit Opinion Mining research as well asCommunity Mining from Social Networks.A straight-forward approach to this problem isto apply Opinion Mining techniques, and extracteach discussant?s attitudes towards other discussantsand entities being discussed.
But the challenge isthat Opinion Mining is not mature enough to ex-tract all the correct opinions of discussants.
In ad-dition, without domain knowledge, using unsuper-vised techniques to do this is quite challenging.On observing interactions from these threads, webelieve that there is another dimension of attitudewhich is expressed implicitly.
We find that peoplesharing the same opinion tend to speak about thesame topics even though they do not explicitly ex-press their sentiment.
We refer to this as ImplicitAttitude.
One such example may be seen in the twoposts in Table 1.
It can be seen that even though dis-cussants A and B do not express explicit sentiments,they hold similar views.
Hence it can be said thatthere is an agreement in their implicit attitudes.Attempting to find a surface level word similar-ity between posts of two discussants is not sufficientas there are typically few overlapping words sharedamong the posts.
This is quite significant a problemespecially given the relative short context of posts.Accordingly, in this work, we attempt to model theimplicit latent similarity between posts as a means ofidentifying the implicit attitudes among discussants.We apply variants on Latent Dirichelet Allocation(LDA) based topic models to the problem (Blei etal., 2003).Our goal is identify subgroups with respect to dis-cussants?
attitudes towards each other, the entitiesand topics in a discussion forum.
To our knowl-edge, this is the first attempt at using text similar-ity as an indication of user attitudes.
We investigatethe influence of the explicit and implicit attitudes ontwo genres of data, one more formal than the other.We find an interesting trend.
Explicit attitude alone65as a feature is more useful than implicit attitude inidentifying sub-groups in informal data.
But in thecase of formal data, implicit attitude yields better re-sults.
This may be due to the fact that in informaldata, strong subjective opinions about entities/eventsor towards other discussants are expressed more ex-plicitly.
This is generally not the case in the formalgenre where ideas do not have as much sentiment as-sociated with them, and hence the opinions are more?implicit?.
Finally, we observe that combining bothkinds of features improves performance of our sys-tems for both genres.2 Related WorkSubstantial research exists in the fields of Opin-ion Identification and Community Mining that is re-lated to our current work.
(Ganapathibhotla andLiu, 2008) deal with the problem of finding opin-ions from comparative sentences.
Many previousresearch efforts related to Opinion Target Identifi-cation (Hu and Liu, 2004; Kobayashi et al, 2007;Jakob and Gurevych, 2010), focus on the domain ofproduct reviews where they exploit the genre in mul-tiple ways.
Somasundaran and Wiebe (2009) usedunsupervised methods to identify stances in onlinedebates.
They mine the web to find associationsindicative of opinions and combine them with dis-course information.
Their problem essentially dealswith the debate genre and finding the stance of an in-dividual given two options.
Ours is a more generalproblem since we deal with discussion data in gen-eral and not debates on specific topics.
Hence ouraim is to identify multiple groups, not just two.In terms of Sentiment Analysis, the work done byHassan et al(2010) in using part-of-speech and de-pendency structures to identify polarities of attitudesis similar to our work.
But they predict binary po-larities in attitudes, and our goal of identification ofsub-groups is a more general problem in that we aimat identifying multiple subgroups.3 ApproachWe tackle the problem using Vector Space Mod-eling techniques to represent the discussion threads.Each vector represents a discussant in the thread cre-ating an Attitude Profile (AP).
We use a clusteringalgorithm to partition the vector space of APs intomultiple sub-groups.
The idea is that resulting clus-ters would comprise sub-groups of discussants withsimilar attitudes.3.1 Basic FeaturesWe use two basic features, namely Negative andPositive sentiment towards specific discussants andentities like in the work done by (Abu-Jbara et al,2012).
We start off by determining sentences thatexpress attitude in the thread, attitude sentences(AS).
We use OpinionFinder (Wilson et al, 2005)which employs negative and positive polarity cues.For determining discussant sentiment, we need tofirst identify who the target of their sentiment is: an-other discussant, or an entity, where an entity couldbe a topic or a person not participating in the dis-cussion.
Sentiment toward another discussant:This is quite challenging since explicit sentiment ex-pressed in a post is not necessarily directed towardsanother discussant to whom it is a reply.
It is pos-sible that a discussant may be replying to anotherposter but expressing an attitude towards a third en-tity or discussant.
However as a simplifying assump-tion, similar to the work of (Hassan et al, 2010),we adopt the view that replies in the sentences thatare determined to be attitudinal and contain second-person pronouns (you, your, yourself) are assumedto be directed towards the recipients of the replies.Sentiment toward an entity: We again adopt a sim-plifying view by modeling all the named entities ina sentence without heeding the roles these entitiesplay, i.e.
whether they are targets or not.
Accord-ingly, we extract all the named entities in a sentenceusing Stanford?s Name Entity Recognizer (Finkel etal., 2005).
We only focus on Person and Organiza-tion named entities.3.2 Extracting Implicit AttitudesWe define implicit attitudes as the semantic sim-ilarity between texts comprising discussant utter-ances or posts in a thread.
We cannot find enoughoverlapping words between posts, since some postsare very short.
Hence we apply LDA (Blei et al,2003) on texts to extract latent semantics of texts.We split text into sentences, i.e., each sentence istreated as a single document.
Accordingly, each sen-tence is represented as a K-dimension vector.
Bycomputing the similarity on these vectors, we obtaina more accurate semantic similarity.66A: There are a few other directors in the history of cinema who have achieved such a singular and consistent worldview as Kubrick.His films are very philosophically deep, they say something about everything, war, crime, relationships, humanity, etc.B: All of his films show the true human nature of man and their inner fights and all of them are veryphilosophical.
Alfred was good in suspense and all, but his work is not as deep as Kubrick?sTable 1: Example of Agreement based on Implicit AttitudeWIKI CDMedian No.
of Discussants (n) 6 29Predicted No.
of Clusters (d?n2 e) 2 4Median No.
of Actual Classes 3 3Table 2: Number of Clusters3.3 Clustering Attitude SpaceA tree-based (hierarchical) clustering algorithm,SLINK (Sibson, 1973) is used to cluster the vec-tor space.
Cosine Similarity between the vectors isused as the inter-data point similarity measure forclustering.1 We choose the number of clusters to bed?n2 e, described as the rule of thumb by (Mardia etal., 1979), where n is the number of discussants inthe group.
This rule seems to be validated by the factthat in the data sets with which we experiment, wenote that the predicted number of clusters accordingto this rule and the classes identified in the gold dataare very close as illustrated in Table 2.
On averagewe note that the gold data has the number of classesper thread to be roughly 2-5.4 DataWe use data from two online forums - Cre-ate Debate [CD]2 and discussions from Wikipedia[WIKI]3.
There is a significant difference in the kindof discussions in these two sources.
Our WIKI datacomprises 117 threads crawled from Wikipedia.
It isrelatively formal with short threads.
It does not havemuch negative polarity and discussants essentiallydiscuss the Wikipedia page in question.
Hence it iscloser to an academic discussion forum.
The threadsare manually annotated with sub-group information.Given a thread, the annotator is asked to identify ifthere are any sub-groups among the discussants withsimilar opinions, and if yes, the membership of those1We also experimented with K-means (MacQueen, 1967)and found that it yields worse results compared to SLINK.There is a fundamental difference between the two algorithms.Where as K-Means does a random initialization of clusters,SLINK is a deterministic algorithm.
The difference in the per-formance may be attributed to the fact that the number of initialdata points is too small for random initialization.
Hence, treebased clustering algorithms are more well suited for the currenttask.2http://www.createdebate.com3en.wikipedia.orgProperty WIKI CDThreads 117 34Posts per Thread 15.5 112Sentences per Post 4.5 7.7Tokens per Post 78.9 118.3Word Types per Post 11.1 10.6Discussants per Thread 6.5 34.15Entities Discovered per Thread 6.15 32.7Table 3: Data Statisticssubgroups.On the other hand, CD is a forum where peopledebate a specific topic.
The CD data we use com-prises 34 threads.
It is more informal (with per-vasive negative language and personal insults) thanWIKI and has longer threads.
It is closer to the de-bate genre.
It has a poll associated with every de-bate.
The votes cast by the discussants in the pollare used as the class labels for our experiments.
De-tailed statistics related to both the data sets and acomparison can be found in Table 3.5 Experimental ConditionsThe following three features represent discussantattitudes:?
Sentiment towards other discussants (SD) - Thiscorresponds to 2 ?
n dimensions in the Attitude Pro-file (AP) vector, n being the number of discussantsin the thread.
This is because there are two polari-ties and n possible targets.
The value representingthis feature is the number of sentences with the re-spective polarity ?
negative or positive ?
towards theparticular discussant.?
Sentiment towards entities in discussion (SE) -Number of dimensions corresponding to this featureis 2?e, where e is the number of entities discovered.Similar to SD, the value taken by this feature is thenumber of sentences in which that specific polarityis shown by the discussant towards the entity.?
Implicit Attitude (IA) - n ?
t dimensions are ex-pressed using this feature, where t is the number oftopics that the topic model contains.
This means thatthe AP of every discussant contains the topic modeldistribution of his/her interactions with every othermember in the thread.
Hence, the topics in the inter-ation between the given discussant and other mem-bers in the thread are being modeled here.
Accord-67ingly, high vector similarity due to IA between twomembers in a thread means that they discussed sim-ilar topics with the same people in the thread.
Inour experiments, we set t = 50.
We use the Gibbssampling based LDA (Griffiths and Steyvers, 2004).The LDA model is built on definitions of two onlinedictionaries WordNet, and Wiktionary, in additionto the Brown corpus (BC).
To create more context,each sentence from BC is treated as a document.The whole corpus contains 393,667 documents and5,080,369 words.The degree of agreement among discussants interms of these three features is used to identify sub-groups among them.
Our experiments are aimed atinvestigating the effect of explicit attitude features(SD and SE) in comparison with implicit feature(IA) and how they perform when combined.
Sothe experimental conditions are: the three featuresin isolation, each of the explicit features SD and SEtogether with IA, and then all three features together.SWD-BASE: As a baseline, we employ a simpleword frequency based model to capture topic dis-tribution, Surface Word Distribution (SWD).
SWDis still topic modeling in the vector space, but the di-mensions of the vectors are the frequencies of all theunique words used by the discussant in question.RAND-BASE: We also apply a very simple base-line using random assignment of discussants togroups, however the number of clusters is deter-mined by the rule of thumb described in Section 3.3.6 Results and AnalysisThree metrics are used for evaluation, as de-scribed in (Manning et al, 2008): Purity, Entropyand F-measure.
Table 4 shows the results of the9 experimental conditions.
The following observa-tions can be made: All the individual conditions SD,SE and IA clearly outperform SWD-BASE.
All theexperimental conditions outperform RAND-BASEwhich indicates that using clustering is contributingpositively to the problem.
SE performs worse thanSD across both datasets CD and WIKI.
This maybe due to two reasons: Firstly, since the problemis of clustering the discussant space, SD should bea better indicator than SE.
Secondly, as seen fromthe comparison in Table 5, there are more polarizedsentences indicating SD than SE.
IA clearly outper-forms SD, SE and SD+SE in the case of WIKI.
InProperty WIKI CDPositive Sentences towards Discussants 5.15 17.94Negative Sentences towards Discussants 6.75 40.38Positive Sentences towards Entities 1.65 8.85Negative Sentences towards Entities 1.59 8.53Table 5: Statistics of the Attitudinal Sentences pereach Thread in the two data setsthe case of CD, it is exactly the opposite.
This is aninteresting result and we believe it is mainly due tothe genre of the data.
Explicit expression of senti-ment usually increases with the increase in the in-formal nature of discussions.
Hence IA is more use-ful in WIKI which is more formal compared to CD,where there is less overt sentiment expression.
Wenote the same trend with the SWD-BASE where per-formance on WIKI is much better than its perfor-mance on CD.
This also suggests that WIKI mightbe an easier data set.
A qualitative comparison of theinter-discussant relations can be gleaned from Ta-ble 5.
There is significantly more negative languagethan positive language in CD when compared withthe ratios of negative to positive language in WIKI,which are almost the same.
The best results over-all are yielded from the combination of IA with SDand SE, the implicit and explicit features together forboth data sets, which suggests that Implicit and ex-plicit attitude features complement each other cap-turing more information than each of them individ-ually.7 ConclusionsWe proposed the use of LDA based topic mod-eling as an implicit agreement feature for the taskof identifying similar attitudes in online discussions.We specifically applied latent modeling to the prob-lem of sub-group detection.
We compared this withexplicit sentiment features in different genres bothin isolation and in combination.
We highlighted thedifference in genre in the datasets and the necessityfor capturing different forms of information fromthem for the task at hand.
The best yielding con-dition in both the dat sets combines implicit and ex-plicit features suggesting that there is a complemen-tarity between the two tpes of feaures.AcknowledgementThis research was funded by the Office of the Di-rector of National Intelligence (ODNI), IntelligenceAdvanced Research Projects Activity (IARPA),through the U.S. Army Research Lab.68ConditionWIKI CDPurity Entropy F-measure Purity Entropy F-measureRAND-BASE 0.6745 0.5629 0.6523 0.3986 0.9664 0.407SWD-BASE 0.7716 0.4746 0.6455 0.4514 0.9319 0.4322SD 0.8342 0.3602 0.667 0.8243 0.3942 0.5964SE 0.8265 0.3829 0.6554 0.7933 0.4216 0.5818SD+SE 0.8346 0.3614 0.6649 0.82 0.3851 0.6039IA 0.8527 0.3209 0.6993 0.787 0.3993 0.5891SD+IA 0.8532 0.3199 0.6977 0.8487 0.3328 0.6152SE+IA 0.8525 0.3216 0.7015 0.7884 0.3986 0.591SD+SE+IA 0.8572 0.3104 0.7032 0.8608 0.3149 0.6251Table 4: Experimental ResultsReferencesAmjad Abu-Jbara, Pradeep Dasigi, Mona Diab, andDragomir Radev.
2012.
Subgroup detection in ideo-logical discussions.
In Proceedings of the 5oth AnnualMeeting of ACL.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of MachineLearning Research, 3.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proceedings of the 43nd Annual Meeting of the As-sociation for Computational Linguistics.Murthy Ganapathibhotla and Bing Liu.
2008.
Miningopinions in comparative sentences.
In Proceedings ofthe 22nd International Conference on ComputationalLinguistics (Coling 2008).Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences, 101.Ahmed Hassan, Vahed Qazvinian, and Dragomir Radev.2010.
What?s with the attitude?
identifying sentenceswith attitude in online discussions.
In Proceedings ofthe 2010 Conference on Empirical Methods in NaturalLanguage Processing,.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining.Niklas Jakob and Iryna Gurevych.
2010.
Using anaphoraresolution to improve opinion target identification inmovie reviews.
In Proceedings of the ACL 2010 Con-ference Short Papers.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-of re-lations in opinion mining.
In Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning.J.
MacQueen.
1967.
Some methods for classification andanalysis of multivariate observations.
In Proceedingsof Fifth Berkeley Symposium on Mathematical Statis-tics and Probability.Christopher D. Manning, Prabhakar Raghavan, , and Hin-rich Schtze.
2008. .
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York,NY,USA.K.
V. Mardia, J. T. Kent, and J. M. Bibby.
1979.
Multi-variate Analysis.
Publisher.R.
Sibson.
1973.
Slink: An optimally efficient algorithmfor the single-link cluster method.
In The ComputerJournal (1973) 16 (1): 30-34.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedings ofthe Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP.Theresa Wilson, Paul Hoffmann, Swapna Somasun-daran, Jason Kessler, JanyceWiebe, Yejin Choi, ClaireCardie, Ellen Riloff, and Siddharth Patwardhan.
2005.Opinionfinder: A system for subjectivity analysis.
InProceedings of HLT/EMNLP 2005 Demonstration.69
