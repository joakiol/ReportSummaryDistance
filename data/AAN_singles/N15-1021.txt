Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 206?210,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsHow to Make a Frenemy:Multitape FSTs for Portmanteau GenerationAliya Deri and Kevin KnightInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern California{aderi, knight}@isi.eduAbstractA portmanteau is a type of compound wordthat fuses the sounds and meanings of twocomponent words; for example, ?frenemy?
(friend + enemy) or ?smog?
(smoke + fog).We develop a system, including a novel mul-titape FST, that takes an input of two wordsand outputs possible portmanteaux.
Our sys-tem is trained on a list of known portmanteauxand their component words, and achieves 45%exact matches in cross-validated experiments.1 IntroductionPortmanteaux are new words that fuse both thesounds and meanings of their component words.
In-novative and entertaining, they are ubiquitous in ad-vertising, social media, and newspapers (Figure 1).Some, like ?frenemy?
(friend + enemy), ?brunch?
(breakfast + lunch), and ?smog?
(smoke + fog), ex-press such unique concepts that they permanentlyenter the English lexicon.Portmanteau generation, while seemingly trivialfor humans, is actually a combination of two com-plex natural language processing tasks: (1) choos-ing component words that are both semanticallyand phonetically compatible, and (2) blending thosewords into the final portmanteau.
An end-to-endsystem that is able to generate novel portmanteauxFigure 1: A New Yorker headline portmanteau.W1W2PMaffluence influenza affluenzaanecdote data anecdatachill relax chillaxflavor favorite flavoriteguess estimate guesstimatejogging juggling jogglingsheep people sheeplespanish english spanglishzeitgeist ghost zeitghostTable 1: Valid component words and portmanteaux.with minimal human intervention would be not onlya useful tool in areas like advertising and journalism,but also a notable achievement in creative NLP.Due to the complexity of both component wordselection and blending, previous portmanteau gen-eration systems have several limitations.
The Neho-vah system (Smith et al, 2014) combines words onlyat exact grapheme matches, making the generationof more complex phonetic blends like ?frenemy?
or?brunch?
impossible.
?Ozbal and Strappavara (2012)blend words phonetically and allow inexact matchesbut rely on encoded human knowledge, such as setsof similar phonemes and semantically related words.Both systems are rule-based, rather than data-driven,and do not train or test their systems with real-worldportmanteaux.In contrast to these approaches, this paperpresents a data-driven model that accomplishes (2)by blending two given words into a portmanteau.That is, with an input of ?friend?
and ?enemy,?
wewant to generate ?frenemy.
?206F1R1EH3N3D4EH3N3AH5M5IY5T1OW1F1UW3T2ER3K5IY5Figure 2: Derivations for friend + enemy ?
?frenemy?and tofu + turkey ?
?tofurkey.?
Subscripts indicate thestep applied to each phoneme.We take a statistical modeling approach to port-manteau generation, using training examples (Table1) to learn weights for a cascade of finite state ma-chines.
To handle the 2-input, 1-output problem in-herent in the task, we implement a multitape FST.This work?s contributions can be summarized as:?
a portmanteau generation model, trained in anunsupervised manner on unaligned portman-teaux and component words,?
the novel use of a multitape FST for a 2-input,1-output problem, and?
the release of our training data.12 Definition of a portmanteauIn this work, a portmanteau PM and its pronuncia-tion PMpronhave the following constraints:?
PM has exactly 2 component words W1andW2, with pronunciations W1pronand W2pron.?
All of PM?s letters are in W1and W2, and allphonemes in PMpronare in W1pronand W2pron.?
All pronunciations use the Arpabet symbol set.?
Portmanteau building occurs at the phonemelevel.
PMpronis built through the followingsteps (further illustrated in Figure 2):1.
0+ phonemes from W1pronare output.2.
0+ phonemes from W2pronare deleted.1Available at both authors?
websites.3.
1+ phonemes from W1pronare aligned with anequal number of phonemes from W2pron.For each aligned pair of phonemes (x, y), eitherx or y is output.4.
0+ phonemes from W1pronare deleted, until theend of W1pron.5.
0+ phonemes from W2pronare output, until theend of W2pron.3 Multitape FST modelFinite state machines (FSMs) are powerful toolsin NLP and are frequently used in tasks like ma-chine transliteration and pronunciation.
Toolkits likeCarmel and OpenFST allow rapid implementationsof complex FSM cascades, machine learning algo-rithms, and n-best lists.Both toolkits implement two types of FSMs: fi-nite state acceptors (FSAs) and finite state transduc-ers (FSTs), and their weighted counterparts (wFSAsand wFSTs).
An FSA has one input tape; an FSThas one input and one output tape.What if we want a one input and two output tapesfor an FST?
Three input tapes for an FSA?
Althoughinfrequently explored in NLP research, these ?mul-titape?
machines are valid FSMs.In the case of converting {W1pron, W2pron} toPMpron, an interleaved reading of two tapes would beimpossible with a traditional FST.
Instead, we modelthe problem with a 2-input, 1-output FST (Figure3).
Edges are labeled x : y : z to indicate inputtapes W1pronand W2pronand output tape PMpron, re-spectively.4 FSM CascadeWe include the multitape model as part of an FSMcascade that converts W1and W2to PM (Figure 4).q1q2q3q4q5q1a q2a q3a q4a q5a :  :   :  :   :  :   :  :  : : : : : : : : : :x : :x :y :x :y :x/yx : : :y :yFigure 3: A 2- input, 1-output wFST for portmanteau pronunciation generation.207wFST BW2pronW1pronFST AFST AW2W1PMpron wFST CPM?wFSA DPM?
?FSA E1,2PM??
?joggingjugglingJH AH G IH NGJH AA G AH L IH NGJH AH G AH L IH NGjoggaling juggling jogglingFigure 4: The FSM cascade for converting W1and W2into a PM, and an illustrative example.phonemes P (x, y ?
z)x y z cond.
joint mixedAA AA AA 1.000 0.017 1.000AH ER AH 0.424 0.007 0.445AH ER ER 0.576 0.009 0.555P B P 0.972 0.002 1.000P B B 0.028 N/A N/AZ SH SH 1.000 N/A N/AJH AO JH 1.000 N/A N/ATable 2: Sample learned phoneme alignment probabili-ties for each method.We first generate the pronunciations of W1andW2with FST A, which functions as a simple look-up from the CMU Pronouncing Dictionary (Weide,1998).Next, wFST B, the multitape wFST from Figure3, translates W1pronand W2proninto PMpron.
wFST C,built from aligned graphemes and phonemes fromthe CMU Pronunciation Dictionary (Galescu andAllen, 2001), spells PMpronas PM?.To improve PM?, we now use three FSAs builtfrom W1and W2.
The first, wFSA D, is a smoothed?mini language model?
which strongly prefers lettertrigrams from W1and W2.
The second and third,FSA E1and FSA E2, accept all inputs except W1and W2.5 DataWe obtained examples of portmanteaux and com-ponent words from Wikipedia and Wiktionary lists(Wikipedia, 2013; Wiktionary, 2013).
We reject anythat do not satisfy our constraints?for example, port-step k description P (k)1 W1pronkeep 0.682 W2prondelete 0.553 align 0.744 W1prondelete 0.645 W2pronkeep 0.76Table 3: Learned step probabilities.
The probabilities ofkeeping and aligning are higher than those of deleting,showing a tendency to preserve the component words.manteaux with three component words (?turkey?
+?duck?
+ ?chicken??
?turducken?)
or without anyoverlap (?arpa?
+ ?net??
?arpanet?).
From 571 ex-amples, this yields 401 {W1, W2, PM} triples.We also use manual annotations of PMpronforlearning the multitape wFST B weights and for mid-cascade evaluation.We randomly split the data for 10-fold cross-validation.
For each iteration, 8 folds are used fortraining data, 1 for dev, and 1 for test.
Training datais used to learn wFST B weights (Section 6) and devdata is used to learn reranking weights (Section 7).6 TrainingFST A is unweighted and wFST C is pretrained.wFSA D and FSA E1,2are built at runtime.We only need to learn wFST B weights, whichwe can reduce to weights on transitions qk?
qkaand q3a ?
q3from Figure 3.
The weights qk?qka represent the probability of each step, or P (k).The weights q3a ?
q3represent the probability ofgenerating phoneme z from input phonemes x andy, or P (x, y ?
z).208model % exact avg.
dist.
% 1k-bestdev test dev test dev testcond 28.9 29.9 1.6 1.6 92.0 91.2joint 44.6 44.6 1.5 1.5 91.0 89.7mixed 31.9 33.4 1.6 1.5 92.8 91.0rerank 51.4 50.6 1.2 1.3 93.1 91.5Table 4: PMpronresults pre- and post-reranking.PM % exact avg.
dist.
% 1k-bestPM?12.03 5.31 42.35PM?
?42.14 1.80 58.10PM??
?45.39 1.59 61.35Table 5: PM results on cross-validated test data.We use expectation maximization (EM) to learnthese weights from our unaligned input and output,{W1pron, W2pron} and PMpron.
We use three differ-ent methods of normalizing fractional counts.
Thelearned phoneme alignment probabilities P (x, y ?z) (Table 2) vary across these methods, but thelearned step probabilities P (k) (Table 3) do not.6.1 Conditional AlignmentOur first learning method models phoneme align-ment P (x, y ?
z) conditionally, as P (z|x, y).Since P (z|x, y) tends to be larger than step prob-abilities P (k), the model prefers to align phonemeswhen possible, rather than keep or delete them sep-arately.
This creates longer alignment regions.Additionally, during training a potential align-ment P (x|x, y) can compete only with its pairP (y|x, y), making it more difficult to zero out analignment?s probability.
The conditional methodtherefore also learns more potential alignments be-tween phonemes.6.2 Joint AlignmentOur second learning method models P (x, y ?
z)jointly, as P (z, x, y).
Since P (z, x, y) is relativelylow compared to the step probabilities, this methodprefers very short alignments?the reverse of the ef-fect seen in the conditional method.However, the model can also zero out the prob-abilities of unlikely aligments, so overall it learnsfewer possible alignments between phonemes.W1W2gold PM hyp.
PMaffluence influenza affluenza affluenzaarchitecture ecology arcology architecologychill relax chillax chilaxfriend enemy frenemy frienemyjapan english japlish japanglishjeans shorts jorts jsjogging juggling joggling jogglingman purse murse mmantofu turkey tofurkey tofurkeyzeitgeist ghost zeitghost zeitghostTable 6: Component words and gold and hypothesis PMs.6.3 Mixed AlignmentOur third learning method initializes alignmentprobabilities with the joint method, then normalizesthem so that P (x|x, y) and P (y|x, y) sum to 1.
This?mixed?
method, like the joint method, is more con-servative in learning phoneme alignments.
However,like the conditional method, it has high alignmentprobabilities and prefers longer alignments.7 Model Combination and RerankingUsing the methods from sections 6.1, 6.2, and 6.3,we train three models and produce three different1000-best lists of PMproncandidates for dev data.We combine these three lists into a single one, andcompute the following features for each candidate:model scores, PMpronlength, percentage of W1pronor W2pronin PMpron, and percentage of PMproninW1pronor W2pron.
We also include a binary featurefor whether PMpronmatches W1pronor W2pron.We then compute feature weights using the aver-aged perceptron algorithm (Zhou et al, 2006), anduse them to rerank the candidate list, for both devand test data.
We combine the reranked PMpronliststo generate wFST C?s input.8 EvaluationWe evaluate our model?s generation of PMpronpre-and post-reranking against our manually annotatedPMpron.
We also compare PM?, PM?
?, and PM???.
Forboth PMpronand PM, we use three metrics:?
percent of 1-best results that are exact matches,?
average Levenshtein edit distance of 1-bests,and?
percent of 1000-best lists with an exact match.2099 Results and DiscussionWe first evaluate the model at PMpron.
Table 4shows that, despite less than 50% exact matches,over 90% of the 1000-best lists contain the correctpronunciation.
This motivates our model combina-tion and reranking, which increase exact matches toover 50%.Next, we evaluate PM (Table 5).
A componentword mini-LM dramatically improves PM?
?com-pared to PM?.
Filtering out component words pro-vides additional gain, to 45% exact matches.In comparison, a baseline that merges W1pronandW2pronat the first shared phoneme achieves 33% ex-act matches for PMpronand 25% for PM.Table 6 provides examples of system output.
Per-fect outputs include ?affluenza,?
?joggling,?
?to-furkey,?
and ?zeitghost.?
For others, like ?chilax?and ?frienemy,?
the discrepancy is negligible and thehypothesis PM could be considered a correct alter-nate output.
Some hypotheses, like ?architecology?and ?japanglish,?
might even be considered superiorto their gold counterparts.
However, some errors,like ?js?
and ?mman,?
are clearly unacceptable sys-tem outputs.10 ConclusionWe implement a data-driven system that generatesportmanteaux from component words.
To accom-plish this, we use an FSM cascade, including a novel2-input, 1-output multitape FST, and train it on exist-ing portmanteaux.
In cross-validated experiments,we achieve 45% exact matches and an average Lev-enshtein edit distance of 1.59.In addition to improving this model, we are inter-ested in developing systems that can select compo-nent words for portmanteaux and reconstruct com-ponent words from portmanteaux.
We also planto research other applications for multi-input/outputmodels.11 AcknowledgementsWe would like to thank the anonymous reviewers fortheir helpful comments, as well as our colleaguesQing Dou, Tomer Levinboim, Jonathan May, andAshish Vaswani for their advice.
This work wassupported in part by DARPA contract FA-8750-13-2-0045.ReferencesLucian Galescu and James F Allen.
2001.
Bi-directionalconversion between graphemes and phonemes usinga joint n-gram model.
In 4th ISCA Tutorial and Re-search Workshop (ITRW) on Speech Synthesis.G?ozde?Ozbal and Carlo Strapparava.
2012.
A computa-tional approach to the automation of creative naming.In Proceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics: Long Papers- Volume 1, ACL ?12, pages 703?711.
Association forComputational Linguistics.Michael R Smith, Ryan S Hintze, and Dan Ventura.2014.
Nehovah: A neologism creator nomen ipsum.In Proceedings of the International Conference onComputational Creativity, pages 173?181.
ICCC.Robert Weide.
1998.
The CMU pronunciation dictio-nary, release 0.6.Wikipedia.
2013.
List of portmanteaus.http://en.wikipedia.org/w/index.php?title=List_of_portmanteaus&oldid=578952494.
[Online; accessed 01-November-2013].Wiktionary.
2013.
Appendix:list of portmanteaux.http://en.wiktionary.org/w/index.php?title=Appendix:List_of_portmanteaux&oldid=23685729.
[Online; accessed 02-November-2013].Zhengyu Zhou, Jianfeng Gao, Frank K. Soong, and HelenMeng.
2006.
A comparative study of discriminativemethods for reranking LVCSR n-best hypotheses indomain adaptation and generalization.
In 2006 IEEEInternational Conference on Acoustics Speech andSignal Processing, ICASSP 2006, Toulouse, France,pages 141?144.210
