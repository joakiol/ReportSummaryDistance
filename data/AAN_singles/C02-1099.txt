An English-Korean Transliteration Model Using Pronunciation andContextual RulesJong-Hoon Oh, and Key-Sun ChoiComputer Science Division, Dept.
of EECS, Korea Advanced Institute of Science & Technology(KAIST) / Korea Terminology Research Center for Language and Knowledge Engineering(KORTERM), 373-1, Kusong-dong, Yusong-gu, Taejon, 305-701, KoreaEmail: {rovellia,kschoi}@world.kaist.ac.krAbstractThere is increasing concern aboutEnglish-Korean (E-K) transliterationrecently.
In the previous works, directconverting methods from Englishalphabets to Korean alphabets were amain research topic.
In this paper, wepresent an E-K transliteration model usingpronunciation and contextual rules.
Unlikethe previous works, our method usesphonetic information such as phonemeand its context.
We also use wordformation information such as Englishwords of Greek origin.
With them, ourmethod shows significant performanceincrease about 31% in word accuracy.1.IntroductionIn Korean, many technical terms in a domainspecific text, especially science and engineeringare from foreign origin.
Sometimes they arewritten in their original forms and sometimesthey are transliterated into Korean words invarious forms.
This makes difficult to handlethem in natural language processing.
Especiallyinformation retrieval, words with the samemeanings are treated as different ones because oftheir different forms.One possible solution can be a dictionary, whichcontains English words and their possibletransliterated forms.
However, this is not apractical solution because technical terms, whichmainly cause the problem, usually have richproductivity.
The other solution can beautomatic transliteration.
There have been workson automatic transliteration from English toother languages ?
English to Japanese (Kang etal., 1996; Knight et al, 1997), and English toKorean (Kang et al, 2000; Kang et al, 2001;Kim et al, 1999; Lee et al, 1998).In E-K transliteration, direct converting methodsfrom English alphabet to Korean alphabet were amain research topic (Kang et al, 2000; Kang etal., 2001; Kim et al, 1999; Lee et al, 1998).
Inthe works, machine learning techniques such asa decision tree and a neural network were used.However, transliteration is more phoneticprocess than orthographic process: ?h?
in theJohnson does not make any Korean character(Knight et al, 1997).
Therefore, patterns for E-Ktransliteration acquired from English/Koreanalphabets as in the previous works, may not beeffective.
In the previous works, they did notconsider origin of English ?
pure English (e.g.,board), English words with Greek origin (e.g.,hernia) and so on In E-K transliteration, originof English words determine the way oftransliteration.
Our method uses phoneticinformation such as phoneme and its context aswell as orthography.
English words of Greekorigin are also considered in transliteration.This paper organized as follows.
In section 2, wesurvey related works.
In section 3, we willdescribe the details of our method.
In section 4,the results of experiments are represented.Finally, the conclusion follows in section 5.2.
Related works2.1 Probability based transliteration(Lee et al, 1998) used formula (1) to generate atransliterated Korean word ?K?
for a givenEnglish word ?E?.
Lee et al (1998) defined apronunciation unit.
It is a chunk of graphemes oralphabets that can be mapped to phoneme.
Theydivided an English word into pronunciation units(PUs) for transliteration.
For example, anEnglish word ?board (/B AO R D/)?
can bedivided into ?b/B/: oa/AO/: r/R/: d/D/?1 ?
?b?,?oa?, ?r?
and ?d?
are PUs.
An English word ?E?was represented as ?E=epu1,epu2,?,epun?
whereepui was the ith PU.
Sequences of Korean PUs,K1,K2,?,Km, where  ?Ki= kpui1,kpui2,?,kpuin?were generated according to epui.
Lee et al(1998) considered all possible English PUsequences and corresponding Korean PUsequences for a given English word, because itspronunciation was not determined.
For example,?data?
can have PU sequences such as ?d :at :a?,?da :ta?, ?d :a :t :a?
and so on.
If the total numberof English PU in E is N and the average numberof kpui generated by epui is M, the total numberof generated Korean PU sequences will be aboutN*M. Then he selected the best result amongthem as a Korean transliteration word.
)|()(maxarg)|(maxarg KEpKpEKpKK= (1)?=?
?niii kpukpupkpupKP211 )|()()(      (2)?=?niii kpuepupKEP1)|()|(       (3)Kim et al, (1999) used the same formula asLee?s (1998) except P(E|K) (formula(4)).
Heused additional information ?
Korean PUs kpui-1and kpui+1 ?
and used a neural network toapproximate P(E|K).?=+?
?niiiii kpukpukpuepupKEP111 ),,|()|(  (4)Probability based transliteration showed about40% precision on E-K transliteration with 1,500E-K pairs for training and 150 E-K pairs fortesting.2.2 Decision Tree based transliterationKang, et al (2000; 2001) proposed an Englishalphabet-to-Korean alphabet conversion methodbased on a decision tree.
This method used sixattribute values ?
left three English alphabetsand right three English alphabets ?
fordetermining Korean alphabets corresponding toEnglish alphabets.
For each English alphabet, itscorresponding decision trees are constructed.Table 1 shows an example of transliteration foran English word ?data?.
In table 1, (E) represents1Henthforce, ?:?
will be used as a PU boundarya current English alphabet, K representsgenerated Korean alphabets by decision trees.L3 L2 L1 (E) R1 R2 R3  K< < < d a t a  ?d?< < d a t a >  ?e-i?< d a t a > >  ?t?d a t a > > >  ?a?Table 1.
An example of decision tree basedtransliterationThis method showed about 49% precision for6,185 E-K pairs for training and 1,000 E-K pairsfor testing.Though the previous works showed relativelygood results, they also showed some limitations.Because they focused on a converting methodfrom English alphabet to Korean alphabet, theydid not consider phonetic features such asphoneme and word formation features such asorigin of English.
This makes some errors whenpronunciation and origin of English wereimportant clues for transliteration - ?Mcdonald?
(pronunciation is needed) and ?amylase?
(originof English word is needed).3.
An English-Korean TransliterationModel using Pronunciation andContextual Rules3.1 Overall System DescriptionFigure1 shows the overall system description.Our method is composed of two phases ?alignment (section 3.2) and transliteration(section 3.3, 3.4, 3.5 and 3.6).First an English pronunciation unit2 (hearafter,EPU) and its corresponding phoneme arealigned.
EPU-to-Phoneme alignment is to findout the most phonetically probablecorrespondence between an Englishpronunciation unit and phoneme.
EPU tophoneme aligned results acquired from thealignment algorithm offer training data forestimating pronunciation of English words,which are not registered in a pronunciationdictionary, for example ?zinkenite?.
Second,English words are transliterated into Koreanwords through several steps.
Using an English2The term ?pronunciation unit?
will be used as the samemeaning as in the Lee?s (Lee et al, 1998)pronunciation dictionary (P-DIC), we can assignpronunciation to a given English word.
When itis not registered in P-DIC, we investigate that ithas a complex word form (section 3.3).
Fordetecting a complex word form, we divide agiven English word into two words(word+word)3 using entries of P-DIC.
If both ofthem are in P-DIC, we can assign pronunciationto the given word otherwise we should estimatepronunciation (section 3.5).
Then, we checkwhether the English word is from Greek originor not (section 3.4).
Because a way of E-Ktransliteration for the English words of Greekorigin is different from that for pure Englishwords, it is important to detect them.Pronunciation for English words, which are notregistered in a P-DIC, is estimated (section 3.5)in the next step.
Finally, Korean transliteratedwords are generated using conversion rules(section 3.6).
The right side of figure 1 shows atransliteration example for an English word,?cutline?.Pronunciationdictionary English  wordsDictionary SearchDetecting Complex Word formsDetecting English wordsof Greek originnonoEstimatingpronunciationfor E-classPhoneme to Korean conversionyesyesEstimatingpronunciationfor G-classnoyesEPU-PalignmentEPU-PAlignmentresultsTraining datafor estimatingpronunciation( E and Gclass)DetectingEnglish wordsof Greek originKorean transliterated wordscutlinekeo-teu-la-inComplex word forms ?
(Yes)Registered ina pronunciationdictionary?
(No)Pronunciation toKorean conversion[C/K]:[u/AH]:[T/T][L/L]:[I/AY]:[ne/N]Fig.
1 Overall system description3.2 EPU-to-Phoneme AlignmentEPU-to-Phoneme (hereafter, EPU-P) alignmentis to find out the most phonetically probablecorrespondence between an Englishpronunciation unit and phoneme.
For example,one of the possible alignment for an Englishword ?board?
and its pronunciation ?/B AO RD/?4 is as follows.3?broadcasting?
may be divided into three words : ?broad?,?cast?
and ?ing?.
But from the training corpus andpronunciation dictionary, all of complex word is dividedinto two words like ?broad?
and ?casting?.4 (www.cs.cmu.edu/~laura/pages/arpabet.ps):  ARPAbetsymbol will be used for representing phonemes.
ARPAbetEnglish b oa r d| | | |Pronunciation /B/ /AO/ /R/ /D/Table 2.
One possible alignment between Englishword ?board?
and its pronunciationFor automatic EPU-P alignment, we used themodified version of Kang?s E-K alignmentalgorithm (Kang et al, 2000; Kang et al, 2001).It is based on Covington?s algorithm (Covington,1996).
Covington views an alignment as a wayof stepping through two words ?
a word in oneside and a word in the other side ?
whileperforming ?match?
or ?skip?
operation on eachstep.
Kang added ?forward bind?
and ?backwardbind?
operations to consider one-to-many,many-to- one and many-to-many alignmentsOperation Condition PenaltySimilar C/CP 0V/VP 0V/SVP or C/SVP 30Dissimilar C/CP 240MatchV/CP or C/VP 250Similar C/CP 0V/VP 0V/SVP or C/SVP 30Dissimilar C/CP 190BindV/CP or C/VP 200Table 3.
Penalty metrics: C, V, CP, VP, and SVPrepresent consonants, vowels, consonantphonemes, vowel phonemes 5  and semi-vowelphonemes respectively.English b o a r D TotalOperation M M < M M PenaltyPronunciation B AO < R DPenalty +0 +0 +0 +0 +0 0Table 4.
The best alignment result for an Englishword ?board?.
?M?
represents ?match?, and ?<?represents ?backward bind?.Unlike the previous alignment algorithm, wecombine ?skip?
and ?bind?
operations becausethe ?skip?
operation can be replaced with the?bind?
operation.
This makes all PUs to bemapped into phoneme.
It means that ouralgorithm does not allow null-to-phonemealignment or PU-to-null alignment.
All the validalignments that are possible by ?match?, and?bind?
operations can be generated.
Alignmentis one of the method for coding phonemes into ASCIIchracters.5In this paper, vowel pronunciation includes diphthongs.may be interpreted as finding the best resultamong them.
To find the best result, a penaltyscheme is used ?
the best alignment result is onethat has the least penalty values.
Since Kang?smethod focused on an E-K character alignment,a penalty scheme and an E-Kcharacter-matching table were restricted to anE-K alignment.
Instead of Kang?s E-K characterpenalty scheme, we developed an EPU-P penaltyscheme and an EPU-P matching table usingmanually aligned EPU-P data.
We assume thatall vowels can be aligned with all vowelphonemes without penalty.
Table 3 shows ourpenalty metrics and table 4 shows an example ofEPU-P alignment.We aligned about 120,000 English word andPronunciation pairs in ?The CMU PronouncingDictionary?.
For evaluating performance of thealignment, we randomly selected 100 results.The performnance of EPU-P alignment is 99%.3.3 Dealing with a Complex word formSome English words are not in P-DIC, becausethey are in a complex word form.
In this paper,we define words in a complex word form asthose composed of two base nouns in P-DIC.When a given word is not in P-DIC, it issegmented into all possible two words.
If thetwo words are in P-DIC, we can assign theirpronunciation.
For example, ?cutline?
can besegmented into ?c+utline?, ?cu+tline?, ?cut+line?and so on.
?cut+line?
is the correct segmentationof ?cutline?, because ?cut?
and ?line?
are in theP-DIC.
If words are not in P-DIC and they arenot in a complex word form, we should estimatetheir pronunciation.
The details of estimatingpronunciation will be described in the section3.5.3.4 Detecting English words of Greek originIn Korean, there are two methods for E-Ktransliteration ?
?written word transliteration?and ?spoken word transliteration?
(Lee et al,1998).
The two methods use similar mechanismfor consonant transliteration.
However, ?writtenword transliteration?
uses its character and?spoken word transliteration?
uses its phonemewhen they transliterate vowels.
For example, ?a?in ?piano?
can be transliterated into ?pi-a-no?with its character and ?pi-e-no?
with its phoneme.Since, a vowel in a pure English word is usuallytransliterated using its phoneme and that in anEnglish word of Greek origin is usuallytransliterated with its character in E-Ktransliteration- for example, ?hernia?
(he-reu-ni-a), ?acacia?
(a-ka-si-a), ?adenoid?
(a-de-no-i-deu) and so on -, it is important todetect them.
We use suffix and prefix patternsfor detecting English words of Greek origin(Luschnig, 2001) 6  and table 5 7  shows thepatterns.
If words have the affixes in table 5, wedetermine them as words of Greek originotherwise pure English words.Suffix -ic, -tic, -ac, -ics, -ical, -oid, -ite, -ast,-isk, -iscus, -ia, -sis, -me, -maPrefix amphi-, ana-, anti-, apo-, dia-, dys-, ec-,ecto-, enantio-, endo-, epi-, cata-, cat-,meta-, met-, palin-, pali-, para-, par-,peri-, pros-, hyper-, hypo-, hyp-Table 5.
Suffix and prefix patterns for detectingEnglish words of Greek origin.3.5 Estimating PronunciationEstimating pronunciation is composed of twosteps.
Using aligned EPU-P pairs as trainingdata, we can find EPUs in the given Englishword (Chunking EPU) and assign theirappropriate phoneme (EPU-to-Phonemeassignment).
For dealing with English words ofGreek origin, we categorize EPU-P aligned datainto pure English words (E-class) and Englishwords of Greek origin (G-class).
Then weconstruct the ?Chunking EPU?
module and the?EPU-to-Phoneme assignment?
module for eachclass.
?Chunking EPU?
is to find out boundaries ofEPUs in English words.
For example, we canfind EPUs in ?board?
as ?b:oa:r:d?.
For chunkingEPU, we used C4.5 (Quilan, 1993) with tenattributes ?
left five alphabets and right fivealphabets and the setting shows the best resultamong various settings such as eight attributes(left four and right four - 87.2% ) and so on.
8.638 Grek affixes out of 249 Latin and Greek affixes in120 categories described in (John, 1953) are used.
63 out ofthe 120 categories share the meaning though their form issomewhat different7In this paper, some Greek affixes are not used, becausethey such as prefix ?a-?, ?an-?, and postfix ?-y?, ?-m?
maycause error.8C4.5 is one of the popular method for recognizingboundary of chunks.
Unlike Kang et al, (2000)?s method,We use 90% of EPU-P aligned data as trainingdata and 10% of those as test data.
Our?Chunking EPU?
module shows 91.7%precision.
)|()(maxarg)|(maxarg PEpPpEPpPP=   (5)?=?
?niii pppppPP211 )|()()(       (6)?=?niii pepupPEP1)|()|(       (7)Then we can assign phoneme to each EPU.
Forthe given EPU sequence ?E=epu1,epu2,?,epun?and its possible phoneme sequences P1,..,Pmwhere ?Pi=pi1,pi2,?,pin?, the ?EPU-to-Phonemeassignment?
task is to find out the most probablephomene sequence ?Pi=pi1,pi2,?,pin?.
It can berepresented as formula (5).
p(P) and p(E|P) areapproximated as formula (6) and (7).3.6 Phoneme-to-Korean ConversionOur Phoneme-to-Korean (P-K) conversionmethod is based on English-to-Korean StandardConversion Rule (EKSCR) (Ministry, 1995).EKSCR is composed of nine general rules andfive rules for specific cases ?
each rule containsseveral sub-rules.
It describes a transliterationmethod from English alphabets or phonemes toKorean alphabets.
It uses English phoneme as atransliteration condition ?
if a phoneme is Athen transliterate into a Korean alphabet B.However, EKSCR does not contain enough rulesto generate correct Korean words forcorresponding English words, because it mainlyfocuses on a way of mapping from one Englishphoneme to one Korean character withoutcontext of phonemes and PUs.
For example, anEnglish word ?board?
and its pronunciation ?/BAO R D/?, are transliterated into ?bo-reu-deu?
byEKSCR ?
the correct transliteration is ?bo-deu?.In E-K transliteration, the phoneme ?R?
beforeconsonant phonemes and after vowel phonemesis rarely transliterated into Korean characters(Note that the phoneme ?R?
in English words ofGreek origin is transliterated into a Koreanour method produces EPU and it phoneme.
This makespossible for a E-K conversion method (in section 3.6) touse context of EPU and its phoneme.
Because analphabet-to-alphabet mapping method did not use EPU andits phoneme, it may show some errors when phoneme andits context are the most importnat clues, for example,?Mcdonald?.consonant ?r?
frequently.)
These contextual rulesare very important to generate correct Koreantransliterated words.We capture contextual rules by observing errorsin the results, which are generated by applyingEKSCR to 200 randomly selected words fromthe CMU pronunciation dictionary.
The selectedwords are not in the test data in the experiment.Among the generated rules, we selected 27contextual rules with high frequency (above 5).Table 6 shows some rules and their conditions inwhich rules will be fired.
There are threeconditions ?
?Context?, ?TPU (Target PU)?, and?TP (Target Phoneme)?.
In context condition,?
[]?, ?
{}?, C, VP, and CP represent phoneme,pronunciation unit, consonant, vowel phonemesand consonant phonemes respectively.
The rulewith context condition, ?
[R] after VP and beforeCP?, is not fired for the English words of Greekorigin.
Except it, all rules are applied to bothclasses (E-class and G-class).ConditionContext  TPU TPKoreanCharactersC+ {le} ?le?
AH L ?eul?
{or} in the end ofa word?or?
ER ?eo?
{or} in a word ?or?
ER ?eu?
{sm} in the endof a word?sm?
S AH M ?jeum?
[R] after VP andbefore CP?r?
?R?
?eu?Table 6.
Some contextual rules4.Experiment4.1 Experimental SetupWe use two data sets for an accuracy test.
TestSet I (Lee et al, 1998) is composed of 1,650E-K pairs.
Since, the test set was used as acommon testbed for (Lee et al, 1998; Kim et al,1999; Kang et al, 2000; Kang et al, 2001), weuse them as a testbed for comparison betweenour method and other methods.
For comparison,1,500 pairs are used as training data for othermethods and 150 pairs are used as test data forour method and other methods.
Test set II (Kanget al, 2000) consists of 7,185 E-K pairs ?
thenumber of training data is 6,185 and that of testdata is 1,000.
We use Test set II to compare ourmethod with (Kang et al, 2000), which showsthe best result among the previous works.Evaluation is performed by word accuracy (W.A.)
and character accuracy (C.A.
), which wereused as the evaluation measure in the previousworks (Lee and Choi 1998; Kim and Choi 1999;Kang and Choi 2000).wordsgeneratedofwordscorrectofAW##.. =   (8)LsdiLAC )(.. ++?=    (9)where L represents the length of the originalstring, and di, , and s  represent the numberof insertion, deletion and substitutionrespectively.
If )( sdiL ++< , we consider itas zero (Hall and Dowling, 1980).We perform the three experiments as follows.Comparison Test: Comparison betweenour method and the previous worksDictionary Test: Performance oftransliteration for words in apronunciation dictionary and that forothersComponent Test: Effectiveness of eachcomponent4.2 Experimental results4.2.1 Comparison TestMethod C.A W.A[Lee et al, 1998] 69.3% 40.7%9[Kim et al, 1999] 79.0% 35.1%[Kang et al, 2000] 78.1% 37.6%Our method 90.82% 56.0%Table 7 Comparison test results for Test set IMethod C.A W.A[Kang et al, 2000, 2001] 81.8% 48.7%Our method 92.86% 63.0%Table 8 Comparison test results for Test set II.Table 7 and 8 show results of comparison testfor Test set I and Test set II respectively.
In thetables our method shows higher performanceespecially in W.A.
Moreover, our method showshigher performance in C.A.
It means that thegenerated words by our method are more similarto the correct transliteration, when they are notthe correct answer.9with 20 higher rank results.4.2.2 Dictionary TestFor the dictionary test, we use test data of Testset II.
In the result, ?registered?
words showhigher performance.
It can be analysed thatcontextual rules are constructed using registeredwords in a P-DIC and estimating pronunciationmodule makes some errors.
However, ?notregistered?
words also show relatively goodperformance.C.A W.A # of wordsRegistered 93.49% 67.83% 687Notregistered91.47% 52.40% 313Table 9.
Dictionary test results.4.2.3 Component TestFor the component test, we use words, which are?not registered?
in Test set II.
Components,which are tested in ?Component test?
are?Dealing with words in a complex wordform?
[C], ?Detecting English words of Greekorigin?
[G], and ?Contextual rules?
[R].
In theresult, [G] and [R] show good results in contraryto [C].
There are so few words in complex wordforms that [C] does not show significantperformance improvement though theperformance is relatively good ?about 70% W.A.for 43 words (43 words out of total 313 words).For the effective comparison, it will benecessary to consider the number of words,which each component handles.
Our methodshows better performance than ?W/O[R]?(EKSCR).
It indicates that contextual rulesare important.Method C.A.
W.A.W/O [C], [G], and [R] 87.90% 23.96%W/O [G] 88.45% 36.10%W/O [C] 91.99% 50.16%W/O [R] 89.78% 44.41%[C]+[G]+[R] (proposed) 91.47% 52.40%Table 10.
Component test results.4.3.
DiscussionThe previous works focused on analphabet-to-alphabet mapping method.
Because,how the transliteration is more phonetic thanorthographic, without phonetic infomation10 it10Hangul alphabet has phonetic as well as orthographic.
Itmay be adopted to our method as phoneme.
Because onemay be difficult to acquire more relevant result.In the result, ?crepe(keu-le-i-peu/ keu-le-pe) 11?,?dealer (dil-leo/ di-eol-leo)?, ?diode (da-i-o-deu/di-o-deu)?, and ?pheromone (pe-ro-mon/pe-eo-o-mon)?
etc.
produce errors in theprevious works because they are transliteratedinto Korean with pronunciation and the patternscan not be acquired from analphabet-to-alphabet mapping method.
Forexample, ?e?
before ?p?
in ?crepe?
istransliterated into Korean chracters ?e-i?
but it isusually transliterated into ?e?
in training data.Origin of English word also contributesperformance improvement.
For example, wordssuch as ?hittite (hi-ta-i-teu /ha-i-ta-i-teu)?,?hernia (he-leu-ni-a/ heo-ni-a)?, ?cafeteria(ka-pe-te-li-a/ ka-pi-te-ri-a)?.
In summary, E-Ktransliteration is not an alphabet-to-alphabetmapping problem but a problem that can besolved with mixed use of alphabet, phoneme,and word formation information.In the experiments, we find that voweltransliteration is the main reason of errors ratherthan consonant transliteration in E-Ktransliteration.
Especially, ?AH?
is the mostambiguous phoneme because it can be severalKorean characters such as ?eo?, ?e?, ?u?, and soon.
To improve performance of E-Ktransliteration, more specific rules may benecessary to handle vowel transliteration.5.
ConclusionWe propose an English-Korean transliterationmodel using pronunciation and contextual rules.Unlike the previous works, our method usephonetic and orthographic information fortransliteration.
With them our method showedsignificant performance increase about 31%.
Wealso showed that origin of English words wasimportant in E-K transliteration.In future works, a study is attempting to developa method for handling English of various foreignorigin, which this paper did not handle.
Toimprove accuracy, contextual rules must beadded using larger data.
Our method may beuseful to many NLP applications such asEPU may produce many phonemes, it may be difficult toacquire a good result without context of phoneme and EPU.11English word (correct transliteration / transliteration bythe previous works)automatic bi-lingual dictionary construction,information retrieval, machine translation,speech recognition and so on.ReferencesBrown, P. F. and et al (1990), ?A StatisticalApproach to Machine Translation,?
ComputationalLinguistics, Vol 16 (2), June.Covington, M. A., (1996).
?An algorithm to alignwords for historical comparison?, ComputationalLinguistics, 22.Hall, P., and G. Dowling, (1980), ?Approximatestring matching,?
Computing Surveys, 12(4),381-402.John Hough, (1953) ?Scientific Terminology?
NewYork: Rhinehart & Company, Inc.Kang, Y. and A.
A. Maciejewski, (1996).
?Analgorithm for Generating a Dictionary of JapaneseScientific Terms?, Literary and LinguisticComputing, 11(2).Kang B.J.
and K-S. Choi (2000), ?AutomaticTransliteration and Back-transliteration byDecision Tree Learning?, In Proceedings of the2nd International Conference on LanguageResources and Evaluation, Athens, Greece.Kang B.J.
and  Key-Sun Choi, (2001) ?Twoapproaches for the resolution of word mismatchproblem caused by English words and foreignwords in Korean information retrieval?,International journal of computer processing oforiental language vol 14/No 2, 109-131Kim J.J., J.S.
Lee, and K-S.
Choi., (1999).
?Pronunciation unit based automaticEnglish-Korean transliteration model using neuralnetwork?, In Proceedings of Korea CognitiveScience Association (in Korean)Knight, K. and J. Graehl, (1997).
?MachineTransliteration?.
In Proceedings.
of the 35thAnnual Meetings of the Association forComputational Linguistics (ACL) Madrid, Spain.Lee, J. S. and K. S. Choi, 1998.
English to KoreanStatistical transliteration for information retrieval.Computer Processing of Oriental Languages,12(1):17-37.Luschnig, C.A.E.
(2001) English word origin,http://www.ets.uidaho.edu/luschnig/EWOMinistry of culture and tourism, Republic of Korea,?English-to-Korean Standard conversion rule?,1995 (in Korean)Quinlan,J.R.
(1993), ?C4.5: Programs for MachineLearning?, Morgan Kauffman.
