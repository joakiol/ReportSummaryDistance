Reso lv ing  Anaphora  in a Por tab le  Natura l  LanguageFront End  to DatabasesFhlv ia  A. Burros  and Anne DeRoeckDepartment of Computer ScienceUniversity of EssexColchester - CO4 3SQ - U.K.\ [bar r f  - deroe \ ]  ~essex .ac .ukAbst ractAn analysis of the evolution of Natu-ral Language front ends in the last threedecades shows that the growth in portabil-ity brought, as a side effect, the narrow-ing of the provided coverage of contextu-ally based linguistic phenomena, such asanaphora nd ellipsis.This paper presents the design and stateof development of a computational mecha-nism which provides pronominal AnaphoraResolution within the environment of ahighly portable Natural Language frontend to databases, SQUIRREL3 Simplecases of Ellipsis are also treated by the pro-posed model.An Overview of SQUIRREL is presented,followed by a description of the DiscourseModule and the results achieved so far.
Theprototype is implemented in C-Prolog.1 I n t roduct ionThe development of Natural Language (NL) systemsfor data retrieval has been a central issue in NL Pro-cessing research for the last three decades, motivatedby the aim of helping non-expert database users.When we try to draw a line of evolution of suchsystems, it can be observed that growth in portabil-ity, essential for commercial viability, came at a costin terms of broader linguistic overage.
2Earlier systems, mostly research motivated, weremainly developed for a single application, usingdomain-dependent information for treating contex-tual phenomena (eg, DEACON (Craig et al, 1966),SHRDLU (Winograd, 1972), LUNAR (Woods,1The current system forms the base line for a jointSERC/DTI funded collaborative project between theUniversity of Essex and Status IQ Ltd. for construct-ing an integrated platform for the retrieval of structuredand textual data through Natural Language queries.2See (Burros and DeRoeck, 1993) for a comprehensivereview on Portable NL front ends.1973), LADDER (Hendrix et al, 1978)).
In con-trast, the subsequent generation of interfaces car-ried a higher emphasis on portability in their de-sign (eg, INTELLECT (Harris, 1984), IRUS (Bateset al, 1986), TEAM (Grosz et al, 1987)).
Thesesystems, however, offer a reduced coverage of dis-course phenomena,  central issue when continuityin the database consultation carries some priority.Thus, the ideal NL Front End (NLFE) should carrya broader linguistic overage, in order to support auser focused query process, combined with a highdegree of portability.In this light, we designed a Discourse Module,which is incorporated into a highly portable NLFE,SQUIRREL (DeRoeck et al, 1991).
The system wasoriginally conceived with a single-query based modeof consultation.
By providing for anaphora nd sim-ple cases of ellipsis resolution, the Discourse Mod-ule yields continuous consultations without the useof world models (to maintain the system's generalportability).2 Issues in Anaphora ResolutionOur primary goal is the achievement of dialogue-likequerying by extending SQUIRREL to a system ca-pable of dealing with basic pronominal naphora andellipsis.
Information about each query is made avail-able to the following queries, such that references toentities already introduced can be resolved.This solution is common practice among NLFEsimplementations (eg, LDC-1 (Ballard el al., 1984),Datenbank-DIALOG (Trost el al., 1988)).
However,it is subject o limitations.
In particular, sequenceslike the following cannot be handled:Query: who works for which salary in shoes?DB answer: \[malcolm- $5,000.00\]Query: who is his boss?because the resulting queryQuery: who is the boss of \[who works for whichsalary in shoes\] ?leads the system into a type error, as a personalpronoun was substituted by a sentence.
This was our119ramm~~ English Sentence ( f  Extended'~ Query ~x Data Mo del Js'n's mH HRepresent.
Represent.
Represent.
Represent.
I I SQLDatabaseAnswer,,IL .
.
.
.
.
.
.
.
.
.
.
.
.
~'l Context  :-~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 !I.
.
.
.
.
.
.
.
.
.
.
Jquery\]Figure h SQUIRREL with Discourse Module.main motivation for keeping information conveyedby the DB answer, so it could be used for futurereference.
We consider this essential for achieving adialogue-like mode of consultation.3 Overv iew o f  SQUIRRELThe system consists of a portable Natural Lan-guage front end prototype for the interrogation oflogical and relational database systems (DeRoeck etal., 1991).
It is divided into two main sections: theFront End and the Back End \[Fig.
1\].The Front End takes the input sentence, produc-ing syntactic and semantic representations, which itmaps into First Order Logic.
All representationsare independent of the domain of application ordatabase model.
Syntactic and semantic rules workin tandem.
The former are a feature-based CFG,whereas the latter are expressed in Property Theory(Turner, 1987).
The lexicon is incomplete, treatingunknown words as proper nouns to be fully inter-preted when reaching the database.The Back End uses an Extended Data Model tomap the logical representation i to expressions inthe Domain Relational Calculus (DRC), which istranslated via Tuple Relational Calculus (TRC) intoSQL (a standard query language) by means of a syn-tactic transducer.
All representations at this levelare domain dependent.Both the Front End and Back End were designedto guarantee modularity and portability to the sys-tem as a whole.
Strict separation between domaindependent and independent components must bemaintained for the sake of portability.
The systemhas no world model embedded in it, and no infer-ence engine.
Only the lexicon and the table-basedExtended Data Model have to be customised for anew domain of application.SQUIRREL maintains three levels of ambiguity,induced by the syntax, the semantics, and the do-main.
The Back End has a type checker, which usesthe Extended Data Model to resolve ambiguity fromthe semantic level.
At each level, all possible repre-sentations are generated by the system, and triedone at a time.
Only the appropriate ones survivethe type checking and the database consultation.As a consequence, more than one successful an-swer can be obtained from the same query.
All suc-cessful answers are presented to the user, who is incharge of choosing one.
This feature was added tothe original system in order to give the user controlover which elements are added to the context duringthe consultation.4 The  D iscourse  Modu le  - Overv iewThe core of the Discourse Module is the context, adynamic list of candidate antecedents for anaphoricreference.
The context grows as a stack, i.e., can-didates selected from each query and its DB answerare stored on top of the candidates from the previousqueries as the consultation evolves.
All candidatesare represented in the same format.Selection of candidates from the query is regulatedby rules embedded in the system's grammar, whereeach syntactic rule has its associated context rule.Entries are associated with information pertainingto category, number, gender and semantic represen-tation.
Since the lexicon allows open classes (such asproper names, for which no specific lexical entry ex-ists), some of this information may not become avail-able until the query reaches the database.
At thispoint, a separate database interrogation will supplygender information for proper nouns in the context.Selecting which items in database answers areadded to the context is less straightforward, as nosyntactic or semantic information is available con-cerning a particular answer.
Furthermore, the selec-tion may depend on a specific application and shouldbe a factor for customisation.
As a consequence, in-formation on which entities are to be kept as candi-dates for reference in the context is encoded in the120Extended Data Model.
Entries are formatted andassociated with syntactic and semantic information(on the basis of the characteristics of the databasedomain from which they are retrieved) and, in caseswhere the data derives from domains associated withproper nouns, gender is retrieved immediately.This context grows dynamically and is passed fromquery to query.
Nevertheless, this structure doesnot grow indefinitely during the consultation (thecontext updating mechanism is presented in ?5.2).When an anaphor is encountered in a query, acandidate is chosen among the available possible an-tecedents, and its semantics i inserted in the query'ssemantic representation, which is then passed to theback end in the normal way.
The binding mechanismis presented in ?5.3.Clearly, much hinges on an effective process to de-termine appropriate antecedents.
In the context ofthis application, which strongly emphasizes portabil-ity and, hence, seeks to avoid incorporating eneralworld knowledge, this issue is subject o constraints.5 The Context5.1 Rat iona leIn resolving anaphoric reference in NLFEs todatabases, due respect must be given to user require-ments; it must remain clear at all times which queryhas been answered.
Findings in Anick et al (1991)also apply here.
The operation of the front end mustbe clear to the user, who must retain the ability toaffect the system's decisions.
As a consequence, weadopt a protocol whereby (i) the user can alwaysreject the bindings offered by the system, and (ii)choice between competing candidates i in the handsof the user.This scenario has some consequences.
First ofall, our strategy aims not to completely resolve ananaphoric reference at all costs, but to present heuser with alternatives selected on the basis of reliablesystem information.
Secondly, to make this processhelpful, in a manageable way, the choice of candi-dates must be focused, intuitively credible, and oflimited size.5.2 Context  S t ructur ingHelpful selection of candidate antecedents presup-poses a sensitivity to the structure of the currentdiscourse.
More is needed than a simple collectionof items based on compliance with syntactic con-straints.
The literature offers a collection of ap-proaches to modelling discourse structure.Some views concentrate on deriving coherence re-lations between discourse segments, with the help ofworld models (Hobbs, 1979; Reichman, 1984).
Workon Discourse Structure Theory (Grosz, 1977; Groszand Sidner, 1986) searches for automatic ways of seg-menting discourse based on intentions and purposesembedded in discourse segments.Most of the results available are not readily adapt-able to the current type of application.
No worldmodel can be introduced without severe conse-quences for portability.
Segmentation i formationis not available and cannot be realised in advancesince consultation is on-line.The lack of clues regarding how to segment hedialogue between user and interface, and how toidentify the relationships between such segments re-stricts the possible solutions.
Nonetheless, somedomain information is present in the Data Modeland can be exploited.
The segmentation processdeployed here relies on two potential sources foridentifying coherence in relational queries.
First ofall, 'meaningful' queries are always associated witha complete access path covering relations and at-tributes in the database: if we represent the datamodel as a graph, a meaningful query will alwayscover a connected subgraph.
This gives us a mea-sure of cohesion within a single query.Building on this, we can develop a notion of dis-course domain covered by successive queries by com-paring the access paths involved in them.
To use thegraphical analogy as above, a collection of queriescovers a discourse domain if their graphs intersect.Finally, the degree and area of intersection (con-sulted attributes) may offer information which canbe used in the identification of focus.Candidates for anaphoric reference are groupedin segments, each containing all successive querieswhich share part of an access path.
The first querystarts the first segment of the context.
When anew query is entered, its covered omain is matchedagainst that of the segment on top of the context.If the intersection is not empty, candidates from thequery are added to this segment.
In case the in-tersection is empty, the system identifies a changeof focus on the consultation, and a new segment isstarted.
In order to allow the user to return to theprevious topic after the change of focus occurred, anumber of segments are held in the context.
Thisnumber can vary from application to application,and the current limit is set to three.Following Grosz and Sidner (1986), segments oc-cur in sequence, or are embedded, to allow usersto elaborate on a change of focus before returningto the previous topic.
In case the current segmentintersects with the second most recent one on thecontext list (if any), this can be seen as a returnto the previous topic (segments 1 and 3 in Fig 2).The current segment will continue to grow indepen-dently, but the candidates in the second most recentsegment will become available for reference.Within a segment, candidates are grouped byquery number.
When a candidate re-occurs, it isplaced on the top of the context list, and its previ-ous occurrence is deleted, regardless what segmentit belongs to.
The antecedent of a resolved anaphoris also added to the top \[Fig.
2\].
This strategy al-121lows for the representation f a notion of 'distance'between candidate antecedents and anaphor.5.3 The  Bind ing  Mechan ismWhen an anaphoric expression is encountered, allcandidates in the current segment with appropriatesyntactic characteristics are selected and placed inthe loci list (Sidner, 1983).
This list is presented tothe user, who must select a candidate or reject alloptions (in case there is more than one) \[Fig.
3\].Once a candidate is selected, its semantic repre-sentation is spliced into the First Order Logic rep-resentation of the current query, and the normalquerying process is resumed.5.4 ExamplesExample  1: Context updating mechanism \[Fig.
2\]query:  who is edna's boss?db answer: \[malcolm\]query: who supplies hoes?db answer : \[peterSJCO\]query:  what is sylvia's salary?db answer: \[2500\]query:  who is her boss?
** USER:  P lease  choose  one  subst i tu te  fo rthe  pronoun 'her'  :I - sy lv ia2 - none  above  number :  1db  answer: \[edna\]query:  what is kate's address?db answer: \[spring ave/query:  what is her account?
** USER: P lease  choose  one  substitute forthe pronoun 'her' :1 - kate2 - none  above  number :  1db  answer: \[678.655\]Candidates are grouped by query number and seg-ment number.
In the fourth query above, only sylviais presented as a substitute for the anaphor her, sincethis is the only entry with appropriate syntactic fea-tures in the current segment (segment 3 - Fig.
2).In case the user rejects it, edna (second most recentsegment) will be presented as a second option.
Sim-ilarly, in the last query, only kate is presented as aninitial choice (current segment).Example  2:query: whodb answer:query: whodb answer:The binding mechanism \[Fig.
3\]is edna's boss?\[malcolm\] "is sylvia's boss ?\[edn4query: who works for her  ?
** USER: P lease  choose  one substitute forthe  pronoun Cher' :I - sy lv ia2 - edna3 - none  above  number :db  answer: \[mary, sylvia, ted\]The binding mechanism relies solely on informa-tion provided by the Data Model, since there is noworld model available.
The absence of such a knowl-edge base is justified by the preoccupation withportability.
However, the task of dealing with dis-course phenomena is made more difficult.The user is given the burden of establishing pri-ority when chosing candidates for anaphora.
In Ex-ample  2, for instance, the system has no means ofdisambiguating between the two possible candidatesfor binding the pronoun 'her' (sylvia, edna), sinceboth have the same properties.
Note that humanswould not be able to select one either.Care must be taken in using information aboutcandidates to resolve ambiguity (for instance, thefact that edna is a boss, whereas ylvia is not), sincethis could lead into erroneous interpretations.
Theperson edna can be used in different contexts withinthe same dialogue, although it was introduced in thecontext via a query where she appears as boss.
Imag-ine that she is a boss in a shop, but also a registeredcustomer.
In such case, references to her name as acustomer would be disregarded.6 P lu ra l sThe importance of a proper context updating mech-anism is better seen when we focus on the treatmentof plurals.
Currently, the system is being extendedto cope with plural nouns and groups, referred toby pronouns like they, them, their.
The incorpora-tion in the context of these elements appearing inthe query or DB answer is processed as follows:(a) p lu ra l  nouns  appearing in the query or DBanswer are kept as plural elements, having one entryin the context;(b) g roups  resulting from a DB answer have eachof their elements incorporated in isolation, as a sin-gular noun, as well as one entry with all elementscombined as a group element;(e) con junct ions  appearing in the query aretreated as in (b).In the present system, problems mostly concernthe identification of which elements, appearing inseparate queries or in a query/DB answer, shouldbe gathered together to constitute a group entry.When a plural anaphor is encountered, the contextis searched.
In case there are no plural/group candi-dates available, or the user rejects them all, elementsin the current discourse segment will be gathered to-gether and presented to the user as a group.122Context Stack Context StackDomain Domain4.6 kate4.6 account ---~iI4.~ k_~t~ - -4.5 address4.5 spring ave3.4 sylvia3.4 boss3.4 edna3.3  - - : - -*3.3 salary3.3 25002.2 shoes2.2 peter~CO\[ ~- - _ - \ [ _  _1.1 edrn~ :1.1 b&~ :1.1 malcolmcustomeremployeesupplier Iemployee(a )Figure 2: Context Behaviour4.6 kate4.6 account z4.5 address b4.5 spring ave ~-3.4 sylvia3.4 boss3.4 edna3.3 salary S3.3 25002.2 shoes I "--~2.2 peter&COF"~Context Foci List Context(b)customeremployeesupplier2 sylvia2 ednal"e21hi" - -1 malcolmFigure 3:2 sylvia2 edna(a )Context - Foci List3 edna3 mary3 sylvia3 ted1 malcolm(b)1237 Conc lus ionsWe presented here a module for anaphora resolutionin a highly portable NLFE - SQUIRREL, which al-lows for continuous consultations whilst maintainingthe system's portability.A mechanism to deal with possible alternative suc-cessful DB answers has also been added.
Such fea-tures did not constitute a problem for the originalsystem, since no information was passed forward.With the incorporation of answers into the context,it became necessary to allow users to choose amongthe multiple possibilities presented by the system,assuring that a unique answer is selected.We treat some simple cases of there (although itis not an anaphor, but a deictic adverb), due to thehigh rate of usage of such pointing back device indialogues.
In the domain covered by this implemen-tation, its use allows reference to addresses and lo-cations like department and floor.We maintain that portability is an importantproperty, as NLFEs to databases only make sensein a commercial context.
We have demonstratedthat it is possible to include reliable, user-orientedfeatures of discourse phenomena in the coverage ofmodular NLFEs without recourse to world models,safeguarding portability.ReferencesAnick, Peter G.; Brennan, Jeffrey D.; Flynn, Rex A.;Hanssen, David R.; Alvey, Bryan; and Robbins,Jeffrey M. (1990).
"A Direct Manipulation Inter-face for Boolean Information Retrieval via NaturalLanguage Query."
In 13th International Confer-ence on Research and Development in InformationRetrieval (ACM-SIGIR), 135-150.
Brussels.Ballard, Bruce W.; Lusth, John C.; and Tinkham,Nancy L. (1984).
"LDC-I: A Transportable,Knowledge-Based Natural Language Processor forOffice Environments."
In ACM Transactions onOffice Information Systems 2(1), 1-25.Barros, Flavia A., and DeRoeck, Anne (1993).
"Portable Natural Language Front Ends- A Re-view".
Research Report CSM-194.
Dept.
of Com-puter Science.
University of Essex, U.K.Bates, Madeleine; Moser, M.G.
; and Stallar, David(1986).
"The IRUS Transportable Natural Lan-guage Database Interface."
In Expert DatabaseSystems, edited by Larry Kerschberg, 617-630.The Benjamin/Cummings Pub.
Co. Inc.DeRoeck, Anne; Fox, Chris; Lowden, Barryl;Turner, Ray; and Walls, Bryan (1991).
"A Nat-ural Language System Based on Formal Seman-tics."
Proceedings of the International Conferenceon Current Issues in Computational Linguistics,221-234.
Penang, Malaysia.Grosz, Barbara J.
(1977).
"The Representation a dUse of Focus in a System for Understanding Di-alogs."
In Readings in Natural Language Process-ing, edited by Barbara J. Grosz, Karen S. Jones,and Bonny L. Webber (1986), 353-362.
MorganKaufmann Pub.
Inc.Grosz, Barbara J., and Sidner, Candace L.
(1986).
"Attention, Intention, and the Structure of Dis-course."
In Computational Linguistics 12(3), 175-204.Grosz, Barbara J.; Appelt, Douglas E.; Martin, PaulA.
; and Pereira, Fernando C.N.
(1987).
"TEAM:An Experiment in the Design of TransportableNatural-Language Interfaces."
In Artificial Intel-ligence 32, 173-243.Harris, Larry R. (1984).
"Experience with INTEL-LECT: Artificial Intelligence Technology Trans-fer."
In The AI Magazine 2(2), 43-50.Hendrix, Gary G.; Sacerdoti, Earl D.; Sagalowicz,Daniel; and Slocum, Jonathan (1978).
"Devel-oping a Natural Language Interface to ComplexData."
In ACM Transactions on Database Sys-tems 3(2), 105-147.Hobbs, Jerry R. (1979).
"Coherence and Corefer-ence."
In Cognitive Science 3(1), 67-90.Reichman-Adar, Rachel (1984).
"Extended Person-Machine Interface."
In Artificial Intelligence 22,157-218.Sidner, Candace L. (1983).
"Focusing in the Com-prehension of Definite Anaphora."
In Computa-tional Models of Discourse, edited by M. Bradyand R. Berwick, 267-330.
MIT Press.Craig, James A.; Berenzer, Susan C.; Carney, HomerC.
; and Longyear, Christopher R. (1966).
"DEA-CON: Direct English Access and Control."
In FallJoint Conference of AFIPS 29,365-380.
San Fran-cisco, CA.Trost, Harald; Buehberger, Ernst; Heinz, Wolf-gang; H6rtnagl, Christian; and Matiasek, Jo-hannes (1988).
"Datenbank-DIALOG: A Germanlanguage Interface for Relational database."
InApplied Artificial Intelligence 1, 181-203.
Hemi-sphere Publishing Corporation.Turner Ray (1987).
"A Theory of Properties."
InJournal of Symbolic Logic 52(2), 445-472.Winograd, Terry (1972).
Understanding NaturalLanguage.
Academic Press, New York.Woods, Willian A.
(1973).
"Progress in Natural Lan-guage Understanding: An Application to LunarGeology."
In Proceedings of AFIPS National Com-puter Conference, 441-450.124
