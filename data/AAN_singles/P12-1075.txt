Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 712?720,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsUnsupervised Relation Discovery with Sense DisambiguationLimin Yao Sebastian Riedel Andrew McCallumDepartment of Computer ScienceUniversity of Massachusetts, Amherst{lmyao,riedel,mccallum}@cs.umass.eduAbstractTo discover relation types from text, mostmethods cluster shallow or syntactic patternsof relation mentions, but consider only onepossible sense per pattern.
In practice thisassumption is often violated.
In this paperwe overcome this issue by inducing clustersof pattern senses from feature representationsof patterns.
In particular, we employ a topicmodel to partition entity pairs associated withpatterns into sense clusters using local andglobal features.
We merge these sense clus-ters into semantic relations using hierarchicalagglomerative clustering.
We compare againstseveral baselines: a generative latent-variablemodel, a clustering method that does not dis-ambiguate between path senses, and our ownapproach but with only local features.
Exper-imental results show our proposed approachdiscovers dramatically more accurate clustersthan models without sense disambiguation,and that incorporating global features, such asthe document theme, is crucial.1 IntroductionRelation extraction (RE) is the task of determin-ing semantic relations between entities mentioned intext.
RE is an essential part of information extractionand is useful for question answering (Ravichandranand Hovy, 2002), textual entailment (Szpektor et al,2004) and many other applications.A common approach to RE is to assume that rela-tions to be extracted are part of a predefined ontol-ogy.
For example, the relations are given in knowl-edge bases such as Freebase (Bollacker et al, 2008)or DBpedia (Bizer et al, 2009).
However, in manyapplications, ontologies do not yet exist or have lowcoverage.
Even when they do exist, their mainte-nance and extension are considered to be a substan-tial bottleneck.
This has led to considerable inter-est in unsupervised relation discovery (Hasegawa etal., 2004; Banko and Etzioni, 2008; Lin and Pantel,2001; Bollegala et al, 2010; Yao et al, 2011).
Here,the relation extractor simultaneously discovers factsexpressed in natural language, and the ontology intowhich they are assigned.Many relation discovery methods rely exclusivelyon the notion of either shallow or syntactic patternsthat appear between two named entities (Bollegala etal., 2010; Lin and Pantel, 2001).
Such patterns couldbe sequences of lemmas and Part-of-Speech tags, orlexicalized dependency paths.
Generally speaking,relation discovery attempts to cluster such patternsinto sets of equivalent or similar meaning.
Whetherwe use sequences or dependency paths, we will en-counter the problem of polysemy.
For example, apattern such as ?A beat B?
can mean that person Awins over B in competing for a political position,as pair ?
(Hillary Rodham Clinton, Jonathan Tasini)?in ?Sen Hillary Rodham Clinton beats rival JonathanTasini for Senate.?
It can also indicate that an athleteA beat B in a sports match, as pair ?
(Dmitry Tur-sunov, Andy Roddick)?
in ?Dmitry Tursunov beatthe best American player Andy Roddick.?
More-over, it can mean ?physically beat?
as pair ?
(Mr.Harris, Mr. Simon)?
in ?On Sept. 7, 1999, Mr. Har-ris fatally beat Mr.
Simon.?
This is known as poly-semy.
If we work with patterns alone, our extractorwill not be able to differentiate between these cases.Most previous approaches do not explicitly ad-dress this problem.
Lin and Pantel (2001) assumesonly one sense per path.
In (Pantel et al, 2007),they augment each relation with its selectional pref-712erences, i.e.
fine-grained entity types of two ar-guments, to handle polysemy.
However, such finegrained entity types come at a high cost.
It is difficultto discover a high-quality set of fine-grained entitytypes due to unknown criteria for developing sucha set.
In particular, the optimal granularity of en-tity types depends on the particular pattern we con-sider.
For example, a pattern like ?A beat B?
couldrefer to A winning a sports competition against B, ora political election.
To differentiate between thesesenses we need types such as ?Politician?
or ?Ath-lete?.
However, for ?A, the parent of B?
we onlyneed to distinguish between persons and organiza-tions (for the case of the sub-organization relation).In addition, there are senses that just cannot be de-termined by entity types alone: Take the meaningof ?A beat B?
where A and B are both persons; thiscould mean A physically beats B, or it could meanthat A defeated B in a competition.In this paper we address the problem of polysemy,while we circumvent the problem of finding fine-grained entity types.
Instead of mapping entities tofine-grained types, we directly induce pattern sensesby clustering feature representations of pattern con-texts, i.e.
the entity pairs associated with a pattern.This allows us to employ not only local features suchas words, but also global features such as the docu-ment and sentence themes.To cluster the entity pairs of a single relation pat-tern into senses, we develop a simple extension toLatent Dirichlet Allocation (Blei et al, 2003).
Oncewe have our pattern senses, we merge them intoclusters of different patterns with a similar sense.We employ hierarchical agglomerative clusteringwith a similarity metric that considers features suchas the entity arguments, and the document and sen-tence themes.We perform experiments on New York Times ar-ticles and consider lexicalized dependency paths aspatterns in our data.
In the following we shall usethe term path and pattern exchangeably.
We com-pare our approach with several baseline systems, in-cluding a generative model approach, a clusteringmethod that does not disambiguate between senses,and our approach with different features.
We per-form both automatic and manual evaluations.
Forautomatic evaluation, we use relation instances inFreebase as ground truth, and employ two clusteringmetrics, pairwise F-score and B3 (as used in cofer-ence).
Experimental results show that our approachimproves over the baselines, and that using globalfeatures achieves better performance than using en-tity type based features.
For manual evaluation, weemploy a set intrusion method (Chang et al, 2009).The results also show that our approach discovers re-lation clusters that human evaluators find coherent.2 Our ApproachWe induce pattern senses by clustering the entitypairs associated with a pattern, and discover seman-tic relations by clustering these sense clusters.
Werepresent each pattern as a list of entity pairs andemploy a topic model to partition them into differentsense clusters using local and global features.
Wetake each sense cluster of a pattern as an atomic clus-ter, and use hierarchical agglomerative clustering toorganize them into semantic relations.
Therefore, asemantic relation comprises a set of sense clusters ofpatterns.
Note that one pattern can fall into differentsemantic relations when it has multiple senses.2.1 Sense DisambiguationIn this section, we discuss the details of how we dis-cover senses of a pattern.
For each pattern, we forma clustering task by collecting all entity pairs the pat-tern connects.
Our goal is to partition these entitypairs into sense clusters.
We represent each pair bythe following features.Entity names: We use the surface string of the en-tity pair as features.
For example, for pattern ?A playB?, pairs which contain B argument ?Mozart?
couldbe in one sense, whereas pairs which have ?Mets?could be in another sense.Words: The words between and around the twoentity arguments can disambiguate the sense of apath.
For example, ?A?s parent company B?
is dif-ferent from ?A?s largest company B?
although theyshare the same path ?A?s company B?.
The formerdescribes the sub-organization relationship betweentwo companies, while the latter describes B as thelargest company in a location A.
The two words tothe left of the source argument, and to the right of thedestination argument also help sense discovery.
Forexample, in ?Mazurkas played by Anna Kijanowska,pianist?, ?pianist?
tells us pattern ?A played by B?713takes the ?music?
sense.Document theme: Sometimes, the same patterncan express different relations in different docu-ments, depending on the document?s theme.
Forinstance, in a document about politics, ?A defeatedB?
is perhaps about a politician that won an elec-tion against another politician.
While in a documentabout sports, it could be a team that won against an-other team in a game, or an athlete that defeated an-other athlete.
In our experiments, we use the meta-descriptors of a document as side information andtrain a standard LDA model to find the theme of adocument.
See Section 3.1 for details.Sentence theme: A document may cover severalthemes.
Moreover, sometimes the theme of a doc-ument is too general to disambiguate senses.
Wetherefore also extract the theme of a sentence as afeature.
Details are in 3.1.We call entity name and word features local, andthe two theme features global.We employ a topic model to discover senses foreach path.
Each path pi forms a document, and itcontains a list of entity pairs co-occurring with thepath in the tuples.
Each entity pair is representedby a list of features fk as we described.
For eachpath, we draw a multinomial distribution ?
over top-ics/senses.
For each feature of an entity pair, wedraw a topic/sense from ?pi .
Formally, the gener-ative process is as follows:?pi ?
Dirichlet(?
)?z ?
Dirichlet(?
)ze ?
Multinomial(?pi)fk ?
Multinomial(?ze)Assume we have m paths and l entity pairs for eachpath.
We denote each entity pair of a path as e(pi) =(f1, .
.
.
, fn).
Hence we have:P (e1(pi), e2(pi), .
.
.
, el(pi)|z1, z2, .
.
.
, zl)=l?j=1n?k=1p(fk|zj)p(zj)We assume the features are conditionally indepen-dent given the topic assignments.
Each feature isgenerated from a multinomial distribution ?.
Weuse Dirichlet priors on ?
and ?.
Figure 1 shows thegraphical representation of this model.Sp?e(p)f?
?z?nFigure 1: Sense-LDA model.This model is a minor variation on standard LDAand the difference is that instead of drawing an ob-servation from a hidden topic variable, we drawmultiple observations from a hidden topic variable.Gibbs sampling is used for inference.
After infer-ence, each entity pair of a path is assigned to onetopic.
One topic is one sense.
Entity pairs whichshare the same topic assignments form one sensecluster.2.2 Hierarchical Agglomerative ClusteringAfter discovering sense clusters of paths, we employhierarchical agglomerative clustering (HAC) to dis-cover semantic relations from these sense clusters.We apply the complete linkage strategy and take co-sine similarity as the distance function.
The cuttingthreshold is set to 0.1.We represent each sense cluster as one vector bysumming up features from each entity pair in thecluster.
The weight of a feature indicates how manyentity pairs in the cluster have the feature.
Somefeatures may get larger weights and dominate the co-sine similarity.
We down-weigh these features.
Forexample, we use binary features for word ?defeat?in sense clusters of pattern ?A defeat B?.
The twotheme features are extracted from generative mod-els, and each is a topic number.Our approach produces sense clusters for eachpath and semantic relation clusters of the whole data.Table 1 and 2 show some example output.3 ExperimentsWe carry out experiments on New York Times ar-ticles from years 2000 to 2007 (Sandhaus, 2008).Following (Yao et al, 2011), we filter out noisy doc-uments and use natural language packages to anno-tate the documents, including NER tagging (Finkelet al, 2005) and dependency parsing (Nivre et al,2004).
We extract dependency paths for each pair ofnamed entities in one sentence.
We use their lemmas714Path 20:sports 30:entertainment 25:music/artA play BAmericans, Ireland Jean-Pierre Bacri, Jacques Daniel Barenboim, recital of MozartYankees, Angels Rita Benton, Gay Head Dance Mr. Rose, BalladeEcuador, England Jeanie, Scrabble Gil Shaham, Violin RomanceRedskins, Detroit Meryl Streep, Leilah Ms. Golabek, SteinwaysRed Bulls, F.C.
Barcelona Kevin Kline, Douglas Fairbanks Bruce Springsteen, Saintsdoc theme sports music books television music theatersen theme game yankees theater production book film show music reviews operalexical words beat victory num-num won played plays directed artistic director conducted productionentity names - r:theater r:theater r:hall r:york l:operaTable 1: Example sense clusters produced by sense disambiguation.
For each sense, we randomly sample 5 entitypairs.
We also show top features for each sense.
Each row shows one feature type, where ?num?
stands for digitalnumbers, and prefix ?l:?
for source argument, prefix ?r:?
for destination argument.
Some features overlap with eachother.
We manually label each sense for easy understanding.
We can see the last two senses are close to each other.For two theme features, we replace the theme number with the top words.
For example, the document theme of thefirst sense is Topic30, and Topic30 has top words ?sports?.relation pathsentertainment A, who play B:30; A play B:30; star A as B:30sportslead A to victory over B:20; A play to B:20; A play B:20; A?s loss to B:20; A beat B:20; A trail B:20;A face B:26; A hold B:26; A play B:26; A acquire (X) from B:26; A send (X) to B:26;politicsA nominate B:39; A name B:39; A select B:39; A name B:42; A select B:42;A ask B:42; A choose B:42; A nominate B:42; A turn to B:42;law A charge B:39; A file against B:39; A accuse B:39; A sue B:39Table 2: Example semantic relation clusters produced by our approach.
For each cluster, we list the top paths in it,and each is followed by ?
:number?, indicating its sense obtained from sense disambiguation.
They are ranked by thenumber of entity pairs they take.
The column on the left shows sense of each relation.
They are added manually bylooking at the sense numbers associated with each path.for words on the dependency paths.
Each entity pairand the dependency path which connects them forma tuple.We filter out paths which occur fewer than 200times and use some heuristic rules to filter out pathswhich are unlikely to represent a relation, for exam-ple, paths in with both arguments take the syntac-tic role ?dobj?
(direct objective) in the dependencypath.
In such cases both arguments are often partof a coordination structure, and it is unlikely thatthey are related.
In summary, we collect about onemillion tuples, 1300 patterns and half million namedentities.
In terms of named entities, the data is verysparse.
On average one named entity occurs fourtimes.3.1 Feature ExtractionFor the entity name features, we split each entitystring of a tuple into tokens.
Each token is a fea-ture.
The source argument tokens are augmentedwith prefix ?l:?, and the destination argument tokenswith prefix ?r:?.
We use tokens to encourage overlapbetween different entities.For the word features, we extract all the words be-tween the two arguments, removing stopwords andthe words with capital letters.
Words with capitalletters are usually named entities, and they do nottend to indicate relations.
We also extract neigh-boring words of source and destination arguments.The two words to the left of the source argument areadded with prefix ?lc:?.
Similarly the two words tothe right of the destination arguments are added withprefix ?rc:?.Each document in the NYT corpus is associatedwith many descriptors, indicating the topic of thedocument.
For example, some documents are la-beled as ?Sports?, ?Dallas Cowboys?, ?New YorkGiants?, ?Pro Football?
and so on.
Some are labeled715as ?Politics and Government?, and ?Elections?.
Weshall extract a theme feature for each document fromthese descriptors.
To this end we interpret the de-scriptors as words in documents, and train a standardLDA model based on these documents.
We pick themost frequent topic as the theme of a document.We also train a standard LDA model to obtainthe theme of a sentence.
We use a bag-of-wordsrepresentation for a document and ignore sentencesfrom which we do not extract any tuples.
The LDAmodel assigns each word to a topic.
We count theoccurrences of all topics in one sentence and pickthe most frequent one as its theme.
This featurecaptures the intuition that different words can indi-cate the same sense, for example, ?film?
?, ?show?,?series?
and ?television?
are about ?entertainment?,while ?coach?, ?game?, ?jets?, ?giants?
and ?sea-son?
are about ?sports?.3.2 Sense clusters and relation clustersFor the sense disambiguation model, we set thenumber of topics (senses) to 50.
We experimentedwith other numbers, but this setting yielded the bestresults based on our automatic evaluation measures.Note that a path has a multinomial distribution over50 senses but only a few senses have non-zero prob-abilities.We look at some sense clusters of paths.
Forpath ?A play B?, we examine the top three senses,as shown in Table 1.
The last two senses ?enter-tainment?
and ?music?
are close.
Randomly sam-pling some entity pairs from each of them, we findthat the two sense clusters are precise.
Only 1% ofpairs from the sense cluster ?entertainment?
shouldbe assigned to the ?music?
sense.
For the path ?playA in B?
we discover two senses which take themost probabilities: ?sports?
and ?art?.
Both clus-ters are precise.
However, the ?sports?
sense maystill be split into more fine-grained sense clusters.
In?sports?, 67% pairs mean ?play another team in alocation?
while 33% mean ?play another team in agame?.We also closely investigate some relation clusters,shown in Table 2.
Both the first and second relationcontain path ?A play B?
but with different senses.For the second relation, most paths state ?play?
re-lations between two teams, while a few of themexpress relations of teams acquiring players fromother teams.
For example, the entity pair ?
(AtlantaHawks, Dallas Mavericks)?
mentioned in sentence?The Atlanta Hawks acquired point guard AnthonyJohnson from the Dallas Mavericks.?
This is due tothat they share many entity pairs of team-team.3.3 BaselinesWe compare our approach against several baselinesystems, including a generative model approach andvariations of our own approach.Rel-LDA: Generative models have been suc-cessfully applied to unsupervised relation extrac-tion (Rink and Harabagiu, 2011; Yao et al, 2011).We compare against one such model: An extensionto standard LDA that falls into the framework pre-sented by Yao et al (2011).
Each document con-sists of a list of tuples.
Each tuple is represented byfeatures of the entity pair, as listed in 2.1, and thepath.
For each document, we draw a multinomialdistribution over relations.
For each tuple, we drawa relation topic and independently generate all thefeatures.
The intuition is that each document dis-cusses one domain, and has a particular distributionover relations.In our experiments, we test different numbers ofrelation topics.
As the number goes up, precision in-creases whereas recall drops.
We report results with300 and 1000 relation topics.One sense per path (HAC): This system usesonly hierarchical clustering to discover relations,skipping sense disambiguation.
This is similar toDIRT (Lin and Pantel, 2001).
In DIRT, each pathis represented by its entity arguments.
DIRT cal-culates distributional similarities between differentpaths to find paths which bear the same semantic re-lation.
It does not employ global topic model fea-tures extracted from documents and sentences.Local: This system uses our approach (both senseclustering with topic models and hierarchical clus-tering), but without global features.Local+Type This system adds entity type features tothe previous system.
This allows us to compare per-formance of using global features against entity typefeatures.
To determine entity types, we link namedentities to Wikipedia pages using the Wikifier (Rati-nov et al, 2011) package and extract categories fromthe Wikipedia page.
Generally Wikipedia providesmany types for one entity.
For example, ?Mozart?
is716a person, musician, pianist, composer, and catholic.As we argued in Section 1, it is difficult to determinethe right granularity of the entity types to use.
In ourexperiments, we use all of them as features.
In hier-archical clustering, for each sense cluster of a path,we pick the most frequent entity type as a feature.This approach can be seen as a proxy to ISP (Pantelet al, 2007), since selectional preferences are oneway of distinguishing multiple senses of a path.Our Approach+Type This system adds Wikipediaentity type features to our approach.
The Wikipediafeature is the same as used in the previous system.4 Evaluations4.1 Automatic Evaluation against FreebaseWe evaluate relation clusters discovered by all ap-proaches against Freebase.
Freebase comprises alarge collection of entities and relations which comefrom varieties of data sources, including Wikipediainfoboxes.
Many users also contribute to Freebaseby annotating relation instances.
We use coreferenceevaluation metrics: pairwise F-score and B3 (Baggaand Baldwin, 1998).
Pairwise metrics measure howoften two tuples which are clustered in one seman-tic relation are labeled with the same Freebase label.We evaluate approximately 10,000 tuples which oc-cur in both our data and Freebase.
Since our sys-tem predicts fine-grained clusters comparing againstFreebase relations, the measure of recall is underes-timated.
The precision measure is more reliable andwe employ F-0.5 measure, which places more em-phasis on precision.Matthews correlation coefficient (MCC) (Baldi etal., 2000) is another measure used in machine learn-ing, which takes into account true and false positivesand negatives and is generally regarded as a bal-anced measure which can be used when the classesare of very different sizes.
In our case, the true nega-tive number is 100 times larger than the true positivenumber.
Therefor we also employ MCC, calculatedasMCC = TP?TN?FP?FN?
(TP+FP )(TP+FN)(TN+FP )(TN+FN)The MCC score is between -1 and 1.
The larger thebetter.
In perfect predictions, FP and FN are 0, andthe MCC score is 1.
A random prediction results inscore 0.Table 3 shows the results of all systems.
Our ap-proach achieves the best performance in most mea-sures.
Without using sense disambiguation, the per-formance of hierarchical clustering decreases signif-icantly, losing 17% in precision in the pairwise mea-sure, and 15% in terms ofB3.
The generative modelapproach with 300 topics achieves similar precisionto the hierarchical clustering approach.
With moretopics, the precision increases, however, the recallof the generative model is much lower than thoseof other approaches.
We also show the results ofour approach without global document and sentencetheme features (Local).
In this case, both precisionand recall decrease.
We compare global features(Our approach) against Wikipedia entity type fea-tures (Local+Type).
We see that using global fea-tures achieves better performance than using entitytype based features.
When we add entity type fea-tures to our approach, the performance does not in-crease.
The entity type features do not help muchis due to that we cannot determine which particulartype to choose for an entity pair.
Take pair ?
(HillaryRodham Clinton, Jonathan Tasini)?
as an example,choosing politician for both arguments instead ofperson will help.We should note that these measures provide com-parison between different systems although theyare not accurate.
One reason is the following:some relation instances should have multiple la-bels but they have only one label in Freebase.For example, instances of a relation that a per-son ?was born in?
a country could be labeledas ?/people/person/place of birth?
and as ?/peo-ple/person/nationality?.
This decreases the pairwiseprecision.
Further discussion is in Section 4.3.4.2 Path IntrusionWe also evaluate coherence of relation clusters pro-duced by different approaches by creating path in-trusion tasks (Chang et al, 2009).
In each task, somepaths from one cluster and an intruding path fromanother are shown, and the annotator?s job is to iden-tify one single path which is out of place.
For eachpath, we also show the annotators one example sen-tence.
Three graduate students in natural languageprocessing annotate intruding paths.
For disagree-ments, we use majority voting.
Table 4 shows oneexample intrusion task.717SystemPairwise B3Prec.
Rec.
F-0.5 MCC Prec.
Rec.
F-0.5Rel-LDA/300 0.593 0.077 0.254 0.191 0.558 0.183 0.396Rel-LDA/1000 0.638 0.061 0.220 0.177 0.626 0.160 0.396HAC 0.567 0.152 0.367 0.261 0.523 0.248 0.428Local 0.625 0.136 0.364 0.264 0.626 0.225 0.462Local+Type 0.718 0.115 0.350 0.265 0.704 0.201 0.469Our Approach 0.736 0.156 0.422 0.314 0.677 0.233 0.490Our Approach+Type 0.682 0.110 0.334 0.250 0.687 0.199 0.460Table 3: Pairwise and B3 evaluation for various systems.
Since our systems predict more fine-grained clusters thanFreebase, the recall measure is underestimated.Path Example sentenceA beat B Dmitry Tursunov beat the best American player, Andy RoddickA, who lose to B Sluman, Loren Roberts (who lost a 1994 Open playoff to Ernie Els at Oakmont ...A, who beat B ... offender seems to be the Russian Mariya Sharapova, who beat Jelena DokicA, a broker at B Robert Bewkes, a broker at UBS for 12 yearsA meet B Howell will meet Geoff Ogilvy, Harrington will face Davis Love IIITable 4: A path intrusion task.
We show 5 paths and ask the annotator to identify one path which does not belong tothe cluster.
And we show one example sentence for each path.
The entities (As and Bs) in the sentences are bold.
Andthe italic row here indicates the intruder.System CorrectRel-LDA/300 0.737Rel-LDA/1000 0.821HAC 0.852Local+Type 0.773Our approach 0.887Table 5: Results of intruding tasks of all systems.From Table 5, we see that our approach achievesthe best performance.
We concentrate on some in-trusion tasks and compare the clusters produced bydifferent systems.The clusters produced by HAC (without sense dis-ambiguation) is coherent if all the paths in one rela-tion take a particular sense.
For example, one taskcontains paths ?A, director at B?, ?A, specialist atB?, ?A, researcher at B?, ?A, B professor?
and ?A?sprogram B?.
It is easy to identify ?A?s program B?as an intruder when the annotators realize that theother four paths state the relation that people workin an educational institution.
The generative modelapproach produces more coherent clusters when thenumber of relation topics increases.The system which employs local and entity typefeatures (Local+Type) produces clusters with lowcoherence because the system puts high weight ontypes.
For example, (United States, A talk with B,Syria) and (Canada, A defeat B, United States) areclustered into one relation since they share the argu-ment types ?country?-?country?.
Our approach us-ing the global theme features can correct such errors.4.3 Error AnalysisWe also closely analyze the pairwise errors that weencounter when comparing against Freebase labels.Some errors arise because one instance can havemultiple labels, as we explained in Section 4.1.
Oneexample is the following: Our approach predicts that(News Corporation, buy, MySpace) and (Dow Jones& Company, the parent of, The Wall Street Journal)are in one relation.
In Freebase, one is labeled as?/organization/parent/child?, the other is labeled as?/book/newspaper owner/newspapers owned?.
Thelatter is a sub-relation of the former.
We can over-come this issue by introducing hierarchies in relationlabels.Some errors are caused by selecting the incorrectsense for an entity pair of a path.
For instance, weput (Kenny Smith, who grew up in, Queens) and(Phil Jackson, return to, Los Angeles Lakers) into718the ?/people/person/place of birth?
relation clustersince we do not detect the ?sports?
sense for the en-tity pair ?
(Phil Jackson, Los Angeles Lakers)?.5 Related WorkThere has been considerable interest in unsupervisedrelation discovery, including clustering approach,generative models and many other approaches.Our work is closely related to DIRT (Lin and Pan-tel, 2001).
Both DIRT and our approach representdependency paths using their arguments.
Both usedistributional similarity to find patterns representingsimilar semantic relations.
Based on DIRT, Pantelet al (2007) addresses the issue of multiple sensesper path by automatically learning admissible argu-ment types where two paths are similar.
They clusterarguments to fine-grained entity types and rank theassociations of a relation with these entity types todiscover selectional preferences.
Selectional prefer-ences discovery (Ritter et al, 2010; Seaghdha, 2010)can help path sense disambiguation, however, weshow that using global features performs better thanentity type features.Our approach is also related to feature parti-tioning in cross-cutting model of lexical seman-tics (Reisinger and Mooney, 2011).
And our sensedisambiguation model is inspired by this work.There they partition features of words into views andcluster words inside each view.
In our case, eachsense of a path can be seen as one view.
However,we allow different views to be merged since someviews overlap with each other.Hasegawa et al (2004) cluster pairs of named en-tities according to the similarity of context words in-tervening between them.
Hachey (2009) uses topicmodels to perform dimensionality reduction on fea-tures when clustering entity pairs into relations.
Bol-legala et al (2010) employ co-clustering to find clus-ters of entity pairs and patterns jointly.
All the ap-proaches above neither deal with polysemy nor in-corporate global features, such as sentence and doc-ument themes.Open information extraction aims to discover re-lations independent of specific domains (Banko etal., 2007; Banko and Etzioni, 2008).
They employa self-learner to extract relation instances, but noattempt is made to cluster instances into relations.Yates and Etzioni (2009) present RESOLVER fordiscovering relational synonyms as a post process-ing step.
Our approach falls into the same category.Moreover, we explore path senses and global fea-tures for relation discovery.Many generative probabilistic models have beenapplied to relation extraction.
For example, vari-eties of topic models are employed for both opendomain (Yao et al, 2011) and in-domain relationdiscovery (Chen et al, 2011; Rink and Harabagiu,2011).
Our approach employs generative modelsfor path sense disambiguation, which achieves betterperformance than directly applying generative mod-els to unsupervised relation discovery.6 ConclusionWe explore senses of paths to discover semantic re-lations.
We employ a topic model to partition en-tity pairs of a path into different sense clusters anduse hierarchical agglomerative clustering to mergesenses into semantic relations.
Experimental resultsshow our approach discovers precise relation clus-ters and outperforms a generative model approachand a clustering method which does not addresssense disambiguation.
We also show that usingglobal features improves the performance of unsu-pervised relation discovery over using entity typebased features.AcknowledgmentsThis work was supported in part by the Centerfor Intelligent Information Retrieval and the Uni-versity of Massachusetts gratefully acknowledgesthe support of Defense Advanced Research ProjectsAgency (DARPA) Machine Reading Program underAir Force Research Laboratory (AFRL) prime con-tract no.
FA8750-09-C-0181.
Any opinions, find-ings, and conclusion or recommendations expressedin this material are those of the authors and do notnecessarily reflect the view of DARPA, AFRL, orthe US government.ReferencesAmit Bagga and Breck Baldwin.
1998.
Algorithms forscoring coreference chains.
In The First InternationalConference on Language Resources and EvaluationWorkshop on Linguistics Coreference.719Pierre Baldi, S?ren Brunak, Yves Chauvin, Claus A. F.Andersen, and Henrik Nielsen.
2000.
Assessing theaccuracy of prediction algorithms for classification: anoverview.
Bioinformatics, 16:412?424.Michele Banko and Oren Etzioni.
2008.
The tradeoffsbetween open and traditional relation extraction.
InProceedings of ACL-08: HLT.Michele Banko, Michael J Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open in-formation extraction from the web.
In Proceedings ofIJCAI2007.Christian Bizer, Jens Lehmann, Georgi Kobilarov, So?renAuer, Christian Becker, Richard Cyganiak, and Se-bastian Hellmann.
2009.
DBpedia - a crystallizationpoint for the web of data.
Journal of Web Semantics:Science, Services and Agents on the World Wide Web,pages 154?165.David Blei, Andrew Ng, and Michael Jordan.
2003.
La-tent Dirichlet Allocation.
Journal of Machine Learn-ing Research, 3:993?1022, January.Kurt Bollacker, Colin Evans, Praveen Paritosh, TimSturge, and Jamie Taylor.
2008.
Freebase: a collabo-ratively created graph database for structuring humanknowledge.
In SIGMOD ?08: Proceedings of the 2008ACM SIGMOD international conference on Manage-ment of data, pages 1247?1250, New York, NY, USA.ACM.Danushka Bollegala, Yutaka Matsuo, and MitsuruIshizuka.
2010.
Relational duality: Unsupervised ex-traction of semantic relations between entities on theweb.
In Proceedings of WWW.Jonathan Chang, Jordan Boyd-Graber, Chong Wang,Sean Gerrish, and David Blei.
2009.
Reading tealeaves: How humans interpret topic models.
In Pro-ceedings of NIPS.Harr Chen, Edward Benson, Tahira Naseem, and ReginaBarzilay.
2011.
In-domain relation discovery withmeta-constraints via posterior regularization.
In Pro-ceedings of ACL.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informa-tion into information extraction systems by gibbs sam-pling.
In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics (ACL?05), pages 363?370, June.Benjamin Hachey.
2009.
Towards Generic Relation Ex-traction.
Ph.D. thesis, University of Edinburgh.Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.2004.
Discovering relations among named entitiesfrom large corpora.
In ACL.Dekang Lin and Patrick Pantel.
2001.
DIRT - Discoveryof Inference Rules from Text.
In Proceedings of KDD.J.
Nivre, J.
Hall, and J. Nilsson.
2004.
Memory-baseddependency parsing.
In Proceedings of CoNLL, pages49?56.Patrick Pantel, Rahul Bhagat, Bonaventura Coppola,Timothy Chklovski, and Eduard Hovy.
2007.
ISP:Learning Inferential Selectional Preferences.
In Pro-ceedings of NAACL HLT.Lev Ratinov, Dan Roth, Doug Downey, and Mike Ander-son.
2011.
Local and global algorithms for disam-biguation to Wikipedia.
In Proceedings of ACL.Deepak Ravichandran and Eduard Hovy.
2002.
Learningsurface text patterns for a question answering system.In Proceedings of ACL.Joseph Reisinger and Raymond J. Mooney.
2011.
Cross-cutting models of lexical semantics.
In Proceedings ofEMNLP.Bryan Rink and Sanda Harabagiu.
2011.
A generativemodel for unsupervised discovery of relations and ar-gument classes from clinical texts.
In Proceedings ofEMNLP.Alan Ritter, Mausam, and Oren Etzioni.
2010.
A La-tent Dirichlet Allocation method for Selectional Pref-erences.
In Proceedings of ACL10.Evan Sandhaus, 2008.
The New York Times AnnotatedCorpus.
Linguistic Data Consortium, Philadelphia.Diarmuid O Seaghdha.
2010.
Latent variable models ofselectional preference.
In Proceedings of ACL 10.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisition ofentailment relations.
In Proceedings of EMNLP.Limin Yao, Aria Haghighi, Sebastian Riedel, and AndrewMcCallum.
2011.
Structured relation discovery usinggenerative models.
In Proceedings of EMNLP.Alexander Yates and Oren Etzioni.
2009.
Unsupervisedmethods for determining object and relation synonymson the web.
Journal of Artificial Intelligence Research,34:255?296.720
