Coling 2010: Poster Volume, pages 126?134,Beijing, August 2010Improving Graph-based Dependency Parsing with Decision HistoryWenliang Chen?, Jun?ichi Kazama?, Yoshimasa Tsuruoka??
and Kentaro Torisawa?
?Language Infrastructure Group, MASTAR Project, NICT{chenwl, kazama, torisawa}@nict.go.jp?School of Information Science, JAISTtsuruoka@jaist.ac.jpAbstractThis paper proposes an approach to im-prove graph-based dependency parsing byusing decision history.
We introduce amechanism that considers short dependen-cies computed in the earlier stages of pars-ing to improve the accuracy of long de-pendencies in the later stages.
This re-lies on the fact that short dependencies aregenerally more accurate than long depen-dencies in graph-based models and maybe used as features to help parse long de-pendencies.
The mechanism can easilybe implemented by modifying a graph-based parsing model and introducing a setof new features.
The experimental resultsshow that our system achieves state-of-the-art accuracy on the standard PTB testset for English and the standard Penn Chi-nese Treebank (CTB) test set for Chinese.1 IntroductionDependency parsing is an approach to syntacticanalysis inspired by dependency grammar.
In re-cent years, interest in this approach has surged dueto its usefulness in such applications as machinetranslation (Nakazawa et al, 2006), informationextraction (Culotta and Sorensen, 2004).Graph-based parsing models (McDonald andPereira, 2006; Carreras, 2007) have achievedstate-of-the-art accuracy for a wide range of lan-guages as shown in recent CoNLL shared tasks(Buchholz et al, 2006; Nivre et al, 2007).
How-ever, to make parsing tractable, these models areforced to restrict features over a very limited his-tory of parsing decisions (McDonald and Pereira,2006; McDonald and Nivre, 2007).
Previouswork showed that rich features over a wide rangeof decision history can lead to significant im-provements in accuracy for transition-based mod-els (Yamada and Matsumoto, 2003a; Nivre et al,2004).In this paper, we propose an approach to im-prove graph-based dependency parsing by usingdecision history.
Here, we make an assumption:the dependency relations between words with ashort distance are more reliable than ones betweenwords with a long distance.
This is supported bythe fact that the accuracy of short dependenciesis in general greater than that of long dependen-cies as reported in McDonald and Nivre (2007)for graph-based models.
Our idea is to use deci-sion history, which is made in previous scans in abottom-up procedure, to help parse other words inlater scans.
In the bottom-up procedure, short de-pendencies are parsed earlier than long dependen-cies.
Thus, we introduce a mechanism in whichwe treat short dependencies built earlier as deci-sion history to help parse long dependencies inlater stages.
It can easily be implemented by mod-ifying a graph-based parsing model and designinga set of features for the decision history.To demonstrate the effectiveness of the pro-posed approach, we present experimental resultson English and Chinese data.
The results indi-cate that the approach greatly improves the accu-racy and that richer history-based features indeedmake large contributions.
The experimental re-sults show that our system achieves state-of-the-art accuracy on the data.2 MotivationIn this section, we present an example to showthe idea of using decision history in a dependencyparsing procedure.Suppose we have two sentences in Chinese, asshown in Figures 1 and 2, where the correct de-pendencies are represented by the directed links.For example, in Figure 1 the directed link from126w3:?
(bought) to w5:?
(books) mean that w3 isthe head and w5 is the dependent.
In Chinese,the relationship between clauses is often not madeexplicit and two clauses may simply be put to-gether with only a comma (Li and Thompson,1997).
This makes it hard to parse Chinese sen-tences with several clauses.ROOT??
?
?
?
?
???
?
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1         w2   w3         w4      w5      w6     w7        w8    w9     w10      w11      w12(Last year I bought some books and this year he also bought some books.
)Figure 1: Example AROOT??
?
?
?
?
???
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (also) (bought) (NULL) (books) w1         w2   w3        w4        w5      w6     w7     w8        w9       w10        w11(Last year I bought some books and this year too)Figure 2: Example BIf we employ a graph-based parsing model,such as the model of (McDonald and Pereira,2006; Carreras, 2007), it is difficult to assign therelations between w3 and w10 in Example A andbetween w3 and w9 in Example B.
For simplicity,we use wAi to refer to wi of Example A and wBi torefer to wi of Example B in what follows.The key point is whether the second clauses areindependent in the sentences.
The two sentencesare similar except that the second clause of Exam-ple A is an independent clause but that of Exam-ple B is not.
wA10 is the root of the second clauseof Example A with subject wA8 , while wB9 is theroot of the second clause of Example B, but theclause does not have a subject.
These mean thatthe correct decisions are to assign wA10 as the headof wA3 and wB3 as the head of wB9 , as shown by thedash-dot-lines in Figures 1 and 2.However, the model can use very limited infor-mation.
Figures 3-(a) and 4-(a) show the rightdependency relation cases and Figures 3-(b) and4-(b) show the left direction cases.
For the rightdirection case of Example A, the model has theinformation about wA3 ?s rightmost child wA5 andwA10?s leftmost child wA6 inside wA3 and wA10, but itdoes not have information about the other children??
?
?
?
?
?
??
?
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1         w2   w3        w4        w5      w6     w7     w8    w9     w10        w11      w12(a)??
?
?
?
?
?
??
?
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books)(b)w1         w2   w3        w4        w5      w6     w7     w8    w9     w10        w11      w12Figure 3: Example A: two directions??
?
?
?
?
???
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (also) (bought) (NULL) (books) w1         w2   w3         w4    w5      w6  w7        w8     w9         w10        w11      (a)??
?
?
?
?
???
?
?
?
?
(last year) (I) (bought) (NULL) (books) ( ) (this year) (also) (bought) (NULL) (books)(b),w1         w2   w3         w4    w5      w6  w7        w8     w9         w10        w11Figure 4: Example B: two directions(such as wA8 ) of wA3 and wA10, which may be usefulfor judging the relation between wA3 and wA10.
Theparsing model can not find the difference betweenthe syntactic structures of two sentences for pairs(wA3 ,wA10) and (wB3 ,wB9 ).
If we can provide the in-formation about the other children of wA3 and wA10to the model, it becomes easier to find the correctdirection between wA3 and wA10.Next, we show how to use decision history tohelp parse wA3 and wA10 of Example A.In a bottom up procedure, the relations betweenthe words inside [wA3 , wA10] are built as followsbefore the decision for wA3 and wA10.
In the firstround, we build relations for neighboring words(word distance1=1), such as the relations betweenwA3 and wA4 and between wA4 and wA5 .
In the sec-ond round, we build relations for words of dis-tance 2, and then for longer distance words untilall the possible relations between the inside wordsare built.
Figure 5 shows all the possible relationsinside [wA3 , wA10] that we can build.
To simplify,we use undirected links to refer to both directions1Word distance between wi and wj is |j ?
i|.127of dependency relations between words in the fig-ure.??
?
?
?
?
?
??
?
?
?
?
?
(last year) (I) (bought) (NULL) (books)   (,) (this year) (he) (also) (bought) (NULL) (books) w1         w2   w3         w4 w5        w6  w7        w8   w9     w10     w11      w12Figure 5: Example A: first stepThen given those inside relations, we choosethe inside structure with the highest score for eachdirection of the dependency relation between wA3and wA10.
Figure 6 shows the chosen structures.Note that the chosen structures for two directionscould either be identical or different.
In Figure6-(a) and -(b), they are different.??
?
?
?
?
?
??
?
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12(a)(b)??
?
?
?
?
?
??
?
?
?
?
?
(last year) (I) (bought) (NULL) (books) (,) (this year) (he) (also) (bought) (NULL) (books) w1         w2   w3        w4        w5      w6     w7     w8    w9     w10        w11      w12Figure 6: Example A: second stepFinally, we use the chosen structures as deci-sion history to help parse wA3 and wA10.
For ex-ample, the fact that wA8 is a dependent of wA10 isa clue that suggests that the second clause may beindependent.
This results in wA10 being the head ofwA3 .This simple example shows how to use the de-cision history to help parse the long distance de-pendencies.3 Background: graph-based parsingmodelsBefore we describe our method, we briefly intro-duce the graph-based parsing models.
We denoteinput sentence w by w = (w0, w1, ..., wn), wherew0 = ROOT is an artificial root token inserted atthe beginning of the sentence and does not dependon any other token in w and wi refers to a word.We employ the second-order projective graph-based parsing model of Carreras (2007), which isan extension of the projective parsing algorithm ofEisner (1996).The parsing algorithms used in Carreras (2007)independently find the left and right dependents ofa word and then combine them later in a bottom-up style based on Eisner (1996).
A subtree thatspans the words in [s, t] (and roots at s or t) isrepresented by chart item [s, t, right/left, C/I],where right (left) indicates that the root of the sub-tree is s (t) and C means that the item is completewhile I means that the item is incomplete (Mc-Donald, 2006).
Here, complete item in the right(left) direction means that the words other than s(t) cannot have dependents outside [s, t] and in-complete item in the right (left) direction, on theother hand, means that t (s) may have dependentsoutside [s, t].
In addition, t (s) is the direct depen-dent of s (t) in the incomplete item with the right(left) direction.Larger chart items are created from pairs ofsmaller chart items by the bottom-up procedure.Figure 7 illustrates the cubic parsing actions of theEisner?s parsing algorithm (Eisner, 1996) in theright direction, where s, r, and t refer to the startand end indices of the chart items.
In Figure 7-(a), all the items on the left side are complete andrepresented by triangles, where the triangle of [s,r] is complete item [s, r,?, C] and the triangle of[r + 1, t] is complete item [r + 1, t,?, C].
Thenthe algorithm creates incomplete item [s, t,?, I](trapezoid on the right side of Figure 7-(a)) bycombining the chart items on the left side.
Thisaction builds the dependency from s to t. In Fig-ure 7-(b), the item of [s, r] is incomplete andthe item of [r, t] is complete.
Then the algo-rithm creates complete item [s, t,?, C].
For theleft direction case, the actions are similar.
Notethat only the actions of creating the incompletechart items build new dependency relations be-tween words, while the ones of creating the com-plete items merge the existing structures withoutbuilding new relations.Once the parser has considered the dependencyrelations between words of distance 1, it goes on128to dependency relations between words of dis-tance 2, and so on by the parsing actions.
Forwords of distance 2 and greater, it considers ev-ery possible partition of the structures into twoparts and chooses the one with the highest scorefor each direction.
The score is the sum of the fea-ture weights of the chart items.
The features aredesigned over edges of dependency trees and theweights are given by model parameters (McDon-ald and Pereira, 2006; Carreras, 2007).
We storethe obtained chart items in a table.
The chart itemincludes the information on the optimal splittingpoint of itself.
Thus, by looking up the table, wecan obtain the best tree structure (with the highestscore) of any chart item.s         r     r+1    t            s                   t(a)s         r     r t               s                 t(b)Figure 7: Cubic parsing actions of Eisner (1996)4 Parsing with decision historyAs mentioned above, the actions for creatingthe incomplete items build the relations betweenwords.
In this study, we only consider using his-tory information when creating incomplete items.4.1 Decision historySuppose we are going to compute the scores ofthe relations between ws and wt.
There are twopossible directions for them.By using the bottom-up style algorithm, thescores of the structures between words with dis-tance < |s?t| are computed in previous scans andthe structures are stored in the table.
We dividethe decision history into two types: history-insideand history-outside.
The history-inside type is thedecision history made inside [s,t] and the history-outside type is the history made outside [s,t].4.1.1 History-insideWe obtain the structure with the highest scorefor each direction of the dependency between wsand wt.
Figure 8-(b) shows the best solution (withthe highest score) of the left direction, where thestructure is split into two parts, [s, r1,?, C] and[r1 + 1, t,?, C].
Figure 8-(c) shows the best so-lution of the right case, where the structure is splitinto two parts, [s, r2,?, C] and [r2 + 1, t,?, C].s          r1 r1+1               tws ?
wt (b)(a)s r r +1 t2 2(c)Figure 8: History-insideBy looking up the table, we have a subtree thatroots at ws on the right side of ws and a subtreethat roots at wt on the left side of wt.
We use thesestructures as the information on history-inside.4.1.2 History-outsideFor history-outside, we try to obtain the sub-tree that roots at ws on the left side of ws andthe one that roots at wt on the right side of wt.However, compared to history-inside, obtaininghistory-outside is more complicated because wedo not know the boundaries and the proper struc-tures of the subtrees.
Here, we use an simpleheuristic method to find a subtree whose root isat ws on the left side of ws and one whose root isat wt on the right side of wt.We introduce two assumptions: 1) The struc-ture within a sub-sentence 2 is more reliable thanthe one that goes across from sub-sentences.
2)More context (more words) can result in a bettersolution for determining subtree structures.2To simplify, we split one sentence into sub-sentenceswith punctuation marks.129Algorithm 1 Searching for history-outsideboundaries1: Input: w, s, t2: for k = s?
1 to 1 do3: if(isPunct(wk)) break;4: if(s?
k >= t?
s?
1) break5: end for6: bs = k7: for k = t + 1 to |w| do8: if(isPunct(wk)) break;9: if(k ?
t >= t?
s?
1) break10: end for11: bt = k12: Output: bs, btUnder these two assumptions, Algorithm 1shows the procedure for searching for history-outside boundaries, where bs is the boundary forfor the descendants on the left side of ws , btis the boundary for searching the descendants onthe right side of wt, and isPunct is the functionthat checks if the word is a punctuation mark.
bsshould be in the same sub-sentence with s and|s?
bs| should be less than |t?
s|.
bt should be inthe same sub-sentence with t and |bt ?
t| shouldbe less than |t?
s|.Next we try to find the subtree structures.
First,we collect the part-of-speech (POS) tags of theheads of all the POS tags in training data andremove the tags that occur fewer than 10 times.Then, we determine the directions of the relationsby looking up the collected list.
For bs and s, wecheck if the POS tag of ws could be the head tagof the POS tag of wbs by looking up the list.
Ifso, the direction d is ?.
Otherwise, we check ifthe POS tag of wbs could be the head tag of thePOS tag of ws.
If so, d is ?, else d is ?.
Fi-nally, we obtain the subtree of ws from chart item[bs, s, d, I].
Similarly, we obtain the subtree of wt.Figure 9 shows the history-outside information forws and wt, where the relation between wbs and wsand the relation between wbt and wt will be de-termined by the above method.
We have subtree[rs, s, left, C] that roots at ws on the left side ofws and subtree [t, rt, right, C] that roots at wt onthe right side of wt in Figure 9-(b) and (c).4.2 Parsing algorithmThen, we explain how to use these decision his-tory in the parsing algorithm.
We use Lst to rep-bs rs s        t         rt bt(b)ws ?
wt(a)b r s t r b(c)s s t tFigure 9: History-outsideresent the scores of basic features for the left di-rection and Rst for the right case.
Then we designhistory-based features (described in Section 4.3)based on the history-inside and history-outside in-formation, as mentioned above.
Finally, we up-date the scores with the ones of the history-basedfeatures by the following equations:L+st = Lst + Ldfst (1)R+st = Rst + Rdfst (2)where L+st and R+st refer to the updated scores, Ldfstand Rdfst refer to the scores of the history-basedfeatures.Algorithm 2 Parsing algorithm1: Initialization: V [s, s, dir, I/C] = 0.0 ?s, dir2: for k = 1 to n do3: for s = 0 to n?
k do4: t = s + k5: % Create incomplete items6: Lst=V [s, t,?, I]= maxs?r<tV I(r);7: Rst=V [s, t,?, I]= maxs?r<tV I(r);8: Calculate Ldfst and Rdfst ;9: % Update the scores of incomplete chart items10: V [s, t,?, I]=L+st=Lst + Ldfst11: V [s, t,?, I]=R+st=Rst + Rdfst12: % Create complete items13: V [s, t,?, C]= maxs?r<tV C(r);14: V [s, t,?, C]= maxs<r?tV C(r);15: end for16: end forAlgorithm 2 is the parsing algorithm withthe history-based features, where V [s, t, dir, I/C]refers to the score of chart item [s, t, dir, I/C],V I(r) is a function to search for the optimalsibling and grandchild nodes for the incompleteitems (line 6 and 7) (Carreras, 2007) given the130splitting point r and return the score of the struc-ture, and V C(r) is a function to search for the op-timal grandchild node for the complete items (line13 and 14).
Compared with the parsing algorithmsof Carreras (2007), Algorithm 2 uses history in-formation by adding line 8, 10, and 11.In Algorithm 2, it first creates chart items withdistance 1, then goes on to chart items with dis-tance 2, and so on.
In each round, it searches forthe structures with the highest scores for incom-plete items shown at line 6 and 7 of Algorithm 2.Then we update the scores with the history-basedfeatures by Equation 1 and Equation 2 at line 10and 11 of Algorithm 2.
However, note that we cannot guarantee to find the candidate with the high-est score with Algorithm 2 because new featuresviolate the assumptions of dynamic programming.4.3 History-based featuresIn this section, we design features that capture thehistory information in the recorded decisions.For a dependency between two words, say s andt, there are four subtrees that root at s or t. We de-sign the features by combining s, twith each childof s and t in the subtrees.
The feature templatesare shown as follows: (In the following, c meansone of the children of s and t, and the nodes in thetemplates are expanded to their lexical form andPOS tags to obtain actual features.
):C+Dir this feature template is a 2-tuple con-sisting of (1) a c node and (2) the direction of thedependency.C+Dir+S/C+Dir+T this feature template is a 3-tuple consisting of (1) a c node, (2) the directionof the dependency, and (3) a s or t node.C+Dir+S+T this feature template is a 4-tupleconsisting of (1) a c node, (2) the direction of thedependency, (3) a s node, and (4) a t node.s     csi r1 r1+1 cti tr2 cso cto r3Figure 10: Structure of decision historyWe use SHI to represent the subtree of s inthe history-inside, THI to represent the one of tin the history-inside, SHO to represent the oneof s in the history-outside, and THO to representthe one of t in the history-outside.
Based on thesubtree types, the features are divided into foursets: FSHI , FTHI , FSHO, and FTHO refer to thefeatures related to the children that are in subtreesSHI , THI , SHO, and THO respectively.Figure 10 shows the structure of decision his-tory of a left dependency (between s and t) re-lation.
For the right case, the structure is simi-lar.
In the figure, SHI is chart item [s, r1,?, C],THI is chart item [r1 + 1, t,?, C], SHO ischart item [r2, s,?, C], and THO is chart item[t, r3,?, C].
We use csi, cti, cso, and cto to repre-sent a child of s/t in subtrees SHI , THI , SHO,and THO respectively.
The lexical form featuresof FSHI and FSHO are listed as examples in Table1, where ?L?
refers to the left direction.
We canalso expand the nodes in the templates to the POStags.
Compared with the algorithm of Carreras(2007) that only considers the furthest children ofs and t, Algorithm 2 considers all the children.Table 1: Lexical form features of FSHI and FSHOtemplate FSHI FSHOC+DIR word-csi+L word-cso+LC+DIR+S word-csi+L+word-s word-cso+L+word-sC+DIR+T word-csi+L+word-t word-cso+L+word-tC+DIR word-csi+L word-cso+L+S+T +word-s+word-t +word-s+word-t4.4 Policy of using historyIn practice, we define several policies to use thehistory information for different word pairs as fol-lows:?
All: Use the history-based features for all theword pairs without any restriction.?
Sub-sentences: use the history-based fea-tures only for the relation of two words fromsub-sentences.
Here, we use punctuationmarks to split sentences into sub-sentences.?
Distance: use the history-based features forthe relation of two words within a predefineddistance.
We set the thresholds to 3, 5, and10.1315 Experimental resultsIn order to evaluate the effectiveness of thehistory-based features, we conducted experimentson Chinese and English data.For English, we used the Penn Treebank (Mar-cus et al, 1993) in our experiments and the tool?Penn2Malt?3 to convert the data into dependencystructures using a standard set of head rules (Ya-mada and Matsumoto, 2003a).
To match previouswork (McDonald and Pereira, 2006; Koo et al,2008), we split the data into a training set (sec-tions 2-21), a development set (Section 22), and atest set (section 23).
Following the work of Kooet al (2008), we used the MXPOST (Ratnaparkhi,1996) tagger trained on training data to providepart-of-speech tags for the development and thetest set, and we used 10-way jackknifing to gener-ate tags for the training set.For Chinese, we used the Chinese Treebank(CTB) version 4.04 in the experiments.
We alsoused the ?Penn2Malt?
tool to convert the data andcreated a data split: files 1-270 and files 400-931for training, files 271-300 for testing, and files301-325 for development.
We used gold stan-dard segmentation and part-of-speech tags in theCTB.
The data partition and part-of-speech set-tings were chosen to match previous work (Chenet al, 2008; Yu et al, 2008).We measured the parser quality by the unla-beled attachment score (UAS), i.e., the percentageof tokens with the correct HEAD 5.
And we alsoevaluated on complete dependency analysis.In our experiments, we implemented our sys-tems on the MSTParser6 and extended withthe parent-child-grandchild structures (McDonaldand Pereira, 2006; Carreras, 2007).
For the base-line systems, we used the first- and second-order(parent-sibling) features that were used in Mc-Donald and Pereira (2006) and other second-orderfeatures (parent-child-grandchild) that were usedin Carreras (2007).
In the following sections, wecall the second-order baseline systems Baseline3http://w3.msi.vxu.se/?nivre/research/Penn2Malt.html4http://www.cis.upenn.edu/?chinese/.5As in previous work, English evaluation ignores any to-ken whose gold-standard POS tag is one of {??
`` : , .}
andChinese evaluation ignores any token whose tag is ?PU?.6http://mstparser.sourceforge.netand our new systems OURS.5.1 Results with different feature settingsIn this section, we test our systems with differentsettings on the development data.Table 2: Results with different policiesChinese EnglishBaseline 89.04 92.43D1 88.73 92.27D3 88.90 92.36D5 89.10 92.59D10 89.32 92.57Dsub 89.57 92.63Table 2 shows the parsing results when we useddifferent policies defined in Section 4.4 with allthe types of features, where Dsub refers to apply-ing the policy: sub-sentence, D1 refers to apply-ing the policy: all, and D3|5|10 refers to applyingthe policy: distance with the predefined distance3, 5, or 10.
The results indicated that the accu-racies of our systems decreased if we used thehistory information for short distance words.
Thesystem with Dsub performed the best.Table 3: Results with different types of FeaturesChinese EnglishBaseline 89.04 92.43+FSHI 89.14 92.53+FTHI 89.33 92.35+FSHO 89.25 92.47+FTHO 88.99 92.54Then we investigated the effect of differenttypes of the history-based features.
Table 3 showsthe results with policy Dsub.
From the table, wefound that FTHI provided the largest improve-ment for Chinese and FTHO performed the bestfor English.In what follows, we used Dsub as the policy forall the languages, the features FSHI + FTHI +FSHO for Chinese, and the features FSHI +FSHO + FTHO for English.5.2 Main resultsThe main results are shown in the upper parts ofTables 4 and 5, where the improvements by OURSover the Baselines are shown in parentheses.
Theresults show that OURS provided better perfor-mance over the Baselines by 1.02 points for Chi-132Table 4: Results for ChineseUAS CompleteBaseline 88.41 48.85OURS 89.43(+1.02) 50.86OURS+STACK 89.53 49.42Zhao2009 87.0 ?Yu2008 87.26 ?STACK 88.95 49.42Chen2009 89.91 48.56nese and 0.29 points for English.
The improve-ments of (OURS) were significant in McNemar?sTest with p < 10?4 for Chinese and p < 10?3 forEnglish.5.3 Comparative resultsTable 4 shows the comparative results for Chinese,where Zhao2009 refers to the result of (Zhao etal., 2009), Yu2008 refers to the result of Yu etal.
(2008), Chen2009 refers to the result of Chenet al (2009) that is the best reported result onthis data, and STACK refers to our implementa-tion of the combination parser of Nivre and Mc-Donald (2008) using our baseline system and theMALTParser7.
The results indicated that OURSperformed better than Zhao2009, Yu2008, andSTACK, but worse than Chen2009 that used large-scale unlabeled data (Chen et al, 2009).
We alsoimplemented the combination system of OURSand the MALTParser, referred as OURS+STACKin Table 4.
The new system achieved further im-provement.
In future work, we can combine ourapproach with the parser of Chen et al (2009).Table 5 shows the comparative results for En-glish, where Y&M2003 refers to the parser of Ya-mada and Matsumoto (2003b), CO2006 refers tothe parser of Corston-Oliver et al (2006), Z&C2008 refers to the combination system of Zhangand Clark (2008), STACK refers to our implemen-tation of the combination parser of Nivre and Mc-Donald (2008), KOO2008 refers to the parser ofKoo et al (2008), Chen2009 refers to the parserof Chen et al (2009), and Suzuki2009 refers tothe parser of Suzuki et al (2009) that is the bestreported result for this data.
The results showsthat OURS outperformed the first two systems thatwere based on single models.
Z&C 2008 andSTACK were the combination systems of graph-7http://www.maltparser.org/Table 5: Results for EnglishUAS CompleteBaseline 91.92 44.28OURS 92.21 (+0.29) 45.24Y&M2003 90.3 38.4CO2006 90.8 37.6Z&C2008 92.1 45.4STACK 92.53 47.06KOO2008 93.16 ?Chen2009 93.16 47.15Suzuki2009 93.79 ?based and transition-based models.
OURS per-formed better than Z&C 2008, but worse thanSTACK.
The last three systems that used large-scale unlabeled data performed better than OURS.6 Related workThere are several studies that tried to overcomethe limited feature scope of graph-based depen-dency parsing models .Nakagawa (2007) proposed a method to dealwith the intractable inference problem in a graph-based model by introducing the Gibbs samplingalgorithm.
Compared with their approach, our ap-proach is much simpler yet effective.
Hall (2007)used a re-ranking scheme to provide global fea-tures while we simply augment the features of anexisting parser.Nivre and McDonald (2008) and Zhang andClark (2008) proposed stacking methods to com-bine graph-based parsers with transition-basedparsers.
One parser uses dependency predictionsmade by another parser.
Our results show that ourapproach can be used in the stacking frameworksto achieve higher accuracy.7 ConclusionsThis paper proposes an approach for improvinggraph-based dependency parsing by using the de-cision history.
For the graph-based model, wedesign a set of features over short dependen-cies computed in the earlier stages to improvethe accuracy of long dependencies in the laterstages.
The results demonstrate that our proposedapproach outperforms baseline systems by 1.02points for Chinese and 0.29 points for English.133ReferencesBuchholz, S., E. Marsi, A. Dubey, and Y. Kry-molowski.
2006.
CoNLL-X shared task onmultilingual dependency parsing.
Proceedings ofCoNLL-X.Carreras, X.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings ofthe CoNLL Shared Task Session of EMNLP-CoNLL2007, pages 957?961.Chen, WL., D. Kawahara, K. Uchimoto, YJ.
Zhang,and H. Isahara.
2008.
Dependency parsing withshort dependency relations in unlabeled data.
InProceedings of IJCNLP 2008.Chen, WL., J. Kazama, K. Uchimoto, and K. Torisawa.2009.
Improving dependency parsing with subtreesfrom auto-parsed data.
In Proceedings of EMNLP2009, pages 570?579, Singapore, August.Corston-Oliver, S., A. Aue, Kevin.
Duh, and Eric Ring-ger.
2006.
Multilingual dependency parsing usingbayes point machines.
In HLT-NAACL2006.Culotta, A. and J. Sorensen.
2004.
Dependency treekernels for relation extraction.
In Proceedings ofACL 2004, pages 423?429.Eisner, J.
1996.
Three new probabilistic models fordependency parsing: An exploration.
In Proc.
ofCOLING 1996, pages 340?345.Hall, Keith.
2007.
K-best spanning tree parsing.
InProc.
of ACL 2007, pages 392?399, Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Koo, T., X. Carreras, and M. Collins.
2008.
Simplesemi-supervised dependency parsing.
In Proceed-ings of ACL-08: HLT, Columbus, Ohio, June.Li, Charles N. and Sandra A. Thompson.
1997.
Man-darin Chinese - A Functional Reference Grammar.University of California Press.Marcus, M., B. Santorini, and M. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: the Penn Treebank.
Computational Linguis-ticss, 19(2):313?330.McDonald, R. and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.In Proceedings of EMNLP-CoNLL, pages 122?131.McDonald, R. and F. Pereira.
2006.
Online learningof approximate dependency parsing algorithms.
InProc.
of EACL2006.McDonald, Ryan.
2006.
Discriminative Training andSpanning Tree Algorithms for Dependency Parsing.Ph.D.
thesis, University of Pennsylvania.Nakagawa, Tetsuji.
2007.
Multilingual dependencyparsing using global features.
In Proceedings ofthe CoNLL Shared Task Session of EMNLP-CoNLL2007, pages 952?956.Nakazawa, T., K. Yu, D. Kawahara, and S. Kurohashi.2006.
Example-based machine translation based ondeeper NLP.
In Proceedings of IWSLT 2006, pages64?70, Kyoto, Japan.Nivre, J. and R. McDonald.
2008.
Integrating graph-based and transition-based dependency parsers.
InProceedings of ACL-08: HLT, Columbus, Ohio,June.Nivre, J., J.
Hall, and J. Nilsson.
2004.
Memory-based dependency parsing.
In Proc.
of CoNLL2004, pages 49?56.Nivre, J., J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL 2007shared task on dependency parsing.
In Proceed-ings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915?932.Ratnaparkhi, A.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proceedings of EMNLP,pages 133?142.Suzuki, Jun, Hideki Isozaki, Xavier Carreras, andMichael Collins.
2009.
An empirical study of semi-supervised structured conditional models for depen-dency parsing.
In Proc.
of EMNLP 2009, pages551?560, Singapore, August.
Association for Com-putational Linguistics.Yamada, H. and Y. Matsumoto.
2003a.
Statistical de-pendency analysis with support vector machines.
InProceedings of IWPT2003, pages 195?206.Yamada, H. and Y. Matsumoto.
2003b.
Statistical de-pendency analysis with support vector machines.
InProceedings of IWPT2003, pages 195?206.Yu, K., D. Kawahara, and S. Kurohashi.
2008.
Chi-nese dependency parsing with large scale automati-cally constructed case structures.
In Proceedings ofColing 2008, pages 1049?1056, Manchester, UK,August.Zhang, Y. and S. Clark.
2008.
A tale of twoparsers: Investigating and combining graph-basedand transition-based dependency parsing.
In Pro-ceedings of EMNLP 2008, pages 562?571, Hon-olulu, Hawaii, October.Zhao, Hai, Yan Song, Chunyu Kit, and GuodongZhou.
2009.
Cross language dependency parsingusing a bilingual lexicon.
In Proceedings of ACL-IJCNLP2009, pages 55?63, Suntec, Singapore, Au-gust.
Association for Computational Linguistics.134
