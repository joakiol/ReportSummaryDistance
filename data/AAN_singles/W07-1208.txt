Proceedings of the 5th Workshop on Important Unresolved Matters, pages 57?64,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsSelf- or Pre-Tuning?Deep linguistic processing of language variantsAnto?nio BrancoUniversidade de LisboaAntonio.Branco@di.fc.ul.ptFrancisco CostaUniversidade de Lisboafcosta@di.fc.ul.ptAbstractThis paper proposes a design strategyfor deep language processing grammarsto appropriately handle language vari-ants.
It allows a grammar to be re-stricted as to what language variant it istuned to, but also to detect the varianta given input pertains to.
This is eval-uated and compared to results obtainedwith an alternative strategy by which therelevant variant is detected with currentlanguage identification methods in a pre-processing step.1 IntroductionThis paper addresses the issue of handling dif-ferent variants of a given language by a deeplanguage processing grammar for that language.In the benefit of generalization and grammarwriting economy, it is desirable that a grammarcan handle language variants ?
that share mostgrammatical structures and lexicon ?
in order toavoid endless multiplication of individual gram-mars, motivated by inessential differences.From the viewpoint of analysis, however, in-creased variant coverage typically opens the wayto increased spurious overgeneration.
Conse-quently, the ability for the grammar to be tunedto the relevant dialect of the input is impor-tant to control overgeneration arising from itsflexibility.Control on what is generated is also desirable.In general one wants to be able to parse as muchvariants as possible, but at the same time be se-lective in generation, by consistently generatingonly in a given selected variant.Closely related to the setting issue (addressedin the next Section 2) is the tuning issue: if asystem can be restricted to a particular variety,what is the best way to detect the variety of theinput?
We discuss two approaches to this issue.One of them consists in using pre-processingcomponents that can detect the language varietyat stake.
This pre-tuning approach explores thehypothesis that methods developed for languageidentification can be used also to detect languagevariants (Section 5).The other approach is to have the computa-tional grammar prepared for self-tuning to thelanguage variant of the input in the course ofprocessing that input (Section 4).We evaluate the two approaches and comparethem (last Section 6).2 Variant-sensitive GrammarIn this Section, we discuss the design options fora deep linguistic processing grammar allowingfor its appropriate tuning to different languagevariants.
For the sake of concreteness of the dis-cussion, we assume the HPSG framework (Pol-lard and Sag, 1994) and a grammar that handlestwo close variants of the same language, Euro-pean and Brazilian Portuguese.
These assump-tions are merely instrumental, and the resultsobtained can be easily extended to other lan-guages and variants, and to other grammaticalframeworks for deep linguistic processing.A stretch of text from a language L can dis-play grammatical features common to all vari-ants of L, or contain a construction that per-tains to some or only one of its variants.
Hence,undesirable overgeneration due to the grammarreadiness to cope with all language variants can57ep-variantvariantsingle-variant bp-varianteuropean-portuguese portuguese brazilian-portugueseFigure 1: Type hierarchy under variant.be put in check by restricting the grammarto produce variant-?consistent?
analyses.
Moreprecisely, if the input string contains an elementthat can only be found in variety v1and that in-put string yields ambiguity in a different stretchbut only in varieties vkother than v1, this ambi-guity will not give rise to multiple analyses if thegrammar can be designed so that it can be con-strained to accept strings with marked elementsof at most one variety, v1.The approach we propose seeks to implementthis mode of operation in analysis, with the im-portant effect of permitting also to control thevariant under which generation should be per-formed.
It relies on the use of a feature VARIANTto model variation.
This feature is appropriatefor all signs and declared to be of type variant.Given the working language variants assumedhere, its values are presented in Figure 1.This attribute is constrained to take the ap-propriate value in lexical items and construc-tions specific to one of the two varieties.
Forexample, a hypothetical lexical entry for the lex-ical item autocarro (bus, exclusive to EuropeanPortuguese) would include the constraint thatthe attribute VARIANT has the value ep-variantand the corresponding Brazilian Portuguese en-try for o?nibus would constrain the same featureto bear the value bp-variant.
The only two typesthat are used to mark signs are ep-variant andbp-variant.
The remaining types presented inFigure 1 are used to constrain grammar behav-ior, as explained below.Lexical items are not the only elements thatcan have marked values in the VARIANT fea-ture.
Lexical and syntax rules can have them,too.
Such constraints model constructions thatmarkedly pertain to one of the dialects.Feature VARIANT is structure-shared amongall signs comprised in a full parse tree.
Thisis achieved by having all lexical or syntacticrules unifying their VARIANT feature with theVARIANT feature of their daughters.If two signs (e.g.
from lexical items and syn-tax rules) in the same parse tree have differentvalues for feature VARIANT (one has ep-variantand the other bp-variant), they will unify to por-tuguese, as can be seen from Figure 1.
This typemeans that lexical items or constructions spe-cific to two different varieties are used together.Furthermore, since this feature is shared amongall signs, it will be visible everywhere, for in-stance in the root node.It is possible to constrain feature VARIANT inthe root condition of the grammar so that thegrammar works in a variant-?consistent?
fash-ion: this feature just has to be constrained tobe of type single-variant (in root nodes) andthe grammar will accept either European Por-tuguese or Brazilian Portuguese.
Furthermore,in the non natural condition where the inputstring bears marked properties of both vari-ants, that string will receive no analysis: featureVARIANT will have the value portuguese in thiscase, and there is no unifier for portuguese andsingle-variant.If this feature is constrained to be of typeeuropean-portuguese in the root node, the gram-mar will not accept any sentence with fea-tures of Brazilian Portuguese, since they will bemarked to have a VARIANT of type bp-variant,which is incompatible with european-portuguese.It is also possible to have the grammar re-ject European Portuguese (using type brazilian-portuguese) or to ignore variation completely bynot constraining this feature in the start symbol.With this grammar design it is thus possi-ble to control beforehand the mode of operationfor the grammar, either for it to handle onlyone variant or several.
But it is also possibleto use the grammar to detect to which varietyinput happens to belong.
This self-tuning ofthe grammar to the relevant variant is done byparsing that input and placing no constraint onfeature VARIANT of root nodes, and then read-ing the value of attribute VARIANT from the re-sulting feature structure: values ep-variant andbp-variant result from parsing text with proper-ties specific to European Portuguese or BrazilianPortuguese respectively; value variant indicatesthat no marked elements were detected and thetext can be from both variants.
Also here wherethe language variant of the input is detected bythe grammar, the desired variant-?consistent?58behavior of the grammar is enforced.If the input can be known to be specificallyEuropean or Brazilian Portuguese before it isparsed, the constraints on feature VARIANT canbe set accordingly to improve efficiency: Whenparsing text known to be European Portuguese,there is no need to explore analyses that aremarkedly Brazilian Portuguese, for instance.It is thus important to discuss what meth-ods for language variant detection can be putin place that support a possible pre-processingstep aimed at pre-tuning the grammar for therelevant variant of the input.
It is also impor-tant to gain insight on the quality of the per-formance of this method and on how the perfor-mance of this pre-tuning setup compares withthe self-tuning approach.
This is addressed inthe next Sections.3 Experimental setupBefore reporting on the results obtained with theexperiments on the performance of the two ap-proaches (self- and pre-tuning), it is importantto introduce the experimental conditions underwhich such exercises were conducted.3.1 DataTo experiment with any of these two approachesto variant-tuning, two corpora of newspaper textwere used, CETEMPublico (204M tokens) andCETENFolha (32M tokens).
The first containstext from the European newspaper O Pu?blico,and the latter from the South American Folhade Sa?o Paulo.
These corpora are only minimallyannotated (paragraph and sentence boundaries,inter alia), but are very large.Some preprocessing was carried out: XML-like tags, like the <s> and </s> tags markingsentence boundaries, were removed and each in-dividual sentence was put in a single line.Some heuristics were also employed to removeloose lines (parts of lists, etc.)
so that only linesending in ., !
and ?, and containing more than 5tokens (whitespace delimited) were considered.Other character sequences that were judged ir-relevant and potential misguiders for the pur-pose at hand were normalized: URLs were re-placed by the sequence URL, e-mail addressesby MAIL, hours and dates by HORA and DATA,etc.
Names at the beginning of lines indicatingspeaker (in an interview, for instance) were re-moved, since they are frequent and the grammarthat will be used is not intended to parse nameplus sentence strings.The remaining lines were ordered by length interms of words and the smallest 200K lines fromeach of the two corpora were selected.
Smalllines were preferred as they are more likely toreceive an analysis by the grammar.Given the methods we will be employing forpre-tuning reportedly perform well even withsmall training sets (Section 5), only a modestportion of text from these corpora was needed.In the benefit of comparability of the twoapproaches for grammar tuning, it is impor-tant that all the lines in the working data areparsable by the grammar.
Otherwise, even ifin the pre-tuning approach the pre-processorgets the classification right for non parsable sen-tences, this will be of no use since the grammarwill not produce any result out of that.
90K linesof text were thus randomly selected from eachcorpus and checked as to whether they could beparsed by the grammar.
25K of parsable lines ofthe American corpus and 21K of parsable linesof the European corpus were obtained (46K linesout of 180K, representing 26% rate of parsabil-ity for the grammar used ?
more details on thisgrammar in the next Section).It is worth noting that the use of two corpora,one from an European newspaper and the otherfrom an American newspaper, without furtherannotation, does not allow their appropriate usein the present set of experiments.
The reasonis that if a sentence is found in the Europeancorpus, one can have almost absolute certaintythat it is possible in European Portuguese, butone does not know if it is Brazilian Portuguese,too.
The same is true of any sentences in theAmerican corpus ?
it can also be a sentenceof European Portuguese in case it only containswords and structures common to both variants.In order to prepare the data, a native speakerof European Portuguese was asked to manuallydecide from sentences found in the Americancorpus whether they are markedly Brazilian Por-tuguese.
Conversely, a Brazilian informant de-tected markedly European Portuguese sentencesfrom the European corpus.From these parsed lines we drew around 1800random lines of text from each corpus, and hadthem annotated.
The lines coming from theAmerican corpus were annotated for whetherthey are markedly Brazilian Portuguese, and59vice-versa for the other corpus.
Thus a three-way classification is obtained: any sentencewas classified as being markedly Brazilian Por-tuguese, European Portuguese or common toboth variants.The large majority of the sentences werejudged to be possible in both European andBrazilian Portuguese.
16% of the sentences inthe European corpus were considered not be-longing to Brazilian Portuguese, and 21% of thesentences in the American corpus were judged asnot being European Portuguese.1 Overall, 81%of the text was common to both varieties.10KB of text from each one of the three classeswere obtained.
140 lines, approximately 5KB,were reserved for training and another 140 fortest.
In total, the 30 K corpus included 116, 170,493 and 41 sentence tokens for, respectively, 8,7, 6 and 5 word length sentence types.3.2 VariationThese training corpora were submitted to man-ual inspection in order to identify and quantifythe sources of variant specificity.
This is impor-tant to help interpret the experimental resultsand to gain insight on the current coverage ofthe grammar used in the experiment.This analysis was performed over the 140 linesselected as markedly Brazilian Portuguese, andassumed that the sources of variant specificityshould have broadly the same distribution inthe other 140K lines markedly European Por-tuguese.1.
Mere orthographic differences (24%) e.g.ac?a?o vs. acc?a?o (action)2.
Phonetic variants reflected in orthography(9.3%) e.g.
iro?nico vs. iro?nico (ironic)1A hypothetical explanation for this asymmetry (16%vs.
21%) is that one of the most pervasive differencesbetween European and Brazilian Portuguese, clitic place-ment, is attenuated in writing: Brazilian text often dis-plays word order between clitic and verb similar to Euro-pean Portuguese, and different from oral Brazilian Por-tuguese.
Therefore, European text displaying Europeanclitic order tends not be seen as markedly European.
Infact, we looked at the European sentences with cliticplacement characteristic of European Portuguese thatwere judged possible in Brazilian Portuguese.
If theywere included in the markedly European sentences, 23%of the European text would be unacceptable BrazilianPortuguese, a number closer to the 21% sentences judgedto be exclusively Brazilian Portuguese in the Americancorpus.3.
Lexical differences (26.9% of differences)(a) Different form, same meaning (22.5%)e.g.
time vs. equipa (team)(b) Same form, different meaning (4.4%)e.g.
policial (policeman/criminal novel4.
Syntactic differences (39.7%)(a) Possessives w/out articles (12.2%)(b) In subcategorization frames (9.8%)(c) Clitic placement (6.4%)(d) Singular bare NPs (5.4%)(e) In subcat and word sense (1.9%)(f) Universal todo + article (0.9%)(g) Contractions of Prep+article (0.9%)(h) Questions w/out SV inversion (0.9%)(i) Postverbal negation (0.5%)(j) other (0.5%)About 1/3 of the differences found would dis-appear if a unified orthography was adopted.Differences that are reflected in spelling can bemodeled via multiple lexical entries, with con-straints on feature VARIANT reflecting the vari-ety in which the item with that spelling is used.Interestingly, 40% of the differences are syn-tactic in nature.
These cases are expected tobe more difficult to detect with stochastic ap-proaches than with a grammar.4 Self-tuning4.1 Grammar and baselineThe experiments on the self-tuning approachwere carried out with a computational grammarfor Portuguese developed with the LKB plat-form (Copestake, 2002) that uses MRS for se-mantic representation (Copestake et al, 2001)(Branco and Costa, 2005).
At the time of theexperiments reported here, this grammar wasof modest size.
In terms of linguistic phenom-ena, it covered basic declarative sentential struc-tures and basic phrase structure of all cate-gories, with a fully detailed account of the struc-ture of NPs.
It contained 42 syntax rules, 37lexical rules (mostly inflectional) and a totalof 2988 types, with 417 types for lexical en-tries.
There were 2630 hand-built lexical entries,mostly nouns, with 1000 entries.
It was coupledwith a POS tagger for Portuguese, with 97% ac-curacy (Branco and Silva, 2004).60In terms of the sources of variant specificityidentified above, this grammar was specificallydesigned to handle the co-occurrence of prenom-inal possessives and determiners and most of thesyntactic constructions related to clitic-verb or-der.
As revealed by the study of the trainingcorpus, these constructions are responsible foralmost 20% of marked sentences.The lexicon contained lexical items markedlyEuropean Portuguese and markedly BrazilianPortuguese.
These were taken from the Por-tuguese Wiktionary, where this information isavailable.
Leaving aside the very infrequentitems, around 740 marked lexical items werecoded.
Items that are variant specific found inthe training corpora (80 more) were also enteredin the lexicon.These items, markedly belonging to one vari-ant, were declined into their inflected forms andthe resulting set Lexbslwas used in the followingbaseline for dialect tuning: for a sentence s andNep, resp.
Nbp, the number of tokens of itemsin Lexbslmarkedly European, resp.
BrazilianPortuguese, occurring in s, s is tagged as Euro-pean Portuguese if Nep> Nbp, or vice-versa, orelse, ?common?
Portuguese if Nep= Nbp= 0.Known Predicted classclass EP BP Common RecallEP 45 0 95 0.32BP 3 45 92 0.32Common 4 4 132 0.94Precision 0.87 0.98 0.41Table 1: Baseline: Confusion matrix.For this baseline, the figure of 0.53 of overallaccuracy was obtained, detailed in Table 1.24.2 Results with self-tuningThe results obtained for the self-tuning modeof operation are presented in Table 2.3 Whenthe grammar produced multiple analyses for a2Naturally, extending the operation of this baselinemethod beyond the terms of comparability with gram-mars that handle each sentence at a time, namely byincreasingly extending the number of sentences in thestretch of text being classified, will virtually lead it toreach optimal accuracy.3These figures concern the test corpus, with the threeconditions represented by 1/3 of the sentences, which areall parsable.
Hence, actual recall over a naturally occur-ring text is expected to be lower.
Using the estimate thatonly 26% of input receives a parse, that figure for recallwould lie somewhere around 0.15 (= 0.57 x 0.26).given sentence, that sentence was classified asmarkedly European, resp.
Brazilian, Portugueseif all the parses produced VARIANT with type ep-variant, resp.
bp-variant.
In all other cases, thesentence would be classified as common to bothvariants.Known Predicted classclass EP BP Common RecallEP 53 1 86 0.38BP 6 61 73 0.44Common 14 1 125 0.89Precision 0.73 0.97 0.44Table 2: Self-tuning: Confusion matrix.Every sentence in the test data was classified,and the figure of 0.57 was obtained for over-all accuracy.
The analysis of errors shows thatthe sentence belonging to Brazilian Portugueseor to ?common?
Portuguese wrongly classifiedas European Portuguese contain clitics follow-ing the European Portuguese syntax, and somemisspellings conforming to the European Por-tuguese orthography.5 Pre-tuning5.1 Language Detection MethodsMethods have been developed to detect the lan-guage a given text is written in.
They havealso been used to discriminate varieties of thesame language, although less often.
(Lins andGonc?alves, 2004) look up words in dictionariesto discriminate among languages, and (Oakes,2003) runs stochastic tests on token frequencies,like the chi-square test, in order to differentiatebetween European and American English.Many methods are based on frequency of byten-grams in text because they can simultaneouslydetect language and character encoding (Li andMomoi, 2001), and can reliably classify shortportions of text.
They have been applied in webbrowsers (to identify character encodings) andinformation retrieval systems.We are going to focus on methods based oncharacter n-grams.
Because all information usedfor classification is taken from characters, andthey can be found in text in much larger quanti-ties than words or phrases, problems of scarcityof data are attenuated.
Besides, training datacan also be easily found in large amounts be-cause corpora do not need to be annotated (it is61only necessary to know the language they belongto).
More importantly, methods based on char-acter n-grams can reliably classify small portionsof text.
The literature on automatic languageidentification mentions training corpora as smallas 2K producing classifiers that perform with al-most perfect accuracy for test strings as little as500 Bytes (Dunning, 1994) and considering sev-eral languages.
With more training data (20K-50K of text), similar quality can be achieved forsmaller test strings (Prager, 1999).Many n-gram based methods have been ex-plored besides the one we opted for.4 Manycan achieve perfect or nearly perfect classifica-tion with small training corpora on small texts.In previous work (Branco and Costa, 2007),we did a comparative study on two classifiersthat use approaches very well understood inlanguage processing and information retrieval,namely Vector Space and Bayesian models.
Weretain here the latter as this one scored compar-atively better for the current purposes.In order to know which language Li?
L gen-erated string s, Bayesian methods can be usedto calculate the probabilities P (s|Li) of string sappearing in language Lifor all Li?
L, the con-sidered language set, and decide for the languagewith the highest score (Dunning, 1994).
That is,in order to compute P (Li|s), we only computeP (s|Li).
The Bayes rule allows us to cast theproblem in terms of P (s|Li)P (Li )P (s), but as is stan-dard practice, the denominator is dropped sincewe are only interested here in getting the highestprobability, not its exact value.
The prior P (Li)is also ignored, corresponding to the simplify-ing assumption that all languages are equallyprobable for the operation of the classifier.
Theway P (s|Li) is calculated is also the standardway to do it, namely assuming independenceand just multiplying the probabilities of charac-ter cigiven the preceding n-1 characters (usingn-grams), for all characters in the input (esti-mated from n-gram counts in the training set).For our experiments, we implemented the al-gorithm described in (Dunning, 1994).
Othercommon strategies were also used, like prepend-ing n?1 special characters to the input string toharmonize calculations, summing logs of proba-bilities instead of multiplying them to avoid un-4See (Sibun and Reynar, 1996) and (Hughes et al,2006) for surveys.derflow errors, and using Laplace smoothing toreserve probability mass to events not seen intraining.5.2 Calibrating the implementation5.2.1 Detection of languagesFirst of all, we want to check that the lan-guage identification methods we are using, andhave implemented, are in fact reliable to identifydifferent languages.
Hence, we run the classifieron three languages showing strikingly differentcharacters and character sequences.
This is adeliberately easy test to get insight into the ap-propriate setting of the two parameters at stakehere, size of of the n-gram in the training phase,and size of the input in the running phase.For this test, we used the Universal Declara-tion of Human Rights texts.The languages usedwere Finnish, Portuguese and Welsh.5Several tests were conducted, splitting thetest data in chunks 1, 5, 10 and 20 lines long.The classifier obtained perfect accuracy on alltest conditions (all chunk sizes), for all values ofn between 1 and 7 (inclusively).
For n = 8 andn = 9 there were errors only when classifying 1line long items.The average line length for the test corporawas 138 characters for Finnish, 141 for Por-tuguese and 121 for Welsh (133 overall).
In thecorpora we will be using in the following experi-ments, average line length is much lower (around40 characters per line).
To become closer toour experimental conditions, we also evaluatedthis classifiers with the same test corpora, buttruncated each line beyond the first 50 charac-ters, yielding test corpora with an average linelength around 38 characters (since some weresmaller than that).
The results are similar.
TheBayesian classifier performed with less than per-fect accuracy also with n = 7 when classifying 1line at a time.Our classifier was thus performing well at dis-criminating languages with short values of n,and can classify short bits of text, even withincomplete words.5The Preamble and Articles 1?19 were used for train-ing (8.1K of Finnish, 6.9K of Portuguese, and 6.1K ofWelsh), and Articles 20?30 for testing (4.6K of Finnish,4.7K of Portuguese, and 4.0K of Welsh).625.2.2 Detection of originating corpusIn order to study its suitability to discrimi-nate also the two Portuguese variants, we ex-perimented our implementation of the Bayesianclassifiers on 200K lines of text from each of thetwo corpora.
We randomly chose 20K lines fortesting and the remaining 180K for training.
Aclassification is considered correct if the classi-fier can guess the newspaper the text was takenfrom.The average line length of the test sentences is43 characters.
Several input lengths were triedout by dividing the test data into various setswith varying size.
Table 3 summarizes the re-sults obtained.Length of Test Item1 line 5 lines 10 lines 20 linesn = 2 0.84 0.99 1 1n = 3 0.96 0.99 1 1n = 4 0.96 1 1 1n = 5 0.94 1 1 1n = 6 0.92 0.99 1 1n = 7 0.89 0.98 0.99 1Table 3: Originating corpora: AccuracyThe accuracy of the classifier is surprisinglyhigh given that the sentences that cannot be at-tributed to a single variety are estimated to bearound 81%.5.2.3 Scaling down the training dataA final check was made with the classifierto gain further insight on the comparability ofthe results obtained under the two tuning ap-proaches.
It was trained on the data preparedfor the actual experiment, made of the 10Kwith lines that have the shortest length and areparsable, but using only the markedly Europeanand Brazilian Portuguese data (leaving aside thesentences judged to be common to both).
Thisway the two setups can be compared, since inthe test of the Subsection just above much moredata was available for training.Results are in Table 4.
As expected, witha much smaller amount of training data thereis an overall drop in the accuracy, with a no-ticed bias at classifying items as European Por-tuguese.
The performance of the classifier de-grades with larger values of n. Nevertheless, theclassifier is still very good with bigrams, with anLength of Test Item1 line 5 lines 10 lines 20 linesn = 2 0.86 0.98 0.96 1n = 3 0.82 0.73 0.64 0.5n = 4 0.68 0.55 0.5 0.5Table 4: Two-way classification: Accuracyalmost optimal performance, only slightly worsethan the one observed in the previous Subsec-tion, when it was trained with more data.From these preliminary tests, we learned thatwe could expect a quasi optimal performance ofthe classifier we implemented to act as a prepro-cessor in the pre-tuning approach, when n = 2and it is run under conditions very close to theones it will encounter in the actual experimentaimed at comparing the two tuning approaches.5.3 Results with pre-tuningIn the final experiment, the classifier shoulddiscriminate between three classes, decidingwhether the input is either specifically Euro-pean or Brazilian Portuguese, or else whetherit belongs to both variants.
It was trained overthe 15K tokens/420 lines of training data, andtested over the held out test data of identicalsize.Length of Test Item1 line 5 lines 10 lines 20 linesn = 2 0.59 0.67 0.76 0.76n = 3 0.55 0.52 0.45 0.33n = 4 0.48 0.39 0.33 0.33Table 5: Three-way classification: AccuracyThe results are in Table 5.
As expected, theclassifier based in bigrams has the best perfor-mance for every size of the input, which im-proves from 0.59 to 0.76 as the size of the inputgets from 1 line to 20 lines.6 Discussion and conclusionsFrom the results above for pre-tuning, it is thevalue 0.59, obtained for 1 line of input, that canbe put on a par with the value of 0.57 obtainedfor self-tuning ?
both of them to be appreciatedagainst the baseline of 0.53.Interestingly, the performance of both ap-proaches are quite similar, and quite encour-aging given the limitations under which thepresent pilot exercise was executed.
But this is63also the reason why they should be consideredwith the appropriate grano salis.Note that there is much room for improve-ment in both approaches.
From the severalsources of variant specificity, the grammar usedwas prepared to cope only with grammaticalconstructs that are responsible for at most 20%of them.
Also the lexicon, that included a littlemore than 800 variant-distinctive items, can belargely improved.As to the classifier used for pre-tuning, it im-plements methods that may achieve optimal ac-curacy with training data sets of modest size butthat need to be nevertheless larger than the veryscarce 15K tokens used this time.
Using backoffand interpolation will help to improve as well.Some features potentially distinguish, how-ever, the pre-tuning based on Bayesian classifierfrom the self-tuning by the grammar.Language detection methods are easy to scaleup with respect to the number of variants used.In contrast, the size of the type hierarchy undervariant is exponential on the number of languagevariants if all combinations of variants are takeninto account, as it seems reasonable to do.N-grams based methods are efficient and canbe very accurate.
On the other hand, like anystochastic method, they are sensitive to trainingdata and tend to be much more affected than thegrammar in self-tuning by a change of text do-main.
Also in dialogue settings with turns fromdifferent language variants, hence with smalllengths of texts available to classify and suc-cessive alternation between language variants,n-grams are likely to show less advantage thanself-tuning by fully fledged grammars.These are issues over which more acute insightwill be gained in future work, which will seekto improve the contributions put forward in thepresent paper.Summing up, a major contribution of thepresent paper is a design strategy for type-feature grammars that allows them to be appro-priately set to the specific language variant of agiven input.
Concomitantly, this design allowsthe grammars either to be pre-tuned or to self-tune to that dialect ?
which, to the best of ourknowledge, consists in a new kind of approach tohandling language variation in deep processing.In addition, we undertook a pilot experimentwhich can be taken as setting the basis for amethodology to comparatively assess the perfor-mance of these different tuning approaches andtheir future improvements.ReferencesAnto?nio Branco and Francisco Costa.
2005.
LX-GRAM ?
deep linguistic processing of Portuguesewith HSPG.
Technical report, Dept.
of Informat-ics, University of Lisbon.Anto?nio Branco and Francisco Costa.
2007.
Han-dling language variation in deep processing.
InProc.
CLIN2007.Anto?nio Branco and Joa?o Silva.
2004.
Evaluat-ing solutions for the rapid development of state-of-the-art POS taggers for Portuguese.
In Proc.LREC2004.Ann Copestake, Dan Flickinger, Carl Pollard, andIvan Sag.
2001.
Minimal Recursion Semantics:An introduction.
Language and Computation, 3.Ann Copestake.
2002.
Implementing typed featurestructure grammars.
CSLI.Ted Dunning.
1994.
Statistical identification of lan-guage.
Technical Report MCCS-94-273, Comput-ing Research Lab, New Mexico State Univ.Baden Hughes, Timothy Baldwin, Steven Bird,Jeremy Nicholson, and Andrew MacKinlay.
2006.Reconsidering language identification for writtenlanguage resources.
In Proc.
LREC2006.Shanjian Li and Katsuhiko Momoi.
2001.
A com-posite approach to language/encoding detection.In Proc.
19th International Unicode Conference.Rafael Lins and Paulo Gonc?alves.
2004.
Automaticlanguage identification of written texts.
In Proc.2004 ACM Symposium on Applied Computing.Michael P. Oakes.
2003.
Text categorization: Auto-matic discrimination between US and UK Englishusing the chi-square test and high ratio pairs.
Re-search in Language, 1.Carl Pollard and Ivan Sag.
1994.
Head-driven phrasestructure grammar.
CSLI.John M. Prager.
1999.
Linguini: Language iden-tification for multilingual documents.
Journal ofManagement Information Systems, 16(3).Penelope Sibun and Jeffrey C. Reynar.
1996.
Lan-guage identification: Examining the issues.
In 5thSymposium on Document Analysis and IR.64
