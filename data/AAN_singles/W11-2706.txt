Proceedings of the UCNLG+Eval: Language Generation and Evaluation Workshop, pages 39?44,Edinburgh, Scotland, UK, July 31, 2011. c?2011 Association for Computational LinguisticsLinguistically Motivated Complementizer Choice in Surface RealizationRajakrishnan Rajkumar and Michael WhiteDepartment of LinguisticsThe Ohio State UniversityColumbus, OH, USA{raja,mwhite}@ling.osu.eduAbstractThis paper shows that using linguis-tically motivated features for Englishthat-complementizer choice in an averagedperceptron model for classification canimprove upon the prediction accuracy of astate-of-the-art realization ranking model.We report results on a binary classificationtask for predicting the presence/absence of athat-complementizer using features adaptedfrom Jaeger?s (2010) investigation of theuniform information density principle in thecontext of that-mentioning.
Our experimentsconfirm the efficacy of the features basedon Jaeger?s work, including informationdensity?based features.
The experiments alsoshow that the improvements in predictionaccuracy apply to cases in which the presenceof a that-complementizer arguably makes asubstantial difference to fluency or intelli-giblity.
Our ultimate goal is to improve theperformance of a ranking model for surfacerealization, and to this end we conclude witha discussion of how we plan to combine thelocal complementizer-choice features withthose in the global ranking model.1 IntroductionJohnson (2009) observes that in developing statis-tical parsing models, ?shotgun?
features ?
that is,myriad scattershot features that pay attention to su-perficial aspects of structure ?
tend to be remark-ably useful, while features based on linguistic the-ory seem to be of more questionable utility, withthe most basic linguistic insights tending to have thegreatest impact.1 Johnson also notes that featuredesign is perhaps the most important but least un-derstood aspect of statistical parsing, and thus thedisappointing impact of linguistic theory on pars-ing models is of real consequence.
In this paper,by contrast, we show that in the context of sur-face realization, using linguistically motivated fea-tures for English that-complementizer choice canimprove upon the prediction accuracy of a state-of-the-art realization ranking model, arguably in waysthat make a substantial difference to fluency and in-telligiblity.2 In particular, we report results on a bi-nary classification task for predicting the presenceor absence of a that-complementizer using featuresadapted from Jaeger?s (2010) investigation of theuniform information density principle in the con-text of that-mentioning.
This information-theoreticprinciple predicts that language production is af-fected by a preference to distribute information uni-formly across the linguistic signal.
In Jaeger?s study,uniform information density emerges as an impor-tant predictor of speakers?
syntactic reduction pref-erences even when taking a sizeable variety of con-trols based on competing hypotheses into account.Our experiments confirm the efficacy of the fea-tures based on Jaeger?s work, including informationdensity?based features.1The term ?shotgun?
feature appears in the slides forJohnson?s talk (http://www.cog.brown.edu/?mj/papers/johnson-eacl09-workshop.pdf), ratherthan in the paper itself.2For German surface realization, Cahill and Riester (2009)show that incorporating information status features based onthe linguistics literature improves performance on realizationranking.39That-complementizers are optional words that in-troduce sentential complements in English.
In thePenn Treebank, they are left out roughly two-thirdsof the time, thereby enhancing conciseness.
Thisfollows the low complementizer rates reported inprevious work (Tagliamonte and Smith, 2005; Ca-coullos and Walker, 2009).
While some surface re-alizers, such as FUF/SURGE (Elhadad, 1991), havemade use of input features to control the choice ofwhether to include a that-complementizer, for manyapplications the decision seems best left to the real-izer, since multiple surface syntactic factors appearto govern the choice, rather than semantic ones.
Inour experiments, we use the OpenCCG3 surface re-alizer with logical form inputs underspecified for thepresence of that in complement clauses.
While inmany cases, adding or removing that results in anacceptable paraphrase, in the following example, theabsence of that in (2) introduces a local ambiguity,which the original Penn Treebank sentence avoidsby including the complementizer.
(1) He said that for the second month in arow, food processors reported a shortageof nonfat dry milk.
(WSJ0036.61)(2) ?
He said for the second month in a row,food processors reported a shortage ofnonfat dry milk.The starting point for this paper is White and Ra-jkumar?s (2009) realization ranking model, a state-of-the-art model employing shotgun features ga-lore.
An error analysis of this model, performedby comparing CCGbank Section 00 realized deriva-tions with their corresponding gold standard deriva-tions, revealed that out of a total of 543 that-complementizer cases, the realized output did notmatch the gold standard choice 82 times (see Table 3in Section 5 for details).
Most of these mismatchesinvolved cases where a clause originally containinga that-complementizer was realized in reduced form,with no that.
This under-prediction of that-inclusionis not surprising, since the realization ranking modelmakes use of baseline n-gram model features, andn-gram models are known to have a built-in bias forstrings with fewer words.3openccg.sf.netWe report here on experiments comparing thisglobal model to ones that employ local featuresspecifically designed for that-choice in complementclauses.
As a prelude to incorporating these fea-tures into a model for realization ranking, we studythe efficacy of these features in isolation by meansof a binary classification task to predict the pres-ence/absence of that in complement clauses.
Ina global realization ranking setting, the impact ofthese phenomenon-specific features might be lessevident, as they would interact with other featuresfor lexical selection and ordering choices that theranker makes.
Note that a comprehensive rankingmodel is desirable, since linear ordering and that-complementizer choices may interact.
For exam-ple, Hawkins (2003) reports examples where explic-itly marked phrases can occur either close to or farfrom their heads as in (3) and (4), whereas zero-marked phrases are only rarely attested at some dis-tance from their heads and prefer adjacency, as (5)and (6) show.
(3) I realized [that he had done it] with sad-ness in my heart.
(4) I realized with sadness in my heart [thathe had done it].
(5) I realized [he had done it] with sadness inmy heart.
(6) ?
I realized with sadness in my heart [hehad done it].2 BackgroundCCG (Steedman, 2000) is a unification-based cat-egorial grammar formalism defined almost en-tirely in terms of lexical entries that encode sub-categorization as well as syntactic features (e.g.number and agreement).
OpenCCG is a pars-ing/generation library which includes a hybridsymbolic-statistical chart realizer (White, 2006).The chart realizer takes as input logical forms rep-resented internally using Hybrid Logic DependencySemantics (HLDS), a dependency-based approachto representing linguistic meaning (Baldridge andKruijff, 2002).
To illustrate the input to OpenCCG,consider the semantic dependency graph in Figure 1.In the graph, each node has a lexical predication(e.g.
make.03) and a set of semantic features (e.g.40aa1heh3he h2<Det><Arg0> <Arg1><TENSE>pres<NUM>sg<Arg0>w1 want.01m1<Arg1><GenRel><Arg1><TENSE>presp1pointh1have.03make.03<Arg0>s[b]\np/npnp/nnpns[dcl]\np/nps[dcl]\np/(s[to]\np)npFigure 1: Semantic dependency graph from the CCGbankfor He has a point he wants to make [.
.
.
], along withgold-standard supertags (category labels)?NUM?sg); nodes are connected via dependency re-lations (e.g.
?ARG0?).
In HLDS, each semantic head(corresponding to a node in the graph) is associatedwith a nominal that identifies its discourse referent,and relations between heads and their dependentsare modeled as modal relations.
We extract HLDS-based quasi logical form graphs from the CCG-bank and semantically empty function words such ascomplementizers, infinitival-to, expletive subjects,and case-marking prepositions are adjusted to reflecttheir purely syntactic status.
Alternative realizationsare ranked using an averaged perceptron model de-scribed in the next section.3 Feature DesignWhite and Rajkumar?s (2009) realization rankingmodel serves as the baseline for this paper.
It isa global, averaged perceptron ranking model usingthree kinds of features: (1) the log probability of thecandidate realization?s word sequence according tothree linearly interpolated language models (as wellas a feature for each component model), much asin the log-linear models of Velldal & Oepen (2005)and Nakanishi et al (2005); (2) integer-valued syn-tactic features, representing counts of occurrences ina derivation, from Clark & Curran?s (2007) normalform model; and (3) discriminative n-gram features(Roark et al, 2004), which count the occurrences ofeach n-gram in the word sequence.Table 1 shows the new complementizer-choicefeatures investigated in this paper.
The example fea-tures mentioned in the table are taken from the twocomplement clause (CC) forms (with-that CC vs.that-less CC) of the sentence below:(7) The finding probably will support thosewho argue [ that/?
the U.S. should regu-late the class of asbestos including croci-dolite more stringently than the commonkind of asbestos, chrysotile, found in mostschools and other buildings], Dr. Talcottsaid.
(WSJ0003.19)The first class of features, dependency length andposition of CC, have been adapted from the relatedcontrol features in Jaeger?s (2010) study.
For theabove example, the position of the matrix verb withrespect to the start of the sentence (feature namemvInd and having the value 7.0), the distance be-tween the matrix verb and the onset of the CC (fea-ture name mvCCDist with the value 1.0) and fi-nally the length of the CC (feature ccLen with valueof 29.0 for the that-CC and 28.0 for the that-lessCC) are encoded as features.
The second class offeatures includes various properties of the matrixverb viz.
POS tag, form, stem and supertag (fea-ture names mv Pos, mvStem, mvForm, mvSt, respec-tively).
These features were motivated by the factthat Jaeger controls for the per-verb bias of this con-struction, as attested in the earlier literature.
Thethird class of features are related to information den-sity.
Jaeger (2010) estimates information density atthe CC onset by using matrix verb subcategorizationfrequency.
In our case, more like the n-gram fea-tures employed by Levy and Jaeger (2007), we usedlog probabilities from two existing n-gram models,viz.
a trigram word model and trigram word modelwith semantic class replacement.
For each CC, twofeatures (one per language model) were extracted bycalculating the average of the log probs of individualwords from the beginning of the complement clause.In the that-CC version of the example above, lo-cal CC-features having the prefix $uidCCMean werecalculated by averaging the individual log probs ofthe 3 words that the U.S. to get feature values of-0.8353556 and -2.0460036 per language model (see41Feature Example for that-CCs Example for that-less CCsDependency length and position of CCPosition of matrix verb thatCC:mvInd 7.0 noThatCC:mvInd 7.0Dist between matrix verb & CC thatCC:mvCCDist 1.0 noThatCC:mvCCDist 1.0Length of CC thatCC:ccLen 29.0 noThatCC:ccLen 28.0Matrix verb featuresPOS-tag thatCC:mvPos:VBP 1.0 noThatCC:mvPos:VBP 1.0Stem thatCC:mvStem:argue 1.0 noThatCC:mvStem:argue 1.0Form thatCC:mvForm:argue 1.0 noThatCC:mvForm:argue 1.0CCG supertag thatCC:mvSt:s[dcl]\np/s[em] 1.0 noThatCC:mvSt:s[dcl]\np/s[dcl] 1.0uniform information density (UID)Average n-gram log probs thatCC:$uidCCMean1 -0.8353556 noThatCC:$uidCCMean1 -2.5177214of first 2 words of that-less CCs thatCC:$uidCCMean2 -2.0460036 noThatCC:$uidCCMean2 -3.6464245or first 3 words of that-CCsTable 1: New features introduced (the prefix of each feature encodes the type of CC; subsequent parts supply thefeature name)last part of Table 1).
In the that-less CC version,$uidCCMean features were calculated by averagingthe log probs of the first two words in the comple-ment clause, i.e.
the U.S.4 Classification ExperimentTo train a local classification model to predict thepresence of that in complement clauses, we usedan averaged perceptron ranking model with thecomplementizer-specific features listed in Table 1to rank alternate with-that vs. that-less CC choices.For each CC classification instance in CCGbankSections 02?21, the derivation of the competing al-ternate choice was created; i.e., in the case of a that-CC, the corresponding that-less CC was created andvice versa.
Table 2 illustrates classification resultson Sections 00 (development) using models contain-ing different feature sets & Section 23 (final test) forthe best-performing classification and ranking mod-els.
For both the development as well as test sec-tions, the local classification model performed sig-nificantly better than the global realization rankingmodel according to McNemar?s ?2 test (p = 0.005,two-tailed).
Feature ablation tests on the develop-ment data (Section 00) revealed that removing theinformation density features resulted in a loss of ac-curacy of around 1.8%.5 DiscussionAs noted in the introduction, in many cases, addingor removing that to/from the corpus sentence resultsin an acceptable paraphrase, while in other casesthe presence of that appears to make a substantialModel Features % 00 % 23Most Frequent Baseline 68.7 66.8Global Realization Ranking 78.45 77.0Local That-ClassificationOnly UID feats 74.77Table 1 features except UID ones 81.4Both feature sets above 83.24 83.02Table 2: Classification accuracy results (Section 00 has170/543 that-CCs; Section 23 has 192/579 that-CCs)Construction %that % that / %AccuracyGold Classification RankingGerundive (26) 53.8 61.5 / 92.3 26.9 / 57.7Be-verb (21) 71.4 95.2 / 66.7 47.6 / 57.1Non-adjacent CCs (53) 49.1 54.7 / 67.9 30.2 / 66.0Total (543) 31.3 29.3 / 83.2 21.9 / 78.5Table 3: Section 00 construction-wise that-CC propor-tions and model accuracies (total CC counts given inbrackets alongside labels); gold standard obviously has100% accuracy; models are local that-classification andWhite and Rajkumar?s (2009) global realization rankingmodeldifference to intelligibility or fluency.
In order tobetter understand the effect of the complementizer-specific features, we examined three constructiontypes in the development data, viz.
non-adjacentcomplement clauses, gerundive matrix verbs and ahost of sub-cases involving a matrix be-verb (wh-clefts, be+adjective etc.
), where the presence of thatseemed to make the most difference.
The results areprovided in Table 3.
As is evident, the global realiza-tion ranking model under-proposes the that-choice,most likely due to the preference of n-gram mod-els towards fewer words, while the local classifica-42WSJ0049.64 Observing [that/??
the judge has never exhibited any bias or prejudice], Mr. Murray concluded that he would be impartialin any case involving a homosexual or prostitute as a victim.WSJ0020.16 ?
what this tells us is [that/??
U.S. trade law is working] ?, he said .WSJ0010.5 The idea, of course: to prove to 125 corporate decision makers [that/??
the buckle on the Rust Belt is n?t so rusty after all ,that it ?s a good place for a company to expand].WSJ0044.118 Editorials in the Greenville newspaper allowed [that/??
Mrs. Yeargin was wrong], but also said the case showed how testingwas being overused.WSJ0060.7 Viacom denies [?/?that it ?s using pressure tactics].WSJ0018.4 The documents also said [that/??
although the 64-year-old Mr. Cray has been working on the project for more than six years ,the Cray-3 machine is at least another year away from a fully operational prototype].Table 4: Examples from model comparisontion model is closer to the gold standard in terms ofthat-choice proportions.
For all the three construc-tion types as well as overall, classifier performancewas better than ranker performance.
The differencein performance between the local classification andglobal ranking models in the case of gerundive ma-trix verbs is statistically significant according to theMcNemar?s ?2 test (Bonferroni corrected, two tailedp = 0.001).
The performance difference was notsignificant with the other two constructions, how-ever, using only the cases in Section 00.Table 4 lists relevant examples where the classi-fication model?s that-choice prediction matched thegold standard while a competing model?s predic-tion did not.
Example WSJ0049.64 is one suchinstance of classifier success involving a gerun-dive matrix verb (in contrast to the realizationranking model), Example WSJ0020.16 exemplifiessuccess with a wh-cleft construction and Exam-ple WSJ0010.5 contains a non-adjacent CC.
Apartfrom these construction-based analyses, exampleslike WSJ0044.118 indicate that the classificationmodel prefers the that-CC choice in cases that sub-stantially improve intelligiblity, as here the overtcomplementizer helps to avoid a local syntactic am-biguity where the NP in allowed NP is unlikely to beinterpreted as the start of an S.Finally, we also studied the effect of the uniforminformation density features by comparing the fullclassification model to a model without the UIDfeatures.
The full classification model exhibited atrend towards significantly outperforming the ab-lated model (McNemar?s p = 0.10, 2-tailed); moretest data would be needed to establish significanceconclusively.
Examples are shown at the bottom ofTable 4.
In WSJ0060.7, the full classification modelpredicted a that-less clause (matching the gold stan-dard), while the ablated classification model pre-dicted a clause with that.
In all such examples ex-cept one, the information density features helped theclassification model avoid predicting that-inclusionwhen not necessary.
Example WSJ0018.4 is theonly instance where the best classification modeldiffered in predicting the that-choice.6 Conclusions and Future WorkIn this paper, we have shown that using linguisticallymotivated features for English that-complementizerchoice in a local classifier can improve upon theprediction accuracy of a state-of-the-art global re-alization ranking model employing myriad shotgunfeatures, confirming the efficacy of features basedon Jaeger?s (2010) investigation of the uniform in-formation density principle in the context of that-mentioning.
Since that-complementizer choice in-teracts with other realization decisions, in futurework we plan to investigate incorporating these fea-tures into the global realization ranking model.
Thismove will require binning the real-valued features,as multiple complement clauses can appear in a sin-gle sentence.
Should feature-level integration proveineffective, we also plan to investigate alternative ar-chitectures, such as using the local classifier outputsas features in the global model.AcknowledgementsThis work was supported in part by NSF IIS-0812297 and by an allocation of computing timefrom the Ohio Supercomputer Center.
Our thanksalso to Florian Jaeger, William Schuler, Peter Culi-cover and the anonymous reviewers for helpful com-ments and discussion.43ReferencesJason Baldridge and Geert-Jan Kruijff.
2002.
CouplingCCG and Hybrid Logic Dependency Semantics.
InProc.
ACL-02.Rena Torres Cacoullos and James A. Walker.
2009.
Onthe persistence of grammar in discourse formulas: Avariationist study of ?that?.
Linguistics, 47(1):1?43.Stephen Clark and James R. Curran.
2007.
Wide-Coverage Efficient Statistical Parsing with CCG andLog-Linear Models.
Computational Linguistics,33(4):493?552.Michael Elhadad.
1991.
FUF: The universal unifier usermanual version 5.0.
Technical Report CUCS-038-91,Dept.
of Computer Science, Columbia University.John A. Hawkins.
2003.
Why are zero-marked phrasesclose to their heads?
In Gu?nter Rohdenburg and BrittaMondorf, editors, Determinants of Grammatical Vari-ation in English, Topics in English Linguistics 43.
DeGruyter Mouton, Berlin.T.
Florian Jaeger.
2010.
Redundancy and reduction:Speakers manage information density.
Cognitive Psy-chology, 61(1):23?62, August.Mark Johnson.
2009.
How the statistical revolutionchanges (computational) linguistics.
In Proceedings ofthe EACL 2009 Workshop on the Interaction betweenLinguistics and Computational Linguistics: Virtuous,Vicious or Vacuous?, pages 3?11, Athens, Greece,March.
Association for Computational Linguistics.Roger Levy and T. Florian Jaeger.
2007.
Speakers opti-mize information density through syntactic reduction.Advances in Neural Information Processing Systems,19:849.Hiroko Nakanishi, Yusuke Miyao, and Jun?ichi Tsujii.2005.
Probabilistic methods for disambiguation of anHPSG-based chart generator.
In Proc.
IWPT-05.Brian Roark, Murat Saraclar, Michael Collins, and MarkJohnson.
2004.
Discriminative language modelingwith conditional random fields and the perceptron al-gorithm.
In Proc.
ACL-04.Mark Steedman.
2000.
The syntactic process.
MITPress, Cambridge, MA, USA.S.
Tagliamonte and J. Smith.
2005.
No momentaryfancy!
the zero ?complementizer?
in English dialects.English Language and Linguistics, 9(2):289?309.Erik Velldal and Stephan Oepen.
2005.
Maximum en-tropy models for realization ranking.
In Proc.
MTSummit X.Michael White and Rajakrishnan Rajkumar.
2009.
Per-ceptron reranking for CCG realization.
In Proceedingsof the 2009 Conference on Empirical Methods in Nat-ural Language Processing, pages 410?419, Singapore,August.
Association for Computational Linguistics.Michael White.
2006.
Efficient Realization of Coordi-nate Structures in Combinatory Categorial Grammar.Research on Language and Computation, 4(1):39?75.44
