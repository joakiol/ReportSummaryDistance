Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1668?1676,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsDependency-Based Decipherment for Resource-Limited MachineTranslationQing Dou and Kevin KnightInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern California{qdou,knight}@isi.eduAbstractWe introduce dependency relations into deci-phering foreign languages and show that de-pendency relations help improve the state-of-the-art deciphering accuracy by over 500%.We learn a translation lexicon from largeamounts of genuinely non parallel data withdecipherment to improve a phrase-based ma-chine translation system trained with limitedparallel data.
In experiments, we observeBLEU gains of 1.2 to 1.8 across three differenttest sets.1 IntroductionState-of-the-art machine translation (MT) systemsapply statistical techniques to learn translation rulesfrom large amounts of parallel data.
However, par-allel data is limited for many language pairs and do-mains.In general, it is easier to obtain non parallel data.The ability to build a machine translation systemusing monolingual data could alleviate problemscaused by insufficient parallel data.
Towards build-ing a machine translation system without a paral-lel corpus, Klementiev et al(2012) use non paral-lel data to estimate parameters for a large scale MTsystem.
Other work tries to learn full MT systemsusing only non parallel data through decipherment(Ravi and Knight, 2011; Ravi, 2013).
However, theperformance of such systems is poor compared withthose trained with parallel data.Given that we often have some parallel data,it is more practical to improve a translation sys-tem trained on parallel corpora with non parallelFigure 1: Improving machine translation with deci-pherment (Grey boxes represent new data and process).Mono: monolingual; LM: language model; LEX: trans-lation lexicon; TM: translation model.data.
Dou and Knight (2012) successfully applydecipherment to learn a domain specific translationlexicon from monolingual data to improve out-of-domain machine translation.
Although their ap-proach works well for Spanish/French, they do notshow whether their approach works for other lan-guage pairs.
Moreover, the non parallel data used intheir experiments is created from a parallel corpus.Such highly comparable data is difficult to obtain inreality.In this work, we improve previous work by Douand Knight (2012) using genuinely non parallel data,1668and propose a framework to improve a machinetranslation system trained with a small amount ofparallel data.
As shown in Figure 1, we use a lexi-con learned from decipherment to improve transla-tions of both observed and out-of-vocabulary (OOV)words.
The main contributions of this work are:?
We extract bigrams based on dependency re-lations for decipherment, which improves thestate-of-the-art deciphering accuracy by over500%.?
We demonstrate how to improve translationsof words observed in parallel data by us-ing a translation lexicon obtained from largeamounts of non parallel data.?
We show that decipherment is able to find cor-rect translations for OOV words.?
We use a translation lexicon learned by de-ciphering large amounts of non parallel datato improve a phrase-based MT system trainedwith limited amounts of parallel data.
In ex-periments, we observe 1.2 to 1.8 BLEU gainsacross three different test sets.2 Previous WorkMotivated by the idea that a translation lexicon in-duced from non parallel data can be applied toMT, a variety of prior research has tried to build atranslation lexicon from non parallel or compara-ble data (Rapp, 1995; Fung and Yee, 1998; Koehnand Knight, 2002; Haghighi et al 2008; Garera etal., 2009; Bergsma and Van Durme, 2011; Daume?and Jagarlamudi, 2011; Irvine and Callison-Burch,2013b; Irvine and Callison-Burch, 2013a).
Al-though previous work is able to build a translationlexicon without parallel data, little has used the lex-icon to improve machine translation.There has been increasing interest in learningtranslation lexicons from non parallel data with de-cipherment techniques (Ravi and Knight, 2011; Douand Knight, 2012; Nuhn et al 2012).
Decipher-ment views one language as a cipher for another andlearns a translation lexicon that produces a good de-cipherment.In an effort to build a MT system without a paral-lel corpus, Ravi and Knight (2011) view Spanish as acipher for English and apply Bayesian learning to di-rectly decipher Spanish into English.
Unfortunately,their approach can only work on small data with lim-ited vocabulary.
Dou and Knight (2012) propose twotechniques to make Bayesian decipherment scalable.First, unlike Ravi and Knight (2011), who deci-pher whole sentences, Dou and Knight (2012) deci-pher bigrams.
Reducing a ciphertext to a set of bi-grams with counts significantly reduces the amountof cipher data.
According to Dou and Knight (2012),a ciphertext bigram F is generated through the fol-lowing generative story:?
Generate a sequence of two plaintext tokense1e2 with probability P (e1e2) given by a lan-guage model built from large numbers of plain-text bigrams.?
Substitute e1 with f1 and e2 with f2 with prob-ability P (f1|e1) ?
P (f2|e2).The probability of any cipher bigram F is:P (F ) =?e1e2P (e1e2)2?i=1P (fi|ei)Given a corpus of N cipher bigrams F1...FN , theprobability of the corpus is:P (corpus) =N?j=1P (Fj)Given a plaintext bigram language model,the goal is to manipulate P (f |e) to maximizeP (corpus).
Theoretically, one can directly applyEM to solve the problem (Knight et al 2006).
How-ever, EM has time complexity O(N ?
V 2e ) and spacecomplexity O(Vf ?
Ve), where Vf , Ve are the sizesof ciphertext and plaintext vocabularies respectively,and N is the number of cipher bigrams.Ravi and Knight (2011) apply Bayesian learningto reduce the space complexity.
Instead of esti-mating probabilities P (f |e), Bayesian learning triesto draw samples from plaintext sequences given ci-phertext bigrams.
During sampling, the probabilityof any possible plaintext sample e1e2 is given as:Psample(e1e2) = P (e1e2)2?i=1Pbayes(fi|ei)1669misio?n de naciones unidas en oriente mediomisio?n de misio?n nacionesde naciones naciones unidasnaciones unidas misio?n enunidas en en orienteen oriente oriente mediooriente medioTable 1: Comparison of adjacent bigrams (left) and de-pendency bigrams (right) extracted from the same Span-ish textwith Pbayes(fi|ei) defined as:Pbayes(fi|ei) =?P0(fi|ei) + count(fi, ei)?+ count(ei)where P0 is a base distribution, and ?
is a parameterthat controls how much we trust P0.
count(fi, ei)and count(ei) record the number of times fi, ei andei appear in previously generated samples respec-tively.At the end of sampling, P (fi|ei) is estimated by:P (fi|ei) =count(fi, ei)count(ei)However, Bayesian decipherment is still veryslow with Gibbs sampling (Geman and Geman,1987), as each sampling step requires consideringVe possibilities.
Dou and Knight (2012) solve theproblem by introducing slice sampling (Neal, 2000)to Bayesian decipherment.3 From Adjacent Bigrams to DependencyBigramsA major limitation of work by Dou and Knight(2012) is their monotonic generative story for deci-phering adjacent bigrams.
While the generation pro-cess works well for deciphering similar languages(e.g.
Spanish and French) without considering re-ordering, it does not work well for languages thatare more different in grammar and word order (e.g.Spanish and English).
In this section, we first lookat why adjacent bigrams are bad for decipherment.Then we describe how to use syntax to solve theproblem.The left column in Table 1 contains adjacent bi-grams extracted from the Spanish phrase ?misio?nde naciones unidas en oriente medio?.
The cor-rect decipherment for the bigram ?naciones unidas?should be ?united nations?.
Since the decipheringmodel described by Dou and Knight (2012) doesnot consider word reordering, it needs to decipherthe bigram into ?nations united?
in order to getthe right word translations ?naciones??
?nations?and ?unidas???united?.
However, the English lan-guage model used for decipherment is built from En-glish adjacent bigrams, so it strongly disprefers ?na-tions united?
and is not likely to produce a sensi-ble decipherment for ?naciones unidas?.
The Span-ish bigram ?oriente medio?
poses the same prob-lem.
Thus, without considering word reordering, themodel described by Dou and Knight (2012) is not agood fit for deciphering Spanish into English.However, if we extract bigrams based on depen-dency relations for both languages, the model fitsbetter.
To extract such bigrams, we first use de-pendency parsers to parse both languages, and ex-tract bigrams by putting head word first, followedby the modifier.1 We call these dependency bi-grams.
The right column in Table 1 lists exam-ples of Spanish dependency bigrams extracted fromthe same Spanish phrase.
With a language modelbuilt with English dependency bigrams, the samemodel used for deciphering adjacent bigrams isable to decipher Spanish dependency bigram ?na-ciones(head) unidas(modifier)?
into ?nations(head)united(modifier)?.We might instead propose to consider word re-ordering when deciphering adjacent bigrams (e.g.add an operation to swap tokens in a bigram).
How-ever, using dependency bigrams has the followingadvantages:?
First, using dependency bigrams avoids com-plicating the model, keeping deciphering effi-cient and scalable.?
Second, it addresses the problem of long dis-tance reordering, which can not be modeled byswapping tokens in bigrams.Furthermore, using dependency bigrams al-lows us to use dependency types to further1As use of ?del?
and ?de?
in Spanish is much more frequentthan the use of ?of?
in English, we skip those words by usingtheir head words as new heads if any of them serves as a head.1670improve decipherment.
Suppose we have aSpanish dependency bigram ?accepto?
(verb) solici-tud(object)?.
Then all of the following English de-pendency bigrams are possible decipherments: ?ac-cepted(verb) UN(subject)?, ?accepted(verb) govern-ment(subject)?, ?accepted(verb) request(object)?.However, if we know the type of the Spanish depen-dency bigram and use a language model built withthe same type in English, the only possible decipher-ment is ?accepted(verb) request(object)?.
If we limitthe search space, a system is more likely to find abetter decipherment.4 Deciphering Spanish GigawordIn this section, we compare dependency bigramswith adjacent bigrams for deciphering Spanish intoEnglish.4.1 DataWe use the Gigaword corpus for our deciphermentexperiments.
The corpus contains news articles fromdifferent news agencies and is available in Spanishand English.
We use only the AFP (Agence France-Presse) section of the corpus in decipherment ex-periments.
We tokenize the corpus using tools thatcome with the Europarl corpus (Koehn, 2005).
Toshorten the time required for running different sys-tems on large amounts of data, we keep only the top5000 most frequent word types in both languagesand replace all other word types with UNK.
We alsothrow away lines with more than 40 tokens, as theSpanish parser (Bohnet, 2010) we use is slow whenprocessing long sentences.
After preprocessing, thecorpus contains approximately 440 million tokens inSpanish and 350 million tokens in English.
To ob-tain dependency bigrams, we use the Bohnet parsers(Bohnet, 2010) to parse both the Spanish and En-glish version of the corpus.4.2 SystemsThree systems are evaluated in the experiments.
Weimplement a baseline system, Adjacent, based onDou and Knight (2012).
The baseline system col-lects adjacent bigrams and their counts from Spanishand English texts.
It then builds an English bigramlanguage model using the English adjacent bigramsand uses it to decipher the Spanish adjacent bigrams.Dependency TypesGroup 1 Verb/SubjectGroup 2 Preposition/Preposition-Object,Noun/Noun-ModifierGroup 3 Verb/Noun-ObjectTable 2: Dependency relations divided into three groupsWe build the second system, Dependency, usingdependency bigrams for decipherment.
As the twoparsers do not output the same set of dependency re-lations, we cannot extract all types of dependencybigrams.
Instead, we select a subset of dependencybigrams whose dependency relations are shared bythe two parser outputs.
The selected dependency re-lations are: Verb/Subject, Verb/Noun-Object, Prepo-sition/Object, Noun/Modifier.
Decipherment runsthe same way as in the baseline system.The third system, DepType, is built using bothdependent bigrams and their dependency types.
Wefirst extract dependency bigrams for both languages,then group them based on their dependency types.As both parsers treat noun phrases dependent on?del?, ?de?, and ?of?
as prepositional phrases, wechoose to divide the dependency bigrams into 3groups and list them in Table 2.
A separate languagemodel is built for each group of English dependencybigrams and used to decipher the group of Spanishdependency bigrams with same dependency type.For all the systems, language models are built us-ing the SRILM toolkit (Stolcke, 2002).
For the Ad-jacent system, we use Good-Turing smoothing.
Forthe other systems, we use a mix of Witten-Bell andGood-Turing smoothing.4.3 Sampling ProcedureIn experiments, we find that the iterative sam-pling method described by Dou and Knight (2012)helps improve deciphering accuracy.
We also findthat combining results from different deciphermentshelps find more correct translations at each iteration.Thus, instead of using a single sampling process, weuse 10 different sampling processes at each iteration.The details of the new sampling procedure are pro-vided here:?
Extract dependency bigrams from parsing out-puts and collect their counts.1671?
Keep bigrams whose counts are greater than athreshold ?.
Then start 10 different randomlyseeded and initialized sampling processes.
Per-form sampling.?
At the end of sampling, extract word transla-tion pairs (f, e) from the final sample.
Esti-mate translation probabilities P (e|f) for eachpair.
Then construct a translation table by keep-ing translation pairs (f, e) seen in more thanone decipherment and use the average P (e|f)as the new translation probability.?
Lower the threshold ?
to include more bigramsinto the sampling process.
Start 10 differ-ent sampling processes again and initialize thefirst sample using the translation pairs obtainedfrom the previous step (for each Spanish tokenf, choose an English token e whose P (e|f) isthe highest).
Perform sampling again.?
Repeat until ?
= 1.4.4 Deciphering AccuracyWe choose the first 1000 lines of the monolingualSpanish texts as our test data.
The data contains37,505 tokens and 6556 word types.
We use type ac-curacy as our evaluation metric: Given a word typef in Spanish, we find a translation pair (f, e) withthe highest average P (e|f) from the translation ta-ble learned through decipherment.
If the translationpair (f, e) can also be found in a gold translationlexicon Tgold, we treat the word type f as correctlydeciphered.
Let |C| be the number of word typescorrectly deciphered, and |V | be the total number ofword types evaluated.
We define type accuracy as|C||V | .To create Tgold, we use GIZA (Och and Ney,2003) to align a small amount of Spanish-Englishparallel text (1 million tokens for each language),and use the lexicon derived from the alignment asour gold translation lexicon.
Tgold contains a subsetof 4408 types seen in the test data, among which,2878 are also top 5000 frequent word types.4.5 ResultsDuring decipherment, we gradually increase the sizeof Spanish texts and compare the learning curves ofthree deciphering systems in Figure 2.Figure 2: Learning curves for three decipherment sys-tems.
Compared with Adjacent (previous state of the art),systems that use dependency bigrams improve decipher-ing accuracy by over 500%.With 100k tokens of Spanish text, the perfor-mance of the three systems are similar.
However, thelearning curve of Adjacent plateaus quickly, whilethose of the dependency based systems soar up asmore data becomes available and still rise sharplywhen the size of Spanish texts increases to 10 mil-lion tokens, where the DepType system improvesdeciphering accuracy of the Adjacent system from4.2% to 24.6%.
In the end, with 100 million tokens,the accuracy of the DepType system rises to 27.0%.The accuracy is even higher (41%), when evaluatedagainst the top 5000 frequent word types only.5 Improving Machine Translation withDeciphermentIn this section, we demonstrate how to use a trans-lation lexicon learned by deciphering large amountsof in-domain (news) monolingual data to improvea phrase-based machine translation system trainedwith limited out-of-domain (politics) parallel data.5.1 DataWe use approximately one million tokens of the Eu-roparl corpus (Koehn, 2005) as our small out-of-domain parallel training data and Gigaword as ourlarge in-domain monolingual training data to buildlanguage models and a new translation lexicon toimprove a phrase-based MT baseline system.
Fortuning and testing, we use the development data1672ParallelSpanish EnglishEuroparl 1.1 million 1.0 millionTune-2008 52.6k 49.8kTest-2009 68.1k 65.6kTest-2010 65.5k 61.9kTest-2011 79.4k 74.7kNon ParallelSpanish EnglishGigaword 894 million 940 millionTable 3: Size of training, tuning, and testing data in num-ber of tokensfrom the NAACL 2012 workshop on statistical ma-chine translation.
The data contains test data in thenews domain from the 2008, 2009, 2010, and 2011workshops.
We use the 2008 test data for tuning andthe rest for testing.
The sizes of the training, tuning,and testing sets are listed in Table 3.5.2 Systems5.2.1 Baseline Machine Translation SystemWe build a state-of-the-art phrase-based MT sys-tem, PBMT, using Moses (Koehn et al 2007).PBMT has 3 models: a translation model, a distor-tion model, and a language model.
We build a 5-gram language model using the AFP section of theEnglish Gigaword.
We train the other models usingthe Europarl corpus.
By default, Moses uses the fol-lowing 8 features to score a candidate translation:?
direct and inverse translation probabilities?
direct and inverse lexical weighting?
a language model score?
a distortion score?
phrase penalty?
word penaltyThe 8 features have weights adjusted on the tun-ing data using minimum error rate training (MERT)(Och, 2003).
PBMT has a phrase table Tphrase.During decoding, Moses copies out-of-vocabulary(OOV) words, which can not be found in Tphrase,directly to output.
In the following sections, we de-scribe how to use a translation lexicon learned fromlarge amounts of non parallel data to improve trans-lation of OOV words, as well as words observed inTphrase.5.2.2 Decipherment for Machine TranslationTo achieve better decipherment, we:?
Increase the size of Spanish ciphertext from100 million tokens to 894 million tokens.?
Keep top 50k instead of top 5k most frequentword types of the ciphertext.?
Instead of seeding the sampling process ran-domly, we use a translation lexicon learnedfrom a limited amount of parallel data as seed:For each Spanish dependency bigram f1, f2,where both f1 and f2 are found in the seed lex-icon, we find the English sequence e1, e2 thatmaximizes P (e1, e2)P (e1|f1)P (e2|f2).
Other-wise, for any Spanish token f that can be foundin the seed lexicon, we choose English word e,where P (e|f) is the highest as the initial sam-ple; for any f that are not seen in the seed lexi-con, we do random initialization.We perform 20 random restarts with 10k iter-ations on each and build a word-to-word transla-tion lexicon Tdecipher by collecting translation pairsseen in at least 3 final decipherments with eitherP (f |e) ?
0.2 or P (e|f) ?
0.2.5.2.3 Improving Translation of ObservedWords with DeciphermentTo improve translation of words observed in ourparallel corpus, we simply use Tdecipher as an addi-tional parallel corpus.
First, we filter Tdecipher bykeeping only translation pairs (f, e), where f is ob-served in the Spanish part and e is observed in theEnglish part of the parallel corpus.
Then we ap-pend all the Spanish and English words in the fil-tered Tdecipher to the end of Spanish part and En-glish part of the parallel corpus respectively.
Thetraining and tuning process is the same as the base-line machine translation system PBMT.
We denotethis system as Decipher-OBSV.16735.2.4 Improving OOV translation withDeciphermentAs Tdecipher is learned from large amounts of in-domain monolingual data, we expect that Tdeciphercontains a number of useful translations for wordsnot seen in the limited amount of parallel data (OOVwords).
Instead of copying OOV words directly tooutput, which is what Moses does by default, we tryto find translations from Tdecipher to improve trans-lation.During decoding, if a source word f is in Tphrase,its translation options are collected from Tphrase ex-clusively.
If f is not in Tphrase but in Tdecipher,the decoder will find translations from Tdecipher.
Iff is not in either translation table, the decoder justcopies it directly to the output.
We call this systemDecipher-OOV.However, when an OOV?s correct translation issame as its surface form and all its possible transla-tions in Tdecipher are wrong, it is better to just copyOOV words directly to output.
This scenario hap-pens frequently, as Spanish and English share manycommon words.
To avoid over trusting Tdecipher,we add a new translation pair (f, f) for each sourceword f in Tdecipher if the translation pair (f, f) isnot originally in Tdecipher.
For each newly addedtranslation pair, both of its log translation probabil-ities are set to 0.
To distinguish the added transla-tion pairs from the others learned through decipher-ment, we add a binary feature ?
to each translationpair in Tdecipher.
The final version of Tdecipher hasthree feature scores: P (e|f), P (f |e), and ?.
Finally,we tune weights of the features in Tdecipher usingMERT (Och, 2003) on the tuning set.5.2.5 A Combined ApproachIn the end, we build a system Decipher-COMB,which uses Tdecipher to improve translation of bothobserved and OOV words with methods described insections 5.2.3 and 5.2.4.5.3 ResultsWe tune each system three times with MERT andchoose the best weights based on BLEU scores ontuning set.Table 4 shows that the translation lexicon learnedfrom decipherment helps achieve higher BLEUscores across tuning and testing sets.
Decipher-OBSV improves BLEU scores by as much as 1.2points.
We analyze the results and find the gainmainly comes from two parts.
First, adding Tdecipherto small amounts of parallel corpus improves wordlevel translation probabilities, which lead to betterlexical weighting; second, Tdecipher contains new al-ternative translations for words observed in the par-allel corpus.Moreover, Decipher-OOV also achieves betterBLEU scores compared with PBMT across all tun-ing and test sets.
We also observe that systems us-ing Tdecipher learned by deciphering dependency bi-grams leads to larger gains in BLEU scores.
Whendecipherment is used to improve translation of bothobserved and OOV words, we see improvement inBLEU score as high as 1.8 points on the 2010 newstest set.The consistent improvement on the tuning anddifferent testing data suggests that decipherment iscapable of learning good translations for a numberof OOV words.
To further demonstrate that ourdecipherment approach finds useful translations forOOV words, we list the top 10 most frequent OOVwords from both the tuning set and testing set as wellas their translations (up to three most likely transla-tions) in Table 5.
P (e|f) and P (f |e) are averagescores over different decipherment runs.From the table, we can see that deciphermentfinds correct translations (bolded) for 7 out of the10 most frequent OOV words.
Moreover, manyOOVs and their correct translations are homographs, which makes copying OOVs directly to the outputa strong baseline to beat.
Nonetheless, deciphermentstill finds enough correct translations to improve thebaseline.6 ConclusionWe introduce syntax for deciphering Spanish intoEnglish.
Experiment results show that using de-pendency bigrams improves decipherment accuracyby over 500% compared with the state-of-the-artapproach.
Moreover, we learn a domain specifictranslation lexicon by deciphering large amounts ofmonolingual data and show that the lexicon can im-prove a baseline machine translation system trainedwith limited parallel data.1674Decipherment System Tune2008 Test2009 Test2010 Test2011None PBMT (Baseline) 19.1 19.6 21.3 22.1AdjacentDecipher-OBSV 19.5 20.1 22.2 22.6Decipher-OOV 19.4 19.9 21.7 22.5Decipher-COMB 19.5 20.2 22.3 22.5DependencyDecipher-OBSV 19.7 20.5 22.5 23.0Decipher-OOV 19.9 20.4 22.4 22.9Decipher-COMB 20.0 20.8 23.1 23.4Table 4: Systems that use translation lexicons learned from decipherment show consistent improvement over thebaseline system across tuning and testing sets.
The best system, Decipher-COMB, achieves as much as 1.8 BLEUpoint gain on the 2010 news test set.Spanish English P (e|f) P (f |e)obama his 0.33 0.01bush 0.27 0.07clinton 0.23 0.11bush bush 0.47 0.45yeltsin 0.28 0.81he 0.24 0.05festival event 0.68 0.35festival 0.61 0.72wikileaks zeta 0.03 0.33venus venus 0.61 0.74serena 0.47 0.62colchones mattresses 0.55 0.73cars 0.31 0.01helado frigid 0.52 0.44chill 0.37 0.14sandwich 0.42 0.27google microsoft 0.67 0.18google 0.59 0.69cantante singer 0.44 0.92jackson 0.14 0.33artists 0.14 0.77mccain mccain 0.66 0.92it 0.22 0.00he 0.21 0.00Table 5: Decipherment finds correct translations for 7 outof 10 most frequent OOV word types.7 AcknowledgmentsThis work was supported by NSF Grant 0904684and ARO grant W911NF-10-1-0533.
The authorswould like to thank David Chiang, Malte Nuhn,Victoria Fossum, Ashish Vaswani, Ulf Hermjakob,Yang Gao, and Hui Zhang (in no particular order)for their comments and suggestions.ReferencesShane Bergsma and Benjamin Van Durme.
2011.
Learn-ing bilingual lexicons using the visual similarity oflabeled web images.
In Proceedings of the Twenty-Second international joint conference on Artificial In-telligence - Volume Volume Three.
AAAI Press.Bernd Bohnet.
2010.
Top accuracy and fast dependencyparsing is not a contradiction.
In Proceedings of the23rd International Conference on Computational Lin-guistics.
Coling.Hal Daume?, III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by mining un-seen words.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies.
Association for Com-putational Linguistics.Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning.
Associa-tion for Computational Linguistics.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguisticsand 17th International Conference on Computational1675Linguistics - Volume 1.
Association for ComputationalLinguistics.Nikesh Garera, Chris Callison-Burch, and DavidYarowsky.
2009.
Improving translation lexicon induc-tion from monolingual corpora via dependency con-texts and part-of-speech equivalences.
In Proceed-ings of the Thirteenth Conference on ComputationalNatural Language Learning.
Association for Compu-tational Linguistics.Stuart Geman and Donald Geman.
1987.
Stochastic re-laxation, Gibbs distributions, and the Bayesian restora-tion of images.
In Readings in computer vision: is-sues, problems, principles, and paradigms.
MorganKaufmann Publishers Inc.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of ACL-08: HLT.
Association for Computational Linguistics.Ann Irvine and Chris Callison-Burch.
2013a.
Combin-ing bilingual and comparable corpora for low resourcemachine translation.
In Proceedings of the EighthWorkshop on Statistical Machine Translation.
Associ-ation for Computational Linguistics, August.Ann Irvine and Chris Callison-Burch.
2013b.
Supervisedbilingual lexicon induction with multiple monolingualsignals.
In Proceedings of the 2013 Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies.
Association for Computational Linguistics.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky.
2012.
Toward statisti-cal machine translation without parallel corpora.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics.
Association for Computational Linguistics.Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Ya-mada.
2006.
Unsupervised analysis for decipher-ment problems.
In Proceedings of the COLING/ACL2006 Main Conference Poster Sessions.
Associationfor Computational Linguistics.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In Pro-ceedings of the ACL-02 Workshop on UnsupervisedLexical Acquisition.
Association for ComputationalLinguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the ACL on Interac-tive Poster and Demonstration Sessions.
Associationfor Computational Linguistics.Philipp Koehn.
2005.
Europarl: a parallel corpus for sta-tistical machine translation.
In In Proceedings of theTenth Machine Translation Summit, Phuket, Thailand.Asia-Pacific Association for Machine Translation.Radford Neal.
2000.
Slice sampling.
Annals of Statis-tics, 31.Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining languagemodels and context vectors.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics: Long Papers - Volume 1.
Association forComputational Linguistics.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Comput.
Linguist.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofthe 41st Annual Meeting on Association for Computa-tional Linguistics.
Association for Computational Lin-guistics.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd annualmeeting on Association for Computational Linguistics.Association for Computational Linguistics.Sujith Ravi and Kevin Knight.
2011.
Deciphering for-eign language.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies.
Association forComputational Linguistics.Sujith Ravi.
2013.
Scalable decipherment for machinetranslation via hash sampling.
In Proceedings of the51th Annual Meeting of the Association for Computa-tional Linguistics.
Association for Computational Lin-guistics.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing.1676
