Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1363?1372,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsWatermarking the Outputs of Structured Prediction with anapplication in Statistical Machine Translation.Ashish Venugopal1 Jakob Uszkoreit1 David Talbot1 Franz J. Och1 Juri Ganitkevitch21Google, Inc. 2Center for Language and Speech Processing1600 Amphitheatre Parkway Johns Hopkins UniversityMountain View, 94303, CA Baltimore, MD 21218, USA{avenugopal,uszkoreit,talbot,och}@google.com juri@cs.jhu.eduAbstractWe propose a general method to water-mark and probabilistically identify thestructured outputs of machine learning al-gorithms.
Our method is robust to lo-cal editing operations and provides welldefined trade-offs between the ability toidentify algorithm outputs and the qual-ity of the watermarked output.
Unlikeprevious work in the field, our approachdoes not rely on controlling the inputs tothe algorithm and provides probabilisticguarantees on the ability to identify col-lections of results from one?s own algo-rithm.
We present an application in statis-tical machine translation, where machinetranslated output is watermarked at mini-mal loss in translation quality and detectedwith high recall.1 MotivationMachine learning algorithms provide structuredresults to input queries by simulating human be-havior.
Examples include automatic machinetranslation (Brown et al, 1993) or automatictext and rich media summarization (Goldsteinet al, 1999).
These algorithms often estimatesome portion of their models from publicly avail-able human generated data.
As new servicesthat output structured results are made avail-able to the public and the results disseminatedon the web, we face a daunting new challenge:Machine generated structured results contam-inate the pool of naturally generated humandata.
For example, machine translated outputand human generated translations are currentlyboth found extensively on the web, with no auto-matic way of distinguishing between them.
Al-gorithms that mine data from the web (Uszko-reit et al, 2010), with the goal of learning tosimulate human behavior, will now learn mod-els from this contaminated and potentially self-generated data, reinforcing the errors commit-ted by earlier versions of the algorithm.It is beneficial to be able to identify a set ofencountered structured results as having beengenerated by one?s own algorithm, with the pur-pose of filtering such results when building newmodels.Problem Statement: We define a struc-tured result of a query q as r = {z1 ?
?
?
zL} wherethe order and identity of elements zi are impor-tant to the quality of the result r. The structuralaspect of the result implies the existence of alter-native results (across both the order of elementsand the elements themselves) that might vary intheir quality.Given a collection of N results, CN =r1 ?
?
?
rN , where each result ri has k ranked alter-natives Dk(qi) of relatively similar quality andqueries q1 ?
?
?
qN are arbitrary and not controlledby the watermarking algorithm, we define thewatermarking task as:Task.
Replace ri with r?i ?
Dk(qi) for some sub-set of results in CN to produce a watermarkedcollection C?Nsuch that:?
C?N is probabilistically identifiable as havingbeen generated by one?s own algorithm.1363?
the degradation in quality from CN to thewatermarked C?N should be analytically con-trollable, trading quality for detection per-formance.?
C?N should not be detectable as water-marked content without access to the gen-erating algorithms.?
the detection of C?N should be robust to sim-ple edit operations performed on individualresults r ?
C?N .2 Impact on Statistical MachineTranslationRecent work(Resnik and Smith, 2003; Munteanuand Marcu, 2005; Uszkoreit et al, 2010) hasshown that multilingual parallel documents canbe efficiently identified on the web and used astraining data to improve the quality of statisti-cal machine translation.The availability of free translation services(Google Translate, Bing Translate) and tools(Moses, Joshua), increase the risk that the con-tent found by parallel data mining is in fact gen-erated by a machine, rather than by humans.
Inthis work, we focus on statistical machine trans-lation as an application for watermarking, withthe goal of discarding documents from trainingif they have been generated by one?s own algo-rithms.To estimate the magnitude of the problem,we used parallel document mining (Uszkoreit etal., 2010) to generate a collection of bilingualdocument pairs across several languages.
Foreach document, we inspected the page contentfor source code that indicates the use of trans-lation modules/plug-ins that translate and pub-lish the translated content.We computed the proportion of the contentwithin our corpus that uses these modules.
Wefind that a significant proportion of the minedparallel data for some language pairs is gener-ated via one of these translation modules.
Thetop 3 languages pairs, each with parallel trans-lations into English, are Tagalog (50.6%), Hindi(44.5%) and Galician (41.9%).
While theseproportions do not reflect impact on each lan-guage?s monolingual web, they are certainly highenough to affect machine translations systemsthat train on mined parallel data.
In this work,we develop a general approach to watermarkstructured outputs and apply it to the outputsof a statistical machine translation system withthe goal of identifying these same outputs on theweb.
In the context of the watermarking taskdefined above, we output selecting alternativetranslations for input source sentences.
Thesetranslations often undergo simple edit and for-matting operations such as case changes, sen-tence and word deletion or post editing, prior topublishing on the web.
We want to ensure thatwe can still detect watermarked translations de-spite these edit operations.
Given the rapid paceof development within machine translation, itis also important that the watermark be robustto improvements in underlying translation qual-ity.
Results from several iterations of the systemwithin a single collection of documents should beidentifiable under probabilistic bounds.While we present evaluation results for sta-tistical machine translation, our proposed ap-proach and associated requirements are applica-ble to any algorithm that produces structuredresults with several plausible alternatives.
Thealternative results can arise as a result of inher-ent task ambiguity (for example, there are mul-tiple correct translations for a given input sourcesentence) or modeling uncertainty (for example,a model assigning equal probability to two com-peting results).3 Watermark Structured ResultsSelecting an alternative r?
from the space of al-ternatives Dk(q) can be stated as:r?
= arg maxr?Dk(q)w(r,Dk(q), h) (1)where w ranks r ?
Dk(q) based on r?s presen-tation of a watermarking signal computed by ahashing operation h. In this approach, w andits component operation h are the only secretsheld by the watermarker.
This selection crite-rion is applied to all system outputs, ensuringthat watermarked and non-watermarked versionof a collection will never be available for compar-ison.1364A specific implementation of w within our wa-termarking approach can be evaluated by thefollowing metrics:?
False Positive Rate: how often non-watermarked collections are falsely identi-fied as watermarked.?
Recall Rate: how often watermarked col-lections are correctly identified as water-marked.?
Quality Degradation: how significantlydoes C?N differ from CN when evaluated bytask specific quality metrics.While identification is performed at the col-lection level, we can scale these metrics basedon the size of each collection to provide moretask sensitive metrics.
For example, in machinetranslation, we count the number of words inthe collection towards the false positive and re-call rates.In Section 3.1, we define a random hashingoperation h and a task independent implemen-tation of the selector function w. Section 3.2describes how to classify a collection of water-marked results.
Section 3.3 and 3.4 describes re-finements to the selection and classification cri-teria that mitigate quality degradation.
Follow-ing a comparison to related work in Section 4,we present experimental results for several lan-guages in Section 5.3.1 Watermarking: CN ?
C?NWe define a random hashing operation h that isapplied to result r. It consists of two compo-nents:?
A hash function applied to a structured re-sult r to generate a bit sequence of a fixedlength.?
An optional mapping that maps a singlecandidate result r to a set of sub-results.Each sub-result is then hashed to generatea concatenated bit sequence for r.A good hash function produces outputs whosebits are independent.
This implies that we cantreat the bits for any input structured resultsas having been generated by a binomial distri-bution with equal probability of generating 1svs 0s.
This condition also holds when accu-mulating the bit sequences over a collection ofresults as long as its elements are selected uni-formly from the space of possible results.
There-fore, the bits generated from a collection of un-watermarked results will follow a binomial dis-tribution with parameter p = 0.5.
This resultprovides a null hypothesis for a statistical teston a given bit sequence, testing whether it islikely to have been generated from a binomialdistribution binomial(n, p) where p = 0.5 and nis the length of the bit sequence.For a collection CN = r1 ?
?
?
rN , we can definea watermark ranking function w to systemati-cally select alternatives r?i ?
Dk(q), such thatthe resulting C?N is unlikely to produce bit se-quences that follow the p = 0.5 binomial distri-bution.
A straightforward biasing criteria wouldbe to select the candidate whose bit sequence ex-hibits the highest ratio of 1s.
w can be definedas:w(r,Dk(q), h) =#(1, h(r))|h(r)| (2)where h(r) returns the randomized bit sequencefor result r, and #(x, ~y) counts the number ofoccurrences of x in sequence ~y.
Selecting alter-natives results to exhibit this bias will result inwatermarked collections that exhibit this samebias.3.2 Detecting the WatermarkTo classify a collection CN as watermarked ornon-watermarked, we apply the hashing opera-tion h on each element in CN and concatenatethe sequences.
This sequence is tested againstthe null hypothesis that it was generated by abinomial distribution with parameter p = 0.5.We can apply a Fisherian test of statistical sig-nificance to determine whether the observed dis-tribution of bits is unlikely to have occurred bychance under the null hypothesis (binomial withp = 0.5).We consider a collection of results that rejectsthe null hypothesis to be watermarked resultsgenerated by our own algorithms.
The p-valueunder the null hypothesis is efficiently computed1365by:p?
value = Pn(X ?
x) (3)=n?i=x(ni)pi(1?
p)n?i (4)where x is the number of 1s observed in the col-lection, and n is the total number of bits in thesequence.
Comparing this p-value against a de-sired significance level ?, we reject the null hy-pothesis for collections that have Pn(X ?
x) <?, thus deciding that such collections were gen-erated by our own system.This classification criteria has a fixed falsepositive rate.
Setting ?
= 0.05, we know that5% of non-watermarked bit sequences will befalsely labeled as watermarked.
This parameter?
can be controlled on an application specific ba-sis.
By biasing the selection of candidate resultsto produce more 1s than 0s, we have defineda watermarking approach that exhibits a fixedfalse positive rate, a probabilistically boundeddetection rate and a task independent hashingand selection criteria.
In the next sections, wewill deal with the question of robustness to editoperations and quality degradation.3.3 Robustness and Inherent BiasWe would like the ability to identify water-marked collections to be robust to simple editoperations.
Even slight modifications to the ele-ments within an item r would yield (by construc-tion of the hash function), completely differentbit sequences that no longer preserve the biasesintroduced by the watermark selection function.To ensure that the distributional biases intro-duced by the watermark selector are preserved,we can optionally map individual results into aset of sub-results, each one representing some lo-cal structure of r. h is then applied to each sub-result and the results concatenated to representr.
This mapping is defined as a component ofthe h operation.While a particular edit operation might af-fect a small number of sub-results, the majorityof the bits in the concatenated bit sequence forr would remain untouched, thereby limiting thedamage to the biases selected during watermark-ing.
This is of course no defense to edit opera-tions that are applied globally across the result;our expectation is that such edits would eithersignificantly degrade the quality of the result orbe straightforward to identify directly.For example, a sequence of words r = z1 ?
?
?
zLcan be mapped into a set of consecutive n-gramsequences.
Operations to edit a word zi in r willonly affect events that consider the word zi.
Toaccount for the fact that alternatives in Dk(q)might now result in bit sequences of differentlengths, we can generalize the biasing criteria todirectly reflect the expected contribution to thewatermark by defining:w(r,Dk(q), h) = Pn(X ?
#(1, h(r))) (5)where Pn gives probabilities from binomial(n =|h(r)|, p = 0.5).Inherent collection level biases: Our nullhypothesis is based on the assumption that col-lections of results draw uniformly from the spaceof possible results.
This assumption might notalways hold and depends on the type of the re-sults and collection.
For example, consideringa text document as a collection of sentences,we can expect that some sentences might repeatmore frequently than others.This scenario is even more likely when ap-plying a mapping into sub-results.
n-gram se-quences follow long-tailed or Zipfian distribu-tions, with a small number of n-grams contribut-ing heavily toward the total number of n-gramsin a document.A random hash function guarantees that in-puts are distributed uniformly at random overthe output range.
However, the same input willbe assigned the same output deterministically.Therefore, if the distribution of inputs is heav-ily skewed to certain elements of the input space,the output distribution will not be uniformlydistributed.
The bit sequences resulting fromthe high frequency sub-results have the potentialto generate inherently biased distributions whenaccumulated at the collection level.
We want tochoose a mapping that tends towards generatinguniformly from the space of sub-results.
We canempirically measure the quality of a sub-resultmapping for a specific task by computing the1366false positive rate on non-watermarked collec-tions.
For a given significance level ?, an idealmapping would result in false positive rates closeto ?
as well.Figure 1 shows false positive rates from 4 al-ternative mappings, computed on a large corpusof French documents (see Table 1 for statistics).Classification decisions are made at the collec-tion level (documents) but the contribution tothe false positive rate is based on the numberof words in the classified document.
We con-sider mappings from a result (sentence) into its1-grams, 1 ?
5-grams and 3 ?
5 grams as wellas the non-mapping case, where the full resultis hashed.Figure 1 shows that the 1-grams and 1 ?
5-gram generate sub-results that result in heav-ily biased false positive rates.
The 3 ?
5 grammapping yields false positive rates close to theirtheoretically expected values.
1 Small devia-tions are expected since documents make differ-ent contributions to the false positive rate as afunction of the number of words that they repre-sent.
For the remainder of this work, we use the3-5 gram mapping and the full sentence map-ping, since the alternatives generate inherentlydistributions with very high false positive rates.3.4 Considering QualityThe watermarking described in Equation 3chooses alternative results on a per result basis,with the goal of influencing collection level bitsequences.
The selection criteria as describedwill choose the most biased candidates availablein Dk(q).
The parameter k determines the ex-tent to which lesser quality alternatives can bechosen.
If all the alternatives in each Dk(q) areof relatively similar quality, we expect minimaldegradation due to watermarking.Specific tasks however can be particularly sen-sitive to choosing alternative results.
Discrimi-native approaches that optimize for arg max se-lection like (Och, 2003; Liang et al, 2006; Chi-ang et al, 2009) train model parameters such1In the final version of this paper we will perform sam-pling to create a more reliable estimate of the false posi-tive rate that is not overly influenced by document lengthdistributions.that the top-ranked result is well separated fromits competing alternatives.
Different queries alsodiffer in the inherent ambiguity expected fromtheir results; sometimes there really is just onecorrect result for a query, while for other queries,several alternatives might be equally good.By generalizing the definition of the w func-tion to interpolate the estimated loss in qualityand the gain in the watermarking signal, we cantrade-off the ability to identify the watermarkedcollections against quality degradation:w(r,Dk(q), fw) = ?
?
gain(r,Dk(q), fw)?(1?
?)
?
loss(r,Dk(q))(6)Loss: The loss(r,Dk(q)) function reflects thequality degradation that results from selectingalternative r as opposed to the best ranked can-didate in Dk(q)).
We will experiment with twovariants:lossrank(r,Dk(q)) = (rank(r)?
k)/klosscost(r,Dk(q)) = (cost(r)?cost(r1))/ cost(r1)where:?
rank(r): returns the rank of r within Dk(q).?
cost(r): a weighted sum of features (notnormalized over the search space) in a log-linear model such as those mentioned in(Och, 2003).?
r1: the highest ranked alternative in Dk(q).lossrank provides a generally applicable criteriato select alternatives, penalizing selection fromdeep within Dk(q).
This estimate of the qual-ity degradation does not reflect the generatingmodel?s opinion on relative quality.
losscost con-siders the relative increase in the generatingmodel?s cost assigned to the alternative trans-lation.Gain: The gain(r,Dk(q), fw) function reflectsthe gain in the watermarking signal by selectingcandidate r. We simply define the gain as thePn(X ?
#(1, h(r))) from Equation 5.13670 0.2 0.4 0.6 0.8 1 0.05 0.10 0.25 0.5portion of documents p-value thresholdexpectedobserved(a) 1-grams mapping0 0.2 0.4 0.6 0.8 1 0.05 0.10 0.25 0.5portion of documents p-value thresholdexpectedobserved(b) 1?
5-grams mapping0 0.2 0.4 0.6 0.8 1 0.05 0.10 0.25 0.5portion of documents p-value thresholdexpectedobserved(c) 3?
5-grams mapping0 0.2 0.4 0.6 0.8 1 0.05 0.10 0.25 0.5portion of documents p-value thresholdexpectedobserved(d) Full result hashingFigure 1: Comparison of expected false positive rates against observed false positive rates for differentsub-result mappings.4 Related WorkUsing watermarks with the goal of transmittinga hidden message within images, video, audioand monolingual text media is common.
Forstructured text content, linguistic approacheslike (Chapman et al, 2001; Gupta et al, 2006)use language specific linguistic and semanticexpansions to introduce hidden watermarks.These expansions provide alternative candidateswithin which messages can be encoded.
Re-cent publications have extended this idea to ma-chine translation, using multiple systems andexpansions to generate alternative translations.
(Stutsman et al, 2006) uses a hashing functionto select alternatives that encode the hiddenmessage in the lower order bits of the transla-tion.
In each of these approaches, the water-marker has control over the collection of resultsinto which the watermark is to be embedded.These approaches seek to embed a hiddenmessage into a collection of results that is se-lected by the watermarker.
In contrast, we ad-dress the condition where the input queries arenot in the watermarker?s control.The goal is therefore to introduce the water-mark into all generated results, with the goal ofprobabilistically identifying such outputs.
Ourapproach is also task independent, avoiding theneed for templates to generate additional al-ternatives.
By addressing the problem directlywithin the search space of a dynamic program-ming algorithm, we have access to high qualityalternatives with well defined models of qual-ity loss.
Finally, our approach is robust to localword editing.
By using a sub-result mapping, weincrease the level of editing required to obscurethe watermark signal; at high levels of editing,the quality of the results themselves would besignificantly degraded.5 ExperimentsWe evaluate our watermarking approach appliedto the outputs of statistical machine translationunder the following experimental setup.A repository of parallel (aligned source andtarget language) web documents is sampled toproduce a large corpus on which to evaluate thewatermarking classification performance.
The1368corpora represent translations into 4 diverse tar-get languages, using English as the source lan-guage.
Each document in this corpus can beconsidered a collection of un-watermarked struc-tured results, where source sentences are queriesand each target sentence represents a structuredresult.Using a state-of-the-art phrase-based statisti-cal machine translation system (Och and Ney,2004) trained on parallel documents identifiedby (Uszkoreit et al, 2010), we generate a setof 100 alternative translations for each sourcesentence.
We apply the proposed watermarkingapproach, along with the proposed refinementsthat address task specific loss (Section 3.4) androbustness to edit operations (Section 3.3) togenerate watermarked corpora.Each method is controlled via a single param-eter (like k or ?)
which is varied to generatealternative watermarked collections.
For eachparameter value, we evaluate the Recall Rateand Quality Degradation with the goal of find-ing a setting that yields a high recall rate, min-imal quality degradation.
False positive ratesare evaluated based on a fixed classification sig-nificance level of ?
= 0.05.
The false posi-tive and recall rates are evaluated on the wordlevel; a document that is misclassified or cor-rectly identified contributes its length in wordstowards the error calculation.
In this work, weuse ?
= 0.05 during classification correspondingto an expected 5% false positive rate.
The falsepositive rate is a function of h and the signifi-cance level ?
and therefore constant across theparameter values k and ?.We evaluate quality degradation on humantranslated test corpora that are more typical formachine translation evaluation.
Each test cor-pus consists of 5000 source sentences randomlyselected from the web and translated into eachrespective language.We chose to evaluate quality on test corporato ensure that degradations are not hidden byimperfectly matched web corpora and are con-sistent with the kind of results often reported formachine translation systems.
As with the clas-sification corpora, we create watermarked ver-sions at each parameter value.
For a given pa--1.4-1.2-1-0.8-0.6-0.4-0.200.5  0.6  0.7  0.8  0.9  1BLEUlossrecallFRENCH max K-BestFRENCH model cost gainFRENCH rank gainFigure 2: BLEU loss against recall of watermarkedcontent for the baseline approach (max K-best),rank and cost interpolation.rameter value, we measure false positive and re-call rates on the classification corpora and qual-ity degradation on the evaluation corpora.Table 1 shows corpus statistics for the classi-fication and test corpora and non-watermarkedBLEU scores for each target language.
Allsource texts are in English.5.1 Loss Interpolated ExperimentsOur first set of experiments demonstrates base-line performance using the watermarking crite-ria in Equation 5 versus the refinements sug-gested in Section 3.4 to mitigate quality degra-dation.
The h function is computed on the fullsentence result r with no sub-event mapping.The following methods are evaluated in Figure 2.?
Baseline method (labeled ?max K-best?
):selects r?
purely based on gain in water-marking signal (Equation 5) and is param-eterized by k: the number of alternativesconsidered for each result.?
Rank interpolation: incorporates rank intow, varying the interpolation parameter ?.?
Cost interpolation: incorporates cost intow, varying the interpolation parameter ?.The observed false positive rate on the Frenchclassification corpora is 1.9%.1369Classification QualityTarget # words # sentences # documents # words # sentences BLEU %Arabic 200107 15820 896 73592 5503 12.29French 209540 18024 600 73592 5503 26.45Hindi 183676 13244 1300 73409 5489 20.57Turkish 171671 17155 1697 73347 5486 13.67Table 1: Content statistics for classification and quality degradation corpora.
Non-watermarked BLEUscores are reported for the quality corpora.We consider 0.2% BLEU loss as a thresh-old for acceptable quality degradation.
Eachmethod is judged by its ability to achieve highrecall below this quality degradation threshold.Applying cost interpolation yields the bestresults in Figure 2, achieving a recall of 85%at 0.2% BLEU loss, while rank interpolationachieves a recall of 76%.
The baseline approachof selecting the highest gain candidate within adepth of k candidates does not provide sufficientparameterization to yield low quality degrada-tion.
At k = 2, this method yields almost 90%recall, but with approximately 0.4% BLEU loss.5.2 Robustness ExperimentsIn Section 5.2, we proposed mapping results intosub-events or features.
We considered alterna-tive feature mappings in Figure 1, finding thatmapping sentence results into a collection of 3-5 grams yields acceptable false positive rates atvaried levels of ?.Figure 3 presents results that compare mov-ing from the result level hashing to the 3-5 gramsub-result mapping.
We show the impact of themapping on the baseline max K-best method aswell as for cost interpolation.
There are sub-stantial reductions in recall rate at the 0.2%BLEU loss level when applying sub-result map-pings in cases.
The cost interpolation methodrecall drops from 85% to 77% when using the3-5 grams event mapping.
The observed falsepositive rate of the 3-5 gram mapping is 4.7%.By using the 3-5 gram mapping, we expectto increase robustness against local word editoperations, but we have sacrificed recall rate dueto the inherent distributional bias discussed inSection 3.3.-1.4-1.2-1-0.8-0.6-0.4-0.200.5  0.6  0.7  0.8  0.9  1BLEUlossrecallFRENCH nbest max K-best full sentenceFRENCH max K-best 3-5 gramsFRENCH cost interp.
full sentenceFRENCH cost interp.
3-5 gramsFigure 3: BLEU loss against recall of watermarkedcontent for the baseline and cost interpolation meth-ods using both result level and 3-5 gram mappedevents.5.3 Multilingual ExperimentsThe watermarking approach proposed here in-troduces no language specific watermarking op-erations and it is thus broadly applicable totranslating into all languages.
In Figure 4, wereport results for the baseline and cost interpola-tion methods, considering both the result leveland 3-5 gram mapping.
We set ?
= 0.05 andmeasure recall at 0.2% BLEU degradation fortranslation from English into Arabic, French,Hindi and Turkish.
The observed false posi-tive rates for full sentence hashing are: Arabic:2.4%, French: 1.8%, Hindi: 5.6% and Turkish:5.5%, while for the 3-5 gram mapping, they are:Arabic: 5.8%, French: 7.5%, Hindi:3.5% andTurkish: 6.2%.
Underlying translation qual-ity plays an important role in translation qual-ity degradation when watermarking.
Withouta sub-result mapping, French (BLEU: 26.45%)13700.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 Arabic French Hindi Turkishrecall sentence-level3-to-5 gramsFigure 4: Loss of recall when using 3-5 gram mappingvs sentence level mapping for Arabic, French, Hindiand Turkish translations.achieves recall of 85% at 0.2% BLEU loss, whilethe other languages achieve over 90% recall atthe same BLEU loss threshold.
Using a sub-result mapping degrades quality for each lan-guage pair, but changes the relative perfor-mance.
Turkish experiences the highest rela-tive drop in recall, unlike French and Arabic,where results are relatively more robust to usingsub-sentence mappings.
This is likely a result ofdifferences in n-gram distributions across theselanguages.
The languages considered here alluse space separated words.
For languages thatdo not, like Chinese or Thai, our approach canbe applied at the character level.6 ConclusionsIn this work we proposed a general methodto watermark and probabilistically identify thestructured outputs of machine learning algo-rithms.
Our method provides probabilisticbounds on detection ability, analytic control onquality degradation and is robust to local edit-ing operations.
Our method is applicable toany task where structured outputs are generatedwith ambiguities or ties in the results.
We ap-plied this method to the outputs of statisticalmachine translation, evaluating each refinementto our approach with false positive and recallrates against BLEU score quality degradation.Our results show that it is possible, across sev-eral language pairs, to achieve high recall rates(over 80%) with low false positive rates (between5 and 8%) at minimal quality degradation (0.2%BLEU), while still allowing for local edit opera-tions on the translated output.
In future workwe will continue to investigate methods to mit-igate quality loss.ReferencesThorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Minimum error ratetraining in statistical machine translation.
In Pro-ceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning.Peter F. Brown, Vincent J.Della Pietra, StephenA.
Della Pietra, and Robert.
L. Mercer.
1993.The mathematics of statistical machine transla-tion: Parameter estimation.
Computational Lin-guistics, 19:263?311.Mark Chapman, George Davida, and MarcRennhardway.
2001.
A practical and effec-tive approach to large-scale automated linguisticsteganography.
In Proceedings of the InformationSecurity Conference.David Chiang, Kevin Knight, and Wei Wang.
2009.11,001 new features for statistical machine trans-lation.
In North American Chapter of the Associa-tion for Computational Linguistics - Human Lan-guage Technologies (NAACL-HLT).Jade Goldstein, Mark Kantrowitz, Vibhu Mittal, andJaime Carbonell.
1999.
Summarizing text docu-ments: Sentence selection and evaluation metrics.In Research and Development in Information Re-trieval, pages 121?128.Gaurav Gupta, Josef Pieprzyk, and Hua XiongWang.
2006.
An attack-localizing watermarkingscheme for natural language documents.
In Pro-ceedings of the 2006 ACM Symposium on Informa-tion, computer and communications security, ASI-ACCS ?06, pages 157?165, New York, NY, USA.ACM.Percy Liang, Alexandre Bouchard-Cote, Dan Klein,and Ben Taskar.
2006.
An end-to-end dis-criminative approach to machine translation.
InProceedings of the Joint International Conferenceon Computational Linguistics and Association ofComputational Linguistics (COLING/ACL, pages761?768.Dragos Stefan Munteanu and Daniel Marcu.
2005.Improving machine translation performance by ex-ploiting non-parallel corpora.
Computational Lin-guistics.Franz Josef Och and Hermann Ney.
2004.
The1371alignment template approach to statistical ma-chine translation.
Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedingsof the 2003 Meeting of the Asssociation of Com-putational Linguistics.Philip Resnik and Noah A. Smith.
2003.
The web asa parallel corpus.
computational linguistics.
Com-putational Linguistics.Ryan Stutsman, Mikhail Atallah, ChristianGrothoff, and Krista Grothoff.
2006.
Lostin just the translation.
In Proceedings of the 2006ACM Symposium on Applied Computing.Jakob Uszkoreit, Jay Ponte, Ashok Popat, andMoshe Dubiner.
2010.
Large scale parallel doc-ument mining for machine translation.
In Pro-ceedings of the 2010 COLING.1372
