Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 699?703,Dublin, Ireland, August 23-24, 2014.UIO-Lien: Entailment Recognition using Minimal Recursion SemanticsElisabeth LienDepartment of InformaticsUniversity of Oslo, Norwayelien@ifi.uio.noMilen KouylekovDepartment of InformaticsUniversity of Oslo, Norwaymilen@ifi.uio.noAbstractIn this paper we present our participa-tion in the Semeval 2014 task ?Evalu-ation of compositional distributional se-mantic models on full sentences throughsemantic relatedness and textual entail-ment?.
Our results demonstrate that us-ing generic tools for semantic analysis is aviable option for a system that recognizestextual entailment.
The invested effort indeveloping such tools allows us to buildsystems for reasoning that do not requiretraining.1 IntroductionRecognizing textual entailment (RTE) has been apopular area of research in the last years.
It hasappeared in a variety of evaluation campaigns asboth monolingual and multilingual tasks.
A widevariety of techniques based on different levels oftext interpretation has been used, e.g., lexical dis-tance, dependency parsing and semantic role la-beling (Androutsopoulos and Malakasiotis, 2010).Our approach uses a semantic representationformalism called Minimal Recursion Semantics(MRS), which, to our knowledge, has not beenused extensively in entailment decision systems.Notable examples of systems that use MRS areWotzlaw and Coote (2013), and Bergmair (2010).In Wotzlaw and Coote (2013), the authors presentan entailment recognition system which combineshigh-coverage syntactic and semantic text analysiswith logical inference supported by relevant back-ground knowledge.
MRS is used as an interme-diate format in transforming the results of the lin-guistic analysis into representations used for log-ical reasoning.
The approach in Bergmair (2010)This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/uses the syllogism as an approximation of naturallanguage reasoning.
MRS is used as a step in thetranslation of natural language sentences into logi-cal formulae that are suitable for processing.
Bothworks describe approaches that can be adaptedto RTE, but no empirical evaluation is includedto demonstrate the potential of the proposed ap-proaches.In contrast to these approaches, our systembases entailment decision directly on the MRSrepresentations.
Graph alignment over MRS rep-resentations forms the basis for entailment recog-nition.
If key nodes in the hypothesis MRS can bealigned to nodes in the text MRS, this is treated asan indicator of entailment.This paper represents our first attempt to evalu-ate a system based on logical-form semantic rep-resentations in a RTE competition.
Using a state-of-the-art semantic analysis component, we havecreated a generic rule-based system for recogniz-ing textual entailment that obtains competitive re-sults on a real evaluation dataset.
Our approachdoes not require training.
We confront it witha strong baseline provided by the EDITS system(Kouylekov et al., 2011).In Section 2 we describe the computational se-mantics framework that forms the basis of our ap-proach.
Section 3 details our entailment system,and in Section 4 we analyze our results from thetask evaluation.2 Minimal Recursion SemanticsMinimal Recursion Semantics (MRS) (Copestakeet al., 2005) is a framework for computational se-mantics which provides expressive representationswith a clear interface with syntax.
MRS allowsunderspecification of scope, in order to capture thedifferent readings of a sentence with a single MRSrepresentation.
We use the MRS analyses that areproduced by the HPSG English Resource Gram-mar (ERG) (Flickinger, 2000).699The core of an MRS representation is a mul-tiset of relations, called elementary predications(EPs).
An EP represents a single lexeme, or gen-eral grammatical features.
Each EP has a predi-cate symbol, and a label (also called handle) thatidentifies the EPs position within the MRS struc-ture.
Each EP contains a list of numbered argu-ments: ARG0, ARG1, etc., whose values are scopalor non-scopal variables.
The ARG0 value is calledthe EP?s distinguished variable, and denotes anevent or state, or an entity.Finally, an MRS has a set of handle constraintswhich describe how the scopal arguments of theEPs can be equated with EP labels.
A constrainthi=qhjdenotes equality modulo quantifier inser-tion.
EPs are directly and indirectly linked throughhandle constraints and variable sharing, and the re-sulting MRS forms a connected graph.In Figure 1, we see an MRS for the sentenceA woman is cutting a potato.
The topmost EP,cut v 1, has a list of three argument-value pairs:its distinguished variable e3denotes an event, andthe variables x6and x9refer to the entities fillingthe agent and patient roles in the verb event.
x6and x9are in turn the distinguished variables ofthe EPs that represent a woman and a potato, re-spectively.3 System DescriptionIn the following, Tsentand Hsentrefer to the textand hypothesis sentence, and Tmrsand Hmrstotheir MRS representations.The core of our system is a rule based compo-nent, which bases entailment decision on graphalignment over MRS structures.
An earlier ver-sion of the system is described in Lien (2014).The earlier version was developed on the data setfrom the SemEval-2010 shared task Parser Eval-uation using Textual Entailment (PETE) (Yuret etal., 2010).
Using no external linguistic resources,the system output positive entailment decisions forsentence pairs where core nodes of the Hmrscouldbe aligned to nodes in Tmrsaccording to a set ofheuristic matching rules.
The system we presentin this paper extends the earlier version by addingsupport for contradiction recognition, and by us-ing lexical relations from WordNet.For our participation in the entailment recogni-tion task, first, we did an analysis of the SICK trialdata.
In the ENTAILMENT pairs, Hsentis a para-phrase over the whole or part of the text sentence.The changes from Tsentto Hsentcan be syntactic(e.g., active-passive conversion), lexical (e.g., syn-onymy, hyponymy-hypernymy, multiword expres-sions replaced by single word), or Tsentcontainssome element that does not appear in Hsent(e.g.,Tsentis a conjunction and Hsentone of its con-juncts, a modifier in Tsentis left out of Hsent).
Inthe CONTRADICTION category, the sentences ofa pair are also basically the same or paraphrases,and a negation or a pair of antonymous expres-sions create the contradiction.
The NEUTRALpairs often have a high degree of word overlap, butHsentcannot be inferred from Tsent.
Our systemaccounts for many of these characteristics.The system bases its decision on the results oftwo procedures: a) an event relation match whichsearches for an alignment between the MRSs, andb) a contradiction cue check.
After running theseprocedures, the system outputs1.
ENTAILMENT, if the event relation match-ing procedure found an alignment, and nocontradiction cues were found,2.
CONTRADICTION, if contradiction cueswere found,3.
NEUTRAL, if neither of the above condi-tions are met.The event relation matching procedure extendsthe one developed in Lien (2014) to account forthe greater lexical variation in the SICK data.
Theprocedure selects all the EPs in Tmrsand Hmrsthat have an event variable as their ARG0?we callthem event relations.
These event relations mainlyrepresent verbs, verb conjunctions, adjectives, andprepositions.
For each event relation Heventin thehypothesis the procedure tries to find a matchingrelation Teventamong the text event relations.
Wesay that Heventmatches Teventif:1. they represent the same lexeme with thesame part-of-speech, or if both are verbs andHeventis a synonym or hypernym of Tevent,and2.
all their arguments match.
Two event rela-tion arguments in the same argument positionmatch if:?
they are the same or synonymous, or theHeventargument is a hypernym of theTeventargument, or700?h1,h4: a q?0:1?
(ARG0 x6, RSTR h7, BODY h5),h8: woman n 1?2:7?
(ARG0 x6),h2: cut v 1?11:18?
(ARG0 e3, ARG1 x6, ARG2 x9),h10: a q?19:20?
(ARG0 x9, RSTR h12, BODY h11),h13: potato n 1?21:28?
(ARG0 x9){h12=qh13, h7=qh8, h1=qh2} ?Figure 1: MRS for A woman is cutting a potato (pair 4661, SICK trial data).?
the argument in Teventrepresents a nounphrase and the argument in Heventis anunderspecified pronoun like somebody,or?
the argument in Teventis either a sco-pal relation or a conjunction relation,and one of its arguments matches that ofHevent, or?
the argument in Heventis not expressed(i.e., it matches the Teventargument bydefault)The matching procedure does not search formore than one alignment between the event rela-tions of Hmrsand Tmrs.The contradiction cue procedure checkswhether the MRS pairs contain relations express-ing negation.
The quantifier no q rel negatesan entity (e.g., no man), whereas neg reldenotes sentence negation.
If a negation relationappears in one but not the other MRS, we treatthis as an indicator of CONTRADICTION.Example: Figure 1 shows the MRS analysis ofthe hypothesis in the entailment pair A womanis slicing a potato ?
A woman is cutting apotato.
There is only one event relation in Hmrs:cut v 1.
Tmrsis an equivalent structure withone event relation slice v 1.
Using Word-Net, the system finds that cut v 1 is a hyper-nym of slice v 1.
Then, the system comparesthe ARG1 and ARG2 values of the event relations.The arguments match since they are the same re-lations.
There are no contradiction cues in eitherof the MRSs, so the system correctly outputs EN-TAILMENT.If we look at the rule based component?s output(Table 1) for the 481 of the 500 SICK trial sen-tence pairs for which the ERG produced MRSs,we get a picture of how well it covers the phenom-ena in the data set:Of the 134 ENTAILMENT pairs, 59 were para-phrases where the variation was relatively limitedgold ENT gold CON gold NEUsys ENT 59 0 1sys CON 0 51 14sys NEU 75 22 259Table 1: Output for the system on SICK trial data.and could be captured by looking for synonyms,hyponyms, and treating the hypothesis as a sub-graph of the text.
The simple contradiction cuecheck, which looks for negation relations, covered51 of 73 CONTRADICTION pairs.75 ENTAILMENT and 22 CONTRADICTIONpairs were not captured by the matching and con-tradiction cue procedures.
Almost 30% of theENTAILMENT pairs had word pairs whose lex-ical relationship was not recognized using Word-Net (e.g.
: playing a guitar?
strumming a guitar).In the other pairs there were alternations betweensimple and more complex noun phrases (protec-tive gear ?
gear used for protection), change ofpart-of-speech from Tsentto Hsentfor the samemeaning entities (It is raining on a walking man?A man is walking in the rain); some pairs requiredreasoning, and in some cases Hsentcontained in-formation not present in Tsent.
In some cases, en-tailment recognition fails because the MRS analy-sis is not correct (e.g., misrepresentation of passiveconstructions).The contradiction cue check did not look forantonymous words and expressions, and this ac-counts for almost half of the missing CONTRA-DICTION pairs.
The rest contained negation,but were misclassified either because an incorrectMRS analysis was chosen by the parser or becausesynonymous words within the scope of the nega-tion were not recognized.EDITS We used a backoff-system for the pairswhen the rule-based system fails to produce re-701System 1 2 3 4 5Rules Only Rules Only Combined Combined EditsTraining 76.13 75.4 76.62 76.62 74.78Test 77.0 76.35 77.12 77.14 74.79Table 2: Submitted system accuracy on training and test set.sults.
Our choice was EDITS1as it providesa strong baseline system for recognizing textualentailment (Kouylekov et al., 2011).
EDITS(Kouylekov and Negri, 2010) is an open sourcepackage which offers a modular, flexible, andadaptable working environment for experimentingwith the RTE task over different datasets.
Thepackage allows to: i) create an entailment engineby defining its basic components; ii) train thisentailment engine over an annotated RTE corpusto learn a model and iii) use the entailment en-gine and the model to assign an entailment judg-ment and a confidence score to each pair of an un-annotated test corpus.We used two strategies for combining the rule-based system with EDITS: Our first strategy wasto let the rule-based system classify those sentencepairs for which the ERG could produce MRSs, anduse EDITS for the pairs were we did not haveMRSs (or processing failed due to errors in theMRSs) .
The second strategy was to mix the out-put from both systems when they disagree.
In thiscase we took the ENTAILMENT decisions fromthe rule-based, and EDITS contributes with CON-TRADICTION and NEUTRAL.4 AnalysisWe have submitted the results obtained from fivesystem configurations.
The first four used the rule-based system as the core.
The fifth was a systemobtained by training EDITS on the training set.We use the fifth system as a strong baseline.
Inthe few cases in which the rule-based system didnot produce result (2% of the test set pairs) EDITSjudgments were used in the submission.
In System1 and System 2 we have used the first combinationstrategy described in the end of section 3.
In Sys-tem 4 and System 5 the entailment decisions are acombination of the results from the rule-based sys-tem and EDITS as described in the second strategyin the same section.
The rule-based componentin System 1 and System 3 has more fine-grained1http://edits.sf.netPrecision Recall F-MeasureContradiction 0.8422 0.7264 0.78Entailment 0.9719 0.4158 0.5825Neutral 0.7241 0.9595 0.8254Table 3: Performance of System 1.negation rules so that no q rel is not treated asa contradiction cue in different contexts (e.g., Nowoman runs does not contradict A woman sings).Table 2 shows the results for the five submittedsystems.The results demonstrate that the rule-based sys-tem can be used as a general system for recogniz-ing textual entailment.
It surpasses with 3 pointsof accuracy EDITS, which is an established strongbaseline system.
We are quite content with the re-sults obtained as we did not use the training datasetto create the rules, but only the trial dataset.
Thecombination of the two systems brings a slight im-provement.Overall the rule-based system is quite preciseas demonstrated in Table 3.
The numbers in thetable correspond to System 1 but are comparableto the other rule-based systems 2, 3 and 4.
Thesystem achieves an excellent precision on the en-tailment and contradiction relations.
It is almostalways correct when assigning the entailment rela-tion.
And it also obtains a decent recall, correctlyassigning almost half of the entailment pairs.
Onthe contradiction relation the system also obtaineda decent result, capturing most of the negationcases.5 ConclusionsUsing a state-of-the-art semantic analysis compo-nent, we have created a generic rule-based sys-tem for recognizing textual entailment that obtainscompetitive results on a real evaluation dataset.An advantage of our approach is that it does notrequire training.
The precision of the approachmakes it an excellent candidate for a system thatuses textual entailment as the core of an intelligentsearch engine.702ReferencesIon Androutsopoulos and Prodromos Malakasiotis.2010.
A Survey of Paraphrasing and Textual Entail-ment Methods.
J. Artif.
Intell.
Res.
(JAIR), 38:135?187.Richard Bergmair.
2010.
Monte Carlo Semantics: Ro-bust Inference and Logical Pattern Processing withNatural Language Text.
Ph.D. thesis, University ofCambridge.Ann Copestake, Dan Flickinger, Carl Pollard, andIvan A.
Sag.
2005.
Minimal Recursion Semantics:An Introduction.
Research on Language & Compu-tation, 3(2):281?332.Dan Flickinger.
2000.
On Building a More EffcientGrammar by Exploiting Types.
Natural LanguageEngineering, 6(1):15?28.Milen Kouylekov and Matteo Negri.
2010.
AnOpen-Source Package for Recognizing Textual En-tailment.
In 48th Annual Meeting of the Associa-tion for Computational Linguistics (ACL 2010) ,Up-psala, Sweden, pages 42?47.Milen Kouylekov, Yashar Mehdad, and Matteo Negri.2011.
Is it Worth Submitting this Run?
Assess yourRTE System with a Good Sparring Partner.
In Pro-ceedings of the TextInfer 2011 Workshop on TextualEntailment, Edinburgh Scotland, pages 30?34.Elisabeth Lien.
2014.
Using Minimal Recursion Se-mantics for Entailment Recognition.
In Proceed-ings of the Student Research Workshop at the 14thConference of the European Chapter of the Associ-ation for Computational Linguistics, pages 76?84,Gothenburg, Sweden, April.Andreas Wotzlaw and Ravi Coote.
2013.
A Logic-based Approach for Recognizing Textual EntailmentSupported by Ontological Background Knowledge.CoRR, abs/1310.4938.Deniz Yuret, Aydin Han, and Zehra Turgut.
2010.SemEval-2010 Task 12: Parser Evaluation usingTextual Entailments.
In Proceedings of the 5thInternational Workshop on Semantic Evaluation,pages 51?56.703
