Cb or not Cb?
Centering theory applied to NLGRodger  K ibb leInformation Technology Research InstituteUniversity of BrightonLewes RoadBrighton BN2 4GJU.K.Rodger.
K ibble@itr i .
br ighton,  ac.
ukAbstractCentering theory (CT) has been mostly dis-cussed from the point of view of interpretationrather than generation, and research has tendedto concentrate on problems of anaphora resolu-tion.
This paper examines how centering couldfit into the generation task, separating out com-ponents of the theory which are concerned withplanning and lexical choice.
We argue that it isa mistake to define a total ordering on the tran-sitions CONTINUE, PJZTAm, SHIFT and that theyare in fact epiphenomenal;  partia/orderingemerges from the interaction between cohesion(maintaining the same center) and salience (re-all.qing the center as Subject).
CT  has generallybeen neglected by NLG practitioners, possiblybecause it appears to assume that the center isdetermined according to feedbsch from the sur-face grammar, to text planning, but we arguethat this is an artefactual problem which canbe eliminated on an appropriate interpretationof the CT rules.1 What  is Center ing?Centering theory (C~) is a theory of discoursestructure which models the interaction of cohe-sion and salience in the internal organlsation ofa text.
The main assumptions of the theory aspresented by (Gross et a11995 (GJW), Brennanet al1987) rare:1.
For each utterance in a discourse there isprecisely one entity which is the centre ofattention or center.2.
There is a preference for consecutive utter-ances within a discourse segment to keepthe same entity as the center, and for themost salient entity ~realised n in an utter-ance to be interpreted as the center of thefollowing utterance.3.
The center is the entity which is most likelyto be pronominalised.These principles will be more precisely expli-cated in Sect.
2.CT has proved attractive to NLP researchersbecause of the elegance and simplicity of thecore proposals; it provides a framework foranalysing text without having to make toughdecisions about what a partfcular utterance is"about", since all notions are defined in purelystructural terms.Much research in CT has concentrated on in-terpretation, particularly reference resolution,developing algorithms to resolve anaph0ric ex-pressions based on the assumption that thetext is constructed according to Rules 1 and2.
So researchers have focussed on filling in de~tails of the theory which were left unspecified:what counts as an utterance, and how shouldtransitions be handled in complex sentences(Kameyama 1998; cf Suri and McCoy 1994)?how is salience ranking determined (Gordon etal 1993; Stevenson etal 1994;.
Strube and Hahn1996)?
what counts as ~r~Migstion ~ - does thisinclude bridging references (Strube and Hahnop cit.)?
how do centering tra~L~itions relateto discourse segment boundaries (Walker 1998,Passoneau 1998)?In fact I will leave many of these issues asidefor the purposes of this paper; I will not ex-amine the empirical adequacy of CT, for whichthe reader is referred to papers cited above and?
others collected in Walker et al(1998).
I willtake a different approach, which is to examinehow the dements of CT can be applied to theplanning of texts, with the rules and constraintsinterpreted asinstructions to a generator ratherthan a guide for interpretation.
To avoid intro-ducing too many complications I shall assume72Cb(Un)' = Cp(U.
)Cb(Un) ~ Cp(Un)Cb(Un) =" Cb(Un-l)or Cb(Un-.l) undefinedContinueRetainCb(Un) ~ Cb(Un-\[)Smooth ShiftRough ShiftFigure 1: Centering TransitionsConstra/nts "C1.
There is precisely one Cb.C2.
Every element of Cf(Un) must be realised inUn.C3.
Cb(U.)
is the highest-ranked lement of C/(U.- I)  that is realised in Un.RulesRI.
If some lement of Cf(Un-l) is realised as a 1~ronoun i /.
)', then so is Cb(Un).
(Strong version: if Cb(Un) = Cb(Un-1), a pronoun should be used.)112.
Continue is preferred over Retain which is preferred over Smooth Shiftwhich is preferred over Rough Shift .
.
.
.
.
@OOOO@OOOOO@OOOOOOO@O@@@OFigure 2: Centeringa Ucanonical ~ formulation of CT as outlinedby Walker et al (1998, Chapter 1) and theschematic ~consensus ~ generation architecturedescribed by Reiter and Dale (Reiter 1994; Re-iter and Dale 1997).
This consists a ~pipelins"of distinct asks:Text Planning- deciding the content of amessage, and organising the componentpropositions into a text tree;Sentence Planning - aggregating proposi-tions into clausal units and choosing lex-ical items corresponding to concepts in theknowledge base, including referring expres-sions (RE);Linguistic re_8!isation which takes care ofsurface details uch as agreement, orthog-raphy etc.
"Previous researchers have implemP.ntedpronominalisafion decisions using CT, andso have located Centering as part of REgeneration (e.g., Dale 1992, Passoneau 1998),while Mittal et al(1998) have a ~centeringmodule" which forms part of Sentence Planningand seeks to realise the center as Subject insuccessive sentences.
In what follows I willtry to separate out the tasks which make upcentering theory and argue that the way toimplement CT is not as a discrete module butas a series of constraints on the various levelsof the generation process from Text PlanningConstraints and Rulesto RE generation.
I shall also briefly notepoints of comparison with systems discussed byCAhill and Reape (1998) in a survey of appliedNLG systems, and conclude with some remarkson the applicability of my proposals to the"reference architecture n nvisaged by Cahill etal.
(1999), RAGS (1999).2 TrAnsition rulesThe rn~in clahns of CT are formalised in termsof C5, the "backward-looking center ~, C/ ,  alist of ~'orward-looking centers z for each ut-terance Un, and Cp or ~preferred center z, themost salient candidate for subsequent utter*ances.
Cf(Un) is a partial ordering on the en-tities mentioned (or ~ l i sed  n) in Un, rankedby grammatical role, e.g.
SUBJ ) DIR-OBJ >INDIR-OBJ ~> COMP(S) ~> A.DJUNCT(S).
C~(Un)is the highest ~,,ked member of C/(U,J  (usu-ally susJ), and is predicted to be Cb(U,+~).C.f is partial/), ordered in most accounts, whichleaves open the possibility that there is no-nlque Cb.
AJSO, if two successive utteranceshave no referent in common the second Will ha~no Cb.Successive pairs of utterances are charac-terised in terms of tmns/t/on.~ as defined in Fig-ure 1; for instance if two consecutive utteranceshave the same Co, and the Cb in the second ut-terance occurs in Subject position, this is classi-fied as a CONTINUE transition.
A text is judgedto be coherent to the extent that transitions fol-low the preference ordering iven in Rule 2 (Fig73 ?2); and on the assumption that the text is coher-ent, pronominalisation is predicted to conformto Rule 1.The notion of "realisation" is subdivided into"direct' and "indirect": an entity is directly re-alised in an utterance if it is the denotation of anovert NP (or a zero pronoun where this is syn-tactically licensed), while "indirect realisation"covers for example subsectional naphora, pos-sessive pronouns and inferential links such asbridging reference.
Corpus~based investigationsof CT have tended to concentrate on direct re-alisation, since ~nnotation of indirect anaphoriclinks depends on theoretically-based decisionsand it may be difficult to achieve reliability inthis area.
This has obvious implications for theresulting measure of coherence, which I returnto below.2.1 Salience and cohesionTransitions are defined in terms of tests which Ishall call cohesion: Cb(Un) = Cb(U~-l), andsalience: ~(Un)  = ~v(Un).
There are fourpossible combinations, which are displayed inFig.
1.
The most preferred case is where bothapply, namely co~Imm,  and the least pre-ferred is where neither apply, ItOUQH S~.
Forthe intermediate cases there are three logicalpossibilities: prefer cohesion (It,"rAm), prefersalience (SMOOTH SHIFt) or allowboth equally.There is no obvious way to settle this a pr/or/,but Walker et al(1998, Ch.
1) ~ipulate that~"rAm is preferred over SMOOTH SHIFT.
Evi-dence for this position is not conclusive, and in-deed di Eugenio (1998), Passoneau (1998) andHurewitz (1998) all found a higher percentageof shifts than retains.
This suggests either thatsalience is a stronger requirement than cohesionor that it.is easier to satisfy.
"That is, the l~n.guages tudied (English and Italian) may be suf-ficiently flexible that there is usually some wayto realise 6'b as Subj (or first-mention) but onthe other hand the same 6'b can only be main-tained for a- finite n,,mher of utterances.I suggmtthat these results hould be treatedwith some caution since it is not dear that theauthors have the same assumptions about theclaims of CT or that what they are testing di-rectly reflects formulations of CT in the moretheoretical literature.
For instance Passoneau(1998) refers to two variantS of CT: "VersionA" based on Brennan et al(1987) and ~VersionB" taken from Kameyama et  al (1993).
Pas-soneau does n~t address the issue of direct vsindirect realisation and it appears from the ex-amples given that she only takes account of en-tities realised by a full NP or (possibly null)pronoun.
The analysis according to Version Bresults in a count of 52% NULL transitions, i.e.no Cb, which gives the impression that CT isin fact a rather poor measure of coherence, Itis probable that a higher measure might havebeen obtained if Passoneau had allowed entitiesto be added to the U/'s by inference, as dis-cussed in (Brennan et al op cit.).
It is of courseimpossible to verify this without access to theoriginal texts, but it is instructive to considerthe-following example from Strube and Hahn(1996):(1) a. Ein Reserve-Batteriepack vereorgt den316LT ca.
2 Minuten mit Strom.
(A reserve battery pack - supplies- the316LT- ca.
2 minutes - with power.)b.
Der Status des Ak/ms wird dem An-wemier anges  .
(The status of -  the accumulator- is -to the user- indicated.
)S & H treat Ak/m in the (b) sentence as indi-rectly ~; |~ing the 316LT (a kind of computer)in the (a) sentence, so the latter becomes theCb of (b) resulting in a CONTINtrJS transitio~If the authors had only taken account of directrealisations this would be analysed as a NULLtr~nRition.Furthermore, a preponderance of shifts overcontinues may reflect the domain and  contentrather than the organlp-~tion f a text.
In factit can be seen that sequences of smooth shiftsare rather natural in certain kinds of narrativeor descriptive texts; see example (2).
(2) The name of your medicine is RhinocortAquIt contains budmonide.This is one of a group of medicines calledcorticosteroid~ SMOOTH SHIFTThese can help to relieve the symptoms ofhay fever or rhinitis.
SMOOTH SHIFT(pharmaceutical leaflet) ?This does not appear to be an incoherent text,00@@@00@@0@@000000@@@@@@@000@@0@0@@@@@@OQOOOOO@@OOOOOOOOOO@OOOOOOOOO@OOObut there is no way that the c?ntent could berearranged to turn the shifts into continues.2.2 Deconstructing the transitionsStrube and Hahn (1996) question the canonicalordering of transitions, partly on the groundsthat this ordering fails to predict the P~TAIN -SHIFT pattern which has been claimed by manyresearchers to signal a segment boundary or theintroduction of a new =discourse topic".
(SeeSection 3.2 below.)
Recall that the Up is de-fined as the most salient entity realised in Un,which is predicted to be the Gb of U,+l.
How-ever this "prediction" is not in fact cashed outin the rul~ for centering transitions, which takeno account of whether Cp(Un) is actually re-alised in U,+l.
S & H (op cit., p. 275) proposethe principle of cheapness which is satisfied ifCp(U.)
= Cb(U.+ l).
"Cheapness" is claimedto minimise the inferential costs of processingsequences of utteranCes, and is proposed as aconstraint on pairs of successive transitions as areplacement for the canonical orderings in Rule2.We call a tr~n.qition pair cheap if thebackward-looldng center of the cur-rent utterance is correctly predicted by .the preferred center of the immediatelypreceding utterance, i.e~, Cb(Ui) =Cp(U,-d...In fact it turns out that although cheapnessappears to be a sensible principle, it does notneatly partition the types of transition pairs;in particular, this principle does not necessar-Uy hold of all s~rAm - SMOOTH SHIFT se-quences.
S & H propose to rectify this by re-defining the transitions, with an additional testCb(Ui) = Cp(0'/-t) to subdivide CONTIN~ andmOOTS smFr (Strube, p.c.
; Strube and HAhnforthcoming).In what follows I will also argue against hecanonical ordering though on different grounds:one cannot in general predict a .preference forRetain over Shift, for the simple reason thatthere is no point at which the choice betweenthese two alternatives arises.
Rather, at dif-ferent points in the generation process there isa choice between maintaining the .~me Cb orchoosing a new.
one, and a choice of which en-tit), (Cbor non-Cb) to make salient.
So the vari-ous transition types emerge in a partial orderingfrom the interaction between salience and cohe-sion.
Note that if we also include Strube andHahn's "cheapness" principle, there is poten-tial competition with salience in cases whereCb(Un) ~ Cb(Un+l).
That is, we will need away to decide which entity to realise as Cp incases where there are two candidates~ one ofwhich is the current G'b and the other the Cbof the following sentence.
In the remainder ofthis paper I will not directly incorporate the"cheapness" principle but will suggest thatsim-ilar results are obtained with an appropriate in-terpretation of Constraint 3 in the context ofgeneration.3 Arch i tec tureIf we decompose the rules and constraints intoseparate specifications we see that they poten-tially fall under quite different headings in the,schematic architecture described above.
Thetr_~,sitions mentioned in Rule 2 are defined interms of two principles which I have called co-hesion (maintaining the same ~ from one ut-terance to the next) and salience (realising theCb as Cp, normally Subject).
If we considerthese as p|ann|ng operations, cohesion natu-rally comes under Text Planning and salienceunder Sentence pl~nnlng, while Rule I concern-ing pronominalisation falls under the ReferringExpression component of Sentence Planning.3.1 Text P lanningA text planner which operated according to C~would seek to order clauses within ~ segment tom~t~m the same Cb in a sequence of clauses.There are two related issues which compUcatethis project: firstly, Constraint 3 in Fig.
2 im-plies a requirement fo r /~  to determlnethe Cb.
In addition, there is a potential con-flict between top-dow~ hierarchical RST-typeplanning and sequential centering rules.3.1.1 Identifying the  C'bConstraint 3 states that ~for each utterance U~in a discourse segment D.. .The center, Cb(Ui, D) is the highest-ranked element of C/(Ui-I,D) that isrealised in Ui."
(Walker et al1998:3).There are two different implementation strate-gies which could satisfy this constraint:75 ?1.
Take the ranking of Cf(Ui-h D) as givenand use this to identify the Cb.2.
Take the Cb as given and plan the reali-sation of Ui-~ to make this entity the highest-ranked.The first strategy is clearly appropriate for in-terpretation (cf Brennan et al1987) but for gen-e.ration the issue is less clear-cut.
Either thegenerator "interprets" its own output to desig-nate Cb in terms of the grammatical structureof the previous utterance, in which case therehave to be separate principles for deciding onthe grammatical structure, or Cb is indepen-dently defined in the text plan and this infor-mation is used to plan the sentence structure.According to the pipelining principle infor-mation cannot flow 'backwards' between tasks.In a pipelined system, the ~a!isation of an en-tity as Cp may have the effect of setting up anexpectation on the reader'S part that this en-tity will be Cb of the following utterance, butit Cannot influence the decision made by textplanning.
This would mean that the 6"b will nolonger be defined as in Coustraint 3 but mustbe independently designated by the text plan-ner as the centre of attention i  an utterance.
Infact the resulting distribution of tasks would berather similar to the Gossip system (Carcagnoand Iordanskaja 1989) as described by Ca/aiRand Reape (1998):First, the planner produces "sentence-sized semantic nets" which it markswith theme-rheme information....
Furthermore, the theme/themeconstraints influence clause ordering,...pronominalisation .
.
.and lexicalchoice.An implementation f CT with feedbackseems likely to fit more naturally into an in-?rernenta/architecture, where generation tasksmay.
be carried out on an utterance-by-utterance basis in contrast o top-down gener-ation of a text tree for an entire discourse.
Inincremental systems it is possible in principleto plan the content of an utterance according towhich entity is currently made salient by its sur-face grammatical role, whereas this would notin general be possible in a top-down pipelinedsystem.
In fact it turns out that incrementalgenerators tend to perform sentence planningincrementally but not text planning.
(See e.g.Reithinger 1991, DeSmedt and Kempen 1991.
)Ill fact I would argue that the feedback prob-lem is only an artefact of an interpretation ofConstraint 3 as an implication rather than aconstraint.
The ~implicational ~ interpretationis that if an entity a is Cp of Un and is realisedin Un+l, it should be designated as Cb of Un+l.The declarative interpretation is non-directionaland simply equates Cb of Un+l with the mostsalient entity rea lised in Un which is also re-alised in Un+l.
The way to implement this whilekeeping to the pipelining principle is to assumethat the text planner independently designatesthe "theme ", "topic ~ or intended centre of at-tention in each clause, which is marked aS Cbif it is realised in the previous clause, and tohave the Sentence Planner promote an entity tosalience in Un if it is Cb of Un+l.
So the textplanner should annotate ach clausal node Unin the text tree with the following information:Cb of\[/.Cb of U._lCb of Un+lThe sentence planner will then make use of thisinformation to decide on pronominali.qation ac-cording to the values of the current and pre-vious Cb, and on promotion of arguments tosalience depending on the current and \]ollowingCb.
Some concrete proposals are discussed inSection 3.2, "Sentence Planning ~.
The generaldivision of labour is outlined in Fig.
3.3.1.2 Top-down Text P lann ingThe reader may be disappointed that no inde-pendent definition of ~topic" or "theme" is of-feted.
In fact we consider that this may be out-side the scope of CT.
When used for interpreta-tion, CT offers a set of rules of thumb to guidethe system in identifying the centre of atten-tion in each utterance and finding probable an-tecedents for anaphors, but the notion of ~cen-terhood" is not defined separately from theserules.
When used for generation, the most C~can offer is to take the topic or theme as 9/yenand exploit he centerln~ rules and constraintsto construct the text in a way which foregroundsthese entities and enables the user to correctlyidentify antecedents.
So CT has to sit on top ofan independently specified treatment of infor-mation structure.
One candidate is Strube andHahn's (1996) reformulation of the notions of760000@0@0@0@0@00000@@0@0@0000@0@0O@OOOeO@OOOOOO@OOOOeO@OOOOOOOOOOOOOOOOOText P lann ing1.
Content determination.2.
Discourse planning: order clauses Ui (within segments) to maximisecontinuity of reference.For each clause Un:o Designate at most one argument as Ub(U~,), which must be an argument of U,z-I.
(If intersection ofUfs(U,) and Ufs(U~_l) has only one member, that member is Ub.
)o Annotate clause node with IDs of Ub(Un), Ub(Un-l) and Cb(Un+l).Sentence Planning1.
$ente'nce aggregation.2.
Lexica/isation: select verb form for Un so thata.
Cb(U,+t) is most grammatically salient of intersection ofCfs(U,) and Cfs(U,+t);b. subject o (a), Ub(Un) is reafised in most salient available position.3.
Referr ing expression generation: working hypotheses .Cb(U,) may be pronominalised ifio Cb(U.)
= cb(u._,) (QJw 83)o C b(U.)
= cp(u._~) (Brenn~ 98)Figure 3: Locating centering tasks in the pipelinetheme and theme.
Another pomibi\]ity, which iscurrently under investigation, is to experimentwith the effects of rhetorical structure on choiceof Cb.I've assumed above that the task of main-raining continuity of reference can be locatedin the Text Planner.
That is, the TP wouldbe responsible both for annotating the Cb ineach utterance, and for organising the text sothat the same Cb is m~intained over a sequenceof clauses.
However, according to Reiter andDale (1997) a more common method of structur-ing text is to make use of "discourse relations,such as those described by Mann and Thompson(1987), which do not explicitly take continuityof reference into account.
Richard Power (p.c.
)has proposed that the implementation of CT inan RST-ba~i text planner can be treated as anopt~mi-*-~tion problem.
That is, the text plan isiuitiAlly taken to be a tree structure with dis-course relations defined on adjacent nodes butat most a partial specification of linear order.The problem will then consist of selecting a Ubfor each propositional leaf node in such a wayas to maximise the coherence of the text ac-cording to centering rules.
This is an area ofactive research.
Cheng (MS) has proposed a sim-ilar strategy for maintaining local coherence ina text planner using a genetic algorithm.Another issue is whether the CT rules, whichass-me a "flat" sequence of utterances, will re-main valid for a hierarchical/); structured textplan.
In fact it is an open research ques-tion whether CT should operate in this man-her or whether the rules should be reformu-fated to take account of dominance in additionto precedence; di~erent positions are taken byKameyama (1988) and Suri and McCoy (1994).3.2 Sentence planningAccording to the re-interpretation f CT whichwas sketched above, Sentence Planning maypromote an entity for salience if it is the Cbof the current or .following utterance.
Thereis dearly potential competition between thesetwo factors which will be discussed shortly.
Thepreference for rp~di~mg Cb as ~ can be hnple-mented by choosing a verb form which projectsG'~ in subject position.
Some poes~ilities arefranker alternation: buy/sd~ gi~/receive, bor-row/qend etc, or pamivisation: your doctor ma~/prescribe this medicine for gout vs this mtdicine,~y be pr~cnbed .for gout.If we compare the attested example (2) withthe constructed (3) it is clear that the formerreads more naturally: .O) Hypoglycaemia (Cb) may cause faintness,sweating, shaking, weakness and confusion.It m~y be due to lack of food or too high adose of the medicine.CONTINU8It can be put right by eating or drinkingsomething sugary.CONTINU~-77(pharmaceutical leaflet)(4) -..Hypoglycaemia may cause faintness,sweating, shaking, weakness and confusion.A lack of food or too high a dose of themedieinemay cause it.RETAINEating or drinking something sugary canput it right.RETAIN(modified example)Hurewitz (i998) examined the use of passives topromote cohesion and salience and found thatin both written texts and speech approximately75% of passives had either the CONTINUE orSMOOTH-SHIFT transition.
In each case the ef-fect is to promote Gb to Subject in accordancewith the salience principle.
(For written textsthis proportion was not signiRcantly differentfrom a control sample, whereas with the spo-ken passages the proportion was slightly higherthan in the'control.
)One system which explicitly makes Use of CTis the Caption Generation System (CGS) re-ported in (Mittal et al1998).
This system hasa separate "centering module" which orders ar-guments within a clause to improve coherenceof a text but does not influence the order ofclauses.
Thus only the sal ience principle is im-plemented and the centering task is located aspart of Sentence Planning:.
the speci-l!.~ed Cen-tering Module receives Control after clauses have?
been ordered and aggregated (op cit:454).
Thestrategy adopted is to keep ~the highest-rankingforward-looking center of the first clause of thesegment ... as the Cp(Ui) of a/l the followingclauses in the same segment" (op cit:456; myemphasis).
Clearly this strategy isunlikely togeneralise to a variety of domtt;na.As mentioned above there is a potential con-met betwe~ Co~t  3 (make Cb(U.+t)salient) and salience (make Cb(U,)  aslient).As noted in Sect.
2.2 there may also be compe,tition between salience and Strube & Halm'scheapness principle, which can be seen as astronger version of C3.
There are different waysthis conflict could be tadded in the cases whereit arises aad I will consider one of them, whichis to let C3 win out over salience.Consider a text with four clauses Ul - U4.which all have a and b among their arguments.Let a be the Cb of Ul- U2 and b the Cb of Us- U#.According to salience and C3, b will be Cp of/\]3 since it is Cb of that clause and the followingone.
For U2 there is competition between a andb to be Up, and this is decided by C3 in favourof b.
Finally I a is chosen as Up of Ul.
Theresult is as follows:UI : Cb f a, Cp = aU2:Cb=a,  Cp=bU3 : Cb f b, Cp = bU4 : Cb = b, Cp = bIn terms of the conventional transitions thisworks out asU~/U2: RET^INU2/U3: SMOOTH SHIFTus/u~: COnTINUaThis is consistent with Strube and Hahn's(1996) observation that "a II~rAIN transitionideally predicts a SMOOTH ssw'r  in the follow-ing utterance".
Brenuan et al(1987) make avery similar claim:A computational system for 9e-em-tion would try to plan a retention asa signal of an impending shift, so thatafter a retention, a shift would be pre-ferred rather than a continuation.Grosz et al(1995) give the following example ofthe ~Am - SHIFT pattern:(5) a. John has had trouble arranging his va-cation.b.
He (Cb; John) cannot find anyone totake over his responsibilities.c.
He (C/~, John) called up Mike yester-day to work out a plan.
CONTINUBd.
Mike hasannoyed him (Cb; John) a lotrecently, lt~rAINe.
He (Cb; Mike) called John at 5 am onFriday last week.
smrrUnder the approach outlined here, which as-sumes that the Cb is independently designated,?
the system does not needto  plan particulartransition types or even to know about them;the desired effects come about as a result of Io-cal decisions by the sentence planner using in-formation from the text pl-nner.?
Example (5) incidentally illustrates a limita-tion of CT in its Canonical version: the theoryl'~lle w~rd a ~  does not imply that these deci-sions are .taken in sequence.78@00@00000@@0000@@@00@0@@00@@@00000@@000000@@00000000000000000000000000000000000000correctly predicts the pronominal choices in (5C- e) but has nothing to say about the decisionto make Mike rather than John the Subject of(Sd).
In fact, we can construct a variant of thistext which follows centering rules more faith-fully, though it does not read any more natu-rally:(6)e.& John has had trouble arranging his va-cation.b.
He cannot find anyone to take over hisresponsibilities.
(Cb -- John)c. He called up Mike yesterday to workout a plan.
(CONTINUE; Cb = John)d. He has been pretty annoyed with Mikerecently.
(colqzlm~; Cb John)He got a call from him (Mike) at 5 amon Friday last week.
(CONTrol; Cb= John)If we examine the discourse structure of exam-ple (5), it seems that the discourse as a whole isabout John but (Sd,e) form a parenthetical sec-tion which tells us something about M/ke.
Soalthough a blind application of centering ruleswould judge:(6) to be more coherent, (5) is infact maximally coherent within the constraintsof the structure of the discourse.To snmmarise: we assvme that for each utter-ance U, the text planner has identified Cb(U,),Cb(U.-1) and Cb(U.+d.
The task for the sen-tence planner is to select a verb form or someother syntactic device to malise Cb(Un+l) as themost salient of those entities which are reAl|.~edin U. and U.+t, and subject o this, to realiseCb(gJ'.)
in the most salient position available.
(See Figure 3,) So for example if Cb(Un) is notto be realised in U,?t, it will normally be re-alised as Cp(U,); but if i t /8 to be realised inUn+I then the Cb of U,+t will be at least ashighly ranked in Un as the Cb of Un.
Tlfisstrat-egy predicts the Ralisation of M//~ rather thanJohn as Cp in (5d) above.3.3 Referring ExpressionsThe contribution ofCT to Referring Expression(RE) generation is to decide on pronominalisa-tion.
Rule 1 (Fig.
2) which concerns pronom-inalisation has a strong and a weak formula-tion: tile strong one is that a pronoun shouldbe used for the Cb if it is the same as the Cbof the previous utterance, the weak one is thatthe Cb must be pronominalised if anything is.In the context of generation it is probably saferto use the strong version.
Brennan (1998) pro-poses, arguing from corpus analysis, that theCb should be pronominalised only if it is Cp ofthe previous utterance.
Robert Dale's RPICUREsystem employs the terminology of CT in Con?nection with RE generation, as does the ILEXsystem reported in (O'Donnell et al1998).
Boththese systems implement a variant of Rule 1 todetermine whether to pronominalise the center(Dale) or Cb (ILEX), though in neither caseis the center identified according to the stan-dard apparatus of CT.
In ILEX the Cb is des-ignated by the text planner without referenceto the content of the previous entence, and itmay be pronominal|.qed if it is the same as theprevious entence's "Cb".
Dale's IZPIOURE iden-tifies the center with Uthat entity which is theresult of the previously described operation"(Dale 1992:170).
Passoneau (1998) constructedinput for a prototype generator by "hypothesis-ing" a Cb for each proposition in a text basedon the salience of entities in a Situation.
Pas-soneau's ystem uses centering constraints todecide whether to realise ntities as definite pro-nouns, minimal NPs or full NPs.4 Conc lus ions  and  fu ture  workCT has developed primarily as a tool foranalysing the structure of a given text and iden-tifying the most likely candidates for anaphoraresolution.
In this paper we sought to deter?mine whether the principles underlying the con-straints and rules of the theory can be Uturnedround" and used as planning operators for gen-erating coherent text,.
As a side-effect of thisenterprise we have articulated a ~streamlined"formulation of CT in terms of the principleso f  sal ience and cohesion, and argued thatthe preferences for the different transition typesemerge in a partial ordering f~om the interac-tion between these principles.
These princi-ples are rather heterogenous, a fact which isobscured by combining them in the transitiondefinitions, and can be implemented as encap-sulated tasks distributed between text planning,79sentence planning and RE generation.
It mayturn out that individual components such as thecohesion principle do not need to be explicitlystated but emerge as by-products from higher-level text planning.As noted at various points in this paper CThas never been more than partially implementedin NLG systems.
This may be due to a beliefon the part of NLG practitioners that CT getsthings the wrong way round, by relying on sur-face grammatical realisation to determine the?
centre of attention in an utterance.
If this be-lld is commonly held (and anecdotal evidencesuggests that it is), I argue that it is mistaken.In interpretation systems the principles of CTguide the system in identifying the centre ofattention and in choosing likely referents foranaphors.
In NLG systems, if there is a notionof "topic" or "theme =this should be designatedby the text planner, while the CT rules allowthe sentence planner to promote this entity tosalience to keep it as the user's "centre of atten-tion".However, a more fuDd~mental explanation forthe neglect of CT in the generation literatureis provided by the fact that a faithful imple-mentation in a pipelined system turns out torequire an independent way of designating thecentral entity in a proposition, and this itself isa problem which has not had much attentionin the development of NLG systems 2.
So thenext stage in this research will Concentrate ondeveloping a characterisation f Cb based on se-mantic content and information structure, tak-ing account of e.g.
the proposals of Strube andHahn (1996) and experimenting with optlmi-sation algorithms as discussed in section 3.1.2above.As mentioned above the Reiter model hasbeen questioned by members of the RAGSproject in Brighton and Edinburgh who are ac-tively engaged in developing a "Teference" architecture for NLG.
(See Cahlll et al, 1999, RAGS1999.)
To date' the group has concentratedon specifying the data structures which are re-quired at various tages of the generation taskand has identified a number of discrete functionssuch as rhetorical  structur ing,  aggregation,~Thk appHm at lea~ to applied systems;, see CahiU?
and Reape 1998.
One exception appears to be the GOS-.SIP system described in Caragno and Iordaaskaja 1989.coherence tc., without specifying a strict or-der for the execution of these functions.
It is tooearly to assess how the proposals of this paperwould fit into the RAGS scheme, but I antici-pate that, as with the Reiter architecture, theconclusion would be that referential coherenceis not the task of a discrete module but imposesconstraints on a number of different modules.It has been noted that the way the "realise"relation is interpreted can have significant im-plications for the coherence of a text as mea-sured by CT, and that corpus analysis has of-ten concentrated ondirectly realised Cb's.
Anexception is Hahn, Strube and Markert's (1996)treatment of bridging reference, or "textual el-lipsis" in their terminology.
As these authorsnote there have been rather few implementedsystems which are able to interpret bridging ref-erences in a principled way, and research in NLGis particularly weak in this area.
SO, a faith-ful implementation f CT in generation systemswill depend in part on progress in the genera-tion of bridging references.
This is an area forfuture research.....
It is intended that the procedures described in"this" paper will be implemented in ICONOCLAST,an authoring tool which enables domain expertsto create a knowledge base through a sequenceof interactive choice-- and generates hiexarchi-tally structured text according to various tylis-tic constraints (See Power and Scott 1998).AcknowledgementsThis work was carried out as par t  of theGNOME project (Generating Nominal Expres-sions) which is s collaboration between ITRI inthe University of Brighton and the H~tc in the~nlversities of Edinburgh and Durham, fundedby the EPSRc under grant reference GR/L51126.I would like to thank ITRX and GNOME colleaguesfor helpful feedback, particularly Christy 1)o-ran, Renate Henschel, Richard Power and Keesvan Deemter, as well as two anonymous referees.ReferencesS Brennan, M W, lker Priedman and C Pol-lard 1987.
A Centering Approach to Pronouns.
InProc.
25th AC\[, :115-62.L C-hil l ,  C Doran, R Ev-n- ,  C Mell ish, DPalva, M Reape and D Scott 1999.
In search ofa reference architecture for NLG systems.
In Proc.80EWNLG'99.L Cahill and M Reape 1998~ Componenttasks in Applied I:4atural Language Generation Sys-tems.
RAGS Project Deliverable, available atwww.
i t r i .
brighton, ac.
uk/proj ects/rags.D Caragno and L Iordanskaja 1989.
ContentDetermination a d Text Structuring in GOSSIP.
InEztended Abstracts o.f ENLG'89.H Cheng MS.
Experimenting with the Interactionbetween Aggregation and Text Planning.
Unpub-lished paper, Division of InformatiC~, University ofEdinburgh.R Dale 1992, Generating Re/erring Expreasions,Cambridge, MA/London:MIT Press.K De Smedt and G Kempen 1991.
SegmentGrammar: a Formalism for Incremental SentenceGeneration.
In C Paris, W Swartout and W Mann(eds), Natnral Language Ge.era6on in Artificial n-teUigence and Computational Linguistics.B Di Eugenio 1996.
The discourse functions ofItalian subjects: a centering approach.
In Proe.GOLING96.B Di Eugeni0 1998.
Centering in Italian.
InWalker et al(eds) Centering Th~j in Discourse.P Gordon, B Grosz and L Gilllom 1993.
Pro-nouns, Names and the Centering of Attention in Dis-course.
Co#nitiee Scien~ 17/3:311-47.B Grosz, A Joshi and S Weinsteln 199.5.
Cen-teriag: a framework for modelling the local coher-ence of discourse.
Comput~iond Linguistics, 21/2:203-25.U Hahn, M Strube and M Markert 1996.Bridging Textual Ellipses.
In Prec.
e/COLING-96.F Hurewitz 1998.
A Quantitative Look at Dis-course Coherence.
In Wall~ et al(ecb) CenteringTheory in Du~.rs?M Kameyama 1998.
In~tent ia l  Centering: ACase Study.
In Walker et al(eds) Centering Theoryin Diso~rse.M Kameyamm, R Pammneau and M Poeslo1993.
Temporal C4mtefinfr In Prec.
o~ $1stACL.W M- - ,  and S Thompson 1987.
RhetoricalStructure Theory: A Theory of Text Organisation.In L Polanyi (ed.
), The 3ble~ure ojr D/acoerseV Mittal, J Moore, G Carenini and S Roth1998.
Describing Complex Charts in Natural Lan-guage: A Caption Generation System.
Computa-tional Linguistics, 24/3:431-468.?
R Power and D Scott 1998.
Mult'flingual author-ing using ffedback texts.
In Prec.
COLING/ACL'98RAGS 1999.
The RAGS Project.
Towardsa Reference Architecture for Natural LanguageGeneration Systems.
Technical report ITRI-99-14, ITRI, University of Brighton.
Available atwwu.
i t r i .
brighton, ac.
uk/proj ects/rags.E Reiter 1994.
Has a consensus NL generationarchitecture appeared, and is it psycholinguisticallyplausible?
In Proc.
INLG 7.'163-70.E.
Reiter and R. Dale (1997).
Building AppliedNatural-Language G neration Systems.
Journal o.fNatural-Language Engineerin9 3:57-8ZN Reithinger 1991.
POPEL - A Parallel and In-cremental Natural Language Generation System.
InC Paris, W Swartout and W Mann (eds), NaturalLanguafe Generation in Artificial Intelligence andComputational Linguistic.R Stevenson, R Crawley and D Kleinman1994.
Thematic roles, focus and the representationof events.
Laf~3nage and Cognitive Proc_e~_es, 9:519-48.M Strube and U H ,h -  1996.
Fancfional Center-ing.
In Proceedings ACL 34:270-77.M Strube and U Hahn 1999.
Functional Cen-tering:.
Grounding Referential Coherence in Infor-marion Structure.
To appear in Computational Lin-guistics.L Suri and K McCoy 1994.
RAFT/RAPRand Centering: A Comparison and Discussion ofP rob l~ Related to ProcemingComplex Sentences.GompeMtional linguistics 20/2:30!-17.M Walker 1998.
Centering, Anaphora Resolutionand Discourse Structure.
In Walker et al(eds) Cen-tering Theory in Disanwse.M Walker, AK Joshl and E Prince (eds) 1998.Centering Theory in Disburse.
Oxford: ClarendonPreu.81
