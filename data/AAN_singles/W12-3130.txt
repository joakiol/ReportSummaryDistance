Proceedings of the 7th Workshop on Statistical Machine Translation, pages 253?260,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsProbes in a Taxonomy of Factored Phrase-Based Models ?Ondr?ej Bojar, Bushra Jawaid, Amir KamranCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostranske?
na?m.
25, Praha 1, CZ-118 00, Czech Republic{bojar,jawaid,kamran}@ufal.mff.cuni.czAbstractWe introduce a taxonomy of factored phrase-based translation scenarios and conduct arange of experiments in this taxonomy.
Wepoint out several common pitfalls when de-signing factored setups.
The paper also de-scribes our WMT12 submissions CU-BOJARand CU-POOR-COMB.1 IntroductionKoehn and Hoang (2007) introduced ?factors?
tophrase-based MT to explicitly capture arbitrary fea-tures in the phrase-based model.
In essence, inputand output tokens are no longer atomic units butrather vectors of atomic values encoding e.g.
the lex-ical and morphological information separately.
Fac-tored translation has been successfully applied tomany language pairs and with diverse types of infor-mation encoded in the additional factors, i.a.
(Bojar,2007; Avramidis and Koehn, 2008; Stymne, 2008;Badr et al, 2008; Ramanathan et al, 2009; Koehn etal., 2010; Yeniterzi and Oflazer, 2010).
On the otherhand, it happens quite frequently, that the factoredsetup causes a loss compared to the phrase-basedbaseline.
The underlying reason is the complexity ofthe search space which gets boosted when the modelexplicitly includes detailed information, see e.g.
Bo-jar and Kos (2010) or Toutanova et al (2008).?
This work was supported by the project EuroMatrixPlus(FP7-ICT-2007-3-231720 of the EU and 7E09003+7E11051 ofthe Czech Republic) and the Czech Science Foundation grantsP406/11/1499 and P406/10/P259.
We are grateful for review-ers?
comments but we have to obey the 6 page limit.
Thanksalso to Ales?
Tamchyna for supplementary material on MERT.Number of Number ofTranslation Independent StructureSteps Searches of Searches NicknameOne One ?
DirectSeveralOne ?
Single-StepSeveralSerial Two-StepComplex ComplexFigure 1: A taxonomy of factored phrase-based models.In this paper, we first provide a taxonomy of(phrase-based) translation setups and then we exam-ine a range of sample configurations in this taxon-omy.
We don?t state universal rules, because the ap-plicability of each of the setups depends very muchon the particular language pair, text domain andamount of data available, but we hope to draw at-tention to relevant design decisions.The paper also serves as the description of ourWMT12 submissions CU-BOJAR and CU-POOR-COMB between English and Czech.2 A Taxonomy of Factored P-B ModelsFigure 1 suggests a taxonomy of various Moses se-tups.
Following the definitions of Koehn and Hoang(2007), a search consists of several translation andgeneration steps: translation steps map source fac-tors to target factors and generation steps producetarget factors from other target factors.The taxonomy is vaguely linked to the types ofproblems that can be expected with a given config-uration.
Direct translation is likely to suffer fromout-of-vocabulary issues (due to insufficient gener-alization) on either side.
Single-step scenarios have253a very high risk of combinatorial explosion of trans-lation options (think cartesian product of all targetside factors) and/or of spurious ambiguity (severalderivations leading to the same output).
Such addedambiguity can lead to n-best lists with way fewerunique items than the given n, which in turn ren-ders MERT unstable, see also Bojar and Tamchyna(2011).
Serially connected setups (two as our Two-Step or more) can lose relevant candidates betweenthe searches, unless some ambiguous representationlike lattices is passed between the steps.An independent axis on which Moses setups canbe organized consists of the number and function offactors on the source and the target side.We use a very succint notation for the setups ex-cept the ?complex?
one: tX-Y denotes a translationstep between the factors X in the source languageand Y in the target language.
Generation steps aredenoted with gY-Z, where both Y and Z are target-side factors.
Individual mapping steps are combinedwith a plus, while individual source or target factorsare combined with an ?a?.As a simple example, tF-F denotes the directtranslation from source form (F ) to the target form.A linguistically motivated scenario with one searchcan be written as tL-L+tT-T+gLaT-F : translate (1)the lemma (L) to lemma, (2) the morphological tag(T) to tag independently and (3) finally generate thetarget form from the lemma and the tag.We use two more operators: ?:?
delimits al-ternative decoding paths (Birch et al, 2007) usedwithin one search and ?=?
delimits two independentsearches.
A plausible setup is e.g.
tF-LaT=tLaT-F:tL-F motivated as follows: the source word formis translated to the lemma and tag in the target lan-guage.
Then a second search (whose translation ta-bles can be trained on larger monolingual data) con-sists of two alternative decoding paths: either thepair of L and T is translated into the target form, oras a fallback, the tag is disregarded and the targetform is guessed only from the lemma (and the con-text as scored by the language model).
The examplealso illustrated the priorities of the operators.3 Common SettingsThroughout the experiments, we use the Mosestoolkit (Koehn et al, 2007) and GIZA++ (OchDataset Sents (cs/en) Toks (cs/en) SourceSmall 197k parallel 4.2M/4.8M CzEng 1.0 newsLarge 14.8M parallel 205M/236M CzEng 1.0 allMono 18M/50M 317M/1.265G WMT12 monoTable 1: Summary of training data.Decoding Path Language Models BLEUtF-FaLaT form + lemma + tag 13.05?0.44tF-FaT form + tag 13.01?0.44tF-FaLaT form + tag 12.99?0.44tF-F (baseline) form 12.42?0.44tF-FaT form 12.19?0.44tF-FaLaT form 12.08?0.45Table 2: Direct en?cs translation (a single search withone translation step only).and Ney, 2000).
The texts were processed us-ing the Treex platform (Popel and Z?abokrtsky?,2010)1, which included lemmatization and taggingby Morce (Spoustova?
et al, 2007).
After the tag-ging, we tokenized further so words like ?23-year?or ?Aktualne.cz?
became three tokens.Our training data is summarized in Table 1.2In most experiments reported here, we use theSmall dataset only.
The language model (LM) forthese experiments is a 5-gram one based on thetarget-side of Small only.Our WMT12 submissions are based on the Largeand Mono data.
The language model for the largeexperiments uses 6-grams of forms and optionally8-grams of morphological tags.
As in previousyears, the language models are interpolated (to-wards the best cross entropy on WMT08 dataset)from domain-specific LMs, e.g.
czeng-news, czeng-techdoc, wmtmono-2011, wmtmono-2012.Except where stated otherwise, we tune on the of-ficial WMT10 test set and report BLEU (Papineni etal., 2002) scores on the WMT11 test set.4 Direct SetupsTable 2 lists our experiments with direct translation,various factors and language models in our notation.1http://ufal.mff.cuni.cz/treex/2We did not include the parallel en-cs data made availableby the WMT12 organizers.
This probably explains our losscompared to UEDIN but allows a direct comparison with CUTECTOMT, a deep syntactic MT based on the same data.254Decoding Paths LMs Avg.
BLEU Eff.
Nbl.
SizetL-L+tT-T+gLaT-F:tF-FaLaT F + L + T 13.31?0.06 12.24?1.33tL-L+tT-T+gLaT-F F + L + T 13.30?0.05 40.33?3.82tL-L+tT-T+gLaT-F F + T 13.17?0.01 39.91?2.58tL-L+tT-T+gLaT-F:tF-FaLaT, 200-best-list F + L + T 13.15?0.24 20.47?5.63tF-FaLaT F + L + T 13.13?0.06 34.28?3.08tL-L+tT-T+gLaT-F:tF-FaLaT L + T 13.09?0.06 16.65?1.07tF-FaT F + T 13.08?0.05 39.67?2.21tL-L+tT-T+gLaT-F:tF-FaT F + T 13.01?0.43 14.87?5.04tF-F (baseline) F 12.38?0.03 43.13?0.48tL-L+tT-T+gLaT-F:tF-F F 12.30?0.03 17.83?3.27Table 3: Results of three MERT runs of several single-step configurations.Explicit modelling of target-side morphology im-proves translation quality, compare tF-FaLaT withthe baseline tF-F.
However, two results documentthat if some detailed information is distinguished inthe output, it introduces target ambiguity and leadsto a loss in BLEU, unless the detailed information isactually used in the language model: (1) tF-FaLaTwith LM on forms is worse than the baseline tF-Fbut tF-FaLaT with all the three language models isbetter, (2) tF-FaLaT with two LMs (forms and tags)is negligibly worse than tF-FaT with the same lan-guage models.5 Single-Step ExperimentsSingle-step scenarios consist of more than one trans-lation steps within a single search.
We do not distin-guish whether all the translation steps belong to thesame decoding path or to alternative decoding paths.Table 3 lists several single-step configurations(and three direct translations for a compari-son).
The single-step configurations always includethe linguistically-motivated tL-L+tT-T+gLaT-F withvarying language models and optionally with an al-ternative decoding path to serve as the fallback.Aware of the low stability of MERT (Clark et al,2011), we run MERT three times and report the av-erage BLEU score including the standard deviation.The last column in Table 3 lists the average num-ber of distinct candidates per sentence in the n-best lists during MERT, dubbed ?effective n-best listsize?.
Unless stated otherwise, we used 100-bestlists.
We see that due to spurious ambiguity, e.g.various segmentations of the input into phrases, theeffective size does not reach even a half of the limit.We make three observations here:(1) In this small data setting with a very morpho-logically rich language, the complex setup tL-L+tT-T+gLaT-F does not even need the alternative decod-ing path tF-F. Ramanathan et al (2009) report gainsin English-to-Hindi translation and also probably donot use alternative decoding paths.
(2) Reducing the range of language models usedleads to worse scores, which is in line with the ob-servation made with direct setups.
We are surprisedby the relative importance of the lemma-based LM.
(3) Alternative decoding paths significantly re-duce effective n-best list size to just 12?18 uniquecandidates per sentence.
However, we don?t seean obvious relation to the stability of MERT: thestandard deviations of BLEU average are verysimilar except for two outliers: 13.15?0.24 and13.01?0.43.
One of the outliers, 13.15, is actuallya repeated run of the 13.31 with n-best-list size setto 200.
Here we see a slight increase in the effec-tive size (20 instead of 12) but also a slight lossin BLEU.
We repeated the 13.31 experiment alsowith n ?
{300, 400, 500, 600}, three MERT runs foreach n. All the runs reached BLEU of about 13.30except for one (n = 600) where the score droppedto 11.50.
The low result was obtained when MERTended at 25 iterations, the standard limit.
On theother hand, several successful runs also exhaustedthe limit.Figure 2 plots the BLEU scores in the 25 itera-tions of the underperforming run with n = 600.
TheMERT implementation in the Moses toolkit reportsat each iteration what we call ?predicted BLEU?,i.e.
the BLEU of translations selected by the current25500.020.040.060.080.10.120.14  05101520250.12850.1290.12950.130.13050.1310.1315BLEUIterationy2:Predictedy: Predictedy: RealFigure 2: Predicted and real devset BLEU scores.weight settings from the (accumulated) n-best list.We plot this predicted BLEU twice: once on the y2axis alone and for the second time on the primaryy axis together with the real BLEU, i.e.
the BLEUof the dev set when Moses is actually run with theweight settings.
The real BLEU drops several times,indicating that the prediction was misleading.
Sim-ilar drops were observed in all runs.
With bad luckas here, the iteration limit is reached when the opti-mization is still recovering from such a drop.To avoid such a pitfall, one should check the realBLEU and continue or simply rerun the optimizationif the iteration limit was reached.6 Two-Step ExperimentsThe linguistically motivated setups used in the pre-vious sections are prohibitively expensive for largedata, see also Bojar et al (2009).
A number ofresearchers have thus tried diving the complexityof search into two independent phases: (1) transla-tion and reordering, and (2) conjugation and declina-tion.
The most promising results were obtained withthe second step predicting individual morphologicalfeatures using a specialized tool (Toutanova et al,2008; Fraser et al, 2012).
Here, we simply use onemore Moses search as Bojar and Kos (2010).In the first step, source English gets translated toa simplified Czech and in the second step, the sim-plified Czech gets fully inflected.6.1 Factors in Two-Step SetupsTwo-step setups can use factors in the source, middleor the target language.
We experiment with factorsonly in the middle language (affecting both the firstand the second search) and use only the form in bothsource and target sides.In the middle language, we experiment with oneor two factors.
For presentation purposes, we alwaysspeak about two factors: ?LOF?
(?lemma or form?,i.e.
a representation of the lexical information) and?MOT?
(?modified tag?, i.e.
representing the mor-phological properties).
In the single-factor experi-ments the LOF and MOT are simply concatenatedinto a token in the shape LOF+MOT.Figure 3 illustrates the range of LOFs and MOTswe experimented with.
LOF0 and MOT0 are identi-cal to the standard Czech lemma and morphologicaltag as used e.g.
in the Prague Dependency Treebank(Hajic?
et al, 2006).LOF1 and MOT1 together make what Bojar andKos (2010) call ?pluslemma?.
MOT1 is less com-plex than the full tag by disregarding morphologicalattributes not generally overt in the English sourceside.
For most words, LOF1 is simply the lemma,but for frequent words, the full form is used.
Thisincludes punctuation, pronouns and the verbs ?by?t?
(to be) and ?m??t?
(to have).MOT2 uses a more coarse grained part of speech(POS) than MOT1.
Depending on the POS, dif-ferent attributes are included: gender and numberfor nouns, pronouns, adjectives and verbs; case fornouns, pronouns, adjectives and prepositions; nega-tion for nouns and adjectives; tense and voice forverbs and finally grade for adjectives.
The remain-ing grammatical categories are encoded using POS,number, grade and negation.6.2 Decoding Paths in Two-Step SetupsEach of the searches in the two-step setup can beas complex as the various single-step configurations.We test just one decoding path for the one or twofactors in the middle language.All experiments with one middle factor (i.e.
?+?
)follow this config: tF-LOF+MOT = tLOF+MOT-F,i.e.
two direct translations where the first one pro-duces the concatenated LOF and MOT tokens andthe second one consumes them.
The first step uses a5-gram LOF+MOT language model and the secondstep uses a 5-gram LM based on forms.This setup has the capacity to improve transla-tion quality by producing forms of words never seenaligned with a given source form.
For example theEnglish word green would be needed in the parallel256Word Form LOF0 LOF1 MOT0 MOT1 MOT2 Glosslide?
c?love?k c?love?k NNMP1-----A---1 NPA- NMP1-A peopleby by?t by Vc------------- c--- V----- wouldneoc?eka?vali oc?eka?vat oc?eka?vat VpMP---XR-NA--- pPN- VMP-RA expectFigure 3: Examples of LOFs and MOTs used in our experiments.Middle Factors 1 2+ |LOF0 +/|MOT0 11.11?0.48 12.42?0.48LOF1 +/|MOT1 12.10?0.48 11.85?0.42LOF1 +/|MOT2 11.87?0.51 12.47?0.51Table 4: Two-step experiments.data with all the morphological variants of the Czechword zeleny?.
Adding the middle step with appro-priately reduced morphological information so thatonly features overt in the source are represented inthe middle tokens (e.g.
negation and number but notthe case) allows the model to find the necessary formanywhere in the target-side data only:green?
zeleny?+NSA-?
{ zelene?ho (genitive)zelene?mu (dative).
.
.The experiments with two middle factors (i.e.
?|?
)use this path: tF-LOFaMOT = tLOFaMOT-F:LOF-F.
The first step is identical, except that now we usetwo separate LMs, one for LOFs and one for MOTs.The second step has two alternative decoding paths:(1) as before, producing the form from both the LOFand the MOT, and (2) ignoring the morphologicalfeatures from the source altogether and using justtarget-side context to choose an appropriate form ofthe word.
This setup is capable of sacrificing ade-quacy for a more fluent output.6.3 Experiments with Two-Step SetupsTable 4 reports the BLEU scores when changing thenumber of factors (?+?
vs.
?|?)
in the middle lan-guage and the type of the LOF and MOT.We see an interesting difference between MOT1and MOT0 or 2.
The more fine-grained MOT0 or 2work better in the two-factor ?|?
setup that allowsto disregard the MOT, while MOT1 works better inthe direct translation ?+?.Overall, we see no improvement over the tF-Fbaseline (BLEU of 12.42) and this is mainly due toto the fact that we used Small data in both steps.7 A Complex Moses SetupObviously, many setups fall under the ?complex?category of our taxonomy, including also some sys-tem combination approaches.
We tried to combinethree Moses systems: (1) CU-BOJAR as describedbelow, (2) same setup like CU-BOJAR but optimizedtowards 1-TER (Snover et al, 2006), and (3) a large-data two-step setup.3 The system combination isperformed using a fourth Moses search that gets alattice (Dyer et al, 2008) of individual systems?
out-puts, performs an identity translation and scores thecandidates by language models and other features.The lattice is created from the individual system out-puts in the ROVER style (Matusov et al, 2008) uti-lizing the source-to-hypothesis word alignments asproduced by the individual systems.
We use our sim-ple implementation for constructing the confusionnetworks and converting them to the lattices.
The?combination Moses?
was tuned on the WMT11 testset towards BLEU.
The resulting system is calledCU-POOR-COMB, because we felt it underperformedthe individual systems not only in BLEU but also inan informal subjective evaluation.Surprisingly, CU-POOR-COMB won the WMT12automatic evaluation in TER.
In the retrospect, thisis caused by TER overemphasizing word-level pre-cision.
CU-POOR-COMB skipped words not con-firmed by several systems and its hypotheses areshorter (18.1 toks/sent) than those by CU-BOJAR(20.1 toks/sents) or the reference (21.9 toks/sent).A quick manual inspection of 32 sentences suggeststhat about one third or quarter of CU-POOR-COMBsuffer from some information loss whereas the restare acceptable or even better paraphrases.
Prelim-3The large two-step setup is identical to the one by (Bojarand Kos, 2010), except that we use only the current Large andMono datasets as described in Section 3.257Our Scoring matrix.statmt.orgTest Set newstest-2011 newstest-2012Metric BLEU TER*100 BLEU TER*100 BLEU TER?csCU-POOR-COMB ?used?for?
?tuning?
14.17?0.53 64.07?0.53 14.0 0.741CU-BOJAR (tFaT-FaT, lex.
r.) 18.10?0.55 62.84?0.71 16.07?0.55 65.52?0.59 15.9 0.759As ?
but towards 1-TER 16.10?0.54 61.64?0.59 14.13?0.54 64.28?0.55 ?
?Large Two-Step 17.34?0.57 63.47?0.66 15.37?0.54 65.85?0.57 ?
?Unused (tFaT-FaT, dist.
reord.)
18.07?0.56 62.74?0.70 15.92?0.57 65.50?0.60 ?
?Unused (tF-FaT, dist.
reord.)
17.85?0.58 63.13?0.68 15.73?0.55 65.85?0.58 ?
?Unused (tF-F, lex.
reord.)
17.73?0.58 63.04?0.68 15.61?0.57 65.76?0.58 ?
?Unused (tFaT-F, dist.
reord.)
17.62?0.56 62.97?0.70 15.33?0.58 65.70?0.59 ?
?Unused (tF-F, dist.
reord.)
17.51?0.57 63.32?0.69 15.48?0.56 65.79?0.58 ?
?
?enCU-BOJAR (tF-F:tL-F, dist.
reord.)
24.65?0.60 58.54?0.66 23.09?0.59 61.24?0.68 21.5 0.726Unused (tF-F, dist.
reord.)
24.62?0.59 58.66?0.66 22.90?0.56 61.63?0.67 ?
?Table 5: Summary of large data runs and systems submitted to WMT12 manual evaluation.
The upper part lists thetwo submissions in en?cs translation and two more systems used in CU-POOR-COMB.
The lower part of the tableshows the scores for CU-BOJAR when translating to English.
All systems reported here use the Large and Mono data.inary results of WMT 12 manual ranking indicatethat overall, our system combination performs poor.8 Overview of Systems SubmittedTable 5 summarizes the scores for our two sys-tem submissions.
We report the scores in our to-kenization on the official test sets of WMT11 andWMT12 and also the scores as measured by http://matrix.statmt.org.
Note that for the lat-ter, we use the detokenized outputs processed by therecommended normalization script.48.1 Details of CU-BOJAR for en?csWe deliberately used only direct setups for the largedata and due to time constraints, we ran just a fewconfigurations, see Table 5.We knew from previous years that including En-glish (source) POS tag improves overall target sen-tence structure: English words are often ambiguousbetween noun and verb, so without the POS infor-mation, verbs got often translated as nouns, render-ing the sentence incomprehensible.
Tagging and in-cluding the source tag helps, as confirmed by thetFaT-F setup being somewhat better than tF-F.We also knew that target-side tag LM is helpful(esp.
if we can afford up to 8-grams in the LM).This was confirmed by tF-FaT being better than tF-F.
Ultimately, we use tags on both sides: tFaT-FaT4http://www.statmt.org/wmt11/normalize-punctuation.perland get the best scores.
This confirms that our par-allel data is sufficiently large so that even the addedsparsity due to tags does not cause any trouble.A little gain comes from a lexicalized reorder-ing model (or-bi-fe) based on word forms, see CU-BOJAR reaching 18.10 BLEU on WMT11 test set.8.2 Details of CU-BOJAR for cs?enFor the translation into English, we tested just twosetups: tF-F and tF-F:tL-T.
The latter setup fallsback to the Czech lemma, if the exact form is notavailable.
The gain is only small, because our paral-lel data is already quite large.9 ConclusionWe introduced a simple taxonomy of factoredphrase-based setups and conducted several probesfor English?Czech translation.
We gained smallimprovements in both small and large data settings.We also warned about some common pitfalls: (1)all target-side factors should be accompanied with alanguage model to compensate for the added sparse-ness, (2) alternative decoding paths significantly re-duce the effective n-best list size, and (3) the infa-mous instability of MERT can be caused by bad luckat exhausted iteration limit.On a general note, we learnt that a breadth-firstsearch for best configurations should be automatedas much as possible so that more human effort canbe invested into analysis.258ReferencesEleftherios Avramidis and Philipp Koehn.
2008.
Enrich-ing morphologically poor languages for statistical ma-chine translation.
In Proceedings of ACL-08: HLT,pages 763?770, Columbus, Ohio, June.
Associationfor Computational Linguistics.Ibrahim Badr, Rabih Zbib, and James Glass.
2008.Segmentation for english-to-arabic statistical machinetranslation.
In Proceedings of the 46th Annual Meet-ing of the Association for Computational Linguis-tics on Human Language Technologies: Short Pa-pers, HLT-Short ?08, pages 153?156, Stroudsburg, PA,USA.
Association for Computational Linguistics.Alexandra Birch, Miles Osborne, and Philipp Koehn.2007.
CCG Supertags in Factored Statistical Ma-chine Translation.
In Proceedings of the Second Work-shop on Statistical Machine Translation, pages 9?16,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Ondr?ej Bojar and Kamil Kos.
2010.
2010 Failures inEnglish-Czech Phrase-Based MT.
In Proceedings ofthe Joint Fifth Workshop on Statistical Machine Trans-lation and MetricsMATR, pages 60?66, Uppsala, Swe-den, July.
Association for Computational Linguistics.Ondr?ej Bojar and Ales?
Tamchyna.
2011.
ImprovingTranslation Model by Monolingual Data.
In Pro-ceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 330?336, Edinburgh, Scot-land, July.
Association for Computational Linguistics.Ondr?ej Bojar, David Marec?ek, Va?clav Nova?k, MartinPopel, Jan Pta?c?ek, Jan Rous?, and Zdene?k Z?abokrtsky?.2009.
English-Czech MT in 2008.
In Proceedings ofthe Fourth Workshop on Statistical Machine Transla-tion, Athens, Greece, March.
Association for Compu-tational Linguistics.Ondr?ej Bojar.
2007.
English-to-Czech Factored MachineTranslation.
In Proceedings of the Second Workshopon Statistical Machine Translation, pages 232?239,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.Smith.
2011.
Better hypothesis testing for statisticalmachine translation: Controlling for optimizer insta-bility.
In ACL (Short Papers), pages 176?181.
TheAssociation for Computer Linguistics.Christopher Dyer, Smaranda Muresan, and Philip Resnik.2008.
Generalizing word lattice translation.
In Pro-ceedings of ACL-08: HLT, pages 1012?1020, Colum-bus, Ohio, June.
Association for Computational Lin-guistics.Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-bienne Cap.
2012.
Modeling Inflection and Word-Formation in SMT.
In Proc.
of EACL 2012.
Associa-tion for Computational Linguistics.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan S?te?pa?nek, Jir???
Havelka, MarieMikulova?, Zdene?k Z?abokrtsky?, and Magda S?evc???kova?Raz??mova?.
2006.
Prague Dependency Treebank 2.0.LDC2006T01, ISBN: 1-58563-370-4.Philipp Koehn and Hieu Hoang.
2007.
Factored Transla-tion Models.
In Proc.
of EMNLP.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In ACL2007, Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics CompanionVolume Proceedings of the Demo and Poster Sessions,pages 177?180, Prague, Czech Republic, June.
Asso-ciation for Computational Linguistics.Philipp Koehn, Barry Haddow, Philip Williams, and HieuHoang.
2010.
More linguistic annotation for statis-tical machine translation.
In Proceedings of the JointFifth Workshop on Statistical Machine Translation andMetricsMATR, WMT ?10, pages 115?120, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Evgeny Matusov, Gregor Leusch, Rafael E. Banchs,Nicola Bertoldi, Daniel Dechelotte, Marcello Fed-erico, Muntsin Kolss, Young-Suk Lee, Jose B. Marino,Matthias Paulik, Salim Roukos, Holger Schwenk, andHermann Ney.
2008.
System Combination for Ma-chine Translation of Spoken and Written Language.IEEE Transactions on Audio, Speech and LanguageProcessing, 16(7):1222?1237, September.Franz Josef Och and Hermann Ney.
2000.
A Comparisonof Alignment Models for Statistical Machine Transla-tion.
In Proceedings of the 17th conference on Com-putational linguistics, pages 1086?1090.
Associationfor Computational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In ACL 2002, Proceed-ings of the 40th Annual Meeting of the Association forComputational Linguistics, pages 311?318, Philadel-phia, Pennsylvania.Martin Popel and Zdene?k Z?abokrtsky?.
2010.
TectoMT:Modular NLP Framework.
In Hrafn Loftsson, EirikurRo?gnvaldsson, and Sigrun Helgadottir, editors, Lec-ture Notes in Artificial Intelligence, Proceedings of the7th International Conference on Advances in Natu-ral Language Processing (IceTAL 2010), volume 6233of Lecture Notes in Computer Science, pages 293?259304, Berlin / Heidelberg.
Iceland Centre for LanguageTechnology (ICLT), Springer.Ananthakrishnan Ramanathan, Hansraj Choudhary,Avishek Ghosh, and Pushpak Bhattacharyya.
2009.Case markers and morphology: addressing the cruxof the fluency problem in english-hindi smt.
InProceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processing ofthe AFNLP: Volume 2 - Volume 2, ACL ?09, pages800?808, Stroudsburg, PA, USA.
Association forComputational Linguistics.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings AMTA, pages 223?231, August.Drahom?
?ra Spoustova?, Jan Hajic?, Jan Votrubec, Pavel Kr-bec, and Pavel Kve?ton?.
2007.
The best of two worlds:Cooperation of statistical and rule-based taggers forczech.
In Proceedings of the Workshop on Balto-Slavonic Natural Language Processing, ACL 2007,pages 67?74, Praha.Sara Stymne.
2008.
German Compounds in FactoredStatistical Machine Translation.
In Bengt Nordstrmand Aarne Ranta, editors, Advances in Natural Lan-guage Processing, volume 5221 of Lecture Notes inComputer Science, pages 464?475.
Springer Berlin /Heidelberg.Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.2008.
Applying morphology generation models tomachine translation.
In Proceedings of ACL-08: HLT,pages 514?522, Columbus, Ohio, June.
Associationfor Computational Linguistics.Reyyan Yeniterzi and Kemal Oflazer.
2010.
Syntax-to-morphology mapping in factored phrase-based statis-tical machine translation from english to turkish.
InProceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 454?464,Uppsala, Sweden, July.
Association for ComputationalLinguistics.260
