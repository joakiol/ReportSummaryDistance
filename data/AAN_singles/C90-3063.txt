Automatic Processing of Large Corpora fbr the Resolution ofAnaphor  ReferencesIdo Dagan * Alon ItaiComputer Science DepartmentTechnion, tIaifa, Israeldagan~techunix .b i tnet ,  i ta i~ cs.technion, ac.ilAbstractManual acquisition of semantic onstraints in broaddomains is very expensive.
This paper presents anautomatic scheme for collecting statistics on cooc-currence patterns in a large corpus.
To a large ex-tent, these statistics reflect, semantic onstraints andthus are used to disambiguate anaphora referencesand syntactic ambiguities.
The scherne was imple-mented by gathering statistics on the output of otherlinguistic tools.
An experiment was performed toresolve references of the pronoun "it" in sentencesthat were randomly selected from the corpus.
Ttleresults of the experiment show that in most of thecases the cooccurrence statistics indeed reflect thesemantic onstraints and thus provide a basis {'or auseful disambiguat.ion tool.1 Introduct ionThe use of selectional constraints i one of the mostpopular methods in applying semantic informationto the resolution of ambiguities in natural anguages.The constraints typically specify which combina-tions of semantic lasses are acceptable in subject-verb-object relationships and other syntactic struc-tures.
This information is used to filter ont someanalyses of ambiguous constructs or to set prefer-ences between alternatives.Though the use of selectional constraints i verypopular, there is very little success (if any) in im-plementing this method for broad domains.
Themajor problem is the huge amount of informationthat must be acquired in order to achieve a rea-sonable representation of a large domain.
In orderto overcome this problem, our project suggests analternative to the traditional model, based on auto-matic acquisition of constraints fl'om a large corpus.The rest of the paper describes how this method isused to resolve anaphora references.
Similarly, theconstraints are used also to resolve syntactic am-biguities, but this will not be described here.
The*Part of this resem'ch was conducted wb.ile visiting IBMT.
J. Watson Research Center, Yorktown Ileights, NYreader should bare in mind that like the conven-tional use of selectional constraints, our method isinteuded to work in co,tjunction with other disam-biguation means.
These, such as various syntacticand pragmatic onstraints and heuristics \[Carbonetland Brown P.)88, tlobbs 1978\], represent additionallevels of knowledge and are essential when selec-tional constraints are not sufficient.2 The Statist ical  ApproachAccording to the statistical model, cooccurrencepatterns that were observed in tile corpns are usedas selection patterns.
Whenever several alternativesare presented by an ambiguous construct, we preferthe one correspot~ding t.omore frequent patterns.When using selectional constraints for anaphoraresolution, the referent must satisfy the constraintswhich are imposed on the anaphor.
If the anaphorparticipates in a certain syntactic relation, like be-ing an object of some verb, then the substitutionof the anaphor with the referent must satisfy theselectional constraim.s.
In the statistical model, wesubstitute ach of the candidt~tes with the anaphorand approve only those candidates which producefrequent cooccurrence patterns.
Consider, for exam-pie, the following sentence, taken from the Hansardcorpus of the proceedings of the Canadian parlia-ment \[Brown et al 1988\]:(1) They know full well that the companies heldtax money aside for collection later on the b~sisthat the government said it was going to collectit.There are two occurrences of "it" in this sentence.The first serves ~ the subject of "collect" and thesecond as its object.
We gathered the statistics forthree candidates which occur in the sentence: "col-lection", "money" and "government".
According tothe syntactic structure of the sentence, each of themmay serw~' aL, s the referent for each of the occurrencesof the pronoun.
The following table lists the pat-terns that were produced by substituting each can-330 1didate with the anaphor, and the number of timeseach of these patterns occurred in the corpus:subject-verb collection collect 0subject-verb money collect Ssubject-verb government collect 198verb -ob jec t  collect collection 0verb.-obj ect  collect money 149verb-~object collect government 0According to these statistics "government" is pre-ferred as the reti~rent of the first "it", and "money"of the second.This example demonstrates the case of definite se.-mantle constraints which eliminate all but the cor-rect alternative.
In other cases, several alternativesmay ,;atisfy the selectional constraints, and may beobserved in the corpus a significant number of times.In such cases the tlnal selection between the ap-proved candidates hould be performed by othermeans, such as syntactic heuristics or asking theuser.
Another passibility may be to use statisticalpreferences, and prefer the relatively more frequentpatterns, tlowever, at this stage it is not clear to ushow useflfl the statistical preference can be, and weuse the statistics only relative to a certain threshold,approving any patterns that pass this threshold.3 Implementing the Acquisi-tion PhaseThe use of the statistical model involves two sepa-rate phases.
The first is the acquisition pha.se, inwhich the corpus is processed and the statisticaldatabase is built.
The second is the disambigua-tion phase, in which the statistical datab~Lse is usedto resolve ambiguities.The statistical database contains cooccurrencepatterns for various syntactic relations.
In the ex-periment reported here we have used constraints forthe %ubject-verb", "verb-object" and "adjective-noun" relations.
To locate these relations in thesentences of the corpus, each sentence is parsedby the PEG parser \[Jensen 1986\].
Then, a post-processing algorithm identifies the various relationsin the parse tree.
As wa.s noted in \[Grishman etal.
1986\], the cooccurrence patterns reflect regu-larized or canonical structure.
Therefore the post-processing algorithm has to map surface structuresinto the normalized relations.
During our experi-ments we have used two different implementationsfor this algorithm \[Lappin et al 1988\] [Jensen 1989\],which take into account structures like passives, sub-clauses, questions and relative and infinitive clauses.The use of an automatic procedure for extractinginformation from a corpus that was not preprocessedmanually raises a basic problem of circularity.
Sincethe corpus was not disambiguated, it is not possibleto distinguish the semantically correct patterns fromthe incorrect ones.
Both types of ambiguity, syntac-tic and lexical, may cause the system to acquire oruse inappropriate patterns.
This problems is consid~ered very important when dealing with a corpus: itwas the re,Leon for the substantial human interven-tion in the procedure of \[Grishman et al 1986\], andit is the reason why other techniques use manuallytagged corpora (e.g.
\[Church 1988\]).In practice, however, we have discovered that theproblem is not so cruciah semantically vMid pat-terns have occurred many more times in syntac-tically unambiguous constructs than in mnbiguousones.
Thus, they could be identified without theneed of first disambiguating the sentences.
Seman-tically non-valid patterns indeed occurred in the in-appropriate parses but they were too rare to passthe threshold.
As tbr lcxical ambiguities, the chancethat one sense of a word will be confused with an-other during disambiguation seems to be very small,and it never happened in our experiment.4 The ExperimentAn experiment was performed to resolve referencesof the anaphor "it" in the IIansard corpus.
Theexamples of the ambiguous entences were selectedin tile following way: First, sentences containing theword "it" were extracted randomly from the corpus.Then, we manually filtered out sentences that werenot relevant for the use of selectional constraints inresolving anaphoric references.
Such cases were non-anaphoric occurrences of "it", cases where the ref-erent was not a noun phrase and cases where theanaphor was not involved in one of the three rela-tions that we used.
In addition, we have excludedcases where there was only one possible referent,so that our results will reflect correctly the perfor~mance of the disambiguation method.
The filteringprocess eliminated about two t.hirds of the originalsentences, and we proceeded with 59 examples.
Thealternative candidates for the referent (which satisfydefinite syntactic constrair, ts such as number, gen-der and requirements for reflexives) were identifiedmanually in each example.
1The statistics were collected from part o\[ the cor-pus, of about 28 million words.
For 21 out of the 59examples the statistics were not meaningful (we useda threshold of 5 occurrences for each of the alterna-tive patterns).
In these cases the algorithm cannotapprove any of the candidates, getting a "coverage"of 38/59 (64%).As explained in Section 2, the output of the sta-tistical method is used to represent the selectional1 The l lansard corpus, as maintained by the speech g\]'oupat IBM Watson Research Center, does not contain consec-utive sentences.
Therefore, we identified only candidaLeswithin the same sentence as the anaphor.
"I'o provide enoughcandidales, we examined occurrences of "it" ~ffter the 15thword of the senLence.
The examples provided between 2 to 5candidates, with an average of 2,8 candidates per anaphor.2 331constraints.
This is done by approving all pat-terns which appeared a significant nunaber of times.Therefore, the output is considered correct if theappropriate candidate is approved.
This happenedin 33 cases, getting "accuracy" of 33/38 (87%).
In18 of these cases, the appropriate candidate was theonly one which was approved, getting a completeresolution of the ambiguity.This last result demonstrates the advantage of thestatistical data over semantic onstraints.
While se-mantic constraints should approve any combinationof arguments in a syntactic relation that may oc-cur in the text, the statistics approve only thosecombinations that actually occur and reject others.Manual observation of the 18 sentences in which thestatistics completely resolved the ambiguity showedthat only in 7 cases the ambiguity could be elim-inated by traditional selectional constraints.
Thisis consistent with the evaluation in \[Itobbs 1978\],where only in 12 out of 132 sentences the ambiguitywas eliminated by selectional constraints.An additional note should be made concerning thetechnical methodology of the experiment.
Withinthe limited resources of our research, it was not fea-sible to build the statistical database for the entireItansard corpus, which contains about 60 millionwords.
The expensive resources are the parsing timeand the storage for the cooceurrence patterns andtheir statistics.
~ However, it turns out that pars-ing the entire corpus is not necessary to evaluatethe success of the statistical model!
As the evalu-ation relates to a limited number of examples, it issufficient o collect the statistics only for patternsthat are relevant for the disambiguation of these ex-amples.
Therefore, we have extracted from the cor-pus only those sentences that contained at least onecooccurrenee of words from a relevant pattern.
Thisprocedure allowed us to parse only 10,000 sentences.5 ConclusionsWe have suggested using cooccurrence patterns, au-tomatically acquired from a large corpus, as an alter-native to selectional constraints.
The initial resultsindicate that even in its basic form, as presentedhere, the approach is useful for disambiguation, andmany times performs even better than the tradi-tional model.
This should be considered relative tothe effort that would have been required to achievesuch coverage and accuracy by manual acquisitionof constraints, for the broad domain of parliamentproceedings.SAlthough the constnlction of the full size database is notfeasible for us, it is clearly feasible for a large scale project.This is shown by a similar database that w~s implementedas part of the laslgllage model of the IBM speech recognitionsystem.
3?his database contalns counters for occurrences ofsequences of three words in lm'ge corpora (trigrams), whicharc much more numerous than our syntactic patterns.In a general perspective, this project promotes theuse of a large corpus for linguistic research and ap-plications.
Processing such large corpora is a non-trivial engineering problem, the solution of whichenables research to focus on complicated real worldsentences.
Our research demonstrates how statisti-cal methods can be built on top of more 'traditional'linguistic tools, achieving a better and more feasibleenvironment for the resolution of ambiguities.6 AcknowledgementsWe would like to thank Mori Rimon, Shalom Lap-pin, Wlodek Zadrozny, Slavs Katz, John Justeson,Lisa Braden-Harder and Peter Brown for their fruit-ful advice and technical support.7 References\[Brown et al 1988\] Brown, P., Cocke, J., DellaPietra, S., Della Pietra, V., Jelinek, F., Mercer,R.L.
and Roossin P.S., A statistical approachto language translation, COLING 1988.\[Carbonell and Brown 1988\] Carbonell, J. G. andBrown, R. D. Anaphora resolution: A multistrategy approach, COLING I988.\[Church 1988\] Church, K. W., A stochastic partsprogram and noun phrase parser for unre-stricted text, ACL Conf.
on Applied NLP,1988.\[Grishman et al 1986\] R. Grishman, L. Hirschmanand Ngo Thanh Nhan, Discovery procedures forsublanguage selectional patterns initial experi-ments, Computational Linguislics, vol.
12,205-214, 1986.\[Hobbs 1978\] ttobbs, J. R. Resolving pronoun ref-erences, Lingua, vol.
44,311-338, 1978.\[Jensen 1986\] K. Jensen, PEG 1986: A broad-coverage computational syntax of English,Technical Report, IBM T. J. Watson ResearchCenter, 1986.\[Jensen 1989\] Jensen, K. PEGASOS: Derivingpredicate-argument structures after a syntacticparse.
Presented at the International Work-shop on Parsing Technologies, Carnegie MellonUniversity, August 1989.\[Lappin et al 1989\] S. Lappin, I. Golan, M. Ri-mon, Computing grammatical fimctions froma configurational parse tree, Technical Report88.268, IBM Israel Center of Science and Tech-nology, 1989.332 3
