Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 236?240,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsSliding Alignment Windows for Real-Time Crowd CaptioningMohammad Kazemi, Rahman Lavaee, Iftekhar Naim and Daniel GildeaDept.
of Electrical and Computer Engineering andDept.
of Computer ScienceUniversity of RochesterRochester, NY 14627AbstractThe primary way of providing real-timespeech to text captioning for hard of hear-ing people is to employ expensive profes-sional stenographers who can type as fastas natural speaking rates.
Recent work hasshown that a feasible alternative is to com-bine the partial captions of ordinary typ-ists, each of whom is able to type onlypart of what they hear.
In this paper, weextend the state of the art fixed-windowalignment algorithm (Naim et al, 2013)for combining the individual captions intoa final output sequence.
Our method per-forms alignment on a sliding window ofthe input sequences, drastically reducingboth the number of errors and the latencyof the system to the end user over the pre-viously published approaches.1 IntroductionReal-time captioning provides deaf or hard ofhearing people access to speech in mainstreamclassrooms, at public events, and on live televi-sion.
Studies performed in the classroom set-ting show that the latency between when a wordwas said and when it is displayed must be underfive seconds to maintain consistency between thecaptions being read and other visual cues (Wald,2005; Kushalnagar et al, 2014).
The most com-mon approach to real-time captioning is to recruita trained stenographer with a special purpose pho-netic keyboard, who transcribes the speech to textwith less than five seconds of latency.
Unfortu-nately, professional captionists are quite expensive($150 per hour), must be recruited in blocks of anhour or more, and are difficult to schedule on shortTXLFNIR[OD]\GRJ&RPELQHUWKHEURZQIR[MXPSHGIR[MXPSHGRYHUWKHOD]\WKHTXLFNEURZQIR[MXPSHGRYHUWKHOD]\GRJ)LQDO&DSWLRQ0HUJLQJ,QFRPSOHWH&DSWLRQV&&&Figure 1: General layout of crowd captioning sys-tems.
Captionists (C1, C2, C3) submit partial cap-tions that are automatically combined into a high-quality output.notice.
Automatic speech recognition (ASR) sys-tems (Saraclar et al, 2002), on the other hand, at-tempts to provide a cheap and fully automated so-lution to this problem.
However, the accuracy ofASR quickly plummets to below 30% when usedon an untrained speaker?s voice, in a new environ-ment, or in the absence of a high quality micro-phone (Wald, 2006).
The accuracy of the ASRsystems can be improved using the ?re-speaking?technique, which requires a person that the ASRhas been trained on to repeat the words said by aspeaker as he hears them.
Simultaneously hearingand speaking, however, is not straightforward, andrequires some training.An alternative approach is to combine the ef-forts of multiple non-expert captionists (anyonewho can type), instead of relying on trained work-ers (Lasecki et al, 2012; Naim et al, 2013).
Inthis approach, multiple non-expert human work-ers transcribe an audio stream containing speechin real-time.
Workers type as much as they can of236the input, and, while no one worker?s transcript iscomplete, the portions captured by various work-ers tend to overlap.
For each input word, a time-stamp is recorded, indicating when the word istyped by a worker.
The partial inputs are com-bined to produce a final transcript (see Figure 1).This approach has been shown to dramatically out-perform ASR in terms of both accuracy and WordError Rate (WER) (Lasecki et al, 2012; Naim etal., 2013).
Furthermore, recall of individual wordsirrespective of their order approached and even ex-ceeded that of a trained expert stenographer withseven workers contributing, suggesting that the in-formation is present to meet the performance ofa stenographer (Lasecki et al, 2012).
However,aligning these individual words in the correct se-quential order remains a challenging problem.Lasecki et al (2012) addressed this alignmentproblem using off-the-shelf multiple sequencealignment tools, as well as an algorithm based onincrementally building a precedence graph overoutput words.
Improved results for the alignmentproblem were shown using weighted A?searchby Naim et al (2013).
To speed the search forthe best alignment, Naim et al (2013) divided se-quences into chunks of a fixed time duration, andapplied the A?alignment algorithm to each chunkindependently.
Although this method speeds thesearch for the best alignment, it introduces a sig-nificant number of errors to the output of the sys-tem due to inconsistency at the boundaries of thechunks.
In this paper, we introduce a novel slid-ing window technique which avoids the errors pro-duced by previous systems at the boundaries ofthe chunks used for alignment.
This techniqueproduces dramatically fewer errors for the sameamount of computation time.2 Problem Overview and BackgroundThe problem of aligning and combining multipletranscripts can be mapped to the well-studiedMul-tiple Sequence Alignment (MSA) problem (Edgarand Batzoglou, 2006).
Let S1, .
.
.
, SK,K ?
2,be the K sequences over an alphabet ?, and hav-ing length N1, .
.
.
, NK.
For the caption align-ment task, we treat each individual word as a sym-bol in our alphabet ?.
The special gap symbol???
represents a missing word and does not be-long to ?.
Let A = (aij) be a K ?
Nfmatrix,where aij?
?
?
{?
}, and the ithrow has exactly(Nf?Ni) gaps and is identical to Siif we ignoreAlgorithm 1 MSA-A?AlgorithmRequire: K input sequences S = {S1, .
.
.
, SK} havinglength N1, .
.
.
, NK, heuristic weight w, beam size binput start ?
NK, goal ?
Nkoutput an N ?K matrix of integers indicating the index intoeach input sequence of each position in the output se-quence1: g(start)?
0, f(start)?
w ?
h(start).2: Q?
{start}3: while Q 6= ?
do4: n?
EXTRACT-MIN(Q)5: for all s ?
{0, 1}K?
{0K} do6: ni?
n + s7: if ni= goal then8: Return the alignment matrix for the recon-structed path from start to ni9: else if ni6?
Beam(b) then10: continue;11: else12: g(ni)?
g(n) + c(n, ni)13: f(ni)?
g(ni) + w ?
h(ni)14: INSERT-ITEM(Q,ni, f(ni))15: end if16: end for17: end whilethe gaps.
Every column of A must have at leastone non-gap symbol.
Therefore, the jthcolumnof A indicates an alignment state for the jthposi-tion, where the state can have one of the 2K?
1possible combinations.
Our goal is to find the op-timum alignment matrix AOPTthat minimizes thesum of pairs (SOP) cost function:c(A) =?1?i?j?Kc(Aij) (1)where c(Aij) is the cost of the pairwise align-ment between Siand Sjaccording toA.
Formally,c(Aij) =?Nfl=1sub(ail, ajl), where sub(ail, ajl)denotes the cost of substituting ajlfor ail.
If ailand ajlare identical, the substitution cost is zero.The substitution cost for two words is estimatedbased on the edit distance between two words.
Theexact solution to the SOP optimization problem isNP-Complete (Wang and Jiang, 1994), but manymethods solve it approximately.
Our approach isbased on weighted A?search for approximatelysolving the MSA problem (Lermen and Reinert,2000; Naim et al, 2013).2.1 Weighted A?Search for MSAThe problem of minimizing the SOP cost functionfor K sequences is equivalent to estimating theshortest path between a single source node and asingle sink node in a K-dimensional mesh graph,where each node corresponds to a distinct positionin the K sequences.
The source node is [0, .
.
.
, 0]237Algorithm 2 Fixed Window AlgorithmRequire: K input sequences S = {S1, .
.
.
, SK} havinglengthN1, .
.
.
, NK, window parameter chunk length.1: start time?
02: while goal ?
[N1, .
.
.
, NK] do3: for all i do4: start[i]?
closest word(i, start time)5: end for6: end time?
start time + chunk length7: for all i do8: goal[i]?
closest word(i, end time)?
19: end for10: alignmatrix?MSA-A?
(start, goal)11: concatenate alignmatrix onto end of finalmatrix12: start time?
end time13: end while14: Return finalmatrixand the sink node is [N1, .
.
.
, NK].
The total num-ber of nodes in the lattice is (N1+1)?(N2+1)??
?
??
(NK+1), and each node has 2K?1 possiblesuccessors and predecessors.
The A?search algo-rithm treats each node position n = [n1, .
.
.
, nK]as a search state, and estimates the cost functiong(n) and the heuristic function h(n) for each state.The cost function g(n) represents the exact min-imum SOP cost to align the K sequences fromthe beginning to the current position.
The heuris-tic function represents the approximate minimumcost of aligning the suffixes of the K sequences,starting after the current position n. The com-monly used heuristic function is hpair(n):hpair(n) = L(n ?
t) =?1?i<j?Kc(A?p(?ni, ?nj))(2)where L(n ?
t) denotes the lower bound on thecost of the shortest path from n to destination t,A?pis the optimal pairwise alignment, and ?niisthe suffix of node n in the i-th sequence.
Theweighted A?search uses a priority queue Q tostore the search states n. At each step of the A?search algorithm, the node with the smallest eval-uation function, f(n) = g(n)+whpair(n) (wherew ?
1), is extracted from the priority queue Q andexpanded by one edge.
The search continues un-til the goal node is extracted from Q.
To furtherspeed up the search, a beam constraint is appliedon the search space using the timestamps of eachindividual input words.
If the beam size is set to bseconds, then any state that aligns two words hav-ing more than b seconds time lag is ignored.
Thedetailed procedure is shown in Algorithm 1.
Af-ter the alignment, the captions are combined viamajority voting at each position of the alignmentmatrix.
We ignore the alignment columns wherethe majority vote is below a certain threshold tv(typically tv= 2), and thus filter out spurious er-rors and spelling mistakes.Although weighted A?significantly speeds thesearch for the best alignment, it is still too slowfor very long sequences.
For this reason, Naimet al (2013) divided the sequences into chunks ofa fixed time duration, and applied the A?align-ment algorithm to each chunk independently.
Thechunks were concatenated to produce the final out-put sequence, as shown in Algorithm 2.2.2 Limitations of Fixed Window AlgorithmThe fixed window based alignment has two keylimitations.
First, aligning disjoint chunks inde-pendently tends to introduce a large number oferrors at the boundary of each chunk.
This isbecause the chunk boundaries are defined withrespect to the timestamps associated with eachword in the captions, but the timestamps canvary greatly between words that should in fact bealigned.
After all, if the timestamps correspondedprecisely to the original time at which each wordwas spoken, the entire alignment problem wouldbe trivial.
The fact that the various instances ofa single word in each transcription may fall on ei-ther side of a chunk boundary leads to errors wherea word is either duplicated in the final output formore than one chunk, or omitted entirely.
Thisproblem also causes errors in ordering among thewords remaining within one chunk, because thereis less information available to constrain the order-ing relations between transcriptions.
Second, thefixed window alignment algorithm requires longerchunks (?
10 seconds) to obtain reasonable accu-racy, and thus introduces unsatisfactory latency.3 Sliding Alignment WindowsIn order to address the problems described above,we explore a technique based on a sliding align-ment window, shown in Algorithm 3.
We startwith alignment with a fixed chunk size.
Afteraligning the first chunk, we use the informationderived from the alignment to determine wherethe next chunk should begin within each transcrip-tion.
We use a single point in the aligned outputas the starting point for the next chunk, and de-termine the corresponding starting position withineach original transcription.
This single point isdetermined by a tunable parameter keep length238Algorithm 3 Sliding Window AlgorithmRequire: K input sequences S = {S1, .
.
.
, SK}having length N1, .
.
.
, NK, window parameterschunk length and keep length.1: start?
0K, goal?
0K2: while goal ?
[N1, .
.
.
, NK] do3: endtime?
chunk length+maxitime(start[i])4: for all i do5: goal[i]?
closest word(i, endtime)6: end for7: alignmatrix?MSA-A?
(start, goal)8: concatenate first keep length columns ofalignmatrix onto end of finalmatrix9: for all i do10: start[i]?
alignmatrix[keep length][i]11: end for12: end while13: Return finalmatrix00.10.20.30.40.50.60.7Accuracy(1?
WER)Sliding?window, k = 0.50Sliding?window, k = 0.67Sliding?window, k = 0.85Graph?basedMUSCLEFixed?windowFigure 2: Evaluation of different systems on usingWER metric for measuring transcription quality.
(line 10 of Algorithm 3).
The materials in theoutput alignment that follow this point is thrownaway, and replaced with the output produced byaligning the next chunk starting from this point(line 8).
The process continues iteratively, allow-ing us to avoid using the erroneous output align-ments in the neighborhood of the arbitrary end-points for each chunk.4 Experimental ResultsWe evaluate our system on a dataset of four 5-minute long audio clips of lectures in electricalengineering and chemistry lectures taken fromMIT OpenCourseWare.
The same dataset usedby (Lasecki et al, 2012) and (Naim et al, 2013).Each audio clip is transcribed by 10 non-experthuman workers in real time.
We measure the ac-curacy in terms of Word Error Rate (WER) withrespect to a reference transcription.We are interested in investigating how the three5 10 15 20 25 300.460.480.50.520.540.560.580.60.62Latency (millisecond)Accuracy(1?WER)sliding window, k = 50 %sliding window, k = 67 %sliding window, k = 85 %fixed window(a) varying keep-lengths for fixed heuristic weight4000 6000 8000 10000 12000 140000.480.50.520.540.560.580.60.62Average Running Time (millisecond)Accuracy(1?
WER)w = 3w = 4w = 6w = 8(b) varying heuristic weights for fixed keep-lengthFigure 3: Tradeoff between speed and accuracyfor different heuristic wights and keep-lengthskey parameters of the algorithm, i.e., the chunksize (c), the heuristic weight (w) and the keep-length (k), affect the system latency, the searchspeed, and the alignment accuracy.
The chunk sizedirectly determines the latency of the system to theend user, as alignment cannot begin until an entirechunk is captured.
Furthermore, the chunk size,the heuristic weight, and the keep-length help usto trade-off speed versus accuracy.
We also com-pare the performance of our algorithm with thatof the most accurate fixed alignment window al-gorithm (Naim et al, 2013).
The performancein terms of WER for sliding and fixed alignmentwindows is presented in Figure 2.
Out of the sys-tems in Figure 2, the first three systems consist ofsliding alignment window algorithm with differentvalues of keep-length parameter: (1) keep-length= 0.5; (2) keep-length = 0.67; and (3) keep-length= 0.85.
The other systems are the graph-based al-gorithm of (Lasecki et al, 2012), the MUSCLEalgorithm of (Edgar, 2004), and the most accu-239rate fixed alignment window algorithm of (Naimet al, 2013).
We set the heuristic weight param-eter (w) to 3 and the chunk size parameter (c) to5 seconds for all the three sliding window sys-tems and the fixed window system.
Sliding align-ment window produces better results and outper-forms the other algorithms even for large values ofthe keep-length parameter.
The sliding alignmentwindow with keep-length 0.5 achieves 0.5679 av-erage accuracy in terms of (1-WER), providing a18.09% improvement with respect to the most ac-curate fixed alignment window (average accuracy0.4857).
On the same dataset, Lasecki et al (2012)reported 36.6% accuracy using the Dragon Natu-rally Speaking ASR system (version 11.5 for Win-dows).To show the trade-off between latency and ac-curacy, we fix the heuristic weight (w = 3) andplot the accuracy as a function of chunk size inFigure 3.
We repeat this experiment for differentvalues of keep-length.
We observe that the slid-ing window approach dominates the fixed windowapproach across a wide range of chunk sizes.
Fur-thermore, we can see that for smaller values of thechunk size parameter, increasing the keep-lengthmakes the system less accurate.
As the chunksize parameter increases, the performance of slid-ing window systems with different values of keep-length parameter converges.
Therefore, at largerchunk sizes, for which there are smaller number ofboundaries, the keep-length parameter has lowerimpact.Next, we show the trade-off between computa-tion speed and accuracy in Figure 3, as we fix theheuristic weight and vary the chunk size over therange [5, 10, 15, 20, 30] seconds.
Larger chunksare more accurately aligned but require computa-tion time that grows as NKin the chunk size N inthe worst case.
Furthermore, smaller weights al-low faster alignment, but provide lower accuracy.5 ConclusionIn this paper, we present a novel sliding win-dow based text alignment algorithm for real-timecrowd captioning.
By effectively addressing theproblem of alignment errors at chunk boundaries,our sliding window approach outperforms the ex-isting fixed window based system (Naim et al,2013) in terms of word error rate, particularlywhen the chunk size is small, and thus achieveshigher accuracy at lower latency.Acknowledgments Funded by NSF awards IIS-1218209 and IIS-0910611.ReferencesRobert C Edgar and Serafim Batzoglou.
2006.
Mul-tiple sequence alignment.
Current opinion in struc-tural biology, 16(3):368?373.Robert C Edgar.
2004.
MUSCLE: multiple sequencealignment with high accuracy and high throughput.Nucleic Acids Research, 32(5):1792?1797.Raja S Kushalnagar, Walter S Lasecki, and Jeffrey PBigham.
2014.
Accessibility evaluation of class-room captions.
ACM Transactions on AccessibleComputing (TACCESS), 5(3):7.Walter Lasecki, Christopher Miller, Adam Sadilek, An-drew Abumoussa, Donato Borrello, Raja Kushalna-gar, and Jeffrey Bigham.
2012.
Real-time caption-ing by groups of non-experts.
In Proceedings of the25rd annual ACM symposium on User interface soft-ware and technology, UIST ?12.Martin Lermen and Knut Reinert.
2000.
The practi-cal use of the A* algorithm for exact multiple se-quence alignment.
Journal of Computational Biol-ogy, 7(5):655?671.Iftekhar Naim, Daniel Gildea, Walter Lasecki, and Jef-frey Bigham.
2013.
Text alignment for real-timecrowd captioning.
In Proceedings of the 2013 Meet-ing of the North American chapter of the Associationfor Computational Linguistics (NAACL-13).Murat Saraclar, Michael Riley, Enrico Bocchieri, andVincent Goffin.
2002.
Towards automatic closedcaptioning: Low latency real time broadcast newstranscription.
In Proceedings of the InternationalConference on Spoken Language Processing (IC-SLP), pages 1741?1744.Mike Wald.
2005.
Using automatic speech recognitionto enhance education for all students: Turning a vi-sion into reality.
In Proceedings 35th Annual Con-ference on Frontiers in Education, 2005.
FIE ?05.,pages S3G?S3G, Oct.Mike Wald.
2006.
Creating accessible educationalmultimedia through editing automatic speech recog-nition captioning in real time.
Interactive Technol-ogy and Smart Education, 3(2):131?141.Lusheng Wang and Tao Jiang.
1994.
On the complex-ity of multiple sequence alignment.
Journal of Com-putational Biology, 1(4):337?348.240
