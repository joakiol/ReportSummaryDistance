Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 109?117,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsCombining Compositionality and Pagerank for the Identification ofSemantic Relations between Biomedical WordsThierry HamonLIM&BIO UFR SMBHUniversite?
Paris 13, Francethierry.hamon@univ-paris13.frChristopher Engstro?mDivision of Applied MathematicsMa?lardalen UniversityVa?stera?s, SwedenMounira ManserLIM&BIO UFR SMBHUniversite?
Paris 13, FranceZina Badji and Natalia GrabarCNRS UMR 8163 STLUniversite?
Lille 1&359653 Villeneuve d?Ascq, Francenatalia.grabar@univ-lille3.frSergei SilvestrovDivision of Applied MathematicsMa?lardalen UniversityVa?stera?s, SwedenAbstractThe acquisition of semantic resources and re-lations is an important task for several appli-cations, such as query expansion, informationretrieval and extraction, machine translation.However, their validity should also be com-puted and indicated, especially for automaticsystems and applications.
We exploit the com-positionality based methods for the acquisi-tion of synonymy relations and of indicatorsof these synonyms.
We then apply pager-ank-derived algorithm to the obtained seman-tic graph in order to filter out the acquired syn-onyms.
Evaluation performed with two inde-pendent experts indicates that the quality ofsynonyms is systematically improved by 10 to15% after their filtering.1 IntroductionNatural languages have extremely rich means to ex-press or to hide semantic relations: these can bemore or less explicit.
Nevertheless, the semanticrelations are important to various NLP tasks withingeneral or specialized languages (i.e., query expan-sions, information retrieval and extraction, text min-ing or machine translation) and their decipheringmust be tackled by automatic approaches.
We fo-cus in this work on synonymy relations.
Thus, itis important to be able to decide whether two terms(i.e., anabolism and acetone anabolism, acetone an-abolism and acetone biosynthesis, replication of mi-tochondrial DNA and mtDNA replication) conveythe same, close or different meanings.
According tothe ability of an automatic system to decipher suchrelations, the answers of the system will be more orless exhaustive.
Several solutions may be exploitedwhen deciphering the synonymy relations:1.
Exploitation of the existing resources in whichthe synonyms are already encoded.
However,in the biomedical domain, such resources arenot well described.
If the morphological de-scription is the most complete (NLM, 2007;Schulz et al, 1999; Zweigenbaum et al, 2003),little or no freely available synonym resourcescan be found, while the existing terminologiesoften lack the synonyms.2.
Exploitation and adaptation of the existingmethods (Grefenstette, 1994; Hamon et al,1998; Jacquemin et al, 1997; Shimizu et al,2008; Wang and Hirst, 2011).3.
Proposition of new methods specificallyadapted to the processed data.Due to the lack of resources, we propose to ex-ploit the solutions 2 and 3.
In either of these situ-ations, the question arises about the robustness andthe validity of the acquired relations.
For instance,(Hamon and Grabar, 2008) face two problems: (1)contextual character of synonymy relations (Cruse,1986), i.e., two words are considered as synonymsif they can occur within the same context, whichmakes this relation more or less broad depending onthe usage; (2) ability of automatic tools to detect andcharacterize these relations, i.e., two words taken outof their context can convey different relations thanthe one expected.
Our objective is to assess the relia-bility of synonymy resources.
We propose to weightand to filter the synonym relations with the pager-ank-derived algorithm (Brin and Page, 1998).
When109headcomponentcomponentexpansionstoragelipidcomponentexpansionheadcomponentretention lipids(of)Figure 1: Parsing tree of the terms lipid storage and re-tention of lipidsprocessing textual data, this algorithm has been pre-viously applied in different contexts such as seman-tic disambiguation (Mihalcea et al, 2004; Sinha andMihalcea, 2007; Agirre and Soroa, 2009), summa-rization (Fernandez et al, 2009) and, more recently,for the identification of synonyms (Sinha and Mi-halcea, 2011).
This last work takes into account theusage of a given word in corpora and its known syn-onyms from lexical resources.
Other related workspropose also the exploitation of the random walk al-gorithm for the detection of semantic relatedness ofwords (Gaume, 2006; Hughes and Ramage, 2007)and of documents (Hassan et al, 2007).
Our workis different from the previous work in several ways:(1) the acquisition of synonymy is done on resourcesprovided by a specialized domain; (2) the pager-ank algorithm is exploited for the filtering of seman-tic relations generated with linguistically-based ap-proaches; (3) the pagerank algorithm is adapted tothe small size of the processed data.In the following of this paper, we present first thematerial (section 2), then the method we propose(section 3).
We then describe the experiments per-formed and the results (section 4), as well as theirevaluation and discussion (section 5).
Finally, weconclude and indicate some perspectives (section 6).2 MaterialWe use the Gene Ontology (GO) as the original re-source from which synonym lexicon (or elementarysynonym relations) are induced.
The goal of the GOis to produce a structured vocabulary for describingthe roles of genes and their products in any organ-ism.
GO terms are structured with four types of re-lations: subsumption is-a, meronymy part-of,synonymy and regulates.
The version used inthe current work is issued from the UMLS 2011AA.It provides 54,453 concepts and their 94,161 terms.The generated pairs of terms have 119,430 is-aand 101,254 synonymy relations.3 MethodsOur method has several steps: preprocessing of GOterms (section 3.1), induction of elementary syn-onyms (section 3.2) and their characterization withlexical and linguistic indicators (section 3.3), anal-ysis of the synonymy graph, its weighting thanks tothe pagerank algorithm and its filtering (section 3.4).We also perform an evaluation of the generated andfiltered synonymy relations (section 3.5).In the following, we call original synonyms thosesynonyms which are provided by GO, and we callelementary synonyms those synonyms which are in-duced by the compositionality based approach.3.1 Preprocessing the GO terms: Ogmios NLPplatformThe aim of terminology preprocessing step is toprovide syntactic analysis of terms for computingtheir syntactic dependency relations.
We use theOgmios platform1 and perform: segmentation intowords and sentences; POS-tagging and lemmatiza-tion (Tsuruoka et al, 2005); and syntactic analysis2.Syntactic dependencies between term componentsare computed according to assigned POS tags andshallow parsing rules.
Each term is considered asa syntactic binary tree composed of two elements:head component and expansion component.
For in-stance, lipid is the head component of the two termsanalyzed on figure 1.3.2 Compositionality based induction ofsynonymsGO terms present compositional structure (Verspooret al, 2003; Mungall, 2004; Ogren et al, 2005).
Inthe example below (concept GO:0009073) the com-positionality can be observed through the substitu-tion of one of the components (underlined):aromatic amino acid family biosynthesisaromatic amino acid family anabolismaromatic amino acid family formationaromatic amino acid family synthesisWe propose to exploit the compositionality for in-duction of synonym resources (i.e., biosynthesis, an-abolism, formation, synthesis in the given example).1http://search.cpan.org/?thhamon/Alvis-NLPPlatform/2http://search.cpan.org/?thhamon/Lingua-YaTeA/110While the cited works are based on the string match-ing, our approach exploits their syntactic analysis,which makes it independent on their surface graphi-cal form (like examples on figure 1).Compositionality assumes that the meaning of acomplex expression is fully determined by its syn-tactic structure, the meaning of its parts and the com-position function (Partee, 1984).
This assumption isvery often true in specialized langages, which areknown to be compositional.
On the basis of syntac-tically analysed terms, we apply a set of composi-tional rules: if the meaningM of two complex termsA rel B and A?
rel B, where A is its head and B itsexpansion components, is given as following:M(A rel B) = f(M(A),M(B),M(rel))M(A?
rel B) = f(M(A?
),M(B),M(rel))for a given composition function f , if A rel B andA?
rel B are complex synonym terms and if B com-ponents are identical (such as acetone within ace-tone catabolism and acetone breakdown), then thesynonymy relation between components A and A?
{catabolism, breakdown} can be induced.
The mod-ification is also accepted on expansion componentB: from terms replication of mitochondrial DNAand mtDNA replication (fig.
1), we can induce syn-onymy between mitochondrial DNA and mtDNA.Finally, the modification is also accepted for bothcomponents A rel B and A?
rel B?, such as innicotinamide adenine dinucleotide catabolism andNAD breakdown, where one pair, i.e.
{catabolism,breakdown}, can be known from previously pro-cessed synonyms and allow to induce the newpair {nicotinamide adenine dinucleotide, NAD}.
Itshould noticed that rel depends on the original re-lations: if the original terms are synonyms then theelementary terms are also synonyms, if the originalterms are hierarchically related then the elementaryterms are also hierarchically related, etc.3.3 Lexically-based profiling of the inducedelementary synonymsIn order to test and improve the quality of the in-duced synonymy relations, we confront these syn-onyms with approaches which allow to acquire thehyperonymy relations.
All these resources are endo-geneously acquired from the same terminology GO:?
Each induced pair of synonyms is controlledfor the lexical inclusion (Kleiber and Tamba,1990; Bodenreider et al, 2001).
If the test ispositive, like in the pair {DNA binding, bind-ing} this would suggest that this pair may con-vey a hierarchical relation.
Indeed, it has beenobserved that lexical subsumption marks oftena hierarchical subsumption.
Thus, in the pair{DNA binding, binding}, binding is the hierar-chical parent of DNA binding, while DNA bind-ing has a more specific meaning than binding.One can assume that the cooccurrence of syn-onymy with the lexical subsumption makes thesynonymy less reliable;?
The same compositional method, as describedin the previous section, is applied to originalGO term pairs related through is-a relations.In this way, we can also infer is-a elemen-tary relations.
Thus, if a pair of induced syn-onyms is also induced through is-a relations,i.e.
{binding, DNA binding}, this also makesthe synonymy relations less reliable.In summary, an induced synonymy relation is con-sidered to be less reliable when it cooccurs witha lexical inclusion or with is-a relation.
For in-stance, several edges from figure 2 present the cooc-currence of synonymy relations with the is-a rela-tions (such as, {holding, retention}, {retention, stor-age} or {retention, sequestering}).3.4 Pagerank-derived filtering of the inducedelementary synonymsThe induced semantic relations can be representedas graphs where the nodes correspond to words andthe edges to one or more relations between given twowords.
An example of what it can look like can beseen on figure 2: the induced synonymy relationsmay indeed cooccur with non-synonymy relations,like the hierarchical relations is-a.
We propose touse a pagerank approach (Brin and Page, 1998) inorder to separate a given graph of synonym relationsinto subsets (or groups) within which all the wordsare considered as synonyms with each other but notwith any other word outside their subset.
In ordernot to influence the results by the varying size ofthe graphs, we exploit a non-normalized version ofpagerank (Engstro?m, 2011).
Thus, given the usual111storage sequesteringholdingretentionsequestrationsyn(3), is?a(1)syn(1), is?a(3)syn(1), is?a(2)syn(2) syn(2)syn(2)Figure 2: An example of graph generated thanks to theinduced semantic relations: pairs related with synonymyrelations syn may also be related with non-synonymyrelations (like hierarchical relation is-a)normalized version P (1)Si of pagerank:Definition 1 P (1)S for system S is defined as theeigenvector with eigenvalue one to the matrixM = c(A+ gvT )T + (1?
c)v1Twhere g is a n ?
1 vector with zeros for nodes withoutgoing nodes and 1 for all dangling nodes, 0 <c < 1, A is the linkmatrix with sum of every rowequal to one, v is a non-negative weightvector withsum one.As we mentioned, with the processed data wehave to use the non-normalized version of pagerank:Definition 2 P (2)S for system S is defined as:P (2)S =P (1)S ||V ||1d,with d = 1?
?cATP (1)Swhere V is the part of a global weightvector corre-sponding to the system S. We let V be the one vectorsuch that all words are weighted equally.Looking at the example from figure 2, we startfrom any node and then randomly either stop by aprobability c or choose (possibly weighted by edge-weights) a new node by the probability 1 ?
c fromany of those linked to the chosen node.
The page-rank of a node can then be seen as the sum of theprobabilities of all paths to the node in question(starting in every node once including itself).Usually A is a two-dimensional matrix in whichthe sum of every row is equal to one and all non-zero elements are equal between them.
In order touse different types of relations and different weightson these relations we calculate cA.
Given B, whereB contains the weights of different edges and theirtype, we calculate A as:Ai,j = (Bi,j,SY N/(Bi,j,OTHER + 1))/niwhere ni is the total number of edges connected tonode i.
We treat all relations as symmetric relationsfor the filtering algorithm when creating B. Whilesome relations aren?t symmetric it seems reasonableto assume they affect the likelihood of synonyms inboth directions.
We also do not distinguish non-synonym relations among them.
However, we trya few variations on how to weight A such as assign-ing different weights to synonym and non-synonymrelations or using a logarithmic scale to decrease theeffect of very different weights in B.Further to the weighting, the rows of A do notnecessarily sum to one.
We propose then not tochoose a specific value for c, but to threshold thesum of every row in cA to 0.95.
This means that formost of the rows we set crow = 1/?Arow ?
0.95,but for rows with a low sum we don?t increase thestrength of the links but rather keep them as theyare (crow = 1).
Choosing the threshold can beseen as choosing c in the ordinary pagerank formu-lation.
A low threshold means that only the immedi-ate surrounding of a node may impact its pagerank,while a high threshold means that distant nodes mayalso have an impact.
Higher threshold is also use-ful to separate the pagerank of nodes and to makeslower the convergence when calculating the pager-ank.
When the sum of all rows is less than one andall non-zero elements are positive we can guaranteethat the pagerank algorithm converges (Bryan andLeise, 2006).
We also use the Power Method modi-fied for the non-normalized version of pagerank (En-gstro?m, 2011).
On the basis of these elements, weapply the following algorithm for segmenting thegraph into groups of nodes:1.
Calculate weighted linkmatrix;2.
Calculate pagerank from uniform weightvectorvi;1123.
Select the node with the highest pagerank;4.
Calculate pagerank from non-uniformweightvector (zero vector with a single 1for the selected node);5.
Nodes with P (2) > cutoff are selected as syn-onyms with selected node and each other;6.
Remove the found synonym nodes from thegraph;7.
If the graph is non empty, restart from step 1;8.
Otherwise end: words belonging to the samegroup are considered as synonyms.We present the application of the algorithm onthe example from figure 2 using the cutoff =1.5.
We start by calculating the weights on thelinks (weighted linkmatrix).
For instance, giventhe relation from storage to retention we have:Ai,j = (Bi,j,SY N/(Bi,j,OTHER + 1))/ni =(1/(2 + 1))/3 = 1/9.
After computing theweights for all the relations and thresholding thesum of rows to 0.95, when the sum of weightsout of a node is larger than 0.95, we obtain fig-ure 3.
This gives the pagerank from uniform vec-tor [4.8590, 7.7182, 16.4029, 16.1573, 15.4152], inwhich we select the node storage with the highestpagerank.
Pagerank from non-uniform weightvec-tor is then [0.5490, 1.0970, 4.7875, 4.0467, 3.9079],in which we select the nodes with rank larger thancutoff = 1.5 (storage, sequestration, sequestering)as synonyms.
After removing these nodes, we re-calculate the weight matrix and repeate the algo-rithm: the two remaining nodes are found to belongto the same group.
We then terminate the algorithm.3.5 Evaluation protocolThe evaluation is performed against the manuallyvalidated synonymy relations.
This validation hasbeen done by two independent experts with thebackground in biology.
They were asked to vali-date the induced synonyms acquired as the step 3.2of the method.
The inter-expert Cohen?s kappa is0.75.
On the basis of this evaluation, we computethe precision: percentage of relations which allow tocorrectly group terms within the connected compo-nents and the groups.
We compute two kinds of pre-cision (Sebastiani, 2002): micro-precision which isthe classical conception of this measure obtained at3: storage 4: sequestering1: holding2: retention5: sequestration0.060.070.50.440.480.480.450.110.450.080.950.44Figure 3: Example from figure 2 with weighted linksthe level of the relations, and macro-precision whichcorresponds to the mean of the precisions obtainedat the level of connected components or groups.
Theevaluation is done with the induced synonyms andalso after their filtering with the pagerank-derivedalgorithm.
This last evaluation leads to a better ob-servation of the efficiency of the pagerank algorithm.4 Experiments and ResultsThe GO terms have been fully processed with theNLP tools (POS-tagging and syntactic analysis) inorder to prepare the next step, during which the ele-mentary relations and the indicators are acquired.4.1 Application of the lexical NLP methodsWe applied the NLP method to the GO terms.The application of the compositionality approach tooriginal synonymy and hierarchical relations gen-erated 3,707 and 10,068 elementary relations, syn-onymous and hierarchical respectivelly.
Depend-ing on the syntactic structure of the original terms,the synonymy relations are induced between simpleor complex terms, but also between their abbrevi-ated and full forms, between the morpho-syntacticvariants, etc.
Very few of these synonyms existwithin GO or within the WordNet resource (Fell-baum, 1998).
We also detected 1,608 lexical in-clusions.
The lexical inclusions and the is-a re-lations are preserved only if they cooccur with in-113duced synonymy relations.
All these relations arethen grouped into connected components (figure 2):the synonymy relations correspond to edges, termcomponents correspond to nodes, while the infor-mation on is-a relations and on lexical inclusionsappears as reliability indicators of the synonymyedges.
A total of 2,017 connected components aregenerated.
The biggest connected component con-tains 140 nodes and 183 edges.
At this step, the con-nected components are evaluated against the refer-ence data: we compute the precision.4.2 Filtering of the induced synonyms with thepagerank-derived algorithmWe the apply the pagerank-derived algorithm to theinduced synonyms, but also to the combinations ofthese synonyms with is-a relations and/or withlexical inclusions.
The objective is then to filter theinduced synonyms and to improve their reliability.We perform seven experiments, in which the syn-onymy and the indicators may receive the same im-portance or may be weighted:1. syn: only the elementary synonymy relationsare considered;2. syn-isa: combination of synonymy and hierar-chical is-a relations;3. syn-incl: combination of synonymy relationswith lexical inclusions;4. syn-isa-incl: combination of synonymy and hi-erarchical relations with lexical inclusions;5. syn-isa(535): combination of synonymy rela-tions with lexical inclusions, using differentweights: (Ai,j = 5Bi,j,SY N/(3Bi,j,OTHER +5))/ni;6. syn-isa(353): combination of synonymy rela-tions with lexical inclusions, using differentweights: (Ai,j = 3Bi,j,SY N/(5Bi,j,OTHER +3))/ni.7.
syn-isa(log): combination of synonymy rela-tions with lexical inclusions, using logarithmicweights: (Ai,j = ((1/ln(2))ln(Bi,j,SY N +1)/((1/ln(2))ln(Bi,j,OTHER + 2)))/ni.According to the method described in section 3.4,the connected components of the synonymy rela-tions obtained in section 3.2 are segmented againinto one or more smaller and more homogeneousgroups.
The number of groups varies between 745and 1,798 across the experiments.
Moreover, around25% of the synonymy relations may be removed bypagerank.
These connected components and groupscan also be evaluated against the reference data andwe can compute the precision.5 Evaluation and DiscussionThe evaluation has been done by two indepen-dent experts, with the Cohen?s kappa inter-expertagreement 0.75.
We exploit the reference data ofthe two experts separately (we distinguish expert1and expert2) and in common.
We also distinguishmacro-precision and micro-precision.
Finally, theprecision is first evaluated after the induction stepwith the NLP methods, and then after the process-ing of the acquired synonymy relations through thepagerank-derived algorithm and their filtering.For the weighting of the non-synonymy and syn-onymy relations, we tested and applied several coef-ficients: 5, 3 and 5 in experiment 5 (syn-isa535); 3,5 and 3 in experiment 6 (syn-isa353), etc.
Differentweights have been tested ranging from 1 to 7, as wellas the log variations.
On the whole, these variationshave no significant impact on the results.
But then, itis very important to respect the dependence amongthese coefficients and not to set them randomly.The filtering of the synonymy relations has to con-trol two factors: (1) the first is related to the factthat the removed relations are to be true negativesand that among them there should be no or a smallnumber of correct relations; while (2) the second isrelated to the fact that the remaining relations are tobe true positives and that among them there shouldbe no or a small number of wrong relations.Figure 4: Impact of the cutoff values on the filtering ofsynonymy relations114miP_Exp1 maP_Exp1 miP_Exp2 maP_Exp20.60.650.70.750.80.850.90.9511  2  3  4  5  6  7before PagerankmaP_Exp1 and maP_Exp2before PagerankmiP_Exp1miP_Exp2 before Pagerank(a) Connected components with termsmiP_Exp1 maP_Exp1 miP_Exp2 maP_Exp20.60.650.70.750.80.850.90.9511  2  3  4  5  6  7before PagerankmaP_Exp1 and maP_Exp2before PagerankmiP_Exp1miP_Exp2 before Pagerank(b) Groups of termsFigure 5: Evaluation of the results in terms of micro-precision miP and of macro-precision maP for connectedcomponents and for groups of terms (performed according to the reference data provided by two experts)On figure 4, we present the impact of the cut-off values on the selection and filtering of the syn-onyms.
Like with other parameters, we have testedseveral values between 0.5 and 4.
This figure illus-trates the distribution of the correctly removed rela-tions.
The cutoff values have an important impacton the results: we can observe that the optimal cut-off values are set between 1.5 and 2 because theyallow to remove the highest number of the wrongrelations.
We have set the cutoff value to 1.5.
Thechoice of cutoff is an important factor for the defi-nition of the amount of the links that are to be re-moved: the higher the cutoff the higher the numberof clusters.
On the data processed in this work, thecutoff value has been defined experimentally thanksto the observation of the processed data.
For the gen-eralization of this method to new unknown but sim-ilar linguistic data (new terminology, new langage,new domain...), the cutoff will be either set in orderto remove a certain predefined number of links orwill be defined from a typical sample of the data.Contrary to the cutoff values, the choice of thresh-old doesn?t greatly impact the results, although us-ing a lower threshold makes it harder to choose agood cutoff values since the ranking of differentnodes will be closer to each other.As for the analysis of the precision and of therelations which are correctly kept within the con-nected components, let?s observe figure 5.
On thisfigure, we present the evaluation results performedwithin the connected components with induced syn-onyms (figure 5(a)) and within the groups of filteredsynonyms (figure 5(b)).
On the y-axis we indicatethe precision values, and on the x-axis, we indicatethe different experiments performed as mentionedabove: 1 in which only synonyms are exploited, 2in which synonyms are combined with hierarchicalis-a relations, 3 in which synonyms are combinedwith lexical inclusions, etc.
Horizontal lines corre-spond to the precision obtained before the applica-tion of the pagerank: they remain the same whateverthe experiment.
These lines correspond to three ref-erence data provided by the expert1, the expert2 andby their common data.
As for the points, they indi-cate the precision obtained further to the pagerank:it varies according to experiments and experts.
Onthe basis of figure 5, we can observe that:?
the difference between the expert evaluations isvery low (0.02);?
the pagerank allows to increase the precision(between 0.10 and 0.15 for micro-precision,while macro-precision varies by 0.05);?
the consideration of synonymy alone providesperformant results;?
the consideration of is-a relations improvesthe results but lexical inclusions decrease them;?
the increased weight of some of the quality in-dicators has no effect on the evaluation;?
macro-precision is superior to micro-precisionbecause our data contain mainly small groups,115while the few large connected components havea very low precision;?
there is but a small difference between con-nected components (figure 5(a)) and groups(figure 5(b));?
the consideration of is-a relations and of lex-ical inclusions provides the best precision butthe amount of the remaining synonyms is thenthe lowest.
As we explained, it is importantto keep the highest number of the correct re-lations, although when a lot of relations is re-moved, it is logical to obtain a higher precision.This means that the combination of is-a re-lations and of lexical inclusions is not suitablebecause it removes too much of synonyms.In relation with this last observation, is should benoted that the balance between the removed and theremaining relations is a subtle parameter.The obtained results indicate that the pagerank isindeed useful for the filtering of synonyms, althoughthe parameters exploited by this algorithm must bedefined accurately.
Thus, it appears that synonymyalone may be sufficient for this filtering.
When thequality indicators are considered, is-a relations aresuitable for this filtering because very often they pro-pose true hierarchical relations.
However, the lex-ical inclusions have a negative effect of the filter-ing.
We assume this is due to the fact that the lexicalinclusions are ambiguous: they may convey hierar-chical relations but also equivalence relations (Har-alambous and Lavagnino, 2011).
Indeed, contextu-ally some terms may be shortened or may be subjectto an elision while their meaning is not impacted.Currently, the pagerank is limited by the fact thatit is applied to a relatively small set of data whileit is designed to process very large data.
Then, itcan be interesting to enrich the model and to be ableto take into account other quality indicators, such asfrequencies, productivity or other semantic relationsproposed within GO (part-of and regulates).Moreover, we can also give a lesser weight to someindicators (such as lexical inclusions) with penal-ties and keep the strong weight for other indicators.In the current model of the pagerank, we thresh-old rows to < 0.95.
However, we assume that thealgorithm may have problems with very large andvery connected graphs: the pagerank may spreadout in the graph too much and possibly allow thefirst words with the highest pagerank to make groupswith only one word.
This can be corrected if an addi-tional calculation is added and when the group con-tains only one word at step 5.6 Conclusion and PerspectivesWe propose an original approach for inducing syn-onyms from terminologies and for their filtering.The methods exploit the NLP methods, composi-tionality principle and pagerank-derived algorithm.This work is motivated by the fact that synonymyis a contextual relation and its validity and univer-sality are not guaranteed.
We assume the seman-tic cohesiveness of synonymy relations should bequalified and quantified.
The compositionality andNLP methods allow to acquire endogeneously thesynonymy relations and the quality indicators, whilethe pagerank-derived algorithm leads to the filteringof the acquired synonyms.
Its functionning is basedupon the synonymy relations and also upon the ac-quired indicators (is-a relations and lexical inclu-sions).
It appears that the synonymy relations aloneprovide good clues for their filtering.
The is-a re-lations are also fruitful, while the use of the lexicalinclusions appears not to be suitable.In the future, we plan to add and test other indi-cators.
Other experiments will also be done with thepagerank approach.
For instance, it will be inter-esting to propose a model which takes into accountthat, within a cluster, words may be synonym withsome cluster words but not with all the words of thecluster.
This method can be adapted for the process-ing of corpora and also applied to terms from otherterminologies.
The acquired and filtered synonymyrelations will be exploited within the NLP applica-tions in order to test the efficiency of these resourcesand also the usefulness and efficiency of their filter-ing.
Moreover, the compositionality approach canbe adapted and exploited for the paraphrasing of thebiomedical terms and for the improvement of theirunderstanding by non expert people.ReferencesE Agirre and A Soroa.
2009.
Personalizing PageRankfor word sense disambiguation.
In EACL 2009, pages33?41, Athens, Greece, March.116O Bodenreider, A Burgun, and TC Rindflesch.
2001.Lexically-suggested hyponymic relations among med-ical terms and their representation in the UMLS.
InURI INIST CNRS, editor, Terminologie et Intelligenceartificielle (TIA), pages 11?21, Nancy.S Brin and L Page.
1998.
The anatomy of a large-scalehypertextual Web search engine.
Computer Networksand ISDN Systems, 30(1?7):107?117.K Bryan and T Leise.
2006.
The $25, 000, 000, 000eigenvector: the linear algebra behind google.
SIAMRev., 48(3):569?581.David A. Cruse.
1986.
Lexical Semantics.
CambridgeUniversity Press, Cambridge.C Engstro?m.
2011.
Pagerank as a solution to a lin-ear system, pagerank in changing systems and non-normalized versions of pagerank.
Master?s thesis,Mathematics, Centre for Mathematical sciences, LundUniversity.
LUTFMA-3220-2011.C Fellbaum.
1998.
A semantic network of english: themother of all WordNets.
Computers and Humanities.EuroWordNet: a multilingual database with lexical se-mantic network, 32(2-3):209?220.S Fernandez, E SanJuan, and JM Torres-Moreno.
2009.Re?sume?s de texte par extraction de phrases, algo-rithmes de graphe et e?nergie textuelle.
In Socie?te?Francophone de Classification, pages 101?104.B Gaume.
2006.
Cartographier la forme du sens dans lespetits mondes lexicaux.
In JADT.G Grefenstette.
1994.
Explorations in automatic the-saurus discovery.
Kluwer Academic Publishers.T Hamon and N Grabar.
2008.
Acquisition of elementarysynonym relations from biological structured termi-nology.
In Computational Linguistics and IntelligentText Processing (5th International Conference on NLP,2006), number 4919 in LNCS, pages 40?51.
Springer.T Hamon, A Nazarenko, and C Gros.
1998.
A steptowards the detection of semantic variants of termsin technical documents.
In COLING-ACL?98, pages498?504.Y Haralambous and E Lavagnino.
2011.
La re?duction determes complexes dans les langues de spc?ialite?.
TAL,52(1):37?68.S Hassan, R Mihalcea, and C Banea.
2007.
Random-walk term weighting for improved text classification.In ICSC, pages 242?249.T Hughes and D Ramage.
2007.
Lexical semantic relat-edness with random graph walks.
In EMNLP-CoNLL,pages 581?589.
Association for Computational Lin-guistics.C Jacquemin, JL Klavans, and E Tzoukerman.
1997.Expansion of multi-word terms for indexing and re-trieval using morphology and syntax.
In ACL/EACL97), pages 24?31, Barcelona, Spain.G Kleiber and I Tamba.
1990.
L?hyperonymie revisite?e :inclusion et hie?rarchie.
Langages, 98:7?32, juin.R Mihalcea, P Tarau, and E Figa.
2004.
Pagerank on se-mantic networks, with application to word sense dis-ambiguation.
In COLING, pages 1126?1132.CJ Mungall.
2004.
Obol: integrating language andmeaning in bio-ontologies.
Comparative and Func-tional Genomics, 5(6-7):509?520.NLM, 2007.
UMLS Knowledge Sources Manual.
Na-tional Library of Medicine, Bethesda, Maryland.www.nlm.nih.gov/research/umls/.PV Ogren, KB Cohen, and L Hunter.
2005.
Implica-tions of compositionality in the Gene Ontology for itscuration and usage.
In Pacific Symposium of Biocom-puting, pages 174?185.BH Partee, 1984.
Compositionality.
F Landman and FVeltman.S Schulz, M Romacker, P Franz, A Zaiss, R Klar, andU Hahn.
1999.
Towards a multilingual morphemethesaurus for medical free-text retrieval.
In MedicalInformatics in Europe (MIE), pages 891?4.F Sebastiani.
2002.
Machine learning in automated textcategorization.
ACM Computing Surveys, 34(1):1?47.N Shimizu, M Hagiwara, Y Ogawa, K Toyama, andH Nakagawa.
2008.
Metric learning for synonym ac-quisition.
In COLING, pages 793?800.R Sinha and R Mihalcea.
2007.
Unsupervised graph-based word sense disambiguation using measures ofword semantic similarity.
In IEEE International Con-ference on Semantic Computing (ICSC 2007), pages363?369.RS Sinha and RF Mihalcea.
2011.
Using centrality algo-rithms on directed graphs for synonym expansion.
InFLAIRS.Y Tsuruoka, Y Tateishi, JD Kim, T Ohta, J McNaught,S Ananiadou, and J Tsujii.
2005.
Developing a ro-bust part-of-speech tagger for biomedical text.
LNCS,3746:382?392.CM Verspoor, C Joslyn, and GJ Papcun.
2003.
The GeneOntology as a source of lexical semantic knowledgefor a biological natural language processing applica-tion.
In SIGIR workshop on Text Analysis and Searchfor Bioinformatics, pages 51?56.T Wang and G Hirst.
2011.
Exploring patterns in dictio-nary definitions for synonym extraction.
Natural Lan-guage Engineering, 17.P Zweigenbaum, R Baud, A Burgun, F Namer, E?
Jar-rousse, N Grabar, P Ruch, F Le Duff, B Thirion, andS Darmoni.
2003.
Towards a Unified Medical Lexiconfor French.
In Medical Informatics in Europe (MIE),pages 415?20.117
