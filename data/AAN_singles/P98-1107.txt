A Method for Correcting Errors in Speech Recognition Using the StatisticalFeatures of Character Co-occurrenceSatoshi Kaki, Eiichiro Sumita, and Hitoshi IidaATR Interpreting Telecommunications Research Labs,Hikaridai 2-2 Seika-cho, Soraku-gun, Kyoto 619-0288, Japan{skaki, sumita, iida}@itl.atr.co.jpAbstractIt is important to correct he errors in the results ofspeech recognition to increase the performance of aspeech translation system.
This paper proposes amethod for correcting errors using the statisticalfeatures of character co-occurrence, and evaluates themethod.The proposed method comprises two successivecorrecting processes.
The first process uses pairs ofstrings: the first string is an erroneous substring of theutterance predicted by speech recognition, the secondstring is the corresponding section of the actualutterance.
Errors are detected and corrected accordingto the database learned from erroneous-correctutterance pairs.
The remaining errors are passed to theposterior process which uses a string in the corpusthat is similar to the string including recognitionerrors.The results of our evaluation show that the use ofour proposed method as a post-processor for speechrecognition is likely to make a significant contributionto the performance of speech translation systems.method also obtains reliably recognized partial segmentsof an utterance by cooperatively using both grammaticaland n-gram based statistical language constraints, and usesa robust parsing technique to apply the grammaticalconstraints described by context-free grammar (Tsukada etaL, 97).
However, these methods do not carry out any errorcorrection on a recognition result, but only specify correctparts in it.In this paper we therefore propose a method forcorrecting errors, which is characterized by learning thetrend of errors and expressions, and by processing in anarbitrary length string.Similar work on English was presented by (E.K.Ringger et al, 96).
Using a noisy-channel model, theyimplemented a post-processor tocorrect word-level errorscommitted by a speech recognizer.2 Method for Correcting ErrorsWe refer to two compositions of the proposal as Error-Pattem-Correction (EPC) and Similar-String-Correction(SSC) respectively.
The correction using EPC and SSCtogether inthis order is abbreviated toEPC+SSC.1 IntroductionIn spite of the increased performance of speech recognitionsystems, the output still contains many errors.
For languageprocessing such as a machine translation, it is extremelydifficult o deal with such errors.In integrating recognition and translation i to a speechtranslation system, the development of the followingprocesses i therefore important: (1) detection of errors inspeech recognition results; (2) sorting of speechrecognition results by means of error detection; (3)providing feedback to the recognition process and/ormaking the user speak again; (4) correct errors, etc.For this purpose, a number of methods have beenproposed.
One method is to translate correct partsextracted from speech recognition results by using thesemantic distance between words calculated with anexample-based approach (Wakita et al, 97).
Another2.1 Error-Pattern-Correction (EPC)When examining errors in speech recognition, errors arefound to occur in regular pattems rather than at random.EPC uses such error pattems for correction.
We refer tothis pattern as an Ermr-Pattem.An Error-Pattem is made up of two strings.
One is theMa chiog I \[Sobsti tingE.or- Corre  -\]pa ofE.or / I forPattern l \ [  Error-Part~pa rror-Pattern-Databa~-~irs of Error- and Correct-~JFigure 2-1 The block diagram for EPC653string including errors, and the other is the correspondingcorrect string (the former string is referred to as the Error-Part, and the latter as the Correct-Part espectively).
Theseparts are extracted from the speech recognition results andthe corresponding actual utterances, then they are stored ina database (referred to as an Error-Pattern-Database).
InEPC, the correction is made by substituting a Correct-Partfor an Error-Part when the Error-Part is detected in arecognition result (see Figure 2-1).
Table 2-1 shows someError-Pattern examples.Table 2-1 Examples of Error-PatternsCorrect-Part Error-Part2.1.1 Extraction of Error-PatternsThe Error-Pattern-Database is mechanically preparedusing a pair of parts from the speech recognitionresults and the corresponding actual utterance.
Theexamples below show candidates grouped accordingto the correct part '<~>'  and the erroneous part '< ~~1.Error-Pattern Candidates Frq.<N> : <t.
?> 3~<N> : !~<t.~> 3~<N> : ~\[.~</'.c> 3EPC is a simple and effective method because itdetects and corrects errors only by pattern-matching.The unrestricted use of Error-Patterns, however, mayproduce the wrong correction.
Therefore a carefulselection of Error-Patterns is necessary.
In thismethod, several selection conditions are applied inorder, as described below.
Candidates passing all ofthe conditions are employed as Error-Patterns.Condition of High Frequency: Candidates of not lessthan a given threshold value (2 in the experiment) infrequency are selected to collect errors which have a highfrequency of occurrence inrecognition results.Condition of Non-Side Effect:, This step excludes thecandidate whose Error-Part is included in actual utterancesto prevent he Error-Part from matching with a section ofactual utterances.Condition of Inclusion-l: Because a long Error-Part ismore accurate for matching, this step selects an Error-Pattern whose Error-Part is as long as possible.
For twoarbitrary candidates, when one of their Error-Parts includesthe other, and their frequencies are the same value, thecandidate whose Error-Part includes the other is accepted.Condition of Inclusion-2: If some Error-Parts are derivedfrom different utterances and have a common part in them,this common part is suitable for an Error-Pattern.Therefore in this step, an Error-Pattem with its Error-Partas short as possible is selected.
For two arbitrarycandidates, when one of their Error-Parts includes theother, and their frequencies have different values, theincluded candidate isaccepted.2.2 Similar-String-Correction (SSC)In an erroneous Japanese sentence, the correctexpressions can be estimated frequently by the row ofcharacters before and after the erroneous ections ofthe sentence.
This means that we are involuntarilyapplying a portion of a regular expression to anerroneous ection.Instead of this portion of the regular expression,SSC uses a collection of strings, the members ofwhich are in the corpus (this collection we refer to asthe String-Database).
As shown in the block diagramin figure 2-2, the correction is performed through thefollowing steps, the first step is error detection.
Thenext step is the retrieval of the string that is mostI Input StringErrorDetectionRetrieval ofSimilar StringSubstitution ofDissimilar PartI Corrected StringFigure 2-2 The block diagram of SSC654similar to the string including errors from the String-Database (the former string is referred to as theSimilar-String, and the latter as the Error-String).Finally, the correction is made using the differencebetween these two strings.2.2.1 Procedure for CorrectionThe procedure for correction varies slightly,depending on the position of the detected error: a top,a middle, or a tail, in an utterance.
Here we willexplain the case of a middle.Step 1: Estimate an erroneous section (referred to as anerror-block) with error detection method'.
If there is noerror-block, the procedure is terminated.Depending on the position of the error-block, theprocedure branches inthe following way.If P1 is less than T (T=4), then go to the step for a top.If a value L - P2 + T is less than T, then go to the stepfor a tail.In all other cases, go to the step for a middle.Here, P1 and P2 denote the start and end positions ofan error-block, and L denotes the length of the input string.Step 2: Take the string (Error-String) that comprises anerror-block and each M (5 in the experiment) characterbefore and after the error-block out of the input string, andusing this string (Error-String) as a query key, retrieve astring (Similar-String) from the String-Database to satisfythe following condition.
It must be located in a middle ofan utterance, it must have the highest value (S), and S mustbe not less than a given threshold value ( 0.6 in theexperiment).
Here, S is defined as:S=(L -N) /Lwhere L is the len~uh of the Similar String, and N is theminimum number of character insertions, deletions, orsubstitutions ecessary totransform the Error-String to theSimilar-String.If there is no Similar-String, then go to step 1 leavingthis error-block undone.Step 3: If the two strings (denoted A and B), that are eachK (2 in the experiment) characters before and after anerror-block in the Error-String, am found in the Similar-String, take out the string (denoted C) between A and B in1 For detecting errors in Japanese sentences, the method using theprobability of character sequence was reported to be fairlyeffective (Araki et al, 93).
The result of a preliminaryexperiment was that the precision and recall rates were over80% and over 70% respectively.<error-block>Error-String: \['~@\] {~<:fi~A.
~>t;l:l \[ffJ'~\]\[A\] A' ' /~ ~Substituti?n ~ ~ \[B\]Similar-String: \[~'9"-\] {~A.~r~l;~t \[ffJ'~\]~J~'~Ict ~"_h)'ffure 2-3 The procedure o?
SSCthe Similar-String.
ff k is not found, then go to Step 1leaving this error-block undone.Substitute string C as the correct string for the stringbetween A and B in the Error-String (see figure 2-3).3.
Evaluation3.1 Data Condition for ExperimentsResults of Speech Recognition: We used 4806recognition results including errors, from the output ofspeech recognition (Masataki et al, 96; Shimizu et al, 96)experiment using an ATR spoken language database(Morimoto et al, 94) on travel arrangements.
Thecharacteristics of those results are shown in table 3-1.The breakdown of these 4806 results is as follows:4321 results were used for the preparation of Error-Patterns and the other 495 results were used for theevaluation.Table 3-1 The recognition characteristicsRecognitionaccuracy(%) Insertion Deletion Substitution Sum(in character)74.73 2642 1702 8087 12431Preparation of Error-Patterns: As the threshold valuefor the frequency of the occurrence, we employed a valueof not less than 2, therefore we obtained 629 Error-Pattemsusing the 4321 results of speech recognition.Preparation of the String-Database: Using the differentdata-sets of the ATR spoken language database from theabove-mentioned 4806 results, we prepared the String-Database.We employed 3 as the threshold value for the frequencyof the occurrence, and 10 as the length of a string,therefore obtaining 16655 strings.3.2 Two Factors for EvaluationWe evaluated the following two factors before andafter correction: (1) the counting of errors, and (2) theeffectiveness of the method in understanding therecognized results.655To confirm the effectiveness, the recognitionresults were evaluated by two native Japanese.
Theyassigned one of five levels, A-E, to each recognitionresult before and after correction, by comparing itwith the corresponding actual utterance.
Finally, weemployed the overall results of the stricter of twoevaluators.
(A) No lacking in the meaning of the actual utterance,and with perfect expression.
(B) No lacking in meaning, but with slightly awkwardexpression.
(C) Slightly lacking in meaning.
(D) Considerably lacking in meaning.
(E) Unable to understand, and unable to imagine theactual utterance.4.
Results and Discussions4.1 Decrease in the Number of ErrorsTable 4-1 shows the number of errors before and aftercorrection.
These results show the following.Table 4-1 The number of errors before and after correctionInsertion Deletion Substitution SumBefore 264 206 891 1361EPC 226(-14.4) 190(-7.8) 853(-4.3) 1269(-6.8)SSC 251(-4.9) 214(+3.9) 870(-2.4) 1335(-1.9)EPC+SSC 216(-18.2) 198(-3.9) 831 (-7.9) 1245(-8.5)The values inside brackets 0 are the rate of decreaseIn EPC+SSC, the rate of decrease was 8.5%, andthe decrease was obtained in all type of errors.In SSC, the number of deletion errors increased by3.9%.
The reason for this is that in SSC, correction bydeleting the part of a substitution error frequentlycaused new deletion errors as shown in the examplebelow.
From the standpoint of the correction it mightbe a mistaken correction, but it increasesunderstanding of the results by deleting a noise andmakes the results viable for machine translation.
Ittherefore practically refines the speech recognitionresults.Correct String:'~:t~ ~ 5 ~%~ ~'?
,V , ,~  ~-)~,~/19~'~,='~?~ ~'?
'"Hai arigatou gozaimasu Kyoto Kanko Hoteru yoyaku gakari degozaimasu", ('l'hank you for calling Kyoto Kanko Hotel reservations.
)Input String:-?,"A hai arigatou gozaimasu e Kyoto Kanko Hoteru yanichikangozaimasu", (Thank you for calling Kyoto Kanko Hotel ....... )Corrected String:"A hai arigatou gozaimasu e Kyoto Kanko Hoteru de gozaimasu",(Thank you for calling Kyoto Kanko Hotel.
)6564.2 Improvement of UnderstandabilityTable 4-2 shows the number of change in theevaluated level.The rate of improvement after correction was 7%.There were also a lot of cases that improved theirlevel by recovering content words.
For example, theword "cash" was recovered in '~,~ , "~'--~,@, "~"(before-'after), "guide" in '~i\]X-J --~ ~-"~' ,  etc.These results confirm that our method is effectivein improving the understanding of the recognitionresults.On the other hand, there were four level-downcases.
Three of these cases were caused by themisdetection of errors in the SSC procedure.
Theremaining case occurred in the EPC procedure.
TheError-Pattern used in this case could not be excludedby the condition of non-side effects because its Error-Part was not included in the corpus of the actualutterance.Table 4-2 The number of changes in the evaluated level beforeand aJier correction.EPC SSC EPC+SSCImprove 18(3 .7 )  15(3 .1 )  34(7 .0 )No Change 466( 96.1 ) 467(96.3) 447(92.2)Down 1(0 .2 )  3 (0 .6 )  4 (0 .8 )The values inside brackets 0 are the rate (%) of the number to totalnumber of evaluated results.4.3 More Applicable for a Result Having a FewErrorsTable 4-3 shows the rate of change in the evaluatedlevel by the original number of erroneous characters 2Table 4-3 The rate of change in the evaluated level by theoriginal number of erroneous characters involved in therecoNum.
of erroneouscharactersnition results (EPC+SSC).Num.
of Rate(%) of changeNo results Improve Change Down0 102 0.0 98.0 2.01 30 16.7 80.0 3.32 21 28.6 66.7 4.83 26 19.2 80.8 0.04 40 12.5 87.5 0.05 27 14.8 85.2 0.06 24 12.5 87.5 0.07 21 9.5 90.5 0.08 17 0.0 100.0 0.09 20 5.0 95.0 0.010 29 0.0 100.0 0.011 22 0.0 100.0 0.012 > 106 2.8 97.2 0.0Total 485 7.0 92.2 0.8This number is the min imum number of  character insertions,deletions or substitutions necessary to transform the result ofrecognition into a corresponding actual utterance.included in the recognition results.The recognition results improving their level aftercone~tion mosdy fell in the range of erroneous numbersby not more than 7.
The reasons for this are that with therebeing many errors, the failure of the corrections increasesbecause the corrections are prevented by other surroundingerrors.
In addition, when only a few successful correctionshave been made, they have little influence on the overallunderstanding.These results show that the proposed method is moreapplicable for a recognition result having a few errors, ascompared with one having many errors.5 ConclusionAs described above, our proposed method has thefollowing features:(1) Since the proposed method is designed with a arbitrarylength string as a unit, it is capable of correcting errorswhich are hard to deal with by methods designed to treatwords as units.For example, the insertion error '~" ("wo") in the string'3~f.~L ~,~ Jj"(~ ' ("shiharai wo houhou'~ shown in table 2-1 cannot be corrected by a method esigned to treat wordsas units, because of the existence of the particle' ~'  ("wo")as a correct word.
However with the proposed method, it ispossible to correct his kind of error by using the row ofcharacters before and after '~'  ("wo").
(2) In the proposed method of learning the trend of errorsand expressions with long strings, it is possible to correcterrors where it is difficult to narrow the candidates down tothe correct character with the probability of the charactersequence alone.When considering the candidate for "(" ("te") in' l.,U.
"( ~ ~.
~ ?U."
("shitetekimasunode '~) shown in table 2-1to satisfy the probability of the character sequence, itscandidates, '4 ~' ("/"), '}3' Co"), 'I~' ("itada'~ are arrangedin order of increasing probability.
It is therefore difficult tonarrow the candidates into the correct character ' I~'("itada") by the probability of character sequence alone.But with the proposed method it is possible to correct hiskind of error by using the row of the characters before andafter "(" Cte").
(3) Both the Error-Pattem-Database nd String-Databasecan be mechanically prepared, which reduces the effortrequired to prepare the databases and makes it possible toapply this method to a new recognition system in a shorttime.From the evaluation, it became clear that theproposed method has the following effects:(1) It reduces over 8% of the errors.
(2) It improves the understanding of the recognition resultsby7%.
(3) It has very little influence on correct recognition results.
(4) It is more applicable for a recognition result with a fewerrors than one with many errors.Judging from these results and features, the use of theproposed method as a post-processor for speechrecognition is likely to make a significant contribution tothe performance of speech translation systems.In the future, we will try to improve the correctingaccuracy by changing algorithms and will also try toimprove translation performance by combining ourmethod with Wakita's method.ReferencesT.
Araki et al, 93.
A Method for Detecting and Correcting ofCharacters Wrongly Substituted, Deleted or Inserted inJapanese Strings Using 2nd-Order Markov Model IPSJ,Report of SIG-NL, 97-5, pp.
29-35 (1993)T. Morimoto et al, 94: A Speech and language database forspeech translation research.
Proc.
of ICSLP 94, pp.
1791-1794, 1994.H.
Masataki et al, 96.
Variable-order n-gram generation byword-class splitting and consecutive word grouping.
In Proc.of ICASSP, 1996.T.
Shimizu et al, 96.
Spontaneous Dialogue Speech Recognitionusing Cross-word Context Constrained Word Graphs.ICASSP 96, pp.
145-148, 1996.Y.
Wakita et al, 97.
Correct parts extraction from speechrecognition results using semantic distance calculation, andits application to speech translation.
ACI.JF_.ACL WorkshopSpoken Language Translation, pp.
24-31, 1997-7.H.
Tsukada et al, 97.
Integration of grammar and statisticallanguage constraints for partial word-sequence recognition.In Proc.
of 5th European Conference on SpeechCommunication a d Technology (EuroSpeech 97), 1997.E.K.Ringger et al, 96.
A Fertility Channel Model for Post-Correction of Continuous Speech Recognition.
ICSLP96, pp.897-900, 1996.657
