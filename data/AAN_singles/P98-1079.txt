A Text Understander  that LearnsUdo Hahn &: K lemens  Schnat t ingerComputat ional  Linguistics Lab, Freiburg UniversityWerthmannplatz  1, D-79085 Freiburg, Germany{hahn, schnatt inger}@col ing.
uni-freiburg, deAbst rac tWe introduce an approach to the automatic ac-quisition of new concepts fi'om natural anguagetexts which is tightly integrated with the under-lying text understanding process.
The learningmodel is centered around the 'quality' of differ-ent forms of linguistic and conceptual evidencewhich underlies the incremental generation andrefinement of alternative concept hypotheses,each one capturing a different conceptual read-ing for an unknown lexical item.1 I n t roduct ionThe approach to learning new concepts as aresult of understanding natural language textswe present here builds on two different sourcesof evidence - -  the prior knowledge of the do-main the texts are about, and grammatical con-structions in which unknown lexical items oc-cur.
While there may be many reasonable inter-pretations when an unknown item occurs for thevery first time in a text, their number rapidlydecreases when more and more evidence is gath-ered.
Our model tries to make explicit the rea-soning processes behind this learning pattern.Unlike the current mainstream in automaticlinguistic knowledge acquisition, which can becharacterized as quantitative, surface-orientedbulk processing of large corpora of texts (Hin-dle, 1989; Zernik and Jacobs, 1990; Hearst,1992; Manning, 1993), we propose here aknowledge-intensive model of concept learningfrom few, positive-only examples that is tightlyintegrated with the non-learning mode of textunderstanding.
Both learning and understand-ing build on a given core ontology in the formatof terminological assertions and, hence, makeabundant use of terminological reasoning.
The'plain' text understanding mode can be consid-ered as the instantiation and continuous fillingd~udr s,y ~ trw~ Hyl~si~ space- jHyputhcsist spal.
'c-n I Q*mlifi~rQ*mlity ~,l~*IneFigure 1: Architecture of the Text Learnerof roles with respect o single concepts alreadyavailable in the knowledge base.
Under learningconditions, however, a set of alternative concepthypotheses has to be maintained for each un-known item, with each hypothesis denoting anewly created conceptual interpretation tenta-tively associated with the unknown item.The underlying methodology is summarizedin Fig.
1.
The text parser (for an overview, cf.BrSker et al (1994)) yields information fromthe grammatical constructions in which an un-known lexical item (symbolized by the blacksquare) occurs in terms of the corresponding de-pendency parse tree.
The kinds of syntactic on-structions (e.g., genitive, apposition, compara-tive), in which unknown lexical items appear,are recorded and later assessed relative to thecredit they lend to a particular hypothesis.
Theconceptual interpretation of parse trees involv-ing unknown lexical items in the domain knowl-edge base leads to the derivation of concept hy-potheses, which are further enriched by concep-tual annotations.
These reflect structural pat-terns of consistency, mutual justification, anal-ogy, etc.
relative to already available conceptdescriptions in the domain knowledge base orother hypothesis spaces.
This kind of initial ev-idence, in particular its predictive "goodness"for the learning task, is represented by corre-sponding sets of linguistic and conceptual qual-476iSyntax SemanticsCMD C ~ QD zCuD CZuD zVR.C {d e A z \[ RZ(d) C_ C z}RnS R z nS zc ln  {(d,d')en z l d e C z}RIG {(d, d') ?
n z I d' ?
C z)Table l: Some Concept andRole TermsAxiom SemanticsA - C A z = C za : C a z E C zQ - R QZ = RZa R b (a z, b z) E R zTable 2: Axioms forConcepts and Rolesity labels.
Multiple concept hypotheses for eachunknown lexical item are organized in terms ofcorresponding hypothesis paces, each of whichholds different or further specialized conceptualreadings.The quality machine estimates the overallcredibility of single concept hypotheses by tak-ing the available set of quality labels for eachhypothesis into account.
The final computa-tion of a preference order for the entire set ofcompeting hypotheses takes place in the qual-ifier, a terminological classifier extended by anevaluation metric for quality-based selection cri-teria.
The output of the quality machine is aranked list of concept hypotheses.
The rankingyields, in decreasing order of significance, eitherthe most plausible concept classes which classifythe considered instance or more general conceptclasses subsuming the considered concept class(cf.
Schnattinger and Hahn (1998) for details).2 Methodo log ica l  F rameworkIn this section, we present he major method-ological decisions underlying our approach.2.1 Termino log ica l  LogicsWe use a standard terminological, KL-ONE-style concept description language, here referredto as C:D?
(for a survey of this paradigm, cf.Woods and Schmolze (1992)).
It has severalconstructors combining atomic concepts, rolesand individuals to define the terminological the-ory of a domain.
Concepts are unary predicates,roles are binary predicates over a domain A,with individuals being the elements of A. Weassume a common set-theoretical semantics forC7)?
- an interpretation Z is a function thatassigns to each concept symbol (the set A) asubset of the domain A, Z : A -+ 2 n, to eachrole symbol (the set P) a binary relation of A,Z : P --+ 2 ~?n, and to each individual symbol(the set I) an element of A, Z : I --+ A.Concept terms and role terms are defined in-ductively.
Table 1 contains some constructorsand their semantics, where C and D denote con-cept terms, while R and S denote roles.
R z (d)represents the set of role fillers of the individuald, i.e., the set of individuals e with (d, e) E R z.By means of terminological xioms (for a sub-set, see Table 2) a symbolic name can be intro-duced for each concept to which are assignednecessary and sufficient constraints using thedefinitional operator '"= .
A finite set of suchaxioms is called the terminology or TBox.
Con-cepts and roles are associated with concrete in-dividuals by assertional axioms (see Table 2; a, bdenote individuals).
A finite set of such axiomsis called the world description or ABox.
An in-terpretation Z is a model of an ABox with re-gard to a TBox, iff Z satisfies the assertionaland terminological xioms.Considering, e.g., a phrase such as 'Theswitch of the Itoh-Ci-8 ..', a straightforwardtranslation into corresponding terminologicalconcept descriptions i illustrated by:(el) switch.1 : SWITCH(P2) Itoh-Ci-8 HAS-SWITCH switch.1(P3) HAS-SWITCH - -(OuTPUTDEV LJ INPUTDEV U IHAS-PARTISwITCHSTORAGEDEV t3 COMPUTER)Assertion P1 indicates that the instanceswitch.1 belongs to the concept class SWITCH.P2 relates Itoh-Ci-8 and switch.1 via the re-lation HAS-SWITCH.
The relation HAS-SWITCHis defined, finally, as the set of all HAS-PARTrelations which have their domain restricted tothe disjunction of the concepts OUTPUTDEV,INPUTDEV, STORAGEDEV or COMPUTER andtheir range restricted to SWITCH.In order to represent and reason about con-cept hypotheses we have to properly extend theformalism of C~?.
Terminological hypotheses,in our framework, are characterized by the fol-lowing properties: for all stipulated hypotheses(1) the same domain A holds, (2) the same con-cept definitions are used, and (3) only differentassertional axioms can be established.
Theseconditions are sufficient, because ach hypoth-esis is based on a unique discourse entity (cf.
(1)), which can be directly mapped to associ-ated instances (so concept definitions are stable(2)).
Only relations (including the ISA-relation)among the instances may be different (3).477Axiom Semantics(a : C)h a z E C zn(aRb)h (a z,b z) ER  zhTable 3: Axioms in CDf.. hvp?Given these constraints, we may annotateeach assertional axiom of the form 'a : C' and'a R b' by a corresponding hypothesis label h sothat (a : C)h and (a R b)h are valid terminolog-ical expressions.
The extended terminologicallanguage (cf.
Table 3) will be called CD?
~y~?.Its semantics is given by a special interpreta-tion function Zh for each hypothesis h, which isapplied to each concept and role symbol in thecanonical way: Zh : A --+ 2zx; Zh : P --+ 2 AxA.Notice that the instances a, b are interpreted bythe interpretation function Z, because there ex-ists only one domain ?x.
Only the interpretationof the concept symbol C and the role symbol Rmay be different in each hypothesis h.Assume that we want to represent two of thefour concept hypotheses that can be derivedfrom (P3), viz.
Itoh-Ci-Sconsidered as a storagedevice or an output device.
The correspondingABox expressions are then given by:( Itoh-Ci-8 HAS-SWITCH switch.1)h,(Itoh-Ci-8 : STORAGEDEV)h 1( Itoh-C i-8 HAS-SWITCH switch.1)h2(Itoh-Ci-8 : OUTPUTDEV)h~The semantics associated with this ABoxfi'agment has the following form:~h, (HAS-SWITCH) -" {(Itoh-Ci-8, switch.l)},Zhx (STORAGEDEV) m {Itoh-Ci-8},Zha (OuTPUTDEV) "- 0Zh~(HAS-SWITCH) : {(Itoh-Ci-8, switch.l)},Zh2(STORAGEDEV) = 0,:~h..(OUTPUTDEV) : {Itoh-Ci-8}2.2 Hypothesis Generation RulesAs mentioned above, text parsing and con-cept acquisition from texts are tightly coupled.Whenever, e.g., two nominals or a nominal anda verb are supposed to be syntactically relatedin the regular parsing mode, the semantic in-terpreter simultaneously evaluates the concep-tual compatibility of the items involved.
Sincethese reasoning processes are fully embedded ina terminological representation system, checksare made as to whether a concept denoted byone of these objects is allowed to fill a role ofthe other one.
If one of the items involved isunknown, i.e., a lexical and conceptual gap isencountered, this interpretation mode generatesinitial concept hypotheses about the class mem-bership of the unknown object, and, as a conse-quence of inheritance mechanisms holding forconcept taxonomies, provides conceptual roleinformation for the unknown item.Given the structural foundations of termi-nological theories, two dimensions of concep-tual learning can be distinguished - -  the tax-onomic one by which new concepts are locatedin conceptual hierarchies, and the aggregationalone by which concepts are supplied with clus-ters of conceptual relations (these will be usedsubsequently by the terminological c assifier todetermine the current position of the item tobe learned in the taxonomy).
In the follow-ing, let target.con be an unknown concept de-noted by the corresponding lexical item tar-get.lex, base.con be a given knowledge base con-cept denoted by the corresponding lexical itembase.lex, and let target.lex and base.lex be re-lated by some dependency relation.
Further-more, in the hypothesis generation rules belowvariables are indicated by names with leading'?
'; the operator TELL  is used to initiate thecreation of assertional axioms in C7)?
hyp?.Typical linguistic indicators that can be ex-ploited for taxonomic integration are apposi-tions ('.. the printer @A@ .. '), exemplificationphrases ('.. printers like the @A @ .. ') or nomi-nal compounds ( '.. the @A @ printer .. 1.
Theseconstructions almost unequivocally determine'@A@' (target.lex) when considered as a propername 1to denote an instance of a PRINTER (tar-get.con), given its characteristic dependency re-lation to 'printer' (base.lex), the conceptual cor-relate of which is the concept class PRINTER(base.con).
This conclusion is justified indepen-dent of conceptual conditions, simply due to thenature of these linguistic constructions.The generation of corresponding concept hy-potheses i  achieved by the rule sub-hypo (Ta-ble 4).
Basically, the type of target.con is carriedover from base.con (function type-o f ) .
In addi-tion, the syntactic label is asserted which char-acterizes the grammatical construction figuringas the structural source for that particular hy-1Such a part-of-speech ypothesis can be derivedfrom the inventory of valence and word order specifi-cations underlying the dependency grammar model weuse (BrSker et al, 1994).478sub-hypo (target.con, base.con, h, label)?type := type-of(base.con)TELL (target.con : ?type)hadd-label((target.con : ?type)h ,label)Table 4: Taxonomic Hypothesis Generation Rulepothesis (h denotes the identifier for the selectedhypothesis pace), e.g., APPOSITION, EXEMPLI-FICATION, or NCOMPOUND.The aggregational dimension of terminologi-cal theories is addressed, e.g., by grammaticalconstructions causing case frame assignments.In the example '.. @B@ is equipped with 32 MBof RAM ..', role filler constraints of the verbform 'equipped' that relate to its PATIENT rolecarry over to '@B~'.
After subsequent seman-tic interpretation of the entire verbal complex,'@B@' may be anything that can be equippedwith memory.
Constructions like prepositionalphrases ( '.. @C@ from IBM..  ') or genitives ('..IBM's @C@ .. ~ in which either target.lex orbase.lex occur as head or modifier have a simi-lar effect.
Attachments of prepositional phrasesor relations among nouns in genitives, however,open a wider interpretation space for '@C~'than for '@B~', since verbal case frames providea higher role selectivity than PP attachmentsor, even more so, genitive NPs.
So, any conceptthat can reasonably be related to the conceptIBM will be considered a potential hypothesisfor '@C~-", e.g., its departments,  products, For-tune 500 ranking.Generalizing from these considerations, westate a second hypothesis generation rule whichaccounts for aggregational patterns of conceptlearning.
The basic assumption behind thisrule, perm-hypo (cf.
Table 5), is that target.confills (exactly) one of the n roles of base.con itis currently permitted to fill (this set is deter-mined by the function por to - f i l l e r ) .
Depend-ing on the actual linguistic construction one en-counters, it may occur, in particular for PPand NP constructions, that one cannot decideon the correct role yet.
Consequently, severalalternative hypothesis paces are opened andtarget.co~ is assigned as a potential filler ofthe i-th role (taken from ?roleSet, the set ofadmitted roles) in its corresponding hypothesisspace.
As a result, the classifier is able to de-rive a suitable concept hypothesis by specializ-ing target.con according to the value restrictionof base.con's i-th role.
The function member-of?roleSet :=perm-f i l le r (  target.con, base.con, h)?r := \[?roleSet IFORALL ?i :=?r DOWNTO 1 DO?rolel := member-of ( ?roleSet )?roleSet :=?roleSet \ {?rolei}IF ?i = 1THEN ?hypo := hELSE ?hypo := gen-hypo(h)TELL (base.con ?rolei target.con)?hypoadd-label  ((base.con ?rolei target.con)?hypo, label )Table 5: Aggregational Hypothesis Generation Ruleselects a role from the set ?roleSet; gen-hypocreates a new hypothesis space by assertingthe given axioms of h and outputs its identi-fier.
Thereupon, the hypothesis pace identifiedby ?hypo is augmented through a TELL  op-eration by the hypothesized assertion.
As forsub-hypo, perm-hypo assigns a syntactic qual-ity label (function add- labe l )  to each i-th hy-pothesis indicating the type of syntactic con-struction in which target.lex and base.lex arerelated in the text, e.g., CASEFRAME,  PPAT-TACH or  GENIT IVENP.Getting back to our example, let us assumethat the target Itoh-Ci-8 is predicted already asa PRODUCT as a resu l t  o f  p reced ing  in terpreta -t ion processes, i.e., Itoh-Ci-8 : PRODUCT holds.Let PRODUCT be defined as:PRODUCT --VHAS-PART.PHYSICALOBJECT I-1 VHAS-SIZE.SIZE \["1VHAS-PRICE.PRICE i-I VHAS-WEIGHT.WEIGHTAt this level of conceptual restriction, fourroles have to be considered for relating the tar-get Itoh-Ci-8 - as a tentative PRODUCT - tothe base concept SWITCH when interpreting thephrase 'The switch of the Itoh-Ci-8 .. '.
Three ofthem, HAS-SIZE, HAS-PRICE, and  HAS-WEIGHT,are ruled out due to the violation of a simpleintegrity constraint ( 'switch'does not denote ameasure unit).
Therefore, only the role HAS-PART must be considered in terms of the expres-sion Itoh-Ci-8 HAS-PART switch.1 (or, equiva-lently, switch.1 PART-OF Itoh-Ci-8).
Due to thedefinition of HAS-SWITCH (cf.
P3, Subsection2.1), the instantiation of HAS-PART is special-ized to HAS-SWITCH by the classifier, since therange of the HAS-PART relation is already re-stricted to SWITCH (P1).
Since the classifier ag-gressively pushes hypothesizing to be maximallyspecific, the disjunctive concept referred to in479the domain restrictiou of the role HAS-SWITCHis split into four distinct hypotheses, two ofwhich are sketched below.
Hence, we assumeItoh-Ci-8 to deuote either a STORAGEDEviceor an OUTPUTDEvice or an INPUTDEvice or aCOMPUTER (note that we also include parts ofthe IS-A hierarchy in the example below).
(Itoh-Ci-8 : STORAGEDEV)h,,(Itoh-Ci-8 : DEVICE)h~,..,( Itoh-C i-8 HAS-SWITCH switch.1)h~(Itoh-Ci-8 : OUTPUTDEv)h~,(Itoh-Ci-8 : DEVICE)h2,..,(Itoh-Ci-8 HAS-SWITCH swilch.1)h~,...2.3 Hypothes is  Annotat ion  RulesIn this section, we will focus on the quality as-sessment of concept hypotheses which occurs atthe knowledge base level only; it is due to theoperation of hypothesis annotation rules whichcontinuously evaluate the hypotheses that havebeen derived from linguistic evidence.The M-Deduction rule (see Table 6) is trig-gered for any repetitive assignment of the samerole filler to one specific conceptual relation thatoccurs in different hypothesis paces.
This rulecaptures the assu,nption that a role filler whichhas been multiply derived at different occasionsmust be granted more strength than one whichhas been derived at a single occasion only.EXISTS Ol,O2, R, hl,h~.
:(Ol R o2)hl A (Ol R o2)h~ A hi ~ h~TELL (ol R o~_)h~ : M-DEDUCTIONTable 6: The Rule M-DeductionConsidering our example at the end of subsec-tion 2.2, for 'Itoh-Ci-8' the concept hypothesesSTORAGEDEV and OUTPUTDEV were derivedindependently of each other in different hypoth-esis spaces.
Hence, DEVICE as their commonsuperconcept has been multiply derived by theclassifier in each of these spaces as a result oftransitive closure computations, too.
Accord-ingly, this hypothesis is assigned a high degreeof confidence by the classifier which derives theconceptual quality label M-DEDUCTION:(Itoh-Ci-8 : DEVICE)hi A (Itoh-Ci-8 : DEVICE)h~=:=> (Itoh-Ci-8 : DEVICE)hi : M-DEDUCTIONThe C-Support rule (see Table 7) is triggeredwhenever, within the same hypothesis pace,a hypothetical relation, RI, between two in-stances can be justified by another elation, R2,involving the same two instances, but where therole fillers occur in 'inverted' order (R1 and R2need not necessarily be semantically inverse re-lations, as with 'buy' and 'sell~.
This causesthe generation of the quality label C-SuPPORTwhich captures the inherent symmetry betweenconcepts related via quasi-inverse relations.EXISTS Ol, 02, R1, R2, h :(ol R1 o2)h ^ (02 R2 ol)h ^ ftl # R~ ~=~TELL (Ol R1 o2)h : C-SuPPORTTable 7: The Rule C-SupportExample:(Itoh SELLS ltoh-Ci-8)h A(Itoh-Ci-8 DEVELOPED-BY Itoh)h(ltoh SELLS ltoh-Ci-8)h : C-SuPPORTWhenever an already filled conceptual rela-tion receives an additional, yet different rolefiller in the same hypothesis pace, the Add-Filler rule is triggered (see Table 8).
Thisapplication-specific rule is particularly suited toour natural language understanding task andhas its roots in the distinction between manda-tory and optio,lal case roles for (ACTION) verbs.Roughly, it yields a negative assessment interms of the quality label ADDFILLER for anyattempt to fill the same mandatory case rolemore than once (unless coordinations are in-volved).
Iu contradistinction, when the samerole of a non-ACTION concept (typically de-noted by nouns) is multiply filled we assign thepositive quality label SUPPORT, since it reflectsthe conceptual proximity a relation induces onits component fillers, provided that they sharea common, non-ACTION concept class.EXISTS 01,02, 03, R, h :(01 R 02)h A (01 R 03)h A (01 : ACTION)h ===VI TELL (01 R o~_)h : ADDFILLERTable 8: The Rule AddFillerWe give examples both for the assignmeut ofan ADDFILLER as well as for a SUPPORT label:Examples:(produces.1 : ACTION)h A(produces.1 AGENT ltoh)h A(produces.1 AGENT IBM)h(produces.1 AGENT Itoh)h : ADDFILLER(ltoh-Ci-8 : PRINTER)h A (Itoh-Ct : PRINTER)h A(Itoh SELLS Itoh-Ci-8)h A (Itoh SELLS Itoh-Ct)h A(ltoh : -~AcTION)h(Itoh-Ci-8 : PRINTER)h : SUPPORT4802.4 Qual i ty  D imens ionsThe criteria from which concept hypothesesare derived differ in the dimension from whichthey are drawn (grammatical vs. conceptual ev-idence), as well as the strength by which theylend support to the corresponding hypotheses(e.g., apposition vs. genitive, multiple deduc-tion vs. additional role filling, etc.).
In orderto make these distinctions explicit we have de-veloped a "quality calculus" at the core of whichlie the definition of and inference rules for qual-ity labels (cf.
Schnattinger and Hahn (1998) formore details).
A design methodology for specificquality calculi may proceed along the follow-ing lines: (1) Define the dimensions from whichquality labels can be drawn.
In our application,we chose the set I:Q := { l l , .
.
.
,  Ira} of linguisticquality labels and CQ := {cl , .
.
.
,c~} of con-ceptual quality labels.
(2) Determine a partialordering p among the quality labels from one di-mension reflecting different degrees of strengthamong the quality labels.
(3) Determine a totalordering among the dimensions.In our application, we have empirical evi-dence to grant linguistic criteria priority overconceptual ones.
Hence, we state the followingconstraint: Vl E LQ, Vc E CQ : l >p cThe  d imens ion  I:Q. Linguistic quality labelsreflect structural properties of phrasal patternsor discourse contexts in which unknown lexi-cal items occur 2 - -  we here assume that thetype of grammatical construction exercises aparticular interpretative force on the unknownitem and, at the same time, yields a particu-lar level of credibility for the hypotheses beingderived.
Taking the considerations from Sub-section 2.2 into account, concrete xamples ofhigh-quality labels are given by APPOSITION orNCOMPOUND labels.
Still of good quality butalready less constraining are occurrences of theunknown item in a CASEFRAME construction.Finally, in a PPATTACH or GENITIVENP con-struction the unknown lexical item is still lessconstrained.
Hence, at the quality level, theselatter two labels (just as the first two labels weconsidered) form an equivalence class whose el-ements cannot be further discriminated.
So weend up with the following quality orderings:2In the future, we intend to integrate additional typesof constraints, e.g., quality criteria reflecting the degreeof completeness v .
partiality of the parse.NCOMPOUND ----p APPOSITIONNCOMPOUND >p CASEFRAMEAPPOSITION >p CASEFRAMECASEFRAME >p GENITIVENPCASEFRAME >p PPATTACHGENITIVENP =p PPATTACHThe d imens ion  CQ.
Conceptualquality labelsresult from comparing the conceptual represen-tation structures of a concept hypothesis withalready existing representation structures in theunderlying domain knowledge base or other con-cept hypotheses from the viewpoint of struc-tural similarity, compatibility, etc.
The closerthe match, the more credit is lent to a hypoth-esis.
A very positive conceptual quality label,e.g., is M-DEDUCTION, whereas ADDFILLER isa negative one.
Still positive strength is ex-pressed by SUPPORT or C -SuPPORT,  both beingindistinguishable, however, from a quality pointof view.
Accordingly, we may state:M-DEDUCTION >p SUPPORT~{-DEDUCTION >p C-SuPPORTSUPPORT --p C-SuPPORTSUPPORT >p ADDFILLEKC-SuPPORT >p ADDFILLER2.5 Hypothesis Rank ingEach new clue available for a target concept obe learned results in the generation of additionallinguistic or conceptual quality labels.
So hy-pothesis paces get incrementally augmented byquality statements.
In order to select the mostcredible one(s) among them we apply a two-stepprocedure (the details of which are explainedin Schnattinger and Hahn (1998)).
First, thoseconcept hypotheses are chosen which have ac-cumulated the greatest amount of high-qualitylabels according to the linguistic dimension ?
:Q.Second, further hypotheses are selected fromthis linguistically plausible candidate set basedon the quality ordering underlying CQ.We have also made considerable fforts toevaluate the performance of the text learnerbased on the quality calculus.
In order to ac-count for the incrementality of the learning pro-cess, a new evaluation measure capturing thesystem's on-line learning accuracy was defined,which is sensitive to taxonomic hierarchies.
Theresults we got were consistently favorable, asour system outperformed those closest in spirit,CAMILLE (Hastings, 1996) and ScIsoR (Rau et481al., 1989), by a gain in accuracy on the or-der of 8%.
Also, the system requires relativelyfew hypothesis paces (2 to 6 on average) andprunes the concept search space radically, re-quiring only a few examples (for evaluation de-tails, cf.
Hahn and Schnattinger (1998)).3 Re la ted  WorkWe are not concerned with lexical acquisitionfrom very large corpora using surface-level collo-cational data as proposed by Zernik and Jacobs(1990) and Velardi et al (1991), or with hy-ponym extraction based on entirely syntacticcriteria as in Hearst (1992) or lexico-semanticassociations (e.g., Resnik (1992) or Sekine et al(1994)).
This is mainly due to the fact thatthese studies aim at a shallower level of learn-ing (e.g., selectional restrictions or thematic re-lations of verbs), while our focus is on muchmore fine-grained conceptual knowledge (roles,role filler constraints, integrity conditions).Our approach bears a close relationship, how-ever, to the work of Mooney (1987), Berwick(1989), Rau et al (1989), Gomez and Segami(1990), and Hastings (1996), who all aim at theautomated learning of word meanings from con-text using a knowledge-intensive approach.
Butour work differs from theirs in that the need tocope with several competing concept hypothesesand to aim at a reason-based selection in termsof the quality of arguments i not an issue inthese studies.
Learning from real-world textsusually provides the learner with only sparseand fragmentary evidence, such that multiplehypotheses are likely to be derived and a needfor a hypothesis evaluation arises.4 Conc lus ionWe have introduced a solution for the semanticacquisition problem on the basis of the auto-matic processing of expository texts.
The learn-ing methodology we propose is based on theincremental assignment and evaluation of thequality of linguistic and conceptual evidence foremerging concept hypotheses.
No specializedlearning algorithm is needed, since learning isa reasoning task carried out by the classifierof a terminological reasoning system.
However,strong heuristic guidance for selecting betweenplausible hypotheses comes from linguistic andconceptual quality criteria.Acknowledgements .
We would like to thankour colleagues in the CLIF group for fruitful discus-sions, in particular Joe Bush who polished the textas a native speaker.
K. Schnattinger is supported bya grant from DFG (Ha 2097/3-1).Re ferencesR.
Berwick.
1989.
Learning word meanings fromexamples.
In D. Waltz, editor, Semantic Struc-tures., pages 89-124.
Lawrence Erlbaum.N.
BrSker, U. Hahn, and S. Schacht.
1994.Concurrent lexicalized ependency parsing: thePARSETALK model.
In Proc.
of the COLING'94.Vol.
I, pages 379-385.F.
Gomez and C. Segami.
1990.
Knowledge acqui-sition from natural anguage for expert systemsbased on classification problem-solving methods.Knowledge Acquisition, 2(2):107-128.U.
Hahn and K. Schnattinger.
1998.
Towards textknowledge ngineering.
In Proc.
of the AAAI'98.P.
Hastings.
1996.
Implications of an automatic lex-ical acquisition system.
In S. Wermter, E. Riloff,and G. Scheler, editors, Connectionist, Statisticaland Symbolic Approaches to Learning for NaturalLanguage Processing, pages 261-274.
Springer.M.
Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proc.
of theCOLING'92.
Vol.2, pages 539-545.D.
Hindle.
1989.
Acquiring disambiguation rulesfrom text.
In Proc.
of the A CL'89, pages 26-29.C.
Manning.
1993.
Automatic acquisition of largesubcategorization dictionary from corpora.
InProc.
of the A CL'93, pages 235-242.R.
Mooney.
1987.
Integrated learning of wordsand their underlying concepts.
In Proe.
of theCogSci'87, pages 974-978.L.
Rau, P. Jacobs, and U. Zernik.
1989.
Informationextraction and text summarization using linguis-tic knowledge acquisition.
Information ProcessingManagement, 25(4):419-428.P.
Resnik.
1992.
A class-based approach to lexicaldiscovery.
In Proe.
of the A CL '92, pages 327-329.K.
Schnattinger and U. Hahn.
1998.
Quality-basedlearning.
In Proc.
of the ECAI'98, pages 160-164.S.
Sekine, J. Carroll, S. Ananiadou, and J. Tsujii.1994.
Automatic learning for semantic olloca-tion.
In Proc.
of the ANLP'94, pages 104-110.P.
Velardi, M. Pazienza, and M. Fasolo.
1991.How to encode semantic knowledge: a method formeaning representation a d computer-aided ac-quisition.
Computational Linguistics, 17:153-170.W.
Woods and J. Schmolze.
1992.
The KL-ONEfamily.
Computers ~ Mathematics with Applica-tions, 23(2/5):133-177.U.
Zernik and P. Jacobs.
1990.
Tagging for learn-ing: collecting thematic relations from corpus.
InProc.
of the COLING'90.
Vol.
1, pages 34-39.482
