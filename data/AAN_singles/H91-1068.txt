FAST TEXT PROCESSING FOR INFORMATION RETRIEVALTomek Strzalkowski and Barbara VautheyCourant Institute of Mathematical SciencesNew York University251 Mercer StreetNew York, NY 10012{tomek, vauthey }@cs.nyu.eduABSTRACTWe describe an advanced text processing system for information retrievalfrom natural language document collections.
We use both syntactic pro-cessing as well as statistical term clustering to obtain a representation fdocuments which would be more accurate than those obtained with moretraditional key-word methods.
A reliable top-down parser has beendeveloped that allows for fast processing of large amounts of text, and fora precise identification of desired types of phrases for statistical nalysis.Two statistical measures are computed: the measure of informational con-tribution of words in phrases, and the similarity measure between words.APPROXIMATE PARSING WITH TTPTrp  (Tagged Text Parser) is a top down English parserspecifically designed for fast, reliable processing of large amountsof text.
The parser operates on a tagged input, where each wordhas been marked with a tag indicating a syntactic ategory: apartof speech with selected morphological features uch as number,tense, mode, case end degree) As an example, consider the fol-lowing sentence from an article appearing in the Communicationsof the ACM:The binary number system often many advantages over a de-cimal representation fora high-performance, g neral-purposecomputer.This sentence is tagged as follows (we show the best-tags optiononly; dt - determiner, nn - singular noun, nns - plural noun, in -preposition, jj - adjective, vbz - verb in present tense third personsingular):\[\[the,dt\],\[binary,jj\],\[number,nn\],\[system,rm\],\[offers,vbz\],\[many,jj\],\[adventages,rms\],\[over, in\], \[a,dt\],\[decimal,jj\],\[representafion,nn\], \[for,in\] , [a, dt\], \[high_per formence,nn\],\[comS,comS\],\[general pu pose,nn\],\[computer,nn\],\[perS,perS\]\]Tagging of the input text substantially reduces the search space ofa top-down parser since it resolves many lexical ambiguities, uchas singular verb vs. plural noun, past tense vs. past participle, orpreposition vs. wh-determiner.
Tagging also helps to reduce thenumber of parse structures that can be assigned to a sentence,decreases the demand for consulting of the dictionary, endsimplifies dealing with unknown words.t At present we use the 35-tag Penn Treebank Tagset created at theUniversity of Pennsylvania.
Prior to parsing, the text is tagged automati-cally using a program supplied by Bolt Beranek and Newman.
We wish tothank Ralph Weischedel and Marie Meeter of BBN for providing and as-sisting in the use of the tagger.T\]'P is based on the Linguistic String Grammar developedby Sager \[8\] and partially incorporated in the Proteus parser \[3\].T IP  is written in Quintus Prolog, and currently implements morethan 400 grammar productions.
The restriction component of theoriginal LSP Grammar as well as the lamlxta-reduction based"semantics" of the Proteus implementation have been redesignedfor the unification-hased nvironment.
2 TI'P produces a regular-ized representation of each parsed sentence that reflects thesentence's logical structure.
This representation may differ con-siderably from a standard parse tree, in that the constituents getmoved around (e.g., de-passivization, de-dativization), and car-rain noun phrases get transformed into equivalent clauses (de-non'finalization).
The aim is to produce a uniform representationacross different paraphrases; for example, the phrase context-freelanguage recognition or parsing is represented asshown below:\[\[verb,\[or,\[recognize,parse\]\]\]\[subject, anyone\]\[object,\[np,\[n,language\],\[edj,\[context See\]\]\]\]\].The parser is equipped with a time-out mechanism that allows forfast closing of more difficult sub-constituents after a presetamount of time has elapsed without producing a parse.
When thetime-out option is turned on (which happens automatically duringthe parsing), the parser is permitted to skip portions of input toreach a starter terminal for the next constituent to be parsed, andclosing the currently open one (or ones) with whatever partialrepresentation has been generated thus far.
The result is anapproximate partial parse, which shows the overall structure ofthe sentence, from which some of the constituents may be miss-ing.
Since the time-out option can be regulated by setting anappropriate flag before the parsing starts, the parser may be tunedto reach an acceptable compromise between its speed and preci-sion.The time-out mechanism is implemented using a straight-forward parameter passing and is at present limited to only a sub-set of nonterminals u ed by the grammar.
Suppose that X is sucha nonterminal, and that it occurs on the right-hand side of a pro-duction S -> X Y Z.
The set of "starters" is computed for Y,which consists of the word tags that can occur as the left-most2 See \[10\] for details.346constituent of Y.
This set is passed as a parameter while theparser attempts to recognize X in the inpuL If X is recognizedsuccessfully within a preset time, then the parser proceeds toparse a Y, and nothing else happens.
On the other hand, if theparser cannot determine whether there is an X in the input or not,that is, it neither succeeds nor fails in parsing X before beingtimed out, the unfinished X constituent is closed with a partialparse, and the parser is restarted at the closest element from thestarters et for Y that can be found in the remainder of the input.If Y rewrites to an empty sizing, the starters for Z to the right of Yare added to the starters for Y and both sets are passed as aparameter to X.
As an example consider the following clause inthe TrP  parser (some arguments are removed for expository rea-sons):clause(SR,P) :-sa(\[pdt,dt'cd,pp,ppS jj,jjr,jjs,nn, ns,np,nps\] ,PAI),subject(\[vbd,vbz,vbp\] ,Tail,P 1 ),verbphrase(SR,Tail, PI,PAI,P),subtail(Tail).In this production, a (finite) clause rewrites into an (optional) san-tence adjunct (SA), a subject, a verbphrase and subject's rightadjunct (SUBTAIL, also optional).
With the exception of subtail,each predicate has a parameter that specifies the list of "starter"tags for restarting the parser, should the evaluation of this predi-cate exceed the allotted portion of time.
Thus, in case sa isaborted before its evaluation is complete, the parser will jumpover some elements of the unparsed portion of the input lookingfor a word that could begin a subject phrase (either a pre-determiner, a determiner, a count word, a pronoun, an adjective, anoun, or a proper name).
Likewise, when subject is timed out, theparser will restart with verbphrase at either vbz, vbd or vbp (finiteforms of a verb).
Note that if verbphrase is timed out, then subtailwill be ignored, both verbphrase and clause will be closed, andthe parser will restart at an element of set SR passed down fromclause.
The examples in Figures 1 to 3 show approximate parsestructures generated by TTP.The sentence in Figure 1 has been parsed nearly to the end,but T\]'P has failed to find the main verb and it has thrown outmuch of the last phrase such as the LR(k) grammars, partly due toan improper tokenization ofLR(k).
In Figure 2, the parser has ini-tially assumed that the conjunction i  the sentence has the narrowscope, then it realized that something went wrong but, apparently,there was no time left to back up.
Occasionally, however, sen-tences may come out substantially runcated, as shown in Figure3 (where although as been mistagged as a preposition).There are at least several options to realize the kind oftime-regulated parsing discussed above.
One involves allotting acertain amount of time per sentence and, when this time is up,entering the time-out mode for the rest of the current sentenceprocessing.
This amounts to a rapid, though controlled, exit frompresently open constituents mostly ignoring the unparsed portionof the sentence.
This option gives each sentence in the inputroughly the same amount of time, and thus allows the parser toexplore more alternatives while processing shorter sentences,while setting tight limits for the longer ones.
In our experimentswith the CACM collection we found that 0.7 sec/parse is accept-able for an average sentence.
One other option is to set up timelimits per nonterminal, and restore normal parsing after eachtime-out.
The advantage here is that longer sentences receive pro-portionally more time to process (allowing for some backtrackingto explore alternatives).
The disadvantage is that one loses theSENTENCE:The problem of determining whether an arbitrary context-free grammar isa member of some easily parsed subclass of grammars such as the LR(k)grammars i considered.APPROXIMATE PARSE\[assert,\[\[verb,be\],\[ subjcct,\[np,\[n,problem\], \[t_pos,the\],\[of,\[\[verb,\[determine\]\],\[subject,anyone\],\[object,\[\[verb,\[be\]\],\[subject,\[np,\[n,grammar\],\[t_.pos,an\],\[edj,\[arbitrary\]\] ,\[adj,\[context free\]\]\]\],\[obj ect,\[np,\[n,member\],\[t..pos,a\],\[of,\[np,\[n,subelass\] ,It pos,some\],\[a...pos v,\[\[verb,\[parse,\[adv,easily\]\]\],\[subject,anyone\],\[object,pro\]l\],\[of, lnp,\[n,grammar\],\[ro wh,\[\[verb, be\],\[subject,\[np,\[n,k\],\[adj,\[such\]\]...\]Figure I. Parsing with TTP.SENTEN(\]X:The TX-2 computer at MIT Lincoln Laboratory was used for the imple-?
me.ration of such a system and the characteristics of this implementationare reported.APPROXIMA'I~ PAR,~B:\[assert,\[\[be\],l\[verb,luse\]\],\[subject,anyone\],\[object,lnp,\[n,computerl ,\[t_pos ,the\] ,\[edj,ltx 2\] 11\],\[for,\[np,\[n,implernentation\],\[t_pos,the\],\[of,\[and,\[np,\[n,system\],\[t_pos,\[such,a\]\]\],\[np,\[n,characteristics\],\[t_.pos,the\]\]\]\]\]\]\],\[at,\[np,\[n Jaboratory\],\[adj,\[mit\]\],\[n..pos,\[np,\[n Jlncoln\]\]\]\]\],\[of,\[np,\[n,implementation\],\[t..pos,this\],\[m_wh,\[\[verb,be\],\[subject,\[\]\]\]\]\]\]\]\]Figure 2.
Parsing with TTP.347SENTENCE:In principle, the system can deal with any orthography, although atpresent i is limited to 4000 Chinese characters and some mathematicalsymbols.APPROXIMATB PARSE:\[assert,\[\[can_aux\],\[\[verb,\[deal\]l,\[subject,\[np,\[n,system\],\[t..pos,the\]\]\],\[object, t\]\],\[sub_.ord,\[with,\[\[verb,\[limit\]\],\[subject,anyone\],\[object,\[\]\],\[to,\[np,\[n,character\] ,\[connt ,\[4000,chinese\]l\]\] \] \]\] ,\[in,\[np, \[n,principle\]\] \] \]Figure 3, Parsing with TIP.right control upon the overall speed of the parser; now complexsentences may take a considerably onger time to finish.
Variousmixed options are also possible, for instance one may initiallyallot x milliseconds to each sentence, and if necessary, restart itwith a half that time, and so forth.Another method for containing the time allowed for pars-ing is to limit the amount of nondeterminism by a stricter controlover the rule selection and by disabling backtracking at certainpoints, again at the expense of producing only an approximateparse.
Certain types of structural ambiguity, such as preposirionalphrase attachment which cannot be resolved at the syntax levelanyway, frequently remain unresolved in the parse structure gen-erated by 'ITP (although, 'I'\]'P attempts to resolve some struc-tural ambiguities using preferences whenever possible).'
ITP is also quite robust; it can parse nearly every sentenceor phrase, provided the latter is reasonably correctly tagged.
Weparsed the entire CACM-3204 collection and only two sentenceswere returned unparsed, because of multiple tagging errors.
3Toassure a gradual degradation of output rather than an outrightfailure, and also to allow for handling of sentence fragments andisolated phrases uch as titles, each sentence/phrase i  attemptedto be analyzed in up to four ways: (1) as a sentence, (2) as a nounphrase or a preposition phrase with a right adjunct(s), (3) as agerundive clause, and eventually (4) as a series of simple nounphrases.
Each of these attempts is allotted a new time slice, andthe next analysis is started after the previous one fails hut beforeit is timed out.
Although parsing of some sentences may nowapproach four times the allotted time limit, we noted that theaverage parsing time per sentence remains basically unaffected.
43 CACM-3204 is a standard collection used in information retrievalexperiments and includes, in addition to the abstracts, a set of 64 queriesand relevance judgements for them.
The pure text portion of the collectioncontains nearly 10,000 sentences and phrases, or about 235,000 words.4 The average parsing time per sentence is0.745 sec.EXTRACTION OF SYNTACTIC PHRASESThe similarity measure that we use for term classificationis based on quantitative information about word and phrase fre-quencies and word co-occurrences within the text.
We collectedthis information for two-word "phrases" extracted from the parseddocurnents, s The co-occurrence analysis gives the best resultswhen the words are connected by the same grammatical relation,for example verb-object, or noun-right adjunct, etc.
We noted,however, that including multiple relations in the analysis is possi-ble so long as they could be considered to convey similar "seman-tic" dependencies.
In our experiments the following types ofword pairs are extracted: (1) a noun and its left noun adjunct, (2)a noun and the head of its right adjunct, (3) the main verb of aclause and the head of its object phrase, and (4) a noun and itsadjective, where the noun is the head of a noun phrase as recog-nized by the parser.The pairs are extracted from the regularized parse struc-tures with a pattern-matching procedure which uses an exclusionlist to disregard some "uninteresting" words (such as be, such,any).
The words with the common stem but different forms arereplaced by a single "normal" form.
Working on the parsed textensures a high degree of precision in capturing the meaningfulphrases, which is especially evident when compared with theresults usually obtained from a "raw" text (either unprocessed oronly partially processed).
~ On the other hand, since our parser isallowed to skip some portions of each sentence that cannot beparsed within a preset ime limit, the structures it produces areoccasionally incomplete so that the extraction procedure will gen-erate orily a subset of all relevant phrases.
The precision, how-ever, remains very high: few undesired phrases are ever turnedout (as far as the four specified types are concerned), which isparticularly important in subsequent s atistical processes, sincethese tend to be quite sensitive on the amount of noise in theanalyzed material.
An example is shown in Figure 4.STATISTICAL SIMILARITY MEASUREClassification of words and phrases based on similaritiesin their meaning is particularly important in information retrievaisystems.
Various word taxonomies derived from machine-readable dictionaries may be of relevance here \[1\], but general-purpose dictionaries, uch as Oxford's Advanced Learner's Dic-tionary (OALD) or Longman's Dictionary of ContemporaryEnglish (LDOCE), both available on-line, are usually quite lim-ited in their coverage of domain specific vocabulary, includingdomain-specific use of common words as well as technical termi-nology.
Statistical methods for word clustering may provide apartial solution to this problem given a sufficient amount of tex-tual data that display a certain uniformity of subject matter andstyle.
These problems have been studied to some extent withinthe sublanguage paradigm \[4,5\], and also using elements of infor-marion theory \[2,6\].
One general problem with the latter approachis that information theory, which deals with code transmission,5 Lewis and Croft \[71 define the syntactic phrase as "any pxir ofnon-function words in a sentence that are heads of syntactic structuresconnected by a grammatical relation.
"6 Partial processing may include tagging and/or a limited parsing,see, for example \[7\], and also \[9\] for a more comprehensive vi w.348SKN'r~Nc~:The techniques are discussed and related to a general tape manipulationroutine.PARSE STRUCTURB:\[assert,\[\[heI,\[\[verb,\[and,\[disenss\],\[relate\]\]\],\[subject,anyone\],\[object,\[np,\[n,technique\] ,\[t pos,the\]\]\],\[to,\[np,tn,routinel,\[t_pos,al,\[adj,Igeneral\]\],\[n..pos,\[np,\[n#nanipulation\]\]\],\[n..pos,\[np,in,tapellllllll.EXTRACTI/D PAroS:\[discuss,technique\], \[relate,technique\], \[routine,general\],\[roufine,manipulationI, \[manipulation,tapelFigure 4.
Extraction of syntactic pairs.may not be straightforwardly applicable to the analysis of textwhere the basic tokens are words of natural language.
Church andHanks \[2\] used Fano's mutual information to compute word co-occurrence patterns in a 44 million word corpus of AssociatedPress news stories, but they also noted that this measure oftenproduces counterintuitive results.
The reason is that the observedfrequencies of many words remain low even in very large cor-pora.
For very small counts the mutual information becomesunstable and fails to produce credible results.
~Ideally, a measure of relation between words should bestable ven at low counts and more sensitive to fluctuations in fre-quency among different words.
We are particularly interested inthe low and medium frequency words became of their highindexing value.
An interesting comparison among different func-tions used to study word co-occurrences in the Longmen diction-ary is presented by Wilks et al \[11\].
They assumed that the bestfunction would most closely reflect a correlation between achance co-occurrence and a minimum relatedness between words,on the one hand, and between the maximum observed frequencyof co-occurrence and a maximum relatedness, on the other, sAnother question is whether the relatedness measureshould be symmetric.
In other words, for any given pair of words,can we assume that they contribute qually to their mutual rela-tionship7 We felt that the words making up a syntactic phrase donot contribute equally to the informational value of the phrase andthat their contributions depend upon the distribution characteris-tics of each word within a particular type of text.
For example, ina general computer science text the information attached to thephrase parallel system is more significantly related to the word* This may be contrasted with a distribution of symbols from asmall finim alphabet.s A chance co-occurrence of a pair of words is when the probabilityof their occurring together is the product of the probabilities of their beingobserved independently.
Two words have the largest possible frequencyof co-occunence if they never occur separately.
Unfo~onately, a chanceco-occurrence is very difficult o observe.parallel than to the word system.
This relationship can change ifthe phrase is found in a different ype of text where parallel ismore commonplace than system, for example, in a text from aparallel computation subdomain.Based on these considerations, we introduce an asym-metric measure of informational contribution of words in syntac-tic phrases.
This measure IC (x, \[x,y \]) is based on (an estimate of)the conditional probability of seeing a word y to the right of theword x, 9 modified with a dispersion parameter for x.
The disper-sion parameter, d,, understood as the number of distinct wordswith which x is paired, has been defined as follows (f~y is theobserved frequency of the pair \[x,y\]):Ywhereiff~y>OFor each word x occurring in any of the selected syntacticphrases, the informational contribution of this word in a pair ofwords Ix, y\] is calculated according to the following formula:lC(x, \[x,y \ ] )= farth+d, -  1where n z is the number of pairs in which x occurs at the sameposition as in Ix, y\].
IC(x, Ix, y\]) takes values from the <0,1>interval; it is equal to 0 when x and y never occur together (i.e.,fay = 0), and it is equal to 1 when x occurs only with y (i.e.,fay = nx and d~ = 1).
Empirical tests with this formula on theCACM-3204 collection give generally satisfactory results, and afurther improvement may be possible if larger corpora are used(perhaps 1 million words or more).
For each pair of words Ix,y\]two informational contribution values are calculated: IC(x, \[x,y \])and IC(y, \[x,y\]), and they may differ considerably as seen inTable 1.1?
The relative similarity between any two words is meas-ured in terms of their occurrence in common contexts end is thesum of the informational contributions of the context weightedwith the informational contribution of the less significant of thetwo words.
A partial similarity for words xl and x2 in the contextof another word y is therefore given as:si, n,(xx,xz) = p,(xl,x2) (IC (y, \[xx,y \]) + IC (y, \[x2,y \]))wherep,(xl,X2) = min (IC (xi,\[x ,y \]),IC (x2, \[x2,y \]))The total similarity between two words xx and x2 is given as asum of all partial similarities, normalized with a logarithmic func-tion.SIM(x 1,x 2) = log (1000 ~ sirny(x 1,xz))YWe calculated the similarity measure for any two words whichoccurred in at least two common contexts, that is, those whichhave been paired with a common word in at least two distinctoccasions.
The results are summarized inTables 1 to 3.
In Table1 we list the values of IC function for selected pairs.
Tables 29 The conditional probability formula produced the best results inthe experiments reported in \[11\].l0 All tables are placed at the end of the paper.349and 3 show the top elements in the similarity classes generatedfor words graramar and memory.
We noted that the similarityvalue of about 2.0 or more usually coincided with a high degreeof correlation i  meaning, while the smaller values were generallyless interesting.This first classification can be further improved by distin-guishing among word senses.
Many words have multiple senses,and these, rather than the lexical words themselves, hould beused in indexing a text.
However, obtaining a right dissociationbetween different senses of a word presents a separate researchproblem which is beyond the scope of this paper.CONCLUSIONSIn this paper we described the experiments with anefficient processing of large collections of natural language docu-ments that could lead to an effective and reliable method forautomated indexing of text in information retrieval applications.The documents are initially tagged with a stochastic tagger, andthen parsed with the 'ITP parser that generates approximate r gu-larked "logical" structure for each sentence.
These structures aresubsequently analyzed by various tatistical processes that collectdata about word frequencies, co-occurrences and similarities.
Theresults obtained in deriving word pairs show a marked improve-ment in precision for capturing the "correct" word dependenciesas compared to more traditional methods in information retrievalthat use only very limited parsing \[7\].
The computed similaritysets are quite interesting and they produce meaningfulclassifications.
These results can still be improved if the statisticaldata is collected from a larger amount of text.
We believe that theimproved precision in text indexing will translate into animproved precision in document retrieval.ACKNOWLEDGEMENTSThis paper is based upon work supported by the DefenseAdvanced Research Project Agency under Contract N00014-90-J-1851 from the Office of Naval Research, the National ScienceFoundation under Grant IRI-89-02304, and a grant from theSwiss National Foundation for Scientific Research.REFERENCES\[1\] Chodorow, Martin S., Roy J. Byrd, and George E. Heidom.1985.
"Extracting semantic hierarchies from a large on-linedictionary."
Proc.
of the 23rd Meeting of the ACL, pp.
299-304.\[2\] Church, Kenneth Ward and Hanks, Patrick.
1990.
"Wordassociation orms, mutual information, and lexicography.
"ComputationalLinguistics, 16(1), M1T Press, pp.
22-29.\[3\] Grishrnan" Ralph.
1986.
Proteus Parser Reference Manual.Proteus Project Memorandum #4, Courant Institute ofMathematical Sciences, New York University.\[4\] Grishrnan" Ralph, and Kittredge, Richard (eds).
1986.Analyzing Language in Restricted Domains: SublanguageDescription and Processing.
Lawrence Erlbaum Assoc.,Hillsdale, NJ.\[5\] Grishrnan, Ralph, Lyrtette Hirschman,and Ngo T. Nhan.1986.
"Discovery procedures for sublanguage selectionalpatterns: initial experiments".
Computational Linguistics,12(3), pp.
205-215.\[6\] Hindle, Donald.
1990.
"Noun classification from predicate-argument structures."
Proc.
28 Meeting of the ACL, Pitts-burgh, PA, pp.
268-275.\[7\] Lewis, David D. and Croft, W, Bruce.
1990.
"Term cluster-ing of syntactic phrases."
Proc.
13th ACM-SIGIR Confer-ence, Brussels, Belgium, pp.
385-404.\[8\] Sager, Naomi.
1981.
Natural Language Information Pro-cessing.
Addison-Wesley.\[9\] Salton, Gerard.
1989.
Automatic Text Processing: thetransformation, analysis, and retrieval of information bycomputer.
Addison-Wesley, Reading, MA.\[10\] Strzalkowski, Tomek.
1990.
"Reversible logic grammars fornatural language parsing and generation."
ComputationalIntelligence, 6(3), NRC Canada, pp.
145-171.\[ll\]Wilks, Yorick A., Dan Fass, Cheng-ming Guo, James E,McDonald, Tony Plate, and Brian M. Slator.
1990.
"Provid-ing machine tractable dictionary tools."
Machine Transla-tion, 5, pp.
99-154.Table 1.
Informational Contribution for selected word pairsIx, y\] ;C(x, Ix, y\]) ;C(y, \[x,y \]) fxa n, d~,\[system,parallel\] 2 910 322\[system,computation\] 78 910 322\[path,parallel\] 1 19 14\[class,grammar\] 5 128 86\[define,grammar\] 3 131 80\[class,language\] 1 128 86\[define,language\] 9 131 800.0016 57 240.0634 740 2010.0313 57 240.0235 47 340.0143 47 340.0047 295 1160.0429 295 1160.0250.08300.01250.06250.03750.00240.0220350Table 2.
Words most similar to grarar~rword similarity value common contextlogic 2.16 analysis, application, equivalent, inference, networklanguage 1.98 analysis, application, class, code, construct, define, extend, inference, program,sentence, syntax, term, usereduction 1.93 class, equivalentdata 1.88 analysis, base, class, code, define, include, modify, network, processor, pro-gram, usecircuit 1.66 analysis, equivalent, usematch 1.64 equivalent, usecomputation 1.56 analysis, application, class, code, construct, detect, extend, network, produc-tion, program, usetechnique 1.54 analysis, application, base, class, code, extend, include, modify, program,show, Usearea 1.53 class, cover, extend, include, use Ialgofithra 1.43 analysis, application, base, class, code, construct, extend, include, modify, pro- lgram, restrict, show, use ITable 3.
Words most similar to memoryword similarity value common contextstorage 3.41 access, allocate, amount, block, capacity, contain, effect, hierarchy, number,operate, organization, partition, reference, request, size, space, structure, sys-tern, time, unit, use, wordspace 2.79 allocate, amount, concept, limit, model, multics, page, partition, requestresource 2.68 allocate, to the amount, compute, management, request, share, time, usecomputation 2.56 allocate, character, compose, concept, configuration, effect, environment, func-tion, management, model, number, operate, page, program, protection, request,resource, share, simulate, storage, system, technology, time, use, wordblock 2.38 access, allocate, buffer, concept, locate, occupy, size, storage, structure, usefile 2.25 allocate, character, concept, contain, locate, number, organization, size, storage,structure, system, usesystem 2.23 block, character, compute, concept, configuration, contain, core, effect, func-tion, limit.., model, number, operate, organization, part, program, protection, re-quest, resource, section, share, simulate, storage, structure, technology, unit,use, viewbuffer 2.16 allocate, block, request, size, storage, usecore 2.05 allocate, resident, storage, unit, useprocess 1.96 allocate, amount, character, concept, configuration, effect, end, environment,function, hierarchy, number, object, operate, organization, program, request,share, size, system, time, unit, use, view351
