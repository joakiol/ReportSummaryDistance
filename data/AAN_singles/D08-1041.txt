Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 391?399,Honolulu, October 2008. c?2008 Association for Computational LinguisticsWhen Harry Met Harri,  and :Cross-lingual Name Spelling NormalizationFei Huang , Ahmad Emami and Imed ZitouniIBM T. J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598{huangfe, emami, izitouni}@us.ibm.comAbstractForeign name translations typically includemultiple spelling variants.
These variantscause data sparseness problems, increaseOut-of-Vocabulary (OOV) rate, and presentchallenges for machine translation,information extraction and other NLP tasks.This paper aims to identify name spellingvariants in the target language using thesource name as an anchor.
Based on word-to-word translation and transliterationprobabilities, as well as the string editdistance metric, target name translations withsimilar spellings are clustered.
With thisapproach tens of thousands of high precisionname translation spelling variants areextracted from sentence-aligned bilingualcorpora.
When these name spelling variantsare applied to Machine Translation andInformation Extraction tasks, improvementsover strong baseline systems are observed inboth cases.1 IntroductionForeign names typically have multiple spellingvariants after translation, as seen in thefollowing examples:He confirmed that "al-Kharroubprovince is at the top of ourpriorities.
"?for the Socialist ProgressiveParty in upper Shuf and the Al-Kharrub region,?
?during his tour of a number ofvillages in the region of Al-Kharub,?
?Beirut and its suburbs andIqlim al-Khurub,?Such name spelling variants also frequentlyappear in other languages, such as (bushi) /(bushu) / (buxi) (for Bush) in Chinese,and 	 (sbrngfyld) /	  (sbryngfyld) / 	 (sbrynjfyld) (for Springfield) in Arabic.These spelling variants present challenges formany NLP tasks, increasing vocabulary size andOOV rate, exacerbating the data sparsenessproblem and reducing the readability of MToutput when different spelling variants aregenerated for the same name in one document.We address this problem by replacing eachspelling variant with its corresponding canonicalform.
Such text normalization could potentiallybenefit many NLP tasks including informationretrieval, information extraction, questionanswering, speech recognition and machinetranslation.Research on name spelling variants has beenstudied mostly in Information Retrieval research,especially in query expansion and cross-lingualIR.
Baghat and Hovy (2007) proposed twoapproaches for spelling variants generation,based on the letters-to-phonemes mapping andSoundex algorithm (Knuth 1973).
Raghaven andAllan (2005) proposed several techniques togroup names in ASR output and evaluated theireffectiveness in spoken document retrieval(SDR).
Both approaches use a named entityextraction system to automatically identifynames.
For multi-lingual name spelling variants,Linden (2005) proposed to use a general editdistance metric with a weighted FST to findtechnical term translations (which were referredto as ?cross-lingual spelling variants?).
These391variants are typically translated words withsimilar stems in another language.
Toivonen andcolleagues (2005) proposed a two-step fuzzytranslation technique to solve similar problems.Al-Onaizan and Knight (2002), Huang (2003)and Ji and Grishman (2007) investigated thegeneral name entity translation problem,especially in the context of machine translation.This paper aims to identify mono-lingualname spelling variants using cross-lingualinformation.
Instead of using a named entitytagger to identify name spelling variants, wetreat names in one language as the anchor ofspelling variants in another language.
Fromsentence-aligned bilingual corpora we collectword co-occurrence statistics and calculate wordtranslation1 probabilities.
For each source word,we group its target translations into clustersaccording to string edit distances, then calculatethe transliteration cost between the source wordand each target translation cluster.
Word pairswith small transliteration costs are considered asname translations, and the target cluster containsmultiple spelling variants corresponding to thesource name.We apply this approach to extract nametransliteration spelling variants from bilingualcorpora.
We obtained tens of thousands of highprecision name translation pairs.
We furtherapply these spelling variants to MachineTranslation (MT) and Information Extraction (IE)tasks, and observed statistically significantimprovement on the IE task, and close to oracleimprovement on the MT task.The rest of the paper is organized as follows.In section 2 we describe the technique toidentify name spelling variants from bilingualdata.
In section 3 and 4 we address theirapplication to MT and IE respectively.
Wepresent our experiment results and detailedanalysis in section 5.
Section 6 concludes thispaper with future work.2 Finding Name Translation Variants1In this paper, the translation cost measures the semanticdifference between source and target names, which areestimated from their co-occurrence statistics.
Thetransliteration cost measures their phonetic distance and areestimated based on a character transliteration model.Starting from sentence-aligned parallel data, werun HMM alignment (Vogel et.
al.
1996 & Ge2004) to obtain a word translation model.
Foreach source word this model generates targetcandidate translations as well as their translationprobabilities.
A typical entry is shown in Table 1.It can be observed that the Arabic name?stranslations include several English words withsimilar spellings, all of which are correcttranslations.
However, because the lexicaltranslation probabilities are distributed amongthese variants, none of them has the highestprobability.
As a result, the incorrect translation,iqlim, is assigned the highest probability andoften selected in MT output.
To fix this problem,it is desirable to identify and group these targetspelling variants, convert them into a canonicalform and merge their translation probabilities. | Alxrwbiqlim[0.22]al-kharrub[0.16]al-kharub[0.11]overflew[0.09]junbulat[0.05]al-khurub[0.05]hours[0.04]al-kharroub[0.03]Table 1.
English translations of a Romanized Arabicname Alxrwb with translation probabilities.For each source word in the word translationmodel, we cluster its target translations based onstring edit distances using group averageagglomerative clustering algorithm (Manningand Sch?tze, 2000).
Initially each target word isa single word cluster.
We calculate the averageediting distance between any two clusters, andmerge them if the distance is smaller than acertain threshold.
This process repeats until theminimum distance between any two clusters isabove a threshold.
In the above example, al-kharrub, al-kharub, al-khurub and al-kharroubare grouped into a single cluster, and each of theungrouped words remains in its single wordcluster.
Note that the source word may not be aname while its translations may still have similarspellings.
An example is the Arabic word which is aligned to English words brief, briefing,briefed and briefings.
To detect whether a sourceword is a name, we calculate the transliterationcost between the source word and its targettranslation cluster, which is defined as theaverage transliteration cost between the sourceword and each target word in the cluster.
As392many names are translated based on theirpronunciations, the source and target nameshave similar phonetic features and lowertransliteration costs.
Word pairs whosetransliteration cost is lower than an empiricallyselected threshold are considered as nametranslations.2.1 Name Transliteration CostThe transliteration cost measures the phoneticsimilarity between a source word and a targetword.
It is calculated based on the charactertransliteration model, which can be trained frombilingual name translation pairs.
We segment thesource and target names into characters, then runmonotone2 HMM alignment on the source andtarget character pairs.
After the training,character transliteration probabilities can beestimated from the relevant frequencies ofcharacter alignments.Suppose the source word f contains mcharacters, f1, f2, ?, fm,  and the target word econtains n characters, e1, e2, ?, en.
For j=1, 2,?,n, letter  ej is aligned to character jaf accordingto the HMM aligner.
Under the assumption thatcharacter alignments are independent, the wordtransliteration probability is calculated as?==njaj jfepfeP1)|()|(          (2.1)where )|(jaj fep is the character transliterationprobability.
Note that in the above configurationone target character can be aligned to only onesource character, and one source character canbe aligned to multiple target characters.An example of the trained A-E charactertransliteration model is shown in Figure 1.
TheArabic character  is aligned with highprobabilities to English letters with similarpronunciation.
Because Arabic words typicallyomit vowels, English vowels are also aligned toArabic characters.
Given this model, thecharacters within a Romanized Arabic name andits English translation are aligned as shown inFigure 1.2As name are typically phonetically translated, thecharacter alignment are often monotone.
There is no cross-link in character alignments.2.2 Transliteration Unit SelectionThe transliteration units are typically characters.The Arabic alphabet includes 32 characters, andthe English alphbet includes 56 letters 3 .However, Chinese has about 4000 frequentcharacters.
The imbalance of Chinese andEnglish vocabulary sizes results in suboptimaltransliteration model estimation.
Each Chinesecharacter also has a pinyin, the Romanizedrepresentation of its pronunciation.
Segmentingthe Chinese pinyin into sequence of Romanletters, we now have comparable vocabularysizes for both Chinese and English.
We build apinyin transliteration model using Chinese-English name translation pairs, and compare itsperformance with a character transliterationmodel in Experiment section 5.1.h[0.44]K[0.29]k[0.21]a[0.03]u[0.015]i[0.004]  Figure 1.
Example of the learned A-E charactertransliteration model with probabilities, and itsapplication in the alignment between an RomanizedArabic name and an English translation.3 Application to Machine TranslationWe applied the extracted name translationspelling variants to the machine translation task.Given the name spelling variants, we updatedboth the translation and the language model,adding variants?
probabilities to the canonicalform.Our baseline MT decoder is a phrase-baseddecoder as described in (Al-Onaizan andPapineni 2006).
Given a source sentence, thedecoder tries to find the translation hypothesiswith minimum translation cost, which is definedas the log-linear combination of different featurefunctions, such as translation model cost,language model cost, distortion cost and3Uppercase and lowercase letters plus some specialsymbols such as ?_?, ?-?.393sentence length cost.
The translation costincludes word translation probability and phrasetranslation probability.3.1 Updating The Translation ModelGiven target name spelling variants { mttt ,...,, 21} for a source name s, here mttt ,...,, 21 are sortedbased on their lexical translation probabilities,).|(...)|()|( 21 stpstpstp m??
?We select 1t  as the canonical spelling, andmerge other spellings?
translation probabilitieswith this one:?==mjm stpstp11 ).|()|(Other spelling variants get zero probability.Table 2 shows the updated word translationprobabilities for ?|Alxwrb?.
Comparedwith Figure 1, the translation probabilities fromseveral spelling variants are merged with thecanonical form, al-kharrub, which now has thehighest probability in the new model.Table 2.
English translations of an Arabic name |Alxrwb with the updated word translationmodel.The phrase translation table includes sourcephrases, their target phrase translations and thefrequencies of the bilingual phrase pairalignment.
The phrase translation probabilitiesare calculated based on their alignmentfrequencies, which are collected from wordaligned parallel data.
To update the phrasetranslation table, for each phrase pair including asource name and its spelling variant in the targetphrase, we replace the target name with itscanonical spelling.
After the mapping, two targetphrases differing only in target names may endup with the identical target phrase, and theiralignment frequencies are added.
Phrasetranslation probabilities are re-estimated with theupdated frequencies.3.2 Updating The Language ModelThe machine translation decoder uses a languagemodel as a measure of a well-formedness of theoutput sentence.
Since the updated translationmodel can produce only the canonical form of agroup of spelling variants, the language modelshould be updated in that all m-grams( Nm ?
?1 ) that are spelling variants of eachother are merged (and their counts added),resulting in the canonical form of the m-gram.Two m-grams are considered spelling variants ofeach other if they contain words it1 ,it2 ( ii tt 21 ?
)at the same position i in the m-gram, and that it1and it2 belong to the same spelling variant group.An easy way to achieve this update is toreplace every spelling variant in the originallanguage model training data with itscorresponding canonical form, and then buildthe language model again.
However, since we donot want to replace words that are not names weneed to have a mechanism for detecting names.For simplicity, in our experiments we assumed aword is a name if it is capitalized, and wereplaced spelling variants with their canonicalforms only for words that start with a capitalletter.4 Applying to Information ExtractionInformation extraction is a crucial step towardunderstanding a text, as it identifies theimportant conceptual objects in a discourse.
Weaddress here one important and basic task ofinformation extraction: mention detection4: wecall instances of textual references to objectsmentions, which can be either named (e.g.
JohnSmith), nominal (the president) or pronominal(e.g.
he, she).
For instance, in the sentence?
President John Smith said he has nocomments.there are two mentions: John Smith and he.Similar to many classical NLP tasks, weformulate the mention detection problem as aclassification problem, by assigning to eachtoken in the text a label, indicating whether itstarts a specific mention, is inside a specificmention, or is outside any mentions.
Good4We adopt here the ACE (NIST 2007) nomenclature. | Alxwrbal-kharrub[0.35]iqlim[0.22]al-kharub[0.0]overflew[0.09]junbulat[0.05]al-khurub[0.0]hours[0.04]al-kharroub[0.0]394performance in many natural languageprocessing tasks has been shown to dependheavily on integrating many sources ofinformation (Florian et al 2007).
We select anexponential classifier, the Maximum Entropy(MaxEnt henceforth) classifier that can integratearbitrary types of information and make aclassification decision by aggregating allinformation available for a given classification(Berger et al 1996).
In this paper, the MaxEntmodel is trained using the sequential conditionalgeneralized iterative scaling (SCGIS) technique(Goodman, 2002), and it uses a Gaussian priorfor regularization (Chen and Rosenfeld, 2000).In ACE, there are seven possible mentiontypes: person, organization, location, facility,geopolitical entity (GPE), weapon, and vehicle.Experiments are run on Arabic and English.
Ourbaseline system achieved very competitive resultamong systems participating in the ACE 2007evaluation.
It uses a large range of features,including lexical, syntactic, and the output ofother information extraction models.
Thesefeatures were described in (Zitouni and Florian,2008 & Florian et al 2007), and are notdiscussed here.
In this paper we focus onexamining the effectiveness of name spellingvariants in improving mention detectionsystems.
We add a new feature that for eachtoken xi  to process we fire its canonical form(class label) C(xi) ,  representative of namespelling variants of xi .
This name spellingvariant feature is also used in conjunction withthe lexical (e.g., words and morphs in a 3-wordwindow, prefixes and suffixes of length up to 4,stems in a 4-word window for Arabic) andsyntactic (POS tags, text chunks) features.5 Experiments5.1 Evaluating the precision of namespelling variantsWe extracted Arabic-English and English-Arabic name translation variants from sentence-aligned parallel corpora released by LDC.
Theaccuracy of the extracted name translationspelling variants are judged by proficient Arabicand Chinese speakers.The Arabic-English parallel corpora include5.6M sentence pairs, 845K unique Arabic wordsand 403K unique English words.
We trained aword translation model by running HMMalignment on the parallel data, grouped targettranslation with similar spellings and computedthe average transliteration cost between theArabic word and each English word in thetranslation clusters according to Formula 2.1.We sorted the name translation groups accordingto their transliteration costs, and selected 300samples at different ranking position forevaluation (20 samples at each ranking position).The quality of the name translation variants arejudged as follows: for each candidate nametranslation group }|,...,,{ 21 sttt m , if the sourceword s is a name and all the target spellingvariants are correct translations, it gets a creditof 1.
If s is not a name, the credit is 0.
If s is aname but only part of the target spelling variantsare correct, it gets partial credit n/m, where n isthe number of correct target translations.
Weevaluate only the precision of the extractedspelling variants 5 .
As seen in Figure 2, theprecision of the top 22K A-E name translationsis 96.9%.
Among them 98.5% of the Arabicwords are names.
The precision gets lower andlower when more non-name Arabic words areincluded.
On average, each Arabic name has2.47 English spelling variants, although there aresome names with more than 10 spelling variants.Switching the source and target languages, weobtained English-Arabic name spelling variants,i.e., one English name with multiple Arabicspellings.
As seen in Figure 3, top 20K E-Aname pairs are obtained with a precision above87.9%, and each English name has 3.3 Arabicspellings on average.
Table 3 shows some A-Eand E-A name spelling variants, where Arabicwords are represented in their Romanized form.We conduct a similar experiment on theChinese-English language pair, extractingChinese-English and English-Chinese namespelling variants from 8.7M Chinese-Englishsentence pairs.
After word segmentation, theChinese vocabulary size is 1.5M words, andEnglish vocabulary size is 1.4M words.
With the5Evaluating recall requires one to manually look throughthe space of all possible transliterations (hundreds ofthousands of entries), which is impractical.395Chinese pinyin transliteration model, we extract64K C-E name spelling variants with 93.6%precision.
Figure 4 also shows the precisioncurve of the Chinese character transliterationmodel.
On average the pinyin transliterationmodel has about 6% higher precision than thecharacter transliteration model.
The pinyintransliteration model is particularly better on thetail of the curve, extracting more C-Etransliteration variants.
Figure 5 shows theprecision curve for E-C name spelling variants,where 20K name pairs are extracted using letter-to-character transliteration model, and obtaininga precision of 74.3%.Table 4 shows some C-E and E-C namespelling variants.
We observed errors due toword segmentation.
For example, the last twoChinese words corresponding to ?drenica?
haveadditional Chinese characters, meaning ?drenicaregion?
and ?drenica river?.
Similarly for tenet,the last two Chinese words also havesegmentation errors due to missing or spuriouscharacters.
Note that in the C-E spelling variants,the source word ? ?
has 14 spellingvariants.
Judge solely from the spelling, it ishard to tell whether they are the same personname with different spellings.5.2   Experiments on Machine TranslationWe apply the Arabic-English name spellingvariants on the machine translation task.
Ourbaseline system is trained with 5.6M Arabic-English sentence pairs, the same training dataused to extract A-E spelling variants.
Thelanguage model is a modified Kneser-Ney 5-gram model trained on roughly 3.5 billion words.After pruning (using count cutoffs), it contains atotal of 935 million N-grams.
We updated thetranslation models and the language model withthe name spelling variant class.Table 5 shows a Romanized Arabic sentence,the translation output from the baseline systemand the output from the updated models.
In thebaseline system output, the Arabic name?Alxrwb?
was incorrectly translated into?regional?.
This error was fixed in the updatedmodel, where both translation and languagemodels assign higher probabilities to the correcttranslation ?al-kharroub?
after spelling variantnormalization.		Figure 2.
Arabic-English name spelling variantsprecision curve (Precision of evaluation sample atdifferent ranking positions.
The larger square indicatesthe cutoff point).		rankingpinyin charFigure 4.
Chinese-English name spelling variantsprecision curve.		Figure 3.
English-Arabic name spelling variantsprecision curve.		Figure 5.
English-Chinese name spelling variantsprecision curve.396Source Alm&tmr AlAwl lAqlym Alxrwb AlErby AlmqAwmReference the first conference of the Arab resistance in Iqlim KharoubBaseline the first conference of the Arab regional resistanceUpdated model first conference of the Al-Kharrub the Arab resistanceTable 5.
English translation output with the baseline MT system and the system with updated modelsBLEUr1n4 TERBaseline 0.2714 51.66Baseline+ULM+UTM 0.2718 51.46Ref.
Normalization 0.2724 51.40Table 6.
MT scores with updated TM and LMWe also evaluated the updated MT models on aMT test set.
The test set includes 70 documentsselected from GALE 2007 Development set.
Itcontains 42 newswire documents and 28 weblogand newsgroup documents.
There are 669sentences with 16.3K Arabic words in the testdata.
MT results are evaluated against onereference human translation using BLEU(Papineni et.
al.
2001) and TER (Snover et.
al.2006) scores.
The results using the baselinedecoder and the updated models are shown inTable 6.
Applying the updated language model(ULM) and the translation model (UTM) lead toa small reduction in TER.
After we apply similarname spelling normalization on the referencetranslation, we observed some additionalimprovements.
Overall, the BLEU score isincreased by 0.1 BLEU point and TER isreduced by 0.26.Although the significance of correct nametranslation can not be fully represented byTable 3.
Arabic-English and English-Arabic name spelling variant examples.
Italic words represent differentpersons with similar spelling names.Lang.
Pair Source Name Target Spelling VariantsAlxmyny khomeini al-khomeini al-khomeni khomeni khomeyni khamenei khameneh'ikrwby     karroubi karrubi krobi karubi karoubi kroubiArabic-EnglishgbryAl     gabriel gabrielle gabrial ghobrial ghybrialcirebon   syrybwn syrbwn syrbn kyrybwn bsyrybwn bsyrwbwnmbinda     mbyndA mbndA mbydA AmbyndA AmbAndA mbynydAEnglish-Arabicnguyen     njwyn ngwyn ngwyyn ngyyn Angwyn nygwyyn nygwyn wnjwyn njwyynnyjyn bnjwyn wngyyn ngwyAn njyn nykwynTable 4.
Chinese-English and English-Chinese name spelling variant examples with pinyin for Chinese characters.Italic words represent errors due to word segmentation.Lang.
Pair Source Name  Target Spelling Variants(yan/duo/wei/ci/ji)endovitsky jendovitski yendovitski endovitski(si/te/fan/ni)stefani steffani stephani stefanni stefaniaChinese-English(wei/er/man)woermann wellman welman woellmann wohrmann wormann velmanwollmann wehrmann verman woehrmann wellmann welmann wermanntenet (te/ni/te) (te/nei/te) (tai/nei/te) (te/nai/te) (te/nai/te) (te/nei/te/yu) (te/nei)drenica (de/lei/ni/cha) (de/lei/ni/ka) (te/lei/ni/cha) (te/lei/ni/cha) (de/lei/ni/cha/qu) (de/lei/ni/cha/he)English-Chineseahmedabad (ai/ha/mai/da/ba/de) (ai/a/mai/da/ba/de)  (ai/ha/mo/de/ba/de)  (a/ha/mai/da/ba/de)397BLEU and TER scores 6 , we still want tounderstand the reason of the relatively smallimprovement.
After some error analysis, wefound that in the testset only 2.5% of Arabicwords are names with English spelling variants.Among them, 73% name spelling errors can becorrected with the translation spelling variantsobtained in section 5.1.
Because the MT systemis trained on the same bilingual data from whichthe name spelling variants are extracted, some ofthese Arabic names are already correctlytranslated in the baseline system.
So the room ofimprovement is small.
We did an oracleexperiment, manually correcting the nametranslation errors in the first 10 documents (89sentences with 2545 words).
With only 6 nametranslation errors corrected, this reduced theTER from 48.83 to 48.65.5.2 Experiments on InformationExtractionMention detection system experiments areconducted on the ACE 2007 data sets in Arabicand English.
Since the evaluation test set is notpublicly available, we have split the publiclyavailable training corpus into an 85%/15% datasplit.
To facilitate future comparisons with workpresented here, and to simulate a realisticscenario, the splits are created based on articledates: the test data is selected as the latest 15%of the data in chronological order.
This way, thedocuments in the training and test data sets donot overlap in time, and the content of the testdata is more recent than the training data.
ForEnglish we use 499 documents for training and100 documents for testing, while for Arabic weuse 323 documents for training and 56documents for testing.
English and Arabicmention detection systems are using a largerange of features, including lexical (e.g., wordsand morphs in a 3-word window, prefixes andsuffixes of length up to 4, stems in a 4-wordwindow for Arabic), syntactic (POS tags, textchunks), and the output of other informationextraction models.
These features weredescribed in (Zitouni and Florian, 2008 &Florian et al 2007) with more details.
Our goalhere is to investigate the effectiveness of name6These scores treat information bearing words, like names,the same as any other words, like punctuations.spelling variants information in improvingmention detection system performance.Baseline Baseline+NSVP R F P R FEnglish 84.4 80.6 82.4 84.6 80.9 82.7Arabic 84.3 79.0 81.6 84.4 79.1 81.7Table 7: Performance of English and Arabic mentiondetection systems without (Baseline) and with(Baseline+NSV) the use of name spelling variants.Performance is presented in terms of Precision (P),Recall (R), and F-measure (F).Results in Table 7 show that the use of namespelling variants (NSV) improves mentiondetection systems performance, especially forEnglish; an interesting improvement is obtainedin recall ?
which is to be expected, given themethod ?, but also in precision, leading tosystems with better performance in terms of F-measure (82.4 vs. 82.7).
This improvement inperformance is statistically significant accordingto the stratified bootstrap re-samplingapproach (Noreen 1989).
This approach is usedin the named entity recognition shared task ofCoNLL-2002 7 .
However, the smallimprovement obtained for Arabic is notstatistically significant based on the approachdescribed earlier.
One hypothesis is that Arabicname spelling variants are not rich enough andthat a better tuning of the alignment score isrequired to improve precision.6 ConclusionWe proposed a cross-lingual name spellingvariants extraction technique.
We extracted tensof thousands of high precision bilingual nametranslation spelling variants.
We applied thespelling variants to the IE task, observingstatistically significant improvements over astrong baseline system.
We also applied thespelling variants to MT task and even though theoverall improvement is relatively small, itachieves performance close to the one observedin an oracle experiment.7http://www.cnts.ua.ac.be/conll2002/ner/398AcknowledgmentsThis work was supported by DARPA/IPTOContract No.
HR0011-06-2-0001 under theGALE program.
We are grateful to Yaser Al-Onaizan, Salim Roukos and anonymousreviewers for their constructive comments.ReferencesAl-Onaizan, Y. and Papineni, K. Distortion Models forStatistical Machine Translation.
In Proceedings of the44th Annual Meeting on Association For ComputationalLinguistics.
Sydney, Australia.
July 2006.Al-Onaizan, Y. and Knight, K. Translating named entitiesusing monolingual and bilingual resources.
InProceedings of the 40th Annual Meeting on AssociationFor Computational Linguistics (Philadelphia,Pennsylvania, July 07 - 12, 2002).
Annual Meeting ofthe ACL.
Association for Computational Linguistics,Morristown, NJ.
2002Berger, A., S. Della Pietra, and V. Della Pietra.
AMaximum entropy approach to natural languageprocessing.
Computational Linguistics, 22(1):39?71.1996Bhagat, R. and Hovy, E. "Phonetic Models for GeneratingSpelling Variants", In Proceedings International JointConference of Artificial Intelligence (IJCAI).Hyderabad, India.
2007.Chen, S. and Rosenfeld R. A survey of smoothingtechniquesfor ME models.
IEEE Trans.
On Speech andAudio Processing.
2002Florian, R., Hassan, H., Ittycheriah, A., Jing, H.,Kambhatla, N., Luo, X., Nicolov, N., and Roukos.
S. Astatistical model for multilingual entity detection andtracking.
In Proceedings of the Human LanguageTechnology Conference of the North American Chapterof the Association for Computational Linguistics: HLT-NAACL 2004, pages 1?8.Ge, N. Improvements in Word Alignments.
Presentationgiven at DARPA/TIDES NIST MT Evaluationworkshop.
2004Goodman.
J. Sequential conditional generalized iterativescaling.
In Proceedings of the 40th Annual Meeting onAssociation For Computational Linguistics(Philadelphia, Pennsylvania, July 07 - 12, 2002).
AnnualMeeting of the ACL.
Association for ComputationalLinguistics, Morristown, NJ.
2002Huang, F., Vogel, S., and Waibel, A.
Automatic extractionof named entity translingual equivalence based onmulti-feature cost minimization.
In Proceedings of theACL 2003 Workshop on Multilingual and Mixed-Language Named Entity Recognition - Annual Meetingof the ACL.
Association for Computational Linguistics,Morristown, NJ, 2003Ji, H. and Grishman.
R. Collaborative Entity Extraction andTranslation.
Proc.
International Conference on RecentAdvances in Natural Language Processing.
Borovets,Bulgaria.
Sept 2007.Knuth, D. The Art of Computer Programming ?
Volume 3:Sorting and Searching.
Addison- Wesley PublishingCompany, 1973.Linden, K. ?Multilingual Modeling of Cross-LingualSpelling Variants?, Information Retrieval, Vol.
9, No.
3.
(June 2006), pp.
295-310.Manning, C.D., and Schutze., H.  Foundations of StatisticalNatural Language Processing.
MIT Press, 2000NIST.
2007.
The ACE evaluation plan.www.nist.gov/speech/tests/ace/index.htm.Noreen, E. W. Computer-Intensive Methods for TestingHypothesis.
John Wiley Sons.
1989Papineni, K.A., Roukos, S., Ward, T., Zhu, W.J.
BLEU: amethod for automatic evaluation of machine translation.Technical Report RC22176 (W0109-022), IBMResearch Division, Thomas J. Watson Research Center(2001)Raghavan, H. and Allan, J., "Matching InconsistentlySpelled Names in Automatic Speech Recognizer Outputfor Information Retrieval," the Proceedings ofHLT/EMNLP 2005, pp.
451-458.Snover, M., Dorr, B., Schwartz, R., Micciulla, L., andMakhoul, J.
"A Study of Translation Edit Rate withTargeted Human Annotation," Proceedings ofAssociation for Machine Translation in the Americas,2006.Toivonen, J., Pirkola, A., Keskustalo, H., Visala, K. andJ?rvelin, K. Translating cross-lingual spelling variantsusing transformation rules.
Inf.
Process.
Manage.
41(4):859-872 (2005)Vogel, S., Ney, H., and Tillmann, C.. HMM-based wordalignment in statistical translation.
In Proceedings of the16th Conference on Computational Linguistics - Volume2 (Copenhagen, Denmark, August 05 - 09, 1996).International Conference On Computational Linguistics.Association for Computational Linguistics, Morristown,NJ 1996Zitouni, I., Florian R..
Mention Detection Crossing theLanguage Barrier.
Proceedings of  Conference onEmpirical Methods in Natural Language Processing.Waikiki, Honolulu, Hawaii  (October, 2008)Zitouni, I., Sorensen, J., Luo, X., and Florian, R. Theimpact of morphological stemming on Arabic mentiondetection and coreference resolution.
In Proceedings ofthe ACL Workshop on Computational Approaches toSemitic Languages.
The 43rd Annual Meeting of theAssociation for Computational Linguistics.
Ann Arbor(June, 2005)399
