Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1017?1024,Sydney, July 2006. c?2006 Association for Computational LinguisticsSemantic Retrieval for the Accurate Identification of Relational Conceptsin Massive TextbasesYusuke Miyao?
Tomoko Ohta?
Katsuya Masuda?
Yoshimasa Tsuruoka?Kazuhiro Yoshida?
Takashi Ninomiya?
Jun?ichi Tsujii??
?Department of Computer Science, University of Tokyo?School of Informatics, University of Manchester?Information Technology Center, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 JAPAN{yusuke,okap,kmasuda,tsuruoka,kyoshida,ninomi,tsujii}@is.s.u-tokyo.ac.jpAbstractThis paper introduces a novel frameworkfor the accurate retrieval of relational con-cepts from huge texts.
Prior to retrieval,all sentences are annotated with predicateargument structures and ontological iden-tifiers by applying a deep parser and a termrecognizer.
During the run time, user re-quests are converted into queries of regionalgebra on these annotations.
Structuralmatching with pre-computed semantic an-notations establishes the accurate and effi-cient retrieval of relational concepts.
Thisframework was applied to a text retrievalsystem for MEDLINE.
Experiments onthe retrieval of biomedical correlations re-vealed that the cost is sufficiently small forreal-time applications and that the retrievalprecision is significantly improved.1 IntroductionRapid expansion of text information has motivatedthe development of efficient methods of access-ing information in huge texts.
Furthermore, userdemand has shifted toward the retrieval of moreprecise and complex information, including re-lational concepts.
For example, biomedical re-searchers deal with a massive quantity of publica-tions; MEDLINE contains approximately 15 mil-lion references to journal articles in life sciences,and its size is rapidly increasing, at a rate of morethan 10% yearly (National Library of Medicine,2005).
Researchers would like to be able tosearch this huge textbase for biomedical correla-tions such as protein-protein or gene-disease asso-ciations (Blaschke and Valencia, 2002; Hao et al,2005; Chun et al, 2006).
However, the frameworkof traditional information retrieval (IR) has diffi-culty with the accurate retrieval of such relationalconcepts because relational concepts are essen-tially determined by semantic relations betweenwords, and keyword-based IR techniques are in-sufficient to describe such relations precisely.The present paper demonstrates a frameworkfor the accurate real-time retrieval of relationalconcepts from huge texts.
Prior to retrieval, weprepare a semantically annotated textbase by ap-plying NLP tools including deep parsers and termrecognizers.
That is, all sentences are annotatedin advance with semantic structures and are storedin a structured database.
User requests are con-verted on the fly into patterns of these semanticannotations, and texts are retrieved by matchingthese patterns with the pre-computed semantic an-notations.
The accurate retrieval of relational con-cepts is attained because we can precisely describerelational concepts using semantic annotations.
Inaddition, real-time retrieval is possible because se-mantic annotations are computed in advance.This framework has been implemented for atext retrieval system for MEDLINE.
We first ap-ply a deep parser (Miyao and Tsujii, 2005) anda dictionary-based term recognizer (Tsuruoka andTsujii, 2004) to MEDLINE and obtain annotationsof predicate argument structures and ontologicalidentifiers of genes, gene products, diseases, andevents.
We then provide a search engine for theseannotated sentences.
User requests are convertedinto queries of region algebra (Clarke et al, 1995)extended with variables (Masuda et al, 2006) onthese annotations.
A search engine for the ex-tended region algebra efficiently finds sentenceshaving semantic annotations that match the inputqueries.
In this paper, we evaluate this system withrespect to the retrieval of biomedical correlations1017Symbol CRPName C-reactive protein, pentraxin-relatedSpecies Homo sapiensSynonym MGC88244, PTX1Product C-reactive protein precursor, C-reactiveprotein, pentraxin-related proteinExternal links EntrezGene:1401, GDB:119071, .
.
.Table 1: An example GENA entryand examine the effects of using predicate argu-ment structures and ontological identifiers.The need for the discovery of relational con-cepts has been investigated intensively in Infor-mation Extraction (IE).
However, little researchhas targeted on-demand retrieval from huge texts.One difficulty is that IE techniques such as pat-tern matching and machine learning require heav-ier processing in order to be applied on the fly.Another difficulty is that target information mustbe formalized beforehand and each system is de-signed for a specific task.
For instance, an IEsystem for protein-protein interactions is not use-ful for finding gene-disease associations.
Apartfrom IE research, enrichment of texts with vari-ous annotations has been proposed and is becom-ing a new research area for information manage-ment (IBM, 2005; TEI, 2004).
The present studybasically examines this new direction in research.The significant contribution of the present paper,however, is to provide the first empirical results ofthis framework for a real task with a huge textbase.2 Background: Resources and Tools forSemantic AnnotationsThe proposed system for the retrieval of relationalconcepts is a product of recent developments inNLP resources and tools.
In this section, ontologydatabases, deep parsers, and search algorithms forstructured data are introduced.2.1 Ontology databasesOntology databases are collections of words andphrases in specific domains.
Such databases havebeen constructed extensively for the systematicmanagement of domain knowledge by organizingtextual expressions of ontological entities that aredetached from actual sentences.For example, GENA (Koike and Takagi, 2004)is a database of genes and gene products thatis semi-automatically collected from well-knowndatabases, including HUGO, OMIM, Genatlas,Locuslink, GDB, MGI, FlyBase, WormBase,Figure 1: An output of HPSG parsingFigure 2: A predicate argument structureCYGD, and SGD.
Table 1 shows an example ofa GENA entry.
?Symbol?
and ?Name?
denoteshort forms and nomenclatures of genes, respec-tively.
?Species?
represents the organism speciesin which this gene is observed.
?Synonym?
is alist of synonyms and name variations.
?Product?gives a list of products of this gene, such as pro-teins coded by this gene.
?External links?
pro-vides links to other databases, and helps to obtaindetailed information from these databases.
Forbiomedical terms other than genes/gene products,the Unified Medical Language System (UMLS)meta-thesaurus (Lindberg et al, 1993) is a largedatabase that contains various names of biomedi-cal and health-related concepts.Ontology databases provide mappings be-tween textual expressions and entities in the realworld.
For example, Table 1 indicates that CRP,MGC88244, and PTX1 denote the same gene con-ceptually.
Hence, these resources enable us tocanonicalize variations of textual expressions ofontological entities.2.2 Parsing technologiesRecently, state-of-the-art CFG parsers (Charniakand Johnson, 2005) can compute phrase structuresof natural sentences at fairly high accuracy.
Theseparsers have been used in various NLP tasks in-cluding IE and text mining.
In addition, parsersthat compute deeper analyses, such as predicateargument structures, have become available for1018the processing of real-world sentences (Miyao andTsujii, 2005).
Predicate argument structures arecanonicalized representations of sentence mean-ings, and express the semantic relations of wordsexplicitly.
Figure 1 shows an output of an HPSGparser (Miyao and Tsujii, 2005) for the sentence?A normal serum CRP measurement does not ex-clude deep vein thrombosis.?
The dotted lines ex-press predicate argument relations.
For example,the ARG1 arrow coming from ?exclude?
pointsto the noun phrase ?A normal serum CRP mea-surement?, which indicates that the subject of ?ex-clude?
is this noun phrase, while such relations arenot explicitly represented by phrase structures.Predicate argument structures are beneficial forour purpose because they can represent relationalconcepts in an abstract manner.
For example, therelational concept of ?CRP excludes thrombosis?can be represented as a predicate argument struc-ture, as shown in Figure 2.
This structure is univer-sal in various syntactic expressions, such as pas-sivization (e.g., ?thrombosis is excluded by CRP?
)and relativization (e.g., ?thrombosis that CRP ex-cludes?).
Hence, we can abstract surface varia-tions of sentences and describe relational conceptsin a canonicalized form.2.3 Structural search algorithmsSearch algorithms for structured texts have beenstudied extensively, and examples include XMLdatabases with XPath (Clark and DeRose, 1999)and XQuery (Boag et al, 2005), and region alge-bra (Clarke et al, 1995).
The present study fo-cuses on region algebra extended with variables(Masuda et al, 2006) because it provides an ef-ficient search algorithm for tags with cross bound-aries.
When we annotate texts with various levelsof syntactic/semantic structures, cross boundariesare inherently nonnegligible.
In fact, as describedin Section 3, our system exploits annotations ofpredicate argument structures and ontological en-tities, which include substantial cross boundaries.Region algebra is defined as a set of operatorson regions, i.e., word sequences.
Table 2 showsoperators of the extended region algebra, whereA and B denote regions, and results of operationsare also regions.
For example, ?A & B?
denotes aregion that includes both A and B.
Four contain-ment operators, >, >>, <, and <<, represent an-cestor/descendant relations in XML.
For example,?A > B?
indicates that A is an ancestor of B.
In[tag] Region covered with ?<tag>?A > B A containing BA >> B A containing B (A is not nested)A < B A contained by BA << B A contained by B (B is not nested)A - B Starting with A and ending with BA & B A and BA | B A or BTable 2: Operators of the extended region algebra[sentence] >>(([word arg1="$subject"] > exclude) &([phrase id="$subject"] > CRP))Figure 3: A query of the extended region algebraFigure 4: Matching with the query in Figure 3search algorithms for region algebra, the cost ofretrieving the first answer is constant, and that ofan exhaustive search is bounded by the lowest fre-quency of a word in a query (Clarke et al, 1995).Variables in the extended region algebra allowus to express shared structures and are necessaryin order to describe predicate argument structures.For example, Figure 3 shows a formula in the ex-tended region algebra that represents the predicateargument structure of ?CRP excludes something.
?This formula indicates that a sentence contains aregion in which the word ?exclude?
exists, thefirst argument (?arg1?)
phrase of which includesthe word ?CRP.?
A predicate argument relation isexpressed by the variable, ?$subject.?
Figure 4shows a situation in which this formula is satisfied.Three horizontal bars describe regions covered by<sentence>, <phrase>, and <word> tags,respectively.
The dotted line denotes the relationexpressed by this variable.
Given this formula as aquery, a search engine can retrieve sentences hav-ing semantic annotations that satisfy this formula.3 A Text Retrieval System for MEDLINEWhile the above resources and tools have been de-veloped independently, their collaboration opensup a new framework for the retrieval of relationalconcepts, as described below (Figure 5).Off-line processing: Prior to retrieval, a deepparser is applied to compute predicate argument1019Figure 5: Framework of semantic retrievalstructures, and a term recognizer is applied to cre-ate mappings from textual expressions into identi-fiers in ontology databases.
Semantic annotationsare stored and indexed in a structured database forthe extended region algebra.On-line processing: User input is converted intoqueries of the extended region algebra.
A searchengine retrieves sentences having semantic anno-tations that match the queries.This framework is applied to a text retrieval en-gine for MEDLINE.
MEDLINE is an exhaustivedatabase covering nearly 4,500 journals in the lifesciences and includes the bibliographies of arti-cles, about half of which have abstracts.
Researchon IE and text mining in biomedical science hasfocused mainly on MEDLINE.
In the present pa-per, we target al articles indexed in MEDLINE atthe end of 2004 (14,785,094 articles).
The follow-ing sections explain in detail off-/on-line process-ing for the text retrieval system for MEDLINE.3.1 Off-line processing: HPSG parsing andterm recognitionWe first parsed all sentences using an HPSG parser(Miyao and Tsujii, 2005) to obtain their predi-cate argument structures.
Because our target isbiomedical texts, we re-trained a parser (Hara etal., 2005) with the GENIA treebank (Tateisi etal., 2005), and also applied a bidirectional part-of-speech tagger (Tsuruoka and Tsujii, 2005) trainedwith the GENIA treebank as a preprocessor.Because parsing speed is still unrealistic forparsing the entire MEDLINE on a single ma-chine, we used two geographically separated com-puter clusters having 170 nodes (340 Xeon CPUs).These clusters are separately administered and notdedicated for use in the present study.
In order toeffectively use such an environment, GXP (Taura,2004) was used to connect these clusters and dis-tribute the load among them.
Our processes weregiven the lowest priority so that our task would notdisturb other users.
We finished parsing the entireMEDLINE in nine days (Ninomiya et al, 2006).# entries (genes) 517,773# entries (gene products) 171,711# entries (diseases) 148,602# expanded entries 4,467,855Table 3: Sizes of ontologies used for term recog-nitionEvent type Expressionsinfluence effect, affect, role, response, .
.
.regulation mediate, regulate, regulation, .
.
.activation induce, activate, activation, .
.
.Table 4: Event expression ontologyNext, we annotated technical terms, such asgenes and diseases, to create mappings to onto-logical identifiers.
A dictionary-based term recog-nition algorithm (Tsuruoka and Tsujii, 2004) wasapplied for this task.
First, an expanded termlist was created by generating name variations ofterms in GENA and the UMLS meta-thesaurus1.Table 3 shows the size of the original database andthe number of entries expanded by name varia-tions.
Terms in MEDLINE were then identifiedby the longest matching of entries in this expandedlist with words/phrases in MEDLINE.The necessity of ontologies is not limited tonominal expressions.
Various verbs are used forexpressing events.
For example, activation eventsof proteins can be expressed by ?activate,?
?en-hance,?
and other event expressions.
Although thenumbers of verbs and their event types are muchsmaller than those of technical terms, verbal ex-pressions are important for the description of rela-tional concepts.
Since ontologies of event expres-sions in this domain have not yet been constructed,we developed an ontology from scratch.
We inves-tigated 500 abstracts extracted from MEDLINE,and classified 167 frequent expressions, includingverbs and their nominalized forms, into 18 eventtypes.
Table 4 shows a part of this ontology.
Theseexpressions in MEDLINE were automatically an-notated with event types.As a result, we obtained semantically annotatedMEDLINE.
Table 5 shows the size of the orig-inal MEDLINE and semantic annotations.
Fig-ure 6 shows semantic annotations for the sentencein Figure 1, where ?-?
indicates nodes of XML,21We collected disease names by specifying a query withthe semantic type as ?Disease or Syndrome.
?2Although this example is shown in XML, this textbasecontains tags with cross boundaries because tags for predicateargument structures and technical terms may overlap.1020# papers 14,785,094# abstracts 7,291,857# sentences 70,935,630# words 1,462,626,934# successfully parsed sentences 69,243,788# predicate argument relations 1,510,233,701# phrase tags 3,094,105,383# terms (genes) 84,998,621# terms (gene products) 27,471,488# terms (diseases) 19,150,984# terms (event expressions) 51,810,047Size of the original MEDLINE 9.3 GByteSize of the semantic annotations 292 GByteSize of the index file for region algebra 954 GByteTable 5: Sizes of the original and semantically an-notated MEDLINE textbases- <sentence sentence_id="e6e525">- <phrase id="0" cat="S" head="15" lex_head="18">- <phrase id="1" cat="NP" head="4" lex_head="14">- <phrase id="2" cat="DT" head="3" lex_head="3">- <word id="3" pos="DT" cat="DT" base="a" arg1="4">- A- <phrase id="4" cat="NP" head="7" lex_head="14">- <phrase id="5" cat="AJ" head="6" lex_head="6">- <word id="6" pos="JJ" cat="AJ" base="normal" arg1="7">- normal- <phrase id="7" cat="NP" head="10" lex_head="14">- <phrase id="8" cat="NP" head="9" lex_head="9">- <word id="9" pos="NN" cat="NP" base="serum" mod="10">- serum- <phrase id="10" cat="NP" head="13" lex_head="14">- <phrase id="11" cat="NP" head="12" lex_head="12">- <entity_name id="entity-1" type="gene"gene_id="GHS003134" gene_symbol="CRP"gene_name="C-reactive protein, pentraxin-related"species="Homo sapiens"db_site="EntrezGene:1401|GDB:119071|GenAtlas:CRP">- <word id="12" pos="NN" cat="NP" base="crp" mod="13">- CRP- <phrase id="13" cat="NP" head="14" lex_head="14">- <word id="14" pos="NN" cat="NP" base="measurement">- measurement- <phrase id="15" cat="VP" head="16" lex_head="18">- <phrase id="16" cat="VP" head="17" lex_head="18">- <phrase id="17" cat="VP" head="18" lex_head="18">- <word id="18" pos="VBZ" cat="VP" base="do"arg1="1" arg2="21">- does- <phrase id="19" cat="AV" head="20" lex_head="20">- <word id="20" pos="RB" cat="AV" base="not" arg1="21">- not- <phrase id="21" cat="VP" head="22" lex_head="23">- <phrase id="22" cat="VP" head="23" lex_head="23">- <word id="23" pos="VB" cat="VP" base="exclude"arg1="1" arg2="24">- exclude...Figure 6: A semantically annotated sentencealthough the latter half of the sentence is omittedbecause of space limitations.
Sentences are an-notated with four tags,3 ?phrase,?
?word,?
?sen-tence,?
and ?entity name,?
and their attributes asgiven in Table 6.
Predicate argument structures areannotated as attributes, ?mod?
and ?argX ,?
whichpoint to the IDs of the argument phrases.
For ex-ample, in Figure 6, the <word> tag for ?exclude?has the attributes arg1="1" and arg2="24",which denote the IDs of the subject and objectphrases, respectively.3Additional tags exist for representing document struc-tures such as ?title?
(details omitted).Tag Attributesphrase id, cat, head, lex headword id, cat, pos, base, mod, argX , rel typesentence sentence identity name id, type, gene id/disease id, gene symbol,gene name, species, db siteAttribute Descriptionid unique identifiercat syntactic categoryhead head daughter?s IDlex head lexical head?s IDpos part-of-speechbase base form of the wordmod ID of modifying phraseargX ID of the X-th argument of the wordrel type event typesentence id sentence?s IDtype whether gene, gene prod, or diseasegene id ID in GENAdisease id ID in the UMLS meta-thesaurusgene symbol short form of the genegene name nomenclature of the genespecies species that have this genedb site links to external databasesTable 6: Tags (upper) and attributes (lower) forsemantic annotations3.2 On-line processingThe off-line processing described above results inmuch simpler on-line processing.
User input isconverted into queries of the extended region al-gebra, and the converted queries are entered into asearch engine for the extended region algebra.
Theimplementation of a search engine is described indetail in Masuda et al (2006).Basically, given subject x, object y, and verb v,the system creates the following query:[sentence] >>([word arg1="$subject" arg2="$object"base="v"] &([phrase id="$subject"] > x) &([phrase id="$object"] > y))Ontological identifiers are substituted for x, y,and v, if possible.
Nominal keywords, i.e., x andy, are replaced by [entity_name gene_id="n"]or [entity_name disease_id="n"], where n isthe ontological identifier of x or y.
For verbal key-words, base="v" is replaced by rel_type="r",where r is the event type of v.4 EvaluationOur system is evaluated with respect to speed andaccuracy.
Speed is indispensable for real-time in-teractive text retrieval systems, and accuracy is keyfor the motivation of semantic retrieval.
That is,our motivation for employing semantic retrieval1021Query No.
User input1 something inhibit ERK22 something trigger diabetes3 adiponectin increase something4 TNF activate IL65 dystrophin cause disease6 macrophage induce something7 something suppress MAP phosphorylation8 something enhance p53 (negative)Table 7: Queries for experiments[sentence] >>([word rel_type="activation"] &[entity_name type="gene" gene_id="GHS019685"] &[entity_name type="gene" gene_id="GHS009426"])[sentence] >>([word arg1="$subject" arg2="$object"rel_type="activation"] &([phrase id="$subject"] >[entity_name type="gene" gene_id="GHS019685"]) &([phrase cat="np" id="$object"] >[entity_name type="gene" gene_id="GHS009426"]))Figure 7: Queries of the extended region algebrafor Query 4-3 (upper: keyword search, lower: se-mantic search)was to provide a device for the accurate identifica-tion of relational concepts.
In particular, high pre-cision is desired in text retrieval from huge textsbecause users want to extract relevant information,rather than collect exhaustive information.We have two parameters to vary: whether touse predicate argument structures and whether touse ontological identifiers.
The effect of usingpredicate argument structures is evaluated by com-paring ?keyword search?
with ?semantic search.
?The former is a traditional style of IR, in whichsentences are retrieved by matching words in aquery with words in sentences.
The latter is anew feature of the present system, in which sen-tences are retrieved by matching predicate argu-ment relations in a query with those in a semanti-cally annotated textbase.
The effect of using onto-logical identifiers is assessed by changing queriesof the extended region algebra.
When we use theterm ontology, nominal keywords in queries arereplaced with ontological identifiers in GENA andthe UMLS meta-thesaurus.
When we use the eventexpression ontology, verbal keywords in queriesare replaced with event types.Table 7 is a list of queries used in the follow-ing experiments.
Words in italics indicate a classof words: ?something?
indicates that any wordcan appear, and disease indicates that any dis-ease expression can appear.
These queries wereselected by a biologist, and express typical re-lational concepts that a biologist may wish tofind.
Queries 1, 3, and 4 represent relations ofgenes/proteins, where ERK2, adiponectin, TNF,and IL6 are genes/proteins.
Queries 2 and 5 de-scribe relations concerning diseases, and Query 6is a query that is not relevant to genes or diseases.Query 7 expresses a complex relation concern-ing a specific phenomena, i.e., phosphorylation,of MAP.
Query 8 describes a relation concerninga gene, i.e., p53, while ?(negative)?
indicates thatthe target of retrieval is negative mentions.
This isexpressed by ?not?
modifying a predicate.For example, Query 4 attempts to retrieve sen-tences that mention the protein-protein interaction?TNF activates IL6.?
This is converted into queriesof the extended region algebra given in Figure 7.The upper query is for keyword search and onlyspecifies the appearances of the three words.
Notethat the keywords are translated into the ontolog-ical identifiers, ?activation,?
?GHS019685,?
and?GHS009426.?
The lower query is for semanticsearch.
The variables in ?arg1?
and ?arg2?
indi-cate that ?GHS019685?
and ?GHS009426?
are thesubject and object, respectively, of ?activation?.Table 8 summarizes the results of the experi-ments.
The postfixes of query numbers denotewhether ontological identifiers are used.
X-1 usedno ontologies, and X-2 used only the term ontol-ogy.
X-3 used both the term and event expressionontologies4.
Comparison of X-1 and X-2 clarifiesthe effect of using the term ontology.
Comparisonof X-2 and X-3 shows the effect of the event ex-pression ontology.
The results for X-3 indicatethe maximum performance of the current system.This table shows that the time required for the se-mantic search for the first answer, shown as ?time(first)?
in seconds, was reasonably short.
Thus,the present framework is acceptable for real-timetext retrieval.
The numbers of answers increasedwhen we used the ontologies, and this result indi-cates the efficacy of both ontologies for obtainingrelational concepts written in various expressions.Accuracy was measured by judgment by a bi-ologist.
At most 100 sentences were retrieved foreach query, and the results of keyword search andsemantic search were merged and shuffled.
A bi-ologist judged the shuffled sentences (1,839 sen-tences in total) without knowing whether the sen-4Query 5-1 is not tested because ?disease?
requiresthe term ontology, and Query 6-2 is not tested because?macrophage?
is not assigned an ontological identifier.1022Query Keyword search Semantic searchNo.
# ans.
time (first/all) precision n-precision # ans.
time (first/all) precision relative recall1-1 252 0.00/ 1.5 74/100 (74%) 74/100 (74%) 143 0.01/ 2.5 96/100 (96%) 51/74 (69%)1-2 348 0.00/ 1.9 61/100 (61%) 61/100 (61%) 174 0.01/ 3.1 89/100 (89%) 42/61 (69%)1-3 884 0.00/ 3.2 50/100 (50%) 50/100 (50%) 292 0.01/ 5.3 91/100 (91%) 21/50 (42%)2-1 125 0.00/ 1.8 45/100 (45%) 9/ 27 (33%) 27 0.02/ 2.9 23/ 27 (85%) 17/45 (38%)2-2 113 0.00/ 2.9 40/100 (40%) 10/ 26 (38%) 26 0.06/ 4.0 22/ 26 (85%) 19/40 (48%)2-3 6529 0.00/ 12.1 42/100 (42%) 42/100 (42%) 662 0.01/1527.4 76/100 (76%) 8/42 (19%)3-1 287 0.00/ 1.5 20/100 (20%) 4/ 30 (13%) 30 0.05/ 2.4 23/ 30 (80%) 6/20 (30%)3-2 309 0.01/ 2.1 21/100 (21%) 4/ 32 (13%) 32 0.10/ 3.5 26/ 32 (81%) 6/21 (29%)3-3 338 0.01/ 2.2 24/100 (24%) 8/ 39 (21%) 39 0.05/ 3.6 32/ 39 (82%) 8/24 (33%)4-1 4 0.26/ 1.5 0/ 4 (0%) 0/ 0 (?)
0 2.44/ 2.4 0/ 0 (?)
0/ 0 (?
)4-2 195 0.01/ 2.5 9/100 (9%) 1/ 6 (17%) 6 0.09/ 4.1 5/ 6 (83%) 2/ 9 (22%)4-3 2063 0.00/ 7.5 5/100 (5%) 5/ 94 (5%) 94 0.02/ 10.5 89/ 94 (95%) 2/ 5 (40%)5-2 287 0.08/ 6.3 73/100 (73%) 73/100 (73%) 116 0.05/ 14.7 97/100 (97%) 37/73 (51%)5-3 602 0.01/ 15.9 50/100 (50%) 50/100 (50%) 122 0.05/ 14.2 96/100 (96%) 23/50 (46%)6-1 10698 0.00/ 42.8 14/100 (14%) 14/100 (14%) 1559 0.01/3014.5 65/100 (65%) 10/14 (71%)6-3 42106 0.00/3379.5 11/100 (11%) 11/100 (11%) 2776 0.01/5100.1 61/100 (61%) 5/11 (45%)7 87 0.04/ 2.7 34/ 87 (39%) 7/ 15 (47%) 15 0.05/ 4.2 10/ 15 (67%) 10/34 (29%)8 1812 0.01/ 7.6 19/100 (19%) 17/ 84 (20%) 84 0.20/ 29.2 73/ 84 (87%) 7/19 (37%)Table 8: Number of retrieved sentences, retrieval time, and accuracytence was retrieved by keyword search or semanticsearch.
Without considering which words actuallymatched the query, a sentence is judged to be cor-rect when any part of the sentence expresses all ofthe relations described by the query.
The modalityof sentences was not distinguished, except in thecase of Query 8.
These evaluation criteria may bedisadvantageous for the semantic search becauseits ability to exactly recognize the participants ofrelational concepts is not evaluated.
Table 8 showsthe precision attained by keyword/semantic searchand n-precision, which denotes the precision ofthe keyword search, in which the same number,n, of outputs is taken as the semantic search.
Thetable also gives the relative recall of the semanticsearch, which represents the ratio of sentences thatare correctly output by the semantic search amongthose correctly output by the keyword search.
Thisdoes not necessarily represent the true recall be-cause sentences not output by keyword search areexcluded.
However, this is sufficient for the com-parison of keyword search and semantic search.The results show that the semantic search exhib-ited impressive improvements in precision.
Theprecision was over 80% for most queries and wasnearly 100% for Queries 4 and 5.
This indicatesthat predicate argument structures are effective forrepresenting relational concepts precisely, espe-cially for relations in which two entities are in-volved.
Relative recall was approximately 30?50%, except for Query 2.
In the following, wewill investigate the reasons for the residual errors.Table 9 shows the classifications of the errors ofDisregarding of noun phrase structures 45Term recognition errors 33Parsing errors 11Other reasons 8Incorrect human judgment 7Nominal expressions 41Phrasal verb expressions 26Inference required 24Coreference resolution required 19Parsing errors 16Other reasons 15Incorrect human judgment 10Table 9: Error analysis (upper: 104 false positives,lower: 151 false negatives)semantic retrieval.
The major reason for false pos-itives was that our queries ignore internal struc-tures of noun phrases.
The system therefore re-trieved noun phrases that do not directly mentiontarget entities.
For example, ?the increased mor-tality in patients with diabetes was caused by .
.
.
?does not indicate the trigger of diabetes.
Anotherreason was term recognition errors.
For exam-ple, the system falsely retrieved sentences con-taining ?p40,?
which is sometimes, but not nec-essarily used as a synonym for ?ERK2.?
Ma-chine learning-based term disambiguation will al-leviate these errors.
False negatives were causedmainly by nominal expressions such as ?the in-hibition of ERK2.?
This is because the presentsystem does not convert user input into querieson nominal expressions.
Another major reason,phrasal verb expressions such as ?lead to,?
is alsoa shortage of our current strategy of query cre-ation.
Because semantic annotations already in-1023clude linguistic structures of these expressions, thepresent system can be improved further by creat-ing queries on such expressions.5 ConclusionWe demonstrated a text retrieval system for MED-LINE that exploits pre-computed semantic anno-tations5.
Experimental results revealed that theproposed system is sufficiently efficient for real-time text retrieval and that the precision of re-trieval was remarkably high.
Analysis of resid-ual errors showed that the handling of noun phrasestructures and the improvement of term recogni-tion will increase retrieval accuracy.
Althoughthe present paper focused on MEDLINE, the NLPtools used in this system are domain/task indepen-dent.
This framework will thus be applicable toother domains such as patent documents.The present framework does not conflict withconventional IR/IE techniques, and integrationwith these techniques is expected to improve theaccuracy and usability of the proposed system.
Forexample, query expansion and relevancy feedbackcan be integrated in a straightforward way in orderto improve accuracy.
Document ranking is usefulfor the readability of retrieved results.
IE systemscan be applied off-line, in the manner of the deepparser in our system, for annotating sentences withtarget information of IE.
Such annotations will en-able us to retrieve higher-level concepts, such asrelationships among relational concepts.AcknowledgmentThis work was partially supported by Grant-in-Aidfor Scientific Research on Priority Areas ?SystemsGenomics?
(MEXT, Japan), Genome NetworkProject (NIG, Japan), and Solution-Oriented Re-search for Science and Technology (JST, Japan).ReferencesC.
Blaschke and A. Valencia.
2002.
The frame-basedmodule of the SUISEKI information extraction sys-tem.
IEEE Intelligent Systems, 17(2):14?20.S.
Boag, D. Chamberlin, M. F. Ferna?ndez, D. Florescu,J.
Robie, and J. Sime?on.
2005.
XQuery 1.0: AnXML query language.E.
Charniak and M. Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.In Proc.
ACL 2005.5A web-based demo of our system is available on-line at:http://www-tsujii.is.s.u-tokyo.ac.jp/medie/H.-W. Chun, Y. Tsuruoka, J.-D. Kim, R. Shiba, N. Na-gata, T. Hishiki, and J. Tsujii.
2006.
Extractionof gene-disease relations from MedLine using do-main dictionaries and machine learning.
In Proc.PSB 2006, pages 4?15.J.
Clark and S. DeRose.
1999.
XML Path Language(XPath) version 1.0.C.
L. A. Clarke, G. V. Cormack, and F. J. Burkowski.1995.
An algebra for structured text search and aframework for its implementation.
The ComputerJournal, 38(1):43?56.Y.
Hao, X. Zhu, M. Huang, and M. Li.
2005.
Dis-covering patterns to extract protein-protein interac-tions from the literature: Part II.
Bioinformatics,21(15):3294?3300.T.
Hara, Y. Miyao, and J. Tsujii.
2005.
Adaptinga probabilistic disambiguation model of an HPSGparser to a new domain.
In Proc.
IJCNLP 2005.IBM, 2005.
Unstructed Information Management Ar-chitecture (UIMA) SDK User?s Guide and Refer-ence.A.
Koike and T. Takagi.
2004.
Gene/protein/familyname recognition in biomedical literature.
In Proc.Biolink 2004, pages 9?16.D.
A. Lindberg, B. L. Humphreys, and A. T. Mc-Cray.
1993.
The Unified Medical Language Sys-tem.
Methods in Inf.
Med., 32(4):281?291.K.
Masuda, T. Ninomiya, Y. Miyao, T. Ohta, andJ.
Tsujii.
2006.
Nested region algebra extended withvariables.
In Preparation.Y.
Miyao and J. Tsujii.
2005.
Probabilistic disam-biguation models for wide-coverage HPSG parsing.In Proc.
43rd ACL, pages 83?90.National Library of Medicine.
2005.
Fact Sheet MED-LINE.
Available at http://www.nlm.nih.gov/pubs/factsheets/medline.html.T.
Ninomiya, Y. Tsuruoka, Y. Miyao, K. Taura, andJ.
Tsujii.
2006.
Fast and scalable HPSG parsing.Traitement automatique des langues (TAL), 46(2).Y.
Tateisi, A. Yakushiji, T. Ohta, and J. Tsujii.
2005.Syntax annotation for the GENIA corpus.
In Proc.IJCNLP 2005, Companion volume, pages 222?227.K.
Taura.
2004.
GXP : An interactive shell for the gridenvironment.
In Proc.
IWIA2004, pages 59?67.TEI Consortium, 2004.
Text Encoding Initiative.Y.
Tsuruoka and J. Tsujii.
2004.
Improving the per-formance of dictionary-based approaches in proteinname recognition.
Journal of Biomedical Informat-ics, 37(6):461?470.Y.
Tsuruoka and J. Tsujii.
2005.
Bidirectional infer-ence with the easiest-first strategy for tagging se-quence data.
In Proc.
HLT/EMNLP 2005, pages467?474.1024
