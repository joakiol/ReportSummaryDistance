Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1259?1267,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsIncorporating Extra-linguistic Information into Reference Resolution inCollaborative Task DialogueRyu Iida Shumpei Kobayashi Takenobu TokunagaTokyo Institute of Technology2-12-1, O?okayama, Meguro, Tokyo 152-8552, Japan{ryu-i,skobayashi,take}@cl.cs.titech.ac.jpAbstractThis paper proposes an approach to ref-erence resolution in situated dialoguesby exploiting extra-linguistic information.Recently, investigations of referential be-haviours involved in situations in the realworld have received increasing attentionby researchers (Di Eugenio et al, 2000;Byron, 2005; van Deemter, 2007; Spangeret al, 2009).
In order to create an accuratereference resolution model, we need tohandle extra-linguistic information as wellas textual information examined by exist-ing approaches (Soon et al, 2001; Ng andCardie, 2002, etc.).
In this paper, we incor-porate extra-linguistic information into anexisting corpus-based reference resolutionmodel, and investigate its effects on refer-ence resolution problems within a corpusof Japanese dialogues.
The results demon-strate that our proposed model achieves anaccuracy of 79.0% for this task.1 IntroductionThe task of identifying reference relations includ-ing anaphora and coreferences within texts has re-ceived a great deal of attention in natural languageprocessing, from both theoretical and empiricalperspectives.
Recently, research trends for refer-ence resolution have drastically shifted from hand-crafted rule-based approaches to corpus-based ap-proaches, due predominately to the growing suc-cess of machine learning algorithms (such as Sup-port Vector Machines (Vapnik, 1998)); many re-searchers have examined ways for introducing var-ious linguistic clues into machine learning-basedmodels (Ge et al, 1998; Soon et al, 2001; Ngand Cardie, 2002; Yang et al, 2003; Iida et al,2005; Yang et al, 2005; Yang et al, 2008; Poonand Domingos, 2008, etc.).
Research has contin-ued to progress each year, focusing on tackling theproblem as it is represented in the annotated datasets provided by the Message Understanding Con-ference (MUC)1 and the Automatic Content Ex-traction (ACE)2.
In these data sets, coreference re-lations are defined as a limited version of a typ-ical coreference; this generally means that onlythe relations where expressions refer to the samenamed entities are addressed, because it makesthe coreference resolution task more informationextraction-oriented.
In other words, the corefer-ence task as defined by MUC and ACE is gearedtoward only identifying coreference relations an-chored to an entity within the text.In contrast to this research trend, investigationsof referential behaviour in real world situationshave continued to gain interest in the languagegeneration community (Di Eugenio et al, 2000;Byron, 2005; van Deemter, 2007; Foster et al,2008; Spanger et al, 2009), aiming at applica-tions such as human-robot interaction.
Spangeret al (2009) for example constructed a corpus byrecording dialogues of two participants collabo-ratively solving the Tangram puzzle.
The corpusincludes extra-lingustic information synchronisedwith utterances (such as operations on the puzzlepieces).
They analysed the relations between re-ferring expressions and the extra-linguistic infor-mation, and reported that the pronominal usage ofreferring expressions is predominant.
They alsorevealed that the multi-modal perspective of refer-ence should be dealt with for more realistic refer-ence understanding.
Thus, a challenging issue inreference resolution is to create a model bridging areferring expression in the text and its object in thereal world.
As a first step, this paper focuses onincorporating extra-linguistic information into anexisting corpus-based approach, taking Spanger etal.
(2009)?s REX-J corpus3 as the data set.
In our1www-nlpir.nist.gov/related projects/muc/2www.itl.nist.gov/iad/mig//tests/ace/3The corpus was named REX-J after their publication of1259problem setting, a referent needs to be identifiedby taking into account extra-linguistic informa-tion, such as the spatiala relations of puzzle piecesand the participants?
operations on them, as wellas any preceding utterances in the dialogue.
Weparticularly focus on the participants?
operation ofpieces and so introduce it as several features in amachine learning-based approach.This paper is organised as follows.
We first ex-plain the corpus of collaborative work dialoguesin Section 2, and then present our approach foridentifying a referent given a referring expres-sion in situated dialogues in Section 3.
Section 4shows the results of our empirical evaluation.In Section 5 we compare our work with exist-ing work on reference resolution, and then con-clude this paper and discuss future directions inSection 6.2 REX-J corpus: a corpus ofcollaborative work dialogueFor investigating dialogue from the multi-modalperspective, researchers have developed data setsincluding extra-linguistic information, bridgingobjects in the world and their referring expres-sions.
The COCONUT corpus (Di Eugenio et al,2000) is collected from keyboard-dialogues be-tween two participants, who are collaborating ona simple 2D design task.
The setting tends to en-courage simple types of expressions by the partic-ipants.
The COCONUT corpus is also limited toannotations with symbolic information about ob-jects, such as object attributes and location in dis-crete coordinates.
Thus, in addition to the artifi-cial nature of interaction, such as using keyboardinput, this corpus only records restricted types ofdata.On the other hand, though the annotated corpusby Spanger et al (2009) focuses on a limited do-main (i.e.
collaborative work dialogues for solvingthe Tangram puzzle using a puzzle simulator onthe computer), the required operations to solve thepuzzle, and the situation as it is updated by a seriesof operations on the pieces are both recorded bythe simulator.
The relationship between a referringexpression in a dialogue and its referent on a com-puter display is also annotated.
For this reason,we selected the REX-J corpus for use in our em-pirical evaluations on reference resolution.
Beforeexplaining the details of our evaluation, we sketchSpanger et al (2009), which describes its construction.goal shape areaworking areaFigure 1: Screenshot of the Tangram simulatorout the REX-J corpus and some of its prominentstatistics.2.1 The REX-J corpusIn the process of building the REX-J corpus,Spanger et al (2009) recruited 12 Japanese grad-uate students (4 females and 8 males), and splitthem into 6 pairs.
All pairs knew each other previ-ously and were of the same sex and approximatelythe same age.
Each pair was instructed to solvethe Tangram puzzle.
The goal of the puzzle is toconstruct a given shape by arranging seven piecesof simple figures as shown in Figure 1.
The pre-cise position of every piece and every action thatthe participants make are recorded by the Tangramsimulator in which the pieces on the computer dis-play can be moved, rotated and flipped with sim-ple mouse operations.
The piece position and themouse actions were recorded at intervals of 10msec.
The simulator displays two areas: a goalshape area (the left side of Figure 1) and a work-ing area (the right side of Figure 1) where piecesare shown and can be manipulated.A different role was assigned to each participantof a pair: a solver and an operator.
Given a cer-tain goal shape, the solver thinks of the necessaryarrangement of the pieces and gives instructionsto the operator for how to move them.
The op-erator manipulates the pieces with the mouse ac-cording to the solver?s instructions.
During thisinteraction, frequent uttering of referring expres-sions are needed to distinguish the pieces of thepuzzle.
This collaboration is achieved by placinga set of participants side by side, each with theirown display showing the work area, and a shieldscreen set between them to prevent the operatorfrom seeing the goal shape, which is visible onlyon the solver?s screen, and to further restrict their1260interaction to only speech.2.2 StatisticsTable 1 lists the syntactic and semantic features ofthe referring expressions in the corpus with theirrespective frequencies.
Note that multiple fea-tures can be used in a single expression.
This listdemonstrates that ?pronoun?
and ?shape?
featuresare frequently uttered in the corpus.
This is be-cause pronominal expressions are often used forpointing to a piece on a computer display.
Expres-sions representing ?shape?
frequently appear in di-alogues even though they may be relatively redun-dant in the current utterance.
From these statistics,capturing these two features can be judged as cru-cial as a first step toward accurate reference reso-lution.3 Reference Resolution usingExtra-linguistic InformationBefore explaining the treatment of extra-linguisticinformation, let us first describe the task defini-tion, taking the REX-J corpus as target data.
Inthe task of reference resolution, the reference res-olution model has to identify a referent (i.e.
apiece on a computer display)4.
In comparison toconventional problem settings for anaphora reso-lution, where the model searches for an antecedentout of a set of candidate antecedents from pre-ceding utterances, expressions corresponding toantecedents are sometimes omitted because refer-ring expressions are used as deixis (i.e.
physicallypointing to a piece on a computer display); theymay also refer to a piece that has just been manip-ulated by an operator due to the temporal saliencein a series of operations.
For these reasons, eventhough the model checks all candidates in the pre-ceding utterances, it may not find the antecedentof a given referring expression.
However, we doknow that each referent exists as a piece on thedisplay.
We can therefore establish that when a re-ferring expression is uttered by either a solver oran operator, the model can choose one of sevenpieces as a referent of the current referring expres-sion.3.1 Ranking model to identify referentsTo investigate the impact of extra-linguistic infor-mation on reference resolution, we conduct an em-4In the current task on reference resolution, we deal onlywith referring expressions referring to a single piece to min-imise complexity.pirical evaluation in which a reference resolutionmodel chooses a referent (i.e.
a piece) for a givenreferring expression from the set of pieces illus-trated on the computer display.As a basis for our reference resolution model,we adopt an existing model for reference res-olution.
Recently, machine learning-based ap-proaches to reference resolution (Soon et al, 2001;Ng and Cardie, 2002, etc.)
have been developed,particularly focussing on identifying anaphoric re-lations in texts, and have achieved better perfor-mance than hand-crafted rule-based approaches.These models for reference resolution take into ac-count linguistic factors, such as relative salience ofcandidate antecedents, which have been modeledin Centering Theory (Grosz et al, 1995) by rank-ing candidate antecedents appearing in the preced-ing discourse (Iida et al, 2003; Yang et al, 2003;Denis and Baldridge, 2008).
In order to take ad-vantage of existing models, we adopt the ranking-based approach as a basis for our reference resolu-tion model.In conventional ranking-based models, Yang etal.
(2003) and Iida et al (2003) decompose theranking process into a set of pairwise compar-isons of two candidate antecedents.
However, re-cent work by Denis and Baldridge (2008) reportsthat appropriately constructing a model for rank-ing all candidates yields improved performanceover those utilising pairwise ranking.Similarly we adopt a ranking-based model, inwhich all candidate antecedents compete withone another to decide the most likely candi-date antecedent.
Although the work by Denisand Baldridge (2008) uses Maximum Entropy tocreate their ranking-based model, we adopt theRanking SVM algorithm (Joachims, 2002), whichlearns a weight vector to rank candidates for agiven partial ranking of each referent.
Each train-ing instance is created from the set of all referentsfor each referring expression.
To define the par-tial ranking of referents, we simply rank referentsreferred to by a given referring expression as firstplace and other referents as second place.3.2 Use of extra-linguistic informationRecent work on multi-modal reference resolutionor referring expression generation (Prasov andChai, 2008; Foster et al, 2008; Carletta et al,2010) indicates that extra-linguistic information,such as eye-gaze and manipulation of objects, is1261Table 1: Referring expressions in REX-J corpusfeature tokens exampledemonstratives 742adjective 194 ?ano migigawa no sankakkei (that triangle at the right side)?pronoun 548 ?kore (this)?attribute 795size 223 ?tittyai sankakkei (the small triangle)?shape 566 ?o?kii sankakkei (the large triangle)?direction 6 ?ano sita muiteru dekai sankakkei (that large triangle facing to the bottom)?spatial relations 147projective 143 ?hidari no okkii sankakkei (the small triangle on the left)?topological 2 ?o?kii hanareteiru yatu (the big distant one)?overlapping 2 ?
sono sita ni aru sankakkei (the triangle underneath it)?action-mentioning 85 ?migi ue ni doketa sankakkei (the triangle you put away to the top right)?one of essential clues for distinguishing deicticreference from endophoric reference.For instance, Prasov and Chai (2008) demon-strated that integrating eye-gaze information (es-pecially, relative fixation intensity, the amount oftime spent fixating a candidate object) into theconventional dialogue history-based model im-proved the performance of reference resolution.Foster et al (2008) investigated the relationship ofreferring expressions and the manupluation of ob-jects on a collaborative construction task, whichis similar to our Tangram task5.
They reportedabout 36% of the initial mentioned referring ex-pressions in their corpus were involved with par-ticipant?s operations of objects, such as mouse ma-nipulation.From these background, in addition to the in-formation about the history of the preceding dis-course, which has been used in previous machinelearning-based approaches, we integrate extra-linguistic information into the reference resolutionmodel shown in Section 3.1.
More precisely, weintroduce the following extra-linguistic informa-tion: the information with regards to the historyof a piece?s movement and the mouse cursor po-sitions, and the information of the piece currentlymanipulated by an operator.
We next elaborate onthese three kinds of features.
All the features aresummarised in Table 2.3.2.1 Discourse history featuresFirst, ?type of?
features are acquired from the ex-pressions of a given referring expression and itsantecedent in the preceding discourse if the an-5Note that the task defined in Foster et al (2008) makes nodistinction between two roles; a operator and a solver.
Thus,two partipants both can mamipulate pieces on a computer dis-play, but need to jointly construct to create a predefined goalshape.tecedent explicitly appears.
These features havebeen examined by approaches to anaphora orcoreference resolution (Soon et al, 2001; Ng andCardie, 2002, etc.)
to capture the salience of a can-didate antecedent.
To capture the textual aspectof dialogues for solving Tangram puzzle, we ex-ploit the features such as a binary value indicatingwhether a referring expression has no antecedentin the preceding discourse and case markers fol-lowing a candidate antecedent.3.2.2 Action history featuresThe history of the operations may yield importantclues that indicate the salience in terms of the tem-poral recency of a piece within a series of opera-tions.
To introduce this aspect as a set of features,we can use, for example, the time distance of acandidate referent (i.e.
a piece in the Tangram puz-zle) since the mouse cursor was moved over it.
Wecall this type of feature the action history feature.3.2.3 Current operation featuresThe recency of operations of a piece is also an im-portant factor on reference resolution because it isdirectly associated with the focus of attention interms of the cognition in a series of operations.For example, since a piece which was most re-cently manipulated is most salient from cognitiveperspectives, it might be expected that the piecetends to be referred to by unmarked referring ex-pressions such as pronouns.
To incorporate suchclues into the reference resolution model, we canuse, for example, the time distance of a candidatereferent since it was last manipulated in the pre-ceding utterances.
We call this type of feature thecurrent operation feature.1262Table 2: Feature set(a) Discourse history featuresDH1 : yes, no a binary value indicating that P is referred to by the most recent referring expression.DH2 : yes, no a binary value indicating that the time distance to the last mention of P is less than or equal to 10 sec.DH3 : yes, no a binary value indicating that the time distance to the last mention of P is more than 10 sec and lessthan or equal to 20 sec.DH4 : yes, no a binary value indicating that the time distance to the last mention of P is more than 20 sec.DH5 : yes, no a binary value indicating that P has never been referred to by any mentions in the preceding utterances.DH6 : yes, no, N/A a binary value indicating that the attributes of P are compatible with the attributes of R.DH7 : yes, no a binary value indicating that R is followed by the case marker ?o (accusative)?.DH8 : yes, no a binary value indicating that R is followed by the case marker ?ni (dative)?.DH9 : yes, no a binary value indicating that R is a pronoun and the most recent reference to P is not a pronoun.DH10 : yes, no a binary value indicating that R is not a pronoun and was most recently referred to by a pronoun.
(b) Action history featuresAH1 : yes, no a binary value indicating that the mouse cursor was over P at the beginning of uttering R.AH2 : yes, no a binary value indicating that P is the last piece that the mouse cursor was over when feature AH1 is?no?.AH3 : yes, no a binary value indicating that the time distance is less than or equal to 10 sec after the mouse cursorwas over P.AH4 : yes, no a binary value indicating that the time distance is more than 10 sec and less than or equal to 20 secafter the mouse cursor was over P.AH5 : yes, no a binary value indicating that the time distance is more than 20 sec after the mouse cursor was over P.AH6 : yes, no a binary value indicating that the mouse cursor was never over P in the preceding utterances.
(c) Current operation featuresCO1 : yes, no a binary value indicating that P is being manipulated at the beginning of uttering R.CO2 : yes, no a binary value indicating that P is the most recently manipulated piece when feature CO1 is ?no?.CO3 : yes, no a binary value indicating that the time distance is less than or equal to 10 sec after P was most recentlymanipulated.CO4 : yes, no a binary value indicating that the time distance is more than 10 sec and less than or equal to 20 secafter P was most recently manipulated.CO5 : yes, no a binary value indicating that the time distance is more than 20 sec after P was most recently manipu-lated.CO6 : yes, no a binary value indicating that P has never been manipulated.P stands for a piece of the Tangram puzzle (i.e.
a candidate referent of a referring expression) and R stands for the targetreferring expression.4 Empirical EvaluationIn order to investigate the effect of the extra-linguistic information introduced in this paper, weconduct an empirical evaluation using the REX-Jcorpus.4.1 ModelsAs we see in Section 2.2, the feature testingwhether a referring expression is a pronoun ornot is crucial because it is directly related to the?deictic?
usage of referring expressions, whereasother expressions tend to refer to an expression ap-pearing in the preceding utterances.
As describedin Denis and Baldridge (2008), when the size oftraining instances is relatively small, the modelsinduced by learning algorithms (e.g.
SVM) shouldbe separately created with regards to distinct fea-tures.
Therefore, focusing on the difference ofthe pronominal usage of referring expressions, weseparately create the reference resolution models;one is for identifying a referent of a given pro-noun, and the other is for all other expressions.We henceforth call the former model the pronounmodel and the latter one the non-pronoun modelrespectively.
At the training phase, we use onlytraining instances whose referring expressions arepronouns for creating the pronoun model, andall other training instances are used for the non-pronoun model.
The model using one of thesemodels depending on the referring expression tobe solved is called the separate model.To verify Denis and Baldridge (2008)?s premisementioned above, we also create a model using alltraining instances without dividing pronouns andother.
This model is called the combined modelhereafter.4.2 Experimental settingWe used 40 dialogues in the REX-J corpus6, con-taining 2,048 referring expressions.
To facilitatethe experiments, we conduct 10-fold crossvalida-tion using 2,035 referring expressions, each ofwhich refers to a single piece in a computer dis-6Spanger et al (2009)?s original corpus contains only 24dialogues.
In addition to this, we obtained anothor 16 dia-logues by favour of the authors.1263Table 3: Results on reference resolution: accuracymodel discourse history +action history* +current operation +action history,(baseline) +current operation*separated model (a+b) 0.664 (1352/2035) 0.790 (1608/2035) 0.685 (1394/2035) 0.780 (1587/2035)a) pronoun model 0.648 (660/1018) 0.886 (902/1018) 0.692 (704/1018) 0.875 (891/1018)b) non-pronoun model 0.680 (692/1017) 0.694 (706/1017) 0.678 (690/1017) 0.684 (696/1017)combined model 0.664 (1352/2035) 0.749 (1524/2035) 0.650 (1322/2035) 0.743 (1513/2035)?*?
means the extra-lingustic features (or the combinations of them) significantly contribute to improving performance.
For thesignificant tests, we used McNemar test with Bonferroni?s correction for multiple comparisons, i.e.
?/K = 0.05/4 = 0.01.play7.As a baseline model, we adopted a model onlyusing the discourse history features.
We utilisedSVMrank8 as an implementation of the RankingSVM algorithm, in which the parameter c was setas 1.0 and the remaining parameters were set totheir defaults.4.3 ResultsThe results of each model are shown in Table 3.First of all, by comparing the models with andwithout extra-linguistic information (i.e.
themodel using all features shown in Table 2 andthe baseline model), we can see the effectivenessof extra-linguistic information.
The results typi-cally show that the former achieved better perfor-mance than the latter.
In particular, it indicates thatexploiting the action history features are signifi-cantly useful for reference resolution in this dataset.Second, we can also see the impact of extra-linguistic information (especially, the action his-tory features) with regards to the pronoun andnon-pronoun models.
In the former case, themodel with extra-linguistic information improvedby about 22% compared with the baseline model.On the other hand, in the latter case, the accuracyimproved by only 7% over the baseline model.The difference may be caused by the fact that pro-nouns are more sensitive to the usage of the ac-tion history features because pronouns are oftenuttered as deixis (i.e.
a pronoun tends to directlyrefer to a piece shown in a computer display).The results also show that the model usingthe discourse history and action history featuresachieved better performance than the model usingall the features.
This may be due to the duplicateddefinitions between the action history and current7The remaining 13 instances referred to either more thanone piece or a class of pieces, thus were excluded in this ex-periment.8www.cs.cornell.edu/people/tj/svm light/svm rank.htmlTable 4: Weights of the features in each modelpronoun model non-pronoun modelrank feature weight feature weight1 AH1 0.6371 DH6 0.70602 AH3 0.2721 DH2 0.22713 DH1 0.2239 AH3 0.20354 DH2 0.2191 AH1 0.18395 CO1 0.1911 DH1 0.15736 DH9 0.1055 DH7 0.06697 AH2 0.0988 CO5 0.04338 CO3 0.0852 CO3 0.03939 DH6 0.0314 CO1 0.032410 CO2 0.0249 DH3 0.017711 DH10 0 AH4 0.007912 DH7 -0.0011 AH2 0.006913 DH3 -0.0088 CO4 0.005914 CO6 -0.0228 DH10 0.005915 CO4 -0.0308 DH9 016 CO5 -0.0317 CO2 -0.016717 DH8 -0.0371 DH8 -0.072818 AH6 -0.0600 CO6 -0.088519 AH4 -0.0761 DH4 -0.092420 DH5 -0.0910 AH5 -0.104221 DH4 -0.1193 AH6 -0.107222 AH5 -0.1361 DH5 -0.1524operation features.
As we can see in the featuredefinitions of CO1 and AH1, some current opera-tion features partially overlap with the action his-tory features, which is effectively used in the rank-ing process.
However, the other current operationfeatures may have bad effects for ranking refer-ents due to their ill-formed definitions.
To shedlight on this problem, we need additional investi-gation of the usage of features, and to refine theirdefinitions.Finally, the results show that the performanceof the separated model is significantly better thanthat of the combined model9, which indicates thatseparately creating models to specialise in distinctfactors (i.e.
whether a referring expression is apronoun or not) is important as suggested by Denisand Baldridge (2008).We next investigated the significance of each9For the significant tests, we used McNemar test (?
=0.05).1264Table 5: Frequencies of REs relating to on-mousepronouns others total# all REs 548 693 1,241# on-mouse 452 155 607(82.5%) (22.4%) (48.9%)?# all REs?
stands for the frequency of referring expressionsuttered in the corpus and ?# on-mouse?
is the frequency of re-ferring expressions in the situation when a referring expres-sion is uttered and a mouse cursor is over the piece referredto by the expression.feature of the pronoun and non-pronoun models.We calculate the weight of feature f shown inTable 2 according to the following formula.weight(f) =?x?SV swxzx(f) (1)where SVs is a set of the support vectors in a rankerinduced by SVMrank, wx is the weight of the sup-port vector x, zx(f) is the function that returns 1if f occurs in x, respectively.The feature weights are shown in Table 4.
Thisdemonstrates that in the pronoun model the ac-tion history features have the highest weight, whilewith the non-pronoun model these features are lesssignificant.
As we can see in Table 5, pronounsare strongly related to the situation where a mousecursor is over a piece, directly causing the weightsof the features associated with the ?on-mouse?
sit-uation to become higher than other features.On the other hand, in the non-pronoun model,the discourse history features, such as DH6 andDH2, are the most significant, indicating that thecompatibility of the attributes of a piece and a re-ferring expression is more crucial than other ac-tion history and current operation features.
This iscompatible with the previous research concerningtextual reference resolution (Mitkov, 2002).Table 4 shows that feature AH3 (aiming at cap-turing the recency in terms of a series of oper-ations) is also significant.
It empirically provesthat the recent operation is strongly related to thesalience of reference as a kind of ?focus?
by hu-mans.5 Related WorkThere have been increasing concerns about ref-erence resolution in dialogue.
Byron and Allen(1998) and Eckert and Strube (2000) reportedabout 50% of pronouns had no antecedent inTRAINS93 and Switchboard corpora respectively.Strube and Mu?ller (2003) attempted to resolvepronominal anaphora in the Switchboard corpusby porting a corpus-based anaphora resolutionmodel focusing on written texts (e.g.
Soon et al(2001) and Ng and Cardie (2002)).
They usedspecialised features for spoken dialogues as wellas conventional features.
They reported relativelyworse results than with written texts.
The reasonis that the features in their work capture only in-formation derived from transcripts of dialogues,while it is also essential to bridge objects and con-cepts in the real (or virtual) world and their expres-sions (especially pronouns) for recognising refer-ential relations intrinsically.To improve performance on reference resolu-tion in dialogue, researchers have focused onanaphoricity determination, which is the task ofjudging whether an expression explicitly has anantecedent in the text (i.e.
in the preceding ut-terances) (Mu?ller, 2006; Mu?ller, 2007).
Theirwork presented implementations of pronominalreference resolution in transcribed, multi-party di-alogues.
Mu?ller (2006) focused on the determina-tion of non-referential it, categorising instances ofit in the ICSI Meeting Corpus (Janin et al, 2003)into six classes in terms of their grammatical cat-egories.
They also took into account each charac-teristic of these types by using a refined feature set.In the work by Mu?ller (2007), they conducted anempirical evaluation including antecedent identifi-cation as well as anaphoricity determination.
Theyused the relative frequencies of linguistic patternsas clues to introduce specific patterns for non-referentials.
They reported that their performancefor detecting non-referentials was relatively high(80.0% in precision and 60.9% in recall), whilethe overall performance was still low (18.2% inprecision and 19.1% in recall).
These results indi-cate the need for advancing research in referenceresolution in dialogue.In contrast to the above mentioned research, ourtask includes the treatment of entity disambigua-tion (i.e.
selecting a referent out of a set of pieceson a computer display) as well as conventionalanaphora resolution.
Although our task setting islimited to the problem of solving the Tangram puz-zle, we believe it is a good starting point for incor-porating real (or virtual) world entities into coven-tional anaphora resolution.12656 ConclusionThis paper presented the task of reference reso-lution bridging pieces in the real world and theirreferents in dialogue.
We presented an imple-mentation of a reference resolution model ex-ploiting extra-linguistic information, such as ac-tion history and current operation features, to cap-ture the salience of operations by a participantand the arrangement of the pieces.
Through ourempirical evaluation, we demonstrated that theextra-linguistic information introduced in this pa-per contributed to improving performance.
Wealso analysed the effect of each feature, showingthat while action history features were useful forpronominal reference, discourse history featuresmade sense for the other references.In order to enhance this kind of reference res-olution, there are several possible future direc-tions.
First, in the current problem setting, weexclude zero-anaphora (i.e.
omitted expressionsrefer to either an expression in the previous utter-ances or an object on a display deictically).
How-ever, zero-anaphora is essential for precise mod-eling and recognition of reference because it isalso directly related with the recency of referents,either textually or situationally.
Second, repre-senting distractors in a reference resolution modelis also a key.
Although, this paper presents animplementation of a reference model consideringonly the relationship between a referring expres-sion and its candidate referents.
However, theremight be cases when the occurrence of expressionsor manipulated pieces intervening between a refer-ring expression and its referent need to be takeninto account.
Finally, more investigation is neededfor considering other extra-linguistic information,such as eye-gaze, for exploring what kinds of in-formation is critical to recognising reference in di-alogue.ReferencesD.
K. Byron and J. F. Allen.
1998.
Resolving demon-strative pronouns in the trains93 corpus.
In Proceed-ings of the 2nd Colloquium on Discourse Anaphoraand Anaphor Resolution (DAARC2), pages 68?81.D.
K. Byron.
2005.
Utilizing visual attention forcross-model coreference interpretation.
In CON-TEXT 2005, pages 83?96.J.
Carletta, R. L. Hill, C. Nicol, T. Taylor, J. P.de Ruiter, and E. G. Bard.
2010.
Eyetrackingfor two-person tasks with manipulation of a virtualworld.
Behavior Research Methods, 42:254?265.P.
Denis and J. Baldridge.
2008.
Specialized modelsand ranking for coreference resolution.
In Proceed-ings of the 2008 Conference on Empirical Methodsin Natural Language Processing, pages 660?669.B.
P. W. Di Eugenio, R. H. Thomason, and J. D. Moore.2000.
The agreement process: An empirical investi-gation of human-human computer-mediated collab-orative dialogues.
International Journal of Human-Computer Studies, 53(6):1017?1076.M.
Eckert and M. Strube.
2000.
Dialogue acts, syn-chronising units and anaphora resolution.
Journalof Semantics, 17(1):51?89.M.
E. Foster, E. G. Bard, M. Guhe, R. L. Hill, J. Ober-lander, and A. Knoll.
2008.
The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue.
In Proceedings of the3rd ACM/IEEE international conference on Humanrobot interaction (HRI ?08), pages 295?302.N.
Ge, J. Hale, and E. Charniak.
1998.
A statistical ap-proach to anaphora resolution.
In Proceedings of the6th Workshop on Very Large Corpora, pages 161?170.B.
J. Grosz, A. K. Joshi, and S. Weinstein.
1995.Centering: A framework for modeling the local co-herence of discourse.
Computational Linguistics,21(2):203?226.R.
Iida, K. Inui, H. Takamura, and Y. Matsumoto.2003.
Incorporating contextual cues in trainablemodels for coreference resolution.
In Proceedingsof the 10th EACL Workshop on The ComputationalTreatment of Anaphora, pages 23?30.R.
Iida, K. Inui, and Y. Matsumoto.
2005.
Anaphoraresolution by antecedent identification followed byanaphoricity determination.
ACM Transactions onAsian Language Information Processing (TALIP),4(4):417?434.A.
Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart,N.
Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stol-cke, and C. Wooters.
2003.
The ICSI meeting cor-pus.
In Proceedings of the IEEE International Con-ference on Acoustics, Speech and Signal Processing,pages 364?367.T.
Joachims.
2002.
Optimizing search engines usingclickthrough data.
In Proceedings of the ACM Con-ference on Knowledge Discovery and Data Mining(KDD), pages 133?142.R.
Mitkov.
2002.
Anaphora Resolution.
Studies inLanguage and Linguistics.
Pearson Education.C.
Mu?ller.
2006.
Automatic detection of nonrefer-ential It in spoken multi-party dialog.
In Proceed-ings of the 11th Conference of the European Chap-ter of the Association for Computational Linguistics,pages 49?56.1266C.
Mu?ller.
2007.
Resolving It, This, and That in un-restricted multi-party dialog.
In Proceedings of the45th Annual Meeting of the Association of Compu-tational Linguistics, pages 816?823.V.
Ng and C. Cardie.
2002.
Improving machine learn-ing approaches to coreference resolution.
In Pro-ceedings of the 40th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages104?111.H.
Poon and P. Domingos.
2008.
Joint unsupervisedcoreference resolution with Markov Logic.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing, pages 650?659.Z.
Prasov and J. Y. Chai.
2008.
What?s in a gaze?
:the role of eye-gaze in reference resolution in mul-timodal conversational interfaces.
In Proceedings ofthe 13th international conference on Intelligent userinterfaces (IUI ?08), pages 20?29.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
Amachine learning approach to coreference resolu-tion of noun phrases.
Computational Linguistics,27(4):521?544.P.
Spanger, Y. Masaaki, R. Iida, and T. Takenobu.2009.
Using extra linguistic information for gen-erating demonstrative pronouns in a situated collab-oration task.
In Proceedings of Workshop on Pro-duction of Referring Expressions: Bridging the gapbetween computational and empirical approaches toreference.M.
Strube and C. Mu?ller.
2003.
A machine learningapproach to pronoun resolution in spoken dialogue.In Proceedings of the 41st Annual Meeting of the As-sociation for Computational Linguistics, pages 168?175.K.
van Deemter.
2007.
TUNA: Towards a unified al-gorithm for the generation of referring expressions.Technical report, Aberdeen University.V.
N. Vapnik.
1998.
Statistical Learning Theory.Adaptive and Learning Systems for Signal Process-ing Communications, and control.
John Wiley &Sons.X.
Yang, G. Zhou, J. Su, and C. L. Tan.
2003.Coreference resolution using competition learningapproach.
In Proceedings of the 41st Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 176?183.X.
Yang, J. Su, and C. L. Tan.
2005.
Improving pro-noun resolution using statistics-based semantic com-patibility information.
In Proceeding of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 165?172.X.
Yang, J. Su, J. Lang, C. L. Tan, T. Liu, and S. Li.2008.
An entity-mention model for coreferenceresolution with inductive logic programming.
InProceedings of Annual Meeting of the Associationfor Computational Linguistics (ACL): Human Lan-guage Technologies (HLT), pages 843?851.1267
