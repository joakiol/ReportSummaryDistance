Developments in Affect Detection in E-dramaLi Zhang, John A. Barnden, Robert J. Hendley, and Alan M. WallingtonSchool of Computer ScienceUniversity of Birmingham, UKl.zhang@cs.bham.ac.ukAbstractWe report work1 in progress on addingaffect-detection to an existing programfor virtual dramatic improvisation, moni-tored by a human director.
To partiallyautomate the directors?
functions, wehave partially implemented the detectionof emotions, etc.
in users?
text input, bymeans of pattern-matching, robust pars-ing and some semantic analysis.
Thework also involves basic research intohow affect is conveyed by metaphor.1 IntroductionImprovised drama and role-play are widely usedin education, counselling and conflict resolution.Researchers have explored frameworks for e-drama, in which virtual characters (avatars) in-teract under the control of human actors.
Thespringboard for our research is an existing sys-tem (edrama) created by Hi8us Midlands Ltd,used in schools for creative writing and teachingin various subjects.
The experience suggests thate-drama helps students lose their usual inhibi-tions, because of anonymity etc.
In edrama,characters are completely human-controlled,their speeches textual in speech bubbles, andtheir visual forms cartoon figures.
The actors(users) are given a loose scenario within which toimprovise, but are at liberty to be creative.
Thereis also a human director, who constantly moni-tors the unfolding drama and can intervene by,1 This work is supported by grant RES-328-25-0009 fromthe ESRC under the ESRC/EPSRC/DTI ?PACCIT?
pro-gramme.
We are grateful to Hi8us Midlands Ltd, MaverickTelevision Ltd, BT, and our colleagues W.H.
Edmondson,S.R.
Glasbey, M.G.
Lee and Z. Wen.
The work is also par-tially supported by EPSRC grant EP/C538943/1.for example, sending messages to actors, or byintroducing and controlling a minor ?bit-part?character to interact with the main characters.But this places a heavy burden on directors, es-pecially if they are, for example, teachers andunpracticed in the directorial role.
One researchaim is thus partially to automate the directorialfunctions, which importantly involve affect de-tection.
For instance, a director may intervenewhen emotions expressed or discussed by char-acters are not as expected.
Hence we have devel-oped an affect-detection module.
It has not yetactually been used for direction, but instead tocontrol a simple automated bit-part actor,EmEliza.
The module identifies affect in charac-ters?
speeches, and makes appropriate responsesto help stimulate the improvisation.
Within affectwe include: basic and complex emotions such asanger and embarrassment; meta-emotions suchas desiring to overcome anxiety; moods such ashostility; and value judgments (of goodness,etc.).
Although merely detecting affect is limitedcompared to extracting full meaning, this is oftenenough for stimulating improvisation.Much research has been done on creating affec-tive virtual characters in interactive systems.
Emo-tion theories, particularly that of Ortony et al(1988; OCC in the following), have been usedwidely.
Prendinger & Ishizuka (2001) used OCCto reason about emotions.
Mehdi et al (2004) usedOCC to generate emotional behaviour.
Gratch andMarsella?s (2004) model reasons about emotions.However, few systems are aimed at detecting af-fect as broadly as we do and in open-ended utter-ances.
Although Fa?ade (Mateas, 2002) includedprocessing of open-ended utterances, the broaddetection of emotions, rudeness and value judge-ments is not covered.
Zhe & Boucouvalas (2002)demonstrated emotion extraction using a taggerand a chunker to help detect the speaker?s ownemotions.
But it focuses only on emotional adjec-tives, considers only first-person emotions and203neglects deep issues such as figurative expression.Our work is distinctive in several respects.
Ourinterest is not just in (a) the positive first-personcase: the affective states that a virtual character Ximplies that it has (or had or will have, etc.
), butalso in (b) affect that X implies it lacks, (c) affectthat X implies that other characters have or lack,and (d) questions, commands, injunctions, etc.concerning affect.
We aim also for the software tocope partially with the important case of meta-phorical conveyance of affect (Fussell & Moss,1998; K?vecses, 1998).Our project does not involve using or develop-ing deep, scientific models of how emotionalstates, etc., function in cognition.
Instead, thedeep questions investigated are on linguistic mat-ters such as the metaphorical expression of af-fect.
Also, in studying how people understandand talk about affect, what is of prime impor-tance is their common-sense views of how affectworks, irrespective of scientific reality.
Metaphoris strongly involved in such views.2 A Preliminary ApproachVarious characterizations of emotion are used inemotion theories.
The OCC model uses emotionlabels and intensity, while Watson and Tellegen(1985) use positive and negative affects as themajor dimensions.
Currently, we use an evalua-tion dimension (positive and negative), affectlabels and intensity.
Affect labels with intensityare used when strong text clues signalling affectare detected, while the evaluation dimensionwith intensity is used when only weak text cluesare detected.2.1 Pre-processing ModulesThe language in the speeches created in e-dramasessions, especially by excited children, severelychallenges existing language-analysis tools ifaccurate semantic information is sought.
Thelanguage includes misspellings, ungrammatical-ity, abbreviations (such as in texting), slang, useof upper case and special punctuation (such asrepeated exclamation marks) for affective em-phasis, repetition of letters or words for empha-sis, and open-ended onomatopoeic elements suchas ?grrrr?.
The genre is similar to Internet chat.To deal with the misspellings, abbreviationsand onomatopoeia, several pre-processing mod-ules are used before the detection of affect startsusing pattern matching, syntactic processing bymeans of the Rasp parser (Briscoe & Carroll,2002), and subsequent semantic processing.A lookup table has been used to deal with ab-breviations e.g.
?im (I am)?, ?c u (see you)?
and?l8r (later)?.
It includes abbreviations used inInternet chat rooms and others found in an anly-sis of previous edrama sessions.
We handle am-biguity (e.g.,?2?
(to, too, two) in ?I?m 2 hungry 2walk?)
by considering the POS tags of immedi-ately surrounding words.
Such simple processinginevitably leads to errors, but in evaluations us-ing examples in a corpus of 21695 words derivedfrom previous transcripts we have obtained85.7% accuracy, which is currently adequate.The iconic use of word length (correspondingroughly to imagined sound length) as found bothin ordinary words with repeated letters (e.g.?seeeee?)
and in onomatopoeia and interjections,(e.g.
?wheee?, ?grr?, ?grrrrrr?, ?agh?, ?aaaggghhh?
)normally implies strong affective states.
We havea small dictionary containing base forms of somespecial words (e.g.
?grr?)
and some ordinarywords that often have letters repeated in e-drama.Then the Metaphone spelling-correction algo-rithm, which is based on pronunciation, workswith the dictionary to locate the base forms ofwords with letter repetitions.Finally, the Levenshtein distance algorithmwith a contemporary English dictionary dealswith misspelling.2.2 Affect DetectionIn the first stage after the pre-processing, ouraffect detection is based on textual pattern-matching rules that look for simple grammaticalpatterns or phrasal templates.
Thus keywords,phrases and partial sentence structures are ex-tracted.
The Jess rule-based Java framework isused to implement the pattern/template-matchingrules.
This method has the robustness to dealwith ungrammatical and fragmented sentencesand varied positioning of sought-after phraseol-ogy, but lacks other types of generality and canbe fooled by suitable syntactic embedding.
Forexample, if the input is ?I doubt she?s really an-gry?, rules looking for anger in a simple way willoutput incorrect results.The transcripts analysed to inspire our initialknowledge base and pattern-matching rules hadindependently been produced earlier from edramaimprovisations based on a school bullying sce-nario.
We have also worked on another, distinctlydifferent scenario concerning a serious disease,based on a TV programme produced by MaverickTelevision Ltd.
The rule sets created for one sce-nario have a useful degree of applicability to an-other, although some changes in the specific204knowledge database will be needed.As a simple example of our pattern-matching,when the bully character says ?Lisa, you PizzaFace!
You smell?, the module detects that he isinsulting Lisa.
Patterns such as ?you smell?
havebeen used for rule implementation.
The rules workout the character?s emotions, evaluation dimension(negative or positive), politeness (rude or polite)and what response EmEliza might make.
Althoughthe patterns detected are based on English, wewould expect that some of the rules would requirelittle modification to apply to other languages.Multiple exclamation marks and capitalisationof whole words are often used for emphasis in e-drama.
If exclamation marks or capitalisation aredetected, then emotion intensity is deemed to becomparatively high (and emotion is suggestedeven without other clues).A reasonably good indicator that an inner stateis being described is the use of ?I?
(see also Craggsand Wood (2004)), especially in combination withthe present or future tense.
In the school-bullyingscenario, when ?I?
is followed by a future-tenseverb, a threat is normally being expressed; and theutterance is often the shortened version of an im-plied conditional, e.g., ?I?ll scream [if you stayhere].?
When ?I?
is followed by a present-tenseverb, other emotional states tend to be expressed,as in ?I want my mum?
and ?I hate you?.Another useful signal is the imperative mood,especially when used without softeners such as?please?
: strong emotions and/or rude attitudes areoften being expressed.
There are common impera-tive phrases we deal with explicitly, such as ?shutup?
and ?mind your own business?.
But, to gobeyond the limitations of the pattern matchingwe have done, we have also used the Rasp parserand semantic information in the form of the se-mantic profiles for the 1,000 most frequentlyused English words (Heise, 1965).Although Rasp recognizes many simple im-peratives directly, it can parse some imperativesas declaratives or questions.
Therefore, furtheranalysis is applied to Rasp?s syntactic output.For example, if the subject of an input sen-tence is ?you?
followed by certain special verbsor verb phrases (e.g.
?shut?, ?calm?, ?get lost?, ?goaway?, etc), and Rasp parses a declarative, then itwill be changed to imperative.
If the softener?please?
is followed by a base forms of the verb,the inputs are also deemed to be imperatives.
If asingular proper noun or ?you?
is followed by abase form of the verb, the sentence is deemed tobe imperative (e.g.
?Dave bring me the menu?
).When ?you?
or a singular proper noun is fol-lowed by a verb whose base form equals its pasttense form, ambiguity arises (e.g.
?Lisa hit me?
).For one special case of this, if the direct object is?me?, we exploit the evaluation value of the verbfrom Heise?s (1965) semantic profiles.
Heiselists values of evaluation (goodness), activation,potency, distance from neutrality, etc.
for eachword covered.
If the evaluation value for theverb is negative, then the sentence is probablynot imperative but a declarative expressing acomplaint (e.g ?Mayid hurt me?).
If it has a posi-tive value, then other factors suggesting impera-tive are checked in this sentence, such as excla-mation marks and capitalizations.
Previous con-versation is checked to see if there is any recentquestion sentence toward the speaker.
If so, thenthe sentence is taken to be declarative.There is another type of sentence: ?don?t you +(base form of verb)?, which is often a negativeversion of an imperative with a ?you?
subject (e.g.
?Don?t you call me a dog?).
Normally Rasp re-gards such strings as questions.
Further analysishas also been implemented for such sentencestructure, which implies negative affective state,to change the sentence type to imperative.Aside from imperatives, we have also imple-mented simple types of semantic extraction ofaffect using affect dictionaries and WordNet.3 Metaphorical Expression of AffectThe explicit metaphorical description of emo-tional states is common and has been extensivelystudied (Fussell & Moss, 1998).
Examples are?He nearly exploded?, and ?Joy ran through me.
?Also, affect is often conveyed implicitly viametaphor, as in ?His room is a cess-pit?, whereaffect associated with a source item (cess-pit) iscarried over to the corresponding target item.Physical size is often metaphorically used toemphasize evaluations, as in ?you are a bigbully?, ?you?re a big idiot?, and ?you?re just alittle bully?, although the bigness may be literalas well.
?Big bully?
expresses strong disapproval(Sharoff, 2005) and ?little bully?
can expresscontempt, although ?little?
can also convey sym-pathy.
Such examples are not only practicallyimportant but also theoretically challenging.We have also encountered quite creative useof metaphor in e-drama.
For example, in aschool-bullying improvisation that occurred,Mayid had already insulted Lisa by calling her a?pizza?, developing a previous ?pizza-face?
in-sult.
Mayid then said ?I?ll knock your toppingoff, Lisa?
?
a theoretically intriguing spontane-205ous creative elaboration of the ?pizza?
metaphor.Our developing approach to metaphor handlingin the affect detection module is partly to lookfor stock metaphorical phraseology and straight-forward variants of it, and partly to use a simpleversion of the more open-ended, reasoning-basedtechniques taken from the ATT-Meta project(Barnden et al, 2002; 2003; 2004).
ATT-Metaincludes a general-purpose reasoning engine, andcan potentially be used to reason about emotionin relation to other factors in a situation.
In turn,the realities of metaphor usage in e-drama ses-sions are contributing to our basic research onmetaphor processing.4 ConclusionWe have implemented a limited degree of affect-detection in an automated actor by means of pat-tern-matching, robust parsing and some semanticanalysis.
Although there is a considerable dis-tance to go in terms of the practical affect-detection that we plan to implement, the alreadyimplemented detection is able to cause reasona-bly appropriate contributions by the automatedcharacter.
We have conducted a two-day pilotuser test with 39 secondary school students.
Weconcealed the involvement of an earlier versionof EmEliza in some sessions, in order to test byquestionnaire whether its involvement affectsuser satisfaction, etc.
None of the measures re-vealed a significant effect.
Also, judging by thegroup debriefing sessions after the e-drama ses-sions, nobody found out that one bit-part charac-ter was sometimes computer-controlled.
Furtheruser testing with students at several Birminghamschools will take place in March 2006.ReferencesBarnden, J.A., Glasbey, S.R., Lee, M.G.
& Walling-ton, A.M., 2002.
Reasoning in metaphor under-standing: The ATT-Meta approach and system.
InProceedings of the 19th International Confer-ence on Computational Linguistics.Barnden, J.A., Glasbey, S.R., Lee, M.G.
& Walling-ton, A.M., 2003.
Domain-transcending mappingsin a system for metaphorical reasoning.
In Pro-ceedings of the Research Note Sessions of the10th Conference of EACL.Barnden, J.A., Glasbey, S.R., Lee, M.G.
& Walling-ton, A.M. 2004.
Varieties and Directions of Inter-domain Influence in Metaphor.
Metaphor andSymbol, 19(1), pp.1-30.Briscoe, E. & J. Carroll.
2002.
Robust Accurate Sta-tistical Annotation of General Text.
In Proceed-ings of the 3rd International Conference onLanguage Resources and Evaluation, Las Pal-mas, Gran Canaria.
pp.1499-1504.Craggs, R. & Wood.
M. 2004.
A Two DimensionalAnnotation Scheme for Emotion in Dialogue.
InProceedings of AAAI Spring Symposium: Ex-ploring Attitude and Affect in Text.Fussell, S. & Moss, M. 1998.
Figurative Language inDescriptions of Emotional States.
In S. R. Fusselland R. J. Kreuz (Eds.
), Social and cognitive ap-proaches to interpersonal communication.Lawrence Erlbaum.Gratch, J.
& Marsella, S. 2004.
A Domain-Independent Framework for Modeling Emotion.Journal of Cognitive Systems Research.
Vol 5,Issue 4, pp.269-306.Heise, D. R. 1965.
Semantic Differential Profiles for1,000 Most Frequent English Words.
Psychologi-cal Monographs 79, pp.1-31.K?vecses, Z.
1998.
Are There Any Emotion-SpecificMetaphors?
In Speaking of Emotions: Concep-tualization and Expression.
Athanasiadou, A.and Tabakowska, E.
(eds.
), Berlin and New York:Mouton de Gruyter, pp.127-151.Mateas, M. 2002.
Ph.D. Thesis.
Interactive Drama,Art and Artificial Intelligence.
School of ComputerScience, Carnegie Mellon University.Mehdi, E.J., Nico P., Julie D. & Bernard P. 2004.Modeling Character Emotion in an Interactive Vir-tual Environment.
In Proceedings of AISB 2004Symposium: Motion, Emotion and Cognition.Leeds, UK.Ortony, A., Clore, G.L.
& Collins, A.
1988.
TheCognitive Structure of Emotions.
CUPPrendinger, H. & Ishizuka, M. 2001.
Simulating Af-fective Communication with Animated Agents.
InProceedings of Eighth IFIP TC.13 Conferenceon Human-Computer Interaction, Tokyo, Japan,pp.182-189.Sharoff, S. 2005.
How to Handle Lexical Semantics inSFL: a Corpus Study of Purposes for Using SizeAdjectives.
Systemic Linguistics and Corpus.London: Continuum.Watson, D. & Tellegen, A.
1985.
Toward a Consen-sual Structure of Mood.
Psychological Bulletin,98, pp.219-235.Zhe, X.
& Boucouvalas, A. C. 2002.
Text-to-EmotionEngine for Real Time Internet Communication.
InProceedings of International Symposium onCommunication Systems, Networks and DSPs,Staffordshire University, UK, pp.164-168.206
