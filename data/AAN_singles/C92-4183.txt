Uniform Recognition tbr Acyclic Context-Sensitive Grammars isNil '-completeF, rik Aarts*l/.escarch Ins t i tu te  for L~mguagc & SpeechTrans  103512 JK  UtrechtThe  Nether landsAbst rac tContext-sensit ive grammars in which each rule isof the forln aZf l  - -~ (-*Tfl are acyclic if the associ-ated context-free grammar  with the rules Z ~ 3'is acyclic.
The problem whether an intmt string isin the language generated by an acyclic context-sensitive grammar  is NP-conlplete.IntroductionOne of the most well-known classifications ofrewrite grammars is the Chomsky hierarchy.Grammars  and languages ~Lre of type 3 (regular),type 2 (context-free), type 1 (context-sensitive)or of type 0 (unrestricted).
It is easy to de-cide whether a str ing is in tile language gener-ated by a regular or (:ontext-free gralntnar.
Forcontext-.free grammars input strings can be re(:ogmzed in a t ime that  is polynomiM in the lengthof the input  string as well as in the length of thegrammar.
Earley \[197(I\] ha.s shown a t)ound ofO(\[GI2n a) where G is the size of the grammarand n the length of the inlmt string, l/.ecogni-l ion for context-sensit ive gralnmars is harder: itis PSPACE-complete \[Garey aaM Johnson, 1979\],referring to \[Kuroda, 1964\] and \[Karp, 1972 t.II.ecognition of type 0 hulguages is undccidat)le(see e.g.
Lewis and Papadimitr iou \[1981\]).The area between context-free grammars andcontext-sensit ive grammars is interesting for tworea.sons.
First, people have tr ied to describe nat-ural languages with rewrite grammars.
Context-free grammars do not seem powerfull enough todescrihe natura l  languages.
Context-free gram-mars generate context-free languages.
Natural*The author was sponsored by project NF 102/62-356('StructurM and Semantic Parallels in Natural Languagesand Programming Languages'), flmded by the NetherlandsOrganization for the Advancement of l\[escarch (NWO).languages are probal)ly not context-free.
Theeounterexamples of sentences that  caal not bedescribed with a context-free grammar  are al-ways a bit artif ieiah Very big subparts  of nat-IlEal languages are context-free.
A grammar  fornaturM languages has to be only a bit strongerthan context-free.
That 's  why we are interestedin grammars  that  are between context-free andcontext-sensitive.The second perspective is the one of efficientproeessability, lu a context-free model, sentencescan be processed ellMently.
In a context-sensit iveone, they can not.
It is very interest ing to knowwhere the border lies: in which models sentencescan be processed efficiently and in which ones theyCall not'?In tile 60's and 70's, a t tempts  have been madeto put  restrict ions on context-sensit ive grammarsin order to generate context-fl-ee lmtguages.
Ex-a:mples are Book \[1972\[, t i l l )bard \[1974\] and Gins-burg aud Greibaeh \[1966 I. Baker \[1974\] has shownthat  these methods come down to tile same moreor less.
They all block the use of eontex~ topass information through the string.
Book \[1973\]gives ;m ow~rview of atteHtpts to generate context-flee languages with non-context-free grammars.How to restrict permutat ive grammars  in orderto generate context-free languages is described inMiLkkinen \[1985\].t 'eters 3r.
and Ritchie \[1973\] proposed a lin-guisticMly mot ivated chaatge in the definition ofthe notion grammar.
Subsequent replacementsin a str ing are relflaced by node admissibi l i tyconstraints in the parse trees of sentences in acon(ext.-flee grammar.
However, this formalismleads to generation of context-free 1,'mguages too.The approach of restr ict ing ramlnaxs uch thatthey generate context-tree languages does notseem interesting from the natura l  language per-spective nor fi'o~l the efficiency perspective.
ThcAcrl,:s DE COLING-92, NANTES, 23-28 AO()I 1992 1 1 5 7 ~RO?
O: COI.ING 92 NnNIES, AUG. 23-28, 1992oMy advantages of tlfis kind of restrictions lie inthe possibilty to describe a context-free languagein a different way, which may be easier for somepurpose.Another argument agMnst blocking information\[/3aker, \]974\] is the problem of unbounded epen-dencies.
Unbounded ependencies are dependen-cies over an mlbounded istance.
Wh-movcmentis an examI)le of it.
The number of unbounded e-pendencies in naturM hmguage is (almost) alwaysrestricted.
Models that  restrict the amount of in-formation that  can be sent seem to come closer tomodels of hummL language than models restrictthe distance over wlfich information can be sent.In the 70's and 80's attent ion has shifted tothe perspective of efficient processing.
Context-sensitive grammars have been restricted so thatcomplexity of recognition lies somewhere between7)SPAC$ and T'.
Book \[1978\] has shown thatfor l inear t ime context-sensitive grammars recog-nit ion is NP-complete ven for (some) fixed gram-mars.
l~lrthermore there is a result that  recog-nit ion for growing context-sensitive grammars ist)olynomial for tLxed grammars \[Dalflhaus andWarmuth,  t986\].
This article also tries to definea border between early-eflicient and just-efficientnmdels.We can define the notions uniform (or univer-sal) recognition and recognition for a fixed gram-mar  as follows.UNIFORM RECOGNIT IONINSTANCE: A grammar G and a string w.QUESTION: Is w in the language generated by G?The grammar,  as well ms the input str ing are in-puts for the problem (these two types of input areeasily confused!).
The uniform recognition prob-lena is one problem.There are infinitely many other problems:Suppose we have a grammar G.RECOGNIT ION FOR, F IXED GRAM-MAR GINSTANCE: A string w.QUESTION: Is w in the language generated by GvThings are gett ing even more difficult when wesay things fikc: "For every grammar G RECOG-NIT ION FOR FD(ED GRAMMAR G .
.
. "
.
Thedifference between uniform recognition and recog-nit ion for all fixed G can be i l lustrated with anexample from Barton Jr., Berwick and l~istad\[1987\].
They show that uniform recognition forunordered context-free grammar (UCFG) can bedone in t ime O(21C;In3).
It has not been shownthat  the mfiform recognition problem is in 3 ?.
Forevery G, however, tile fixed recognition problemcan be solved in t ime O(n 3) and all these problemsare in 7 ~.
Barton Jr., Berwick and Ristad \[1987\]show the problem to be polynomial  for any fixedgrammar by a compilat ion step.
The UCFG iscompiled into a big context-free grammar.
Theyuse this grammar and the Earley algorithm in or-der to prove a polynomial  bound.
Just forgettingabout the grammar  size (replacing IGI by a con-staslt) gives a polynomial  bound too.
It is notclear why Barton Jr., Berwick and Ristad \[1987\]always associate the fixed grarnmar problem withcompilation (cf.
their pp.
27-30, 64-79 and 202-206).This article is about uniform recognition for onetype of restricted context-sensit ive grammars,  theacyclie context sensitive grammars (ACSG's).
Weprove it to be NP-complete.
This means they areas complex as the Agreement Grammars  and theUnordered CFG's of Barton Jr., Berwick and Ris-tad \[1987\].
ACSG's are the pure rewrite gram-mars in this group.
They fit in the Chomsky hi~erarchy.The Uniform Recognition ProblemPSPACE--completeNP--completePOne might ask when we can use acycfic context-sensitive grammars.
One can use them every-where where one wants to use context-sensit ivegranlmars.
But  one has to be careful: cyclesare not allowed.
This property of acyclicity canbe checked easily 1.
For most purposes one doesnot need cycles at all.
One field where context-sensitive grammars can be used is e.g.
morphol-ogy.
Characters in a word are often changed when1 It is much easier than checking whether a CSG is t~ lin-ear time CSG as defined by Book \[1978\].
One has to reasonabout length of possible derivations.
In ACSG, derivationsa.t'e short as a result of their acyclicity.ACnT~S DE COIJNG-92, NAIgfES, 2.3-28 ao~r 1992 1 15 8 PRO(:.
OF COLlNG-92, N^r?ll~s, AuG. 23-28, 1992some suffix is added.
These changes in a wordare context-sensit ive aald can be descr ibed by acontext-sensit ivc grammar .
Once a character  ischanged,  we normal ly  do not  want to change itback,  the grammax we use is an acychc one.The complexity of recognit ion for ACSG islower thmt in the unrestr ic ted case (CSG, withcomplexi ty  PSPACE)  because we restr ict  theamount of in format ion that  can be passed throughthe sentence.
The  number  of messages that  e~'ut besent is l imited (and we do not block the messagesby barr iers as in Baker  \[1974\] !).
In the unre-str icted case we can send messages that  leave notrace.
E.g.
after a message that  changes 0~s intol~s we can send a message that  does the reverse.In sending a message f rom one posit ion in the sen-tence to another~ the intermediate  symbols are notchazlged.
In fact  they are changed twice: backand  forth.
Wi th  acycl lc context-sensit ive gram-mars ,  this is not  possible.
Every messages leavesa t race aatd the amount  of in format ion that  ca~tbe sent, is restr icted by the gr~munar.Def in i t ionsA grammar is a 4-tuple, G = (V, E, R,  S), whereV is a set of symbols,  :E C V is the set of termina lsymbols.
R C V ~ x V* is a relat ion defined onstr ings.
E lements of _R arc called rules.
S E V \is the s tar tsymbol .A grammar  is context-sensitive if each rule isof the form aZfl ---* ?~7fl where Z ff V \ E ;c?,/~, 7 G V* ; 7 5 L e. A granLmar is context-freeif each rule is of the form Z -~ 3' where Z C V \;TEV* .Derivability (-%) between str ings is defined as fol-lows: uc~v ~ uflv (u,v,c*,fl E V*) iff (~,f l)  E R.The  transit ive closure of -% is denoted by =L~.
Thetransit ive rettcxive closure of =4- is denoted by:~.
The  language generated by G is defined msL(G) = {w E E* I S ~ w}.A derivation of a str ing ~ is a sequence of str ingsz l ,x2, .
.
.
,x ,~ with xa = S, for "all i (1 < i < n)Xi =2- Xi+l  and  X n = ~.A context- free grammar  is acyclic if there is noZ E V \E  such that  Z ~+ Z. Th is imphes  thatthere is no str ing a E V* such that  cr ~ a .We can map a context-sensit ive grammar  G ontoits associated context-free grammar  G ~ as follows:If G is (V ,E ,R ,S)  then G' is (V ,E ,R ' ,S)  wherefor every rule aZfl -~ oeTfl E R there is a ruleZ -~ 7 ff R r. There  axe no other  rules in R I.Note that  the associated grammar  does not  con-ta in empty  product ions.We cefll G aeyclic iff the associated context-f leegrammar  C is acycllc.The notat ion  we use for context-sensit ive rulesis ms follows: the rule aZfl ---* ceTfl is wr i t tenas Z -~ \ [a l l \ [a~\ ] .
.
.
i ak l  3' \[flllL621 .
.
.
\[ f i l l  with~ : C~la2...?~k andf l  = fllfl2...fll, ai,flj E V(l < i<k , l  < j_<l).An example of a context-sensit ive grammar  withthe corresponding context- f lee rules is:context-sensit ive rules context- free par t1 -~ \[0\] 2 1 ~ 20-~ i \[21 0 -~ 12 - ,  \[1\] 0 2 -~ 0This contextMsensitive grammar is  cyclic.
I r i s  ableto permute  (}'s and  its,Recogn i t ion  i s  NP-completeUNIFORM RECOGNIT ION FORACYCL IC  CONTEXT-SENSIT IVEGRAMMARINSTANCE:  An acyehc context-sensit ive gram-mar  G = (V, Z ,R ,S )  and  a st r ing w G E*.QUEST ION:  Is w in the language generated  by G?The proof  can be found in Aar ts  \[1991b\].
Toprove that  it  is in NP wc have to prove thatderivations ill ACSG's  aa'e short  (have po lynomia llength).
Tiffs follows f rom the fact that  deriva-t ions in context- free grammars  have po lynomia llength.
Derivations in an  acyclie CSG are iden-tical with derivat ions in the associated context-free grammar .
The  proof  of NP-hardness  is morecompl icated.
The known NP-hard  prob lem 3-SATcan be reduced to UNIFORM RECOGNIT IONfor ACSG.
Any  3-SAT formula  can be t rans latedin a grammar  and  an input  for ACSG-recogult ion.AcrEs DE COLING-92, NANTES, 23-28 Aour 1992 1 1 5 9 PROc, O1: COLING-92.
NAbrl'ES, AUG. 23-28, 1992Recognizing PowerAny context-free grammar can be transformedinto ant acyclic context-free grammar without lossof recognizing power.
A cycle can be removedby introduction of a new symbol.
This sym-bol rewrites to any member of the cycle.
Anycontext-free grammar with empty productionscan bc changed into a context-free grammar with-out empty productions that recognizes the samelanguage.
There's one exception here: languagescontaining the empty string can not be generated.Any acyclic context-free grammar withont emptyproductions i an acyclic context-sensitive granl-mar.
Therefore, ACSG's recognize all context-free10alguages that do not contain the empty word.Furthermore, acyclic context-sensitive grana-mars recognize languages that are not context-free.
One example is the language{anb2~c** In  > 1}This language is recognized by the grammar ("X"is a nouternfinM):X~ \[A\] ABB \[B\] B -~\ [A \ ]X \ [X \ ]  A -4ax -~ IX\] B B\[B\] B - .
\[B\] X \[Xl B -~ bX - , \ [X \ ]BnC\ [C \ ]  ~ ~\ [B \ ]X \ [C \ ]  C~eS -~ A B B CAder ivat ionof "AABBBBCC"S~ABBC-~ABXC~AXXC~AXBBCC~AABBBBCC~aabbbbcc .With the pumping lemma one caal prove that thel~tbmage is not context-free.DiscussionWe have proved that UNIFORM RECOGNI-TION FOR.
ACYCLIC CONTEXT-SENSITIVEGf\[AMMAR is NP-complete.
It turns out tobe important for complexity of recognition withcontext-sensitive grammars whether sending in-formation leaves a trace.We have reduced 3-SAT to the uniform recog-nition problem for acyclic context-sensitive gram-mars.
Every 3-SAT formula results in a differentgrammar.
Probably it is not possible to constructan acyclic context-sensitive grammar that recog-nizes all 3-SAT formulas.
My conjecture is thatACSG-recognition is not NP-hard for any fixedgrammar.
If this is not true, there would exist agrammar that recognizes all 3-SAT formulas.
Forthis grammar the recognition problem would beNP-hard.
In such a grammar, not every 3-SATvariable is encoded in a different symbol in thegrammar.
The variables are numbered and theirnumbers are encoded in sequences of O's and l 'se .g .
.
A grammar that recognizes all 3-SAT for-muta's must be able to compare such sequences.It must e.g.
be able to recognize tile language{ww I w ?
V*}.
I fw is  anumber,  two numbersare compared.
Context-sensitive grammars canrecognize ww.
Some can even recognize all 3-SATformula's.ACSG's are not that strong.
They can not evenrecognize ww.
Any ACSG can compare only afixed number of characters (only fixed amounts ofinformation cazt be sent).
Therefore my conjec-ture is that the recognition problem for any fixedgrammar is not so hard: it's polynomial.
Chartparsers for ACSG have been designed and imple-mented \[Aarts, 1991\].
They recognize inputs formany hard grammars in polynomial time.
It ishard to prove, however, that they run in poly-nomial time for every grammar.
If it could beproved, complexity of ACSG-recognition is similarto complexity of UCFG-recognition: NP-completefor the uniform case and a known algorithm thatruns in time something like O(21GIna)) (polyno-mial in n but not in G).The polynmnial bound (which has not beenproved yet) would be an explanation of the factthat humans can process language fllcicntly.
Hu-mans have a fixed grammar in mind which doesnot change.
The complexity of recognition with afixed grammar should be compared with the speedof human language processing.
The argumentsof Barton Jr., Berwick and Ristad \[1987\] againstthis are based on two kinds of arguments.
Thefirst has to do with compilation or preprocessing.We have polynomial bounds without compilationor preprocessing (just fix IGD.
These argumentsdo not seem to hold.
The other ones have to dowith language acq~fisition.
When a child is learn-ing a language, the grammar she uses is changing.At every sentence utterance or understanding thegraramar seems to be fixed.
The difference be-tween uniform recognition and recognition for anyfixed grammar is that small that we can not drawconclusions about what kind of processing chil-dren perform when learning a language.AcrEs DE COLING-92, NAbrrES, 23-28 ^O~q" 1992 1 1 6 0 PROC.
OF COLING-92, NAh'rES, AUG. 23-28, 1992AcknowledgementsI want to thank Peter van Erode Boa.s, ReinhardMuskens, Mart Trautwein and Theo Jansen fortheir comments on carher versions of this paper.Re ferencesAarts, E., Itecognition for Acychc Context-Sensitive Grammars is probably Polyno-mial for Fixed Grammars, Tillmrg Univer-sity, ITK Research Memo no.
8, 199L.Aarts, E.,Uniform Recognition for Acychc Context-Sensitive Grazumars is NP-complete, pa-per presented at Computing Science in theNetherlands, Amstcrdam, 19911).Baker, B. S., Non-context-Free Grammars Gen-erating Context-Frec Languages, Inform.and Control, 24,231 -246, 1974.Barton Jr., G. E., R. C. Berwick ~ld E. S. Ris-tad, Computational complexity and natu-rM language, MIT Press, Cambridge, MA,1987.Book, R. V., Terminal context in context-sensitivegramanars, SIAM J.
Comput., 1, 20-30,1972.Book, R. V., On the Structure of Context-Sensitive Grammars, lnternat.
J. Comput.lnform.
Sci., 2, 129 139, 1973.Book, R. V., On the Complexity of Formal Grain-mars, Acta/nform., 9,171 181, 1978.Dahlhaus, E. and M. K. Warmuth, Membershil)for Growing Context-Sensitive GrammarsIs Polynomial, lnternat.
J. Comput.
1n-form.
Sci., 33,456--472, 1986.Earley, J., An Efficient Context-Free Parsing Al-gorithm, Comm.
ACM, 13(2), 94-102,Feb.
1970.
(~arey, M. R. aztd D. S. Johnson, Computersand lntractabillty: A C~uide to the The-ory of NP-Completeness, W. H. Freemalland Company, San l~rancisco, CA, 1979.Ginsburg, S. and S. A. Greibach, Mappings whichPreserve Context Sensitive Languages,/n-form.
and Control, 9, 563-582, 1966.Hibbard, T. N., Context-Limited Grammars, J.Assoc.
Comput.
Mach., 21(3), 446-453,July 1974.Karl), R. M., Reducibihty among combinato-rim problems, in CompleJdty of ComputerComputations, edited by R. E. Millerand J. W. Thatcher, pp.
85-103, PlenumPress, New York, 1972.Kuroda, S.
oY., Classes of Languages and Linear?Bounded Automata,/nform.
and Control,7, 207-223, 1964.Lewis, H. R. and C. H. Papadlmitriou, Elementsof the theory of computation, Prentice-Hall, Englewood Cliffs, N J, 1981.M?kklnen, E., On Permntative Gra~nmars Gen-erating Context-Free Lang~tagcs, BIT, 25,604-610, 1985.Peters Jr., P. S. mad R. W. Ritchie, Context-Sensitive Immediate Constituent Anal-ysis: Context-Free Languages Revisited,Math.
Systems Theory, 6(4), 324-333,1973.AcrF.s DE COLlNG-92, NAMES, 23-28 AOr~q ' 1992 1 1 6 1 PRO(:.
OF COLING-92, NANteS.
AUG. 23-28, 1992
