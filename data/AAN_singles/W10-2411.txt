Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 71?75,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsEnglish to Indian Languages Machine Transliteration System atNEWS 2010Amitava Das1, Tanik Saikh2, Tapabrata Mondal3, Asif Ekbal4, Sivaji Bandyopadhyay5Department of Computer Science and Engineering1,2,3,5Jadavpur University,Kolkata-700032, Indiaamitava.santu@gmail.com1, tanik4u@gmail.com2, tapabratamon-dal@gmail.com3, sivaji_cse_ju@yahoo.com5Department of Computational Linguistics4University of HeidelbergIm Neuenheimer Feld 32569120 Heidelberg, Germanyekbal@cl.uni-heidelberg.deAbstractThis paper reports about our work in theNEWS 2010 Shared Task on TransliterationGeneration held as part of ACL 2010.
Onestandard run and two non-standard runs weresubmitted for English to Hindi and Bengalitransliteration while one standard and one non-standard run were submitted for Kannada andTamil.
The transliteration systems are basedon Orthographic rules and Phoneme basedtechnology.
The system has been trained onthe NEWS 2010 Shared Task on Translitera-tion Generation datasets.
For the standard run,the system demonstrated mean F-Score valuesof 0.818 for Bengali, 0.714 for Hindi, 0.663for Kannada and 0.563 for Tamil.
The reportedmean F-Score values of non-standard runs are0.845 and 0.875 for Bengali non-standard run-1 and 2, 0.752 and 0.739 for Hindi non-standard run-1 and 2, 0.662 for Kannada non-standard run-1 and 0.760 for Tamil non-standard run-1.
Non-Standard Run-2 for Ben-gali has achieved the highest score among allthe submitted runs.
Hindi Non-Standard Run-1and Run-2 runs are ranked as the 5th and 6thamong all submitted Runs.1 IntroductionTransliteration is the method of translating onesource language word into another target lan-guage by expressing and preserving the originalpronunciation in their source language.
Thus, thecentral problem in transliteration is predicting thepronunciation of the original word.
Translitera-tion between two languages that use the same setof alphabets is trivial: the word is left as it is.However, for languages those use different al-phabet sets the names must be transliterated orrendered in the target language alphabets.
Trans-literation of words is necessary in many applica-tions, such as machine translation, corpus align-ment, cross-language Information Retrieval, in-formation extraction and automatic lexicon ac-quisition.
In the literature, a number of translite-ration algorithms are available involving English(Li et al, 2004; Vigra and Khudanpur, 2003; Go-to et al, 2003), European languages (Marino etal., 2005) and some of the Asian languages,namely Chinese (Li et al, 2004; Vigra and Khu-danpur, 2003), Japanese (Goto et al, 2003;Knight and Graehl, 1998), Korean (Jung et al,2000) and Arabic (Al-Onaizan and Knight,2002a; Al-Onaizan and Knight, 2002c).
Recent-ly, some works have been initiated involvingIndian languages (Ekbal et al, 2006; Ekbal et al,2007; Surana and Singh, 2008).
The detailed re-port of our participation in NEWS 2009 could befound in (Das et al, 2009).One standard run for Bengali (BengaliStandard Run: BSR), Hindi (Hindi StandardRun: HSR), Kannada (Kannada Standard Run:KSR) and Tamil (Tamil Standard Run: TSR)were submitted.
Two non-standard runs for Eng-lish to Hindi (Hindi Non-Standard Run 1 & 2:HNSR1 & HNSR2) and Bengali (Bengali Non-Standard Run 1 & 2: BNSR1 & BNSR1) transli-teration were submitted.
Only one non-standardrun were submitted for Kannada (Kannada Non-Standard Run-1: KNSR1) and Tamil (TamilNon-Standard Run-1: TNSR1).712 Machine Transliteration SystemsFive different transliteration models have beenproposed in the present report that can generatethe transliteration in Indian language from anEnglish word.
The transliteration models arenamed as Trigram Model (Tri), Joint Source-Channel Model (JSC), Modified Joint Source-Channel Model (MJSC), Improved ModifiedJoint Source-Channel Model (IMJSC) and Inter-national Phonetic Alphabet Based Model (IPA).Among all the models the first four are catego-rized as orthographic model and the last one i.e.IPA based model is categorized as phonemebased model.An English word is divided into Translitera-tion Units (TUs) with patterns C*V*, where Crepresents a consonant and V represents a vowel.The targeted words in Indian languages are di-vided into TUs with patterns C+M?, where Crepresents a consonant or a vowel or a conjunctand M represents the vowel modifier or matra.The TUs are the basic lexical units for machinetransliteration.
The system considers the Englishand Indian languages contextual information inthe form of collocated TUs simultaneously tocalculate the plausibility of transliteration fromeach English TU to various Indian languagescandidate TUs and chooses the one with maxi-mum probability.
The system learns the map-pings automatically from the bilingual NEWS2010 training set being guided by linguistic fea-tures/knowledge.
The output of the mappingprocess is a decision-list classifier with collo-cated TUs in the source language and theirequivalent TUs in collocation in the target lan-guage along with the probability of each decisionobtained from the training set.
A Direct examplebase has been maintained that contains the bilin-gual training examples that do not result in theequal number of TUs in both the source and tar-get sides during alignment.
The Direct examplebase is checked first during machine translitera-tion of the input English word.
If no match isobtained, the system uses direct orthographicmapping by identifying the equivalent TU in In-dian languages for each English TU in the inputand then placing the target language TUs in or-der.
The IPA based model has been used forEnglish dictionary words.
Words which are notpresent in the dictionary are handled by otherorthographic models as Trigram, JSC, MJSC andIMJSC.The transliteration models are described belowin which S and T denotes the source and the tar-get words respectively:3 Orthographic Transliteration modelsThe orthographic models work on the idea ofTUs from both source and target languages.
Theorthographic models used in the present systemare described below.
For transliteration, P(T),i.e., the probability of transliteration in the targetlanguage, is calculated from a English-Indianlanguages bilingual database If, T is not found inthe dictionary, then a very small value isassigned to P(T).
These models have beendesribed in details in Ekbal et al (2007).3.1 TrigramThis is basically the Trigram model where theprevious and the next source TUs are consideredas the context.
( | ) ( , | )1, 11KP S T P s t s sk k kk= < >??
+=( ) arg max { ( ) ( | )}S T S P T P S TT?
= ?3.2  Joint Source-Channel Model (JSC)This is essentially the Joint Source-Channelmodel (Hazhiou et al, 2004) where theprevious TUs with reference to the current TUsin both the source (s) and the target sides (t) areconsidered as the context.
( | ) ( , | , )11KP S T P s t s tk kk= < > < >?
?=( ) arg max { ( ) ( | )}S T S P T P S TT?
= ?3.3 Modified Joint Source-Channel Model(MJSC)In this model, the previous and the next TUs inthe source and the previous target TU areconsidered as the context.
This is the ModifiedJoint Source-Channel model.
( | ) ( , | , )1, 11KP S T P s t s t sk k kk= < > < >??
+=( ) arg max { ( ) ( | )}S T S P T P S TT?
= ?3.4 Improved Modified Joint Source-Channel Model (IMJSC)In this model, the previous two and the next TUsin the source and the previous target TU areconsidered as the context.
This is the  ImprovedModified Joint Source-Channel model.72( | ) ( , | , )1 1, 11KP S T P s t s s t sk k k kk= < > < >?
+ ?
+=( ) arg max { ( ) ( | )}S T S P T P S TT?
= ?4 International Phonetic Alphabet(IPA) ModelThe NEWS 2010 Shared Task on TransliterationGeneration challenge addresses general domaintransliteration problem rather than named entitytransliteration.
Due to large number of dictionarywords as reported in Table 1 in NEWS 2010 dataset a phoneme based transliteration algorithmhas been devised.Train Dev TestBengali 7.77% 5.14% 6.46%Hindi 27.82% 15.80% 3.7%Kannada 27.60% 14.63% 4.4%Tamil 27.87% 17.31% 3.0%Table 1: Statistics of Dictionary WordsThe International Phonetic Alphabet (IPA) is asystem of representing phonetic notations basedprimarily on the Latin alphabet and devised bythe International Phonetic Association as astandardized representation of the sounds ofspoken language.
The machine-readableCarnegie Mellon Pronouncing Dictionary 1  hasbeen used as an external resource to capturesource language IPA structure.
The dictionarycontains over 125,000 words and theirtranscriptions with mappings from words to theirpronunciations in the given phoneme set.
Thecurrent phoneme set contains 39 distinctphonemes.
As there is no such parallel IPAdictionary available for Indian languages,English IPA structures have been mapped to TUsin Indian languages during training.
An exampleof such mapping between phonemes and TUs areshown in Table 3, for which the vowels maycarry lexical stress as reported in Table 2.
Thisphone set is based on the ARPAbet2 symbol setdeveloped for speech recognition uses.Representation Stress level0 No1 Primary2 SecondaryTable 2: Stress Level on VowelA pre-processing module checks whether atargeted source English word is a validdictionary word or not.
The dictionary words arethen handled by phoneme based transliterationmodule.1www.speech.cs.cmu.edu/cgi-bin/cmudict2http://en.wikipedia.org/wiki/ArpabetPhoneme Example Translation TUsAA odd AA0-D -AH hut HH0-AH-T -D dee D-IY1 -?Table 3: Phoneme Map Patterns of EnglishWords and TUsIn the target side we use our TU segregationlogic to get phoneme wise transliteration pattern.We present this problem as a sequence labellingproblem, because transliteration pattern changesdepending upon the contextual phonemes insource side and TUs in the target side.
We use astandard machine learning based sequencelabeller Conditional Random Field (CRF)3 here.IPA based model increased the performancefor Bengali, Hindi and Tamil languages asreported in Section 6.
The performance hasdecreased for Kannada.5 RankingThe ranking among the transliterated outputsfollow the order reported in Table 4: The rankingdecision is based on the experiments as describedin (Ekbal et al, 2006) and additionally based onthe experiments on NEWS 2010 developmentdataset.Word Type  Ranking Order 1 2 3 4 5Dictionary IPA IMJSC MJSC JSC TriNon-Dictionary IMJSC MJSC JSC Tri -Table 4: Phoneme Patterns of English WordsIn BSR, HSR, KSR and TSR the orthographicTU based models such as: IMJSC, MJSC, JSCand Tri have been used only trained by NEWS2010 dataset.
In BNSR1 and HNSR1 all the or-thographic models have been trained with addi-tional census dataset as described in Section 6.
Incase of BNSR2, HNSR2, KNSR1 and TNSR1the output of the IPA based model has been add-ed with highest priority.
As no census data isavailable for Kannada and Tamil therefore thereis only one Non-Standard Run was submitted forthese two languages only with the output of IPAbased model along with the output of StandardRun.6 Experimental ResultsWe have trained our transliteration models usingthe NEWS 2010 datasets obtained from theNEWS 2010 Machine Transliteration SharedTask (Li et al, 2010).
A brief statistics of the3http://crfpp.sourceforge.net73datasets are presented in Table 5.
During train-ing, we have split multi-words into collections ofsingle word transliterations.
It was observed thatthe number of tokens in the source and targetsides mismatched in various multi-words andthese cases were not considered further.
Follow-ing are some examples:Paris Charles de Gaulle  ????????
??
??
?
???
?Suven Life Scie  ?
?? ???
?Delta Air Lines  ??????
?In the training set, some multi-words werepartly translated and not transliterated.
Such ex-amples were dropped from the training set.
In thefollowing example the English word ?National?is being translated in the target as ?????
?.Australian National Univer-sity  ?????
?????????
?Set Number of examples Bng Hnd Kn TmTraining 11938 9975 7990 7974Development 992 1974 1968 1987Test 991 1000 1000 1000Table 5: Statistics of DatasetThere is less number of known examples inthe NEWS 2010 test set from training set.
Theexact figure is reported in the Table 6.Matches with trainingBengali 14.73%Hindi 0.2%Kannada 0.0%Tamil 0.0%Table 6: Statistics of DatasetIf the outputs of any two transliteration modelsare same for any word then only one output areprovided for that particular word.
Evaluation re-sults of the final system are shown in Table 7 forBengali, Table 8 for Hindi, Table 9 for Kannadaand Table 10 for Tamil.ParametersAccuracyBSR BNSR1 BNSR2Accuracy in top-1 0.232 0.369 0.430Mean F-score 0.818 0.845 0.875Mean Reciprocal Rank (MRR) 0.325 0.451 0.526Mean Average Precision(MAP)ref 0.232 0.369 0.430Table 7: Results on Bengali Test SetParametersAccuracyHSR HNSR1 HNSR2Accuracy in top-1 0.150 0.254 0.170Mean F-score 0.714 0.752 0.739Mean Reciprocal Rank (MRR) 0.308 0.369 0.314Mean Average Precision(MAP)ref0.150 0.254 0.170Table 8: Results on Hindi Test SetParametersAccuracyKSR KNSR1Accuracy in top-1 0.056 0.055Mean F-score 0.663 0.662Mean Reciprocal Rank (MRR) 0.112 0.169Mean Average Precision (MAP)ref 0.056 0.055Table 9: Results on Kannada Test SetParametersAccuracyTSR TNSR1Accuracy in top-1 0.013 0.082Mean F-score 0.563 0.760Mean Reciprocal Rank (MRR) 0.121 0.142Mean Average Precision (MAP)ref 0.013 0.082Table 10: Results on Tamil Test SetThe additional dataset used for the non-standard runs is mainly the census data consist-ing of only Indian person names that have beencollected from the web 4 .
In the BNSR1 andHNSR1 we have used an English-Bengali/Hindibilingual census example dataset.
English-Hindiset consist of 961,890 examples and English-Bengali set consist of 582984 examples.
Thisdatabase contains the frequency of the corres-ponding English-Bengali/Hindi name pair.7 ConclusionThis paper reports about our works as part of theNEWS 2010 Shared Task on TransliterationGeneration.
We have used both the orthographicand phoneme based transliteration modules forthe present task.
As our all previous efforts wasfor named entity transliteration.
TheTransliteration Generation challenge addressesgeneral domain transliteration problem ratherthan named entity transliteration.
To handlegeneral transliteration problem we proposed aIPA based methodology.4http://www.eci.gov.in/DevForum/Fullname.asp74ReferencesA.
Das, A. Ekbal, Tapabrata Mondal and S. Bandyo-padhyay.
English to Hindi Machine Transliterationat NEWS 2009.
In Proceedings of the NEWS 2009,In Proceeding of ACL-IJCNLP 2009, August 7th,2009, Singapore.Al-Onaizan, Y. and Knight, K. 2002a.
Named EntityTranslation: Extended Abstract.
In Proceedings ofthe Human Language Technology Conference,122?
124.Al-Onaizan, Y. and Knight, K. 2002b.
TranslatingNamed Entities using Monolingual and BilingualResources.
In Proceedings of the 40th AnnualMeeting of the ACL, 400?408, USA.Ekbal, A. Naskar, S. and Bandyopadhyay, S. 2007.Named Entity Transliteration.
International Journalof Computer Processing of Oriental Languages(IJCPOL), Volume (20:4), 289-310, World Scien-tific Publishing Company, Singapore.Ekbal, A., Naskar, S. and Bandyopadhyay, S. 2006.
AModified Joint Source Channel Model for Transli-teration.
In Proceedings of the COLING-ACL2006, 191-198, Australia.Goto, I., Kato, N., Uratani, N. and Ehara, T. 2003.Transliteration Considering Context Informationbased on the Maximum Entropy Method.
In Pro-ceeding of the MT-Summit IX, 125?132, New Or-leans, USA.Jung, Sung Young , Sung Lim Hong and Eunok Paek.2000.
An English to Korean Transliteration Modelof Extended Markov Window.
In Proceedings ofInternational Conference on Computational Lin-guistics (COLING 2000), 383-389.Knight, K. and Graehl, J.
1998.
Machine Translitera-tion, Computational Linguistics, Volume (24:4),599?612.Kumaran, A. and Tobias Kellner.
2007.
A genericframework for machine transliteration.
In Proc.
ofthe 30th SIGIR.Li, Haizhou, A Kumaran, Min Zhang and VladimirPervouchine.
2010.
Whitepaper: NEWS 2010Shared Task on Transliteration Generation.
In theACL 2010 Named Entities Workshop (NEWS-2010), Uppsala, Sweden, Association for Computa-tional Linguistics, July 2010.Li, Haizhou, Min Zhang and Su Jian.
2004.
A JointSource-Channel Model for Machine Translitera-tion.
In Proceedings of the 42nd Annual Meetingof the ACL, 159-166.
Spain.Marino, J.
B., R. Banchs, J. M. Crego, A. de Gispert,P.
Lambert, J.
A. Fonollosa and M. Ruiz.
2005.Bilingual n-gram Statistical Machine Translation.In Proceedings of the MT-Summit X, 275?282.Surana, Harshit, and Singh, Anil Kumar.
2008.
AMore Discerning and Adaptable MultilingualTransliteration Mechanism for Indian Languages.In Proceedings of the 3rd International Joint Confe-rence on Natural Language Processing (IJCNLP-08), 64-71, India.Vigra, Paola and Khudanpur, S. 2003.
Transliterationof Proper Names in Cross-Lingual Information Re-trieval.
In Proceedings of the ACL 2003 Workshopon Multilingual and Mixed-Language Named Enti-ty Recognition, 57?60.75
