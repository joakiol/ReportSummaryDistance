Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 118?121,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsDomain Adaptation of Coreference Resolution for Radiology ReportsEmilia Apostolova, Noriko Tomuro, Pattanasak Mongkolwat*, Dina Demner-Fushman?College of Computing and Digital Media, DePaul University, Chicago, IL*Department of Radiology, Northwestern University Medical School, Chicago, IL?Communications Engineering Branch, National Library of Medicine, Bethesda, MDemilia.aposto@gmail.com, tomuro@cs.depaul.edu,p-mongkolwat@northwestern.edu, ddemner@mail.nih.govAbstractIn this paper we explore the applicability ofexisting coreference resolution systems to abiomedical genre: radiology reports.
Analysisrevealed that, due to the idiosyncrasies of thedomain, both the formulation of the problemof coreference resolution and its solution needsignificant domain adaptation work.
We refor-mulated the task and developed an unsuper-vised algorithm based on heuristics for coref-erence resolution in radiology reports.
Thealgorithm is shown to perform well on a testdataset of 150 manually annotated radiologyreports.1 IntroductionCoreference resolution is the process of determin-ing whether two expressions in natural language re-fer to the same entity in the world.
General purposecoreference resolution systems typically cluster allmentions (usually noun phrases) in a document intocoreference chains according to the underlying ref-erence entity.
A number of coreference resolutionalgorithms have been developed for general texts.
Toname a few, Soon et al (2001) employed machinelearning on the task and achieved an F-score of 62.6and 60.4 on the MUC-6 (1995) and MUC-7 (1997)coreference corpora respectively.
Ng et al (2002)improved this learning framework and achieved F-scores of 70.4 and 63.4 respectively on the samedatasets.There are also a number of freely available off-the-shelf coreference resolution modules developedfor the general domain.
For example, BART (Vers-ley et al, 2008) is an open source coreference reso-lution system which provides an implementation ofthe Soon et al algorithm (2001).
The Stanford De-terministic Coreference Resolution System (Raghu-nathan et al, 2010) uses an unsupervised sieve-likeapproach to coreference resolution.
Similarly, theGATE Information Extraction system (Cunninghamet al, 2002) includes a rule-based coreference reso-lution module consisting of orthography-based pat-terns and a pronominal coreferencer (matching pro-nouns to the most recent referent).While coreference resolution is a universal dis-course problem, both the scope of the problem andits solution could vary significantly across domainsand text genres.
Newswire coreference resolutioncorpora (such as the MUC corpus) and general pur-pose tools do not always fit the needs of specific do-mains such as the biomedical domain well.The importance and distinctive characteristics ofcoreference resolution for biomedical articles hasbeen recognized, for example (Castano et al, 2002;Gasperin, 2006; Gasperin et al, 2007; Su et al,2008).
Within the biomedical field, clinical textshave been noted as a genre that needs specializedcoreference corpora and methodologies (Zheng etal., 2011).
The importance of the task for the clini-cal domain has been attested by the 2011 i2b2 NLPshared task (Informatics for Integrating Biology andthe Bedside1) which provided an evaluation plat-form for coreference resolution for clinical texts.However, even within the clinical domain, coref-erence in different sub-genres could vary signifi-1https://www.i2b2.org/NLP/Coreference/118cantly.
In this paper we demonstrate the idiosyn-crasies of the task of coreference resolution in aclinical domain sub-genre, radiology reports, anddescribe an unsupervised system developed for thetask.2 Coreference Resolution for RadiologyReportsRadiology reports have some unique characteristicsthat preclude the use of coreference resolution mod-ules or algorithms developed for the general biomed-ical domain or even for other types of clinical texts.The radiology report is a clinical text used to com-municate medical image findings and observationsto referring physicians.
Typically, radiology reportsare produced by radiologists after examining medi-cal images and are used to describe the findings andobservations present in the accompanied images.The radiology report accompanies an imagingstudy and frequently refers to artifacts present inthe image.
In radiology reports, artifacts presentin the image exhibit discourse salience, and as aresult are often introduced with definite pronounsand articles.
For example, consider the sentenceThe pericardial space is clear.
The definite nounphrase the pericardial space does not represent ananaphoric (or cataphoric) discourse entity and hasno antecedent.
In contrast, coreference resolutionin general texts typically considers definite nounphrases to be anaphoric discourse entities and at-tempts to find their antecedents.Another important distinction between generalpurpose coreference resolution and the coreferenceresolution module needed by an NLP system forclinical texts is the scope of the task.
General pur-pose coreference resolution systems typically clusterall mentions in a document into coreference chains.Such comprehensive mention clustering is often notnecessary for the purposes of clinical text NLP sys-tems.
Biomedical Information Extraction systemstypically first identify named entities (medical con-cepts) and map them to unambiguous biomedicalstandard vocabularies (e.g.
UMLS2 or RadLex3 inthe radiological domain).
While multiple mentionsof the same named entity could exist in a document,2http://www.nlm.nih.gov/research/umls/3http://www.radlex.org/in most cases these mentions were previously as-signed to the same medical concept.
For example,multiple report mentions of ?the heart?
or ?the lung?will normally be mapped to the same medical con-cept and clustering of these mentions into corefer-ence chains is typically not needed.3 Task DefinitionAnalysis revealed that the coreference resolutiontask could be simplified and still meet the needs ofmost Information Extraction tasks relevant to the ra-diological domain.
Due to their nature, texts de-scribing medical image finding and observations donot contain most pronominal references typicallytargeted by coreference resolution systems.
For ex-ample, no occurrence of personal pronouns (e.g.
he,I), possessive pronouns (e.g.
his, my), and indefi-nite pronouns (e.g.
anyone, nobody) was found inthe validation dataset.
Demonstrative pronouns andnon-pleonastic ?it?
mentions were the only pronom-inal references observed in the dataset4.
The fol-lowing examples demonstrate the use of demonstra-tive pronouns and the non-pleonastic ?it?
pronoun(shown in bold):There is prominent soft tissue swelling involvingthe premaxillary tissues.
This measures approxi-mately 15 mm in thickness and extends to the infe-rior aspect of the nose.There is a foreign object in the proximal left main-stem bronchus on series 11 image 17 that was notpresent on the prior study.
It has a somewhat ovoidto linear configuration.Following these observations, the coreference res-olution task has been simplified as follows.
Corefer-ence chains are assigned only for demonstrative pro-nouns and ?it?
noun phrases.
The coreference reso-lution task then involves selecting for each mentiona single best antecedent among previously annotatednamed entities (medical concepts) or the NULL an-tecedent.4 DatasetA total of 300 radiology reports were set aside forvalidation and testing purposes.
The dataset consists4Pleonastic ?it?
refers to its use as a ?dummy?
pronoun, e.g.It is raining, while non-pleonastic use of the pronoun refers toa specific entity.119Figure 1: A sample DICOM image from an imagingstudy described by the following radiology report snip-pet: .
.
.
FINDINGS: Targeted sonography of the upper in-ner left breast was performed.
At the site of palpable ab-normality, at the 11 o?clock position 3 cm from the nipple,there is an oval circumscribed, benign-appearing hypoe-choic mass measuring 2.0 x 1.6 x 1.4 cm.
There is mildinternal blood flow.
It is surrounded by normal appearingglandular breast tissue.. .
.of 100 Computed Tomography Chest reports, 100Ultrasound Breast reports, and 100 Magnetic Res-onance Brain reports, all randomly selected basedon their report types from a dataset of more than100,000 de-identified reports spanning a period of9 years5.
These three types of reports representa diverse dataset covering representative imagingmodalities and body regions.
Figure 1 shows a sam-ple Breast Ultrasound DICOM6 image and its asso-ciated radiology report.The reports were previously tagged (using an au-tomated system) with medical concepts and theirsemantic types (e.g.
anatomical entity, disorder,imaging observation, etc.).
Half of the dataset (150reports) was manually annotated with coreferencechains using the simplified task definition describedabove.
The other half of the dataset was used forvalidation of the system described next.5 Method and ResultsThe coreference resolution task involves selectingfor each mention a single best antecedent amongpreviously annotated named entities or the NULLantecedent.
Mentions are demonstrative pronounphrases or definite noun phrases containing previ-ously annotated named entities.5The collection is a proprietary dataset belonging to North-western University Medical School.6Digital Imaging and Communications in Medicine, c?
TheNational Electrical Manufacturers Association.We implemented an algorithm for the task de-scribed above which was inspired by the work ofHaghighi and Klein (2009).
The algorithm first iden-tifies mentions within each report and orders themlinearly according to the position of the mentionhead.
Then it selects the antecedent (or the NULLantecedent) for each mention as follows:1.
The possible antecedent candidates are first fil-tered based on a distance constraint.
Only mentionsof interest belonging to the preceding two sentencesare considered.
The rationale for this filtering step isthat radiology reports are typically very concise andless cohesive than general texts.
Paragraphs oftendescribe multiple observations and anatomical enti-ties sequentially and rarely refer to mentions moredistant than the preceding two sentences.2.
The remaining antecedent candidates are thenfiltered based on a syntactic constraint: the co-referent mentions must agree in number (singular orplural based on the noun phrase head).3.
The remaining antecedent candidates are thenfiltered based on a semantic constraint.
If the twomentions refer to named entities, the named entitiesneed to have the same semantic category7.4.
After filtering, the closest mention from the setof remaining possible antecedents is selected.
If theset is empty, the NULL antecedent is selected.Pairwise coreference decisions are consideredtransitive and antecedent matches are propagatedtransitively to all paired co-referents.The algorithm was evaluated on the manually an-notated test dataset.
Results (Table 1) were com-puted using the pairwise F1-score measure: preci-sion, recall, and F1-score were computed over allpairs of mentions in the same coreference cluster.Precision Recall F1-score74.90 48.22 58.66Table 1: Pairwise coreference resolution results.The system performance is within the range ofstate-of-the-art supervised and unsupervised coref-erence resolution systems8.
F1-scores could range7The same semantic type in the case of UMLS concepts orthe same parent in the case of RadLex concepts.8Source code for the described system will be made avail-able upon request.120between 39.8 and 67.3 for various methods andtest sets (Haghighi and Klein, 2009).
The simpli-fication of the coreference resolution problem de-scribed above allowed us to focus only on corefer-ence chains of interest to clinical text InformationExtraction tasks and positively influenced the out-come.
In addition, our goal was to focus on highprecision results as opposed to optimizing the over-all F1-score.
This guarantees that coreference reso-lution errors will result in mostly omissions of coref-erence pairs and will not introduce information ex-traction inaccuracies.6 ConclusionIn this paper, we presented some of the challengesinvolved in the task of adapting coreference resolu-tion for the domain of clinical radiology.
We pre-sented a domain-specific definition of the corefer-ence resolution task.
The task was reformulated andsimplified in a practical manner that ensures that theneeds of biomedical information extraction systemsare still met.
We developed an unsupervised ap-proach to the task of coreference resolution of radi-ology reports and demonstrate state-of-the-art preci-sion and reasonable recall results.
The developedsystem is made publicly available to the NLP re-search community.ReferencesJ.
Castano, J. Zhang, and J. Pustejovsky.
2002.
Anaphoraresolution in biomedical literature.
In InternationalSymposium on Reference Resolution.
Citeseer.D.H.
Cunningham, D.D.
Maynard, D.K.
Bontcheva, andM.V.
Tablan.
2002.
GATE: A Framework and Graph-ical Development Environment for Robust NLP Toolsand Applications.C.
Gasperin, N. Karamanis, and R. Seal.
2007.
Annota-tion of anaphoric relations in biomedical full-text arti-cles using a domain-relevant scheme.
In Proceedingsof DAARC, volume 2007.
Citeseer.C.
Gasperin.
2006.
Semi-supervised anaphora resolutionin biomedical texts.
In Proceedings of the Workshopon Linking Natural Language Processing and Biology:Towards Deeper Biological Literature Analysis, pages96?103.
Association for Computational Linguistics.A.
Haghighi and D. Klein.
2009.
Simple coreferenceresolution with rich syntactic and semantic features.In Proceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume 3-Volume 3, pages 1152?1161.
Association for Compu-tational Linguistics.V.
Ng and C. Cardie.
2002.
Improving machine learn-ing approaches to coreference resolution.
In Proceed-ings of the 40th Annual Meeting of the Association forComputational Linguistics, pages 104?111.K.
Raghunathan, H. Lee, S. Rangarajan, N. Chambers,M.
Surdeanu, D. Jurafsky, and C. Manning.
2010.
Amulti-pass sieve for coreference resolution.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, pages 492?501.Association for Computational Linguistics.W.M.
Soon, H.T.
Ng, and D.C.Y.
Lim.
2001.
A ma-chine learning approach to coreference resolution ofnoun phrases.
Computational Linguistics, 27(4):521?544.J.
Su, X. Yang, H. Hong, Y. Tateisi, J. Tsujii, M. Ash-burner, U. Leser, and D. Rebholz-Schuhmann.
2008.Coreference resolution in biomedical texts: a machinelearning approach.
Ontologies and Text Mining forLife Sciences 08.Y.
Versley, S.P.
Ponzetto, M. Poesio, V. Eidelman,A.
Jern, J. Smith, X. Yang, and A. Moschitti.
2008.Bart: A modular toolkit for coreference resolution.
InProceedings of the 46th Annual Meeting of the Asso-ciation for Computational Linguistics on Human Lan-guage Technologies: Demo Session, pages 9?12.
As-sociation for Computational Linguistics.J.
Zheng, W.W. Chapman, R.S.
Crowley, and G.K.Savova.
2011.
Coreference resolution: A review ofgeneral methodologies and applications in the clinicaldomain.
Journal of biomedical informatics.121
