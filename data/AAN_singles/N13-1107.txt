Proceedings of NAACL-HLT 2013, pages 868?877,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsOpen Information Extraction with Tree KernelsYing Xu, Mi-Young Kim, Kevin Quinn, Randy Goebel and Denilson BarbosaDepartment of Computing ScienceUniversity of Alberta{yx2,miyoung2,kfjquinn,goebel,denilson}@cs.ualberta.caAbstractTraditional relation extraction seeks to iden-tify pre-specified semantic relations withinnatural language text, while open InformationExtraction (Open IE) takes a more general ap-proach, and looks for a variety of relationswithout restriction to a fixed relation set.
Withthis generalization comes the question, whatis a relation?
For example, should the moregeneral task be restricted to relations medi-ated by verbs, nouns, or both?
To help answerthis question, we propose two levels of sub-tasks for Open IE.
One task is to determine ifa sentence potentially contains a relation be-tween two entities?
The other task looks toconfirm explicit relation words for two enti-ties.
We propose multiple SVM models withdependency tree kernels for both tasks.
Forexplicit relation extraction, our system can ex-tract both noun and verb relations.
Our resultson three datasets show that our system is su-perior when compared to state-of-the-art sys-tems like REVERB and OLLIE for both tasks.For example, in some experiments our systemachieves 33% improvement on nominal rela-tion extraction over OLLIE.
In addition wepropose an unsupervised rule-based approachwhich can serve as a strong baseline for OpenIE systems.1 IntroductionRelation Extraction (RE) systems are designed todiscover various semantic relations (e.g.
<Obama,president, the United States>) from natural lan-guage text.
Traditional RE systems extract spe-cific relations for prespecified name-entity types(Bunescu and Mooney, 2005; Chan and Dan, 2011;Zhou and Zhu, 2011).
To train such systems, ev-ery relation needs manually annotated training ex-amples, which supports limited scope and is diffi-cult to extend.
For this reason, Banko et al(2007)proposed Open Information Extraction (Open IE),whose goal is to extract general relations for two en-tities.
The idea is to avoid the need for specific train-ing examples, and to extract a diverse range of rela-tions.
This generalized form has received significantattention, e.g., (Banko et al 2007; Akbik, 2009; Wuand Weld, 2010; Fader et al 2011; Mausam et al2012).Because Open IE is not guided by or not restrictedto a prespecified list of relations, the immediate chal-lenge is determining about what counts as a relation?Most recent Open IE systems have targeted verbalrelations (Banko et al 2007; Mausam et al 2012),claiming that these are the majority.
However, Chanand Dan (2011) show that only 20% of relations inthe ACE programs Relation Detection and Charac-terization (RDC) are verbal.
Our manually extractedrelation triple set from the Penn Treebank shows thatthere are more nominal relations than verbal ones,3 to 2.
This difference arises because of the ambi-guity of what constitutes a relation in Open IE.
Itis often difficult even for humans to agree on whatconstitutes a relation, and which words in the sen-tence establish a relation between a pair of entities.For example, in the sentence ?Olivetti broke Cocomrules?
is there a relation between Olivetti and Co-com?
This ambiguity in the problem definition leadsto significant challenges and confusion when eval-uating and comparing the performance of differentmethods and systems.
An example are the resultsin Fader et al(2011) and Mausam et al(2012).
InFader et al(2011), REVERB ?is reported?
as su-868perior to WOEparse, a system proposed in Wu andWeld (2010); while in Mausam et al(2012), it isreported the opposite.To better answer the question, what counts as arelation?
we propose two tasks for Open IE.
Thefirst task seeks to determine whether there is a re-lation between two entities (called ?Binary task?
).The other is to confirm whether the relation wordsextracted for the two entities are appropriate (the?Triple task?).
The Binary task does not restrict re-lation word forms, whether they are mediated bynouns, verbs, prepositions, or even implicit rela-tions.
The Triple task requires an abstract repre-sentation of relation word forms, which we develophere.
We assume that relation words are nouns orverbs; in our data, these two types comprise 71% ofexplicit relations.We adapt an SVM dependency tree kernel model(Moschitti, 2006) for both tasks.
The input to ourtasks is a dependency parse, created by StanfordParser.
Selecting relevant features from a parse treefor semantic tasks is difficult.
SVM tree kernelsavoid extracting explicit features from parse treesby calculating the inner product of the two trees.For the Binary task, our dependency path is the pathbetween two entities.
For the Triple task, the pathis among entities and relation words (i.e.
relationtriples).
Tree kernels have been used in traditionalRE and have helped achieve state of the art perfor-mance (Culotta and Sorensen, 2004; Bunescu andMooney, 2005; Wang, 2008; Nguyen et al 2009;Zhou and Zhu, 2011).
But one challenge of usingtree kernels on Open IE is that the lexicon of re-lations is much larger than those of traditional RE,making it difficult to include the lexical informationas features.
Here we proposed an unlexicalized treestructure for Open IE.
As far as we know, this is thefirst time an SVM tree kernel has been applied inOpen IE.
Experimental results on multiple datasetsshow our system outperforms state-of-the-art sys-tems REVERB and OLLIE.
Typically an Open IEsystem is tested on one dataset.
However, becausethe definition of relation is ambiguous, we believethat is necessary to test with multiple datasets.In addition to the supervised model, we also pro-pose an unsupervised model which relies on severalheuristic rules.
Results with this approach show thatthis simple unsupervised model provides a robuststrong baseline for other approaches.In summary, our main contributions are:?
Use SVM tree kernels for Open IE.
Our sys-tem is robust comparing with other Open IEsystems, achieving superior scores in two testsets and comparative scores in another set.?
Extend beyond verbal relations, which areprevalent in current systems.
Analyze implicitrelation problem in Open IE, which is ignoredby other work.?
Propose an unsupervised model for Open IE,which can be a strong baseline for other ap-proaches.The rest of this paper is organized as follows.
Sec-tion 2 provides the problem description and systemstructure, before summarizing previous work in Sec-tion 3.
Section 4 defines our representation of rela-tion word patterns crucial to our task two, and Sec-tion 5 describes tree kernels for SVM.
Section 6 de-scribes the unsupervised model, and Section 7 ex-plains our experiment design and results.
Section 8concludes with a summary, and anticipation of fu-ture work.2 Problem Definition and SystemStructureThe common definition of the Open IE task is afunction from a sentence, s, to a set of triples,{< E1, R,E2 >}, where E1 and E2 are entities(noun phrases) and R is a textual fragment indicat-ing a semantic relation between the two entities.
Our?Triple task?
is within this definition.
However it isoften difficult to determine which textual fragmentsto extract.
In addition, semantic relations can be im-plicit, e.g., consider the located in relation in the sen-tence fragment ?Washington, US.?
To illustrate howmuch information is lost when restricting the rela-tion forms, we add another task (the ?Binary task?
),determining if there is a relation between the two en-tities.
It is a function from s, to a set of binary rela-tions over entities, {< E1, E2 >}.
This binary taskis designed to overcome the disadvantage of currentOpen IE systems, which suffer because of restrictingthe relation form, e.g., to only verbs, or only nouns.The two tasks are independent to each other.869						 !" "	"	Figure 1: Our Open IE system structure.Figure 1 presents our Open IE system structure.Both tasks need pre-processing with the StanfordNLP tools 1.
Entities and pairs within a certaindistance are extracted2, and sentences are parsed.We employ the typed collapsed dependency parse(De Marneffe et al 2006), which is computed fromthe constituent parsing and has proved to be usefulfor semantic tasks (MacCartney et al 2006).
For theBinary task, an SVM model is employed to filter outthe extracted entity pair candidates, and output pairswhich have certain relations.
For the Triple task, weidentify relation word candidates of the pairs, basedon regular expression patterns.
Then another SVMmodel is employed to decide if the relation triplesare correct or not.3 Related WorkIn traditional relation extraction, SVM tree kernelmodels are the basis for the current state of the art(Culotta and Sorensen, 2004; Bunescu and Mooney,2005; Wang, 2008; Nguyen et al 2009; Zhou andZhu, 2011).
But there is more recent work on OpenIE (Banko et al 2007; Akbik, 2009; Wu and Weld,2010; Christensen et al 2011; Fader et al 2011;Mausam et al 2012).1Other equivalent tools such as Open NLP could be used.2Here distance means number of tokens in between		 Figure 2: Relation Pattern Form (RelW representsrelation words, E1 and E2 are two entities.
)Fader et al(2011) have developed REVERB,which solves the problem of incoherent extractionsand uninformative extractions of two previous sys-tems.
Instead of extracting entities first, they extractverbal relation sequences based on a set of POS pat-terns.
Then entities are identified around the relationsequence, so their system only extracts relation to-kens between two entities tokens, e.g.
relations suchas <he, live in, city> in ?Living in this city, he lovesthe city.?
are ignored.
Finally, relation triple candi-date noise is filtered by a supervised model which isbased on lexical and POS features.Mausam et al(2012) present an improved sys-tem called OLLIE, which relaxes the previous sys-tems?
constraints that relation words are mediated byverbs, or relation words that appear between two en-tities.
OLLIE creates a training set which includesmillions of relations extracted by REVERB withhigh confidence.
Then OLLIE learns relation pat-terns composed of dependency path and lexicon in-formation.
Relations matching the patterns can thenbe extracted.Both REVERB and OLLIE output a confidencevalue for every relation triples, instead of classifyingthem as true or false.4 Relation Candidate ExtractionFor the Triple task, we extract textual fragmentswhich matches certain POS patterns in an entitypair?s context as relation candidates for that pair.In our experiments, the fragments are n-grams withn < 5 and between the pairs or in a window size of10 before the first entity or after the second entity,which is experimentally a good choice to minimizenoise while attaining maximum number of relations.Our representation of POS regular expression pat-870tern sets expands that of Fader et al(2011).
Thepatterns are composed of verb and noun phrases (seeFigure 2).
A relation candidate can consist of wordsbefore, between, or after the pair, or the combina-tion of two consecutive positions.
Instead of ex-tracting only verbal relations (e.g.
give birth to),our patterns also extract relations specified throughnoun phrases.
In the sentence ?Obama, the presidentof the United States, made a speech?
the relation?president?
matches the relational form ?RelW=N,N=noun?.
Our method can also extract relationwords interspersed between the two entities: e.g.,ORG has NUM employees, which matches the pat-tern ?E1 RelW E2 RelW?
; the first RelW matches V,with V=verb, and the second RelW matches N, withN=noun.
We choose not to use the dependency pathfor relation word extraction because of the reasonmentioned in (Fader et al 2011).
The dependencymethod will create incoherent relations.
For exam-ple, in the sentence ?They recalled that Nungesserbegan his career as a precinct leader.?
recall beganwill be extracted as a relation because the two wordsare linked.
Although this pattern based method haslimitations, finding further improvements remainsfuture work.5 Tree KernelsMany methods recognize the value of leveragingparsing information in support of semantic tasks.But selecting relevant features from a parse tree is adifficult task.
With kernel-based SVMs, both learn-ing and classification relies on the inner-product be-tween instances.
SVM tree kernels avoid extract-ing explicit features from parse trees by calculatingthe inner product of the two trees, so the tree kernelvalue depends on the common substructure of twotrees.
A tree kernel function over Tree T1 and T1 isK(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2),NT1 and NT2 are the set of trees?
nodes (Collins andDuffy, 2001).
The ?
function provides the basis foridentifying subtrees of nodes, which is the essentialdistinction between different tree kernel functions.Here we adapt the partial tree kernel (PTK) proposedby Moschitti (2006)3, which can be used with bothconstituent and dependency parse trees.
The com-3Thanks to Prof. Moschitti for his PTK package.         		   		     (a) SDTP         		  		    (b) SDTP2 	(c) GRCT  	(d) unlexicalizedGRCTFigure 3: Example trees for shortest dependencypath between J.P. Bolduc and W.R.Grace Co. in sen-tence ?J.P.
Bolduc, vice chairman of W.R.Grace Co.,comes here.?
Figure (a) is the shortest dependencytree path (SDTP), (b) is the collapsed form, (c) is theGRCT, (d) is an unlexicalized GRCT with ?NE?.putation of ?
function of PTK is(?J1,J2,l(J1)=l(J2)?d(J1)+d(J2)l(J1)?i=1?
(cn1(J1i), cn2(J2i))+?2)?
(1)when the node labels of n1 and n2 are the same,?
= 0 when they are different.
cn1 and cn2 are childsequences of nodes n1 and n2 respectively, J1 =<J11, J12, J13... > and J2 =< J21, J22, J23... > areindex sequences of the two child sequences, J1i andJ2i are the i-th children of the two sequences.
l()means the sequence length, d(J1) = J1l(J1) ?
J11and d(J2) = J2l(J2) ?
J21.
?
and ?
are two decayfactors for the height of the tree and the length of thechild sequences respectively, which we choose thedefault setting in the experiments.
For a more de-tailed description of PTK, please refer to (Moschitti,2006).Now we present our unlexicalized dependency871tree structures for the tree kernel.
One question aris-ing in the conversion dependency structures (e.g.,Figure 3a) for the tree kernel is how should we addPOS tags and dependency link labels?
The kernelcannot process labels on the arcs; they must be as-sociated with tree nodes.
Our conversion is similarto the idea of a Grammatical Relation Centered Tree(GRCT) of Croce et al(2011).
First we order thenodes of dependency trees so that the dominant, i.e.the parent of the dependency link is on the top, thedependent, i.e.
the child at the bottom.
At this stage,the link label is with the corresponding dependentPOS-tag and the word (Figure 3b).
If a dominant hasmore than one child, the children will be ordered ac-cording to their position in the sentence, from left toright.
Next, every node is expanded such that the de-pendent POS-tags are the children of the link labelsand parent of their words.
For example, in Figure 3c,NN is the child of appos, parent of chairman.
It ison the left of prep of because chairman is on the leftof W.R.Grace Co. in the sentence.
As customary inOpen IE, we do not add content words, while func-tion words are optional.
The unlexicalized GRCT isshown in Figure 3d.
Note that for the root node, thelink label is replaced by the POS-tag of the fist nodein the path.Recall that we have two tasks: detecting whetherthere is a relation between two entities (the Binarytask), and whether the relation triple <E1, relation,E2> is correct (the Triplet task).
We define two ex-panded versions of unlexicalized GRCT for the twotasks.
The two versions contain different fragmentsof a dependency tree of a sentence.For the Binary task, the shortest path betweentwo entities?
heads4 is extracted and represented as aGRCT.
The root node is the POS-tag of the fist nodein the path.
?NE?
is used to represent the position oftwo entities while relation words are not specified.Figure 3d shows the example final outcome of ourtree structure.
It is used to decide if there is a rela-tion between the entities Bolduc J.P. and W.R.GraceCo.For the Triple task, we first extract relation wordsbased on regular expression patterns as indicated inSection 4.
If any relation word is between the short-4The head words of phrases are words which do not dependon any words in the phrases.  	(a) Example 1.	  (b) Example 2.Figure 4: Tree structure with ?R?
added.
Figure (a)is the example 1, which has R in the SDTP of theentity pair.
Figure (b) is the example 2, with R notin the SDTP of the entity pair.est path of the two entities, the path is chosen asthe input for SVM.
Otherwise, two shortest pathsbetween two entities and relation words will be ex-tracted separately.
The shortest one will be attachedto the path between two entities.
In our representa-tion, relation words are tagged by having ?R?
as thechild.
Figure 4a shows the path form of the previousexample.
Figure 4b shows another example where?R?
is not in the shortest path of the pair.
The tripleis <United States, president, Obama> for the sen-tence ?United States President Barack Obama saysso.?
The figure on the left is the dependency path.The figure on the right is the final tree for the tripletask.
The root is the POS-tag for Obama.For the Triple task we combine the tree kernelwith a polynomial kernel (Moschitti, 2005) appliedto a feature vector.
The feature set is in Table 1.
F3tries to preserve the semantic link between two dis-continuous relation word segments.
F6 constrainsrelation words to include only necessary preposi-tions.
For verbal relations, if there is a preposi-tion at the end of the relation word sequence, thenthere must be a preposition link between the rela-tion and any of the two entities, and vice versa.
Forinstance, in the sentence ?Bob teaches at the Univer-872sity?
<Bob, teach at, University> is correct while<Bob, teach, University> is wrong.
For nominalrelations, inclusion of the head word is necessary.Prepositions can be ignored, but if they exist, theymust match with the dependency link.
We concen-trate on verb prepositions because prepositions aremore attached to noun phrases than verb phrases.Verb relations have more preposition choices, anddifferent choices have different semantic impact, forexample, the subject or object.
But noun relations?preposition are more fixed, such as ?president of?.The last two features F7 and F8 are added accordingto the observation of experiment results in a develop-ment set: we note that one problem is the appositionor conjunction structure between entities 5.6 Unsupervised MethodWe also propose the use of an unsupervised methodbased on heuristic rules to produce a relation wordnoise filter, as an alternative to using SVM in theTriple task.
The heuristic rules are also based on theStanford collapsed dependency parsing.
There aretwo parts in the noise filter: one is that the relationwords should have necessary links with two entitiesand the other is that relation words should be consis-tent.We first mention the heuristic rules for necessarydependency links.
The intuition is from Chan andDan (2011), they classified relations into 5 differentsyntactic structures; premodifier, possessive, prepo-sition, formulaic, and verbal.
They proposed heuris-tic POS patterns covering the first four patterns withthe exception of the verbal structure.We present heuristic rules based on dependencypaths instead of POS for the structures, except thecategory formulaic, which are implicit relations.
Ina premodifier structure one entity and the relationare modifiers of the other entity, (e.g., US.
Presi-dent Obama).
In a possessive structure one entityis in a possessive case (e.g., Microsoft?s CEO SteveBallmer).
In a preposition structure, relation wordsare related with one entity by a preposition (e.g.,Steve Ballmer, CEO of Microsoft).
In a verbal struc-ture relations are verb phrases.The heuristic rules are presented in Figure 5.
The5But adding the two features seems does not solve the prob-lem.      Figure 5: Dependent link heuristics for relation de-tection.premodifier and possessive relation words are not inthe Stanford collapsed form of the dependency pathbetween two entities.
When there is a direct depen-dency link between two entities that is labelled nnor poss, there should be an nn link between the sec-ond entity and the relation candidate (in Figure 5?stop two rows).
Otherwise, there should be links be-tween the two entities and the relation, respectively(in Figure 5?s last row).
In this case, link types anddirections are not constrained.
For example, bothE1?
(nsubj) R?
(dobj) E2 for the triple <Obama,visit, Canada> in ?Obama visited Canada.?
and E1?
(appos) R?
(prep of) E2 for the triple <Obama,president, United States> in ?Obama, the presidentof the United States, visited Canada.?
belong to thatstructure.
To refine the verbal pattern, the link be-tween the relation words and entities cannot be aconjunction.Next, we need to check the consistency of relationwords.
Two separated sequences of relation wordsshould have a dependency link between each otherto confirm that they are semantically related.
Rela-tion sequences should include only necessary prepo-sitions.7 ExperimentsWe compared the unsupervised heuristic rulemethod and the supervised SVM method discussedabove against REVERB (Fader et al 2011) and OL-LIE (Mausam et al 2012), using three datasets.
Onedataset consists of sentences from the Penn Tree-bank, and the other two are the experiment datasetsof each of the two systems being compared.873E feature F1 the dependency link label between two entities, null if none.R features F2 whether relation is a noun phrase or a verb phraseF3 whether there is a link between the two segments (if there are two discontinuous segments)between E and R F4 whether there is a link between entities and the relationF5 the shortest dependency path distance between entities and the relation (1,2,3,4, or >4)F6 the preposition link and the last preposition word of relation (if there is such a link or word)F7 whether there is a conjunction link in the shortest path between entities and the relationF8 whether there is a apposition link in the shortest path between entities and the relationTable 1: Noise filter feature vector.7.1 Treebank Set7.1.1 Preparing DataWithin the research community, it is difficult tofind Open IE test data which includes all kinds ofrelations.
So we have created our own data from thePenn Treebank for evaluation6.
We assess the dropin performance introduced by using a tool to parsesentences compared to using ?ideal?
parse trees pro-vided in the Penn Treebank.
Named entities aretagged for every sentence using the Stanford NLPtool.
Candidate NE pairs are extracted within a cer-tain distance7.
We randomly selected 756 sentencesfromWSJ Sections 2-21 as our training set, 100 eachfrom Section 22 and Section 23-24 as the develop-ment and the test set, respectively.
This is also thesetting for most parsers.We manually annotated whether there is a relationbetween two entities in a sentence (for evaluationof the Binary task).
If there is a relation betweentwo entities, the annotator needs to indicate whichwords are relation words (for evaluation of the Tripletask).
There is no restriction of relation forms for theannotator in this task.We manually analyzed 417 relation instancesfrom our training set.
28% are implicit relations, i.e.,relations without words or with prepositions.
Lessthan 1% are with adjectives, while 71% are noun orverb phrases.
In the 71%, 60% are noun relationsand 40% are verbal.
The relation pattern in Section4 can extract 80% of them.
Our data contains moreverbal relations than the ACE?s RDC, less than cor-pora in other Open IE papers.We compare every system by recall, precision,and F-score.
The evaluation of the Binary task is6The data can be downloaded from http://cs.ualberta.ca/?yx2/7Here we set the distance as 20, determined by empiricalevidence, a majority of the relations are within this distance.based on entity pairs and is straightforward.
Theevaluation of the Triple task is based on relationtriples.
We need to manually compare the triplesextracted by each system and the gold standard toavoid double-counting.
For instance, if both vicepresident and president are extracted, it is countedas one8.
Several entity pairs have multiple relations,such as ?A is CEO and founder of B.?
Any relationwhich can not be represented by a verb or noun iscounted as one miss in the Triple task.To compare with the REVERB system, NE pairsare labelled as two noun phrase chunks for the sys-tem input.
It is difficult to compare with OLLIE,as the system is a black box with integrated entityextraction and parsing.
We compared manually thepairs extracted by OLLIE and the tagged data.
Onlyresults of intersection entity pairs are considered.The threshold of OLLIE and REVERB confidenceis set to achieve the best F-score in the developmentset.7.1.2 ResultsThe Binary task results on the test set are shownin Table 2.
Each system decides whether there isa relation between two entities.
The heuristic rule(DP rules) method, REVERB, and OLLIE each tagpairs containing a relation if any relation candidatesare identified.
As indicated, the SVM method per-forms the best with DP rules ranking second.
Notethat OLLIE uses MaltParser, so it?s better to com-pare with the coupling of SVMwith Stanford Parser,but that comparison doesn?t change the result.The Triple task results are shown in Table 3.
Eachsystem extracts relation triples from sentences.
TheSVM features include both tree (Figure 4) and vectorfeatures (Table 1).
All relations in the table includenominal, verbal, and implicit relations.
To scrutinize8It is difficult to decide if president in this case is wrong.This is related to multi-word expression and will be future work.874P R F-scoreTreebank parsing + DP rules 0.833 0.549 0.662Treebank parsing + SVM 0.896 0.767 0.826Stanford parsing + DP rules 0.783 0.522 0.627Stanford parsing + SVM 0.744 0.711 0.727REVERB (no parsing) 0.333 0.1 0.153OLLIE (MaltParser) 0.583 0.389 0.467Table 2: Relation extraction results on Treebank set(Binary)All relations P R F-scoreTreebank parsing + DP rules 0.741 0.467 0.573Treebank parsing + SVM 0.824 0.462 0.592Stanford parsing + SVM 0.75 0.433 0.549OLLIE (MaltParser) 0.583 0.389 0.467Noun relations P R F-scoreTreebank parsing + DP rules 0.75 0.735 0.742Treebank parsing + SVM 0.829 0.708 0.764Stanford parsing + SVM 0.756 0.
689 0.721OLLIE (MaltParser) 0.8 0.408 0.54Verb relations P R F-scoreTreebank parsing + DP rules 0.7 0.368 0.483Treebank parsing + SVM 0.727 0.381 0.5Stanford parsing + SVM 0.727 0.32 0.444REVERB (no parsing) 0.286 0.381 0.327OLLIE (MaltParser) 0.429 0.714 0.536Table 3: Relation extraction results on Treebank set(Triple)the result, we also show the results on noun and verbrelations separately.
The SVM model achieves bestperformance, 33% improvement on nominal relationextractions over OLLIE.The loss of recall for systems (except SVM) in theBinary task can be explained by the fact that nearly20% of relations are implicit.In both the Binary and Triple tasks, one source offailure arose from conjunction and apposition struc-tures.
For example, in the sentence ?...industry ex-ecutives analyzed the appointment of the new chiefexecutive, Robert Louis-Dreyfus, who joins Saatchi...?
the method can detect the relation <chief ex-ecutive, joins, Saatchi>, but not <Robert Louis-Dreyfus, joins, Saatchi>.
We attempted to addressthis problem by adding features into SVM linear ker-nel (Table 1), but this has not worked in our tests.One cause of recall loss in the Triple task for RE-VERB and our two approaches is that verbal rela-tion words can be non-consecutive.
For instance, thepreposition might be far away from the related verbin one sentence, in which case both our methods andREVERB can not confirm that extraction.
OLLIEP R F-scoreStanford parsing + DP rules 0.711 0.811 0.756Stanford parsing + SVM 0.718 0.859 0.781REVERB 0.577 0.95 0.716Table 4: Relation extraction results on REVERB set(Triple).has better results on verb relations mainly becausethey use dependency link patterns to extract relationwords, which alleviate the problem.
On the otherside, one drawback of OLLIE is that it failed to ex-tract a few premodifer structure relations, e.g.
?U.S.President Obama.?
That may happen because theydo not have an independent step for named entityextraction, which is crucial for that type of relations.7.2 REVERB SetThe authors of the REVERB method provide 1000tagged training sentences and 500 test sentences.They also provide REVERB?s extracted relationsand instances?
confidence for the 500 test sentences.The 500 test sentences are segmented into 5 folds fora significance t-test.
At each iteration, the remaining400 sentences are used as a development set to setthe threshold of REVERB confidence.To compare with REVERB, we use as input thesentences parsed by the Stanford parser and rela-tion triples extracted by REVERB for both train-ing and testing.
The output of our system is trueor false for every triple by using the tree kernel9.The SVM system is trained on the 1000 training sen-tences.
The results are shown in Table 4.
Only SVMis statistically significant better than REVERB (with?
= 0.05)10.7.3 OLLIE setThe authors of the OLLIE system provide a test setwhich has 300 sentences and OLLIE extracted 900triples.
Experiment setting is similar to that of RE-VERB set.
The SVM tree kernel model is trained onOLLIE?s leave one out dataset.
The results in Table9The polynomial kernel is not used for REVERB and OL-LIE data as the their relation word form is simpler than ours.10Note that the results here seem better than the results shownon (Fader et al 2011).
It is because our evaluation is based onthe set REVERB extracted, as we only want to compare noisefilters not with entity extraction, while the results in (Fader etal., 2011) is based on the union relation set of several systems.875P R F-scoreStanford parsing + SVM 0.685 0.941 0.793OLLIE 0.667 0.961 0.787Table 5: Relation extraction results on OLLIE set(Triple).5 show our method achieves slightly better perfor-mance, although not statistically significant.Besides errors caused by parsing, one main causeof loss of precision is that our system is unable todetect entities that are wrong as we only concern thehead of the entity.
For instance, ?Bogan ?s Birming-ham Busters , before moving to Los Angeles , Cal-ifornia?
is one entity in one OLLIE relation, whereonly ?Bogan ?s Birmingham Busters?
is the correctentity.8 ConclusionWe have described some of the limits of currentOpen IE systems, which concentrate on identifyingexplicit relations, i.e., relations which are mediatedby open class words.
This strategy ignores what wedescribe as implicit relations, e.g., locate relationsin ?Washington, U.S.?
We propose two subtasks forOpen IE: first confirming whether there is a rela-tion between two entities, and then whether a rela-tion thus extracted is correct.
The first task includeboth implicit and explicit relations; the second taskis common in the previous Open IE which deals withexplicit relations.
In our case we have developed anOpen IE system which uses SVM tree kernels ap-plied to dependency parses for both tasks.
Our sys-tem achieves superior results on several datasets.
Wealso propose an unsupervised method which is basedon heuristic rules from dependency parse links, andcompared that with our SVM tree kernel methods.Our experiments show it is a strong baseline forOpen IE.For further work, we intend to improve Open IEby tackling the conjunction and apposition structureproblem.
Another direction will be to extract re-lation words for implicit relations.
Relation wordssuch as locate for ?Washington, U.S.?
will be con-sidered.AcknowledgmentsWe would like to acknowledge Prof. Grzegorz Kon-drak ?s valuable advice.
We also want to thank theanonymous reviewers for their helpful suggestions.This work was funded in part by the NSERC Busi-ness Intelligence Network, Alberta Innovates Centerfor Machine Learning (AICML) and Alberta Inno-vates Technology Futures (AITF).ReferencesAlan Akbik.
2009.
Wanderlust : Extracting semanticrelations from natural language text using dependencygrammar patterns.
In WWW 2009 Workshop on Se-mantic Search, volume 137, pages 279?290.Michele Banko, Michael J Cafarella, Stephen Soderl,Matt Broadhead, and Oren Etzioni.
2007.
Openinformation extraction from the web.
In In Inter-national Joint Conference on Artificial Intelligence,pages 2670?2676.Razvan C. Bunescu and Raymond J. Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In Proceedings of the conference on HumanLanguage Technology and Empirical Methods in Nat-ural Language Processing, HLT ?05, pages 724?731,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Yee Seng Chan and Roth Dan.
2011.
Exploitingsyntactico-semantic structures for relation extraction.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies - Volume 1, HLT ?11, pages 551?560, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Janara Christensen, Mausam, Stephen Soderland, andOren Etzioni.
2011.
An analysis of open informa-tion extraction based on semantic role labeling.
InProceedings of the sixth international conference onKnowledge capture, K-CAP ?11, pages 113?120, NewYork, NY, USA.
ACM.Michael Collins and Nigel Duffy.
2001.
Convolutionkernels for natural language.
In Advances in NeuralInformation Processing Systems 14, pages 625?632.MIT Press.Danilo Croce, Alessandro Moschitti, and Roberto Basili.2011.
Structured lexical similarity via convolutionkernels on dependency trees.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?11, pages 1034?1046,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.876Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedings ofthe 42nd Annual Meeting on Association for Compu-tational Linguistics, ACL ?04, Stroudsburg, PA, USA.Association for Computational Linguistics.M.C.
De Marneffe, B. MacCartney, and C.D.
Manning.2006.
Generating typed dependency parses fromphrase structure parses.
In Proceedings of LREC, vol-ume 6, pages 449?454.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open informationextraction.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?11, pages 1535?1545, Stroudsburg, PA,USA.
Association for Computational Linguistics.Bill MacCartney, Trond Grenager, Marie-Catherinede Marneffe, Daniel Cer, and Christopher D. Man-ning.
2006.
Learning to recognize features of validtextual entailments.
In Proceedings of the main con-ference on Human Language Technology Conferenceof the North American Chapter of the Association ofComputational Linguistics, HLT-NAACL ?06, pages41?48.
Association for Computational Linguistics.Mausam, Michael Schmitz, Robert Bart, Stephen Soder-land, and Oren Etzioni.
2012.
Open language learn-ing for information extraction.
In Proceedings of the2012 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning, pages 523?534.
Association forComputational Linguistics.Alessandro Moschitti.
2005.
Automatic text catego-rization: from information retrieval to support vectorlearning.
Aracne.Alessandro Moschitti.
2006.
Efficient convolution ker-nels for dependency and constituent syntactic trees.In Proceedings of the 17th European conference onMachine Learning, ECML?06, pages 318?329, Berlin,Heidelberg.
Springer-Verlag.Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structures forrelation extraction.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing: Volume 3 - Volume 3, EMNLP ?09, pages1378?1387, Stroudsburg, PA, USA.
Association forComputational Linguistics.Mengqui Wang.
2008.
A re-examination of dependencypath kernels for relation extraction.
In Proceedings ofthe Third International Joint Conference on NaturalLanguage Processing, pages 841?846, Hyderabad, In-dia.
Asian Federation of Natural Language Processing,Association for Computational Linguistics.Fei Wu and Daniel S. Weld.
2010.
Open information ex-traction using wikipedia.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, ACL ?10, pages 118?127, Stroudsburg,PA, USA.
Association for Computational Linguistics.Guo-Dong Zhou and Qiao-Ming Zhu.
2011.
Kernel-based semantic relation detection and classification viaenriched parse tree structure.
J. Comput.
Sci.
Technol.,26(1):45?56, January.877
