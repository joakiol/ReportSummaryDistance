Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 34?41,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsReordering rules for English-Hindi SMTRaj Nath Patel, Rohit Gupta, Prakash B. Pimpale and Sasikumar MCDAC Mumbai, Gulmohar Cross Road No.
9,Juhu, Mumbai-400049India{rajnathp,rohitg,prakash,sasi}@cdac.inAbstractReordering is pre-processing stage for Statisti-cal Machine Translation (SMT) system wherethe words of the source sentence are re-ordered as per the syntax of the target lan-guage.
We are proposing a rich set of rules forbetter reordering.
The idea is to facilitate thetraining process by better alignments and par-allel phrase extraction for a phrase based SMTsystem.
Reordering also helps the decodingprocess and hence improving the machinetranslation quality.
We have observed signifi-cant improvements in the translation qualityby using our approach over the baseline SMT.We have used BLEU, NIST, multi-referenceword error rate, multi-reference position inde-pendent error rate for judging the improve-ments.
We have exploited open source SMTtoolkit MOSES to develop the system.1 IntroductionThis paper describes syntactic reordering rules toreorder English sentences as per the Hindi lan-guage structure.
Generally in reordering ap-proach, the source sentence is parsed(E) and syn-tactic reordering rules are applied to form reor-dered sentence(E`).
The training of SMT systemis performed using parallel corpus having sourceside reordered(E`) and target side.
The decodingis done by supplying reordered source sentences.The source sentences prior to decoding are reor-dered using the same syntactic rules as appliedfor the training data.
So, this process works as apreprocessing stage for the phrase-based SMTsystem.
It has been observed that reordering as apre-processing stage is beneficial for developingEnglish-Hindi phrase based SMT system (Rama-nathan et al 2008; Rama et al 2008).
This pa-per describes a rich set of rules for the structuraltransformation of English sentence to Hindi lan-guage structure using Stanford (De et al 2006)parse tree on source side.
These rules are manu-ally extracted based on analysis of source sen-tence tree and Hindi translation.For the evaluation purpose we have trainedand evaluated three different phrase based SMTsystems using MOSES toolkit (Koehn et al2007) and GIZA++(Och and Ney, 2003).
Thefirst system was non-reordered baseline (Brownet al 1990; Marcu and Wong, 2002; Koehn etal., 2003), second using limited reordering de-scribed in Ramanathan et al(2008) and thirdusing improved reordering technique proposed inthe paper.
Evaluation has been carried out forend to end English-Hindi translation outputs us-ing BLEU score (Papineni et al 2001), NISTscore (Doddington, 2002), multi-reference posi-tion-independent word error rate (Tillmann et al1997), multi-reference word error rate (Nie?en etal., 2000).
We have observed improvement ineach of these evaluation metrics used.
Next sec-tion discusses related work.
Section 3 describesour reordering approach followed by experi-ments and results in section 4 and conclusion insection 5.2 Related WorkVarious pre-processing approaches have beenproposed for handling syntax within SMT sys-tems.
These proposed methods reconcile theword-order differences between the source andtarget language sentences by reordering thesource prior to the SMT training and decodingstages.
For English-Hindi statistical machinetranslation reordering approach is used by Ra-manathan et al(2008) and Rama et al(2008).This approach (Ramanathan et al2008) hasshown significant improvements over baseline(Brown et al 1990; Marcu and Wong, 2002;Koehn et al 2003).
The BLEU score for the sys-tem has increased from 12.10 to 16.90 after reor-dering.
The same reordering approach (Rama-nathan et al 2008) used by us has shown slightimprovement in BLEU score of 0.64 over base-line i.e.
BLEU score increased from 21.55 to3422.19 compare to +4.8 BLEU point increase inthe previous case.
The reason can be, when thesystem is able to get bigger chunks from thephrase table itself the local reordering (withinphrase) is not needed and the long distance reor-dering employed in the earlier approach will behelpful for overall better translation.
It may notbe able to show significant improvements whenlocal reordering is not captured by the translationmodel.Other language pairs have also shown signifi-cant improvement when reordering is employed.Xia and Mc-Cord (2004) have observed im-provement for French-English and Chao et al(2007) for Chinese-English language pairs.Nie?en and Ney (2004) have proposed sentencerestructuring whereas Collins et al(2005) haveproposed clause restructuring to improve Ger-man-English SMT.
Popovic and Ney (2006)have also reported the use of simple local trans-formation rules for Spanish-English and Serbian-English translation.Recently, Khalilov and Fonollosa (2011) pro-posed a reordering technique using deterministicapproach for long distance reordering and non-deterministic approach for short distance reorder-ing exploiting morphological information.
Somereordering approaches are also presented exploit-ing the SMT itself (Gupta et al 2012; Dlougachand Galinskaya, 2012).Various evaluation techniques are availablefor reordering and overall machine translationevaluation.
Particularly for reordering Birch andOsborne (2010) have proposed LRScore, a lan-guage independent metric for evaluating the lexi-cal and word reordering quality.
The translationevaluation metrics include BLEU (Papineni et.al., 2002), Meteor (Lavie and Denkowski, 2009),NIST (Doddington, 2002), etc.3 Reordering approachOur reordering approach is based on syntactictransformation of the English sentence parse treeaccording to the target language (Hindi) struc-ture.
It is similar to Ramanathan et al(2008) butthe transformation rules are not restricted to?SVO to SOV?
and ?pre-modifier to post-modifier?
transformations only.The idea was to come up with generic syntac-tic transformation rules to match the target lan-guage grammatical structure.
The motivationcame from the fact that if words are already in acorrect place with respect to other words in thesentence, system doesn?t need to do the extrawork of reordering at the decoding time.
Thisproblem becomes even more complicated whensystem doesn?t able to get bigger phrases fortranslating a sentence.
Assuming an 18 wordssentence, if system is able to get only 2 wordlength phrases, there are 362880(9!)
translations(permutations) possible (still ignoring the casewhere one phrase having more than one transla-tion options) for a sentence.The source and the target sentences are manu-ally analyzed to derive the tree transformationrules.
From the generated set of rules we haveselected rules which seemed to be more generic.There are cases where we have found more thanone possible correct transformations for an Eng-lish sentence as the target language (Hindi) is afree word order language within certain limits.
Insuch cases word order close to English structureis preferred over possible word orders with re-spect to Hindi.We identified 5 categories which are mostprominent candidates for reordering.
These in-clude VPs (verb phrases), NPs (noun phrases),ADJPs (adjective phrase), PPs (prepositionphrase) and ADVPs (adverb phrase).
In the fol-lowing subsections, we have described rules forthese in more detail.Tag Description(Penn tags)dcP   Any, parser generated phrasepp  Prepositional Phrase(PP)whP WH Phrase(WHNP,WHADVP, WHADJP, WHPP)vp Verb Phrase(VP)sbar Subordinate clause(SBAR)np Noun phrase(NP)vpw Verb words(VBN, VBP, VB,VBG,MD, VBZ, VBD)prep Preposition words(IN,TO,VBN,VBG)adv Adverbial words(RB, RBR, RBS)adj Adjunct word(JJ,JJR,JJS)advP Adverb phrase(ADVP)punct Punctuation(,)adjP Adjective phrase(ADJP)OP  advP, np and/or ppTag* One or more occurrences of TagTag?
Zero or one occurrence of TagTable 1: Tag descriptionThe format for writing the rules is as follows:Type_of_phrase(tag1 tag2 tag 3: tag2 tag1 tag3)35This means that ?tag1 tag2 tag3?, structurehas been transformed to ?tag2 tag1 tag3?
for thetype_of_phrase.
This type_of_phrase denotes ourcategory (NP, VP, ADJP, ADVP, PP) in whichrule fall.
The table given above explains aboutvarious tags and corresponding Penn tags used inwriting these rules.The following subsections explain the reorder-ing rules.
The higher precedence rule is writtenprior to the lower precedence.
In general themore specific rules have high precedence.
Eachrule is followed by an example with intermediatesteps of parsing and transformation as per theHindi sentence structure.
?Partial Reordered?shows the effect of the particular rule whereas?Reordered?
shows impact of the whole reorder-ing approach.
The Hindi (transliterated) sentenceis also provided as a reference for the corre-sponding English sentence.3.1 Noun Phrase RulesNP (np1 PP[ prep NP[ np2 sbar]] : np2 prepnp1 sbar)            (1)English: The time of the year when naturedawns all its colorful splendor, is beautiful.Parse: [NP (np1 the time) [PP (prep of) [NP(np2 the year) (sbar when nature dawns all itscolorful splendor)]]] , is beautiful .Partial Reordered: (np2 the year) (prep of)(np1 the time) (sbar when nature dawns all itscolorful splendor) , is beautiful .Reordered: (np2 the year) (prep of) (np1 thetime) (sbar when nature all its colorful splendordawns) , beautiful is .Hindi: varsh ka samay jab prakriti apne sabhirang-birange vabahv failati hai, sundar hai .NP(np SBAR[ S[ dcP ]] :dcP  np)        (2)English: September to march is the best sea-son to visit Udaipur.Parse: September to March is [NP (np thebest season) [SBAR [S (dcP to visit Udaipur)]]] .Partial Reordered: September to March is(dcP to visit Udaipur) (np the best season) .Reordered: September to March (dcP Udai-pur visit to) (np the best season) is .Hindi: september se march udaipur ghumaneka sabse achcha samay hai .NP(np punct advP : advP punct np)                (3)English: The modern town of Mumbai,about 50 km south of Navi Mumbai is Khar-ghar.Parse: The modern town of [NP (np Mumbai)(punct ,) (advP about 50 km south of NaviMumbai)] is Kharghar .Partial Reordered: (advP about 50 kmsouth of Navi Mumbai)) (punct ,) (dcP Themodern town of Mumbai) is kharghar .Reordered: (advP Navi Mumbai of about 50km south) (punct ,) (dcP Mumbai of the moderntown) kharghar is .Hindi: navi mumbai ke 50 km dakshin memumbai ka adhunic sahar kharghar hai .NP( np  vp : vp np)                                           (4)English: The main attraction is a divine treecalled as 'Kalptaru'.Parse: The main attraction is [NP (np a divinetree) (vp called as 'Kalptaru') ] .Partial Reordered: The main attraction is (vp` called as 'Kalptaru') (np a divine tree) .Reordered: The main attraction (vp ` Kalptaru' as called) (np a divine tree) is .Hindi: iska mukhya akarshan kalptaru namakek divya vriksh hai .3.2 Verb Phrase RulesVP( vpw PP [ prep NP[ np  punct?
SBAR[ whPdcP ]]] : np prep vpw punct?
whP dcP)          (5)English: The best time to visit is in the after-noon when the crowd thins out.Parse: The best time to visit [VP (vpw is) PP[(prep in) NP[ (np the afternoon) [SBAR (whPwhen) (dcP the crowd thins out)]]] .Partial Reordered: The best time to visit (npthe afternoon) (prep in) (vpw is) (whP when)(dcP the crowd thins out) .Reordered: visit to The best time (np the af-ternoon) (prep in) (vpw is) (whP when) (dcP thecrowd thins out) .Hindi: bhraman karane ka sabase achchasamay dopahar me hai jab bhid kam ho jati hai .VP( vpw NP[ np punct?
SBAR[ whP dcP ]] : npvpw punct?
whP dcP)                                       (6)English: Jaswant Thada is a white marblemonument which was built in 1899 in thememory of Maharaja Jaswant Singh II.Parse: jaswant thada [VP (vpw is) [NP (np awhite marble monument) [SBAR (whP which)(dcP was built in 1899 in the memory of Maha-raja Jaswant Singh II)]] .Partial Reordered: Jaswant Thada (np awhite marble monument) (vpw is) (whP which)(dcP was built in 1899 in the memory of Maha-raja Jaswant Singh II) .36Reordered: Jaswant Thada (np a white mar-ble monument) (vpw is) (whP which) (dcP Ma-haraja Jaswant Singh II of the memory in 1899 inbuilt was) .Hindi: jaswant thada ek safed sangmarmar kasmarak hai jo ki maharaja jaswant singh dwitiyaki yad me 1889 me banwaya gaya tha .VP(vpw OP sbar : OP vpw sbar )        (7)English: Temples in Bhubaneshwar are builtbeautifully on a common plan as prescribed byHindu norms.Parse: Temples in Bhubaneshwar are [VP(vpw built) (advP beautifully) (pp on a commonplan) (sbar as prescribed by Hindu norms)] .Partial Reordered: Bhubaneshwar in Tem-ples are (advP beautifully) (pp a common planon) (vpw built) (sbar as prescribed by Hindunorms) .Reordered: Bhubaneshwar in Temples (advPbeautifully) (pp a common plan on) (vpw built)are (sbar as Hindu norms by prescribed) .Hindi: bhubaneswar ke mandir hindu niya-mon dwara nirdharit samanya yojana ke anusarbanaye gaye hain .VP(vpw pp1 pp*2: pp*2 pp1 vpw)                  (8)English: Avalanche is located at a distanceof 28 Kms from Ooty.Parse: Avalanche is [VP (vpw located) (pp1 ata distance of 28 kms) (pp2 from Ooty)] .Partial Reordered: Avalanche is (pp2 fromOoty) (pp1 at a distance of 28 kms) (vpw locat-ed) .Reordered: Avalanche (pp2 Ooty from ) (pp128 kms of a distance at) (vpw located) is .Hindi: avalanche ooty se 28 km ki duri parsthit hai .VP(vpw np pp : np pp vbw)         (9)English: Taxis and city buses available out-side the station, facilitate access to the city.Parse: Taxis and city buses available outsidethe station , [VP (vpw facilitate) (np access) (ppto the city)] .Partial Reordered: Taxis and city busesavailable outside the station , (pp to the city) (npaccess) (vpw facilitate) .Reordered: Taxis and city buses the stationoutside available , (pp the city to) (np access)(vpw facilitate) .Hindi: station ke baahar sahar jane  ke liyetaksi aur bus ki suvidha upalabdha hai .VP ( prep dcP : dcP prep)        (10)English: A wall was built to protect it.Parse: A wall was built [VP (prep to) (dcPprotect it)] .Partial Reordered: A wall was built (protectit) (prep to) .Reordered: A wall (dcP it protect) (prep to)built was .Hindi: ek diwar ise surakshit karane ke liyebanayi gayi thi .VP(adv vpw dcphrase: dcphrase adv vpw)    (11)English: Modern artist such as French sculp-tor Bartholdi is best known by his famouswork.Parse: Modern artists such as French sculptorBartholdi is [VP (adv best) (vpw known) (dcP byhis famous work)] .Partial Reordered: Modern artists such asFrench sculptor Bartholdi is (dcP by his famouswork) (adv best) (vpw known) .Reordered: such as French sculptor BartholdiModern artists (dcP his famous work by) (advbest) (vpw known) is .Hindi: french shilpkar bartholdi jaise aa-dhunik kalakar apane prashidha kam ke liyevishesh rup se jane jate hain .VP(advP vpw dcP: advP dcP vpw)           (12)English: Bikaner, popularly known as thecamel county is located in Rajasthan.Parse: Bikaner , [VP (advP popularly) (vpwknown) (dcP as the camel country)] is located inRajsthan .Partial Reordered: Bikaner , (advP popular-ly) (dcP as the camel country) (vpw known) islocated in Rajsthan .Reordered: Bikaner , (advP popularly) (dcPthe camel country as) (vpw known) Rajsthan inlocated is .Hindi: bikaner , jo aam taur par unton kedesh ke naam se jana jata hai, rajasthan me sthithai .VP(vpw adv?
adjP?
dcP: dcP adjP?
adv?
vpw)(13)English: This palace has been beautiful frommany years.Parse: This palace has [VP (vpw been) (adjPbeautiful) (dcP from many years)] .Partial Reordered: This palace has (dcPfrom many years) (adjP beautiful) (vpw been) .Reordered: This palace (dcP many yearsfrom) (adjP beautiful) (vpw been) has .Hindi: yah mahal kai varson se sunder rahahai .373.3 Adjective and Adverb Phrase RulesADJP( vpw pp : pp vpw )        (14)English: The temple is decorated with paint-ings depicting incidents.Parse: The temple is [ADJP (vpw decorated)(pp with paintings depicting incidents )] .Partial Reordered: The temple is (pp withpaintings depicting incidents) (vpw decorat-ed) .Reordered: The temple (pp incidents depict-ing paintings with) (vpw decorated) is .Hindi: mandir ghatnao ko darshate hue chit-ron se sajaya gya hai .ADJP( adjP pp : pp adjP )        (15)English: As a resul, temperatures are nowhigher than ever before .Parse: As a result , temperatures are now[ADJP (adjP higher) (pp than ever)] before .Partial Reordered: As a result , temperaturesare now (pp than ever) (adj higher) before .Reordered: a result As , temperatures nowbefore (pp ever than) (adj higher) are .Hindi: parinam swarup taapman ab pahle sebhi adhik hai .ADJP( adj dcP : dcP adj )        (16)English: The Kanha National park is open tovisitors.Parse: The Kanha National park is [ADJP(adj open) (dcP to visitors)] .Partial Reordered: The Kanha National parkis (pp to visitors ) (adj open)  .Reordered: The Kanha National park (pp vis-itors to) (adj open) is .Hindi: kanha national park paryatakon ke liyekhula hai .ADVP( adv dcP: dcP adv )        (17)English: The temple is most favored spot fortourists apart from the pilgrims.Parse: The temple is most favored spot fortourists [ADVP (adv apart) (dcP from the pil-grims)] .Partial Reordered: The temple is most fa-vored spot for tourists (dcP from the pilgrims )(adv apart)  .Reordered: The temple most favored spot(dcP the pilgrims from) (adv apart) is .Hindi: mandir teerth yatriyon ke alawa par-yatkon ke liye bhi lokpriya sthal hai .3.4 Preposition Phrase RulesPP( adv prep?
dcP : dcP prep?
adv )       (18)English: Does kalajar occur because of sun?Parse: Does kalajar occur [PP (adv because)(prep?
of) (dcP sun)] ?Partial Reordered: Does kalajar occur (dcpsun) (prep?
of) (adv because) ?Reordered: Does kalajar (dcp sun) (prep?
of)(adv because) occur?Hindi: kya kalajar dhup ke karan hota hai ?input Ahmedabad was named after the sultan Ahmed Shah, who built the city in 1411.baseline ahmedabad was named after the sultan ahmed shah, who built the city in 1411.????????
??
???
??
???
???
???????
????
shah, ????
???
1411.ahamdabad ke nam par rakha gaya sultan ahamad shah, wale shahar 1411.limited re-orderingahmedabad the sultan ahmed shah , who the city 1411 in built after named was .????????
??
???
???????
???????
??
, ?????
????
???
???
??????
??
???
?????
???
??
?ahamdabad ka nam sultan ahamadshah ke , jisane 1411 me shahar banawaya kenam par rakha gaya tha .our ap-proachahmedabad the sultan ahmed shah after named was , who 1411 in the city built .????????
??
???
???????
???????
??
???
??
???
??
?????
????
???
?????????
??
?ahamadabad ka nam sultan ahamadshah ke nam se pada tha jisane 1411 me sha-har banawaya tha .reference ????????
??
???
???????
???????
??
???
??
???
?
?, ?????
????
???
?????????
??
?ahamadabad ka nam sultan ahamadshah ke nam par pada tha jisane 1411 meshahar banawaya tha .Table 2: Comparison of translation on a sentence from test corpus384 Experiments and ResultsThe experiments were carried out on the corpusdescribed in Table 3 below.#Sentences #WordsTraining 94926 1235163Tuning 1446 23600Test 500 9792Table 3: Corpus distributionThe baseline system was setup by using thephrase-based model (Brown et al 1990; Marcuand Wong, 2002; Koehn et al 2003).
For thelanguage model, we carried out experiments andfound on comparison that 5-gram model withmodified Kneser-Ney smoothing (Chen andGoodman, 1998) to be the best performing.
Tar-get Hindi corpus from the training set was usedfor creating the language model.
The KenLM(Heafield., 2011) toolkit was used for the lan-guage modeling experiments.
The tuning corpuswas used to set weights for the language models,distortion model, phrase translation model etc.using minimum error rate training (Och, 2003).Decoding was performed using the MOSES de-coder.
Stanford constituency parser (De et al2006) was used for parsing.Table 2 above describes with the help of anexample how the reordering and hence the trans-lation quality has improved.
From the example itcan be seen that the translation by system usingour approach is better than the other two sys-tems.
The output translation is structurally morecorrect in our approach and conveys the samemeaning with respect to the reference translation.phrase-length#phrases #distinct-phrases(distinct on source)baseline limited re-ordering/%IOBL/IOBLour approach/%IOBL/IOBLbaseline limited re-ordering/%IOBL/IOBLour approach/%IOBL/IOBL2 537017 579878/7.98/42861579630/9.98/42613208988 249847/19.55/40859254393/21.72/454053 504810 590265/16.92/85455616381/22.10/111571292183 384518/31.62/92335408240/39.72/1160574 406069 493637/21.56/87568531904/30.98/125835268431 372282/38.68/103851409966/52.72/1415355 313368 391490/24.92/78122431135/37.58/117766221228 313723/41.80/92495354273/60.13/1330456  231146 292899/26.71/61753327192/41.55/96046170852 244643/43.19/73791279723/63.72/1088717 154800 196679/27.05/41879220868/42.67/66068119628 170108/42.19/50480194881/62.90/75253Table 4: Phrase count analysisThe Table 5 below lists four different evalua-tions of the systems under study.
For BLEU andNIST higher score is considered as better and formWER and mPER  lower score is desirable.
Ta-ble 5 shows the results of comparative evaluationof baseline, limited reordering and our approachwith improved reordering.
We find that additionof more reordering rules show substantial im-provements over the baseline phrase based sys-tem and the limited reordering system (Rama-nathan et al 2008).
The impact of improvedsyntactic reordering can be seen as the BLEUand NIST scores have increased whereas mWERand mPER scores have decreased.39BLEU NIST mWER%mPER%baseline 21.55 5.72 68.08 45.54limitedreordering22.19 5.74 66.44 44.70ourapproach24.47 5.88 64.71 43.89Table 5: Evaluation scoresTable 4 above shows the count of overallphrases and distinct phrases (distinct on source)for baseline, limited reordering approach and ourimproved reordering approach.
The table alsoshows increase over baseline (IOBL) and per-centage increase over baseline(%IOBL) for lim-ited reordering and improved reordering.
Wehave observed that no.
of distinct phrases ex-tracted from the training corpus get increased.The %IOBL for bigger phrases is more compareto shorter phrases.
This can be attributed to thebetter alignments resulting in extraction of morephrases (Koehn et al 2003).We have also observed that the overall in-crease is even lesser than the increase in no.
ofdistinct phrases (distinct on source) for all thephrase-lengths in our approach (e.g.
42613 and45405 for phrase-length 2) which shows that re-ordering makes word alignments more consistentand reduces multiple entries for the same sourcephrase.
The training was done on maximumphrase-length 7(default).5 ConclusionIt can be seen that addition of more reorderingrules improve translation quality.
As of now wehave tried these rules only for English-Hindipair, but the plan is to employ similar reorderingrules in other English-Indian language pairs asmost Indian languages are structurally similar toHindi.
Also plans are there to go for comparativestudy of improved reordering system and hierar-chical model.ReferencesAlexandra Birch , Miles Osborne and Phil Blunsom.2010.
Metrics for MT evaluation: evaluating reor-dering.
Machine Translation 24, no.
1: 15-26.Peter  F. Brown, John Cocke, Stephen A. Della Pietra,Vincent J. Della Pietra, Fredrick Jelinek, John D.Lafferty, Robert L. Mercer, and Paul S. Roossin.1990.
A statistical approach to machine translation.Computational linguistics 16(2): 79?85.Wang Chao, Michael Collins, and Philipp Koehn.2007.
Chinese syntactic reordering for statisticalmachine translation.
In Proceedings of the 2007Joint Conference on Empirical Methods inNatural Language Processing and Computa-tional Natural Language Learning (EMNLP-CoNLL).Stanley F. Chen, Joshua Goodman.
1996.
An empiri-cal study of smoothing techniques for languagemodeling.
In Proceedings of the 34th annualmeeting on Association for ComputationalLinguistics.
Association for Computational Lin-guistics.Michael Collins, Philipp Koehn, and Ivona Ku?erov?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting on Association for ComputationalLinguistics.Marneffe De, Marie-Catherine,  Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of LREC, vol.
6, pp.
449-454.Jacob Dlougach and Irina Galinskaya.
2012.
Buildinga reordering system using tree-to-string hierar-chical model.
In Proceedings of the First Work-shop on Reordering for Statistical MachineTranslation at COLING, Mumbai, India.George Doddington.
2002.
Automatic evaluation ofmachine translation quality using n-gram co-occurrence statistics.
In Proceedings of the sec-ond international conference on Human Lan-guage Technology Research.
Morgan KaufmannPublishers Inc.Rohit Gupta, Raj N. Patel and Ritesh Shah.
2012.Learning Improved Reordering Models for Urdu,Farsi and Italian using SMT.
In Proceedings ofthe first workshop on Reordering for Statisti-cal Machine Translation, COLING 2012,Mumbai, India.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In Proceedings of theSixth Workshop on Statistical Machine Trans-lation, Association for Computational Linguis-tics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the NorthAmerican  Chapter of the Association forComputational Linguistics on Human Lan-guage Technology-Volume 1.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Ber-toldi, Brooke Cowan et al2007.
Moses: Open40source toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of theACL on Interactive Poster and Demonstration Ses-sions.Daniel Marcu, and William Wong.
2002.
A phrase-based, joint probability model for statistical ma-chine translation.
Proceedings of EMNLP.Sonja Nie?en, Franz J. Och, Gregor Leusch, andHermann Ney.
2000.
An Evaluation Tool for Ma-chine Translation: Fast Evaluation for MT Re-search.
International Conference on Language Re-sources and Evaluation.Franz J. Och, and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational linguistics, Volume 29, number1:19-51.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedingsof the 41st Annual Meeting on Association forComputational Linguistics-Volume 1:pp.
160-167.Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu.
2001.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
IBM Re-search Report, Thomas J. Watson ResearchCenter.Taraka Rama, Karthik Gali and Avinesh PVS.
2008.Does Syntactic Knowledge help English-HindiSMT ?.
Proceedings of the NLP Tools contest,ICON.Ananthakrishnan Ramanathan, PushpakBhattacharyya, Jayprasad Hegde, Ritesh M. Shah,and M. Sasikumar.
2008.
Simple syntactic andmorphological processing can help English-Hindistatistical machine translation.
In InternationalJoint Conference on NLP (IJCNLP08).Christoph Tillmann, Stephan Vogel, Hermann Ney,Alex Zubiaga, and Hassan Sawaf.
1997.
Accelerat-ed DP based search for statistical translation.
InEuropean Conf.
on Speech Communicationand Technology.Fei Xia and Michael McCord.
2004.
Improving a sta-tistical MT system with automatically learned re-write patterns.
In Proceedings of the 20th inter-national conference on Computational Lin-guistics, p. 508.
Association for ComputationalLinguistics.41
