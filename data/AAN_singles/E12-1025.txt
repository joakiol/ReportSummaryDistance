Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 245?254,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsActive learning for interactive machine translationJesu?s Gonza?lez-Rubio and Daniel Ortiz-Mart?
?nez and Francisco CasacubertaD.
de Sistemas Informa?ticos y Computacio?nU.
Polite`cnica de Vale`nciaC.
de Vera s/n, 46022 Valencia, Spain{jegonzalez,dortiz,fcn}@dsic.upv.esAbstractTranslation needs have greatly increasedduring the last years.
In many situa-tions, text to be translated constitutes anunbounded stream of data that grows con-tinually with time.
An effective approachto translate text documents is to followan interactive-predictive paradigm in whichboth the system is guided by the userand the user is assisted by the system togenerate error-free translations.
Unfortu-nately, when processing such unboundeddata streams even this approach requires anoverwhelming amount of manpower.
Is inthis scenario where the use of active learn-ing techniques is compelling.
In this work,we propose different active learning tech-niques for interactive machine translation.Results show that for a given translationquality the use of active learning allows usto greatly reduce the human effort requiredto translate the sentences in the stream.1 IntroductionTranslation needs have greatly increased duringthe last years due to phenomena such as global-ization and technologic development.
For exam-ple, the European Parliament1 translates its pro-ceedings to 22 languages in a regular basis orProject Syndicate2 that translates editorials intodifferent languages.
In these and many other ex-amples, data can be viewed as an incoming un-bounded stream since it grows continually withtime (Levenberg et al 2010).
Manual translationof such streams of data is extremely expensivegiven the huge volume of translation required,1http://www.europarl.europa.eu2http://project-syndicate.orgtherefore various automatic machine translationmethods have been proposed.However, automatic statistical machine trans-lation (SMT) systems are far from generatingerror-free translations and their outputs usuallyrequire human post-editing in order to achievehigh-quality translations.
One way of taking ad-vantage of SMT systems is to combine themwith the knowledge of a human translator in theinteractive-predictive machine translation (IMT)framework (Foster et al 1998; Langlais and La-palme, 2002; Barrachina et al 2009), which isa particular case of the computer-assisted trans-lation paradigm (Isabelle and Church, 1997).
Inthe IMT framework, a state-of-the-art SMT modeland a human translator collaborate to obtain high-quality translations while minimizing requiredhuman effort.Unfortunately, the application of either post-editing or IMT to data streams with massive datavolumes is still too expensive, simply becausemanual supervision of all instances requires hugeamounts of manpower.
For such massive datastreams the need of employing active learning(AL) is compelling.
AL techniques for IMT se-lectively ask an oracle (e.g.
a human transla-tor) to supervise a small portion of the incomingsentences.
Sentences are selected so that SMTmodels estimated from them translate new sen-tences as accurately as possible.
There are threechallenges when applying AL to unbounded datastreams (Zhu et al 2010).
These challenges canbe instantiated to IMT as follows:1.
The pool of candidate sentences is dynam-ically changing, whereas existing AL algo-rithms are dealing with static datasets only.2452.
Concepts such as optimum translation andtranslation probability distribution are con-tinually evolving whereas existing AL algo-rithms only deal with constant concepts.3.
Data volume is unbounded which makesimpractical to batch-learn one single sys-tem from all previously translated sentences.Therefore, model training must be done in anincremental fashion.In this work, we present a proposal of AL forIMT specifically designed to work with streamdata.
In short, our proposal divides the datastream into blocks where AL techniques for staticdatasets are applied.
Additionally, we implementan incremental learning technique to efficientlytrain the base SMT models as new data is avail-able.2 Related workA body of work has recently been proposed to ap-ply AL techniques to SMT (Haffari et al 2009;Ambati et al 2010; Bloodgood and Callison-Burch, 2010).
The aim of these works is tobuild one single optimal SMT model from manu-ally translated data extracted from static datasets.None of them fit in the setting of data streams.Some of the above described challenges of ALfrom unbounded streams have been previously ad-dressed in the MT literature.
In order to deal withthe evolutionary nature of the problem, Nepveu etal.
(2004) propose an IMT system with dynamicadaptation via cache-based model extensions forlanguage and translation models.
Pursuing thesame goal for SMT, Levenberg et al (2010)study how to bound the space when processing(potentially) unbounded streams of parallel dataand propose a method to incrementally retrainSMT models.
Another method to efficiently re-train a SMT model with new data was presentedin (Ortiz-Mart?
?nez et al 2010).
In this work,the authors describe an application of the onlinelearning paradigm to the IMT framework.To the best of our knowledge, the only previ-ous work on AL for IMT is (Gonza?lez-Rubio etal., 2011).
There, the authors present a na?
?ve ap-plication of the AL paradigm for IMT that do nottake into account the dynamic change in proba-bility distribution of the stream.
Nevertheless, re-sults show that even that simple AL frameworkhalves the required human effort to obtain a cer-tain translation quality.In this work, the AL framework presentedin (Gonza?lez-Rubio et al 2011) is extended inan effort to address all the above described chal-lenges.
In short, we propose an AL framework forIMT that splits the data stream into blocks.
Thisapproach allows us to have more context to modelthe changing probability distribution of the stream(challenge 2) and results in a more accurate sam-pling of the changing pool of sentences (chal-lenge 1).
In contrast to the proposal describedin (Gonza?lez-Rubio et al 2011), we define sen-tence sampling strategies whose underlying mod-els can be updated with the newly available data.This way, the sentences to be supervised by theuser are chosen taking into account previously su-pervised sentences.
To efficiently retrain the un-derlying SMT models of the IMT system (chal-lenge 3), we follow the online learning techniquedescribed in (Ortiz-Mart?
?nez et al 2010).
Finally,we integrate all these elements to define an ALframework for IMT with an objective of obtainingan optimum balance between translation qualityand human user effort.3 Interactive machine translationIMT can be seen as an evolution of the SMTframework.
Given a sentence f from a sourcelanguage to be translated into a sentence e ofa target language, the fundamental equation ofSMT (Brown et al 1993) is defined as follows:e?
= argmaxePr(e | f) (1)where Pr(e | f) is usually approximated by a loglinear translation model (Koehn et al 2003).
Inthis case, the decision rule is given by the expres-sion:e?
= argmaxe{M?m=1?mhm(e, f)}(2)where each hm(e, f) is a feature function repre-senting a statistical model and ?m its weight.In the IMT framework, a human translator is in-troduced in the translation process to collaboratewith an SMT model.
For a given source sentence,the SMT model fully automatically generates aninitial translation.
The human user checks thistranslation, from left to right, correcting the first246source (f ): Para ver la lista de recursosdesired translation (e?
): To view a listing of resourcesinter.-0epes To view the resources listinter.-1ep To viewk aes list of resourcesinter.-2ep To view a listk list ies list i ng resourcesinter.-3ep To view a listingk oes o f resourcesaccept ep To view a listing of resourcesFigure 1: IMT session to translate a Spanish sentenceinto English.
The desired translation is the translationthe human user have in mind.
At interaction-0, the sys-tem suggests a translation (es).
At interaction-1, theuser moves the mouse to accept the first eight charac-ters ?To view ?
and presses the a key (k), then thesystem suggests completing the sentence with ?list ofresources?
(a new es).
Interactions 2 and 3 are simi-lar.
In the final interaction, the user accepts the currenttranslation.error.
Then, the SMT model proposes a new ex-tension taking the correct prefix, ep, into account.These steps are repeated until the user accepts thetranslation.
Figure 1 illustrates a typical IMT ses-sion.
In the resulting decision rule, we have tofind an extension es for a given prefix ep.
To dothis we reformulate equation (1) as follows, wherethe term Pr(ep | f) has been dropped since it doesnot depend on es:e?s = argmaxesPr(ep, es | f) (3)?
argmaxesp(es | f , ep) (4)The search is restricted to those sentences ewhich contain ep as prefix.
Since e ?
ep es, wecan use the same log-linear SMT model, equa-tion (2), whenever the search procedures are ad-equately modified (Barrachina et al 2009).4 Active learning for IMTThe aim of the IMT framework is to obtain high-quality translations while minimizing the requiredhuman effort.
Despite the fact that IMT mayreduce the required effort with respect to post-editing, it still requires the user to supervise allthe translations.
To address this problem, we pro-pose to use AL techniques to select only a smallnumber of sentences whose translations are worthto be supervised by the human expert.This approach implies a modification of theuser-machine interaction protocol.
For a givensource sentence, the SMT model generates an ini-tial translation.
Then, if this initial translation isclassified as incorrect or ?worth of supervision?,we perform a conventional IMT procedure as inFigure 1.
If not, we directly return the initial au-tomatic translation and no effort is required fromthe user.
At the end of the process, we use the newsentence pair (f , e) available to refine the SMTmodels used by the IMT system.In this scenario, the user only checks a smallnumber of sentences, thus, final translations arenot error-free as in conventional IMT.
However,results in previous works (Gonza?lez-Rubio et al2011) show that this approach yields importantreduction in human effort.
Moreover, dependingon the definition of the sampling strategy, we canmodify the ratio of sentences that are interactivelytranslated to adapt our system to the requirementsof a specific translation task.
For example, if themain priority is to minimize human effort, oursystem can be configured to translate all the sen-tences without user intervention.Algorithm 1 describes the basic algorithm toimplement AL for IMT.
The algorithm receives asinput an initial SMT model, M , a sampling strat-egy, S, a stream of source sentences, F, and theblock size, B.
First, a block of B sentences, X ,is extracted from the data stream (line 3).
Fromthis block, we sample those sentences, Y , thatare worth to be supervised by the human expert(line 4).
For each of the sentences in X , the cur-rent SMT model generates an initial translation,e?, (line 6).
If the sentence has been sampled asworthy of supervision, f ?
Y , the user is requiredto interactively translate it (lines 8?13) as exem-plified in Figure 1.
The source sentence f and itshuman-supervised translation, e, are then used toretrain the SMT model (line 14).
Otherwise, wedirectly output the automatic translation e?
as ourfinal translation (line 17).Most of the functions in the algorithm denotedifferent steps in the interaction between the hu-man user and the machine:?
translate(M, f): returns the most proba-ble automatic translation of f given by M .?
validPrefix(e): returns the prefix of e247input : M (initial SMT model)S (sampling strategy)F (stream of source sentences)B (block size)auxiliar : X (block of sentences)Y (sentences worth of supervision)begin1repeat2X = getSentsFromStream (B,F);3Y = S(X,M);4foreach f ?
X do5e?
= translate(M, f);6if f ?
Y then7e = e?
;8repeat9ep = validPrefix(e);10e?s = genSuffix(M, f , ep);11e = ep e?s;12until validTranslation(e) ;13M = retrain(M, (f , e));14output(e);15else16output(e?
);17until True ;18end19Algorithm 1: Pseudo-code of the proposedalgorithm to implement AL for IMT fromunbounded data streams.validated by the user as correct.
This prefixincludes the correction k.?
genSuffix(M, f , ep): returns the suffix ofmaximum probability that extends prefix ep.?
validTranslation(e): returns True ifthe user considers the current translation tobe correct and False otherwise.Apart from these, the two elements that definethe performance of our algorithm are the samplingstrategy S(X,M) and the retrain(M, (f , e))function.
On the one hand, the sampling strat-egy decides which sentences should be supervisedby the user, which defines the human effort re-quired by the algorithm.
Section 5 describes ourimplementation of the sentence sampling to dealwith the dynamic nature of data streams.
On theother hand, the retrain(?)
function incremen-tally trains the SMT model with each new trainingpair (f , e).
Section 6 describes the implementa-tion of this function.5 Sentence sampling strategiesA good sentence sampling strategy must be ableto select those sentences that along with their cor-rect translations improve most the performance ofthe SMT model.
To do that, the sampling strat-egy have to correctly discriminate ?informative?sentences from those that are not.
We can makedifferent approximations to measure the informa-tiveness of a given sentence.
In the followingsections, we describe the three different samplingstrategies tested in our experimentation.5.1 Random samplingArguably, the simplest sampling approach is ran-dom sampling, where the sentences are randomlyselected to be interactively translated.
Althoughsimple, it turns out that random sampling per-form surprisingly well in practice.
The successof random sampling stem from the fact that indata stream environments the translation proba-bility distributions may vary significantly throughtime.
While general AL algorithms ask the user totranslate informative sentences, they may signifi-cantly change probability distributions by favor-ing certain translations, consequently, the previ-ously human-translated sentences may no longerreveal the genuine translation distribution in thecurrent point of the data stream (Zhu et al 2007).This problem is less severe for static data wherethe candidate pool is fixed and AL algorithms areable to survey all instances.
Random samplingavoids this problem by randomly selecting sen-tences for human supervision.
As a result, it al-ways selects those sentences with the most similardistribution to the current sentence distribution inthe data stream.5.2 n-gram coverage samplingOne technique to measure the informativenessof a sentence is to directly measure the amountof new information that it will add to the SMTmodel.
This sampling strategy considers thatsentences with rare n-grams are more informa-tive.
The intuition for this approach is that raren-grams need to be seen several times in order toaccurately estimate their probability.To do that, we store the counts for each n-grampresent in the sentences used to train the SMTmodel.
We assume that an n-gram is accuratelyrepresented when it appears A or more times in248the training samples.
Therefore, the score for agiven sentence f is computed as:C(f) =?Nn=1 |N<An (f)|?Nn=1 |Nn(f)|(5)where Nn(f) is the set of n-grams of size nin f , N<An (f) is the set of n-grams of size n inf that are inaccurately represented in the trainingdata and N is the maximum n-gram order.
Inthe experimentation, we assume N = 4 as themaximum n-gram order and a value of 10 for thethreshold A.
This sampling strategy works by se-lecting a given percentage of the highest scoringsentences.We update the counts of the n-grams seen bythe SMT model with each new sentence pair.Hence, the sampling strategy is always up-to-datewith the last training data.5.3 Dynamic confidence samplingAnother technique is to consider that the most in-formative sentence is the one the current SMTmodel translates worst.
The intuition behind thisapproach is that an SMT model can not generategood translations unless it has enough informa-tion to translate the sentence.The usual approach to compute the quality of atranslation hypothesis is to compare it to a refer-ence translation, but, in this case, it is not a validoption since reference translations are not avail-able.
Hence, we use confidence estimation (Gan-drabur and Foster, 2003; Blatz et al 2004; Ueff-ing and Ney, 2007) to estimate the probability ofcorrectness of the translations.
Specifically, weestimate the quality of a translation from the con-fidence scores of their individual words.The confidence score of a word ei of the trans-lation e = e1 .
.
.
ei .
.
.
eI generated from thesource sentence f = f1 .
.
.
fj .
.
.
fJ is computedas described in (Ueffing and Ney, 2005):Cw(ei, f) = max0?j?| f |p(ei|fj) (6)where p(ei|fj) is an IBM model 1 (Brown et al1993) bilingual lexicon probability and f0 is theempty source word.
The confidence score for thefull translation e is computed as the ratio of itswords classified as correct by the word confidencemeasure.
Therefore, we define the confidence-based informativeness score as:C(e, f) = 1?|{ei | Cw(ei, f) > ?w}|| e |(7)Finally, this sampling strategy works by select-ing a given percentage of the highest scoring sen-tences.We dynamically update the confidence samplereach time a new sentence pair is added to the SMTmodel.
The incremental version of the EM algo-rithm (Neal and Hinton, 1999) is used to incre-mentally train the IBM model 1.6 Retraining of the SMT modelTo retrain the SMT model, we implement theonline learning techniques proposed in (Ortiz-Mart?
?nez et al 2010).
In that work, a state-of-the-art log-linear model (Och and Ney, 2002)and a set of techniques to incrementally train thismodel were defined.
The log-linear model is com-posed of a set of feature functions governing dif-ferent aspects of the translation process, includ-ing a language model, a source sentence?lengthmodel, inverse and direct translation models, atarget phrase?length model, a source phrase?length model and a distortion model.The incremental learning algorithm allows usto process each new training sample in constanttime (i.e.
the computational complexity of train-ing a new sample does not depend on the num-ber of previously seen training samples).
To dothat, a set of sufficient statistics is maintained foreach feature function.
If the estimation of thefeature function does not require the use of thewell-known expectation?maximization (EM) al-gorithm (Dempster et al 1977) (e.g.
n-gram lan-guage models), then it is generally easy to incre-mentally extend the model given a new trainingsample.
By contrast, if the EM algorithm is re-quired (e.g.
word alignment models), the estima-tion procedure has to be modified, since the con-ventional EM algorithm is designed for its use inbatch learning scenarios.
For such models, the in-cremental version of the EM algorithm (Neal andHinton, 1999) is applied.
A detailed descriptionof the update algorithm for each of the models inthe log-linear combination is presented in (Ortiz-Mart?
?nez et al 2010).7 ExperimentsWe carried out experiments to assess the perfor-mance of the proposed AL implementation forIMT.
In each experiments, we started with aninitial SMT model that is incrementally updated249corpus use sentenceswords(Spa/Eng)Europarltrain 731K 15M/15Mdevel.
2K 60K/58KNewstest 51K 1.5M/1.2MCommentaryTable 1: Size of the Spanish?English corpora used inthe experiments.
K and M stand for thousands andmillions of elements respectively.with the sentences selected by the current sam-pling strategy.
Due to the unavailability of publicbenchmark data streams, we selected a relativelylarge corpus and treated it as a data stream for AL.To simulate the interaction with the user, we usedthe reference translations in the data stream cor-pus as the translation the human user would liketo obtain.
Since each experiment is carried outunder the same conditions, if one sampling strat-egy outperforms its peers, then we can safely con-clude that this is because the sentences selected tobe translated are more informative.7.1 Training corpus and data streamThe training data comes from the Europarl corpusas distributed for the shared task in the NAACL2006 workshop on statistical machine transla-tion (Koehn and Monz, 2006).
We used this datato estimate the initial log-linear model used by ourIMT system (see Section 6).
The weights of thedifferent feature functions were tuned by meansof minimum error?rate training (Och, 2003) exe-cuted on the Europarl development corpus.
Oncethe SMT model was trained, we use the NewsCommentary corpus (Callison-Burch et al 2007)to simulate the data stream.
The size of these cor-pora is shown in Table 1.
The reasons to choosethe News Commentary corpus to carry out ourexperiments are threefold: first, its size is largeenough to simulate a data stream and test ourAL techniques in the long term; second, it isout-of-domain data which allows us to simulatea real-world situation that may occur in a trans-lation company, and, finally, it consists in edito-rials from eclectic domain: general politics, eco-nomics and science, which effectively representsthe variations in the sentence distributions of thesimulated data stream.7.2 Assessment criteriaWe want to measure both the quality of the gener-ated translations and the human effort required toobtain them.We measure translation quality with the well-known BLEU (Papineni et al 2002) score.To estimate human user effort, we simulate theactions taken by a human user in its interactionwith the IMT system.
The first translation hypoth-esis for each given source sentence is comparedwith a single reference translation and the longestcommon character prefix (LCP) is obtained.
Thefirst non-matching character is replaced by thecorresponding reference character and then a newtranslation hypothesis is produced (see Figure 1).This process is iterated until a full match with thereference is obtained.
Each computation of theLCP would correspond to the user looking for thenext error and moving the pointer to the corre-sponding position of the translation hypothesis.Each character replacement, on the other hand,would correspond to a keystroke of the user.Bearing this in mind, we measure the user ef-fort by means of the keystroke and mouse-actionratio (KSMR) (Barrachina et al 2009).
This mea-sure has been extensively used to report results inthe IMT literature.
KSMR is calculated as thenumber of keystrokes plus the number of mousemovements divided by the total number of refer-ence characters.
From a user point of view thetwo types of actions are different and require dif-ferent types of effort (Macklovitch, 2006).
In anycase, as an approximation, KSMR assumes thatboth actions require a similar effort.7.3 Experimental resultsIn this section, we report results for three differentexperiments.
First, we studied the performanceof the sampling strategies when dealing with thesampling bias problem.
In the second experiment,we carried out a typical AL experiment measur-ing the performance of the sampling strategies asa function of the percentage of the corpus usedto retrain the SMT model.
Finally, we tested ourAL implementation for IMT in order to study thetradeoff between required human effort and finaltranslation quality.7.3.1 Dealing with the sampling biasIn this experiment, we want to study the perfor-mance of the different sampling strategies when250161718192021220  10  20  30  40  50BLEUBlock numberDCS NS RSFigure 2: Performance of the AL methods across dif-ferent data blocks.
Block size 500.
Human supervision10% of the corpus.dealing with the sampling bias problem.
Fig-ure 2 shows the evolution of the translation qual-ity, in terms of BLEU, across different data blocksfor the three sampling strategies described in sec-tion 5, namely, dynamic confidence sampling(DCS), n-gram coverage sampling (NS) and ran-dom sampling (RS).
On the one hand, the x-axisrepresents the data blocks number in their tempo-ral order.
On the other hand, the y-axis representsthe BLEU score when automatically translating ablock.
Such translation is obtained by the SMTmodel trained with translations supervised by theuser up to that point of the data stream.
To fairlycompare the different methods, we fixed the per-centage of words supervised by the human user(10%).
In addition to this, we used a block size of500 sentences.
Similar results were obtained forother block sizes.Results in Figure 2 indicate that the perfor-mances for the data blocks fluctuate and fluctu-ations are quite significant.
This phenomenon isdue to the eclectic domain of the sentences in thedata stream.
Additionally, the steady increase inperformance is caused by the increasing amountof data used to retrain the SMT model.Regarding the results for the different sam-pling strategies, DCS consistently outperformedRS and NS.
This observation asserts that for con-cept drifting data streams with constant changingtranslation distributions, DCS can adaptively askthe user to translate sentences to build a superiorSMT model.
On the other hand, NS obtains worseresults that RS.
This result can be explained by the1516171819202122230  5  10  15  20BLEUPercentage (%) of the corpus in wordsDCS NS SCS RS171819202  4  6  8Figure 3: BLEU of the initial automatic translationsas a function of the percentage of the corpus used toretrain the model.fact that NS is independent of the target languageand just looks into the source language, whileDCS takes into account both the source sentenceand its automatic translation.
Similar phenomenahas been reported in a previous work on AL forSMT (Haffari et al 2009).7.3.2 AL performanceWe carried out experiments to study the perfor-mance of the different sampling strategies.
To thisend, we compare the quality of the initial auto-matic translations generated in our AL implemen-tation for IMT (line 6 in Algorithm 1).
Figure 3shows the BLEU score of these initial translationsrepresented as a function of the percentage of thecorpus used to retrain the SMT model.
The per-centage of the corpus is measured in number ofrunning words.In Figure 3, we present results for the threesampling strategies described in section 5.
Ad-ditionally, we also compare our techniques withthe AL technique for IMT proposed in (Gonza?lez-Rubio et al 2011).
Such technique is similar toDCS but it does not update the IBM model 1 usedby the confidence sampler with the newly avail-able human-translated sentences.
This techniqueis referred to as static confidence sampler (SCS).Results in Figure 3 indicate that the perfor-mance of the retrained SMT models increased asmore data was incorporated.
Regarding the sam-pling strategies, DCS improved the results ob-tained by the other sampling strategies.
NS ob-tained by far the worst results, which confirms theresults shown in the previous experiment.
Finally,2511020304050607080901000  10  20  30  40  50  60  70BLEUKSMRDCSNS SCSRS w/o AL50 5560 6570 7516  18  20  22  24Figure 4: Quality of the data stream translation(BLEU) as a function of the required human effort(KSMR).
w/o AL denotes a system with no retraining.as it can be seen, SCS obtained slightly worst re-sults than DCS showing the importance of dy-namically adapting the underlying model used bythe sampling strategy.7.3.3 Balancing human effort andtranslation qualityFinally, we studied the balance between re-quired human effort and final translation error.This can be useful in a real-world scenario wherea translation company is hired to translate astream of sentences.
Under these circumstances,it would be important to be able to predict the ef-fort required from the human translators to obtaina certain translation quality.The experiment simulate this situation usingour proposed IMT system with AL to translatethe stream of sentences.
To have a broad viewof the behavior of our system, we repeated thistranslation process multiple times requiring an in-creasing human effort each time.
Experimentsrange from a fully-automatic translation systemwith no need of human intervention to a systemwhere the human is required to supervise all thesentences.
Figure 4 presents results for SCS (seesection 7.3.2) and the sentence selection strate-gies presented in section 5.
In addition, we alsopresent results for a static system without AL (w/oAL).
This system is equal to SCS but it do not per-form any SMT retraining.Results in Figure 4 show a consistent reductionin required user effort when using AL.
For a givenhuman effort the use of AL methods allowed toobtain twice the translation quality.
Regarding thedifferent AL sampling strategies, DCS obtains thebetter results but differences with other methodsare slight.Varying the sentence classifier, we can achievea balance between final translation quality and re-quired human effort.
This feature allows us toadapt the system to suit the requirements of theparticular translation task or to the available eco-nomic or human resources.
For example, if atranslation quality of 60 BLEU points is satisfac-tory, then the human translators would need tomodify only a 20% of the characters of the au-tomatically generated translations.Finally, it should be noted that our IMT sys-tems with AL are able to generate new suffixesand retrain with new sentence pairs in tenths of asecond.
Thus, it can be applied in real time sce-narios.8 Conclusions and future workIn this work, we have presented an AL frame-work for IMT specially designed to process datastreams with massive volumes of data.
Our pro-posal splits the data stream in blocks of sentencesof a certain size and applies AL techniques indi-vidually for each block.
For this purpose, we im-plemented different sampling strategies that mea-sure the informativeness of a sentence accordingto different criteria.To evaluate the performance of our proposedsampling strategies, we carried out experimentscomparing them with random sampling and theonly previously proposed AL technique for IMTdescribed in (Gonza?lez-Rubio et al 2011).
Ac-cording to the results, one of the proposed sam-pling strategies, specifically the dynamic con-fidence sampling strategy, consistently outper-formed all the other strategies.The results in the experimentation show that theuse of AL techniques allows us to make a tradeoffbetween required human effort and final transla-tion quality.
In other words, we can adapt our sys-tem to meet the translation quality requirementsof the translation task or the available human re-sources.As future work, we plan to investigate onmore sophisticated sampling strategies such asthose based in information density or query-by-committee.
Additionally, we will conduct exper-iments with real users to confirm the results ob-tained by our user simulation.252AcknowledgementsThe research leading to these results has re-ceived funding from the European Union SeventhFramework Programme (FP7/2007-2013) undergrant agreement no 287576.
Work also supportedby the EC (FEDER/FSE) and the Spanish MECunder the MIPRCV Consolider Ingenio 2010 pro-gram (CSD2007-00018) and iTrans2 (TIN2009-14511) project and by the Generalitat Valencianaunder grant ALMPR (Prometeo/2009/01).ReferencesVamshi Ambati, Stephan Vogel, and Jaime Carbonell.2010.
Active learning and crowd-sourcing for ma-chine translation.
In Proc.
of the conference onInternational Language Resources and Evaluation,pages 2169?2174.Sergio Barrachina, Oliver Bender, Francisco Casacu-berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,Antonio Lagarda, Hermann Ney, Jesu?s Toma?s, En-rique Vidal, and Juan-Miguel Vilar.
2009.
Sta-tistical approaches to computer-assisted translation.Computational Linguistics, 35:3?28.John Blatz, Erin Fitzgerald, George Foster, SimonaGandrabur, Cyril Goutte, Alex Kulesza, AlbertoSanchis, and Nicola Ueffing.
2004.
Confidence es-timation for machine translation.
In Proc.
of the in-ternational conference on Computational Linguis-tics, pages 315?321.Michael Bloodgood and Chris Callison-Burch.
2010.Bucking the trend: large-scale cost-focused activelearning for statistical machine translation.
In Proc.of the Association for Computational Linguistics,pages 854?864.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:parameter estimation.
Computational Linguistics,19:263?311.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2007.
(Meta-) evaluation of machine translation.
In Proc.of the Workshop on Statistical Machine Translation,pages 136?158.Arthur Dempster, Nan Laird, and Donald Rubin.1977.
Maximum likelihood from incomplete datavia the EM algorithm.
Journal of the Royal Statis-tical Society., 39(1):1?38.George Foster, Pierre Isabelle, and Pierre Plamon-don.
1998.
Target-text mediated interactive ma-chine translation.
Machine Translation, 12:175?194.Simona Gandrabur and George Foster.
2003.
Confi-dence estimation for text prediction.
In Proc.
of theConference on Computational Natural LanguageLearning, pages 315?321.Jesu?s Gonza?lez-Rubio, Daniel Ortiz-Mart?
?nez, andFrancisco casacuberta.
2011.
An active learn-ing scenario for interactive machine translation.
InProc.
of the 13thInternational Conference on Mul-timodal Interaction.
ACM.Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.2009.
Active learning for statistical phrase-basedmachine translation.
In Proc.
of the North Ameri-can Chapter of the Association for ComputationalLinguistics, pages 415?423.Pierre Isabelle and Kenneth Ward Church.
1997.
Spe-cial issue on new tools for human translators.
Ma-chine Translation, 12(1-2):1?2.Philipp Koehn and Christof Monz.
2006.
Man-ual and automatic evaluation of machine transla-tion between european languages.
In Proc.
of theWorkshop on Statistical Machine Translation, pages102?121.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics on Human Language Technology - Vol-ume 1, pages 48?54.Philippe Langlais and Guy Lapalme.
2002.
TransType: development-evaluation cycles to boost trans-lator?s productivity.
Machine Translation, 17:77?98.Abby Levenberg, Chris Callison-Burch, and Miles Os-borne.
2010.
Stream-based translation models forstatistical machine translation.
In Proc.
of the NorthAmerican Chapter of the Association for Compu-tational Linguistics, pages 394?402, Los Angeles,California, June.Elliott Macklovitch.
2006.
TransType2: the last word.In Proc.
of the conference on International Lan-guage Resources and Evaluation, pages 167?17.Radford Neal and Geoffrey Hinton.
1999.
A view ofthe EM algorithm that justifies incremental, sparse,and other variants.
Learning in graphical models,pages 355?368.Laurent Nepveu, Guy Lapalme, Philippe Langlais, andGeorge Foster.
2004.
Adaptive language and trans-lation models for interactive machine translation.
InProc, of EMNLP, pages 190?197, Barcelona, Spain,July.Franz Och and Hermann Ney.
2002.
Discriminativetraining and maximum entropy models for statisti-cal machine translation.
In Proc.
of the Associationfor Computational Linguistics, pages 295?302.Franz Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proc.
of the Associa-tion for Computational Linguistics, pages 160?167.253Daniel Ortiz-Mart?
?nez, Ismael Garc?
?a-Varea, andFrancisco Casacuberta.
2010.
Online learning forinteractive statistical machine translation.
In Proc.of the North American Chapter of the Associationfor Computational Linguistics, pages 546?554.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for auto-matic evaluation of machine translation.
In Proc.of the Association for Computational Linguistics,pages 311?318.Nicola Ueffing and Hermann Ney.
2005.
Applica-tion of word-level confidence measures in interac-tive statistical machine translation.
In Proc.
of theEuropean Association for Machine Translation con-ference, pages 262?270.Nicola Ueffing and Hermann Ney.
2007.
Word-level confidence estimation for machine translation.Computational Linguistics, 33:9?40.Xingquan Zhu, Peng Zhang, Xiaodong Lin, and YongShi.
2007.
Active learning from data streams.
InProc.
of the 7th IEEE International Conference onData Mining, pages 757?762.
IEEE Computer So-ciety.Xingquan Zhu, Peng Zhang, Xiaodong Lin, and YongShi.
2010.
Active learning from stream data usingoptimal weight classifier ensemble.
Transactionson Systems, Man and Cybernetics Part B, 40:1607?1621, December.254
