SRI INTERNATIONAL FASTUS SYSTEMMUC-4 TEST RESULTS AND ANALYSISDouglas E. Appelt, John Bear, Jerry R .
Hobbs, David Israel, and Mabry Tyso nSRI InternationalMenlo Park, California 94025appelt?ai .sri .com(415) 859-6150INTRODUCTIONThe system that SRI used for the MUC-4 evaluation represents a significant departure from syste marchitectures that have been employed in the past .
In MUC-2 and MUC-3, SRI used the TACITUS tex tprocessing system [I], which was based on the DIALOGIC parser and grammar, and an abudctive reasone rfor horn-clause logic .
In MUC-4, SRI designed a new system called FASTUS (a permutation of the initia lletters in Finite State .Automata-based Text Understanding System) which we feel represents a significantadvance in the state of the art of text processing .
The system shares certain modules with the earlie rTACITUS system, namely modules for text preprocessing and standardization, spelling correction, Hispani cname recognition, and the core lexicon .
However, the DIALOGIC system and abductive reasoner, which wer ethe heart and soul of the previous system, were replaced by a system whose architecture is based on cascade dfinite-state automata .
Using this system we were capable of achieving a significant level of performance onthe MUC-4 task with less than one month devoted to domain-specific development .
In addition, the systemis extremely fast, and is capable of processing texts at the rate of approximately 3,200 words per minute ,measured in CPU time on a Sun SPARC-2 processor .
(Measured according to elapsed real time, the systemabout 50% slower, but the observed time depends on the particular hardware configuration involved .
)OVERVIEW OF THE FASTUS ARCHITECTUR EThe architecture of the FASTUS system is described in detail in the associated system summary .
It canbe summarized as a three-phase process .
The first phase consists of scanning the text to identify prope rnames, correcting spelling, and similar preprocessing tasks to ensure that the text is in a standardized forma tfor the remainder of the processing .The second phase consists of a finite-state machine that accepts the sequence of words from the text, an dproduces as output a sequence of linguistic consituents ?
noun groups consisting of determiners, prenomi-nals and head noun, verb groups consisting of auxilliaries plus the main verb together with any intervenin gadverbs, and particles, which is a catch-all category including prepositions, conjunctions, and genitive mark-ers .
The output of the second pass is filtered to include only the longest consitutents spanning any give nportion of the sentence .The linguistic consituents from the second phase are given as input to another finite-state machine .
Thetransitions of this third-phase machine are based on the head of each constituent, and each transition build ssome piece of an "incident."
structure, which can be thought of as a "proto-template ."
When a final stateof the machine is reached, the incident, structure that has been produced through that point is saved, an dmerged with all other incident structures produced by the same sentence .
(There may be several, becausethe machines are non-deterministic) .
These incident structures are then merged with incident structure sfrom the rest of the text according to a set of merging heuristics .
The incident structures are converted tothe format of MUC-4 templates in a post-processing phase .143CONTROLLING THE FASTUS SYSTE MIn the course of designing the system, we paramaterized a number of characteristics of the system's oper-ation because we believed that the parameterized behavior would reflect tradeoffs in recall versus precision .Subsequent testing revealed that many of these parameters result in both higher recall and higher precisionwhen in one state or the other, and therefore we left them permanently in their most advantageous state .Those parameters that seemed to affect recall the the expense of precision were set to produce a test ru nin which we attempted to maximize the system's recall .
The effect of these parameters could be describedin general as distrusting the system's filters' ability to eliminate templates corresponding to stale dates ,uninteresting countries, and military incidents .
We observed a small but measurable increase in recall at theexpense of precision by distrusting our filters .The following parameters were implemented and tested on 300 texts before arriving at the decisions fo rthe settings on the final run .?
Conservative Merging.
When this option is selected, the system would not merge incidents that ha dnon-overlapping targets with proper names .
When not selected, any merges consistent with the inciden ttypes were permitted .
Testing revealed that merging should always be conservative .?
Civilian Target Requirement.
This filter would reject any template that did not have at least on enon-military target, including templates that identified a perpetrator, but no physical or human targe tat all .
This option appears to produce a recall-precision tradeoff of about one or two points .?
Subjectless Verb Groups .
This parameter would allow the system to generate an incident structur efrom a verb together with its object, even if its subject could not be determined .
Although early testsshowed a recall-precision tradeoff, subsequent and more thorough testing indicated that this shoul dalways be done .?
Filter Many-Target Templates.
This filter would disallow any template that had more than 100 targets ,on the supposition that such templates often result from vague or general, and hence irrelevant, de-scriptions .
This turns out to be a correct heuristic, but only if the number of targets is evenly divisibl eby 100 .
(An airline bombing with 307 victims is certainly interesting, while "70,000 peasants hav ebeen killed" is probably vague) .?
Military Filtering.
This heuristic causes the system to eliminate all military targets from templates ,on the belief that we may have incorrectly merged a military incident with a civilian incident andincorrectly reported the union of the two .
Tests show that this filtering improves precision slightly .?
Liberal Perpetrator Org.
Setting this parameter would cause the system to pick any likely perpetratororganization out of the text, ignoring whatever the text actually says .
'Testing showed that thi sparameter had no effect, which was such a surprising result that we distrust it, and regard our testin gas inconclusive .?
Spelling Correction This parameter controls how much spelling correction the system does .
Our exper-iments indicated that spelling correction hurts, primarily because novel proper names get corrected t oother words, and hence lost .
We tried a weaker version of spelling correction which would correct onl ymisspelled words that did not occur on a large list of proper names that we had assembled .
This showe dan improvement, but spelling correction still had a small negative effect .
This was also a surprisin gresult, and we were not willing to abandon spelling correction, and ran all tests with weak spellin gcorrection enabled, although to some extent a complete lack of spelling correction is compensated fo rby the presence of common misspellings of important domain words like "guerrilla" and "assassinate"in the lexicon .?
Stale Date Filtering .
This parameter causes filtering of any template that has a date that is earlie rthan two months before the date of the article .
Eliminating this filtering produces an increase in recal l144at the expense of precision, the magnitude of which depends on how well our date detection currentl yworks .
We would expect about a one-point tradeoff .?
Weak Location Filtering .
If the system's location dection finds that the location of an incident i simpossible according to the system ' s location database, it eliminates the template .
If this flag is set ,the template will be produced using only the country as the location.
Testing shows that this is alwaysdesireable .THE RESULTS ON TST3 AND TST4On TST3, we achieved a recall of 44% with precision of 55% in the all-templates row, for an F-scor e(3 = 1) of 48 .9 .
On TST4, the test on incidents from a different time span, we observed, surprisingly, a nidentical recall score of 44%, however our precision fell to 52%, for an F-score of 47 .7 .
It was reassuring tosee that there was very little degradation in performance moving to a time period over which the systemhad not been trained .
We also submitted a run in which we attempted to maximize the system's recal lby not filtering military targets, and allowing incidents with stale dates .
On TST3, this led to a two-pointincrease in recall at the expense of one point in precision .
On TST4, our recall did not increase, howeve rour precision fell by a point, giving us a lower F-score on this run .
These results were consistent with ou robservations during testing, although our failure to produce even a small increase in recall on TST4 wassomewhat disappointing .The runtime for the entire TST3 message set on a SPARC-2 processor was 11 .8 minutes (about 1 6minutes of elapsed real time with our configuration of memory and disk) .
These times are quite consisten twith our runs over the development sets .
During the course of development, the overall run time for 10 0messages increased approximately 50%, but we attribute this increase to the decision to treat more sentence sas relevant .
It appears possible to increase the coverage of the system without an unacceptable increase i nprocessing time .DEVELOPMENT HISTORYDuring December of 1991 we decided to implement a preprocessor for the TACITUS system, at whic hpoint the FASTUS architecture was born .
The system was originally conceived as a preprocessor for TACI-TUS that could be run in a stand-alone mode .
Considerably later in our development we decided that theperformance of FASTUS on the MUC-4 task was so high that we could make FASTUS our complete system .Most of the design work for the FASTUS system took place during January .
The ideas were tested ou ton finding incident locations in February, and with some initial favorable results in hand, we proceded wit hthe implementation of the system in March .
The implementation of the second phase of processing wa scompleted in March, and the general outline of phase three was completed by the end of April .
On May6, we did the first test of the FASTUS system on TST2, which had been withheld as a fair test, and weobtained a score of 8% recall and 42% precision .
At that point we began a fairly intensive effort to hill-clim bon all 1300 development texts, doing periodic runs on the fair test to monitor our progress, culminating i na score of 44% recall, 57% precision in the wee hours of June 1, when we decided to run the official test .
Asthe chart in Figure 1 points out, the rate of progress was rapid enough that even a few hours of work coul dbe shown to have a noticeable impact on the score .
Our scarcest resource was time, and our supply of it wa seventually exhausted well before the point of diminishing returns .CONCLUSIONSFASTUS was more successful than we ever dreamed when the idea was originally conceived .
In retrospect ,145F-Score vs Date for TST2efl44R,APBest MUG-3 Performance (i3E)SRI's MUG-3 Performance303010?m,MGso.o?
?11May1e2023V30 :1Figure 1 : Plot of F-Score versus Date for FASTUS Developmen twe attribute its success to the fact that its processing is extremely well suited to the demands of the task .The system's phase-3 works successfully because the input from phase-2 is already reliably processed .
Phasetwo does only the linguistic processing that can be done reliably and fast, ignoring all the problems of makin gattachment decisions, and the ambiguity introduced by coordination and appositives .
This input is adequatefor phase-3 because the domain pragmatics are sufficiently constrained that given this initial chunking, th erelevant information can be reliably detected and extracted .One source of frustration with the development of this system is that we never had the opportunity t oproduce a decent developer's interface .
We believe that phase-2 is almost completely domain independent ,with all the domain specific knowledge embedded in the phase-3 automata .
We feel that with some carefu lthought devoted to such an interface, we could produce a general text processing system that could b ebrought up to our current level of performance on a MUC-like or TIPSTER-like task in even less than th ethree and a half weeks of effort that we required .Another discovery of this experience is that a MUG-like task is much easier than anyone ever thought .Although the full linguistic complexity of the MUC texts is very high, with long sentences and interestin gdiscourse structure problems, the relative simplicity of the information-extraction task allows much of thi slinguistic complexity to by bypassed ?
indeed much more than we had originally believed was possible .
Thekey to the whole problem, as we see it from our FASTUS experience, is to do exactly the right amount ofsyntax, so that pragmatics can take over its share of the load .
For the MUC task, we think FASTUS display sexactly the right mixture .Finally, we point out that while FASTUS is an elegant engineering achievement,, the whole host o flinguistic problems that were bypassed are still out there, and will have to be addressed eventually fo rmore complex tasks .
and to achieve ever higher performance on simpler tasks .
The nature of competitiveevaluations is that they force everyone to deal with the easiest problems first .
However, the hard problemscannot be ignored forever, and scientific progress requires that they be addressed .146ACKNOWLEDGEMENTSThis research was funded by the Defense Advanced Research Projects Agency under Office of Nava lResearch contracts N00014-90-C-0220, and by an internal research and development grant from SRI Inter-national .References[1] Hobbs, J ., et al., "Description of the TACITUS System as Used for MUC-3," Proceedings of the MUC- 3Workshop, 1991, pp .
200-206 .147
