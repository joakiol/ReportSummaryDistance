Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 921?928,Sydney, July 2006. c?2006 Association for Computational LinguisticsAligning Features with Sense Distinction Dimensions1 Nianwen Xue,  2 Jinying Chen,  3 Martha Palmer1CSLR and 3Department of LinguisticsUniversity of ColoradoBoulder, CO, 80309{Nianwen.Xue,Martha.Palmer}@colorado.edu2 Department of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA, 19104jinying@cis.upenn.eduAbstractIn this paper we present word sensedisambiguation (WSD) experiments onten highly polysemous verbs in Chinese,where significant performanceimprovements are achieved using richlinguistic features.
Our system performssignificantly better, and in some casessubstantially better, than the baseline onall ten verbs.
Our results alsodemonstrate that features extracted fromthe output of an automatic Chinesesemantic role labeling system in generalbenefited the WSD system, even thoughthe amount of improvement was notconsistent across the verbs.
For a fewverbs, semantic role information actuallyhurt WSD performance.
Theinconsistency of feature performance is ageneral characteristic of the WSD task, ashas been observed by others.
We arguethat this result can be explained by thefact that word senses are partitionedalong different dimensions for differentverbs and the features therefore need tobe tailored to particular verbs in order toachieve adequate accuracy on verb sensedisambiguation.1 IntroductionWord sense disambiguation, the determination ofthe correct sense of a polysemous word from anumber of possible senses based on the contextin which it occurs, is a continuing obstacle tohigh performance natural language processingapplications.
There are several well-documentedfactors that make accurate WSD particularlychallenging.
The first has to do with how sensesare defined.
The English data used for theSENSEVAL exercises, arguably the most widelyused data to train and test WSD systems, areannotated based on very fine-grained distinctionsdefined in WordNet (Fellbaum, 1998), withhuman inter-annotator agreement at a little overseventy percent and the top-ranked systems?performances falling between 60%~70%(Palmer, et al, 2001; Mihalcea et al, 2004).
Thesecond source of difficulty for accurate WSDcomes from how senses are distributed.
It isoften the case that a polysemous word has adominant sense or several dominant senses thatoccur with high frequency and not enoughinstances can be found for its low frequencysenses in the currently publicly available data.There are on-going efforts to address theseissues.
For example, the sense annotationcomponent of the OntoNotes project (Hovy, etal., 2006) attempts to create a large-scale coarse-grained sense-annotated corpus with sensesdefined based on explicit linguistic criteria.These problems will be alleviated whenresources like this are available to the generalNLP community.
There have already beenexperiments that show such coarse-grainedsenses lead to substantial improvement in systemperformance (Palmer et al 2006).The goal of our experiments is to explore theimplications of a related and yet separateproblem, specifically the extent to which thelinguistic criteria used to define senses arerelated to what features need to be used inmachine-learning systems.
There are alreadypublished results that show WSD for differentsyntactic categories may need different types offeatures.
For example, Yarowsky and Florian(2002), in their experiments on SENSEVAL2English data, showed that sense distinctions ofverbs relied more on linguistically motivatedfeatures than other parts-of-speech.
In this paper,921we will go one step further and show that evenfor words of the same syntactic category sensesare often defined along different dimensionsbased on different criteria.
One direct implicationof this observation for supervised machine-learning approaches to WSD is that the featureshave to be customized for different wordcategories, or even for different words of thesame category.
This supports previous argumentsfor word-specific feature design and parametricmodeling for WSD tasks (Chen and Palmer,2005; Hoste et al 2002).
We report experimentson ten highly polysemous Chinese verbs andshow that features are not uniformly useful forall words.The rest of the paper is organized as follows.In Section 2, we describe our WSD system,focusing on the features we used.
We also brieflycompare the features we use for Chinese withthose used in a similar English WSD system.
InSection 3, we present our experimental resultsand show that although rich linguistic featuresand features derived from a Chinese SemanticRole Labeling improve the WSD accuracy, theimprovement is not uniform across all verbs.
Weshow that this lack of consistency is due to thedifferent dimensions along which the features aredefined.
In Section 4, we discuss related work.Finally Section 5 concludes this paper anddescribes future directions.2 WSD System for Chinese VerbsOur WSD system uses a smoothed maximumentropy (MaxEnt) model with a Gaussian prior(McCallum, 2002) for learning Chinese verbsenses.
The primary reason is that the MaxEntmodel provides a natural way for combiningdifferent features without the assumption offeature independence.
Furthermore, smoothingthe MaxEnt model with a Gaussian prior is betterthan other smoothing methods at alleviating theoverfitting problem caused by low frequencyfeatures (Chen et al, 1999).
This model has beenapplied successfully for English WSD (Dang,2004; Chen and Palmer, 2005).The features used by our Chinese WSDsystem include:Collocation Features- Previous and next word  (relative to the targetverb), w-1 and w1 and their parts-of-speech p-1and p1Syntactic Features- Whether the target verb takes a direct object(i.e., in a transitive use)- Whether the verb takes a sententialcomplement- Whether the verb, if it consists of a singlecharacter, occurs at the last position of acompound verbSemantic Features- The semantic role information about the verbs- The semantic categories for the verb?s NParguments from a general Chinese nounTaxonomyAll of these features require some level ofpreprocessing of the Chinese raw text, whichcomes without word boundaries.
To extract thecollocation features the raw text needs to besegmented and POS-tagged; to extract thesyntactic and semantic features, the Chinese textneeds to be parsed.
We use an integrated parserthat does segmentation, POS-tagging and parsingin one step.
Since part of the sense-tagged datacomes from the Chinese Treebank that the parseris trained on, we divide the Chinese Treebankinto nine equal-sized portions and parse eachportion with a parsing model trained on the othereight portions so that the parser has not seen anyof the data it parses.
The data that is not from theChinese Treebank is parsed with a parsing modeltrained on the entire Chinese Treebank.
Theparser produces a segmented, POS-tagged andparsed version of the same text to facilitate theextraction of the different types of features.
Theextraction of the semantic role labels as featuresrequires the use of a semantic role tagger, whichwe describe in greater detail in Section 2.2.In addition to using the semantic role labelinginformation, we also extract another type ofsemantic features from the verb?s NP arguments.These features are top-level semantic categoriesfrom a three-level general taxonomy for Chinesenouns, which was created semi-automaticallybased on two Chinese semantic dictionaries(Chen and Palmer, 2004).2.1 A Comparison with  Our English WSDSystemSimilar to our English WSD system, whichachieved the best published results onSENSEVAL2 English verbs for both fine-grained and coarse-grained senses (Chen andPalmer, 2005), our Chinese WSD system usesthe same smoothed MaxEnt machine learningmodel and linguistically motivated features forChinese verb sense disambiguation.
However,the features used in the two systems differ922somewhat  due to the different properties of  thetwo languages .For example, our English system uses theinflected form and the part-of-speech tag of thetarget verb as feature.
For Chinese we no longeruse such features since Chinese words, unlikeEnglish ones, do not contain morphology thatmarks tense.The collocation features used by our Englishsystem include bi-grams and tri-grams of thewords that occur within two positions before orafter the target verb and their part-of-speech tags.In contrast, our Chinese system extractscollocation features from a narrower, three-wordwindow, with one word immediately before andafter the target verb.
This decision was madebased on two observations about the Chineselanguage.
First, certain single-character Chineseverbs, such as the verbs ?
?|chu?, ??|kai?
and??|cheng?
in our experiments, often form acompound with  a verb to its immediate left.
Thatverb is often a good indicator of the sense of thisverb.
An example is given in (1):(1) ??
?
??
?Liaoning  already     show      completion???
??
??
?multidimensional   development        trend?Liaoning Province has shown the trend ofmultidimensional development.
?Being the last  word of a verb compound is astrong indicator for Sense 8 of the verb ??|chu1?
(used after a verb to indicate direction oraspect), as in ??
?|cheng2xian4?|chu1?.Second, unlike English common nouns thatoften require determiners such as the, a or an,Chinese common nouns can stand alone.Therefore, the direct object of a verb oftenoccurs right after the verb in Chinese, as shownin (2).?2???
??
??
??
?mobilize     people      tighten   waistband  collect?
?
??
(direct object)?funds   build highway?Mobilize people to tighten their waistbands (i.e.,save money) in order to collect funds to buildhighways.
?Based on these observations, we use wordssurrounding  the target verb and their part-of-speech tags  as collocation features.
A furtherinvestigation on the different sizes of the contextwindow (3,5,7,9,11) showed that  increasing thewindow size decreased our system?s accuracy.2.2 Features Based on Automatic SemanticRole TaggingIn a recent paper on the WSD of English verbs,Dang and Palmer (2005) showed that semanticrole information significantly improves the WSDaccuracy of English verbs for both fine-grainedand coarse-grained senses.
However, this resultassumes the human annotation of the PennEnglish Propbank (Palmer et al 2005).
It seemsworthwhile to investigate whether the semanticrole information produced by a fully automaticSemantic Role tagger can improve the WSDaccuracy on verbs, and test the hypothesis thatthe senses of a verb  have a high correlation tothe arguments it takes.
To that end, we assignedsemantic role labels to the arguments  of thetarget verb with a fully automatic semantic roletagger (Xue and Palmer, 2005) trained on theChinese Propbank (CPB) (Xue and Palmer,2003), a corpus annotated with semantic rolelabels that are similiar in style to the PennEnglish Propbank.
In this annotation, corearguments such as agent or theme are labeledwith numbered arguments such as Arg0 and Arg1,up to Arg5 while adjunct-like elements areassigned functional tags such as TMP (fortemporal), MNR, prefixed by ArgM.
TheSemantic Role tagger takes as input syntacticparses produced by the parser described above asinput and produces a list of arguments for eachof  the sense-tagged target verbs and assignsargument labels to them.
Features are extractedfrom both the core arguments and adjuncts of thetarget verb.
In addition to providing the sematnicrole labels (e.g., Arg0 and Arg1) of the extractedcore arguments, the Semantic Role tagger alsoprovides Hownet (Dong and Dong, 1991)semantic categories associated with thesearguments.
(3) shows the arguments for thetarget verb ???
identified by the Semantic Roletagger:(3)  [ArgM-MNR ??
?
?
?
?]
,through  three   year   hard   work,[arg0 ?
?]
[rel ?]
?whole   county   dig         finish[Arg1 ?
??]
?
?
?deep    well         three  classifier923?The whole county finished digging three deepwells through 3 years of hard work.
?Based on the output of the Semantic Role taggerand the Chinese noun taxonomy (as described  inSection 2.1), the following features are extracted:SRL+lex               SRL+HowNet     SRL+TaxonomyARG1-??
ARG1-??
ARG1_locationARG0-?
ARG0-??
ARG0_locationARGM|MNR-??
ARGM|MNR-??
ARGM|MNRIn this example, semantic role related featuresinclude: (1) the head word of the core arguments(ARG1-??
and ARG0-?)
and the adjunct(ARGM|MNR-??
); (2) the HowNet semanticcategory for the head word (ARG1-?
?, ARG0-?
?, ARGM|MNR-??
); (3) the semantic rolelabel of the adjunct (ARGM|MNR); and (4) thetop level semantic category from the taxonomyof Chinese nouns for the head word of the NParguments (ARG1_location and ARG0_location).3 Experimental ResultsThe data we used for our experiments aredeveloped as part of the OntoNotes project(Hovy et al, 2006) and they come from a varietyof sources.
Part of the data is from the ChineseTreebank (Xue et al 2005), which has acombination of Xinhua news and SinoramaNews Magazine.
Since some verbs have aninsufficient number of instances for anymeaningful experiments, we also annotatedportions of the People?s Daily corpus, developedby Peking University.
We chose not to use theChinese WSD dataset used in Senseval 3 1because we are mainly interested in investigatinghow the features used in WSD are related to thecriteria used to define the senses of Chineseverbs.
The Chinese Senseval dataset includesboth nouns and verbs.
In addition, the criteriaused to define their senses are not made explicitand therefore are not clear to us.Table 1 summarizes the corpus statistics andthe experimental results for the 10 highlypolysemous Chinese verbs used in ourexperiments.
The results were obtained by using5-fold cross validation.
The top five verbs areverbs that were identified as difficult verbs inDang et als (2002) experiments.
The first threecolumns show the verbs (and their pinyin), thenumber of instances and the number of senses for1 http://www.senseval.org/senseval3each verb in the data.
The fourth column showsthe sense entropy for each verb in its test data, ascalculated in Equation 1.
)(log)(1inii sensePsenseP?=?
(1)Where n is the number of senses of a verb in ourdata; )( isenseP is the probability of the ith senseof the verb, which is estimated based on thefrequency count of the verb?s senses in the data.Sense entropy generally reflects the frequencydistribution of senses in the corpus.
A verb withan evenly distributed sense distribution tends tohave a high entropy value.
However, a verb canalso have a high sense entropy simply because itis highly polysemous (say, has 20 or more senses)even though the sense distribution may beskewed, with one or two dominant senses.
Toseparate the effects of the number of senses, wealso use a normalized sense entropy metric (thesixth column in Table 1), as calculated inEquation 2.)1(log1)(log)(11nPnsensePsensePniinii??==??
(2)Here a large sense number n corresponds to ahigh value for the normalization factor)1(log11 nPnni?=?
.
Therefore, normalized senseentropy can indicate sense frequency distributionmore precisely than sense entropy.Table 1 (Columns 7 to 10) also shows theexperimental results.
As we can see, on average,our system achieved about 19% improvement(absolute gain) in accuracy compared to the mostfrequent sense baseline.
Its performance isconsistently better than the baseline for all 10verbs.3.1 Corpus Statistics and DisambiguationAccuracyThe data in Table 1 shows that verbs with a highnormalized sense entropy have the low frequencybaselines.
Furthermore, this relation is strongerthan that between un-normalized sense entropyand the baseline.
However, sense entropy is abetter predictor for system performance thannormalized sense entropy.
The reason is intuitive:unlike the baseline, the automatic WSD system,trained on the training data, does not only rely onsense frequency information to predict senses.924# ofinstance# ofsensesenseentropynorm.senseentropy baseline all feat all-SRL?|chu 271 11 1.12 0.47 74.54 79.70 78.59?
?|huifu 113 3 0.93 0.84 50.44 69.91 72.57?|jian 167 7 1.01 0.52 72.46 82.63 82.03?|xiang 231 6 1.00 0.56 65.80 76.19 77.49?|yao 254 9 1.56 0.71 33.46 46.46 49.21?|cheng 161 8 1.38 0.67 43.48 73.29 72.67?|da 313 21 2.29 0.75 20.77 45.05 32.59?|kai 382 18 2.31 0.80 19.37 50.00 39.27?
?|tongguo 384 4 0.97 0.70 55.73 81.51 79.17?
?|fazhan 1141 7 0.88 0.45 74.76 79.58 77.56average   9.4     51.08 70.18 67.13total 3417The number of senses has a direct impact on howmany training instances exist for each verb sense.As a consequence, it is more difficult for thesystem to make good generalizations from thelimited training data that is available for highlypolysemous verbs.
Therefore, sense entropy,which is based on both sense frequencydistribution and polysemy is more appropriatefor predicting system accuracy.
A relatedobservation is that the system gain (comparedwith the baseline) is bigger for verbs with a highnormalized sense entropy, such as ???|huifu?,?
?|da?, ?
?|kai?, and ??
?|tongguo?, than forother verbs; and the system gain is very small forverbs with low normalized sense entropy and arelatively large number of senses, such as ??|chu?
and ??
?|fazhan?, since they already havehigh baselines.3.2 The Effect of Semantic Role FeaturesWhen Semantic Role information is used infeatures, the system?s performance on averageimproves 3.05%, from 67.13% to 70.18%compared with when the features derived fromthe Semantic Role information is not used.
If welook at the system?s performance on individualverbs, the results show that adding SemanticRole information as features improves theaccuracy of 7 of the 10 verbs.
For the remaining3 verbs, adding semantic role informationactually hurts the system?s performance.
Webelieve this apparent inconsistency can beexplained by looking at how senses are definedfor the different verbs.
The two verbs thatpresent the most challenge to the system, are??|da?
and  ??|yao?
While Semantic Rolefeatures substantially improve the accuracy of?
?|da?, they actually hurt the accuracy of ??|yao?.
For ?
?|yao?, its three most frequentsenses account for 86% of its total instances (232out of 270) and they are the ?intend to?, ?must,should?
and ?need?
senses:(4) Three most frequent senses of ??|yao?
(a)  ??
??
?
???
??
?two sides  indicate  intend  further   cooperation?The two sides indicated that they intended to step uptheir cooperation.?
(b) ?
?
?
?
??
?
??
?road  very  slippery,     everybody  should  careful?The road is slippery.
Everybody should be careful.?
(c) ??
?
?
?
?Suzhou Steel Works  every   year    need   depend???
??
??
?the Great Canal      transport    raw material?Suzhou Steel Works needs to depend on the GreatCanal to transport raw material.
?Two of the senses, ?must?
and ?need?, areused as auxiliary verbs.
As such, they do not takearguments in the same way non-auxiliary verbsdo.
For example, they do not take noun phrasesas arguments.
As a result, the Semantic Roletagger, which assigns argument labels to headwords of noun phrases or clauses, cannotproduce a meaningful argument for an auxiliaryverb.
For the ?intend to?
sense, even if it is notTable 1 Corpus Statistics and Experimental Results for the 10 Chinese Verbs925an auxiliary verb, it still does not take a nounphrase as an object.
Instead, its object is a verbphrase or a clause, depending on the analysis.The correct head word of its argument should bethe lower verb, which apparently is not a usefuldiscriminative feature either.In contrast, the senses of ??|da?
are generallydefined based on their arguments.
The three mostfrequent senses of ?
?
|da?
are ?call bytelephone?, ?play?
and ?fight?
and they accountfor 40% of the ??|da?
instances.
Some examplesare provided in (5)(5) Top three senses of ??|da?
(a) ?
??
??
?you   have     queue in long line     call??
??
?
??
?
?public   phone  DE     experience    ma?Do you have the experience of queuing in a lineand waiting to make a call with a public phone??
(b) ??
??
??
?
?a few     on duty    personnel      sit?
?
?
??
?one      circle     play    poker?A few of the personnel on duty were sitting in acircle and playing poker.?
(c) ??
?
??
??
?
?mobilize    whole society  power   fight??
??
?
?helping the poor crucial battle?
?mobilize the power of the whole society andfight the crucial battle of helping the poor.
?The senses of ??|da?
are to a large extentdetermined by its PATIENT (or Arg1) argument,which is generally realized in the object position.The Arg1 argument usually forms highlycoherent lexical classes.
For example, the Arg1of the ?call?
sense can be ?
?
?|dianghua/phone, ???|shouji/cellphone?,etc.
its Arg1 argument can be ?
?
?|langqiu/basketball?, ?
??
|qiaopai/bridge?,??
?|youxi/game?, etc for the "play" sense,Finally , for its sense ?fight?, the Arg1 argumentcan be ??
?|gongjian/crucial ?|zhan/battle?,???
|xiangzhang/street warfare?, ????
?youjizhan/guerilla warfare?, etc..
It?s notsurprising that recognizing the arguments of??|da?
is crucial in determining its sense.The accuracy for both verbs is still very low,but for very different reasons.
In the case of?
?|yao4?, the challenge is identifyingdiscriminative features that may not be found inthe narrow local context.
These could forinstance include discourse features.
In the case of?
?|da?, one important reason why the accuracyis still low is because ??|da?
is highlypolysemous and has over forty senses.
Given itslarge number of senses, the majority of its sensesdo not have enough instances to train areasonable model.
We believe that more data willimprove its WSD accuracy.There are other dimensions along which verbsenses are defined in addition to whether or not averb is an auxiliary verb and what type ofauxiliary verb it is, and what types of argumentsit takes.
One sense of ??|chu?
is a verb particlethat indicates the direction or aspect of the mainverb that generally immediately precedes it.
Inthis case the most important feature foridentifying this sense is the collocation feature.Our experimental results seem to lend supportto a WSD approach where features are tailored toeach target word, or at least each class of words,based on a careful analysis of the dimensionsalong which senses are defined.
Automaticfeature selection (Blum and Langley, 1997)could also prove useful in providing this type oftailoring.
An issue that immediately arises is thefeasibility of this approach.
At least for Chinese,the task is not too daunting, as the number ofhighly polysemous verbs is small.
Our estimationbased on a 250K-word chunk of the ChineseTreebank and a large electronic dictionary in ourpossession shows only 6% or 384 verb typeshaving four or more definitions in the dictionary.Even for these verbs, the majority of them arenot difficult to disambiguate, based on work byDang et al (2002).
Only a small number of theseverbs truly need customized features.4 Related workThere is a large body of literature on WSD andhere we only discuss a few that are most relevantto our work.
Dang and Palmer (2005) also usepredicate-argument information as features intheir work on English verbs, but their argumentlabels are not produced by an automatic SRLsystem.
Rather, their semantic role labels aredirectly extracted from a human annotated926corpus, the English Proposition Bank (Palmer etal, 2005), citing the inadequate accuracy ofautomatic semantic role labeling systems.
Incontrast, we used a fully antomated SRL systemtrained on the Chinese Propbank.
Nevertheless,their results show, as ours do, that the use ofsemantic role labels as features improves theWSD accuracy of verbs.There are relatively few attempts to uselinguistically motivated features for Chineseword sense disambiguation.
Niu et al(2004)applied a Naive Bayesian model to ChineseWSD and experimented with different windowsizes for extracting local and topical features anddifferent types of local features (e.g., bigramtemplates, local words with position or parts-of-speech information).
One basic finding of theirexperiments is that simply increasing the windowsize for extracting local features or enriching theset of local features does not improvedisambiguation performance.
This is consistentwith our usage of a small size window forextracting bigram collocation features.
Li et al(2005) used sense-tagged true bigramcollocations 2  as features.
These features wereobtained from a collocation extraction systemthat used lexical co-occurrence statistics toextract candidate collocations and then selectedtrue collocations by using syntactic dependencies(Xu et al, 2003).
In their experiments onChinese nouns and verbs extracted from thePeople?s Daily News and the SENSEVAL3 dataset,  the Naive Bayesian classifier using truecollocation features generally performed betterthan that using simple bigram collocationfeatures (i.e., bigram co-occurence features).
It isworth noting that the true collocations overlap toa large degree with rich syntactic informationused here such as the subject and direct object ofa target verb.
Therefore, their experiments showevidence that rich linguistic information benefitsWSD on Chinese, consistent with our results.Our work is more closely related to the workof Dang et al(2002), who conductedexperiments on 28 verbs and achieved anaccuracy of 94.2%.
However the high accuarcy islargely due to  the fact that their verbs arerandomly chosen from the Chinese Treebank andsome of them are not even polysemous (having asingle sense).
Extracting features from the gold2 In their definition, a collocation is a recurrent andconventional fixed expression of words that holdssyntactic and semantic relations.standard parses also contributed to the highaccuracy, although not by much.
For 5 of their 28verbs, their initial experimental results did notbreak the most frequent sense baseline.
Theyannotated additional data on those five verbs andtheir system trained on this new data didoutperfom the baseline.
However, theyconcluded that the contribution of linguisticmotivated features, such as features extractedfrom a syntactic parse, is insignificant, a findingthey attributed to unique properties of Chinesegiven that the same syntactic featuressignificantly improves the WSD accuracy.
Ourexperimental results show that this conclusion ispremature, without a detailed analysis of thesenses for the individual verbs.5 Conclusion and future workWe presented experiments with ten highlypolysemous Chinese verbs and showed that aprevious conclusion that rich linguistic featuresare not useful for the WSD of Chinese verbs ispremature.
We demonstrated that rich linguisticfeatures, specifically features based on syntacticand semantic role information, are useful for theWSD of Chinese verbs.
We believe that theWSD systems can benefit even more from richlinguistic features as the performance of otherNLP tools such as parsers and Semantic RoleTaggers improves.
Our experimental results alsolend support to the position that feature designfor WSD should be linked tightly to the study ofthe criteria that sense distinctions are based on.This position calls for the customization offeatures for individual verbs based onunderstanding of the dimensions along whichsense distinctions are made and a closer marriagebetween machine learning and linguistics.
Webelieve this represents a rich area of explorationand we intend to experiment with more verbswith further customization of features, includingexperimenting with automatic feature selection.AcknowledgementThis work was supported by National ScienceFoundation Grant NSF-0415923, Word SenseDisambiguation, the DTO-AQUAINT NBCHC-040036 grant under the University of Illinoissubcontract to University of Pennsylvania 2003-07911-01 and the GALE program of the DefenseAdvanced Research Projects Agency, ContractNo.
HR0011-06-C-0022.
Any opinions, findings,and conclusions or recommendations expressedin this material are those of the authors and do927not necessarily reflect the views of the NationalScience Foundation, the DTO, or DARPA.ReferencesAvrim L. Blum and Pat Langley.
1997.
Selection ofrelevant features and examples in machine learning.Artificial Intelligence, 97:245-271, 1997.Jinying Chen and Martha Palmer.
2004.
Chinese VerbSense Discrimination Using an EM ClusteringModel with Rich Linguistic Features, In Proc.
ofthe 42nd Annual meeting of the Assoication forComputational Linguistics, ACL-04.
July 21-24,Barcelona, SpainJinying Chen and Martha Palmer.
2005.
TowardsRobust High Performance Word SenseDisambiguation of English Verbs Using RichLinguistic Features.
In Proc.
of the 2ndInternational Joint Conference on NaturalLanguage Processing.
Jeju Island, Korea, in press.Stanley.
F. Chen and Ronald Rosenfeld.
1999.
AGaussian Prior for Smoothing Maximum EntropyModals.
Technical Report CMU-CS-99-108, CMU.Hoa T. Dang, Ching-yi Chia, Martha Palmer and Fu-Dong Chiou.
2002.
Simple Features for ChineseWord Sense Disambiguation.
In Proceedings ofCOLING-2002, the Nineteenth Int.
Conference onComputational Linguistics, Taipei, Aug.24?Sept.1.Hoa T. Dang.
2004.
Investigations into the role oflexical semantics in word sense disambiguation.PhD Thesis.
University of Pennsylvania.Hoa Dang and Martha Palmer.
2005.
The role ofsemantic roles in  disambiguating verb senses.
InProceedings of ACL-05, Ann Arbor, Michigan.Zhendong Dong and Qiang Dong, HowNet.
1991.http://www.keenage.com.Christiane Fellbaum, ed.
1998.
WordNet: AnElectronic Lexical Database.
Cambridge, MA:MIT Press.Veronique Hoste, Iris Hendrickx, Walter Daelemans,and Antal van den Bosch.
2002.
Parameteroptimization for machine-learning of word sensedisambiguation.
NLE, Special Issue on Word SenseDisambiguation Systems, 8(4):311?325.Eduard Hovy, Mtchchell Marcus, Martha Palmer,Lance Ramshaw and Ralph Weischedel.
2006.OntoNotes: the 90% solution.
In Proceedings of theHLT-NAACL 2006, New York City.Wanyin Li, Qin Lu and Wenjie Li.
2005.
IntegratingCollocation Features in Chinese Word SenseDisambiguation.
In Proceedings of the FourthSighan Workshop on Chinese Language Processing.pp: 87-94.
Jeju, Korea.Andrew K. McCallum: MALLET: A MachineLearning for Language Toolkit.
http://www.cs.umass.edu/~mccallum/mallet (2002).Rada Mihalcea, Timothy Chklovski and AdamKilgarriff.
2004.
The Senseval-3 English lexicalsample task.
In Proceedings of Senseval-3: TheThird International Workshop on the Evaluation ofSystems for the Semantic Analysis of Text.Barcelona, Spain.
July.Zheng-Yu Niu, Dong-Hong Ji and Chew Lim Tan,Optimizing Feature Set for Chinese Word SenseDisambiguation.
2004.
In Proceedings of the 3rdInternational Workshop on the Evaluation ofSystems for the Semantic Analysis of Text(SENSEVAL-3).
Barcelona, Spain.Martha Palmer, Christiane Fellbaum, Scott Cotton,Lauren Delfs, and Hoa Trang Dang.
2001.
Englishtasks: All-words and verb lexical sample.Proceedings of Senseval-2: Second InternationalWorkshop on Evaluating Word SenseDisambiguation Systems, Toulouse, France, 21-24.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An Annotated Corpusof Semantic Roles, Computational Linguistics,31(1): 71?106.Martha Palmer, Christiane Fellbaum and Hoa TrangDang.
(to appear, 2006).
Making fine-grained andcoarse-grained sense distinctions, both manuallyand automatically.
Natural Language Engineering.Ruifeng Xu , Qin Lu, and Yin Li.
2003.
An automaticChinese Collocation Extraction Algorithm BasedOn Lexical Statistics.
In Proceedings of theNLPKE Workshop.
Beijing, China.Nianwen Xue, Fei Xia, Fu-Dong Chiou and MarthaPalmer.
2005.
The Penn Chinese Treebank: PhraseStructure Annotation of a Large Corpus.
NaturalLanguage Engineering, 11(2):207-238.Nianwen Xue and Martha Palmer.
2003.
AnnotatingPropositions in the Penn Chinese Treebank, InProceedings of the 2nd SIGHAN Workshop onChinese Language Processing, in conjunction withACL'03.
Sapporo, Japan.Nianwen Xue and Martha Palmer.
2005.
AutomaticSemantic Role Labeling for Chinese Verbs.
InProceedings of the 19th International JointConference on Artificial Intelligence.
Edinburgh,Scotland.David Yarowsky and Radu Florian.
2002.
Evaluatingsense disambiguation across diverse parameterspaces.
Journal of Natural Language Engineering,8(4): 293?310.928
