INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 100?104,Utica, May 2012. c?2012 Association for Computational LinguisticsWorking with Clinicians to Improve a Patient-Information NLG SystemSaad Mahamood and Ehud ReiterDepartment of Computing ScienceUniversity of AberdeenAberdeen, Scotland, United Kingdom{s.mahamood, e.reiter}@abdn.ac.ukAbstractNLG developers must work closely with do-main experts in order to build good NLG sys-tems, but relatively little has been publishedabout this process.
In this paper, we describehow NLG developers worked with clinicians(nurses) to improve an NLG system whichgenerates information for parents of babies ina neonatal intensive care unit, using a struc-tured revision process.
We believe that such aprocess can significantly enhance the qualityof many NLG systems, in medicine and else-where.1 IntroductionLike other artificial intelligence (AI) systems, mostNatural Language Generation (NLG) systems incor-porate domain knowledge (and domain communica-tion knowledge (Kittredge et al, 1991)), either im-plicitly or explicitly.
Developers must work with do-main experts to acquire such knowledge.
Also likesoftware systems in general, applied NLG systemsmust meet domain and application specific require-ments in order to be useful; these again must comefrom domain experts.Since very few domain experts are familiar withNLG, it is usually extremely difficult to acquire acomplete set of requirements, domain knowledge,and domain communication knowledge at the be-ginning of an NLG project.
Especially, if no pre-existing ?golden standard?
corpus of domain textsexists.
Indeed, in many cases domain experts mayfind it difficult to give detailed requirements andknowledge until they can see a version of the NLGsystem working on concrete examples.
This sug-gests that an iterative software development method-ology should be used, where domain experts re-peatedly try out an NLG system, revise underly-ing domain (communication) knowledge and re-quest changes to the system?s functionality, and waitfor developers to implement these changes before re-peating the process.We describe how we carried out this process onBabyTalk-Family (Mahamood and Reiter, 2011), anNLG system which generates summaries of clini-cal data about a baby in a neonatal intensive careunit (NICU), for the babys parents.
Over a 6 monthperiod, this process enabled us to improve an ini-tial version of the system (essentially the result ofa PhD) to the point where the system was goodenough to be deployable live in a hospital context.We also describe how the feedback from the clini-cians changed over the course of this period.2 Previous ResearchReiter et al (2003) describe a knowledge acquisi-tion strategy for building NLG systems which in-cludes 4 stages: directly asking domain experts forknowledge, structured knowledge acquisition activ-ities with experts, corpus analysis, and revision withexperts.
In this paper we focus on the last of thesephases, revision with experts.
Reiter et al describethis process in high-level qualitative terms; in thispaper our goal is to give a more detailed descriptionof the methodology, and also concrete data aboutthe comments received, and how they changed overtime.The most similar previous work which we are100aware of is Williams and Reiter (2005), who de-scribe a methodology for acquiring content selectionrules from domain experts, which is also based onan iterative refinement process with domain experts.Their process is broadly similar to what we describein this paper, but they focus just on content selection,and do not give quantitative data about the revisionprocess.In the wider software engineering community,there has been a move to iterative developmentmethodologies, instead of the classic ?waterfall?pipeline.
In particular, agile methodologies (Mar-tin, 2002) are based on rapid iterations and frequentfeedback from users; we are in a sense trying to ap-ply some ideas from agile software engineering tothe task of building NLG systems.
Our methodologyalso can be considered to be a type of user-centreddesign (Norman and Draper, 1986).3 BabyTalk-FamilyBabyTalk-Family (Mahamood and Reiter, 2011)generates summaries of clinical data about babies ina neonatal intensive care unit (NICU) for parents.For more details about BabyTalk-Family, includingexample outputs, please see Mahamood and Reiter.BabyTalk-Family (BT-Family) was initially de-veloped as part of a PhD project (Mahamood, 2010).As such it was evaluated by showing output texts(based on real NICU data) to people who had previ-ously had a baby in NICU; the texts did not describethe subject?s own baby (i.e., the subjects read textswhich summarised other people?s babies; they hadno previous knowledge of these babies).
BT-Familywas also not rigorously tested from a software qual-ity assurance perspective.
The work presented herearose from a followup project whose goal was to de-ploy BT-Family live in a NICU, where parents whocurrently had babies in NICU could read summariesof their baby?s clinical data.
Such a deployment re-quired generated texts to be of much higher quality(in terms of both content and language); we achievedthis quality using the revision process described inthis paper.BT-Family is part of the BabyTalk family of sys-tems (Gatt et al, 2009).
All BabyTalk systems usethe same input data (NICU patient record), but theyproduce different texts from this data; in particularBT45 (Portet et al, 2009) produces texts which sum-marise short periods to help real-time decision mak-ing by clinicians, and BT-Nurse (Hunter et al, 2011)produces summaries of 12 hours of data for nurses,to support shift handover.
BT-Nurse was also de-ployed in the ward, to facilitate evaluation by nurseswho read reports about babies they were currentlylooking after.
To support this deployment, the BT-Nurse developers spent about one month carryingout a revision process with clinicians, in a somewhatunstructured fashion.
One outcome of the BT-Nurseevaluation was that the system suffered because therevision process was neither sufficiently well struc-tured nor long enough; this was one of the motiva-tions for the work presented here.4 Revision MethodologyThe revision process was carried out at the Neona-tal Intensive Care Unit in conjunction with the hos-pital Principal Investigator (PI) of our project andtwo research nurses.
We started with an initial fa-miliarisation period for the nurses (the hospital PIwas already familiar with BT-Family), where we ex-plained the goals of the project and asked the nursesto examine some example BT-Family texts, whichwe then discussed.After the nurses were familiar with the project, weconducted a number of revision cycles.
Each cyclefollowed the following procedure:1.
The clinicians (either the hospital PI or the researchnurses) choose between 3 and 11 scenarios (oneday?s worth of data from one baby).
These scenar-ios were chosen to test the system against a diverserange of babies in different clinical conditions; sce-narios were also chosen to check whether issuesidentified in previous cycles had been addressed.2.
The nurses examined the texts generated by BT-Family for the chosen scenarios.
They both directlycommented on the texts (by writing notes on hard-copy), and also (in some cases) edited the texts toshow what they would have liked to see.3.
The NLG developers analysed the comments andrevised texts; distilled from these a list of specificchange requests; prioritised the change requests onthe basis of importance and difficulty; and imple-mented as many change requests as possible giventhe time constraints of the cycle.101Figure 1: Example of marked up text annotated by a research nurse.
The baby?s forename has been blacked out.4.
The scenarios were rerun through the updated sys-tem, and the NLG developers checked that the is-sues had been addressed.
Clinicians did not usuallylook at the revised texts, instead they would checkthat the issues had been resolved in new scenariosin the next cycle.The above process was carried out 14 times overa 6 month period with each cycle taking on average11.28 days.
A research fellow (Saad Mahamood)was assigned to implement these changes workingfull-time over this 6 month period.
The length be-tween each revision cycle was variable due to theavailability of the domain experts and the variablelevel of complexity to implement identified changesto the BT-Family system.Figure 1 shows a extract from an early BT-Familytext generated in July 2011 that needed a lot of re-vision.
In this example, the nurse has identified thefollowing issues:?
Incorrect pronoun: He instead of His.?
Unnecessary phrase: Because XXXX was born ear-lier than expected.?
Change in tense: is being instead of has been.?
Change in wording of time phrase: In the last 24hours instead of Since yesterday.?
Incorrect content: incubator oxygen has increased,it is not stable.?
Grammar mistake: were instead of was.?
Change in content: some (frequency) instead ofmoderate (severity).?
Change in wording: self-resolving instead of self-resolved.5 Analysis of Feedback over TimeWe extracted hand-written comments on BT-Familytexts (of the type shown in Figure 1) and annotatedthe comments using a scheme similar to that usedby Hunter et al(2011) for analysing comments onBT-Nurse texts.
Two annotators were used with thefirst annotating the entire set of 75 reports using apre-agreed classification scheme.
The classificationscheme that was used consisted of three types ofcategories: Content Errors, Language Errors, andComments with each containing specific categori-sation labels as shown in Table 1.
Content Errorslabels were used to annotate comments when therewere content based mistakes.
Language error labelswere used to categorise the different types of lan-guage based mistakes.
Finally, comment labels wereused to classify different types of comments madeby the nurses.
The second annotator annotated arandom partial subset of the reports independentlyto check for the level of agreement between the firstand second annotators.
By using Cohen?s kappa co-efficient we found the level of inter-annotator agree-ment was k=0.702.Content errors were the most predominate type ofannotation (50.54%), followed by Language errors(25.18%), and comments (24.27%).
Positive com-ments were unusual (only 5 in total), because theclinicians were explicitly asked to focus on prob-102Content Errors Language Errors Commentunnecessary (44.20%) spelling mistake (8.14%) positive (3.75%)missing (28.26%) grammar mistake (22.22%) negative (0.75%)wrong (22.82%) incorrect tense/aspect (18.51%) no agreement (1.50%)should-be-elsewhere (4.71%) different word(s) required (35.55%) reformulation (12.78%)unnecessary words (3.70%) observation (66.16%)precision/vagueness (11.85%) question (15.03%)Table 1: List of annotation categories and the labels within each category that was used.
The frequency for each labelin it?s category is given in brackets.Month Number of Avg.
scenarios Avg.
number of Avg.
number of Avg.
number ofrevision cycles per cycle content errors language errors commentsJune 1 5 1.8 4.2 1.2July 2 8 4.93 5.5 1.87August 2 5 4.8 4 5.8September 2 4 6.37 8.5 4October 3 7 2.95 1.57 6.42November 3 5 1.6 1.6 3.6December 1 5 0.8 0 0.4Overall 14 5.7 6.92 3.62 3.32Table 2: Summary table showing the average number of content errors, language errors, and comments per scenario.lems.
Table 2 shows statistics for the revision pro-cess per month; the process started in the second halfof June, and ended in the first half of December.From a qualitative perspective, the data suggeststhat there were two phases to the revision process.In the first phase (June to September), the numberof content and language errors in fact went up.
Webelieve this is because during this phase we wereadding around 16 new types of content to the re-ports (based on requests from the clinicians) as wellas fixing problems with existing content (of the sortshown in Figure 1); this additional content itself of-ten needed to be revised in subsequent revision cy-cles, which increased the error count for these cy-cles.
These additional errors from the addition ofnew content may of arisen due to the complexityand variation of clinical data.
Additionally, our 3-year old anonymised test set of clinical data maynot of been as representative as the live data dueto changes/additions in patient data.
In the sec-ond phase (October to December), requests for newcontent diminished (around 4 requests) and we fo-cused on fixing problems with existing content; inthis phase, the number of content and language er-rors steadily decreased (that is, the system improvedfrom the clinician?s perspective), until we reachedthe point in mid December when the clinicians weresatisfied that the quality of BT-Family texts was con-sistently good from their perspective.When the revision process ended, we started eval-uating BT-Family texts directly with parents, byshowing parents texts about their babies.
This workis ongoing, but initial pilot results to date indicatethat parents are very happy with the texts, and donot see major problems with either the language orthe content of the texts.6 DiscussionThe revision process had a major impact on the qual-ity of BT-Family texts, as perceived by the clini-cians.
At the start of the process (June 2011), thetexts had so many mistakes that they were unusable;the clinicians would not allow us to show parentsBT-Family texts about their babies, even in the con-text of a pilot study.
After 14 revision rounds over a6 month period, text quality had improved dramati-cally, to the point where clinicians allowed us to startworking directly with parents to get their feedbackand comments on BT-Family texts.The fact that a new set of scenarios was used inevery iteration of the revision process was essen-103tial to giving clinicians confidence that text qualitywould be acceptable in new cases; they would nothave had such confidence if we had focused on im-proving the same set of texts.The revision process took 6 months, which is aconsiderable amount of time.
This process wouldhave been shorter if BT-Family had undergone amore rigorous testing and quality assurance (QA)process ahead of time, which would for examplehave addressed grammar mistakes, and (more im-portantly) tested the system?s handling of boundaryand unusual cases.
The process probably could alsohave been further shortened in other ways, for ex-ample by performing 3 revision cycles per monthinstead of 2.However, one reason the process took so long wasthat the functionality of the system changed; as theclinicians got a better idea of what BT-Family coulddo and how it could help parents, they requestednew features, which we tried to add to the systemwhenever possible.
We also had to accommodatechanges in the input data (patient record), whichreflected changes in NICU procedures due to newdrugs, equipment, procedures, etc.
So we were notjust tweaking the system to make it work better, wewere also enhancing its functionality and adapting itto changing input data, which is a time consumingprocess.7 ConclusionWe have presented a methodology for improvingthe quality and appropriateness of texts produced byapplied NLG systems, by repeatedly revising textsbased on feedback from domain experts.
As we haveshow in the results, the process is a time consumingone, but appears to be quite effective in bringing anNLG system to the required level of quality in a clin-ical domain.AcknowledgementsThis work is funded by the UK Engineering and Physical SciencesCouncil (EPSRC) and Digital Economy grant EP/H042938/1.
Manythanks to Dr. Yvonne Freer, Alison Young, and Joanne McCormick ofthe Neonatal Intensive Care Unit at Simpson Centre for ReproductiveHealth, Royal Infirmary of Edinburgh Hospital, for their help.ReferencesAlbert Gatt, Francois Portet, Ehud Reiter, Jum Hunter,Saad Mahamood, Wendy Moncur, and SomayajuluSripada.
2009.
From data to text in the neonatal in-tensive care unit: Using NLG technology for decisionsupport and information management.
AI Communi-cations, 22(3):153?186.James Hunter, Yvonne Freer, Albert Gatt, Ehud Reiter,Somayajulu Sripada, Cindy Sykes, and Dave Westwa-ter.
2011.
BT-Nurse: Computer generation of natu-ral language shift summaries from complex heteroge-neous medical data.
Journal of the Americal MedicalInformatics Association, 18(5):621?624.Richard Kittredge, Tanya Korelsky, and Owen Rambow.1991.
On the need for domain communication lan-guage.
Computational Intelligence, 7(4):305?314.Saad Mahamood and Ehud Reiter.
2011.
Generatingaffective natural language for parents of neonatal in-fants.
In Proceedings of the 13th European Work-shop on Natural Language Generation, pages 12?21,Nancy, France, September.
Association for Computa-tional Linguistics.Saad Mahamood.
2010.
Generating Affective NaturalLanguage for Parents of Neonatal Infants.
Ph.D. the-sis, University of Aberdeen, Department of Comput-ing Science.Richard Martin.
2002.
Agile Software Development,Principles, Patterns, and Practices.Donald A. Norman and Stephen W. Draper.
1986.User Centered System Design; New Perspectives onHuman-Computer Interaction.
L. Erlbaum AssociatesInc., Hillsdale, NJ, USA.Franc?ois Portet, Ehud Reiter, Albert Gatt, Jim Hunter,Somayajulu Sripada, Yvonne Freer, and Cindy Sykes.2009.
Automatic generation of textual summariesfrom neonatal intensive care data.
Artificial Intelli-gence, 173(7-8):789?816.Ehud Reiter, Somayajulu Sripada, and Roma Robertson.2003.
Acquiring correct knowledge for natural lan-guage generation.
Journal of Artificial IntelligenceResearch, 18:491?516.Sandra Williams and Ehud Reiter.
2005.
Deriving con-tent selection rules from a corpus of non-naturally oc-curring documents for a novel NLG application.
InProceedings of Corpus Linguistics workshop on usingCorpora for NLG.104
