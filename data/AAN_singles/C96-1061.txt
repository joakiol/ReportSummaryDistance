Using Discourse Predictions for Ambiguity ResolutionYan Qu, Carolyn P. Ros6 and Barbara Di EugenioComputat iona l  L ingu is t i cs  P rogramDepar tment  of Ph i losophyCarneg ie  Mel lon Un ivers i tyPittsburgh, PA 15213{yqu,cprose}  (6) cs .cmu.edu ,d ieugen i~cmu.cduAbst ractIn this paper we discuss how we all-ply discourse predictions along with noncontext-based predictions to the prob-lem of parse disambiguation i Enthusi-ast, a Spanish-to-English translation sys-tem (Woszcyna et al, 1993; Snhm et al,1994; Levin el; al., 1995).
We discussextensions to our plan-based discourseprocessor in order to make this possi-ble.
We evaluate those extensions anddemonstrate the advantage of exploitingcontext-based predictions over a purelynon context-based approach.1 Introduct ionA system which processes poken language mustaddress all of the ambiguities arising when pro-cessing written language, plus other ambiguitiesspecitie to the speech processing task.
Theseinclude ambiguities derived from speech disflu-encies, speech recognition errors, and the lackof clearly marked sentence boundaries.
Becausea large flexible grammar is necessary to handlethese features of spoken language, as a side-effectthe number of ambiguities increases.
In this pa-per, we discuss how we apply discourse predic-tions along with non context-based predictions tothe problem of parse disambiguation.
This workhas been carried out in the context of Enthusi-ast, a Spanish-to-English speech-to-speech trans-lation system (Woszcyna et al, 1993; Suhm et al,1994; Levin et al, 1995), which currently trans-lates spontaneous dialogues between two peopletrying to schedule a meeting time.A key feature of our approach is that it al-lows multiple hypotheses to be processed throughthe system in parallel, and uses context to disam-biguate among alternatives in the linal stage of theprocess, where knowledge can be exploited to thefullest extent.
In our system, numerical predic-tions based on the more local utterance level aregenerated by tile parser.
The larger discourse con-text is processed and maintained by a plan-baseddiscourse processor, which also produces context-based predictions for ambiguities.
Our goal wasto combine the predictions from the context-baseddiscourse processing approach with those from thenon context-based parser approach.In developing our discourse processor for disam-biguation we needed to address three major issues.First, most plan-based or finite state automatonbased discourse processors (Allen and Schubert,1991; Smith, Hipp, and Biermann, 1995; Lam-bert, 1993; Reithinger and Maim:, 1995), includingtile one we initially developed (l~.osd et al, 1995),only take one semantic representation as input ata time: thus, we had to extend the discourse pro-cessor so thai; it can handle multiple hypotheses asinput.
Secondly, we needed to quantify the disam-biguating predictions made by the plan-based is-course processor in order to combine these predic-tions with the non context-based ones.
Finally, weneeded a method for combining context-based andnon context-based predictions in such a way as toreflect not only which factors are important, butalso to what extent they are important, and underwhat circumstances.
We assume that knowledgefrom different sources provides different perspec-tives on the disambiguation task, each specializingin different ypes of ambiguities.In this paper, we concentrate on the first twoissues which are imperative to integrate a tradi-tional plan-based iscourse processor into the dis-ambiguation module of a whole system.
The thirdissue is very important for successful confl)inationof predictions from different knowledge sources.We address this issue elsewhere in (Rosd and Qu,1995).The paper is organized as follows: Fh'st, webriefly introduce the Enthusiast speech transla-tion system and discuss the ambiguity problemin Enthusiast.
Then we discuss our discourse pro-cessor, focusing on those characteristics needed togenerate predictions lbr disambiguation.
Finally,we evaluate our performance, and demonstratethat tile use of discourse context improves per-formance on disambiguation tasks over a purelynon context-based approach in the absence of cu-mulative error.3582 System DescriptionThe main modules of our system include speechrecognition, parsing, discourse processing, andgeneration.
Processing begins with tim speechinput in the source language.
The top best hy-pothesis of the speaker's utterance is then passedto Lhe parser.
The GLR* parser (Lavie, 1995)produces a set of interlingua texts, or ILFs, for agiven sentence.
For robustness, the.
(-ILI{,* parsercan skil) words in the inpu/, sentence in order tofind a partial parse for a sentence which otherwisewould not be parsable.
An 11:I' is a frame-basedlanguage, independent meaning reprcsen ration of asentence.
The main components of an 11:1' are thesl)eech act (e.g., suggest ,  accept ,  re jec t ) ,  thesentence type (e.g., s ta te ,  query-J.g, fragraent),and the main semantic frame (e.g., I ree ,  busy).An example of an IUI' is shown in Figure 1.
Theparser may produce many Ilfl's for a single sen-tencej sometimes as many as one  hundred or lnore.
((when((fi'ame *simple-time)(day-of-week wednesday)(tin, e-or-day ,noruing)))(a-speech-act(*multiple* *suggest *accept))(who((frame *i)))(frame *free)(sentence-type *state)))Sentence :  1 couhl do it; Wednesday niol'ning too.Figure 1: An  Example  ILT'\['he resulting set of l l Ts  is then sent to the dis-course processor.
The discourse l)rocessor, basedon I,ambert's work (\[,ambert and Carberry, 1992;I,ambert, 1993), disaml)iguates tile sl)eech act ofe~(;h sentence~ normalizes temporal expressions(?oin context, and incorl)orates the seltt, enee intotile discourse context represented by a plan tree.The discourse l)roeessor also updal;es a calendarwhich keeps track of what the speakers h~we saidM)out their schedules.
We will discuss the dis-course i>rocessor and how we extended it for thedisambiguation task in Sectiou 4.3 Ambiguity it, Enthusias(;Because t;he spontal leous sche(\[lding dialogues 3,reunrestricted, ambiguity is a major problenl in En-thusiast.
We gange ambiguities in terms of dif-ferences between members of the set of ILTs pro-duced by the parse, r for the sail~|e source sentence.As we mentioned e, arlier, the disaanbiguation taskbenelits from both non (-ontexL- and context-l)~sedmethods.
We observed that some classes of am-biguities can be more l)erspieuously dealt with inone way or the other.3.1 Non Context -Based  D isambiguat ionWhen the parser produces more than one IlJl' fora single sentence, it scores these ambiguities ac-cording to three diti'e.rent non context-based is-aml)iguation inethods.
The first method, basedon (Carroll and Briscoc, 1993), assigns probal)il-ities to actions in the (~I,R,* l)arser's 1)arse table.The probabilities of the parse actions induce st,a-tistical scores on alternative parse trees, whichare then used for parse disambiguation.
The re-suiting score is called the slalislical score.
Thesecond method the parser uses to score the II/l'smakes use of penalties mammlly assigned to dif-ferent rules in the l)arsing grammar,  rl'he result-ing score from this method is called the gr'am-mar pr'cfercucc score.
The third score, called theparser score, is a heuristic combination of the pre-vious two scores ldUS other information such asthe number of words skil)ped.
These three llOllcontext-based scores will be referred to later whenwe discuss comt)ining non eontext-I)ased l)redic-t, ions with context-based ones.Error analysis of parser disambiguation outputshows that the C, IA{* parser handles well ambigu-ities which are not strongly dependent upon thecontext for a reasonable interpretation, laBr ex--ample, the Sl)anish word uua can mean either oucor a, as an indefinite reference.
The parser alwayschooses the indelinite reference meaning since thevast, majority of training examples use this senseof the word.
Moreover, since in this case incorrectdisambiguation does not adversely affect transla-tion quality, it; ramies sense to handle this ambi-guity in a purely non context-based manner.3.2 Context -Based  D isambiguat ionWhile a broad range of ambiguities can I)e hal>died well in ~ non context-basel\] manner, someambiguities must be treated in a contexl, se, nsitive manner in order to be translated correctly.Table 1 lists some examples of these tyt)es of atn--biguities.
Each type of ambiguity is categorizedby COml)aring either difl'erent slots in alternativell;l 's or dilt'erenL values in ambiguous II2F slol.sgiven \[;he same input utteran(;e.For example, one.
type o1" ambiguity l)est hat>dh'd with ~ contextd)ase(I approactl is the day vshour ~md)iguity, exenq)lified by tim phrase dos acua&v.
It can mean either Ihc second al J'o'a%lhc second lo the Jburlh or lwo go four.
Out ofconte.x|., it is iml)ossil)le to tell which is the I)cstintert)retation.
(~ontextua.l inlk)rmation makes il;possible to choose the correct interpreLal, ion.
I?or(;xaml)le, if l,h(: sl)eakers are trying to estal)lish adab: when they can meet,, then the sccoud to theJourlh is t;hc most liD~ly itd;erl)retatiotJ.
Itowcver,359Types  o f  Ambigu i ty  Descr ip t ionday  vs hour  a tempora l  express ion  can  berecogn ized  as a (lay or  all hours ta te  vs qaery - l f  ambigu i ty  between sentencetype  s ta te  or query - i fspeaker  re ference ambigu i ty  between pro -droppronounstense  ambigu i ty  between past  tenseand present  tensehow vs greet  ambigu i ty  between f rame howand greetwhen vs where  ambigu i ty  between when slotand  where  slotExa lnp lesdos  a cuat rosecond at four  orsecond to four th  ortwo to ,fourest~ b ienI t 's  OK or\[s it  OK?tambidn  podr \ [a  ese d\ [aalso i could that day oralso you  could that dayd6nde nos encont ramoswhere are we meet ing orwhere were we meet inqqu~ talHow are you?
orHow is that?s?bado  qu inceSaturday the f i f teenth orSaturday building 15Table 1: Examples  of  Context -Sens i t ive  Ambigu i t iesif the speakers have already chosen a date and arenegotiating the exact time of the meeting, thenonly the meaning two to four makes sense.Some sentence type ambiguities are alsocontext-based.
For example, l'Sstd bien can be ei-ther the statement It is good or the question Isit good?.
This is an example of what we call thes ta te  vs query- i : f  ambiguity: in Spanish, it isimpossible to tell out of context, and without in-formation about intonation, whether a sentenceis a statement or a yes/no question.
However, ifthe same speaker has just made a suggestion, thenit is more likely that the speaker is requesting aresponse from the other speaker by posing a ques-tion.
ht contrast, if the previous speaker has justmade a suggestion, then it is more likely that thecurrent speaker is responding with an acceptingstatement than posing a question.In generM, we base our context-based predic-tions for disambiguation on turn-taking informa-tion, the stage of negotiation, and the speakers'cMendar information.
This information is encodedin a set of context-based scores produced by thediscourse processor for each ILT.4 Discourse Processing andDisambiguationContext-based ranking of ambiguities is per-formed by the plan-based iscourse processor de-scribed in (Rosd et aL., 1995) which is based on(Lambert and Carberry, 1992; Lambert, 1993).OriginMly, our discourse processor took as its in-put the single best parse returned by the parser.q'he main task of the discourse processor was torelate that representation to the context, i.e., tothe plan tree.
In generaL, plan inference startsfrom the surface \[brms of sentences.
Then speech-acts are inferred.
Multiple speech-acts can be in-ferred for one ILT.
A separate inference chain iscreated for each potential speech act performedby the associated ILT.
Preferences for picking oneinference chain over another were determined bythe focusing heuristics, which provide ordered ex-pectations of discourse actions given the existingplan tree.
Our focusing heuristics, described indetail in (l{os6 et al, 1995), arc an extension ofthose described in (Lambert, 1993).
In determin-ing how the inference chain attaches to the plantree, the speech-act is recognized, since each infer-ence chain is associated with a single speech-act.As mentioned in the introduction, for a plan-based disconrse processor to deal with ambigui-ties, three issues need to be addressed:1.
The discourse processor must be able to dealwith more than one semantic representationas input at a time.
Note that simply extend-ing the discourse processor to accept mul-tiple ILTs is not the whole solution to thedisambiguation problem: finer distinctionsmust be made in terms of coherence with thecontext in order to produce predictions de-tailed enough to distinguish between alterna-tive LLTs.2.
Before context-based predictions can be com-bined with quantitative non context-basedpredictions, they must be quantified, itwas necessary to add a mechanism to pro-duce more detailed quantifiable predictionsthan those produced by the original focusingheuristics described in (Ros6 et al, 1995).3.
Finally, context-based predictions must becombined successfully with non-context-based ones.
The discourse processor must beable to weigh these various predictions in o fder to determine which ones to believe in spe-cific circumstances.Thus, we extended our original discourse pro-cessor as follows.
It takes multiple ambiguouslI,Ts fi'om the parser and computes three quanti-fied discourse scores for each ambiguity.
The dis-course scores are derived by taking into accotmt360attachment preferences to the discourse tree, asreflected by two kinds of focusing scores, and |,hescore returned by the .qradcd conslrainls, a newtype of constraint we introduced.
Then for eachambiguity the discourse processor combines thesethree kinds of context-based scores with the noncontext-based scores l)roduced by other modulesof the system to make tire final choice, and returnsthe chosen IUI'.
As in the first version of the dis-course processor, the chosen I I,T is attached to theplan tree and a speech act is assigned to it.
Wediscuss now how the discourse scores are derived.Note that lower wdues for all scores are preferred.4.1 Focus ing scoresThe focusing scores are derived from focusingheuristics based Ott (Sidner, 198l; l,ambert, 199:f;Rosd et al, 1995).
The focusing heuristics identifythe most coherent relationship between a new in-ference chain and the discourse |)Inn tree.
Atl,achmeat preferences by the Focusing heuristics aretranslated into numerical preference scores basedon attachment positions and the length of the in--ference chains.
The assignment of focusing scoresreflects the assumption thai, the ntost coherentmove in a diMogue is to continue the most salientfocused actions, namely, the ones on the rightfl,ostfrontier of the plan tree.
The first feet(sing scoreis a boolean focusing fla(l. It returns 0 if the infer-ence chain for the associated 11,'1' attaches t,o therightmost fl'outier of the plan tree, 1 if it eitherattaches to the tree but trot to tit(.
', right frontieror doesn't attach to the tree.
The second focusingscore, the J'ocusing score i)roper, assigns a scorebetween 0 and t indicating \[tow far up the right-most frontier the inference chain attaches.
Themaximal score is assigned in the case that the in-ference chain does not attach.4.2 Graded constra intsOnce the.
discourse processor was extended to ac-cept multiple ILTs as input, it became clear thatIbr most ambignous parses the original focusingheuristics did not provide enough information todistinguish among the alternatives.
Our sohttionwas to modity the discourse processor's constraintprocessing mechanism, making it possible to bringmore domain knowledge to bear on the disam-biguation task.
In the original discourse proces-sor, all of the constraints on plan operators, whichwe (:all elimination constraints, were used solely\[or the purpose of binding w~riables and eliminat-ing certain inference possibilities.
Their purposewas to eliminate provably wrong inferences, andit, this way to give the focusing heuristics a higherlikelihood of selecting the torte.c( inference chainfrom the remaining set.We introduced a different type of constraint,graded conslraints, inspired by the concept ofgraded unification discussed it, (Kim, 1994).
Or,-like elimination constraints, they neither bindvariables not" eliminate any inferences.
Gradedconstraints always return true, so they cannoteliminate inferences.
However, they assign numer-ical penalties or preferences to inference chainsbased on domain specific information.
This in-formation is then used to rank the set of possibleinferences Left after the elimination constraints areI)r?cessed.For example, consider the day versus hour ambi-guity we discussed earlier.
In most cases inferencechains for Ilfl's with this ambiguity have tit(; samefocusing scores.
We introduce the poss ib le - t imeconstrMnt to (he.ok whether the temporal con-straints conflict with the dynamic alendar or therecorded dialogue (late when the inference chainsare built.
If the temporal information representedin an II,T is in conflict with the dialogue recorddate (e.g., scheduling a time before the recorddate) or with the temporal constraints already inthe calendar (e.g., propose a time that is ah'eadyrqiected), a penalty score is assigned to that in-ference chain; otherwise, a default value (i.e.
nopenalty) is returned.
Several graded constraintsmay be fired in one inference chain.
Penalties orpreferences for all graded constraints in the infer-ence chain are summed together.
'Phe result is thegraded constraint score for that ambiguity.Introducing raded constraints has two adwm--tages over adding more elimination constraints.As far as tile systetn in ge, neral is COlmerned,graded constraints only give preferences, they donot rule out inferencing and attachment possibil-ities: thtls, introducing new constraints will notdamage the broad coverage of the system.
As faras the discourse processor is concerned, it; wouldbe possible to achieve the same effect by addingmore elimination constraints, but this wouht makeit, necessary to introduce more fine-tuned plan op-erators geared towards specilic cases.
By intro-ducing graded constraints we avoid expanding thesearch space among the plan operators.4.3  Combin ing  Predict, ionsOnce the information from the graded constraintsand the focusing scores is awdlable, the challeng-ing problem of combining these context-based pre-dictions with tile non context-based ones arises.We experimented with two methods of automat--really learning functions for combining our sixscores into one composite score, namely a ge-netic progranmfing approach and a neural net ap-proach.
The basic assumption of our disambigua~tion approach is that the context-based attd noncontext-based scores provide different perspec-tives on the disambiguation task.
They act to-gether, each specializing in different ypes of cases,to constrain the final result.
Thus, we want ourlearning approach to learn not only which factorsare important, but also to what extent they are361important, and under what circumstances.
Thegenetic progranlming and neural net approachesare ideal in this respect.Genetic programming (Koza, 1992; Koza, 1994)is a method for "evolving" a program to accom-plish a particular task, in this case a flmction forcomputing a composite score.
This technique canlearn functions which are efficient and humanlyunderstandable and editable.
Moreover, becausethis technique samples different parts of the searchspace in parallel, it avoids to some extent he prob-lem of selecting locally optimal solutions which arenot globally optimal.Connectionist approaches have been widelyused \['or spoken language processing and other ar-eas of computational linguistics, e.g., (Wermpter,1994; Miikkulainen, 1993) to name only a few.Connectionist approaches are able to learn thestructure inherent in the input data, to make finedistinctions between input patterns in the pres-ence of noise, and to integrate difl'erent informa-tion sources.We refer the reader to (l{osd and Qu, 1995) forfall details about the motivations underlying thechoice of these two methods as well as the advan-tages and disadvantages of each.both kinds of testing are the same becanse cu-mulative error is only an issue for context-basedapproaches.Our results show that the discourse processor isindeed making nsefld predictions for disambigua-tion: when we abstract away the problem of cu-mulative error, we can achieve an improvementof 13% with the genetic programming approachand of 2.5% with the neural net approach overthe parser's non-context based statistical disam-biguatiou technique.
For example, we were able toachieve almost perfect performance on the s ta tevs query - i f  ambiguity, missing only one casewith the genetic programming approach; thus, forthis ambiguity, we can trust the discourse proces-sor's prediction.However, our results also indicate that we havenot solved the whole problem of combining noncontext- and context-based predictions for disam-biguation.
\[n the face of cumulative rror, both ofthe two discourse combination approaches ufferfl'om performance degradation, though to a dif-ferent extent.
Our current direction is to seek asolution to the cumulative rror problem.
Somepreliminary results in this regard are discussed in(Qu et al, 1996).5 Eva luat ionBoth combination methods, the genetic program-ming approach and the neural net approach, weretrained on a set of 15 Spanish scheduling dia-logues.
They were both tested on a set of fivepreviously unseen dialogues.
Only sentences withmultiple ILTs, at least one of which was correct,were used as training and testing data.
Altogether115 sentences were used for training and 76 fortesting.We evaluated the performance of our two meth-ods by comparing them to two non context-basedones: a baseline method of selecting a parse ran-domly, and a Statistical Parse Disambiguationmethod.
The Statistical Parse Disambiguationmethod makes use of the three non context-basedscores described in Section 3.
The two context-based approaches combine the three non context-based scores as well as the three context-basedscores, namely the focusing flag, the focusingscore, and the graded constraint score.Table 2 reports the percentages of ambigu-ous sentences correctly disambiguated by eachmethod.
We present two types of performancestatistics on the testing set: without cumulativeerror Testing without CE and with cumulative r-ror Testing with CE.
Cumulative error builds upwhen an incorrect hypothesis is chosen and incor-porated into the discourse context, causing futurepredictions based on discourse context to be in-accurate.
Notice that for the two non context-based approaches, the performance figures for6 Conc lus ionsIn this article we have discussed how we applypredictions from our plan-based iscourse proces-sor to the problem of disambiguation.
Our eval-uation demonstrates the advantage of incorporat-ing context-based predictions into a purely noncontext-based approach.
While our results indi-cate that we have not solved the whole problemof combining non context- and context-based pre-dictions for disambiguation, they show that thediscourse processor is making usefld predictionsand that we have combined this information suc-cessflllly with the non context-based predictors.Our current efforts are aimed at solving the cu-mulative rror problem in using discourse context.We noticed that cumulative rror is especially aproblem in spontaneous speech systems where un-expected inpnt, disfluencies, out-of-domain sen-tences and missing information cause the deterio-:ration of the quality of context.
One possibility isto reassess and reestablish the context state whena conflict is detected between context and otherpredictions.
A second proposal is to keep the n-best hypotheses and to choose one only after hav-ing processed a sequence of inputs.
Preliminaryexperiments show that both t)roposals help reducethe adverse ffect of the cumulative rror problem.Our results also suggest another possible avenueof future development.
Instead of trying to learna general function for combining various informa-tion sources, we could decide which source of in-formation to trust in a particular case and classify362_I I , l indoinStat ist ical  Parse Bis lunl ) iguat ion\[ D\]P gene l le  Progrt l ln l l i i l lg  DP Noltlcal N(!t' l~ainixlg \] Test ing without CE32% I 45%76.5~ / 76 3%91.
(;% l 89.5%s5,2% _\[ 78.8%Testing with CE45%76.3%60%71 .a%'l'~tble 2: Disanf l i iguat ion (if All hn l l l iguous S(;ntencosthe type of ambiguity at ti;md with the best ap-1)ro~tch for thL<s ~mil)iguity.
This could be ace, om-plished, for exa3nl)h; , with a decision tree le~trning~1 )preach.AcknowledgementsThe authors would like to thank I,ori Levin, AlertI,~vie lind Alex Waibel for COllllllelltS Oi~l the workreported here a, tid th;mk the two ~tnoilyiiiOllS re-viewers for COllillieAltS eli the, earlier version of t, he1)~q)er.
The work is supl)orLod in pa, l'l; by ~L gi':~iilt\['1'OI11 the l )epa,rt l l le l l t  of  I)e\['ellse.l ?e ferencesAllen, J. F. and 1, K. Schubert.
1991.
7'he TrainsProject.
Ph.I).
thesis, University of Rochester,,qchool of (7oHipl lter Science.
(J;~rroll, 3.
~tti(\[ T. Ilriscoe.
1993.
(Jenera, l-ized probabilistic 1,1{, ptu'siiig of natured lal>{e, ua,ge ((:orpol'a 0 with unlflc~d;hm-bascd graAu-lIl;%l'S.
(,*o?ltpnlalioltal Lingnislics, 19(1).Sidner, C. \[,.
1981.
Focusing for \[nterl)retation f\])rono/lllS.
dlmcrican Journal of ComputationalLinguistics, 7(4):217 23 I.Kim, A.
1994.
Graded unitieation: A I)'ameworkfor interactive processing.
In Proceedings of theAssociation for Computational Linguistics.Koza, .1.
1992.
Genetic l'~vgramming: On theI"tvgramming of Computers by Means of Nalu-'ral ,qeleclion.
MI'I' Press.Koza, a.
1994.
Gc.netie Programming 1I.
MITPl'eSS.l,~mibert, I,.
1993.
Recognizing Complex Dis-course Acts: A Tripa;<>titc Plan-Based Model ofDialogue.
Ph.D. thesis, Department of Coin-purer Science, University of l)elaw~-~rc.Lambert, L. and S. (Tarl)erry.
1992.
Modelingnegotiation subdialogues, hi Proceedings @ theACL.Lavie, A.
19{)5.
A Grammar Based Robnsl l'arser/,br 5'ponlaneous Speech.
I'h.1).
thesis, School ofComputer Science, Carnegie Mellon University.Levin, 1,., O. Glickman, Y. Qu, D. Gates,A.
I,avie, C. P. l{osd, 17 Van Ess-Dykema, andA.
Waibe\].
1995.
Using context in machinetranslation of spoken l~mgmtge.
In Theoreticaland Methodological Issues in Machine Transla-tion.Miikkulainen, R,.
1993. ,Sub.symbolic NaturalLanguage P~vcessing: An Intcgrated Model of,%ripls, Lexicon, and Memory.
The M I'F I)ress.Qu, Y., B. l)i F, uge, nio, A. I,avie, I,.
S. l,evin, ~uidC, P. l{os6.
1996.
Minimizing Cumulative Er-ror in I)iscourse (kmtext.
To appear in ICUAIWorkshop Proceedings on Dialogue f'rocessingin ,S'poken Language Systems.lh;ithinger, N. ~md E. Meier.
1995.
Utilizing st~-tisticM diMogue act, t)rocessing in Verbmobil.
InProceedings of the A CL.Rosd, C. P., B. l) i  Igugenio, L. S. l,evin, mid(J. Vl-%ll \ [ ' \ ]ss- l )ykema.
1995.
/)iseourse process-ing of dialogues with multiph" threads, lit Pro-ceedings of the ACL.l{,os6, C. P. ~md Y. Qu.
1995.
AutomaticallyLearning to Use Discourse Information l'brI)isambiguation.
Center for M~chine 'l'rmisl~-tion, (;arnegie Mellon University.
'\['echnical R,e-port.,qiiiith, R. W., l).
II,.
Hipp, iliid A. W. lJierin~liti.1995.
An architecture for voice dialogue sys-tel\[iS based on prolog-style theoreli+i proving.
()omputalional Lin(luislics, 21 (3):218 320.Suhm, B., 1,.
Levin, N. Coccaro, J. CarboneU,K.
Iloriguehi, R,.
Isotani, A.
\[mvie, L. Maylield,C.
|).
l{os(, C. Van-Ess Dykcma, ~md A. W~dbel.1994.
Speech-hmguage integration in a multi-lingual speech translation systeni.
In Proceed-ings of the AAAI Workshop on lnleg#nlion ofNalnral Language and ,qpeech Processing.Werml)ter , S. 1994.
(7onnectionisl, learning of flatsynt~mtic an,~lysis for speech/language systems.In Proceedings of the International ConJerenceon Artificial Neural Networks.Woszeyna, M., N. Coeearo, A. Eisele, A. Lavie,A.
McNair, '\['.
Polzin, I.
Regime, C. P. 1?os6,T.
Slobod~, M. 'Pomita, a. Tsutsumi, N. Waibel,A.
Waibel, and W. W~rd.
1993.
R,ecent ~d-vances in JAN US: a speech translation system.In l'roceedings of the ARI'A lluman Languages7'ethnology Workshop.363
