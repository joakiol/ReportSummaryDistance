Proceedings of the 12th Conference of the European Chapter of the ACL, pages 148?156,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsEM Works for Pronoun Anaphora ResolutionEugene Charniak and Micha ElsnerBrown Laboratory for Linguistic Information Processing (BLLIP)Brown UniversityProvidence, RI 02912{ec,melsner}@cs.brown.eduAbstractWe present an algorithm for pronoun-anaphora (in English) that uses Expecta-tion Maximization (EM) to learn virtuallyall of its parameters in an unsupervisedfashion.
While EM frequently fails to findgood models for the tasks to which it isset, in this case it works quite well.
Wehave compared it to several systems avail-able on the web (all we have found so far).Our program significantly outperforms allof them.
The algorithm is fast and robust,and has been made publically available fordownloading.1 IntroductionWe present a new system for resolving (per-sonal) pronoun anaphora1.
We believe it is ofinterest for two reasons.
First, virtually all ofits parameters are learned via the expectation-maximization algorithm (EM).
While EM hasworked quite well for a few tasks, notably ma-chine translations (starting with the IBM models1-5 (Brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (Meri-aldo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar in-duction (numerous attempts, too many to men-tion).
Thus understanding the abilities and limi-tations of EM is very much a topic of interest.
Wepresent this work as a positive data-point in thisongoing discussion.Secondly, and perhaps more importantly, is thesystem?s performance.
Remarkably, there are veryfew systems for actually doing pronoun anaphoraavailable on the web.
By emailing the corpora-list the other members of the list pointed us to1The system, the Ge corpus, and themodel described here can be downloaded fromhttp://bllip.cs.brown.edu/download/emPronoun.tar.gz.four.
We present a head to head evaluation and findthat our performance is significantly better thanthe competition.2 Previous WorkThe literature on pronominal anaphora is quitelarge, and we cannot hope to do justice to it here.Rather we limit ourselves to particular papers andsystems that have had the greatest impact on, andsimilarity to, ours.Probably the closest approach to our own isCherry and Bergsma (2005), which also presentsan EM approach to pronoun resolution, and ob-tains quite successful results.
Our work improvesupon theirs in several dimensions.
Firstly, theydo not distinguish antecedents of non-reflexivepronouns based on syntax (for instance, subjectsand objects).
Both previous work (cf.
Tetreault(2001) discussed below) and our present resultsfind these distinctions extremely helpful.
Sec-ondly, their system relies on a separate prepro-cessing stage to classify non-anaphoric pronouns,and mark the gender of certain NPs (Mr., Mrs.and some first names).
This allows the incorpo-ration of external data and learning systems, butconversely, it requires these decisions to be madesequentially.
Our system classifies non-anaphoricpronouns jointly, and learns gender without anexternal database.
Next, they only handle third-person pronouns, while we handle first and sec-ond as well.
Finally, as a demonstration of EM?scapabilities, its evidence is equivocal.
Their EMrequires careful initialization ?
sufficiently care-ful that the EM version only performs 0.4% betterthan the initialized program alone.
(We can saynothing about relative performance of their systemvs.
ours since we have been able to access neithertheir data nor code.
)A quite different unsupervised approach isKehler et al (2004a), which uses self-training of adiscriminative system, initialized with some con-148servative number and gender heuristics.
The sys-tem uses the conventional ranking approach, ap-plying a maximum-entropy classifier to pairs ofpronoun and potential antecedent and selecting thebest antecedent.
In each iteration of self-training,the system labels the training corpus and its de-cisions are treated as input for the next trainingphase.
The system improves substantially over aHobbs baseline.
In comparison to ours, their fea-ture set is quite similar, while their learning ap-proach is rather different.
In addition, their systemdoes not classify non-anaphoric pronouns,A third paper that has significantly influencedour work is that of (Haghighi and Klein, 2007).This is the first paper to treat all noun phrase (NP)anaphora using a generative model.
The successthey achieve directly inspired our work.
There are,however, many differences between their approachand ours.
The most obvious is our use of EMrather than theirs of Gibbs sampling.
However, themost important difference is the choice of trainingdata.
In our case it is a very large corpus of parsed,but otherwise unannotated text.
Their system istrained on the ACE corpus, and requires explicitannotation of all ?markables?
?
things that are orhave antecedents.
For pronouns, only anaphoricpronouns are so marked.
Thus the system doesnot learn to recognize non-anaphoric pronouns ?a significant problem.
More generally it followsfrom this that the system only works (or at leastworks with the accuracy they achieve) when theinput data is so marked.
These markings not onlyrender the non-anaphoric pronoun situation moot,but also significantly restrict the choice of possibleantecedent.
Only perhaps one in four or five NPsare markable (Poesio and Vieira, 1998).There are also several papers which treatcoference as an unsupervised clustering problem(Cardie and Wagstaff, 1999; Angheluta et al,2004).
In this literature there is no generativemodel at all, and thus this work is only looselyconnected to the above models.Another key paper is (Ge et al, 1998).
The dataannotated for the Ge research is used here for test-ing and development data.
Also, there are manyoverlaps between their formulation of the problemand ours.
For one thing, their model is genera-tive, although they do not note this fact, and (withthe partial exception we are about to mention) theyobtain their probabilities from hand annotated datarather than using EM.
Lastly, they learn their gen-der information (the probability of that a pronounwill have a particular gender given its antecedent)using a truncated EM procedure.
Once they havederived all of the other parameters from the train-ing data, they go through a larger corpus of unla-beled data collecting estimated counts of how of-ten each word generates a pronoun of a particulargender.
They then normalize these probabilitiesand the result is used in the final program.
This is,in fact, a single iteration of EM.Tetreault (2001) is one of the few papers thatuse the (Ge et al, 1998) corpus used here.
Theyachieve a very high 80% correct, but this isgiven hand-annotated number, gender and syntac-tic binding features to filter candidate antecedentsand also ignores non-anaphoric pronouns.We defer discussion of the systems againstwhich we were able to compare to Section 7 onevaluation.3 PronounsWe briefly review English pronouns and theirproperties.
First we only concern ourselves with?personal?
pronouns: ?I?, ?you?, ?he?, ?she?, ?it?,and their variants.
We ignore, e.g., relative pro-nouns (?who?, ?which?, etc.
), deictic pronouns(?this?, ?that?)
and others.Personal pronouns come in four basic types:subject ?I?, ?she?, etc.
Used in subject position.object ?me?, ?her?
etc.
Used in non-subject po-sition.possessive ?my?
?her?, andreflexive ?myself?, ?herself?
etc.
Required byEnglish grammar in certain constructions ?e.g., ?I kicked myself.
?The system described here handles all of thesecases.Note that the type of a pronoun is not connectedwith its antecedent, but rather is completely deter-mined by the role it plays in it?s sentence.Personal pronouns are either anaphoric or non-anaphoric.
We say that a pronoun is anaphoricwhen it is coreferent with another piece of text inthe same discourse.
As is standard in the field wedistinguish between a referent and an antecedent.The referent is the thing in the world that the pro-noun, or, more generally, noun phrase (NP), de-notes.
Anaphora on the other hand is a relation be-149tween pieces of text.
It follows from this that non-anaphoric pronouns come in two basic varieties ?some have a referent, but because the referent isnot mentioned in the text2 there is no anaphoricrelation to other text.
Others have no referent (ex-pletive or pleonastic pronouns, as in ?It seems that.
.
.
?).
For the purposes of this article we do notdistinguish the two.Personal pronouns have three properties otherthan their type:person first (?I?,?we?
), second (?you?)
or third(?she?,?they?)
person,number singular (?I?,?he?)
or plural (?we?,?they?
), andgender masculine (?he?
), feminine (?she?)
orneuter (?they?
).These are critical because it is these propertiesthat our generative model generates.4 The Generative ModelOur generative model ignores the generation ofmost of the discourse, only generating a pronoun?sperson, number,and gender features along with thegovernor of the pronoun and the syntactic relationbetween the pronoun and the governor.
(Infor-mally, a word?s governor is the head of the phraseabove it.
So the governor of both ?I?
and ?her?
in?I saw her?
is ?saw?.We first decide if the pronoun is anaphoricbased upon a distribution p(anaphoric).
(Actu-ally this is a bit more complex, see the discus-sion in Section 5.3.)
If the pronoun is anaphoricwe then select a possible antecedent.
Any NPin the current or two previous sentences is con-sidered.
We select the antecedent based upon adistribution p(anaphora|context).
The nature ofthe ?context?
is discussed below.
Then giventhe antecedent we generative the pronoun?s personaccording to p(person|antecedent), the pronoun?sgender according to p(gender|antecedent), num-ber, p(number|antecedent) and governor/relation-to-governor from p(governor/relation|antecedent).To generate a non-anaphoric third person singu-lar ?it?
we first guess that the non-anaphoric pro-nouns is ?it?
according to p(?it?|non-anaphoric).2Actually, as in most previous work, we only consider ref-erents realized by NPs.
For more general approaches see By-ron (2002).and then generate the governor/relation accordingto p(governor/relation|non-anaphoric-it);Lastly we generate any other non-anaphoricpronouns and their governor with a fixed probabil-ity p(other).
(Strictly speaking, this is mathemati-cally invalid, since we do not bother to normalizeover all the alternatives; a good topic for future re-search would be exploring what happens when wemake this part of the model truly generative.
)One inelegant part of the model is the needto scale the p(governor/rel|antecedent) probabili-ties.
We smooth them using Kneser-Ney smooth-ing, but even then their dynamic range (a factor of106) greatly exceeds those of the other parameters.Thus we take their nth root.
This n is the last ofthe model parameters.5 Model Parameters5.1 IntuitionsAll of our distributions start with uniform val-ues.
For example, gender distributions start withthe probability of each gender equal to one-third.From this it follows that on the first EM iterationall antecedents will have the same probability ofgenerating a pronoun.
At first glance then, the EMprocess might seem to be futile.
In this section wehope to give some intuitions as to why this is notthe case.As is typically done in EM learning, we startthe process with a much simpler generative model,use a few EM iterations to learn its parameters,and gradually expose the data to more and morecomplex models, and thus larger and larger sets ofparameters.The first model only learns the probability ofan antecedent generating the pronoun given whatsentence it is in.
We train this model through fouriterations before moving on to more complex ones.As noted above, all antecedents initially havethe same probability, but this is not true after thefirst iteration.
To see how the probabilities diverge,and diverge correctly, consider the first sentence ofa news article.
Suppose it starts ?President Bushannounced that he ...?
In this situation there isonly one possible antecedent, so the expectationthat ?he?
is generated by the NP in the same sen-tence is 1.0.
Contrast this with the situation in thethird and subsequent sentences.
It is only then thatwe have expectation for sentences two back gener-ating the pronoun.
Furthermore, typically by thispoint there will be, say, twenty NPs to share the150probability mass, so each one will only get an in-crease of 0.05.
Thus on the first iteration only thefirst two sentences have the power to move the dis-tributions, but they do, and they make NPs in thecurrent sentence very slightly more likely to gener-ate the pronoun than the sentence one back, whichin turn is more likely than the ones two back.This slight imbalance is reflected when EMreadjusts the probability distribution at the end ofthe first iteration.
Thus for the second iteration ev-eryone contributes to subsequent imbalances, be-cause it is no longer the case the all antecedents areequally likely.
Now the closer ones have higherprobability so forth and so on.To take another example, consider how EMcomes to assign gender to various words.
By thetime we start training the gender assignment prob-abilities the model has learned to prefer nearerantecedents as well as ones with other desirableproperties.
Now suppose we consider a sentence,the first half of which has no pronouns.
Considerthe gender of the NPs in this half.
Given no fur-ther information we would expect these genders todistribute themselves accord to the prior probabil-ity that any NP will be masculine, feminine, etc.But suppose that the second half of the sentencehas a feminine pronoun.
Now the genders will beskewed with the probability of one of them beingfeminine being much larger.
Thus in the same waythese probabilities will be moved from equality,and should, in general be moved correctly.5.2 Parameters Learned by EMVirtually all model parameters are learned by EM.We use the parsed version of the North-AmericanNews Corpus.
This is available from the (Mc-Closky et al, 2008).
It has about 800,000 articles,and 500,000,000 words.The least complicated parameter is the proba-bility of gender given word.
Most words that havea clear gender have this reflected in their probabil-ities.
Some examples are shown in Table 1.
Wecan see there that EM gets ?Paul?, ?Paula?, and?Wal-mart?
correct.
?Pig?
has no obvious genderin English, and the probabilities reflect this.
Onthe other hand ?Piggy?
gets feminine gender.
Thisis no doubt because of ?Miss Piggy?
the puppetcharacter.
?Waist?
the program gets wrong.
Herethe probabilities are close to gender-of-pronounpriors.
This happens for a (comparatively small)class of pronouns that, in fact, are probably neverWord Male Female Neuterpaul 0.962 0.002 0.035paula 0.003 0.915 0.082pig 0.445 0.170 0.385piggy 0.001 0.853 0.146wal-mart 0.016 0.007 0.976waist 0.380 0.155 0.465Table 1: Words and their probabilities of generat-ing masculine, feminine and neuter pronounsantecedent p(singular|antecedent)Singular 0.939048Plural 0.0409721Not NN or NNP 0.746885Table 2: The probability of an antecedent genera-tion a singular pronoun as a function of its numberan antecedent, but are nearby random pronouns.Because of their non-antecedent proclivities, thissort of mistake has little effect.Next consider p(number|antecedent), that is theprobability that a given antecedent will generate asingular or plural pronoun.
This is shown in Table2.
Since we are dealing with parsed text, we havethe antecedent?s part-of-speech, so rather than theantecedent we get the number from the part ofspeech: ?NN?
and ?NNP?
are singular, ?NNS?and ?NNPS?
are plural.
Lastly, we have the prob-ability that an antecedent which is not a noun willhave a singular pronoun associated with it.
Notethat the probability that a singular antecedent willgenerate a singular pronoun is not one.
This iscorrect, although the exact number probably is toolow.
For example, ?IBM?
may be the antecedentof both ?we?
and ?they?, and vice versa.Next we turn to p(person|antecedent), predict-ing whether the pronoun is first, second or thirdperson given its antecedent.
We simplify thisby noting that we know the person of the an-tecedent (everything except ?I?
and ?you?
andtheir variants are third person), so we computep(person|person).
Actually we condition on onefurther piece of information, if either the pronounor the antecedent is being quoted.
The idea is thatan ?I?
in quoted material may be the same personas ?John Doe?
outside of quotes, if Mr. Doe isspeaking.
Indeed, EM picks up on this as is il-lustrated in Tables 3 and 4.
The first gives thesituation when neither antecedent nor pronoun iswithin a quotation.
The high numbers along the151Person of PronounPerson of Ante First Second ThirdFirst 0.923 0.076 0.001Second 0.114 0.885 0.001Third 0.018 0.015 0.967Table 3: Probability of an antecedent generating afirst,second or third person pronoun as a functionof the antecedents personPerson of PronounPerson of Ante First Second ThirdFirst 0.089 0.021 0.889Second 0.163 0.132 0.705Third 0.025 0.011 0.964Table 4: Same, but when the antecedent is inquoted material but the pronoun is notdiagonal (0.923, 0.885, and 0.967) show the ex-pected like-goes-to-like preferences.
Contrast thiswith Table 4 which gives the probabilities whenthe antecedent is in quotes but the pronoun is not.Here we see all antecedents being preferentiallymapped to third person (0.889, 0.705, and 0.964).We save p(antecedent|context) till last becauseit is the most complicated.
Given what we knowabout the context of the pronoun not all antecedentpositions are equally likely.
Some important con-ditioning events are:?
the exact position of the sentence relative tothe pronoun (0, 1, or 2 sentences back),?
the position of the head of the antecedentwithin the sentence (bucketed into 6 bins).For the current sentence position is measuredbackward from the pronoun.
For the two pre-vious sentences it is measure forward fromthe start of the sentence.?
syntactic positions ?
generally we expectNPs in subject position to be more likely an-tecedents than those in object position, andthose more likely than other positions (e.g.,object of a preposition).?
position of the pronoun ?
for example thesubject of the previous sentence is very likelyto be the antecedent if the pronoun is veryearly in the sentence, much less likely if it isat the end.?
type of pronoun ?
reflexives can only bebound within the same sentence, while sub-Part of Speech pron proper common0.094 0.057 0.032Word Position bin 0 bin 2 bin 50.111 0.007 0.0004Syntactic Type subj other object0.068 0.045 0.037Table 5: Geometric mean of the probability ofthe antecedent when holding everything expect thestated feature of the antecedent constantject and object pronouns may be anywhere.Possessives may be in previous sentences butthis is not as common.?
type of antecedent.
Intuitively other pro-nouns and proper nouns are more likely tobe antecedents than common nouns and NPsheaded up by things other than nouns.All told this comes to 2592 parameters (3 sen-tences, 6 antecedent word positions, 3 syntacticpositions, 4 pronoun positions, 3 pronoun types,and 4 antecedent types).
It is impossible to sayif EM is setting all of these correctly.
There aretoo many of them and we do not have knowledgeor intuitions about most all of them.
However, allhelp performance on the development set, and wecan look at a few where we do have strong intu-itions.
Table 5 gives some examples.
The first tworows are devoted to the probabilities of particularkind of antecedent (pronouns, proper nouns, andcommon nouns) generating a pronoun, holding ev-erything constant except the type of antecedent.The numbers are the geometric mean of the prob-abilities in each case.
The probabilities are or-dered according to, at least my, intuition with pro-noun being the most likely (0.094), followed byproper nouns (0.057), followed by common nouns(0.032), a fact also noted by (Haghighi and Klein,2007).
When looking at the probabilities as a func-tion of word position again the EM derived proba-bilities accord with intuition, with bin 0 (the clos-est) more likely than bin 2 more likely than bin5.
The last two lines have the only case where wehave found the EM probability not in accord withour intuitions.
We would have expected objectsof verbs to be more likely to generate a pronounthan the catch-all ?other?
case.
This proved not tobe the case.
On the other hand, the two are muchcloser in probabilities than any of the other, moreintuitive, cases.1525.3 Parameters Not Set by EMThere are a few parameters not set by EM.Several are connected with the well known syn-tactic constraints on the use of reflexives.
A simpleversion of this is built in.
Reflexives must have anantecedent in same sentence, and generally cannotbe coreferent-referent with the subject of the sen-tence.There are three system parameters that we setby hand to optimize performance on the develop-ment set.
The first is n. As noted above, the distri-bution p(governor/relation|antecedent) has a muchgreater dynamic range than the other probabilitydistributions and to prevent it from, in essence,completely determining the answer, we take itsnth root.
Secondly, there is a probability of gen-erating a non-anaphoric ?it?.
Lastly we have aprobability of generating each of the other non-monotonic pronouns along with (the nth root of)their governor.
These parameters are 6, 0.1, and0.0004 respectively.6 Definition of CorrectnessWe evaluate all programs according to Mitkov?s?resolution etiquette?
scoring metric (also usedin Cherry and Bergsma (2005)), which is definedas follows: if N is the number of non-anaphoricpronouns correctly identified, A the number ofanaphoric pronouns correctly linked to their an-tecedent, and P the total number of pronouns, thena pronoun-anaphora program?s percentage correctis N+AP .Most papers dealing with pronoun coreferenceuse this simple ratio, or the variant that ignoresnon-anaphoric pronouns.
It has appeared undera number of names: success (Yang et al, 2006),accuracy (Kehler et al, 2004a; Angheluta et al,2004) and success rate (Tetreault, 2001).
Theother occasionally-used metric is the MUC scorerestricted to pronouns, but this has well-knownproblems (Bagga and Baldwin, 1998).To make the definition perfectly concrete, how-ever, we must resolve a few special cases.
Oneis the case in which a pronoun x correctly saysthat it is coreferent with another pronoun y. How-ever, the program misidentifies the antecedent ofy.
In this case (sometimes called error chaining(Walker, 1989)), both x and y are to be scored aswrong, as they both end up in the wrong corefer-ential chain.
We believe this is, in fact, the stan-dard (Mitkov, personal communication), althoughthere are a few papers (Tetreault, 2001; Yang etal., 2006) which do the opposite and many whichsimply do not discuss this case.One more issue arises in the case of a systemattempting to perform complete NP anaphora3.
Inthese cases the coreferential chains they createmay not correspond to any of the original chains.In these cases, we call a pronoun correctly re-solved if it is put in a chain including at least onecorrect non-pronominal antecedent.
This defini-tion cannot be used in general, as putting all NPsinto the same set would give a perfect score.
For-tunately, the systems we compare against do notdo this ?
they seem more likely to over-split thanunder-split.
Furthermore, if they do take someinadvertent advantage of this definition, it helpsthem and puts our program at a possible disadvan-tage, so it is a more-than-fair comparison.7 EvaluationTo develop and test our program we use the datasetannotated by Niyu Ge (Ge et al, 1998).
Thisconsists of sections 0 and 1 of the Penn tree-bank.
Ge marked every personal pronoun and allnoun phrases that were coreferent with these pro-nouns.
We used section 0 as our developmentset, and section 1 for testing.
We reparsed thesentences using the Charniak and Johnson parser(Charniak and Johnson, 2005) rather than usingthe gold-parses that Ge marked up.
We hopethereby to make the results closer to those a userwill experience.
(Generally the gold trees performabout 0.005 higher than the machine parsed ver-sion.)
The test set has 1119 personal pronounsof which 246 are non-anaphoric.
Our selection ofthis dataset, rather than the widely used MUC-6corpus, is motivated by this large number of pro-nouns.We compared our results to four currently-available anaphora programs from the web.
Thesefour were selected by sending a request to a com-monly used mailing list (the ?corpora-list?)
ask-ing for such programs.
We received four leads:JavaRAP, Open-NLP, BART and GuiTAR.
Ofcourse, these systems represent the best availablework, not the state of the art.
We presume thatmore recent supervised systems (Kehler et al,2004b; Yang et al, 2004; Yang et al, 2006) per-3Of course our system does not attempt NP coreferenceresolution, nor does JavaRAP.
The other three comparisonsystems do.153form better.
Unfortunately, we were unable to ob-tain a comparison unsupervised learning system atall.Only one of the four is explicitly aimedat personal-pronoun anaphora ?
RAP (Resolu-tion of Anaphora Procedure) (Lappin and Le-ass, 1994).
It is a non-statistical system orig-inally implemented in Prolog.
The version weused is JavaRAP, a later reimplementation in Java(Long Qiu and Chua, 2004).
It only handles thirdperson pronouns.The other three are more general in that theyhandle all NP anaphora.
The GuiTAR system(Poesio and Kabadjov, 2004) is designed to workin an ?off the shelf?
fashion on general text GUI-TAR resolves pronouns using the algorithm of(Mitkov et al, 2002), which filters candidate an-tecedents and then ranks them using morphosyn-tactic features.
Due to a bug in version 3, GUI-TAR does not currently handle possessive pro-nouns.GUITAR also has an optional discourse-new classification step, which cannot be used asit requires a discontinued Google search API.OpenNLP (Morton et al, 2005) uses amaximum-entropy classifier to rank potential an-tecedents for pronouns.
However despite beingthe best-performing (on pronouns) of the existingsystems, there is a remarkable lack of publishedinformation on its innards.BART (Versley et al, 2008) also uses amaximum-entropy model, based on Soon et al(2001).
The BART system also provides a moresophisticated feature set than is available in thebasic model, including tree-kernel features and avariety of web-based knowledge sources.
Unfor-tunately we were not able to get the basic versionworking.
More precisely we were able to run theprogram, but the results we got were substantiallylower than any of the other models and we believethat the program as shipped is not working prop-erly.Some of these systems provide their own pre-processing tools.
However, these were bypassed,so that all systems ran on the Charniak parse trees(with gold sentence segmentation).
Systems withnamed-entity detectors were allowed to run themas a preprocess.
All systems were run using themodels included in their standard distribution; typ-ically these models are trained on annotated newsarticles (like MUC-6), which should be relativelysimilar to our WSJ documents.System Restrictions PerformanceGuiTAR No Possessives 0.534JavaRap Third Person 0.529Open-NLP None 0.593Our System None 0.686Table 6: Performance of Evaluated Systems onTest DataThe performance of the remaining systems isgiven in Table 6.
The two programs with restric-tions were only evaluated on the pronouns the sys-tem was capable of handling.These results should be approached with somecaution.
In particular it is possible that the re-sults for the systems other than ours are underes-timated due to errors in the evaluation.
Compli-cations include the fact all of the four programsall have different output conventions.
The betterto catch such problems the authors independentlywrote two scoring programs.Nevertheless, given the size of the differencebetween the results of our system and the others,the conclusion that ours has the best performanceis probably solid.8 ConclusionWe have presented a generative model of pronoun-anaphora in which virtually all of the parametersare learned by expectation maximization.
We findit of interest first as an example of one of the fewtasks for which EM has been shown to be effec-tive, and second as a useful program to be put ingeneral use.
It is, to the best of our knowledge, thebest-performing system available on the web.
Todown-load it, go to (to be announced).The current system has several obvious limita-tion.
It does not handle cataphora (antecedentsoccurring after the pronoun), only allows an-tecedents to be at most two sentences back, doesnot recognize that a conjoined NP can be the an-tecedent of a plural pronoun, and has a very lim-ited grasp of pronominal syntax.
Perhaps thelargest limitation is the programs inability to rec-ognize the speaker of a quoted segment.
The resultis a very large fraction of first person pronouns aregiven incorrect antecedents.
Fixing these prob-lems would no doubt push the system?s perfor-mance up several percent.However the most critical direction for futureresearch is to push the approach to handle full NP154anaphora.
Besides being of the greatest impor-tance in its own right, it would also allow us toadd one piece of information we currently neglectin our pronominal system ?
the more times a doc-ument refers to an entity the more likely it is to doso again.9 AcknowledgementsWe would like to thank the authors and main-tainers of the four systems against which we didour comparison, especially Tom Morton, MijailKabadjov and Yannick Versley.
Making your sys-tem freely available to other researchers is one ofthe best ways to push the field forward.
In addi-tion, we thank three anonymous reviewers.ReferencesRoxana Angheluta, Patrick Jeuniaux, Rudradeb Mi-tra, and Marie-Francine Moens.
2004.
Clusteringalgorithms for noun phrase coreference resolution.In Proceedings of the 7es Journes internationalesd?Analyse statistique des Donnes Textuelles, pages60?70, Louvain La Neuve, Belgium, March 10?12.Amit Bagga and Breck Baldwin.
1998.
Algorithms forscoring coreference chains.
In In The First Interna-tional Conference on Language Resources and Eval-uation Workshop on Linguistics Coreference, pages563?566.P.
Brown, S. Della Pietra, V. Della Pietra, and R. Mer-cer.
1993.
The mathematics of statistical machinetranslation: Parameter estimation.
ComputationalLinguistics, 19(2).Donna K. Byron.
2002.
Resolving pronominalreference to abstract entities.
In Proceedings ofthe 40th Annual Meeting of the Association forComputational Linguistics (ACL2002), pages 80?87, Philadelphia, PA, USA, July 6?12.Claire Cardie and Kiri Wagstaff.
1999.
Noun phrasecoreference as clustering.
In In Proceedings ofEMNLP, pages 82?89.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminativereranking.
In Proc.
of the 2005 Meeting of theAssoc.
for Computational Linguistics (ACL), pages173?180.Colin Cherry and Shane Bergsma.
2005.
An Expecta-tion Maximization approach to pronoun resolution.In Proceedings of the Ninth Conference on Compu-tational Natural Language Learning (CoNLL-2005),pages 88?95, Ann Arbor, Michigan, June.
Associa-tion for Computational Linguistics.Michael Collins and Yorav Singer.
1999.
Unsuper-vised models for named entity classification.
In Pro-ceedings of the Joint SIGDAT Conference on Empir-ical Methods in Natural Language Processing andVery Large Corpora (EMNLP 99).Niyu Ge, John Hale, and Eugene Charniak.
1998.
Astatistical approach to anaphora resolution.
In Pro-ceedings of the Sixth Workshop on Very Large Cor-pora, pages 161?171, Orlando, Florida.
HarcourtBrace.Aria Haghighi and Dan Klein.
2007.
Unsupervisedcoreference resolution in a nonparametric Bayesianmodel.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics, pages 848?855.
Association for ComputationalLinguistics.Andrew Kehler, Douglas Appelt, Lara Taylor, andAleksandr Simma.
2004a.
Competitive self-trainedpronoun interpretation.
In Daniel Marcu Susan Du-mais and Salim Roukos, editors, HLT-NAACL 2004:Short Papers, pages 33?36, Boston, Massachusetts,USA, May 2 - May 7.
Association for Computa-tional Linguistics.Andrew Kehler, Douglas E. Appelt, Lara Taylor, andAleksandr Simma.
2004b.
The (non)utility ofpredicate-argument frequencies for pronoun inter-pretation.
In Proceedings of the 2004 Human Lan-guage Technology Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics, pages 289?296.Shalom Lappin and Herber J. Leass.
1994.
An algo-rithm for pronouminal anaphora resolution.
Compu-tational Linguistics, 20(4):535?561.Min-Yen Kan Long Qiu and Tat-Seng Chua.
2004.A public reference implementation of the RAPanaphora resolution algorithm.
In Proceedings ofthe Fourth International Conference on LanguageResources and Evaluation, volume I, pages 291?294.David McClosky, Eugene Charniak, and MarkJohnson.2008.
BLLIP North American News Text, Complete.Linguistic Data Consortium.
LDC2008T13.Bernard Merialdo.
1991.
Tagging text with a prob-abilistic model.
In International Conference onSpeech and Signal Processing, volume 2, pages801?818.Ruslan Mitkov, Richard Evans, and Constantin Ora?san.2002.
A new, fully automatic version of Mitkov?sknowledge-poor pronoun resolution method.
InProceedings of the Third International Conferenceon Intelligent Text Processing and ComputationalLinguistics (CICLing-2002), Mexico City, Mexico,February, 17 ?
23.Thomas Morton, Joern Kottmann, Jason Baldridge, andGann Bierner.
2005.
Opennlp: A java-based nlptoolkit.
http://opennlp.sourceforge.net.155Massimo Poesio and Mijail A. Kabadjov.
2004.A general-purpos, of-the-shelf anaphora resolutionmodule: implementataion and preliminary evalu-ation.
In Proceedings of the 2004 internationalConference on Language Evaluation and Resources,pages 663,668.Massimo Poesio and Renata Vieira.
1998.
A corpus-based investigation of definite description use.
Com-putational Linguistics, 24(2):183?216.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Joel R. Tetreault.
2001.
A corpus-based evaluationof centering and pronoun resolution.
ComputationalLinguistics, 27(4):507?520.Yannick Versley, Simone Ponzetto, Massimo Poesio,Vladimir Eidelman, Alan Jern, Jason Smith, Xi-aofeng Yang, and Alessandro Moschitti.
2008.Bart: A modular toolkit for coreference resolution.In Companion Volume of the Proceedings of the 46thAnnual Meeting of the Association for Computa-tional Linguistics, pages 9?12.Marilyn A. Walker.
1989.
Evaluating discourse pro-cessing algorithms.
In ACL, pages 251?261.Xiaofeng Yang, Jian Su, Guodong Zhou, andChew Lim Tan.
2004.
Improving pronoun res-olution by incorporating coreferential informationof candidates.
In Proceedings of the 42nd An-nual Meeting of the Association for ComputationalLinguistics (ACL2004), pages 127?134, Barcelona,Spain, July 21?26.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2006.Kernel-based pronoun resolution with structuredsyntactic knowledge.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and 44th Annual Meeting of the Association forComputational Linguistics, pages 41?48, Sydney,Australia, July.
Association for Computational Lin-guistics.156
