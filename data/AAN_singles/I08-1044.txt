A Framework Based on Graphical Models with Logic forChinese Named Entity Recognition ?Xiaofeng YU Wai LAM Shing-Kit CHANInformation Systems LaboratoryDepartment of Systems Engineering & Engineering ManagementThe Chinese University of Hong KongShatin, N.T., Hong Kong{xfyu,wlam,skchan}@se.cuhk.edu.hkAbstractChinese named entity recognition (NER) has re-cently been viewed as a classification or sequencelabeling problem, and many approaches have beenproposed.
However, they tend to address thisproblem without considering linguistic informa-tion in Chinese NEs.
We propose a new frameworkbased on probabilistic graphical models with first-order logic for Chinese NER.
First, we use Condi-tional Random Fields (CRFs), a standard and the-oretically well-founded machine learning methodbased on undirected graphical models as a basesystem.
Second, we introduce various types ofdomain knowledge into Markov Logic Networks(MLNs), an effective combination of first-orderlogic and probabilistic graphical models for vali-dation and error correction of entities.
Experimen-tal results show that our framework of probabilis-tic graphical models with first-order logic signifi-cantly outperforms the state-of-the-art models forsolving this task.1 IntroductionNamed entity recognition (NER) is the task of identifyingand classifying phrases that denote certain types of namedentities (NEs), such as person names (PERs), locations(LOCs) and organizations (ORGs) in text documents.
Itis a well-established task in the NLP and data mining com-munities and is regarded as crucial technology for manyhigher-level applications, such as information extraction,question answering, information retrieval and knowledgemanagement.
The NER problem has generated much in-terest and great progress has been made, as evidenced byits inclusion as an understanding task to be evaluated in the?The work described in this paper is substantially supported bygrants from the Research Grant Council of the Hong Kong SpecialAdministrative Region, China (Project Nos: CUHK 4179/03Eand CUHK4193/04E) and the Direct Grant of the Faculty of En-gineering, CUHK (Project Codes: 2050363 and 2050391).
Thiswork is also affiliated with the Microsoft-CUHK Joint Laboratoryfor Human-centric Computing and Interface Technologies.Message Understanding Conference (MUC), the Multilin-gual Entity Task (MET) evaluations, and the Conference onComputational Natural Language Learning (CoNLL).Compared to European-language NER, Chinese NERseems to be more difficult (Yu et al, 2006).
Recent ap-proaches to Chinese NER are a shift away from manu-ally constructed rules or finite state patterns towards ma-chine learning or statistical methods.
However, rule-based NER systems lack robustness and portability.
Sta-tistical methods often suffer from the problem of datasparsity, and machine learning approaches (e.g., HiddenMarkov Models (HMMs) (Bikel et al, 1999; Zhou andSu, 2002), Support Vector Machines (SVMs) (Isozaki andKazawa, 2002), Maximum Entropy (MaxEnt) (Borthwick,1999; Chieu and Ng, 2003), Transformation-based Learn-ing (TBL) (Brill, 1995) or variants of them) might be un-satisfactory to learn linguistic information in Chinese NEs.Current state-of-the-art models often view Chinese NER asa classification or sequence labeling problem without con-sidering the linguistic and structural information in ChineseNEs.
They assume that entities are independent, howeverin most cases this assumption does not hold because ofthe existing relationships among the entities.
They seekto locate and identify named entities in text by sequentiallyclassifying tokens (words or characters) as to whether ornot they participate in an NE, which is sometimes prone tonoise and errors.In fact, Chinese NEs have distinct linguistic character-istics in their composition and human beings usually useprior knowledge to recognize NEs.
For example, about 365of the highest frequently used surnames cover 99% Chi-nese surnames (Sun et al, 1995).
Some LOCs containlocation salient words, while some ORGs contain organi-zation salient words.
For the LOC ?
?lA?/Hong KongSpecial Region?, ?
?l/Hong Kong?
is the name part and?A?/Special Region?
is the salient word.
For the ORG?
?lA??/Hong Kong Special Region Government?,?
?l/Hong Kong?
is the LOC name part, ?A?/SpecialRegion?
is the LOC salient word and ??/Government?is the ORG salient word.
Some ORGs contain one ormore PERs, LOCs and ORGs.
A more complex exam-335ple is the nested ORG ????D??u??O??
?/School of Computer Science, Tsinghua Univer-sity, Haidian District, Beijing City?
which contains twoORGs ??u?
?/Tsinghua University?
and ?O??
?/School of Computer Science?
and two LOCs ??
?/Beijing City?
and ?
?D?/Haidian District?.
The twoORGs contain ORG salient words ???/University?
and?
?/School?, while the two LOCs contain LOC salientwords ??/City?
and ??/District?
respectively.Inspired by the above observation, we propose a newframework based on probabilistic graphical models withfirst-order logic which treats Chinese NER 1 as a statisti-cal relational learning (SRL) problem and makes use ofdomain knowledge.
First, we employ Conditional RandomFields (CRFs), a discriminatively trained undirected graph-ical model which has theoretical justification and has beenshown to be an effective approach to segmenting and label-ing sequence data, as our base system.
We then exploit avariety of domain knowledge into Markov Logic Networks(MLNs), a powerful combination of logic and probability,to validate and correct errors made in the base system.
Weshow how a variety of domain knowledge can be formu-lated as first-order logic and incorporated into MLNs.
Weuse three Markov chain Monte Carlo (MCMC) algorithms,including Gibbs sampling, Simulated Tempering, as well asMC-SAT, andMaximum a posteriori/Most Probable Expla-nation (MAP/MPE) algorithm for probabilistic inferencein MLNs.
Experimental results show that our frameworkbased on graphical models with logic yields substantiallybetter NER results, leading to a relative error reduction ofup to 23.75% on the F-measure over state-of-the-art mod-els.
McNemar?s tests confirm that the improvements weobtained are statistically highly significant.2 State of the Art2.1 CRF Model for Chinese NERConditional Random Fields (CRFs) (Lafferty et al, 2001)are undirected graphical models trained to maximize theconditional probability of the desired outputs given the cor-responding inputs.
CRFs have the great flexibility to en-code a wide variety of arbitrary, non-independent featuresand to straightforwardly combine rich domain knowledge.Furthermore, they are discriminatively trained, and are of-ten more accurate than generative models, even with thesame features.
CRFs have been successfully applied to anumber of real-world tasks, including NP chunking (Shaand Pereira, 2003), Chinese word segmentation (Peng etal., 2004), information extraction (Pinto et al, 2003; Pengand McCallum, 2004), named entity identification (Mc-Callum and Li, 2003; Settles, 2004), and many others.1In this paper we only focus on PERs, LOCs and ORGs.
Sincetemporal, numerical and monetary phrases can be well identifiedwith rule-based approaches.Recently, CRFs have been shown to perform excep-tionally well on Chinese NER shared task on the thirdSIGHAN Chinese language processing bakeoff (SIGHAN-06) (Zhou et al, 2006; Chen et al, 2006b,a).
We followthe state-of-the-art CRF models using features that havebeen shown to be very effective in Chinese NER, namelythe current character and its part-of-speech (POS) tag, sev-eral characters surrounding (both before and after) the cur-rent character and their POS tags, current word and severalwords surrounding the current word.We also observe some important issues that significantlyinfluence the performance as follows:Window size: The primitive window size we use is 5 ( 2characters preceding the current character and 2 followingthe current character).
We extend the window size to 7 butfind that it slightly hurts.
The reason is that CRFs can dealwith non-independent features.
A larger window size mayintroduce noisy and irrelevant features.Feature representation: For character features, we usecharacter identities.
For word features, BIES representa-tion (each character is beginning of a word, inside of aword, end of a word, or a single word) is employed.Labeling scheme: The labeling scheme can be BIO, BIOEor BIOES representation.
In BIO representation, each char-acter is tagged as either the beginning of a named entity(B), a character inside a named entity (I), or a characteroutside a named entity (O).
In BIOE, the last character inan entity is labeled as E while in BIOES, single-characterentities are labeled as S. In general, BIOES representationis more informative and yields better results than both BIOand BIOE.2.2 Error AnalysisEven though the CRFmodel is able to accommodate a largenumber of well-engineered features which can be easily ob-tained across languages, some NEs, especially LOCs andORGs are difficult to identify due to the lack of linguisticor structural characteristics.
Since predictions are made to-ken by token, some typical and serious tagging errors arestill made, as shown below:?
ORG is incorrectly tagged as LOC: In Chinese, manyORGs contain location information.
The CRF model onlytags the location information (in the ORGs) as LOCs.For example, ?/?n?
?/Tangshan Technical Insti-tute?
and ??H??
?/Hainan Provincial Committee ?
areORGs and they contain LOCs ?/?/Tangshan?
and ?
?H?/Hainan Province?, respectively.
?/?/Tangshan?
and?
?H?/Hainan Province?
are only incorrectly tagged asLOCs.
This affects the tagging performance of both ORGsand LOCs.?
LOC is incorrectly tagged as ORG: The LOCs ?GZy?/Sydney Opera?
and ??N?,/Beijing Gymnasium?are mistakenly tagged as ORGs by the CRF model with-out taking into account the location salient words ?y?/Opera?
and ?N?,/Gymnasium?.336?
The boundary of entity is tagged incorrectly: This mis-take occurs for all the entities.
For example, the PER?)0??
?d/Tom Cruise?
may be tagged as a PER ?)0/Tom?
; the LOC ??5r/Bremen?
may be tagged asa LOC ?5r/Laimei?, which is a meaningless word; theORG ?u?
?i/Huawei Corporation?
may be tagged as anORG ?u?/Huawei?.
The reasons for these errors are bothcomplicated and varied.
However, some of them are relatedto linguistic knowledge.?
Common nouns are incorrectly tagged as entities: For ex-ample, the two common nouns ?y??
?/Modern Mathe-matics?
and ??=???
?/Galanz Microwave Oven?
maybe improperly tagged as a LOC and an ORG.
Some taggingerrors could be easily rectified.
Take the erroneous ORG???|?
?/City Committee Organizes,?
for example, in-tuitively it is not an ORG since an entity cannot span anypunctuation.3 Our Proposed Framework3.1 OverviewWe propose a framework based on probabilistic graphicalmodels with first-order logic for Chinese NER.
As shownin Figure 1, the framework is composed of three main com-ponents.
The CRF model is used as a base model.
Then weincorporate domain knowledge that can be well formulatedinto first-order logic to extract entity candidates from CRFresults.
Finally, the Markov Logic Network (MLN), anundirected graphical model for statistical relational learn-ing, is used to validate and correct the errors made in thebase model.
We begin by briefly reviewing the necessarybackground of MLNs, including weight learning and infer-ence.3.2 Markov Logic NetworksA Markov Network (also known as Markov Random Field)is a model for the joint distribution of a set of variables(Pearl, 1988).
It is composed of an undirected graph G =(V,E) and a set of real-valued potential functions ?k.
AFirst-Order Knowledge Base (KB) (Genesereth and Nisls-son, 1987) is a set of sentences or formulas in first-orderlogic.A Markov Logic Network (MLN) (Richardson andDomingos, 2006) is a KB with a weight attached to eachformula (or clause).
Together with a set of constantsrepresenting objects in the domain, it species a groundMarkov Network containing one feature for each possi-ble grounding of a first-order formula Fi in the KB, withthe corresponding weight wi.
The basic idea in MLNsis that: when a world violates one formula in the KBit is less probable, but not impossible.
The fewer for-mulas a world violates, the more probable it is.
Theweights associated with the formulas in an MLN jointlydetermine the probabilities of those formulas (and viceversa) via a log-linear model.
An MLN is a statisti-cal relational model that defines a probability distributionover Herbrand interpretations (possible worlds), and canFigure 1: Framework Overviewbe thought of as a template for constructing Markov Net-works.
Given different sets of constants, it will producedifferent networks.
These networks will have certain reg-ularities in structure and parameter given by the MLNand they are called ground Markov Networks.
SupposePeter(A), Smith(B) and IBM(X) are 3 constants,a KB and generated features are listed in Table 1.
Theformula Employ(x,y)?Person(x),Company(y)means x is employed by y and Colleague(x,y)?Employ(x,z)?Employ(y,z) means x and y are col-leagues if they are employed by the same company.
Fig-ure 2 shows the graph of the ground Markov networkdefined by the formulas in Table 1 and the 3 constantsPeter(A), Smith(B) and IBM(X).
The probabilitydistribution over possible worlds x specified by the groundMarkov Network ML,C is given byP (X = x) =1Zexp(?wini(x )) =1Z?
?i(x{i})ni(x)(1)where ni (x) is the number of true groundings of Fi inx, x{i} is the true value of the atoms appearing in Fi, and?i(x{i})= ewi .In the case of Chinese NER, a named entity can be con-nected to another named entity for instance, because theyshare the same location salient word.
Thus in an undirectedgraph, two node types exist, the LOC nodes and the loca-tion salient word nodes.
The links (edges) indicate the rela-tion (LOCs contain location salient words) between them.This representation can be well expressed by MLNs.However, one problem concerning relational data is, howto extract useful relations for Chinese NER.
There are manykinds of relations between NEs, some relations are criticalto the NER problemwhile others not.
Another problem thatwe address is whether these relations can be formulated infirst-order logic and combined in MLNs.
In Section 3.3,we exploit domain knowledge.
We will show how theseknowledge can capture essential characteristics of ChineseNEs and can be well and concisely formulated in first-orderlogic in Section 3.4.337Table 1: Example of a KB and Generated FeaturesFist-Order Logic (KB) Generated Features?
x,y Employ(x,y)?Person(x),Company(y) Employ(Peter,IBM)?Person(Peter),Company(IBM)Employ(Smith,IBM)?Person(Smith),Company(IBM)?
x,y,z Colleague(x,y)?
Employ(x,z)?Employ(y,z) Colleague(Peter,Smith)?
Employ(Peter,IBM)?Employ(Smith,IBM)3.2.1 Learning WeightsGiven a relational database, MLN weights can in princi-ple be learned generatively by maximizing the likelihood ofthis database on the closed world assumption.
The gradientof the log-likelihood with respect to the weights is?
?wilogPw(X = x) = ni (x) ?
?Pw(X = x?)ni(x?
)(2)where the sum is over all possible databases x?
, andPw(X = x?)
is P (X = x?)
computed using the cur-rent weight vector w = (w1, ..., wi, ...).
Unfortunately,computing these expectations can be very expensive.
In-stead, we can maximize the pseudo-log-likelihood of thedata more efficiently.
If x is a possible database and xl isthe lth ground atom?s truth value, the pseudo-log-likelihoodof x given weights w islogP ?w(X = x) =n?l=1logPw(Xl=xl | MBx(Xl )) (3)where MBx (Xl) is the state of Xl?s Markov blanket 2in the data.
Computing Equation 3 and its gradient doesnot require inference over the model, and is therefore muchfaster.
We can optimize the pseudo-log-likelihood usingthe limited-memory BFGS algorithm (Liu and Nocedal,1989).3.2.2 InferenceIf F1 and F2 are two formulas in first-order logic, C isa finite set of constants including any constants that appearin F1 or F2, and L is an MLN, thenP (F1 | F2, L, C) = P (F1 | F2,ML,C)=P (F1 ?
F2 | ML,C)P (F2 | ML,C)=?x??F1?
?F2P (X = x | ML,C)?x?
?F2P (X = x | ML,C)(4)where ?Fi is the set of worlds where Fi holds, and P (x |ML,C) is given by Equation 1.
The question of whether aknowledge base entails a formula F in first-order logic isthe question of whether P (F | LKB, CKB,F ) = 1, whereLKB is the MLN obtained by assigning infinite weight to2 The Markov blanket of a node is the minimal set of nodesthat renders it independent of the remaining network; in a MLN,this is simply the node?s neighbors in the graph.Figure 2: A Ground Markov network defined by the formu-las in Table 1 and the constants Peter(A), Smith(B)and IBM(X).all the formulas in KB, andCKB,F is the set of all constantsappearing in KB or F .A large number of efficient inference techniques are ap-plicable to MLNs.
The most widely used approximate so-lution to probabilistic inference in MLNs is Markov chainMonte Carlo (MCMC) (Gilks et al, 1996).
In this frame-work, the Gibbs sampling algorithm is to generate an in-stance from the distribution of each variable in turn, con-ditional on the current values of the other variables.
Thekey to the Gibbs sampler is that one only considers uni-variate conditional distributions-the distribution when allof the random variables but one are assigned fixed values.One way to speed up Gibbs sampling is by Simulated Tem-pering (Marinari and Parisi, 1992), which performs simu-lation in a generalized ensemble, and can rapidly achievean equilibrium state.
Poon and Domingos (2006) pro-posedMC-SAT, an inference algorithm that combines ideasfrom MCMC and satisfiability.
MC-SAT works well and isguaranteed to be sound, even when deterministic or near-deterministic dependencies are present in real-world rea-soning.Besides MCMC framework, maximum a posteriori(MAP) inference can be carried out using a weighted sat-isfiability solver like MaxWalkSAT.
It is closely related tomaximum likelihood (ML), but employs an augmented op-timization objective which incorporates a prior distributionover the quantity one wants to estimate.
MAP estimationcan therefore be seen as a regularization of ML estimation.3.3 Domain KnowledgeWe incorporate various kinds of domain knowledge viaMLNs to predict the newly extracted NE candidates from338CRF hypotheses.
We extract 165 location salient wordsand 843 organization salient words from Wikipedia3 andthe LDC Chinese-English bi-directional NE lists compiledfrom Xinhua News database, as shown in Table 2.
We alsomake a punctuation list which contains 18 items and somestopwords which Chinese NEs cannot contain.
The stop-words are mainly conjunctions, auxiliary and functionalwords.
We extract new NE candidates from the CRF re-sults according to the following consideration:?
Definitely, if a chunk (a series of continuous characters) oc-curs in the training data as a PER or a LOC or an ORG, thenthis chunk should be a PER or a LOC or an ORG in the test-ing data.
In general, a unique string is defined as a PER, itcannot be a LOC somewhere else.?
Obviously, if a tagged entity ends with a location salientword, it is a LOC.
If a tagged entity ends with an organi-zation salient word, it is an ORG.?
If a tagged entity is close to a subsequent location salientword, probably they should be combined together as a LOC.The closer they are, the more likely that they should be com-bined.?
If a series of consecutive tagged entities are close to a sub-sequent organization salient word, they should probably becombined together as an ORG because an ORG may containmultiple PERs, LOCs and ORGs.?
Similarly, if there exists a series of consecutive tagged enti-ties and the last one is tagged as an ORG, it is likely that allof them should be combined as an ORG.?
Entity length restriction: all kinds of tagged entities cannotexceed 25 Chinese characters.?
Stopword restriction: intuitively, all tagged entities cannotcomprise any stopword.?
Punctuation restriction: in general, all tagged entities cannotspan any punctuation.?
Since all NEs are proper nouns, the tagged entities shouldend with noun words.?
The CRF model tags each token (Chinese character) witha conditional probability.
A low probability implies alow-confidence prediction.
For a chunk with low condi-tional probabilities, all the above assumptions are adopted(The marginal probabilities are normalized, and probabili-ties lower than the user-defined threshold are regarded aslow conditional probabilities).All the above domain knowledge can be formulated asfirst-order logic to construct the structure of MLNs.
Andall the extracted chunks are accepted as new NE candidates(or common nouns).
We train an MLN to recognize them.3http://en.wikipedia.org/wiki/.Table 2: Domain Knowledge for Chinese NERLocation Salient Word Organization Salient Wordg?
?/Municipality z?
?i/Department Store??
?/Railway Station n?
?/Technical InstituteU,/Hotel ?1/Travel Agency?
/Park ?
?/Pressp/Plateau <?
?/Personnel Department?/Province ?1/Bank/Town ?
?/University?/City ?
?/City CommitteeStopword PunctuationE,/still "?/but ?
?~/very ?ff/of ;/and so on ?
@/that ?3.4 First-Order Logic RepresentationWe declared 14 predicates (person(candidate), location(candidate), organization(candidate), endwith(candidate, salientword), closeto(candidate, salientword), containstopword(candidate), containpunctuation(candidate), etc) and specified 15 first-order formulas (SeeTable 3 for some examples) according to the domainknowledge described in Section 3.3.
For example, weused person(candidate) to specify whether a candi-date is a PER.
Formulas are recursively constructed fromatomic formulas using logical connectives and quantifiers.They are constructed using four types of symbols: con-stants, variables, functions, and predicates.
Constant sym-bols represent objects in the domain of interest (e.g., ??/Beijing?
and ???/Shanghai?
are LOCs).
Variablesymbols (e.g., r and p) range over the objects in the do-main.
To reduce the size of ground Markov Network,variables and constants are typed; for example, the vari-able r may range over candidates, and the constant ??/Beijing?
may represent a LOC.
Function symbols repre-sent mappings from tuples of objects to objects.
Predicatesymbols represent relations among objects (e.g., person)in the domain or attributes of objects (e.g., endwith).
Aground atom is an atomic formula all of whose argumentsare ground terms (terms containing no variables).
For ex-ample, the ground atom location(??)
conveysthat ??
?/Beijing City?
is a LOC.For example in Table 3, ??
?/Wu City?
is mis-taggedas an ORG by the CRF model, but it contains the locationsalient word ??/City?.
So it is extracted as a new entitycandidate, and the corresponding formula endwith(r,p)?locsalientword(p)?location(r) means ifr ends with a location salient word p, then it is a LOC.Besides the formulas listed in Table 3, we also speci-fied logic such as person(p)?!
(location(p) vorganization(p)), which means a candidate p can339Table 3: Examples of NE Candidates and First-Order FormulasMis-tagged NEs New NE Candidates First-Order LogicF.p[common noun] F.p occurperson(p)?person(p)?m[PER] ?m occurlocation(p)?location(p)??8?
[common noun] ??8?
occurorganization(p)?organization(p)??
[ORG] ??
endwith(r,p)?locsalientword(p)?location(r)=?
[LOC] =?
endwith(r,p)?orgsalientword(p)?organization(r)?
[LOC]s	 ?s	 closeto(r,p)?locsalientword(p)?location(r)a?[LOC]??
a???
closeto(r,p)?orgsalientword(p)?organization(r)?
?ff?A[LOC] ?
?ff?A containstopword(p)?!
(person(p) v location(p) vorganization(p))?z????
?%[ORG] ?z????
?% containpunctuation(p)?!
(person(p) v location(p)v organization(p))only belong to one class.We assume that the relational database contains only bi-nary relations.
Each extracted NE candidate is representedby one or more strings appearing as arguments of groundatoms in the database.
The goal of NE prediction is to de-termine whether the candidates are entities and the types ofentities (query predicates), given the evidence predicatesand other relations that can be deterministically derivedfrom the database.
As we will see, despite their simplic-ity and consistency, these first-order formulas incorporatethe essential features for NE prediction.4 Experiments4.1 DatasetWe used People?s Daily corpus (January-Jun, 1998) inour experiments, which contains approximately 357K sen-tences, 156K PERs, 219K LOCs and 87K ORGs, respec-tively.
We did some modifications on the original data tomake it cleaner.
We enriched some tags so that the abbre-viation proper nouns are well labeled.
We preprocessedsome nested names to make them in better form.
We alsoprocessed some person names.
We enriched tags for differ-ent kinds of person names (e.g., Chinese and transliteratednames) and separated consecutive person names.4.2 The Baseline NER SystemWe use CRFs to build a character-based Chinese NER sys-tem, with features described in Section 2.1.
To avoid over-fitting, we penalized the log-likelihood by the commonlyused zero-mean Gaussian prior over the parameters.
Inaddition, we exploit clue word features which can capturenon-local dependencies.
This gives us a competitive base-line CRF model using both local and non-local informationfor Chinese NER.For clue word features, we employ 412 career titles (e.g.,o?/President,?/Professor,?
/Police), 59 family ti-tles (e.g.,ww/Father,~~/Sister), 33 personal pronouns(e.g., \?/Your, ?
?/We) and 109 direction words (e.g.,?/North, H?/South) to represent non-local informa-tion.
Career titles, family titles and personal pronouns mayFigure 3: An Example of Non-local Dependency.
The Ca-reer Title ???
Indicates a PER ?
?^?imply a nearby PER and direction words may indicate aLOC or an ORG.
Figure 3 illustrates an example of non-local dependency.We do not take the advantage of using the golden-standard word segmentation and POS tagging provided inthe original corpus, since such information is hardly avail-able in real text.
Instead, we use an off-the-shelf Chi-nese lexical analysis system, the open source ICTCLAS(Zhang et al, 2003), to segment and POS tag the corpus.This module employs a hierarchical Hidden Markov Model(HHMM) and provides word segmentation, POS tagging(labels Chinese words using a set of 39 tags) and unknownword recognition.
It performs reasonably well, with seg-mentation precision recently evaluated at 97.58%.
The re-call of unknown words using role tagging is over 90%.We use one-month corpus for training and 9-day corpusfor testing.
Table 4 shows the experimental results.4.3 NER System Based on Graphical Models withLogicTo test the effectiveness of our proposed model, we extractall the NEs (19,879 PERs, 25,661 LOCs and 11,590 ORGs)from the training corpus.
An MLN training database,which consists of 14 predicates, 16,620 constants and97,992 ground atoms was built.The MLNs were trained using a Gaussian prior withzero mean and unit variance on each weight to penalizethe pseudo-likelihood, and with the weights initialized atthe mode of the prior (zero).
During MLN learning, eachformula is converted to Conjunctive Normal Form (CNF),and a weight is learned for each of its clauses.
The weight340Table 4: Chinese NER by CRF ModelPrecision Recall F?=1Character featuresPER 92.88% 79.42% 85.62LOC 90.95% 82.88% 86.73ORG 88.16% 83.86% 85.96Overall 90.92% 82.07% 86.27Character+WordPER 93.27% 82.99% 87.83LOC 91.49% 85.16% 88.21ORG 88.94% 84.79% 86.82Overall 91.48% 84.46% 87.83Character+Word+POSPER 92.17% 90.64% 91.40LOC 90.56% 89.74% 90.15ORG 89.15% 85.19% 87.12Overall 90.76% 89.13% 89.94All featuresPER 92.12% 90.57% 91.34LOC 90.62% 89.74% 90.18ORG 89.72% 85.44% 87.53Overall 90.89% 89.16% 90.02Table 5: Chinese NER by Graphical Models with LogicPrecision Recall F?=1 RERCRF BaselinePER 92.12% 90.57% 91.34LOC 90.62% 89.74% 90.18ORG 89.72% 85.44% 87.53Overall 90.89% 89.16% 90.02Graphical Models (GS Inference)PER 93.52% 93.32% 93.42LOC 93.19% 91.91% 92.55ORG 90.16% 90.71% 90.43Overall 92.70% 92.09% 92.39 23.75%Graphical Models (ST Inference)PER 93.52% 93.32% 93.42LOC 93.19% 91.91% 92.55ORG 90.16% 90.71% 90.43Overall 92.70% 92.09% 92.39 23.75%Graphical Models (MC-SAT Inference)PER 93.52% 93.32% 93.42LOC 93.19% 91.91% 92.55ORG 90.16% 90.71% 90.43Overall 92.70% 92.09% 92.39 23.75%Graphical Models (MAP/MPE Inference)PER 92.87% 93.15% 93.01LOC 93.15% 91.61% 92.37ORG 90.56% 89.10% 89.82Overall 92.57% 91.58% 92.07 20.54%of a clause is used as the mean of a Gaussian prior for thelearned weight.
These weights reflect how often the clausesare actually observed in the training data.We extract 529 entity candidates to construct the MLNtesting database, which contains 2,543 entries and these en-tries are used as evidence for inference.
Inference is per-formed by grounding the minimal subset of the network re-quired for answering the query predicates.
We employed 3MCMC algorithms: Gibbs sampling (GS), Simulated Tem-pering (ST) as well as MC-SAT, and the MAP/MPE algo-rithm for inference and the comparative NER results areshown.
The probabilistic graphical models greatly outper-form the CRF model stand-alone by a large margin.
It canbe seen from Table 5, the probabilistic graphical modelsintegrating first-order logic improve the precision and re-call for all kinds of entities, thus boosting the overall F-measure.
We achieve a 23.75% relative error reduction(RER) on F-measure by using 3 MCMC algorithms anda 20.54% RER by using MAP/MPE algorithm, over an al-ready competitive CRF baseline.
We obtained the sameresults using GS, ST and MC-SAT algorithms.
MCMC al-gorithms yields slightly better results than the MAP/MPEalgorithm.4.4 Significance TestIdeally, comparisons among NER systems would controlfor feature sets, data preparation, training and test proce-dures, parameter tuning, and estimate the statistical sig-nificance of performance differences.
Unfortunately, re-ported results sometimes leave out details needed for ac-curate comparisons.We give statistical significance estimates using McNe-mar?s paired tests 4 (Gillick and Cox, 1989) on labelingdisagreements for CRF model and graphical probabilisticmodels that we evaluated directly.Table 6 summarizes the correctness of the labeling de-cisions between the models with a 95% confidence inter-val (CI).
These tests suggest that the graphical probabilisticmodels are significantly more accurate and confirm that thegains we obtained are statistically highly significant.Table 6: McNemar?s Tests on Labeling DisagreementsNull Hypothesis 95% CI p-valueProposed Model (GS) vs. CRFs 5.71-9.52 < 1 ?
10?6Proposed Model (ST) vs. CRFs 5.71-9.52 < 1 ?
10?6Proposed Model (MC-SAT) vs. CRFs 5.71-9.52 < 1 ?
10?6Proposed Model (MAP/MPE) vs. CRFs 4.50-7.37 < 1 ?
10?65 Related WorkAs a well-established task, Chinese NER has been studiedextensively and a number of techniques for this task havebeen reported in the literature.
Most recently, the trendin Chinese NER is to use improved machine learning ap-proaches, or to integrate various kinds of useful evidences,features, or resources.Fu and Luke (2005) presented a lexicalized HMM-based approach to unifying unknown word identification4Most researchers refer to statistically significant as p < 0.05and statistically highly significant as p < 0.001.341and NER as a single tagging task on a sequence of knownwords.
Although lexicalized HMMs was shown to be su-perior to standard HMMs, this approach has some disad-vantages: it is a purely statistical model and it suffers fromthe problem of data sparseness.
And the model fails to tagsome complicated NEs (e.g., nested ORGs) correctly dueto lack of domain adaptive techniques.
The F-measures ofLOCs and ORGs are only 87.13 and 83.60, which showthat there is still a room for improving.A method of incorporating heuristic human knowledgeinto a statistical model was proposed in (Wu et al, 2005).Here Chinese NER was regarded as a probabilistic taggingproblem and the heuristic human knowledge was used toreduce the searching space.
However, this method assumesthat POS tags are golden-standard in the training data andheuristic human knowledge is often ad hoc.
These draw-backs make the method unstable and highly sensitive toPOS errors; and when golden-standard POS tags are notavailable (this is often the case), it may degrade the perfor-mance.Cohen and Sarawagi (2004) proposed a semi-Markovmodel which combines a Markovian, HMM-like extrac-tion process and a dictionary component.
This process isbased on sequentially classifying segments of several ad-jacent words.
However, this technique requires that entiresegments have the same class label, while our techniquedoes not.
Moreover, compared to a large-scale dictionary,our domain knowledge is much easier to obtain.However, all the above models treat NER as classifi-cation or sequence labeling problem.
To the best of ourknowledge, MLNs have not been previously used for NERproblem.
To our knowledge, we first view Chinese NERas a statistical relational learning problem and exploit do-main knowledge which can be concisely formulated inMLNs, allowing the training and inference algorithms tobe directly applied to them.6 Conclusion and Future WorkThe contribution of this paper is three-fold.
First, we for-mulate Chinese NER as a statistical relational learningproblem and propose a new framework incorporating prob-abilistic graphical models and first-order logic for ChineseNER which achieves state-of-the-art performance.
Second,We incorporate domain knowledge to capture the essen-tial features of the NER task via MLNs, a unified frame-work for SRL which produces a set of weighted first-order clauses to predict new NE candidates.
To the bestof our knowledge, this is the first attempt at using MLNsfor the NER problem in the NLP community.
Third,our proposed framework can be extendable to language-independent NER, due to the simplicity of the domainknowledge we could access.
Directions for future workinclude learning the structure of MLNs automatically andusing MLNs for information extraction (e.g., entity relationextraction).ReferencesDaniel M. Bikel, Richard Schwartz, and Ralph M. Weischedel.
An algorithm that learns what?s ina name.
Machine Learning, 34(1-3):211?231, February 1999.Andrew Borthwick.
A Maximum Entropy Approach to Named Entity Recognition.
PhD thesis,New York University, September 1999.Eric Brill.
Transformation-based error-driven learning and natural language processing: A casestudy in part-of-speech tagging.
Computational Linguistics, 21(4):543?565, 1995.Aitao Chen, Fuchun Peng, Roy Shan, and Gordon Sun.
Chinese named entity recognition withconditional probabilistic models.
In 5th SIGHAN Workshop on Chinese Language Processing,Australia, July 2006.Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.
Chinese named entity recognition with condi-tional random fields.
In 5th SIGHAN Workshop on Chinese Language Processing, Australia,July 2006.Hai Leong Chieu and Hwee Tou Ng.
Named entity recognition with a maximum entropy approach.In Proceedings of CoNLL-03, 2003.William W. Cohen and Sunita Sarawagi.
Exploiting dictionaries in named entity extraction: Com-bining semi-Markov extraction processes and data integration methods.
In Proceedings ofACM-SIGKDD 2004, 2004.Guohong Fu and Kang-Kwong Luke.
Chinese named entity recognition using lexicalized HMMs.ACM SIGKDD Explorations Newsletter, 7:19?25, June 2005.Michael R. Genesereth and Nils J. Nislsson.
Logical foundations of artificial intelligence.
MorganKaufmann Publishers Inc., San Mateo, CA, 1987.W.R.
Gilks, S. Richardson, and D.J.
Spiegelhalter.
Markov chain Monte Carlo in practice.
Chap-man and Hall, London, UK, 1996.L.
Gillick and Stephen Cox.
Some statistical issues in the comparison of speech recognition algo-rithms.
In Proceedings of ICASSP-89, pages 532?535, 1989.Hideki Isozaki and Hideto Kazawa.
Efficient support vector classifiers for named entity recogni-tion.
In Proceedings of COLING-02, pages 1?7, Taipei, Taiwan, 2002.John Lafferty, Andrew McCallum, and Fernando Pereira.
Conditional random fields: Probabilisticmodels for segmenting and labeling sequence data.
In Proceedings of ICML-01, pages 282?289.
Morgan Kaufmann, San Francisco, CA, 2001.Dong C. Liu and Jorge Nocedal.
On the limited memory BFGS method for large scale optimiza-tion.
Mathematical Programming, 45:503?528, 1989.EnzoMarinari and Giorgio Parisi.
Simulated Tempering: A newMonte Carlo scheme.
EurophysicsLetters, 19:451?458, 1992.AndrewMcCallum andWei Li.
Early results for named entity recognition with conditional randomfields, feature induction and web-enhanced lexicons.
In Proceedings of CoNLL-03, 2003.Judea Pearl.
Probabilistic reasoning in intelligent systems: networks of plausible inference.
Mor-gan Kaufmann Publishers Inc., San Francisco, CA, 1988.Fuchun Peng and Andrew McCallum.
Accurate information extraction from research papers usingconditional random fields.
In Proceedings of HLT-NAACL 2004, pages 329?336, 2004.Fuchun Peng, Fangfang Feng, and Andrew McCallum.
Chinese segmentation and new word de-tection using conditional random fields.
In Proceedings of COLING-04, pages 562?568, 2004.David Pinto, AndrewMcCallum, XingWei, andW.
Bruce Croft.
Table extraction using conditionalrandom fields.
In Proceedings of ACM SIGIR-03, 2003.Hoifung Poon and Pedro Domingos.
Sound and efficient inference with probabilistic and deter-ministic dependencies.
In Proceedings of AAAI-06, Boston, Massachusetts, July 2006.
TheAAAI Press.Matthew Richardson and Pedro Domingos.
Markov logic networks.
Machine Learning, 62(1-2):107?136, 2006.Burr Settles.
Biomedical named entity recognition using conditional random fields and rich featuresets.
In Proceedings of the COLING 2004 International Joint Workshop on Natural LanguageProcessing in Biomedicine and its Applications, Geneva, Switzerland, 2004.Fei Sha and Fernando Pereira.
Shallow parsing with conditional random fields.
In Proceedings ofHLT-NAACL 2003, pages 213?220, 2003.Maosong Sun, Changning Huang, Haiyan Gao, and Jie Fang.
Identifying Chinese names in unre-stricted texts.
Journal of Chinese Information Processing, 1995.Youzheng Wu, Jun Zhao, Bo Xu, and Hao Yu.
Chinese named entity recognition based on multiplefeatures.
In Proceedings of HLT-EMNLP 2005, 2005.Xiaofeng Yu, Marine Carpuat, and Dekai Wu.
Boosting for Chinese named entity recognition.
In5th SIGHAN Workshop on Chinese Language Processing, Australia, July 2006.Hua Ping Zhang, Qun Liu, Xue-Qi Cheng, Hao Zhang, and Hong Kui Yu.
Chinese lexical analysisusing Hierarchical Hidden Markov Model.
In 2nd SIGHAN Workshop on Chinese LanguageProcessing, volume 17, pages 63?70, 2003.Guodong Zhou and Jian Su.
Named entity recognition using an HMM-based chunk tagger.
InProceedings of ACL-02, pages 473?480, Philadelphia, USA, 2002.Junsheng Zhou, Liang He, Xinyu Dai, and Jiajun Chen.
Chinese named entity recognition witha multi-phase model.
In 5th SIGHAN Workshop on Chinese Language Processing, Australia,July 2006.342
