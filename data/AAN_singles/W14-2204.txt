Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 24?33,Baltimore, Maryland, USA, 26 June 2014.c?2014 Association for Computational LinguisticsLingSync & the Online Linguistic Database:New models for the collection and management of data for languagecommunities, linguists and language learnersJoel DunhamUniversity of British Columbia,Department of Linguisticsjrwdunham@gmail.comGina CookiLanguage LabMontr?ealgina.c.cook@gmail.comJoshua HornerAmiliaMontr?ealjosh.horner@gmail.comAbstractLingSync and the Online LinguisticDatabase (OLD) are new models for thecollection and management of data inendangered language settings.
The Ling-Sync and OLD projects seek to close afeedback loop between field linguists, lan-guage communities, software developers,and computational linguists by creatingweb services and user interfaces (UIs)which facilitate collaborative and inclu-sive language documentation.
This paperpresents the architectures of these toolsand the resources generated thus far.
Wealso briefly discuss some of the featuresof the systems which are particularly help-ful to endangered languages fieldwork andwhich should also be of interest to compu-tational linguists, these being a service thatautomates the identification of utteranceswithin audio/video, another that automatesthe alignment of audio recordings andtranscriptions, and a number of servicesthat automate the morphological parsingtask.
The paper discusses the requirementsof software used for endangered languagedocumentation, and presents novel datawhich demonstrates that users are activelyseeking alternatives despite existing soft-ware.1 IntroductionIn this paper we argue that the LingSync/OLDproject is a sustainable new model for data man-agement which facilitates a feedback loop be-tween fieldworkers, language communities, com-putational linguists, and software developers,thereby improving the effectiveness of languagedocumentation efforts for low-resource languagecommunities.
In ?2.1 we present five require-ments for endangered languages fieldwork soft-ware which are currently not met by existing tools,as discussed in ?2.2.
Architectural considerations1under LingSync and the OLD which address theserequirements are briefly outlined in ?3.
The abilityof LingSync/OLD to integrate with existing soft-ware libraries commonly used in language docu-mentation projects is demonstrated in ?5.
Finally,?6 demonstrates how the LingSync/OLD projectis already seeing some closure of the feedbackloop both in creating language learning apps forheritage speakers and in training Kartuli speak-ers to build speech recognition systems built onLingSync/OLD data.2 Endangered languages fieldworkEndangered languages are valuable culturally andscientifically, to their communities of origin (Iron-strack, 2012) and to humanity as a whole (Har-rison, 2007).
Efforts must be made to documentthese languages while there is still time (Good,2012a; Thieberger, 2012).
In cases where there areno longer any native speakers, a community mayembark upon a language reclamation project thatis wholly dependent upon the the products of pastlanguage documentation efforts (Leonard, 2012;Costa, 2012).
Alongside such documentationand revitalization/reclamation projects is research-driven linguistic fieldwork.
These diversely mo-tivated yet interconnected strands within endan-gered languages fieldwork conspire to produce aparticular set of requirements for effective soft-ware in this domain.2.1 Software requirementsThe following five requirements are essential, weclaim, to effective language documentation soft-1For further discussion of actual user interaction,screenshots and how LingSync/OLD data can be ex-ported/published in existing online linguistics repositoriessuch as EOPAS http://www.eopas.org/ and OLAC http://www.language-archives.org/ see Cathcart et al.
(2012).24ware: integration of primary data, curation ofdata, inclusion of stakeholders, openable data,and user productivity.Requirement 1 Integration of primary dataWhile language reclamation projects foundedsolely on textual data can achieve some degreeof success (Ironstrack, 2012), primary audio/videodata in the form of engaging content is crucialto fostering native-like proficiency.
Primary au-dio has formed part of language documentationefforts since the days of phonographs, yet onlyrarely have such audio products been made acces-sible.
Securely and efficiently supporting the inte-gration of primary audio/video data with text ar-tifacts (e.g., dictionaries, grammars, collections ofnarratives) is part of the requirements of any mod-ern language documentation effort (Schroeter andThieberger, 2006; Good, 2012b).2Requirement 2 Curation of dataWhile most language documentation literatureplaces emphasis on the creation of publishable ar-tifacts, our experience has shown that a significantpercentage of language documentation hours areactually dedicated to the curation and filtering ofthe data in preparation for publication.3Even ?afunding body like the ELDP cannot get all of itsgrantees [only 110 out of 216] to deposit in anarchive in a timely fashion (or at all)?
(Thieberger,2012).
We argue that facilitating the collabora-tive curation of data is, in fact, a core requirementof any data management or content managementsoftware, one which is largely overlooked by ex-isting software (cf.
?2.2).Requirement 3 Inclusion of stakeholdersA sustainable language documentation effort in-volves crucially the creation of a positive feed-back loop where the outputs of certain activitiesfuel the advancement of others.
However, realiz-ing this feedback loop requires tools that facili-tate the inclusion of the various stakeholders in-volved in the process of language documentationwhile a project is underway, not post hoc whenthe data is ?polished,?
which in 50% of projects2For a more detailed discussion of the technical limita-tions which are no longer blocking the implementation ofthese requirements see Cathcart et al.
(2012).3Such artifacts might include engaging content to bereused in revitalization efforts, or citable/traceable data setsused to support research claims.never happens (Thieberger, 2012).
This inclusiv-ity requirement means that data and data pro-cesses must be available in formats that are us-able to both humans?i.e., via graphical user inter-faces (GUIs)?and machines?i.e., via softwarelibraries and application programming interfaces(APIs).Requirement 4 Openable dataOne of the unique challenges associated withendangered languages fieldwork is the possibilitythat speakers or language communities may re-quire that all or aspects of the raw data be kept con-fidential for a certain period of time.4Labs lookingto reuse the data collected by field teams may, inparticular, be unaware of the post-colonial contextin which many fieldwork situations are embedded.In the field it often happens that a speaker willspeak quite candidly or receive a phone call dur-ing a recorded elicitation session and may want torestrict access to all or parts of that recording forpersonal reasons.5In some cases the living speak-ers of the language are so few that even anonymiz-ing the data does not conceal the identity of thespeaker from other speakers in the community.
Italso happens that particular stories or descriptionsof rituals and cultural practices may need to be re-stricted to just the language community or even tosub-groups within the community.6In order to provide access to all team mem-bers and stakeholders (including stakeholders whoare distrustful of the project) language documen-tation software must support a non-trivial permis-sions system while also facilitating transparency4Outside of language documentation contexts there arenumerous valid reasons for facilitating data privacy.
As withsocial websites (Facebook, YouTube), user data is generallyconsidered private and not accessible to data scientists.
Manycontent curation sites (Google Docs, WordPress) allow forcontent that is private indefinitely or during a pre-publicationstage.5Of course, as one reviewer points out, basing claimson private data runs contrary to a core tenet of the scien-tific method, namely that claims must be able to be assessedwith transparent access to the methods and data used to sup-port them.
However, in these contexts field linguists generallyprotect the privacy of their language consultants by elicitingnovel sentences which have similar grammatical features forpublication, rather than using the original narrative.
In thecontexts of open data, such highly personal sections of tran-scripts must be ?blacked out?
so that the majority of the datacan be made open.6It is highly preferable for language communities to pro-duce their own content using YouTube and other content sites,permitting the community to manage censorship of sensi-tive topics and personal narratives while creating more publicdata.25and encouraging open collaboration.
Even lan-guage documentation projects using ad hoc con-tent creation solutions (discussed in ?2.2) can-not be fully inclusive for fear that when speak-ers of different dialects disagree they will ?cor-rect?
each other?s data if neither social pressurenor the permissions system prevents it.
In fact, dis-agreements about data judgments remain an un-tapped indirect source of grammaticality informa-tion for linguistics researchers as there are no lan-guage documentation systems which permit inclu-sion of all stakeholders via traceable user activity,non-trivial permissions systems, and confidential-ity of attributes on data.
While not all teams willresort to data encryption or private data, imple-menting these features permits more stakeholdersto have direct conditional access to data and re-moves barriers to adoption by language commu-nities who may be initially distrustful of languagedocumentation projects.Requirement 5 User productivityUsers are accustomed to professionally craftedsoftware built by teams of hundreds of softwareengineers, software designers, and user experi-ence experts (e.g., Facebook, Gmail, Google Docs,YouTube, Evernote, Dropbox).
They can read theiremail on all devices, download and sync photosand videos automatically, and have offline and mo-bile data there seamlessly when they need it.
Yetresearch software is often built by computer sci-ence students with no experience in software en-gineering and human computer interaction.
Over-whelmingly, users attribute their use of genericdata curation software such as Microsoft Excel orGoogle Spreadsheets, rather than software specifi-cally designed for language documentation, to theproductivity of the user experience itself (Cathcartet al., 2012).
In some cases users are so productiveusing Google Spreadsheets that the actual data en-try of a project can be completed before an exist-ing language documentation tool can be evaluatedand/or customized (Troy and Strack, 2014).2.2 Existing softwareFieldwork teams typically have the choicebetween using general-purpose content cura-tion software (Google Spreadsheets, Evernote,Dropbox, MediaWikis, WordPress, etc.
), creat-ing/customizing their own tools, or using special-ized field linguistics desktop applications such asthose developed by SIL International: FieldWorksLanguage Explorer (FLEx),7Toolbox/Shoebox,8and/or WeSay.9The SIL tools10require a not inconsiderablelevel of training in order to be used productively.However, many research teams are unable to im-pose lengthy training upon all team members andrequire tools that are easy to learn and re-learnmonths or years later when they return to theirdata.
In addition, the SIL tools are tailored towardsthe collection of texts and the production of dic-tionaries and descriptive grammars based on such.However, this focus does not always accord withthe needs of research-oriented fieldworkers, manyof whom deal primarily in sentences elicited inisolation and grammaticality judgments.Existing language documentation softwaretools, with the exception of WeSay (a collaborativedictionary tool), have only ad hoc support for col-laboration (Req.
4) and inclusive language docu-mentation (Req.
3) while the project is active, gen-erally using a shared network drive or email withno concurrent editing.
FLEx and many privatetools in the language technology industry are ableto support concurrent editing in most data entrysituations via a Mercurial/SVN/CVS/Git reposi-tory (SIL International, 2013).
However, as no per-missions are built into Mercurial/SVN/CVS/Git,users with read only access must use a man-ual review process to offer their modifications tothe project.
The FLEx Send/Receive collaborationmodule also limits the integration of audio/videoprimary data; it unfortunately does not supportformats used by field linguists including .ogg,.avi, .mp4, and .mov, and limits the maximumfile size to 1MB (SIL International, 2013), despitethe fact that most elicitation sessions or long ut-terances can range between 10MB and 200MB.While these scenarios may seem like rare edgecases, they can, in fact, result in teams opting notto use software designed for language documenta-tion.Over the past decade or so, a numberof language-specific collaborative websites havearisen, examples of which are the Yurok Docu-mentation Project (Garrett et al., 2001), the Washo7http://fieldworks.sil.org/flex8Toolbox is the community-supported continuationof Shoebox http://www-01.sil.org/computing/toolbox/information.htm9http://www.sil.org/resources/software fonts/wesay10For reviews of FLEx and Toolbox, see Butler andvan Volkinburg (2007), Rogers (2010), and Robinson et al.
(2007).26Project (Yu et al., 2005; Cihlar, 2008), the WashoMobile Lexicon (Yu et al., 2008), Karuk Dic-tionary and Texts (Garrett et al., 2009), and theIlaatawaakani project (Troy and Strack, 2014).More recently, collaborative tools have arisen that,like FLEx and Toolbox, are not specific to any onelanguage, but unlike FLEx and Toolbox, run onall devices in a web browser.
In this family be-long TypeCraft (Beermann and Mihaylov, 2012),the OLD (Dunham, 2014), and LingSync (Cath-cart et al., 2012).TypeCraft uses a MediaWiki UI combined withadditional functionality written in Java for manag-ing collaboration permissions and sharing.
Type-Craft falls into the category of field databases de-signed by corpus linguists.
As such it imposesupon users closed lists of categories for languagesand parts of speech (Farrar, 2010), an imposi-tion which is unacceptable to field linguists whoare dealing with evolving fine-grained analyses ofdata categories.
In addition, TypeCraft is onlineonly, a limitation which, as Farrar (2010) correctlypoints out, is ?not inconsiderable, especially forfieldworkers who may not have Internet access.
?None of the software projects discussed in thissection meet the software requirements for endan-gered languages fieldwork outlined in ?2.1.
Weargue that this mismatch in requirements is non-trivial and is the reason why so much fragmenta-tion and introduction of novel language documen-tation tools and software has occurred.113 New models for data collection andmanagement3.1 LingSyncLingSync is composed of existing and novel opensource software modules (rich client-side webcomponents and task-specific web services) whichallow all stakeholders of a language documen-tation effort to collaboratively create corpora ofprimary analyzed and unanalyzed language data(Cathcart et al., 2012).11We would like to point out that there are numerous otherprojects that have started and failed in the past 10 yearswhich we have not had space to mention.
The only stablelong-term fieldwork software projects have been those whichhave been undertaken by the Summer Institute of Linguis-tics (SIL).
The SIL development team is also on GitHub(https://github.com/sillsdev), a social tool for open sourceproject management; this will likely yield technical crossoverwith research teams and more use of HTML5 to facilitatemeeting the requirements delineated in ?2.1 in future SILsoftware.To meet the user productivity requirement (Req.5), LingSync uses a quasi-blackboard system ar-chitecture similar to Android;12that is, modulescan be registered to perform certain tasks, andusers can discover and choose between registeredmodules.
Similar to Praat,13all events in the sys-tem provide an audit trail which can be used byusers,14but also serve as data for automated rea-soning engines, should labs choose to make use ofthe audit data to assist in data cleaning and dataquality assurance.Based on the LingSync team?s collective priorexperience as field linguists, research assistants,professional lexicographers, and linguists in thelanguage technologies industry, we hypothesizethat perhaps 50% of data curation/cleaning tasksare monotonous, repetitive and consistent and thusare candidates for data manipulation best doneby machines or crowdsourcing rather than by oneindividual human for extended periods of time.The automation of tasks in field linguistic researchis rarely done, and for good reason.
Unlike cor-pus linguistics, field linguistics seeks fine-grainedanalysis of novel data on under-documented lan-guages, and data curators must be sensitive tothe slightest ?off?
feeling of analysis which couldeasily be flattened by over-generalizing cleaningscripts.
Automated modifications must be fullytraceable so as to detect side effects of cleaninglong after it has occurred.
They must also be eas-ily undoable so as not to introduce consistency orsystematicity which in fact does not exist in thedata.The potential time-saving features of Ling-Sync?s system design will not bear usable datawithout the explicit and overarching goal of pro-viding a user-friendly experience for both expertand novice users with differing data descriptionvocabularies and interests (Troy and Strack, 2014).Notable user-facing features include complete UIcustomization, powerful searches and mappingover data sets, encryption at a field level, flexi-ble enforcement of data consistency, social col-laborative software features, an inclusive permis-sions system, pluggable semi-automatic glossers,numerous task-oriented web services which wrapexisting libraries and scripts for audio, video, im-age and text analysis, two native Android GUIs12http://developer.android.com13http://praat.org14In the case of Praat users are able to generate automationscripts by clicking to create a repeatable sequence of events.27which function offline (Learn X and the ElicitationSession Recorder), and five browser-based GUIs(the Prototype, Spreadsheet, Activity Feeds, Cor-pus Pages, Lexicon Browser), one of which func-tions offline and provides flexible import and ex-port functionality.
Nearly all logic is performed onthe client-side which permits users to go offlineand consume low bandwidth when there is lim-ited connectivity through 3G or dial-up connec-tions.
For up-to-date examples of GUI interaction,readers are encouraged to search for LingSyncon YouTube.
As of April 2014 there are over 40videos made by users demonstrating diverse fea-tures in the systems.3.2 OLDThe OLD is software for creating web servicesthat facilitate collaborative linguistic fieldwork.A language-specific OLD web service exposes aconsistent API,15meaning that it can easily beused as the backend to multiple user-facing appli-cations or as a component in a larger suite of tools.An OLD web service and the current OLD GUI to-gether provide a number of features that respondto the requirements given in ?2.1.A language-specific OLD application allowsfor multiple contributors to simultaneously create,modify, browse, and search language data.
Thisdata consists of linguistic forms (i.e., morphemes,words, or phrases) that can be used to build cor-pora and texts.
The OLD supports the integra-tion of primary audio/video data by allowing forindividual forms to be associated to any numberof audio or video files (or even to subintervalsof such files) and by generating representationswherein textual and audio/video data are simulta-neously accessible.
Data is presented in interlinearglossed text (IGT) format and individual forms,collections of forms, and texts can be exported as(Xe)LaTeX, tab-separated values (TSV), or plaintext.
The system provides powerful search func-tionality including filters over system-generatedserializations of morphological analyses and, via15The OLD API is RESTful and JavaScript Object No-tation (JSON) is used as the medium of exchange through-out.
This means that OLD resources (e.g., linguistic datapoints such as sentences) can be created, retrieved, updated,deleted, and searched using standard combinations of Hyper-text Transfer Protocol (HTTP) methods and uniform resourcelocator (URL) patterns.
The system is written in Python usingthe Pylons web framework (http://www.pylonsproject.org/projects/pylons-framework/about) and the relational databasesoftware MySQL.integration with TGrep2,16the matching of struc-tural patterns within treebank corpora.Features promoting consistency include config-urable orthography converters, inventory-based in-put validation, and the provision of visual feed-back on the extent to which user-generated mor-phological analyses match existing lexical entriesin the database.
That last feature means that whena user creates a morphologically complex entry,the IGT representation indicates, via colour-codedinternal links, whether the morpheme shapes andglosses match current lexical entries.
It has provedto be quite useful in helping groups of fieldwork-ers to generate consistent morphological analyses.3.3 LingSync/OLDWhile LingSync and the OLD arose independentlyand consequently use different technology stacks,the teams behind the tools have largely comple-mentary interests and are collaborating on futuredevelopments in order to combine strengths andreduce fragmentation of efforts.
In the comingyears, if resources permit, we hope to bring OLD?sglossing UIs, logic for connecting documents toutterances as well as structural search and mor-phological parsing (?5.2) into the LingSync pluginarchitecture, with OLD UIs being used by field lin-guists and LingSync UIs being used by languagecommunity members and computational linguists.When referring collectively to both tools, we willhenceforth use the term LingSync/OLD.4 User adoptionIn the year and a half LingSync?s launch, over 300unique users have registered; this despite the avail-ability of a sample user (username: LingLlama,password: phoneme).
We argue this demonstratesa general interest in novel, even unheard-of, lan-guage documentation software, despite the exist-ing solutions discussed in ?2.2.Table 1 provides an overview of the corpora be-ing edited using the system.
Currently there areabout 13,400 active records, 38 active users, 15 ac-tive corpora, and 1GB of primary audio/image/textdata.
We expect that the low ratio of active vs.registered users (12%) is due to both the multi-task nature of language documentation projectsand early launch of LingSync while it was stillin the alpha testing and the requirements gather-ing phase.
There are currently no published mea-16http://tedlab.mit.edu/?dr/Tgrep2/.28sures of user attrition in language documentationprojects, however social websites/mobile apps de-velopers report 30% retention rate is acceptable.17We will know more about rates for different stake-holders in language documentation projects as theretention rate changes over time in correlation tothe release of new modules.Active Investigating In-active TotalPublic Corpora 2 1 2 5Private Corpora 15 37 321 373Users 38 43 220 301Documents 13,408 2,763 4,541 23,487Disk Size 1GB .9GB 5.3GB 7.2GBTable 1: Data in LingSync corpora (Feb 14, 2014).Active corpora: >300 activities; Investigating cor-pora: 300-10 activities; Active users: >100 activi-ties; Investigating users: 100-10 activities.There are currently nine language-specific OLDapplications in use.
In total, there are about 19,000records (primarily sentences), 300 texts, and 20GB of audio files.
There are 180 registered usersacross all applications, of which 98 have enteredand 87 have elicited at least one record.
The ap-plications for Blackfoot, Nata, Gitksan, Okanagan,and Tlingit are seeing the most use.
The exact fig-ures are summarized in Table 2.18language forms texts audio GB speakersBlackfoot (bla) 8,847 171 2,057 3.8 3,350Nata (ntk) 3,219 32 0 0 36,000Gitksan (git) 2,174 6 36 3.5 930Okanagan (oka) 1,798 39 87 0.3 770Tlingit (tli) 1,521 32 107 12 630Plains Cree (crk) 686 10 0 0 260Ktunaxa (kut) 467 33 112 0.2 106Coeur d?Alene (crd) 377 0 199 0.0 2Kwak?wala (kwk) 98 1 1 0.0 585TOTAL 19,187 324 2,599 19.8Table 2: Data in OLD applications (Feb 14, 2014)The data in Table 1 and Table 2 indicate that thesystems are in fact being used by language docu-mentation teams.17There are no official published statistics; however, inanswers on StackOverflow developers report averages to be30%, cf.
http://stackoverflow.com/questions/6969191/what-is-a-good-active-installs-rate-for-a-free-android-app.18Note that the values in the speakers column are takenfrom Ethnologue (http://www.ethnologue.com) and are pro-vided only to give a rough indication of the speaker popu-lations of the languages.
Also, the three-character codes inthe first column are the ISO 639-3 (http://www-01.sil.org/iso639-3) identifiers of the languages.5 Reusing existing tools and librariesBoth the LingSync and the OLD projects werefounded with the goal of making it easier to in-tegrate existing software libraries to better auto-mate data curation (Req.
2) and improve data qual-ity (Req.
4) while doing fieldwork.
There havebeen numerous plugins in both systems to thisend; however in this paper we will discuss onlythose which may be of most interest to compu-tational linguists working on low-resource lan-guages: morphological parsers in ?5.1, ?5.2 and?5.3 (precursors for Information Retrieval andMachine Translation tasks) and phone-level align-ment of audio and text in ?5.4 (a precursor foracoustic model training in Speech Recognitionsystems).5.1 Existing morphological parsersFor one LingSync team working on Inuktitut, aweb service was written which wraps an existingmorphological analyzer for Inuktitut built in Java(Farley, 2012).
This source code can be used towrap other existing language-specific morpholog-ical analyzers.195.2 Novel morphological parsersAn OLD web service provides functionality thatallows users to create any number of morpho-logical parsers.
The phonological mappings ofthese parsers are declared explicitly, using aformalism?context-sensitive (CS) phonologicalrewrite rules (Chomsky and Halle, 1968)?that iswell understood by linguists.
The lexicon, mor-photactic rules, and parse candidate disambigua-tor components are automatically induced fromcorpora specified by the user.
The fact that thisimplementation requires a good deal of explicitspecification by the user should not be consid-ered a demerit.
By granting linguist fieldwork-ers control over the specification of phonologi-cal, lexical, and morphotactic generalizations, theparser functionality allows for the automatic test-ing of these generalizations against large data sets.This assists in the discovery of counterexamples togeneralizations, thereby expediting the improve-ment of models and advancing linguistic research.The OLD morphological parser implementationcan, of course, co-exist with and complement less19All modules discussed in this paper are available bysearching the GitHub organization page https://github.com/opensourcefieldlinguistics29expert-dependent Machine Learning approachesto creating morphological parsers.The core component of an OLD morpholog-ical parser is a morphophonology that is mod-elled as a finite-state transducer (FST)20and whichmaps transcriptions to morphological analyses,i.e., morpheme segmentations, glosses, and cate-gories.
The morphophonology FST is the compo-sition of a phonology FST that is created explicitlyby the user (using CS phonological rewrite rules)and a morphology (i.e., lexicon and morphotac-tic rules) that is induced from corpora constructedby the user, cf.
Beesley and Karttunen (2003) andHulden (2012).
When the morphophonology re-turns multiple parse candidates, the system em-ploys an N -gram language model (LM)21(esti-mated from a corpus specified by the parser?s cre-ator) to determine the most probable parse.Preliminary tests of the OLD morphologicalparser implementation have been performed usingdata from the Blackfoot OLD22and the standardgrammar (Frantz, 1991) and dictionary (Frantzand Russell, 1995) of the language.
An initialparser implemented the phonology specified inFrantz (1991) and defined a morphology with lexi-cal items extracted from Frantz and Russell (1995)and morphotactic rules induced from words ana-lyzed by contributors to the system.
Analysis ofthe performance of this parser (f-score: 0.21) con-firms what researchers (Weber, 2013) have alreadyobserved, namely that the phonological and mor-phological generalizations of Frantz (1991) cannotaccount for the location of morphologically condi-tioned prominence (i.e., pitch accent) in Blackfootwords.An improved Blackfoot parser, i.e., one whichcan predict prominence location based on the gen-eralizations of Weber (2013), is currently underdevelopment.
The phonology of this parser makesuse of a novel and useful feature, viz.
the abil-ity to specify phonological transformations thatare aware of categorial context.
This allows thephonology to capture the distinct nominal and ver-bal prominence location generalizations of Black-foot.Since OLD morphological parsers can be cre-ated and parses retrieved entirely by issuing20FSTs are constructed using the open source finite-statecompiler and C library foma: http://code.google.com/p/foma21OLD N -gram LMs are estimated using MITLM: https://code.google.com/p/mitlm/.22http://bla.onlinelinguisticdatabase.org/RESTful requests, other applications can easilymake use of them.
In addition, OLD morpholog-ical parser objects can be exported as .zip archivesthat contain all of the requisite binaries (i.e., com-piled foma and MITLM files) and a Python mod-ule and executable which together allow for theparser to be used locally via the command line orfrom within a Python program.5.3 Semi-supervised morphological parsersLingSync?s glosser uses a MapReduce functionwhich efficiently indexes and transforms data tocreate a current ?mental lexicon?
of the corpus.The mental lexicon is modelled as a connectedgraph of morphemes, including precedence rela-tions which are used to seed finite-state automata(Cook, 2009)23which represent morphologicaltemplates in the corpus.
In this way the glosseris ?trained?
on the user?s existing segmentationand glossing, and automatically ?learns?
as theuser adds more data and the glossing/segmentationevolves over the course of data collection andanalysis.
LingSync has a lexicon browser com-ponent which permits users to browse the corpusvia learned relations between morphemes, cleanthe data for consistency, enter novel data, and ex-plicitly document generalizations on lexical nodeswhich might not be immediately evident in theprimary data.
Unlike FLEx (Black and Simons,2006), the OLD, and WeSay, LingSync does notprovide a way to explicit add rules/relations ormorphemes which are not gleaned from the data.To add a morpheme or a relation users must addan example sentence to the corpus.
This ground-ing of morphemes and rules/relations provides ar-guably better learning tools as collocation dic-tionaries and lexicon creators are always able toprovide headwords and grammatical rules in con-text and researchers working on relations betweenmorphemes are able to extract lists of relevantdata.5.4 Audio-transcription alignmentThere are currently three audio web services.The first executes Sphinx speech recognition rou-tines for languages with known language mod-els.
The second, illustrated in Figure 2a, uses23One reviewer requests more details which have not yetbeen published: in the interim please consult the code whichis entirely open source and commented:https://github.com/OpenSourceFieldlinguistics/FieldDBGlosser30Figure 1: Screenshot of the Lexicon Browser, aweb widget which lets users browse relations be-tween morphemes in their corpus, clean and adddeclarative knowledge not found in the lexicontraining process.the Prosodylab-Aligner24tool (developed at theMcGill Prosody Lab) to significantly automatethe association of transcriptions to relevant audioclips and therefore help to provide a class of datathat will prove valuable in applications such astalking dictionaries and language learning tools.The third, illustrated in Figure 2b, is a servicethat wraps FFmpeg25and Praat26to convert anyvideo or audio format to .mp3 and automaticallygenerate syllable timings and suggested utteranceboundaries (De Jong and Wempe, 2009) for auto-matic chunking of data.a) $ curl --cookie my-cookies.txt\--request POST\-F files[]=@omi_imitaa.mov\-F files[]=@omi_imitaa.lab\https://api.lingsync.org/v2/corpora/public-curldemo/utterances?process=alignb) $ curl --cookie my-cookies.txt\--request POST\-F files[]=@omi_imitaa.mov\https://api.lingsync.org/v2/corpora/public-curldemo/utterances?process=detectc) $ curl --cookie my-cookies.txt\--request GET\https://api.lingsync.org/v2/corpora/public-curldemo/files/omi_imitaa.mp3d) $ curl --cookie my-cookies.txt\--request GET\https://api.lingsync.org/v2/corpora/public-curldemo/files/omi_imitaa.TextGridFigure 2: Audio/video and text alignment viaProsodylab-Aligner web service (a), detecting ut-terances and syllable timing from audio/videofiles (b), retrieving web playable audio (c), andTextGrid results (d).24https://github.com/kylebgorman/Prosodylab-Aligner25http://www.ffmpeg.org/26http://www.praat.org/Figure 3: Screenshot of the utterance extractionprocess which converts any audio/video into utter-ance intervals encoded either as JSON or TextGridusing the PraatTextGridJS library.6 Using LingSync/OLDCurrent notable results of the LingSync/OLDproject include Kartuli Glasses for Facebook (atransliterator from the Latin alphabet to the Kar-tuli alphabet),27Georgian Together for Android (alanguage learning app),28and Kartuli Speech Rec-ognizer for Android.29These apps were developedin collaboration with Kartuli speakers and Kartulisoftware developers in Batumi, Georgia during theSpring 2014 semester.Field linguists interested in a more detailed fea-ture breakdown of LingSync and the OLD areencouraged to consult Cathcart et al.
(2012) andDunham (2014), respectively.
Additional detailson LingSync?which may be useful to those in-terested in developing tools with language com-munities or to computational linguists interestedin contributing to the project?can be found in theLingSync WhitePaper (LingSync, 2012).7 ConclusionIn this paper we hope to have illuminated some ofthe complexity involved in building software forendangered language documentation which has re-sulted in software fragmentation.
We have pre-sented LingSync/OLD, an open-ended plugin ar-chitecture which puts Software Engineering bestpractices and our collective experience in the lan-guage technology industry to use to address thisfragmentation.
The LingSync/OLD project hasworked in an iterative fashion, beginning with UIs27Chrome Store https://chrome.google.com/webstore/detail/kartuli-glasses/ccmledaklimnhjchkcgideafpglhejja28Android Store https://play.google.com/store/apps/details?id=com.github.opensourcefieldlinguistics.fielddb.lessons.georgian29Android Store https://play.google.com/store/apps/details?id=com.github.opensourcefieldlinguistics.fielddb.speech.kartuli31for field linguists in 2012-2013 and UIs for com-munity members, and software libraries and train-ing for software developers in 2013-2014.
Userstudies and the dissemination of potentially novellanguage documentation and/or computational lin-guistics contributions are expected in 2014-2015and in the future as the project continues to iterate.For technical updates, interested readers may viewthe project?s completed milestones;30for user-facing updates, readers may visit LingSync.organd OnlineLinguisticDatabase.org.AcknowledgementsWe would like to express our deep thanks to TobinSkinner, Elise McClay, Louisa Bielig, MaryEllenCathcart, Theresa Deering, Yuliya Manyakina,Gretchen McCulloch, Hisako Noguchi, Brian Do-herty, Gay Hazan, Oriana Kilbourn, Kim DanNguyen, Rakshit Majithiya, Mietta Lennes, Nivjade Jong, Ton Wempe, Kyle Gorman, CurtisMesher, Beso Beridze, Tornike Lasuridze, ZviadiBeradze, Rezo Turmanidze, Jason Smith, MartinGausby, Pablo Duboue, Xianli Sun, James Crip-pen, Patrick Littell, Michael McAuliffe as wellas countless other linguistics students, computerscience students and open source software de-velopers who directly or indirectly helped buildLingSync/OLD to what it is today and will bein the future.
We would like to thank the Com-putEL workshop reviewers, LingSync/OLD usersand would-be users for providing feedback, sug-gestions, asking tough questions, and sending bugreports, all of which have been instrumental to theproject?s success and helped drive the its devel-opment.
We would like to thank Faryal Abbassi,Farah Abbasi, Tamilla Paghava, Esma Chkhik-vadze, Nina Gatenadze, and Mari Mgeladze fortheir friendship, patience and for sharing their lan-guage with us.
Finally, we would like to thankJessica Coon, Alan Bale and Michael Wagner fortheir guidance and challenging us to keep theuser interfaces simple and yet flexible, as well asSSHRC Connection Grant (#611-2012-0001) andSSHRC Standard Research Grant (#410-2011-2401) which advocates open source approaches toknowledge mobilization and partially funded thestudents who have doubled as fieldwork researchassistants and interns on the project.
All errors andoversights are naturally our own.30https://github.com/OpenSourceFieldlinguistics/FieldDB/issues/milestones?state=closedReferencesDorothee Beermann and Pavel Mihaylov.
2012.
Type-Craft collaborative databasing and resource sharingfor linguists.
Language Resources and Evaluation,pages 1?23.Kenneth R Beesley and Lauri Karttunen.
2003.
Finite-state morphology: Xerox tools and techniques.CSLI, Stanford.H.
Andrew Black and Gary F. Simons.
2006.
The SILFieldWorks Language Explorer approach to mor-phological parsing.
In Computational Linguisticsfor Less-studied Languages: Proceedings of TexasLinguistics Society, Austin, TX.Lynnika Butler and Heather van Volkinburg.
2007.Review of FieldWorks Language Explorer (FLEx).Language Documentation & Conservation,1(1):100?106.MaryEllen Cathcart, Gina Cook, Theresa Deer-ing, Yuliya Manyakina, Gretchen McCulloch, andHisako Noguchi.
2012.
LingSync: A free tool forcreating and maintaining a shared database for com-munities, linguists and language learners.
In RobertHenderson and Pablo Pablo, editors, Proceedingsof FAMLi II: workshop on Corpus Approaches toMayan Linguistics 2012, pages 247?250.N.
Chomsky and M. Halle.
1968.
The Sound Patternof English.
Harper & Row, New York.Jonathon E. Cihlar.
2008.
Database development forlanguage documentation: A case study in the Washolanguage.
Master?s thesis, University of Chicago.Gina Cook.
2009.
Morphological parsing of Inukti-tut.
Ms, Concordia University, Faculty of Engineer-ing and Computer Science.David Costa.
2012.
Surveying the sources on theMyaamia language.
In Proceedings of the 2012Myaamiaki Conference.N.H.
De Jong and T Wempe.
2009.
Praat script todetect syllable nuclei and measure speech rate auto-matically.
Behavior research methods, 41(2):385?390.Joel Dunham.
2014.
Online Linguistic Databasedocumentation.
http://online-linguistic-database.readthedocs.org, March.Benoit Farley.
2012.
The Uqailaut project.
http://www.inuktitutcomputing.ca, January.Scott Farrar.
2010. Review of TypeCraft.
LanguageDocumentation & Conservation, 4:60?65.Donald G. Frantz and Norma Jean Russell.
1995.Blackfoot Dictionary of Stems, Roots, and Affixes.Toronto: University of Toronto Press.Donald G. Frantz.
1991.
Blackfoot Grammar.Toronto: University of Toronto Press.32Andrew Garrett, Juliette Blevins, Lisa Conathan,Anna Jurgensen, Herman Leung, Adrienne Mamin,Rachel Maxson, Yoram Meroz, Mary Paster,Alysoun Quinby, William Richard, Ruth Rouvier,Kevin Ryan, and Tess Woo.
2001.
The Yuroklanguage project.
http://linguistics.berkeley.edu/?yurok/index.php, January.Andrew Garrett, Susan Gehr, Line Mikkelsen, NicholasBaier, Kayla Carpenter, Erin Donnelly, MatthewFaytak, Kelsey Neely, Melanie Redeye, Clare Sandy,Tammy Stark, Shane Bilowitz, Anna Currey, KourosFalati, Nina Gliozzo, Morgan Jacobs, Erik Maier,Karie Moorman, Olga Pipko, Jeff Spingeld, andWhitney White.
2009.
Karuk dictionary andtexts.
http://linguistics.berkeley.edu/?karuk/links.php, January.Jeff Good.
2012a.
?Community?
collabo-ration in Africa: Experiences from northwestCameroon.
Language Documentation and Descrip-tion, 11(1):28?58.Jeff Good.
2012b.
Valuing technology: Finding thelinguist?s place in a new technological universe.
InLouanna Furbee and Lenore Grenoble, editors, Lan-guage documentation: Practice and values, pages111?131.
Benjamins, Amsterdam.K David Harrison.
2007.
When Languages Die: TheExtinction of the World?s Languages and the Erosionof Human Knowledge.
Oxford University Press.M.
Hulden.
2012. foma: finite state compiler and Clibrary (documentation).
https://code.google.com/p/foma/w/list.George Ironstrack.
2012.
Miloniteeheetaawi eehinkipimihkanaweeyankwi: Let?s reflect on how far wehave traveled.
In Proceedings of the 2012 Myaami-aki Conference.Wesley Leonard.
2012.
Your language isn?t extinct:the role of Myaamia in Language Reclamation.
InProceedings of the 2012 Myaamiaki Conference.LingSync.
2012.
WhitePaper.
http://OpenSourceFieldlinguistics.github.io/FieldDB/,January.Stuart Robinson, Greg Aumann, and Steven Bird.2007.
Managing fieldwork data with ToolBox andthe Natural Language Toolkit.
Language Documen-tation & Conservation, 1(1):44?57.Chris Rogers.
2010. Review of FieldWorks LanguageExplorer (FLEx) 3.0.
Language Documentationa-tion & Conservation, 4:78?84.R.
Schroeter and N. Thieberger.
2006.
EOPAS, theEthnoER online representation of interlinear text.In Sebastian Nordoff, editor, Sustainable Data fromDigital Fieldwork.
University of Sydney, Sydney.SIL International.
2013.
Technical Notes onFieldWorks Send/Receive.
http://fieldworks.sil.org/wp-content/TechnicalDocs/, November.Nick Thieberger.
2012.
Using language documen-tation data in a broader context.
In Frank Seifart,Geoffrey Haig, Nikolaus P. Himmelmann, DagmarJung, Anna Margetts, and Paul Trilsbeek, editors,Potentials of Language Documentation: Methods,Analyses, and Utilization.
University of Hawai?iPress, Honolulu.Doug Troy and Andrew J. Strack.
2014.
Meti-mankwiki kimeh?soominaanaki - we follow our an-cestors trail: Sharing historical Myaamia languagedocuments across myaamionki.
In Proceedings ofthe 2014 Myaamiaki Conference.N.
Weber.
2013.
Accent and prosody in Blackfootverbs.
http://www.academia.edu/4250143/Accentand prosody in Blackfoot verbs.Alan Yu, Ryan Bochnak, Katie Franich,?Ozge Sarigul,Peter Snyder, Christina Weaver, Juan Bueno-Holle,Matt Faytak, Eric Morley, and Alice Rhomieux.2005.
The Washo project.
http://washo.uchicago.edu/dictionary/dictionary.php, January.Alan Yu, Ryan Bochnak, Katie Franich,?Ozge Sarigul,Peter Snyder, Christina Weaver, Juan Bueno-Holle,Matt Faytak, Eric Morley, and Alice Rhomieux.2008.
The Washo mobile lexicon.
http://washo.uchicago.edu/mobile/, January.33
