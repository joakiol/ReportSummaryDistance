Toward Natural Language Computation 1Alan  W.  B ie rmannBruce  W.  Bal lard2Depar tment  of Computer  ScienceDuke UniversityDurham, North Carolina 27706A computer programming system called the "Natural Language Computer" (NLC) isdescribed which allows a user to type English commands while watching them executed onsample data appearing on a display screen.
Direct visual feedback enables the user todetect most misinterpretation errors as they are made so that incorrect or ambiguouscommands can be retyped or clarified immediately.
A sequence of correctly executedcommands may be given a name and used as a subroutine, thus extending the set ofavailable operations and allowing larger English-language programs to be constructedhierarchically.
In addition to discussing the transition network syntax and proceduralsemantics of the system, special attention is devoted to the following topics: the nature ofimperative sentences in the matrix domain; the processing of non-trivial noun phrases;conjunction; pronominals; and programming constructs such as "if", "repeat", and proce-dure definition.1.
IntroductionNatural language programming has been proposedby many authors (Balzer\[2\], Green\[13\], Heidorn\[17\],Petrick\[25\], Sammet\[27\], Woods\[38\]) as the best wayfor humans to input their commands to computers.Humans have developed exquisitely efficient abilitiesfor communicating with each other through naturallanguage, and the possibility of similarly interactingwith maclaines is worthy of investigation.
The abilityto program in natural language instead of traditionalprogramming languages would enable people to usefamiliar constructs in expressing their requests, thusmaking machines accessible to a wider user group.Automatic speech recognition and synthesis devicescould eventually smooth the communication even fur-ther.On the other hand, many problems could arisewhen natural language programming is attempted(Dijkstra\[11\], Petrick\[25\], Simmons\[32\]),  and anysuch research must deal with them.
For example, ithas been argued that current natural language technol-1 This material is based upon work supported by the NationalScience Foundation under Grant Numbers MCS74-14445-A01 andMCS-7904120.2 Current address: Department of Computer and InformationScience, The Ohio State University, Columbus, Ohio 43210.ogy is too primitive to handle a wide variety of syntac-tic and semantic constructs o that the user of such asystem has the difficult task of learning what consti-tutes an acceptable input to the system.
Instead ofhaving to learn the relatively simple syntax of a clearlydefined programming language, the user would beforced to learn a voluminous and very detailed set ofrules giving what words and phrases can be used andhow they can be combined.
Thus the user would betaxed more heavily with a natural language systemthan with a traditional system.
A second argumentagainst natural language programming relates to itsintrinsic vagueness and ambiguity.
It is maintainedthat if one wishes to manipulate information preciselyand reliably within a machine, a clearly defined andunambiguous language should be used.
The program-mer should not have to wonder about the meaning of aparticular input to the system; he or she should knowthe meaning or be able to look it up easily in a manu-al.
A third argument asserts that no one would use anatural language programming system, even if oneexisted, because it would be too verbose.
Why shouldone be willing to input long and wordy descriptions ofa desired computation when there exist simple, easy-to-learn, and concise notations for doing the samething?Copyright 1980 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial dvantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/80/020071-16501.00American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 71Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation1.1 A Natural Language ComputerFormidable as these criticisms may seem, this paperwill attempt o show that some of them can be over-come with a careful system design, while others maybe simply wrong.
This paper describes a system,called the Natural Language Computer (NLC),  whichmakes it possible to perform a limited amount of natu-ral language programming.
This system enables aperson to sit at a computer display terminal, observehis or her data structures on the screen, and watch thecomputation proceed as the individual commands aretyped.
The current implementation is specifically de-signed for array and matrix computation.
In the ex-ample interaction of Figure 1, the user is creating asubroutine to add up the rows and columns of an arbi-trary matrix.
Each item that is modified by a com-mand is marked with an asterisk and other items usedin the calculation are marked with an apostrophe.
Thefirst two commands cause two matrices to appear onthe screen, one to be operated on and the other toreceive the answer.
The third command provides somesample data for the calculation and the fourth com-mand indicates that the imperative verb "sumcolrow"is about to be defined.
Subsequent inputs tell exactlywhat operations must be done to sumcolrow a matrixinto another matrix.
For example, if after this dia-logue the system receives the input"Sumcolrow matrix A1 into matrix Z.
"where A1 and Z are matrices of appropriate dimen-sions, the procedure body following the define state-ment will be executed.
Thus the dialogue causes thesystem to create a subroutine to be called by using thenewly defined imperative verb "sumcolrow".This process is explained in greater detail in latersections of the paper.
The important point to be no-ticed here is that the user is able to watch the systemrespond to each command as it is entered.
Wheneverthe system yields an undesired action, the user canback up and rephrase his or her command more clear-ly.
This format for natural language programmingenables users to examine system performance as eachcommand is typed and to detect most errors immedi-ately.1.2 Concerning the ObjectionsGiven this brief introduction to the NLC user inter-face, it is already possible to respond to the first criti-cism of natural language programming iven above.Although we feel that present day natural languageprocessors tend to have very limited capabilities, it isquite possible within the NLC environment o directthe user to restrict the inputs appropriately.
For thisreason, the user is asked to follow two simple ruleswhich are easily understood from the user's point of"D isp lay  a 3 byTestmatI 2I 0 02 0 03 0 0"D isp lay  a 3 byTestmatII 02 03 0"F i l l  tes tmatTestmatII I*2 2*3 4*"Def ine  a wayans.
"3 matr ix .
Ca l l  it tes tmat .
"30002 matr ix .
Ca l l  it  ans .
"ans3 I0 0 I 00 0 2 00 0 3 0w i th  random numbers .
"ans2 34* -7*  13* I* 22* 2* 3to sumco l row tes tmat  into"Add each co lumn in tes tmat  toco lumn I in ans.
"tes tmat  ansI' 2' 3' I*I I' 4' -7' I -2*2 2' 3' I' 2 6*3 4' 2' 2' 3 8*"Add each row in tes tmat  toco lumn 2 of ans.
"tes tmat  ansI 2 3 II' I' 4' -7' I -22' 2' 3' I' 2 63' 4' 2' 2' 3 8"End the de f in i t ion .
"20002*7*9*-4*Figure 1.
Defining the verb "sumcolrow".view and which simultaneously ease the job of thesystem designers and implementers considerably.The first rule concerns the semantics of inputs:(1) The user may refer only to the data struc-tures seen on the terminal screen and specifysimple operations upon them.That is, the user may refer to matrices, rows, columns,entries, labels, numbers, variables, etc., and specifysimple operations such as add, subtract, move, ex-change, delete, label, etc.
The user may not use do-main specific vocabulary or concepts such as airplaneflights, seats, passengers, and reservations.
This rule iseasily explained to a user and makes it possible tobuild a system without getting into the peculiarities ofany specific domain.
Although it requires the user totranslate his or her problem into the vocabulary of the72 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationsystem, it also makes it possible to experiment withthe system in many different domains.The second rule concerns the syntax of the inputs:(2) The user must begin each sentence with animperative verb.This rule is also easy to explain to the user and it alsogreatly restricts the variety of sentences to be proc-essed.
If this rule is followed, the system can find outmuch about each clause from its first word, includingwhat words or concepts may occur later in the clause.In summary, the strategy for achieving person-to-machine language compatibility taken here is (1) tofind a small number of simple rules which a person caneasily follow to restrict he set of inputs; and then (2)to stretch the language processing technology to thepoint where it can reasonably cover that set.
Whenthis is done, the first criticism of natural languageprogramming stated earlier is overcome.The other major objections to natural languageprogramming relate to its vagueness, ambiguity, andalleged verbosity.
Perspectives on these issues can beachieved by examining some examples of natural an-guage and the corresponding programs in traditionalprogramming languages.
Consider for example thecommand"Square the sixth positive entry in matrix M."Vagueness does not appear to be a problem with theEnglish of this example.
In fact, the sentence is prob-ably shorter than most equivalent formulations writtenin traditional programming languages.
The corre-sponding code in almost any programming languagewill require some declarations and a nesting of loopingand branching constructs.
As an additional example,the reader should examine the English language pro-gram and its corresponding PL/ I  counterpart which isincluded in the Appendix.
Our experience so far withEnglish language programming seems to indicate thatthe language is as precise as its user wants it to be.Concerning the length of English language programs,they seem to be comparable to the length of ordinaryprograms in the domains we have examined.
Ofcourse, one could write down a complicated arithmeticexpression from some standard programming languageand note that its English equivalent is relatively long,unreadable, and unwieldy.
The solution to this prob-lem is to include in the natural anguage processor theability to handle such arithmetic expressions.
Consid-ering the complexity of any reasonable natural lan-guage processor, the cost of adding something like anarithmetic expression handler is modest.
Other con-structs from programming languages which are shownto be convenient could also be considered for inclu-sion.1.3 BackgroundThe NLC system has grown out of an earlier seriesof studies on the "autoprogrammer" (Biermann\[6\])and bears much resemblance to it.
Program synthesisin both the current and the previous systems is basedupon example calculations done by the user on dis-played data structures.
In the current system, theexample is done in restricted English with all its pow-er, which is a dramatic departure from the earlier ap-proach, which simply involved pointing with a lightpen.
However, it is expected that many of the fea-tures from the autoprogrammer, such as "continue"and "automatic indexing", will transfer quite naturallyinto NLC.
This paper emphasizes the natural lan-guage aspects of the system, while other reports dealwith some of the additional automatic programmingfeatures.
The relationship of NLC to other research innatural anguage processing is discussed in a later sec-tion.The next section presents an overview of NLC,after which subsequent sections discuss scanning, syn-tactic and semantic processing, and interpretation ofcommands in the "matrix computer".
The next twosections discuss the processing of flow-of-control com-mands and the level of behavior achieved by the sys-tem.
The final sections include a discussion of relatedresearch and conclusions.2.
System Overv iewThe NLC system is organized as shown in Figure 2,with the user input passing through the conventionalsequence of stages: lexical, syntactic, and semanticprocessing.
The scanner finds the tokens in the inputsentence and looks them up in the dictionary.
It per-forms some morphological processing and spellingcorrection for items not appearing in the dictionary.Additionally, abbreviations (such as "col" for"column") and spelled-out numbers and ordinals("twenty-two", "seventh", etc.)
are recognized.
Theidentified words with their meanings are passed on tothe parser, which is programmed with nondeterministictransition nets similar to the augmented transitionnetworks of Woods\[40\].
The parser has the ability toscreen out many syntactically correct but semanticallymeaningless structures o that the first parse it finds isusually correct.
The parser output goes to the flow-of-control semantics routines which make decisionsabout the nature of the input command and then prop-erly guide it through subsequent processing.The input sentence may be a simple request for asystem defined computation or it may be a flow-of-control command such as a user-defined subroutinecall.
An example of the first case is "Add row 1 torow 2."
Here flow-of-control processing sends thesentence directly to the sentence semantics routineswhich resolve the noun groups and invoke the matrixAmerican Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 73Alan W. Biermann and Bruce W. Ballsrd Toward Natural Language ComputationDic t ionaryGrammarProceduresInput"'iiVSCANNERiiVPARSERIiiV.
.
.
.
.
User -Def ined  Names.
.
.
.
.
Parse  TreesContextData  Wor ldFLOW-OF-CONTROL < .
.
.
.
> SENTENCESEMANTICS  SEMANTICSIIVMATRIX  .
.
.
.
.COMPUTERiiVOutput  to  D isp layFigure 2.
The NLC system modules (upper case) and their associated data structures (lower case).computer to perform the indicated operation.
Anexample of the second case is a command beginningwith a user-defined verb such as "sumcolrow".
Heref low-of-control processing brings in from a file the setof commands for the subroutine which defines theword "sumcolrow".
Then those commands, with par-ameters properly instant iated,  are sequentially trans-ferred to sentence semantics for execution.The major task of the sentence semantics routinesis the processing of noun groups.
They begin with thehead noun in any particular noun group and build arepresentation for the meaning of the noun group bysequentially processing whatever modifying words andphrases there may be.
These routines are concernedwith qualifying relative clauses, prepositional phrases,adjective s , ordinals, pronouns, and numerous otherconstructions appearing in noun groups.
The result ofnoun group processing is usually a designation of anitem or set of items in the displayed data structures tobe manipulated by the matrix computer.Most imperative verbs such as "double" or !
'add"pass through the system without change until theyreach the matrix computer.
This routine then per-forms the indicated operation on the data specified bythe processed noun groups.
All changes in the datastructures are immediately updated on the displayscreen, along with markers to show the user where thechanges have been made.
A few imperative verbs arenot processed by the matrix computer.
Some examplesare "f ind" or "choose",  which are processed by thesentence semantics module, and " repeat"  or user-defined imperatives, which are processed by f low-of-control semantics.Every effort has been made to modularize the sys-tem for understandabil ity and easy modification.
Inaddition, the design attempts to use limited computerresources economically.
It is written in the C languageand runs on a PDP-11/70  under the UNIX  operatingsystem.3.
The  ScannerThe scanner collects the string of tokens from theinput and identifies them as well as possible.
Thesetokens may be numbers or ordinals in various forms,names known to the system, punctuation, or dictionarywords which may be abbreviated or misspelled in aminor way.
The scanner outputs a set of alternativedefinitions for each incoming token, and the syntaxstage attempts to select the intended meaning for eachone.Each dictionary entry consists of a set of pairs offeatures.
Two examples appear in Figure 3, the defi-nitions of the word "zero" as an imperative verb andas an adjective.
"Zero"  as a verb takes one argument74 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationand no particle (type OPS1).
The meaning of an im-perative verb is built into the execution code of thematrix computer as explained in Section 6.
As anadjective, the meaning of "zero" is embedded in thesemantics code described in Section 5.
That code willexecute a routine associated with the name in theAMEANS field, zero.I.
(QUOTE zero)(PART IMPERATIVE)( IMPERTYPE OPS l )2.
(QUOTE zero)(PART ADJ )(AMEANS zero)Figure 3.
Two sample dictionary entries.Figure 4 shows the output from the scanner for anexample input sentence.
Associated with each token isthe set of alternate definitions proposed by the systemand the syntax stage will attempt o make appropriatechoices such that the sentence is meaningful.
Mosttokens are found in the dictionary, but the string"thee" is not.
So dictionary entries are selected bythe spelling corrector which are similar to the un-known.
The token "y"  is also not found in the dic-tionary but is recognized as the name of an existingmatrix entity.
The words "zero" and "to" appear inthe dictionary with multiple meanings.WORDAddYtotheezeroent r iesFigure 4.INTERPRETAT ION ( S )add  - verby - p ropnameto  - verb ic leto  - p repthee  - p ropnamethe  - a r tthem - p ronthen  - e tcthere  - e tcthese  - p ronthese  - a r tth ree  - numzero  - verbzero  - ad jzero  - nument r ies  - noun- punctuat ion"Add y to  thee  zero  ent r ies .
"Scanner output for a sample sentence giving alternateinterpretations for each word.4.
SyntaxMost of the sentences processed by the system canbe thought of as imperative verbs with their associatedoperands.
For example, the sentence"Add the first and last positive entries inrow 1 and the second to smallest entry inthe matrix to each entry in the last row.
"exhibits the overall form(add x to y)where x is the noun group "the first and last ... in thematrix" and y is "each entry in the last row".
Thesystem separately processes constructions related tothe imperative verbs and those related to noun groups.The following two sections discuss these types of con-structions.
Then, Section 4.3 describes a method forrejecting certain kinds of syntactically correct but se-mantically unacceptable parses, Section 4.4 describesour approach to hand.ling syntactic ambiguity, andSection 4.5 gives the form of the output for the parser.4.1 Imperat ives And Their OperandsA transition net for processing the above impera-tive form for "add" is shown in Figure 5.
The wordPARSE means to call routines appropriate for parsingthe indicated construct.
IMPERATIVE  refers to theimperative verb, and NG refers to the noun group.VERBICLE  refers to a particular type of prepositionwhich is often associated with an imperative verb todistinguish its operands.
Thus in the sentences"Multiply x by y.
""Store x in y.
"the words "by"  and "in" are verbicles.
Of course, anygiven imperative will have only a few acceptable verbi-cles, so the parser checks that a suitable one is found.STARTPARSE IMPERATIVEPARSE NGPARSE VERBICLEPARSE NGPARSE " "SUCCEEDFigure 5.
A top-level parser for sentences of the form"add X to Y".American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 75Alan W. Biermann and Bruce W. Ballsrd Toward Natural Language Computat ion4.1.1 Conjunction HandlingAlthough the routine of Figure 5 might be adequatefor a large fraction of the sentences received by NLC,we decided to formulate a facility for handling a widevariety of conjunctions \[33\].
Toward this goal, a rou-tine called MIX was designed as shown in Figure 6.STARTIvPARSEIIIIv- - ->PARSEI II vPARSE AIv.
.
.
.
.
> SUCCEEDA .
.
.
.
.
> PARSE " ,"^ lI IPARSE AIv"and"  <- -PARSE ", "Figure 6.
A simplified transit ion etwork for MIX A.Suppose A is a given construct and suppose x l ,  x2,and x3 are instances of that construct.
Then MIX Awill process forms such asxlxl  and x2x l ,  x2, and x3xl  and x2 and x3and others.
If, for example, A represents the impera-tive clause construct, then MIX A will process"Add y l  to y2, add y3 to y4, and add y5 to y6.
"If A is the unconjoined noun group, then MIX A willprocess"row 1, row 2, and row 3.
"Figure 7 shows how a series of calls of the MIX rou-tine can be used to process reasonably complex nest-ings of conjunctions.
For example, these routines willparse the sentence"Add y l  to y2, to y3, and to y4and y5 to y6and add y7 to y8.
"4.1.2 Other Sentence FormsOf course, not all verbs take two operands and averbicle as in the examples above.
Indeed, verbs suchas "call" have two operands without a verbicle:"Call the matrix x."
(Call y l  y2.
)There are also one-operand verbs which take a parti-cle, such as "add up".
Particles present a specialproblem since they can appear in various positions inthe sentence; NLC handles most of the commonplacements.
Many one-operand verbs appear withoutparticles as in"Double row 1."
(Double y l .
)and there are verbs that take no operand: either witha particle, as in"Back up.
"or without a particle, as in"Quit.
"Most of the imperatives handled by NLC fall intoone or more of the six categories listed above: zero,one, or two operands, with or without averbicle/particle.
The conjunction handling describedabove extends to all of these types o f  imperatives in anatural way.
Although NLC has facilities for accept-ing imperatives with more than two operands or withformats other than those given here, a large proportionof all imperatives in our domain do fit into the simplescheme given here.4.2 Noun Group SyntaxFour types of noun groups appear in the sentencesprocessed by NLC.
The most common type refers tothe entities on the NLC display screen: numbers,entries, rows, matrices and so forth.
These are thenoun groups that appear as operands for the impera-tive verbs.
Many examples appear in previous sec-tions.
The second type of noun group is the nounSTART STARTI IMIX $I PARSE IMPERATIVEI IPARSE ". "
M IX  NGVNGI ISUCCEED SUCCEED(a) Top  leve l  (b) C lause  leve lrout ine  S rout ine  $I .START STARTI IPARSE NG PARSE VERBICLEI iMIX VNG PARSE NGI ISUCCEED SUCCEED(C) Noun-verb ic le -  (d) Verb ic le -nounnoun leve l  leve l  rout ine  VNGrout ine  NGVNGFigure 7.
A sentence parser allowing nested conjunctions.76 American Journal of Computational Linguistics, Volume 6, Number 2, Apri l- June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationresult group, which refers to the result of a computa-tion.
Some examples are "the sum of rows 1 and 2"and "the absolute value of x" where in each case theobject being referred to appears not on the screen butis found by manipulating displayed objects.
The thirdtype of noun group is the noun place group, as illus-trated by "bottom" in"Add the second from bottom row to row 3.
""Bottom" in this example is the place from which theordinal processor begins counting.
Some other wordsthat can fit into this slot are "right", " left", "top",and "last".
The fourth type of noun group is the nounprocedure group, which refers to a procedure, a com-mand, or a set of commands in the NLC input.
Thistype is illustrated in"Repeat he last three commands ten times.
""Double the entries the third commandincremented.
"Only the operand noun groups will be discussed indetail here.Operand level noun groups follow a format similarto the one given by Winograd\[37\].
Let OPT be aroutine which optionally calls a set of routines.
As anillustration, OPT DETERMINER calls routines toparse a determiner.
If those routines fail, however,OPT succeeds anyway, assuming that the noun groupexists without a determiner.
The basic format for theoperand level noun group parser, given in Figure 8, iscompletely exercised by the noun group"the first three positive matrix 1 entrieswhich are odd"DETERMINER:  theORDINAL: firstNUMBER: threeADJECTIVE: positiveCLASSIFIER: matrix 1NOUN: entriesQUALIFIER: which are oddSince OPT is used to look for most of the constituents,the parser analyzes noun groups with those elementsmissing.
(Examples: "the positive entries", "sevennumbers greater than 10", "the smallest entry", etc.
)Constructs of the form "row 1", "columns 2 and 3",or "the constant 4.5" require separate recognition.The DETERMINER routine parses not only thesimple determiners "the" and "a /an"  but also a varie-ty of quantifiers such as "all", "all of the", "both","no more than six of the", "exact ly  two of the", andmany others.
The ORDINAL routine processes thecommon ordinals "f irst", "second",  "next" ,  and"last", which can also appear with superlatives("second greatest") or with modifiers ("second fromright", "second from last").STARTvOPT DETERMINERVOPT ORDINALVOPT NUMBERV.
.
.
.
> OPT  ADJECT IVEIV.
.
.
.
> OPT  CLASS IF IERI IVPARSE NOUNIV.
.
.
.
> OPT  QUAL IF IERI IVSUCCEEDFigure 8.
A Winograd-style noun phrase parser.Six types of qualifiers are handled by NLC:1.
Preposition groups:"the rows IN MATRIX 2"2.
Adjective groups:"the numbers LARGER THAN 6"3.
Relative clauses:"the rows WHICH CONTAINNEGATIVE NUMBERS"4.
ED groups:"the entries ADDED""the entries ADDED TO""the entries ADDED TO ROW 4""the entries ADDED BY THE LASTCOMMAND"5.
ING groups:"the columns CONTAINING 5.5"6.
Rank-shifted clauses:"the entries COLUMN 2 CONTAINS"Many types of conjoined phrases are processedusing the MIX routine as in "the first and last en-tries", "the first two and last three entries", "the firsttwo and the last three entries", and others.
Noungroups may be nested within other noun groups asillustrated inAmerican Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 77Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation"the largest entryin the first rowof the matrixcontaining the columnthat was doubled by the second to lastcommand"4.3 Semantic Checking During Syntactic ProcessingIf the parser is provided with some informationabout the types of nouns and the relationships theymay have with each other, it can reject inappropriateparses.
As an illustration, in the following phrase apossible parse of the qualifiers is as indicated by theparentheses.the entry (in row 2 (in column 3) )That is, row 2 is "in" column 3 and the entry beingreferred to is in that row 2.
However, in an ordinarymatrix it is not possible for a row to be contained in acolumn and so it is desirable that this parse be reject-ed.
The correct parse will be found if it is known thatrow-in-column is a disallowed pattern, forcing "row 2"to stand alone as a noun group:the entry (in row 2) (in column 3)Thus both the qualifiers "in row 2" and "in column 3"modify the noun "entry" .
Since entry-in-row andentry-in-column are semantically acceptable patterns,this parse can be passed to the semantics processor.Observations of this type lead to the concept ofsemantically acceptable patterns and a mechanism forchecking for them.
A hash-coded table was added toNLC which contains the set of all semantically accept-able patterns for certain constructions.
At varioustimes during the processing, checks are made to seethat a sensible parse is being assembled.
Besideschecking for compatibility in prepositional modifiers asindicated above, the system tests relationships givenby relative clauses and adjective groups.
It alsochecks that the operands of imperative verbs are legiti-mate.4.4 Syntactic AmbiguityThe strategy for dealing with syntactic ambiguity isto attempt to anticipate the situations in which it ismost likely to arise and to decide, whenever possible,which alternative is most reasonable.
Having madesuch decisions, it is usually possible to order the gram-mar rules in such a way that the preferred parse is theone arrived at first, thus combining the efficiency of ablind search with the accuracy of a more extensiveone.
Perhaps surprisingly, the method has provenquite successful in meeting the stated objectives.
(See\[5\].)
This is due in part to the formulation of severalgeneral principles stemming from our observations ofhow natural anguage is employed in the NLC domain.The most important of these are:1.
Deep parses are generally preferred.
Thus,"x in y in z"more often attaches the qualifier "in z" with ythan with x when both readings are meaningful.2.
When ambiguity arises because of a conjunction,the intended conjuncts are likely to have similartype.
This contrasts sharply with conventionalprogramming languages, where operators ratherthan operands determine the "binding" in arith-metic expressions uch as "a + b * c".
Thepreference for conjoining similar units is auto-matically supplied by using the MIX routinedescribed earlier.3.
Compatibility checks based on semantic relation-ships should be checked during the parse as de-scribed in Section 4.3.
This offers the benefitof suspending parsing to obtain semantic infor-mation without incurring the inefficiency of suchaction.4.
Special cases exist and should be introduced assuch, rather than erroneously generalized to thepoint of introducing the  possibility for parseswhich users would find ungrammatical.4.5 Syntactic Processor OutputThe output of the syntax processor is a templatefor each clause giving the imperative verb and pointersto structures which represent he operands.
Figure 9gives an example of such an output.Imperat ive  Verb  TemplateOPERATOR addOPERAND IART ICLE  DETERMINEDARTSP S ING-PLURNOUN ent ryNOUNSP PLURMod i f ie r  IPREP INNOUN rowNOUNSP S INGWHICH IMod i f ie r  2COMP GREATERNOUN CONSTANTWHICH 6.0VERBICLE  toOPERAND 2NOUN PROPNAMEQUOTE XFigure 9.
Output of the syntax processor for the sentence "add theentries in row 1 greater than 6.0 to X.
".78 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation5.
Sentence SemanticsThe primary responsibility of the semantics moduleof NLC is the processing of noun groups to determinetheir referents.
Input to semantics consists of theparse trees constructed by the syntactic processor.The imperative, along with its verbicle/particle, issaved for later context references, but not operatedupon at this time.
The principal role of semantics i toproduce a precise internal representation that can beused by the matrix computer in carrying out the re-quested command.A secondary role of semantics is toupdate contextas a consequence of resolving noun phrases.
In thisway, one may refer to previous actions of the system.Thus:"Clear the column that was added to column 2.
""Increment by 5 the row which the lastcommand squared.
"Context is also utilized in the location of referents forpronouns and other words requiring pronominal proc-essing.
Some examples are:"Multiply the smallest entry by IT.
""Replace THAT ENTRY by ITS reciprocal.
""Subtract the NEXT 2 entries from eachmember of row 2.
""Sum up the OTHER entries in those rows.
"The following sections describe briefly the repre-sentations used in the system, noun group resolution,and the processing of pronominal structures.5.1 Internal Data StructuresFor the matrix computer to carry out users' com-mands, physical addresses of the operands must beavailable.
The resolved nouns must also be stored at aconceptual level so that later sentences may refer tothe objects operated upon.
For these reasons, thebasic internal representation of the domain entitiesconsists of a collection of intermediate structures fromwhich hardware addresses are computed.
Since thesyntax parse trees are available, this intermediate no-tation does not refer to the natural anguage input.Most of the internal structures, denoted"datareps", refer to a singular domain entity and havea fixed number of parameters.
These "primitives" are:entry, row, column, matrix, domain, float constant, intconstant, name, noun result, result, and command.
Asan example, the datarep for the noun group "row 2" is(ROW 1 2) which fills 5 bytes in memory and givesthe name of the entity, the matrix number, and theitem designation.Plurals may arise in a variety of ways, some ofwhich are presented here.
In the simplest case, a plu-ral datarep is the direct result of the resolution of aplural noun, as in"rows 3, 4 and 5""the entries in rows 1 and 2"Word-meaning routines such as adjective, ordinal, andsuperlative may produce a plural output, as in"the positive entries in row 2""the last 3 entries that were doubled""the smallest 3 numbers in the last column"In addition, plurals may result from the conjoining ofsingular datareps"row 4 and column 5""row 2 and the last row"or from conjunctions in which one or more of theconjuncts is itself plural"row 3 and the rows containing positive entries""the first 3 and the last 2 rows in matrix 1"An important feature common to all the types of con-junctions mentioned above is that the members of the"set" which represents the resulting plural datarep arethemselves singular.
Thus, for the noun phrase"row 6 and the first 2 rows"the resolution will beSET of size 3:ROW 6ROW 1ROW 2Because of the manner of manipulating the internalstructures and passing them between modules of theNLC system, an array-like data structure was chosenfor sets instead of a LISP-like representation.
A de-tailed description of the precise mechanism for repre-senting sets, beyond the scope of the present paper,may be found in Ballard\[1\].5.2 Noun Group ResolutionThe discovery of the meaning of a particular noungroup begins with the head noun and any "in" qualifi-er which may be found.
Thus in the phrase"the smallest entry in row 2 greater than 10,"the meaning of the words "entry in row 2" is initiallyrepresented as the set {(ENTRY 2 1), (ENTRY 2 2),.
.
.
.
(ENTRY 2 N)}.
Then processing of otherqualifiers and lastly prenominal modifiers has the ef-fect of removing entries from the initial set.
In thiscase, processing of "greater than 10" causes the sys-tem to reference the values of the listed entries andremove from the set those entries not meeting thespecified criterion, "greater than 10".
Processing of"smallest" results in all but the appropriate smallestentry being removed, and processing of "the" involveschecking that the resulting set has only one membersince the head noun is singular.
The final meaning ofthe noun group is thus the set {(ENTRY 2 i)} forAmerican Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 79Alan W. Biermann and Bruce W.  Ballard Toward Natural Language Computationsome i and this representation is passed to the matrixcomputer as an operand for some computation.5.3 Pronominal izat ionThe basic syntactic types of the pronouns withinthe matrix domain are the following:1. pure pronoun"it" / "them""itself" / "themselves"2. pronominal determiner"THAT entry" / "THOSE columns"3. possessive determiner"ITS rows" / "THEIR columns"4. pronominal ordinal"NEXT row""OTHER entries"The fourth category is included among the listing ofpronouns because the semantics involve most of thesame principles.
For instance, "the other entries"demands the semantics that would occur for "the en-tries other than ?
", where "?"
represents the mostgeneral possible pronoun, having no type or numberconstraints.Pronoun reference is done by considering previous?
datareps rather than by traversing trees as describedby Hobbs \[22\].
Specific guidelines for posing theeligible referents to pronouns in a reasonable orderinclude, in order of importance:1.
In all cases, require type, number, and semanticconstraints of the pronoun to agree with thedatarep being examined.2.
Prefer more recently created atareps.3.
For case-level (operand) pronouns, try to matchsource with an old datarep source, destinationwith an old destination.4.
"Fuse", or conjoin, singular data/eps to producea plural referent if necessary.
Thus"Add row 1 to row 2.
""Double those rows.
"entails creating the set consisting of rows 1 and2 at the time pronoun referent location occurs.5.
Consult more distant sentences only after tryingall possibilities on an intervening sentence.Thus,"Clear rows 1 and 2.
""Triple column 4.
""Add row 3 to row 4.
""Double those rows.
"will prefer the complicated but recent fusion inthe immediately preceding command over theexact but less immediate plural three sentencesearlier.6.
The Matrix ComputerThe "matrix computer" of NLC is assigned twomajor tasks: (1) carrying out the computations whichthe user has requested and (2) displaying on the termi-nal the resulting data world.
Since the latter functionis conceptually simple (although tedious to code effec-tively) and since sample system outputs are providedin Figure 1, this section will concentrate only upon thetechniques which the matrix computer uses to performthe desired computations.As discussed in the previous section, essentially allprocessing of noun phrases is completed by the seman-tics module.
What is made available then to the ma-trix computer is a collection of templates, similar tothe ones generated as the parser output, as shownearlier in Figure 9, but with the noun arguments fully"resolved" into datareps as already described.
As anexample of the templates received by the matrix com-puter, consider the English input"Add up the first row, double row 2, andsubtract row 4 from row 5.
"The semantics output for this input isTemplate 1 :Verb: "add"Verbicle/Particle: "up"Operand: (ROW 1)Template 2:Verb: "double"Verbicle/Particle: --Operand: (ROW 2)Template 3:Verb: "subtract"Verbicle/Particle: "from"Operand 1: (ROW 4)Operand 2: (ROW 5)The task of the matrix computer is to decide upon theappropriate operations and to apply them to the ope-rands.It was mentioned earlier that the imperatives, parti-cles, and verbicles recognized at parse time passthrough semantics without alteration.
When the out-put  from semantics becomes available to the matrixcomputer, the imperative verb and the associatedverbicle/particle (if there is one) are looked up in atable to determine the appropriate action.
In mostcases, it has not been necessary to write a separateprocedure for each imperative.
Specifically, "double"is treated as a special case of "multiply".
Thus theuser input"Double the first 2 entries in column 1.
"entails the matrix computer operationsArith-op(*, 2.0, (ENTRY 1 1))Arith-op(*, 2.0, (ENTRY 2 1))80 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationwhere "Arith:op" is the general coding capable ofperforming the basic arithmetic operations.
In thisway, the matrix computer has accommodated a largenumber of arithmetic ommands by the mere additionof one table entry (8 bytes).
Further instances ofarithmetic verbs which make use of the arithmetie-opcode are clear, copy, decrease, decrement, divide,halve, and many others.In general, operating with a scalar (element, varia-ble, or constant) upon an aggregate (row, column ormatrix) means to operate independently on each mem-ber.
The knowledge of how to perform the intendedoperations for all meaningful source-destination pairsmust be coded into the system.
This means specifyingfor each X-Y pair exactly what is required byArith-op(op, X, Y)for datareps 'X' and 'Y'and 'op' a member of { +, * .... }The remaining type of matrix computer operationdeals with the noun result such as in"Add the PRODUCT of the positive entriesto row 1.
""Add the SUM of rows 3, 4 and 5 to row 6.
"Notice that a noun result may yield a scalar as in thefirst example or a vector as in the second.
The nounresult is evaluated similarly to imperative verb opera-tions, and the result of the calculation is inserted intothe appropriate higher level structure for further proc-essing.7.
F low-of -Contro l  Semant icsThus far, this paper has discussed sentence by sen-tence processing, where system actions occur one at atime, determined irectly from keyboard inputs.
Mostmeans of enhancing the usefulness of the system fallinto one of two categories: (1) the introduction ofprogramming-language type control structures and (2)the ability to define and execute self-contained por-tions of natural anguage "coding".
These topics areaddressed separately here.7.1 Condit ional  Execut ionTo specify conditional execution of a command ora group of commands in English, one uses such wordsas "if", "when", "unless", "otherwise", etc.
Follow-ing are some sentences typical of inputs that NLC-likesystems will likely be called upon to process.
"IF row 3 contains a positive entry ...""IF the largest entry occurs in the last row ..."Implementation of this facility is not complete onthe NLC system.
When it becomes totally operative,users will be told that they may begin sentences withthe word "if" as well as with imperative verbs.
Thecharacteristic language feature appearing in each ofthe above sentences i the independent clause: decla-rative (rather than imperative) in nature, and requiringthe evaluation of a Boolean (i.e., a condition whosetruth or falsity is to be determined).
Fortunately, theconjugated verbs are typically either "be" or one ofthe verbs which have already occurred in relativeclauses, and so an appreciable degree of different syn-tactic processing is not required.
Thus,"if row 3 contains a positive entry ..."relates directly to"the rows which contain a positive entry"The semantic routines originally written for qualifierverbs can, therefore, with a slight modification be usedin handling these constructs.7.2 LoopingNLC provides several ways of creating loops usingthe verb "repeat."
In the typical situation, the usersupplies and observes the execution of a sequence ofcommands on particular members of the data world.The system is then capable of abstracting, from thespecific instructions, general code to operate on otherentities.
Frequently, an algorithm requires the applica-tion of a sequence of commands to several members ofthe domain.
One way of accomplishing this is to makeuse of the following pattern.
"Choose an entry which ... and call it x.""
.
.
.
to x.""
x by ""Repeat for the other entries.
"When such a sequence is recognized, the "repeat"processor finds the set given to the most recent un-matched "choose" (or "pick", etc.)
and thereby knowswhat "other" members are to have the interveningcommands applied to them.
In instances where thereis no non-deterministic " hoose"-type operation todelineate the statements to be repeated or to makeexplicit the set to which previous commands are to beapplied, alternate versions of "repeat" are provided.Examples include"Repeat he last 3 commands.
""Repeat he last command 5 times.
""Repeat he last 3 commands for allother odd entries.
""Repeat hose commands twice on row 3.
"7.3 ProceduresAnother way of extending sentence by sentenceprocessing is the facility for defining procedures, ena-bling the user to describe operations in terms of exist-ing commands.
Subsequent inputs may access thenewly-created imperatives as though they had beenpreviously defined, including their use in further pro-American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 81Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationcedure definitions.
Programmers will recognize thefollowing illustration as an instance of the "called-procedure" type of subroutine.
There is no reason,however, for not providing the "function" procedureas well.
Interestingly, the "noun result" discussedearlier corresponds to this value-returning subroutine.In addition, the NLC design includes the creation ofnew adjectives.
The correspondences between aturallanguage words and conventional programming lan-guage procedures are roughly as follows.Natural Language Programming Languageimperative verb "called" subroutinenoun result * "function" subroutineadjective * "predicate"(* - not yet operative on NLC)Both the noun result and the adjective routines requirean explicit "return" command.
Methods of incorpo-rating them into the present system, as well as ways ofrelaxing the restrictions for the imperative verb proce-dures discussed below, are being developed.In order to assure correct re-execution of the com-mands within a procedure, it is necessary to detectoccurrences of the parameters among the nouns of theprocedure body.
To accomplish this, the system re-quires that the arguments at the time of proceduredefinition be names.
When a user input indicates thata procedure is about to be defined, names are saved sothat their re-occurrence can be recognized as denotinga parameter rather than simply the current argument.While the procedure definition is in progress, appropri-ate changes are made in the syntax trees, which arethen saved on disc.
As an example, suppose the usertypes"Define a procedure to zap z into w.""Double w.""Add z to w.""Negate z.""End.
"At this point, there will be four new files contain-ing parse trees which can be informally represented asfollows.filename contentsZap.0001 double param-2Zap.0002 add param-1 to param-2Zap.0003 negate param-1Zap.0004 endThis enables flow-of-control semantics processing,when an invocation of the new "zap...into" imperativeis detected, to evaluate the arguments and substitutethem appropriately into the procedure's syntax treeswherever param-i s present.Syntax for user-created imperatives parallels thatfor the system-provided routines of correspondingtype.
For instance, the same type of verbicle/particlecompatibility checking (where applicable) takes place.Thus some acceptable inputs are"Zap row 3 into row 6.
""Zap into column 4 the second column.
"and some intentionally rejected inputs are"Zap row 5."
\[missing operand\]"Zap row 5 from row 6 . "
\[wrong verbicle\]8.
Sys tem BehaviorThe sentence processing capabilities of the systemwill be indicated in this section by demonstrating itsability to handle paraphrases and by describing anexperiment in which it was used by paid subjects tosolve problems.8.1 Syntact ic  BreadthTo demonstrate the variety of the syntax handledby the system, fifty-five paraphrases are given belowfor the sentence"Double the first row in matrix 1.
"These paraphrases are not all exact in that some ofthem omit reference to matrix 1, assuming contextmakes it clear, others entail side effects, such as thecreation of a label, etc.
This set gives only a smallfraction of all the possible paraphrases that can beprocessed, but it is representative.
The typical timerequired for complete processing of each sentence istwo seconds on the PDP-11/70.The first set of paraphrases demonstrates somevariations on the qualifier.1.
"Double the first row of matrix 1."2.
"Double the first row which is in matrix 1."3.
"Double the first row that appears in matrix 1."4.
"Double the first tow that matrix 1 contains."5.
"Double the first row matrix 1 contains.
"The matrix reference can also appear as a classifier6.
"Double the first matrix 1 row.
"or if context indicates the matrix reference, it can beomitted.7.
"Double the first row."8.
"Double row 1.
"A row may be referred to by the values it contains.9.
"Double the first row that contains a positive ora nonpositive number."10.
"Double the row that contains the first entry ofmatrix 1."11.
"Double the row in whichthe first entry of matrix 1 appears."12.
"Double the first row in which there isa positive or a nonpositive number.
"82 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Alan W. Biermann and Bruce W. Bsllard Toward Natural Language Computation13.
"Double the row containing the first entryof column 1."14.
"Consider column 2.Consider the first entry in it.Double the row which contains that entry.
"Rows may be thought of as sets of entries.15.
"Double the entries of row 1."16.
"Double the elements in row 1."17.
"Double the row 1 entries."18.
"Double the row 1 numbers.
"The next several sentences illustrate some quantifiers.19.
"Double all the entries of row 1."20.
"Double each entry in row 1."21.
"Double every entry in row 1."22.
"Double each one of the entries in row 1.
"Assume the row has 5 members.23.
"Double the first five entries of matrix 1.
"Some rows may be located poSitionally.24.
"Double the top row.
"Suppose there are four rows in the matrix.
The firstrow can be found by counting up from the bottom.25.
"Double the fourth row from the bottom."26.
"Double the fourth from the bottom row."27.
"Double the fourth f rom bottom row."28.
"Double the fourth from the last row.
"Generality of ordinal processing allows for some ratherstrange sentences.29.
"Double the first one row."30.
"Double the first row from the top.
"Row 1 can be located with respect o other rows.31.
"Double the row in matrix 1 corresponding torow 1 in matrix 2."32.
"Double the row in matrix 1 which correspondsto row 1 of matrix 2.
"One can use multiple clauses by labelling or focusingattention in one clause and then using it in the secondclause.33.
"Consider row 1 and double it."34.
"Consider row 1.
Double it."35.
"Consider row 1.
Double that row."36.
~ "Consider and double row 1."37.
"Consider row 1.Double the row considered by thelast command."38.
"Consider row 1.Double the row the last command considered."39.
"Consider matrix 1 and double its first row."40.
"Consider rows 2, 3 and 4.Double the other row."41.
"Consider row 1 of matrix 2.Double the row in matrix 1 corresponding to it.
"Users may access entities by naming them.42.
"Call row 1 x.
Double x."43.
"Call row 1 x.
Double row x."44.
"Call row 1 x.
Double it."45.
"Call row 1 x.
Double the x row."46.
"Call the first entry x.
Double the x row.
"The "backup" command will undo the calculation ofprevious commands.47.
"Double row 1.
Clear it.
Backup.
"Other imperatives can be used to achieve the result of"double".48.
"Add row 1 to itself."49.
"Add row 1 to row 1."50.
"Multiply row 1 by 2."51.
"Divide row 1 by 0.5."52.
"Divide 0.5 into' the first row."53.
"Add the entries in row 1 to themselves.
"Finally, noun result groups may be used.54.
"Put the product of 2 and row 1 into row 1."55.
"Subtract he negative of row 1 fromthat row.
"There are, of course, many paraphrases which arenot currently recognized by NLC.
Some examplesinclude sentences with superfluous words or phrases:1.
"PLEASE double row 1."2.
"Double the VERY first row of matrix 1."3.
"Double the first BUT NOT THESECOND row.
"certain unimplemented noun-result formats:4.
"Put twice row 1 into row 1."5.
"Put row 1 times 2 into row 1.
"and verbs taking more than 2 operands:6.
"Add row 1 to itself, putting the resultinto row 1.
"8.2 Some Observat ions of PerformanceIn April of 1979, twenty-three students in a firstcourse in programming at Duke were paid to be sub-jects in an experiment on the system.
Each subjectwas left alone in a room with the display terminal andgiven a short tutorial to read, a few simple practiceexercises to do, and a problem to solve.
No verbalinteractions were allowed between experimenter andsubject except those related to the administration ofthe test.
Typical times required to complete the tuto-rial, the exercises, and the problem were 35, 15, and50 minutes, respectively.
In the problem solving ses-sions, the subjects typed a total of 1581 sentences, 81American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 83Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationpercent of which were processed immediately andcorrectly.
Approximately half of the remaining 19percent were rejected because of system inadequacies,and the other half were rejected because of errors inuser inputs.
This experiment is described in \[5\] byBiermann, Ballard, and Holler, with an analysis of thetypes of errors that were made.
Also included in theexperiment was a test of the subjects' ability to do thesame problems in the programming language fromtheir course, PL/C.
These results are discussed in \[5\],too.Some specific observations that have come out ofthe experiment and other usages of the system are asfollows:1.
The vocabulary of over 300 words is nearly ade-quate for a reasonable class of problems.
Onlyeight words were typed during the experimentwhich were not available in the system.
Howev-er, any casual user who attempts to push thesystem capabilities ignificantly will quickly findmany unimplemented words.2.
Some of the implemented words have inade-quate definitions.
For example, NLC will proc-ess "the entry corresponding to x" but not "thecorresponding entry".
The latter form is moredifficult because the item to be corresponded tois not explicit.3.
The variety of the syntactic structures which areprocessed is approximately as good as indicatedby the experiment: About 70 to 90 percent of atypical user's inputs will be handled by the par-ser.4.
The error messages for the system are inade-quate.5.
The processor for quantification eeds to beredesigned.
We notice for example that NLCprocesses "Double EACH entry in the first col-umn" but not "Double the first entry in EACHcolumn."
In the former case, the first column isfound and the matrix computer doubles its en-tries in one operation.
In the later case, thedefinitions of "entry 't, "first", "the", and"double" must be invoked in that order for ev-ery column.9.
Compar ison With Other WorkA number of projects in automatic programmingpropose to have a user converse about a problem in acompletely natural manner, using problem dependentvocabulary, and largely omitting discussion of datastructures and coding details.
Examples of such workhave been described by Balzer\[2,3\], Biermann\[4\],Green\[13,14\], Heidorn\[16,17,18,19\], and Martin eta1.\[23\].
Inputs to these systems typically include acollection of fragments about the program to be gener-ated, in which case the system must perform consider-able induction and synthesis to produce an output.While the long term goals of the NLC project are sim-ilar to those of these other projects, the method ofresearch is somewhat different.
Whereas many pro-jeets attempt o tackle problems associated with sever-al levels of cognition at once, NLC attempts to beginwith a reliable sentence-by-sentence processor and toadd facilities slowly while reducing demands on theuser .Many of the research efforts in natural languageprocessing have been associated with information re-trieval from data base systems (Codd\[9\], Harris\[15\],Hendrix et a1.\[20,21\], Petrick\[25\], Plath\[26\], Sim-mons\[31\], Thompson & Thompson\[34\], Waltz\[35,36\],and Woc~ds\[39\]).
Most of the inputs for these systemsare questions or simple imperatives such as "list all ofthe ..." Top level sentence syntax for these systemsmay have more variety than NLC.
At the noun grouplevel, however, NLC appears to have more extensivecapabilities.
This is due to the need in the NLC envi-ronment to conveniently refer to objects or sets ofobjects on the basis of their properties, geometricallocation, operations performed upon them, etc.Concerning world modelling, a system which bearssome resemblance to NLC is SOPHIE by Brown andBurton\[8\].
Their system allows natural anguage inter-action with a simulator for an electric circuit.In the artificial intelligence literature, there is muchemphasis on (1) artificial cognitive abilities, (2) induc-tion mechanisms, (3) problem solving facilities, and(4) mechanisms for dealing with context and sequence.Future work on NLC will move in the direction ofadding such facilities, but in its current state the sys-tem works more like an interpreter for English in thestyle of programming language interpreters than like a"thinking" machine.
Thus the mechanisms describedin Bobrow & Collins\[7\], Cullingford\[10\], Minsky\[24\],Schank\[2g,29,30\], Winograd\[37\], and others for vari-ous kinds of cognition and problem solving are, for thetime being, largely without counterpart in NLC.
Thephilosophy of this project has been to build from thebottom, attempting to solve the least difficult, thoughstill challenging, problems first.10.
ConclusionNatural language programming has seemed in re-cent years to be a rather remote possibility because ofthe slow progress in representation theory, inferencetheory, and computational linguistics.
The NLC sys-tem is designed to compensate partially for the weak-ness of current echnology in these areas by presenting84 American Journal of Computational Linguistics, Volume 6, Number  2, Apr i l - June 1980Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computationthe user with.a good environment and with some well-designed linguistic facilities.
All of the quoted phrasesand sentences in this paper and the Appendix havebeen run on the system except for the "if" construc-tions in Section 7.
Current efforts are aimed at thedevelopment of a number of f low-of-control semanticsfacilities for handling various types of control struc-tures and definitions of new vocabulary items.Appendix: A Natural Language Program and ItsPL/ I  EquivalentThe following "pivot" routine uses a computationaltechnique described in Gallie and Ramm\[12\]  and givesan example of a nontrivial usage of the system.
"Display a 4 by 5 matrix and call it testmat.
""Fill the matrix with random values.
""Choose an entry and call it p.""Define a method to pivot testmat about p.""Choose an entry not in the p row and not inthe p column and call it q.
""Compute the product of the entry which cor-responds to q in the p row and the entrywhich corresponds to q in the p column.
""Divide the result by p and subtract his resultfrom q.
""Repeat for all other entries not in the p rowand not in the p column.
""Divide each entry except p in the p row by pand negate those entries,""Divide each entry except p in the p columnby p.""Put the reciprocal of p in*o p.""End the definition.
"The PL / I  equivalent program as given in \[12\] is asfollows:EXCHANGE:PROCEDURE(MATRIX ,P IVROW,P IVCOL) ;DECLARE (MATRIX(* , * ) ,P IVOT)  FLOAT,(P IVROW,P IVCOL,ROWS,COLMNS, I , J )F IXED BINARY;/* DETERMINE NUMBER OF ROWSAND COLUMNS */ROWS = HBOUND(MATRIX , I ) ;COLMNS = HBOUND(MATRIX ,2) ;/* NAME THE P IVOT ELEMENT */P IVOT = MATRIX(P IVROW,P IVCOL)  ;/* APPLY  THE "RECTANGLE RULE" */DO I = I to P IVROW-I ,P IVROW+I TO ROWS;DO J = I TO P IVCOL- I ,P IVCOL+I  TO COLMNS;MATRIX( I , J )  = MATRIX( I , J )- MATRIX( I ,P IVCOL)  *MATRIX(P IVROW, J )  / PIVOT;END;END;/* CHANGE THE OLD P IVOT ROW */DO J = I TO P IVCOL- I ,P IVCOL+I  TO COLMNS;MATRIX(P IVROW, J )  =- MATRIX(P IVROW, J )  / PIVOT;END;/* CHANGE THE OLD P IVOT COLUMN */DO.I  = I TO P IVROW-I ,P IVROW+I TO ROWS;MATRIX( I ,P IVCOL)  =MATRIX( I ,P IVCOL)  / PIVOT;END;/* CHANGE THE P IVOT */MATRIX(P IVROW,P IVCOL)  = I / PIVOT;END, EXCHANGE;AcknowledgementMiss Anne Holler has produced several sections ofcode in the NLC system, including the spelling correc-tar, the syntax networks for the "i f" and "repeat"clauses, semantics and matrix computer routines fornoun result groups, and all the terminal display rou-tines.
We are grateful to George  ne idorn  and thereferees for extensive help in improving and shorteningthe original 87 page report.ReferencesI.
Ballard, B.W.
Semantic Processing For A Natural LanguageProgramming System (Ph.D. Dissertation), Report CS-1979-5,Duke University, Durham, North Carolina, May, 1979.2.
Balzer, R.M.
"A Global View Of Automatic Programming",Proc.
3rd Joint Conference On Artificial Intelligence, August,1973, pp.
494-499.3.
Balzer, R.M.
"Imprecise Program Specification", Proc.
Con-siglio Nazi.
Ric.
Ist.
Elaborazione Inf., 1975.4.
Biermann, A.
"Approaches To Automatic Programming", inAdvances in Computers, Volume 15, Academic Press, NewYork, 1976, pp.
1-63.5.
Biermann A., Ballard, B., and Holler, A.
"An ExperimentalStudy Of Natural Language Programming," Report CS-1979-9, Duke University, Durham, North Carolina, July, 1979.6.
Biermann, A. and Krishnaswamy, R. "Constructing ProgramsFrom Example Computations", IEEE Transactions on SoftwareEngineering, September, 1976, pp.
141-153.American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 85Alan W.  Biermann and Bruce W.  Ballard Toward Natural Language Computation7.
Bobrow, D.G.
and Collins, A.
Ed., Representation and Under-standing, Academic Press, New York, 1975.8.
Brown, J.S.
and Burton, R.R.
"Multiple Representations OfKnowledge For Tutorial Reasoning", in Representation a dUnderstanding (Bobrow, D.G.
and Collins, A., Eds.
), AcademicPress, New York, 1975, pp.
311 - 349.9.
Codd, E.F. "Seven Steps to RENDEZVOUS With The CasualUser", IBM Report J1333 (#20842), January 17, 1974.
Pres-ented at the IFIP-TC2 Conference on Data Base Management,Cargese, Corsica, April 1-5, 1974.10.
Cullingford, R.E.
Script Application: Computer Understandingof Newspaper Stories (Ph.D. Dissertation).
Research Report#116, Yale University, 1978.11.
Dijkstra, E.W.
"On The Foolishness Of 'Natural LanguageProgramming'".
Unpublished report, 1978.12.
Gallie, T. and Ramm, D. Computer Science/I: An IntroductionTo Structured Programming.
Kendall/Hunt, Dubuque, Iowa,1976.13.
Green, C~ "A Summary Of The PSI Program Synthesis Sys-tem", Proceedings Of 5th International Conference on Artifi-cial Intelligence, Volume I, August 1977, pp.
380 - 381.14.
Green, C.C., Waldinger, R.J., Barstow, D.R., Elsehlager, R.,Lenat, D.B., McCune, B.p., Shaw, D.E., and Steinberg, L.I.
"Progress Report On Program-Understanding Systems", MemoAIM-240, Stanford Artificial Intelligence Laboratory, Stan-ford, California.15.
Harris, L.R.
"Status Report On ROBOT NL Query Proc-essor", SIGART Newsletter, August, 1978, pp.
3-416.
Heidorn, George E. "Augmented Phrase Structure Gram-mars", IBM Thomas J. Watson Research Center, YorktownHeights, New York, December, 1975.17.
Heidorn, George E. "Automatic Programming Through Natu-ral Language Dialogue: A Survey", IBM J. Res.
Develop.,July, 1976, pp.
302-313.18.
Heidorn, George E. Natural Language Inputs To A SimulationProgramming System.
Naval Postgraduate School, October,1972.19.
Heidorn, George E. "Supporting A Computer-Directed NaturalLanguage Dialogue For Automatic Business Programming",Research Report 26157, IBM Thomas J. Watson ResearchCenter, Yorktown Heights, New York, June, 1976.20.
Hendrix, Gary G., Sacerdoti, Earl D., Sagalowicz, Daniel, andSlocum, Jonathan "Developing A Natural Language InterfaceTo Complex Data", ACM Trans.
on Database Systems, June,1978, pp.
105-147.21.
Hendrix, Gary G. "Human Engineering For Applied NaturalLanguage Processing", Proceedings Of 5th International Con-ference on Artificial Intelligence, Volume I, August, 1977, pp.183-191.22.
Hobbs, Jerry R. "Pronoun Resolution", Research Report76-1, Department of Computer Sciences, City College of NewYork, August, 1976.23.
Martin, W.A., Ginzberg, M.J., Krumland, R., Mark, B., Mor-genstern, M., Niamir, B., and Sunguroff, A.
Internal Memos,Automatic Programming Group, MIT, Cambridge, Massachu-setts, 1974.24.
Minsky, M. "A Framework For Representing Knowledge", inThe Psychology Of Computer Vision, Winston, P.H.
ed.,McGraw-Hill, New York, 1975.25.
Petrick, S.R.
"On Natural Language Based Computer Sys-tems", IBM J. Res.
Develop., July, 1976, pp.
314-325.
Alsoappears in Linguistic Structures Processing, A. Zampolli, ed.,North-Holland Publishing Company, Amsterdam, Holland,1977.26.
Plath, W.J.
"REQUEST: A Natural Language Question-Answering System", IBM J. Res.
Develop., July, 1976, pp.326-335.27.
Sammet, J.E.
"The Use of English As A Programming Lan-guage', Comm.
ACM, March, 1966, pp.
228-229.28.
Schank, R.C.
"Identification of Conceptualizations Underly-ing Natural Language", in Computer Models Of Thought AndLanguage, R.C.
Schank, R.C.
and K.M.
Colby, Eds., W.H.Freeman and Company, San Francisco, 1973, pp.
187-247.29.
Schank, R. and Abelson, R. Scripts, Plans, Goals, And Under-standing.
Lawrence Erlbaum Associates, Hillsdale, New Jer-sey, 1977.30.
Schank, R.C.
and Colby, K.M.
Computer Models of ThoughtAnd Language.
W.H.
Freeman and Company, San Francisco,1973.31.
Simmons, R.F.
"Natural Language Question Answering Sys-tems: 1969", Comm.
ACM, January, 1970, pp.
15-30.32.
Simmons, R.F.
Personal Communication at TINLAP-2 Con-ference, Univ.
of Illinois, July, 1978.33.
Stoekwell, R. Schachter, P., and Partee, B.
The Major Syntac-tic Structures Of English.
Holt, Rinehart and Winston, Inc.,New York, 1973, pp.
294-418.34.
Thompson, Frederick B. and Thompson, Bozena H. "PracticalNatural Language Processing: The REL System as Proto-type", in Advances In Computers, Volume 13, M. Rubinoff andM.C.
Yovits, Eds., Academic Press, New York, 1975, pp.109-168.35.
Waltz, D.L.
"An English Language Question AnsweringSystem For A Large Relational Database", Comm.
ACM, July,1978, pp.
526-539.36.
Waltz, D.L., ed.
"Natural Language Interfaces", SIGARTNewsletter, February, 1977.37.
Winograd, T. Understanding Natural Language, AcademicPress, New York, 1972.38.
Woods, W.A.
"A Personal View Of Natural Language Under-standing", in "Natural Language Interfaces", SIGART Newslet-ter, February, 1977, pp.
17-20.39.
Woods, W.A., Kaplan, R.M., and Nash-Weber, B.
The LunarSciences Natural Language Information System: Final Report.Report Number 2378, Bolt, Beranek and Newman, Inc., Cam-bridge, Massachusetts, 1972.40.
Woods, W.A.
"Transition Network Grammars For NaturalLanguage Analysis", Comm.
ACM, October, 1970, pp.
591-606.Alan W. Biermann is an associate professor in theDepartment of  Computer Science at Duke University.He received the Ph.D. degree in electrical engineeringand computer science from the University of  Californiaat Berkeley in 1968.Bruce W. Ballard is an assistant professor in theDepartment of  Computer and Information Science atThe Ohio State University.
He received the Ph.D. degreein computer science from Duke University in 1979.86 American Journal of Computational Linguistics, Volume 6, Number 2.
April-June 1980
