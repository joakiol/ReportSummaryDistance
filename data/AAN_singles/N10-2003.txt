Proceedings of the NAACL HLT 2010: Demonstration Session, pages 9?12,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsPhrasal: A Toolkit for Statistical Machine Translationwith Facilities for Extraction and Incorporation of Arbitrary Model FeaturesDaniel Cer, Michel Galley, Daniel Jurafsky and Christopher D. ManningStanford UniversityStanford, CA 94305, USAAbstractWe present a new Java-based open sourcetoolkit for phrase-based machine translation.The key innovation provided by the toolkitis to use APIs for integrating new fea-tures (/knowledge sources) into the decod-ing model and for extracting feature statis-tics from aligned bitexts.
The package in-cludes a number of useful features written tothese APIs including features for hierarchi-cal reordering, discriminatively trained lineardistortion, and syntax based language models.Other useful utilities packaged with the toolkitinclude: a conditional phrase extraction sys-tem that builds a phrase table just for a spe-cific dataset; and an implementation of MERTthat allows for pluggable evaluation metricsfor both training and evaluation with built insupport for a variety of metrics (e.g., TERp,BLEU, METEOR).1 MotivationProgress in machine translation (MT) depends crit-ically on the development of new and better modelfeatures that allow translation systems to better iden-tify and construct high quality machine translations.The popular Moses decoder (Koehn et al, 2007)was designed to allow new features to be defined us-ing factored translation models.
In such models, theindividual phrases being translated can be factoredinto two or more abstract phrases (e.g., lemma, POS-tags) that can be translated individually and thencombined in a seperate generation stage to arrive atthe final target translation.
While greatly enrichingthe space of models that can be used for phrase-based machine translation, Moses only allows fea-tures that can be defined at the level of individualwords and phrases.The Phrasal toolkit provides easy-to-use APIsfor the development of arbitrary new model fea-tures.
It includes an API for extracting featurestatistics from aligned bitexts and for incor-porating the new features into the decodingmodel.
The system has already been used todevelop a number of innovative new features(Chang et al, 2009; Galley and Manning, 2008;Galley and Manning, 2009; Green et al, 2010) andto build translation systems that have placed wellat recent competitive evaluations, achieving secondplace for Arabic to English translation on the NIST2009 constrained data track.1We implemented the toolkit in Java because it of-fers a good balance between performance and de-veloper productivity.
Compared to C++, develop-ers using Java are 30 to 200% faster, produce fewerdefects, and correct defects up to 6 times faster(Phipps, 1999).
While Java programs were histori-cally much slower than similar programs written inC or C++, modern Java virtual machines (JVMs) re-sult in Java programs being nearly as fast as C++programs (Bruckschlegel, 2005).
Java also allowsfor trivial code portability across different platforms.In the remainder of the paper, we will highlightvarious useful capabilities, components and model-ing features included in the toolkit.2 ToolkitThe toolkit provides end-to-end support for the cre-ation and evaluation of machine translation models.Given sentence-aligned parallel text, a new transla-tion system can be built using a single command:java edu.stanford.nlp.mt.CreateModel \(source.txt) (target.txt) \(dev.source.txt) (dev.ref) (model_name)Running this command will first create wordlevel alignments for the sentences in source.txtand target.txt using the Berkeley cross-EM aligner1http://www.itl.nist.gov/iad/mig/tests/mt/2009/ResultsRelease/currentArabic.html9Figure 1: Chinese-to-English translation using discontinuous phrases.
(Liang et al, 2006).2 From the word-to-wordalignments, the system extracts a phrase ta-ble (Koehn et al, 2003) and hierarchical reorder-ing model (Galley and Manning, 2008).
Two n-gram language models are trained on the tar-get.txt sentences: one over lowercased target sen-tences that will be used by the Phrasal decoderand one over the original source sentences thatwill be used for truecasing the MT output.
Fi-nally, the system trains the feature weights for thedecoding model using minimum error rate train-ing (Och, 2003) to maximize the system?s BLEUscore (Papineni et al, 2002) on the developmentdata given by dev.source.txt and dev.ref.
The toolkitis distributed under the GNU general public license(GPL) and can be downloaded from http://nlp.stanford.edu/software/phrasal.3 DecoderDecoding Engines The package includes two de-coding engines, one that implements the left-to-right beam search algorithm that was first intro-duced with the Pharaoh machine translation system(Koehn, 2004), and another that provides a recentlydeveloped decoding algorithm for translating withdiscontinuous phrases (Galley and Manning, 2010).Both engines use features written to a common butextensible feature API, which allows features to bewritten once and then loaded into either engine.Discontinuous phrases provide a mechanism forsystematically translating grammatical construc-tions.
As seen in Fig.
1, using discontinuous phrasesallows us to successfully capture that the Chineseconstruction?
X?
can be translated as when X.Multithreading The decoder has robust supportfor multithreading, allowing it to take full advantageof modern hardware that provides multiple CPUcores.
As shown in Fig.
2, decoding speed scaleswell when the number of threads being used is in-creased from one to four.
However, increasing the2Optionally, GIZA++ (Och and Ney, 2003) can also be usedto create the word-to-word alignments.1 2 3 4 5 6 7 8152535CorestranlationsperminuteFigure 2: Multicore translations per minute on a sys-tem with two Intel Xeon L5530 processors running at2.40GHz.threads past four results in only marginal additionalgains as the cost of managing the resources sharedbetween the threads is starting to overwhelm thevalue provided by each additional thread.
Mosesalso does not run faster with more than 4-5 threads.3Feature API The feature API was designed toabstract away complex implementation details ofthe underlying decoding engine and provide a sim-ple consistent framework for creating new decodingmodel features.
During decoding, as each phrasethat is translated, the system constructs a Featuriz-able object.
As seen in Table 1, Featurizable objectsspecify what phrase was just translated and an over-all summary of the translation being built.
Code thatimplements a feature inspects the Featurizable andreturns one or more named feature values.
Prior totranslating a new sentence, the sentence is passed tothe active features for a decoding model, so that theycan perform any necessary preliminary analysis.Comparison with Moses Credible research intonew features requires baseline system performancethat is on par with existing state-of-the-art systems.Seen in Table 2, Phrasal meets the performance ofMoses when using the exact same decoding modelfeature set as Moses and outperforms Moses signifi-cantly when using its own default feature set.43http://statmt.org/moses/?n=Moses.AdvancedFeatures (April 6, 2010)4Phrasal was originally written to replicate Moses as it wasimplemented in 2007 (release 2007-05-29), and the current ver-10FeaturizableLast Translated Phrase PairSource and Target AlignmentsPartial TranslationSource SentenceCurrent Source CoveragePointer to Prior FeaturizableTable 1: Information passed to features in the form of aFeaturizable object for each translated phrase.System Features MT06 (tune) MT03 MT05Moses Moses 34.23 33.72 32.51Phrasal Moses 34.25 33.72 32.49Phrasal Default 35.02 34.98 33.21Table 2: Comparison of two configurations of Phrasalto Moses on Chinese-to-English.
One Phrasal configura-tion uses the standard Moses feature set for single factorphrase-based translation with distance and phrase levelmsd-bidirectional-fe reordering features.
The other usesthe default configuration of Phrasal, which replaces thephrase level msd-bidirectional-fe feature with a heirarchi-cal reordering feature.4 FeaturesThe toolkit includes the basic eight phrase-basedtranslation features available in Moses as well asMoses?
implementation of lexical reordering fea-tures.
In addition to the common Moses features, wealso include innovative new features that improvetranslation quality.
One of these features is a hier-archical generalization of the Moses lexical reorder-ing model.
Instead of just looking at the reorder-ing relationship between individual phrases, the newfeature examines the reordering of blocks of ad-jacent phrases (Galley and Manning, 2008) and im-proves translation quality when the material beingreordered cannot be captured by single phrase.
Thishierarchical lexicalized reordering model is used bydefault in Phrasal and is responsible for the gainsshown in Table 2 using the default features.To illustrate how Phrasal can effectively be usedto design rich feature sets, we present an overviewof various extensions that have been built upon thesion still almost exactly replicates this implementation whenusing only the baseline Moses features.
To ensure this con-figuration of the decoder is still competitive, we compared itagainst the current Moses implementation (release 2009-04-13) and found that the performance of the two systems is stillclose.
Tthe current Moses implementation obtains slightlylower BLEU scores, respectively 33.98 and 32.39 on MT06 andMT05.Phrasal feature API.
These extensions are currentlynot included in the release:Target Side Dependency Language Model Then-gram language models that are traditionally usedto capture the syntax of the target language do apoor job of modeling long distance syntactic rela-tionships.
For example, if there are a number ofintervening words between a verb and its subject,n-gram language models will often not be of muchhelp in selecting the verb form that agrees with thesubject.
The target side dependency language modelfeature captures these long distance relationships byproviding a dependency score for the target transla-tions produced by the decoder.
This is done usingan efficient quadratic time algorithm that operateswithin the main decoding loop rather than in a sepa-rate reranking stage (Galley and Manning, 2009).Discriminative Distortion The standard distor-tion cost model used in phrase-based MT systemssuch as Moses has two problems.
First, it does notestimate the future cost of known required moves,thus increasing search errors.
Second, the model pe-nalizes distortion linearly, even when appropriate re-orderings are performed.
To address these problems,we used the Phrasal feature API to design a newdiscriminative distortion model that predicts wordmovement during translation and that estimates fu-ture cost.
These extensions allow us to triple thedistortion limit and provide a statistically significantimprovement over the baseline (Green et al, 2010).Discriminative Reordering with Chinese Gram-matical Relations During translation, a sourcesentence can be more accurately reordered if thesystem knows something about the syntactic rela-tionship between the words in the phrases being re-ordered.
The discriminative reordering with Chinesegrammatical relations feature examines the path be-tween words in a source-side dependency tree anduses it to evaluate the appropriateness of candidatephrase reorderings (Chang et al, 2009).5 Other componentsTraining Decoding Models The package includesa comprehensive toolset for training decoding mod-els.
It supports MERT training using coordinate de-scent, Powell?s method, line search along randomsearch directions, and downhill Simplex.
In addi-tion to the BLEU metric, models can be trained11to optimize other popular evaluation metrics suchas METEOR (Lavie and Denkowski, 2009), TERp(Snover et al, 2009), mWER (Nie?en et al, 2000),and PER (Tillmann et al, 1997).
It is also possibleto plug in other new user-created evaluation metrics.Conditional Phrase Table Extraction Ratherthan first building a massive phrase table from a par-allel corpus and then filtering it down to just whatis needed for a specific data set, our toolkit sup-ports the extraction of just those phrases that mightbe used on a given evaluation set.
In doing so, itdramatically reduces the time required to build thephrase table and related data structures such as re-ordering models.Feature Extraction API In order to assist in thedevelopment of new features, the toolkit providesan API for extracting feature statistics from a word-aligned parallel corpus.
This API ties into the condi-tional phrase table extraction utility, and thus allowsfor the extraction of just those feature statistics thatare relevant to a given data set.6 ConclusionPhrasal is an open source state-of-the-art Java-based machine translation system that was designedspecifically for research into new decoding modelfeatures.
The system supports traditional phrase-based translation as well as translation using discon-tinuous phrases.
It includes a number of new andinnovative model features in addition to those typi-cally found in phrase-based translation systems.
It isalso packaged with other useful components such astools for extracting feature statistics, building phrasetables for specific data sets, and MERT training rou-tines that support a number of optimization tech-niques and evaluation metrics.AcknowledgementsThe Phrasal decoder has benefited from the help-ful comments and code contributions of Pi-ChuanChang, Spence Green, Karthik Raghunathan,Ankush Singla, and Huihsin Tseng.
The softwarepresented in this paper is based on work work wasfunded by the Defense Advanced Research ProjectsAgency through IBM.
The content does not neces-sarily reflect the views of the U.S. Government, andno official endorsement should be inferred.ReferencesThomas Bruckschlegel.
2005.
Microbenchmarking C++,C#, and Java.
C/C++ Users Journal.P.
Chang, H. Tseng, D. Jurafsky, and C.D.
Manning.2009.
Discriminative reordering with Chinese gram-matical relations features.
In SSST Workshop atNAACL.Michel Galley and Christopher D. Manning.
2008.
Asimple and effective hierarchical phrase reorderingmodel.
In EMNLP.Michel Galley and Christopher D. Manning.
2009.Quadratic-time dependency parsing for machine trans-lation.
In ACL.Michel Galley and Christopher Manning.
2010.
Improv-ing phrase-based machine translation with discontigu-ous phrases.
In NAACL.Spence Green, Michel Galley, and Christopher D. Man-ning.
2010.
Improved models of distortion cost forstatistical machine translation.
In In NAACL.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.
Sta-tistical phrase-based translation.
In NAACL.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkit forstatistical machine translation.
In ACL.Philipp Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In AMTA.Alon Lavie and Michael J. Denkowski.
2009.
TheMETEOR metric for automatic evaluation of machinetranslation.
Machine Translation, 23.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In NAACL.Sonja Nie?en, Franz Josef Och, and Hermann Ney.
2000.An evaluation tool for machine translation: Fast eval-uation for MT research.
In LREC.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In ACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In ACL.Geoffrey Phipps.
1999.
Comparing observed bug andproductivity rates for java and C++.
Softw.
Pract.
Ex-per., 29(4):345?358.M.
Snover, N. Madnani, B.J.
Dorr, and R. Schwartz.2009.
Fluency, adequacy, or HTER?
: exploring dif-ferent human judgments with a tunable MT metric.
InSMT workshop at EACL.C.
Tillmann, S. Vogel, H. Ney, A. Zubiaga, and H. Sawaf.1997.
Accelerated DP based search for statisticaltranslation.
In In Eurospeech.12
