Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 42?54,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsDiscourse Structure and Computation: Past, Present and FutureBonnie WebberSchool of InformaticsUniversity of EdinburghEdinburgh UK EH8 9ABbonnie.webber@ed.ac.ukAravind JoshiDept of Computer & Information ScienceUniversity of PennsylvaniaPhiladelphia PA 19104-6228joshi@seas.upenn.eduAbstractThe discourse properties of text have longbeen recognized as critical to language tech-nology, and over the past 40 years, our un-derstanding of and ability to exploit the dis-course properties of text has grown in manyways.
This essay briefly recounts these de-velopments, the technology they employ, theapplications they support, and the new chal-lenges that each subsequent development hasraised.
We conclude with the challenges facedby our current understanding of discourse, andthe applications that meeting these challengeswill promote.1 Why bother with discourse?Research in Natural Language Processing (NLP) haslong benefitted from the fact that text can often betreated as simply a bag of words or a bag of sen-tences.
But not always: Position often matters ?e.g., It is well-known that the first one or two sen-tences in a news report usually comprise its best ex-tractive summary.
Order often matters ?
e.g., verydifferent events are conveyed depending on howclauses and sentences are ordered.
(1) a. I said the magic words, and a genie ap-peared.b.
A genie appeared, and I said the magicwords.Adjacency often matters ?
e.g., attributed mate-rial may span a sequence of adjacent sentences,and contrasts are visible through sentence juxtaposi-tion.
Context always matters ?
e.g., All languagesachieve economy through minimal expressions thatcan only convey intended meaning when understoodin context.Position, order, adjacency and context are intrin-sic features of discourse, and research on discourseprocessing attempts to solve the challenges posed bycontext-bound expressions and the discourse struc-tures that give rise, when linearized, to position, or-der and adjacency.But challenges are not why Language Technol-ogy (LT) researchers should care about discourse:Rather, discourse can enable LT to overcome knownobstacles to better performance.
Consider auto-mated summarization and machine translation: Hu-mans regularly judge output quality in terms that in-clude referential clarity and coherence.
Systems canonly improve here by paying attention to discourse?
i.e., to linguistic features above the level of n-grams and single sentences.
(In fact, we predict thatas soon as cheap ?
i.e., non-manual ?
methods arefound for reliably assessing these features ?
for ex-ample, using proxies like those suggested in (Pitleret al, 2010) ?
they will supplant, or at least com-plement today?s common metrics, Bleu and Rougethat say little about what matters to human text un-derstanding (Callison-Burch et al, 2006).
)Consider also work on automated text simplifica-tion: One way that human editors simplify text isby re-expressing a long complex sentence as a dis-course sequence of simple sentences.
Researchersshould be able to automate this through understand-ing the various ways that information is conveyedin discourse.
Other examples of LT applicationsalready benefitting from recognizing and applyingdiscourse-level information include automated as-sessment of student essays (Burstein and Chodorow,2010); summarization (Thione et al, 2004), infor-42mation extraction (Patwardhan and Riloff, 2007;Eales et al, 2008; Maslennikov and Chua, 2007),and more recently, statistical machine translation(Foster et al, 2010).
These are described in moredetail in (Webber et al, 2012).Our aim here then, on this occasion of ACL?s 50thAnnual Meeting, is to briefly describe the evolutionof computational approaches to discourse structure,reflect on where the field currently stands, and whatnew challenges it faces in trying to deliver on itspromised benefit to Language Technology.2 Background2.1 Early MethodsThe challenges mentioned above are not new.Question-Answering systems like LUNAR (Woods,1968; Woods, 1978) couldn?t answer successivequestions without resolving context-bound expres-sions such as pronouns:(2) What is the concentration of silicon in brec-cias?
?breccia1, parts per million?
?breccia2, parts per million??
.
.
.
?What is it in volcanics?
(Woods, 1978)Early systems for human interaction with animatedagents, including SHRDLU (Winograd, 1973) andHOMER (Vere and Bickmore, 1990), faced thesame challenge.
And early message understand-ing systems couldn?t extract relevant information(like when a sighted submarine submerged ?
?wentsinker?)
without recognizing relations implicit in thestructure of a message, as in(3) VISUAL SIGHTING OF PERISCOPE FOL-LOWED BY ATTACK WITH ASROC AND TOR-PEDO.
WENT SINKER.
LOOSEFOOT 722/723CONTINUE SEARCH.
(Palmer et al, 1993)The same was true of early systems for processingnarrative text (under the rubric story understanding).They took on the problem of recognizing events thathad probably happened but hadn?t been mentionedin the text, given the sequence of events that hadbeen (Lehnert, 1977; Rumelhart, 1975; Schank andAbelson, 1977; Mandler, 1984).Since these early systems never saw more thana handful of examples, they could successfully em-ploy straight-forward, but ad hoc methods to handlethe discourse problems the examples posed.
For ex-ample, LUNAR used a single 10-position ring bufferto store discourse entities associated with both theuser?s and the system?s referring expressions, resolv-ing pronouns by looking back through the bufferfor an appropriate entity and over-writing previousbuffer entries when the buffer was full.The next wave of work in computational dis-course processing sought greater generality throughstronger theoretical grounding, appealing to then-current theories of discourse such as Centering The-ory (Grosz et al, 1986; Grosz et al, 1995), used asa basis for anaphor resolution (Brennan et al, 1987;Walker et al, 1997; Tetreault, 2001) and text genera-tion (Kibble and Power, 2000), Rhetorical StructureTheory (Mann and Thompson, 1988), used as a ba-sis for text generation (Moore, 1995) and documentsummarization (Marcu, 2000b), and Grosz and Sid-ner?s theory of discourse based on intentions (Groszand Sidner, 1986a) and shared plans (Grosz andSidner, 1990), used in developing animated agents(Johnson and Rickel, 2000).
Issues related to fullycharacterizing centering are explored in great detailin (Kehler, 1997) and (Poesio et al, 2004).The approaches considered during this periodnever saw more than a few handfuls of examples.But, as has been clear from developments in PoS-tagging, Named Entity Recognition and parsing,Language Technology demands approaches that candeal with whatever data are given them.
So subse-quent work in computational discourse processinghas similarly pursued robustness through the use ofdata-driven approaches that are usually able to cap-ture the most common forms of any phenomenon(ie, the 80% at the high end of the Zipfian distri-bution), while giving up on the long tail.
This isdescribed in Section 3.2.2 Early AssumptionsWhile early work focussed on the correct assump-tion that much was implicit in text and had to beinferred from the explicit sequence of sentences thatconstituted a text, work during the next period fo-cussed on the underlying structure of discourse andits consequences.
More specificaly, it assumed thatthe sequence of sentences constituting the text werecovered by a single tree structure, similar to the sin-gle tree structure of phrases and clauses covering the43s1 s2s3conditionconditions1s2 s3motivationmotivation(a) (b)Figure 1: Proposed discourse structures for Ex.
4: (a) Interms of informational relations; (b) in terms of inten-tional relationswords in a sentence.
At issue though was the natureof the structure.One issue concerned the nature of the relation be-tween parent and child nodes in a discourse tree,and/or the relation between siblings.
While Rhetor-ical Structure Theory (Mann and Thompson, 1988)posited a single discourse relation holding betweenany two discourse units (i.e., units projecting to ad-jacent text spans), Moore and Pollack (1992) gave anexample of a simple discourse (Ex.
4) in which dif-ferent choices about the discourse relation holdingbetween pairs of units, implied different and non-isomorphic structures.
(4) Come home by 5:00. s1 Then we can go to thehardware store before it closes.
s2 That way wecan finish the bookshelves tonight.
s3Example 4 could be analysed purely in terms ofinformation-based discourse relations, in which s1specified the CONDITION under which s2 held,which in turn specified the CONDITION under whichs3 held.
This would make s1 subordinate to s2,which in turn would be subordinate to s3, as in Fig-ure 1a.
Alternatively, Example 4 could be analysedpurely in terms of intention-based (pragmatic) rela-tions, in which s2 would be MOTIVATION for s1,while s3 would be MOTIVATION for s2.
This wouldmake s3 subordinate to s2, which in turn would besubordinate to s1, as in Figure 1b.
In short, thechoice of relation was not merely a matter of labels,but had structural implications as well.Another issue during this period concerned thenature of discourse structure: Was it really a tree?Sibun (1992), looking at people?s descriptions of thelayout of their house or apartment, argued that theyresembled different ways of linearizing a graph ofthe rooms and their connectivity through doors andhalls.
None of these linearizations were trees.
Sim-ilarly, Knott et al (2001), looking at transcriptionsof museum tours, argued that each resembled a lin-ear sequence of trees, with one or more topic-basedconnections between their root nodes ?
again, nota single covering tree structure.
Wiebe (1993), look-ing at simple examples such as(5) The car was finally coming toward him.
s1He finished his diagnostic tests, s2feeling relief.
s3But then the car started to turn right.
s4pointed multiple lexical items explicitly relating aclause to multiple other clauses.
Here, but wouldrelate s4 to s3 via a CONTRAST relation, while thenwould relate s4 to s2 via a temporal SUCCESSIONrelation.The most well-known of work from this periodis that of Mann and Thompson (1988), Grosz andSidner (1986b), Moore and Moser (1996), Polanyiand van den Berg (1996), and Asher and Lascarides(2003).1The way out of these problems was also a wayto achieve the robustness required of any LanguageTechnology, and that lay in the growing consensustowards the view that discourse does not have a sin-gle monolithic hierarchical structure.
Rather, dif-ferent aspects of a discourse give rise to differentstructures, possibly with different formal properties(Stede, 2008; Stede, 2012; Webber et al, 2012).These different structures we describe in the nextsection, while the fact that this can?t be the end ofthe story, we take up in Section 4.3 The Situation TodayRecent years have seen progress to differing degreeson at least four different types of discourse struc-tures: topic structure, functional structure, eventstructure, and a structure of coherence relations.First we say a bit about the structures, and then aboutthe resources employed in recognizing and labellingthem.3.1 Types of discourse structuresTopic structure and automated topic segmentationaims to break a discourse into a linear sequence of1For a historical account and assessent of work in automatedanaphora resolution in this period and afterwards, we direct thereader to Strube (2007), Ng (2010) and Stede (2012).44topics such the geography of a country, followed byits history, its demographics, its economy, its legalstructures, etc.
Segmentation is usually done on asentence-by-sentence basis, with segments not as-sumed to overlap.
Methods for topic segmenationemply semantic, lexical and referential similarityor, more recently, language models (Bestgen, 2006;Chen et al, 2009; Choi et al, 2001; Eisenstein andBarzilay, 2008; Galley et al, 2003; Hearst, 1997;Malioutov and Barzilay, 2006; Purver et al, 2006;Purver, 2011).Functional structure and automated functionalsegmentation aims to identify sections within a dis-course that serve different functions.
These func-tions are genre-specific.
In the case of scien-tific journals, high-level sections generally includethe Background (work that motivates the objec-tives of the work and/or the hypothesis or claimbeing tested), followed by its Methods, and Re-sults, ending with a Discussion of the results or out-comes, along with conclusions to be drawn.
Finer-grained segments might include the advantage ofa new method (method-new-advantage) or of anold method (method-old-advantage) or the disad-vantage of one or the other (Liakata et al, 2010).Again, segmentation is usually done on a sentence-by-sentence basis, with sentences not assumed tofill more than one function.
Methods for functionalsegmentation have employed specific cue words andphrases, as well as more general language models(Burstein et al, 2003; Chung, 2009; Guo et al,2010; Kim et al, 2010; Lin et al, 2006; McKnightand Srinivasan, 2003; Ruch et al, 2007; Mizutaet al, 2006; Palau and Moens, 2009; Teufel andMoens, 2002; Teufel et al, 2009; Agarwal and Yu,2009).
The BIO approach to sequential classica-tion (Beginning/Inside/Outside) used in Named En-tity Recognition has also proved useful (Hirohataet al, 2008), recognizing that the way the start ofa functional segement is signalled may differ fromhow it is continued.Note that topic segmentation and functional seg-mentation are still not always distinguished.
Forexample, in (Jurafsky and Martin, 2009), the termdiscourse segmentation is used to refer to any seg-mentation of a discourse into a ?high-level?
linearstructure.
Nevertheless, segmentation by functionexploits different features (and in some cases, dif-ferent methods) than segmentation by topic, so theyare worth keeping distinct.Attention to event structure and the identificationof events within a text is a more recent phenomena,after a hiatus of over twenty years.
Here we justpoint to work by (Bex and Verheij, 2010; Cham-bers and Jurafsky, 2008; Do et al, 2011; Finlayson,2009).The automated identification of discourse rela-tions aims to identify discourse relations such asCONDITION and MOTIVATION, as in Example 4,and CONTRAST and SUCCESSION, as in Exam-ple 5.
These have also been called coherence re-lations or rhetorical relations.
Methods used de-pend on whether or not a text is taken to be divisibleinto a covering sequence of a non-overlapping dis-course units related to adjacent units by discourserelations as in Rhetorical Structure Theory (Mannand Thompson, 1988) or to both adjacent and non-adjacent units as in the Discourse GraphBank (Wolfand Gibson, 2005).
If such a cover is assumed,methods involve parsing a text into units using lex-ical and punctuational cues, followed by labellingthe relation holding between them (Marcu, 2000a;Marcu, 2000b; Wolf and Gibson, 2005).
If text isnot assumed to be divisible into discourse units, thenmethods involve finding evidence for discourse re-lations (including both explicit words and phrases,and clausal and sentential adjacency) and their ar-guments, and then labelling the sense of the iden-tified relation (Elwell and Baldridge, 2008; Ghoshet al, 2011; Lin et al, 2010; Lin, 2012; Prasad etal., 2010a; Wellner, 2008; Wellner and Pustejovsky,2007).3.2 Resources for discourse structureAll automated systems for segmenting and labellingtext are grounded in data ?
whether the data hasinformed the manual creation of rules or has beena source of features for an approach based on ma-chine learning.
In the case of topic structure andhigh-level functional structure, there is now a sub-stantial amount of data that is freely available.
Forother types of discourse structure, manual annota-tion has been required and, depending on the type ofstructure, different amounts are currently available.More specifically, work on topic structure andsegmentation has been able to take advantage of the45large, free, still-growing wikipedia, where articleson similar topics tend to show similar explicit seg-mentation into sub-topics.
This is certainly the casewith the English wikipedia.
If similar wikipediaevolving in other languages lack explicit segmenta-tion, it may be that cross-lingual techniques may beable to project explicit segmentation from English-language articles.With respect to high-level functional structure,some work on automated segmentation has beenable to exploit explicit author-provided indicatorsof structure, such as the author-structured abstractsnow required by bio-medical journals indexed byMedLine.
Researchers have used these explicitlystructured abstracts to segment abstracts that lackexplicit structure (Chung, 2009; Guo et al, 2010;Hirohata et al, 2008; Lin et al, 2006).For all other kinds of discourse structures, ded-icated manual annotation has been required, bothfor segmentation and labelling, and many of theseresources have been made available for other re-searchers.
For fine-grained functional structure,there is the ART corpus (Liakata et al, 2010)2.For discourse relations annotated in the RSTframework, there is the RST Discourse TreeBank ofEnglish text (Carlson et al, 2003), available throughthe Linguistic Data Consortium (LDC), as well assimilarly annotated corpora in Spanish (da Cunha etal., 2011), Portugese (Pardo et al, 2008) and Ger-man (Stede, 2004).For discourse relations annotated in the lexically-grounded approach first described in (Webber andJoshi, 1998), there is the Penn Discourse TreeBank(Prasad et al, 2008) in English, as well as corporain Modern Standard Arabic (Al-Saif and Markert,2010; Al-Saif and Markert, 2011), Chinese (Xue,2005; Zhou and Xue, 2012), Czech (Mladova?
et al,2008), Danish (Buch-Kromann et al, 2009; Buch-Kromann and Korzen, 2010), Dutch (van der Vlietet al, 2011), Hindi (Oza et al, 2009), and Turk-ish (Zeyrek and Webber, 2008; Zeyrek et al, 2009;Zeyrek et al, 2010).
Also available are discourse-annotated journal articles in biomedicine (Prasad etal., 2011) and discourse-annotated dialogue (Tonelliet al, 2010).2http://www.aber.ac.uk/en/cs/research/cb/projects/art/art-corpus/4 New challengesAlthough the largely empirically-grounded, multi-structure view of discourse addresses some of theproblems that previous computational approachesencountered, it also reveals new ones, while leavingsome earlier problems still unaddressed.4.1 Evidence for discourse structuresThe first issue has to do with what should be taken asevidence for a particular discourse structure.
Whileone could simply consider all features that can becomputed reliably and just identify the most accu-rate predictors, this is both expensive and, in the end,unsatisfying.With topic structure, content words do seem toprovide compelling evidence for segmentation, ei-ther using language models or semantic relatedness.On the other hand, this might be improved throughfurther evidence in the form of entity chains, as ex-plored earlier in (Kan et al, 1998), but using to-day?s more accurate approaches to automated coref-erence recognition (Strube, 2007; Charniak and El-sner, 2009; Ng, 2010).Whatever the genre, evidence for function struc-ture seems to come from the frequency and distri-bution of closed-class words, particular phrases (orphrase patterns), and in the case of speech, into-nation.
So, for example, Niekrasz (2012) showsthat what he calls participant-relational featuresthat indicate the participants relationships to thetext provide convincing evidence for segmentingoral narrative by the type of narrative activity tak-ing place.
These features include the distributionand frequency of first and second person pronouns,tense, and intonation.
But much work remains tobe done in this area, in establishing what providesreliable evidence within a genre and what evidencemight be stable across genres.Evidence for discourse relations is what we havegiven significant thought to, as the Penn DiscourseTreeBank (Prasad et al, 2008) and related corporamentioned in Section 3.2 aim to ground each in-stance of a discourse relation in the evidence thatsupports it.
The issue of evidence is especiallyimportant because none of these corpora has yetbeen completely annotated with discourse relations.Completing the annotation and developing robust46automated segmentation techniques requires iden-tifying what elements of the language provide evi-dence for coherence relations, and under what con-ditions.The two main types of evidence for discourse re-lations in English are the presence of a discourseconnective and sentence adjacency.
Discourse con-nectives annotated in the PDTB 2.0 come froma list of subordinating and coordinating conjunc-tions, and discourse adverbials ?
a subset of thoseidentified by Forbes-Riley et al(2006).
Subse-quently, Prasad et al (2010b) used Callison-Burch?stechnique for identifying syntax-constrained para-phrases (Callison-Burch, 2008) to identify addi-tional discourse connectives, some of which don?tappear in the PDTB corpus and some of whichappear in the corpus but were not identified andannotated as discourse connectives.
English isn?talone in lacking a complete list of discourse con-nectives: While German has the massive Hand-buch de deutschen Konnektoren (Pasch et al, 2003),even this resource has been found to be incompletethrough clever application of automated tagging andword-alignment of parallel corpora (Versley, 2010).Evidence for discourse relations in the PDTB alsocomes from lexical or phrasal elements that are out-side the initial set of conjunctions and discourse ad-verbials.
This evidence has been called alternativelexicalization or AltLex (Prasad et al, 2010b), andincludes (in English) clause-initial what?s more (Ex-ample 6) and that means (Example 7).
(6) A search party soon found the unscathed air-craft in a forest clearing much too small to haveallowed a conventional landing.
What?s more,the seven mail personnel aboard were missing.
[wsj 0550](7) The two companies each produce marketpulp, containerboard and white paper.
Thatmeans goods could be manufactured closerto customers, saving shipping costs, he said.
[wsj 0317]The discovery of these other forms of evidence3raises the question of when it is that a word or phrasesignals a discourse relation.
For example, only 15 ofthe 33 tokens of that means in the PDTB were anno-tated as evidence of a discourse relation.
While the3which English is not alone in having, cf.
(Rysova, 2012)three paragraph-initial instances were left unanno-tated due to resource limitations (ie, no paragraphinitial sentences were annotated unless they con-tained an explicit discourse connective), the major-ity were ignored because they followed an explicitconnective.As Wiebe?s example (5) showed, there can bemultiple explicit discourse connectives in a clause,each of which is evidence for a separate discourse re-lation (albeit possibly between the same arguments).All of these are annotated in the PDTB ?
eg, both butand then in(8) Congress would have 20 days to reject thepackage with a 50% majority, but then a Presi-dent could veto that rejection.
[wsj 1698]The question is whether an AltLex in the context ofan explicit connective also provides evidence of adistinct discourse relation ?
for example, with theconjunction with But in(9) At a yearling sale, a buyer can go solo and geta horse for a few thousand dollars.
But thatmeans paying the horse?s maintenance; on av-erage, it costs $25,000 a year to raise a horse.
[wsj 1174]As noted above, the PDTB 2.0 also admits sen-tence adjacency as evidence for one, or even two,implicit discourse relations, as in(10) And some investors fault Mr. Spiegel?s lifestyle; [Implicit = because, for instance] heearns millions of dollars a year and fliesaround in Columbia?s jet planes.
[wsj 0179]Here, the implicit token of because is associ-ated with a discourse relation labelled CONTIN-GENCY.CAUSE.REASON, while the implicit tokenof for instance is associated with one labelled EX-PANSION.RESTATEMENT.SPECIFICATION.The question is whether sentence adjacency couldalso serve as evidence for a distinct discourse rela-tion, even when there is also an explicit discourseadverbial, as in the following three instances of in-stead.
Here, Ex.
11 can be paraphrased as And in-stead, Ex.
12 as But instead, and Ex.13 as So in-stead.
(11) But many banks are turning away from strictprice competition.
Instead, they are trying to47build customer loyalty by bundling their ser-vices into packages and targeting them to smallsegments of the population.
[wsj 0085](12) The tension was evident on Wednesdayevening during Mr. Nixon?s final banquettoast, normally an opportunity for reciting plat-itudes about eternal friendship.
Instead, Mr.Nixon reminded his host, Chinese PresidentYang Shangkun, that Americans haven?t for-given China?s leaders for the military assaultof June 3-4 that killed hundreds, and perhapsthousands, of demonstrators.
[wsj 0093](13) Since stars are considerably more massive thanplanets, such wobbles are small and hard tosee directly.
Instead, Dr Marcy and others likehim look for changes that the wobbles cause inthe wavelength of the light from the star.
[TheEconomist, 10 November 2007]These examples suggest that the presence of anexplicit connective should not, in all cases, be con-sidered evidence for the absense of an implicit con-nective.
Once the set of explicit connectives havebeen identified that can co-occur with each other(including for example and for instance, as well asinstead), automated parsers for coherence relationscan be made to consider the presence of an implicitconnective whenever one of these is seen.4.2 Variability in discourse annotationAnother issue relates to variability in annotating dis-course structure: Inter-annotator agreement can bevery low in annotating pragmatic and discourse-related phenomena.
While we will illustrate thepoint here in terms of annotating coherence rela-tions, for other examples, the general point is illus-trated in papers from the DGfS Workshop on BeyondSemantics4 and in an upcoming special issue of thejournal Discourse and Dialogue devoted to the sametopic.The Penn Wall Street Journal corpus containstwenty-four (24) reports of errata in previously-appearing articles.
Twenty-three (23) consist of asingle pair of sentences, with no explicit discourseconnective signalling the relation between them.54http://www.linguistics.ruhr-uni-bochum.de/beyondsem/5The other report contains three sentences, again with noexplicit connectives.One sentence reports the error, and the other, the cor-rect statement ?
e.g.
(14) VIACOM Inc.?s loss narrowed to $21.7 millionin the third quarter from $56.9 million a yearago.
Thursday?s edition misstated the narrow-ing.
[wsj 1747]In twenty of the errata (class C1), the correctstatement is given in the first sentence and the er-ror, in the second; In the other three (class C2), it isthe other way around.
One might think that the twosentences in the twenty C1 reports would be anno-tated as having the same discourse relation holdingbetween them, and the same with the two sentencesin the three C2 reports.
But that is not the case: Thetwenty C1 reports presented to annotators at differ-ent times ended up being labelled with six differentdiscourse relations.
There was even variability inlabelling the three members of the C2 class: Theywere labelled with one discourse relation, and onewith a completely different one.What should one conclude from this variability?One possibility is that there is one right answer,and annotators just vary in their ability to iden-tify it.
This would mean it would be beneficial tohave a large troop of annotators (so that the major-ity view could prevail).
Another possibility is thatthere is more than one right answer, which wouldimply multi-label classification so that multiple la-bels could hold to different degrees.
A third possi-bility reflects the view from Beyond Semantics thatit is often very hard to transfer results from theoreti-cal linguistics based on toy examples to naturally-occurring texts.
In this case, variability is a con-sequence of the still exploratory nature of muchdiscourse annotation.
In the case of errata, whileclearly some relation holds between the pair of sen-tences, it may actually not be any of those used inannotating the PDTB.
That is, as Grosz and Sidner(1986b) argued several years ago, the sentences mayonly be related by their communicative intentions ?one sentence intended to draw the reader?s attentionto the specific error that was made (so that the readerknows what was mis-stated), the other intended tocorrect it.
One might then take the sense annotationof discourse relations as still exploratory in the widerange of corpora being annotated with this informa-tion (cf.
Section 3.2).484.3 Systematic relations between discoursestructuresFortunately for approaches to automated discoursestructure recognition, the lack of isomorphism be-tween different discourse structures does not neces-sarily mean that they are completely independent.This belief that different aspects of discourse wouldbe related, is what led Grosz and Sidner (1986b) topropose a theory that linked what they called the in-tentional structure of discourse, with its linguisticstructure and with the reader or listener?s cognitiveattentional structure.With respect to the different types of discoursestructure considered here, (Lin, 2012) has consid-ered the possibility of systematic relations betweenTeufel?s Argumentative Zone labelling of scientifictexts in a corpus developed for her PhD thesis(Teufel, 1999) and PDTB-style discourse relations,both within and across sentences.
This is certainlyworth additional study, for the value it can bring toautomated methods of discourse structure recogni-tion.4.4 Intentional structureWhen computational discourse processing turnedto machine learning methods based on reliably-identifiable features, it abandoned (at least temporar-ily) the centrality of pragmatics and speaker in-tentions to discourse.
That is, there were few orno features that directly indicated or could serveas reliable proxies for what role speaker intendedhis/her utterance to play in the larger discourse.
Butboth Niekrasz?
work on meeting segmentation (Sec-tion 4.1) and the discussion in Section 4.2 of errataand variability in their labelling draws new attentionto this old question, and not just to Moore and Pol-lack?s observation (Section 3) that intentional andinformational characterizations may confer differ-ent, non-isomorphic structures over a text.
It mayalso be the case that neither structure may provide acomplete cover: A new visit is warranted.4.5 Discourse and inferenceNot only were intentions abandoned in the moveto data-intensive methods, so was inference and is-sues of how readers and listeners recover informa-tion that isn?t explicit.
What?s missing can be anunmentioned event, with classic examples comingfrom the restaurant script (Lehnert, 1977), wheresomeone enters a restaurant, sits down at a ta-ble and gives their order to a waiter, where un-mentioned inter alia is an event in which the per-son becomes informed of what items the restauranthas to offer, say through being given a menu.
Orit can be an unmentioned fact, such as that pro-gram trading involves the computer-executed trad-ing of a basket of fifteen or more stocks.
Thelatter explains the annotation of an implicit EX-PANSION.RESTATEMENT.GENERALIZATION rela-tion between the two sentences in(15) ?You?re not going to stop the idea of trading abasket of stocks,?
says Vanderbilt?s Prof.
Stoll.
?Program trading is here to stay, and computersare here to stay, and we just need to understandit.?
[wsj 0118]The problem here with inference is when labellingan implicit coherence relation requires inferred in-formation about its arguments, those arguments mayhave quite different features than when all the infor-mation needed to label the relation is explicit.5 ConclusionThere are still large challenges ahead for compu-tational discourse modelling.
But we are hopefulthat greater openness to how information is con-veyed through discourse, as well as richer modellingtechniques developed for other problems, will allowneeded progress to be made.
If we can improve sys-tem performance in recognizing the roles that utter-ances are meant to play in discourse in one genre,perhaps it will help us generalize and transport thisintention recognition between genres.
We also hopefor progress in finding more ways to take advantageof unannotated data in discourse research; in un-derstanding more about inter-dependencies betweenfeatures of different types of discourse structure; incontinuing to carry out related computational dis-course research and development in multiple lan-guages and genres, so as to widen the access to theknowledge gained; and in exploiting discourse inLanguage Technology applications, including infor-mation extraction and SMT.49ReferencesShashank Agarwal and Hong Yu.
2009.
Automati-cally classifying sentences in full-text biomedical arti-cles into introduction, methods, results and discussion.Bioinformatics, 25(23):3174?3180.Amal Al-Saif and Katja Markert.
2010.
The Leeds Ara-bic Discourse Treebank: Annotating discourse con-nectives for Arabic.
In Proceedings, 7th InternationalConference on Language Resources and Evaluation(LREC 2010).Amal Al-Saif and Katja Markert.
2011.
Modelling dis-course relations for Arabic.
In Proceedings, EmpiricalMethods in Natural Language Processing, pages 736?747.Nicholas Asher and Alex Lascarides.
2003.
Logicsof Conversation.
Cambridge University Press, Cam-bridge UK.Yves Bestgen.
2006.
Improving text segmentation us-ing Latent Semantic Analysis: A reanalysis of Choi,Wiemer-Hastings, and Moore (2001).
ComputationalLinguistics, 32(1):5?12.Floris Bex and Bart Verheij.
2010.
Story schemes forargumentation about the facts of a crime.
In Proceed-ings, AAAI Fall Symposium on Computational Narra-tives, Menlo Park CA.
AAAI Press.Susan E. Brennan, Marilyn Walker Friedman, and Carl J.Pollard.
1987.
A centering approach to pronouns.
InProceedings of the 25th Annual Meeting, Associationfor Computational Linguistics, pages 155?162, Stan-ford University, Stanford CA.Matthias Buch-Kromann and I?rn Korzen.
2010.
Theunified annotation of syntax and discourse in theCopenhagen Dependency Treebanks.
In Proceedingsof the Fourth Linguistic Annotation Workshop, pages127?131, July.Matthias Buch-Kromann, I?rn Korzen, and Henrik H?egMu?ller.
2009.
Uncovering the ?lost?
structure oftranslations with parallel treebanks.
In Fabio Alves,Susanne Go?pferich, and Inger Mees, editors, Copen-hagen Studies of Language: Methodology, Technol-ogy and Innovation in Translation Process Research,Copenhagen Studies of Language, vol.
38, pages 199?224.
Copenhagen Business School.Jill Burstein and Martin Chodorow.
2010.
Progress andnew directions in technology for automated essay eval-uation.
In R Kaplan, editor, The Oxford Handbook ofApplied Linguistics, pages 487?497.
Oxford Univer-sity Press, 2 edition.Jill Burstein, Daniel Marcu, and Kevin Knight.
2003.Finding the WRITE stuff: Automatic identification ofdiscourse structure in student essays.
IEEE IntelligentSystems: Special Issue on Advances in Natural Lan-guage Processing, 18:32?39.Chris Callison-Burch, Miles Osborne, and PhilippKoehn.
2006.
Re-evaluating the role of bleu in ma-chine translation research.
In 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, pages 249?256, Trento, Italy.Chris Callison-Burch.
2008.
Syntactic constraintson paraphrases extracted from parallel corpora.
InEMNLP ?08: Proceedings of the Conference on Em-pirical Methods in Natural Language Processing.Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski.2003.
Building a discourse-tagged corpus in theframework of rhetorical structure theory.
In J. vanKuppevelt & R. Smith, editor, Current Directions inDiscourse and Dialogue.
Kluwer, New York.Nathanael Chambers and Dan Jurafsky.
2008.
Unsuper-vised learning of narrative event chains.
In Proceed-ings, Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies,pages 789?797.Eugene Charniak and Micha Elsner.
2009.
Em worksfor pronoun anaphora resolution.
In Proc.
EuropeanChapter of the Association for Computational Linguis-tics.Harr Chen, S. R. K. Branavan, Regina Barzilay, andDavid Karger.
2009.
Global models of documentstructure using latent permutations.
In Proceedings,Annual Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL), pages 371?379.Freddy Y. Y. Choi, Peter Wiemer-Hastings, and JohannaMoore.
2001.
Latent Semantic Analysis for text seg-mentation.
In EMNLP ?01: Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 109?117.Grace Chung.
2009.
Sentence retrieval for abstracts ofrandomized controlled trials.
BMC Medical Informat-ics and Decision Making, 10(9), February.Iria da Cunha, Juan-Manuel Torres-Moreno, and GerardoSierra.
2011.
On the development of the rst spanishtreebank.
In Proc.
5th Linguistic Annotation Work-shop, pages 1?10, Portland OR.Quang Xuan Do, Yee Seng Chan, and Dan Roth.
2011.Minimally supervised event causality identification.In Proceedings, Conference on Empirical Methods inNatural Language Processing, pages 294?303.James Eales, Robert Stevens, and David Robertson.2008.
Full-text mining: Linking practice, protocolsand articles in biological research.
In Proceedings ofthe BioLink SIG, ISMB 2008.Jacob Eisenstein and Regina Barzilay.
2008.
Bayesianunsupervised topic segmentation.
In EMNLP ?08:Proceedings of the Conference on Empirical Methodsin Natural Language Processing, pages 334?343.50Robert Elwell and Jason Baldridge.
2008.
Dis-course connective argument identication with connec-tive specic rankers.
In Proceedings of the IEEE Con-ference on Semantic Computing (ICSC-08).Mark Finlayson.
2009.
Deriving narrative morphologiesvia analogical story merging.
In Proceedings, 2nd In-ternational Conference on Analogy, pages 127?136.Katherine Forbes-Riley, Bonnie Webber, and AravindJoshi.
2006.
Computing discourse semantics: Thepredicate-argument semantics of discourse connec-tives in D-LTAG.
Journal of Semantics, 23:55?106.George Foster, Pierre Isabelle, and Roland Kuhn.
2010.Translating structured documents.
In Proceedings ofAMTA.Michel Galley, Kathleen McKeown, Eric Fosler-Lussier,and Hongyan Jing.
2003.
Discourse segmentation ofmulti-party conversation.
In Proceedings of the 41stAnnual Conference of the Association for Computa-tional Linguistics.Sucheta Ghosh, Sara Tonelli, Giuseppe Riccardi, andRichard Johansson.
2011.
End-to-end discourseparser evaluation.
In Proceedings, IEEE Conferenceon Semantic Computing (ICSC-11).Barbara Grosz and Candace Sidner.
1986a.
Attention,intention and the structure of discourse.
Computa-tional Linguistics, 12(3):175?204.Barbara Grosz and Candace Sidner.
1986b.
Attention,intention and the structure of discourse.
Computa-tional Linguistics, 12(3):175?204.Barbara Grosz and Candace Sidner.
1990.
Plans for dis-course.
In Philip Cohen, Jerry Morgan, and MarthaPollack, editors, Intentions in Communication, pages417?444.
MIT Press.Barbara Grosz, Aravind Joshi, and Scott Weinstein.1986.
Towards a computational theory of dis-course interpretation.
Widely circulated unpublishedmanuscript.Barbara Grosz, Aravind Joshi, and Scott Weinstein.1995.
Centering: A framework for modelling the lo-cal coherence of discourse.
Computational Linguis-tics, 21(2):203?225.Yufan Guo, Anna Korhonen, Maria Liakata, Ilona Silins,Lin Sun, and Ulla Stenius.
2010.
Identifying the infor-mation structure of scientific abstracts.
In Proceedingsof the 2010 BioNLP Workshop, July.Marti Hearst.
1997.
TextTiling: Segmenting text intomulti-paragraph subtopic passages.
ComputationalLinguistics, 23(1):33?64.Kenji Hirohata, Naoki Okazaki, Sophia Ananiadou, andMitsuru Ishizuka.
2008.
Identifying sections in scien-tic abstracts using conditional random fields.
In Pro-ceedings of the 3rd International Joint Conference onNatural Language Processing, pages 381?388.W.
Lewis Johnson and Jeff Rickel.
2000.
Animated ped-agogical agents: Face-to-face interaction in interactivelearning environments.
Int?l J.
Artificial Intelligencein Education, 11:47?78.Dan Jurafsky and James Martin.
2009.
Speech and Lan-guage Processing.
Prentice-Hall, Englewood CliffsNJ, 2 edition.Min-Yen Kan, Judith Klavans, and Kathleen McKeown.1998.
Linear segmentation and segment significance.In Proceedings of the Sixth Workshop on Very LargeCorpora.Andrew Kehler.
1997.
Current theories of centering forpronoun intepretation: A critical evaluation.
Compu-tational Linguistics, 23(3):467?475.Rodger Kibble and Richard Power.
2000.
An integratedframework for text planning and pronominalisation.
InProc.
of the First International Conference on NaturalLanguage Generation, pages 77?84, Mitzpe Ramon,Israel, June.Su Nam Kim, David Martinez, and Lawrence Cavedon.2010.
Automatic classification of sentences for evi-dence based medicine.
In Proc.
ACM 4th Int?l Work-shop on Data and Text Mining in Biomedical informat-ics, pages 13?22.Alistair Knott, Jon Oberlander, Mick O?Donnell, andChris Mellish.
2001.
Beyond elaboration: Theinteraction of relations and focus in coherent text.In T Sanders, J Schilperoord, and W Spooren, ed-itors, Text Representation:Linguistic and psycholin-guistic aspects, pages 181?196.
John Benjamins Pub-lishing.Wendy Lehnert.
1977.
A conceptual theory of questionanswering.
In Proc 5th International Joint Conferenceon Artificial Intelligence, pages 158?164.Maria Liakata, Simone Teufel, Advaith Siddharthan, andColin Batchelor.
2010.
Corpora for the conceptuali-sation and zoning of scientific papers.
In Proceedingsof the 7th International Conference on Language Re-sources and Evaluation (LREC 2010).Jimmy Lin, Damianos Karakos, Dina Demner-Fushman,and Sanjeev Khudanpur.
2006.
Generative contentmodels for structural analysis of medical abstracts.
InProceedings of the HLT-NAACL Workshop on BioNLP,pages 65?72.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan.2010.
A PDTB-styled end-to-end discourseparser.
Technical report, Department of Com-puting, National University of Singapore, November.http://arxiv.org/abs/1011.0835.Ziheng Lin.
2012.
Discourse Parsing: Inferring Dis-course Structure, Modelling Coherence, and its Appli-cations.
Ph.D. thesis, National University of Singa-pore.51Igor Malioutov and Regina Barzilay.
2006.
Minimumcut model for spoken lecture segmentation.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and the 44th annual meeting ofthe Association for Computational Linguistics.Jean Mandler.
1984.
Stories, scripts, and scenes: As-pects of schema theory.
Lawrence Erlbaum Asso-ciates, Hillsdale NJ.William Mann and Sandra Thompson.
1988.
RhetoricalStructure Theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.Daniel Marcu.
2000a.
The rhetorical parsing of unre-stricted texts: A surface-based approach.
Computa-tional Linguistics, 26(3):395?448.Daniel Marcu.
2000b.
The theory and practice of dis-course parsing and summarization.
MIT Press.Mstislav Maslennikov and Tat-Seng Chua.
2007.
Amulti-resolution framework for information extractionfrom free text.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 592?599.
Association for ComputationalLinguistics.Larry McKnight and Padmini Srinivasan.
2003.
Cate-gorization of sentence types in medical abstracts.
InProceedings of the AMIA Annual Symposium, pages440?444.Yoko Mizuta, Anna Korhonen, Tony Mullen, and NigelCollier.
2006.
Zone analysis in biology articles as abasis for information extraction.
International Journalof Medical Informatics, 75:468487.Lucie Mladova?, S?a?rka Zika?nova?, and Eva Hajic?ova?.2008.
From sentence to discourse: Building an an-notation scheme for discourse based on the Prague De-pendency Treebank.
In Proceedings of the 6th Interna-tional Conference on Language Resources and Evalu-ation (LREC 2008).Johanna Moore and Martha Pollack.
1992.
A problemfor RST: The need for multi-level discouse analysis.Computational Linguistics, 18(4):537?544.Johanna Moore.
1995.
Participating in Explanatory Di-alogues.
MIT Press, Cambridge MA.Megan Moser and Johanna Moore.
1996.
Toward a syn-thesis of two accounts of discourse structure.
Compu-tational Linguistics, 22(3):409?419.Vincent Ng.
2010.
Supervised noun phrase coreferenceresearch: The first 15 years.
In Proc.
48th AnnualMeeting of the Association for Computational Linguis-tics, pages 1396?1411, Uppsala, Sweden.John Niekrasz.
2012.
Toward Summarization of Com-municative Activities in Spoken Conversation.
Ph.D.thesis, University of Edinburgh.Umangi Oza, Rashmi Prasad, Sudheer Kolachina,Dipti Misra Sharma, and Aravind Joshi.
2009.
Thehindi discourse relation bank.
In Proc.
3rd ACL Lan-guage Annotation Workshop (LAW III), Singapore, Au-gust.Raquel Mochales Palau and Marie-Francine Moens.2009.
Argumentation mining: the detection, classifi-cation and structure of arguments in text.
In Proc.
12thInternational Conference on Artificial Intelligence andLaw, ICAIL ?09, pages 98?107.
ACM.Martha Palmer, Carl Weir, Rebecca Passonneau, and TimFinin.
1993.
The kernal text understanding system.Artificial Intelligence, 63:17?68.Thiago Alexandre Salgueiro Pardo, Maria das GracasVolpe Nunes, and Lucia Helena Machado Rino.
2008.Dizer: An automatic discourse analyzer for brazilianportuguese.
Lecture Notes in Artificial Intelligence,3171:224?234.Renate Pasch, Ursula Brausse, Eva Breindl, and UlrichWassner.
2003.
Handbuch der deutschen Konnek-toren.
Walter de Gruyter, Berlin.Siddharth Patwardhan and Ellen Riloff.
2007.
Effectiveinformation extraction with semantic affinity patternsand relevant regions.
In Proceedings of the 2007 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP-07).Emily Pitler, Annie Louis, and Ani Nenkova.
2010.Automatic evaluation of linguistic quality in multi-document summarization.
In Proc., 48th AnnualMeeting of the Association for Computational Linguis-tics, pages 544?554, Uppsala, Sweden.Massimo Poesio, Rosemary Stevenson, Barbara Di Eu-genio, and Janet Hitzeman.
2004.
Centering: A para-metric theory and its instantiations.
ComputationalLinguistics, 30(3):300?363.Livia Polanyi and Martin H. van den Berg.
1996.Discourse structure and discourse interpretation.
InP.
Dekker and M. Stokhof, editors, Proceedings of theTenth Amsterdam Colloquium, pages 113?131, Uni-versity of Amsterdam.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, and et al 2008.
The Penn Discourse Treebank2.0.
In Proceedings of the 6th International Confer-ence on Language Resources and Evaluation.Rashmi Prasad, Aravind Joshi, and Bonnie Webber.2010a.
Exploiting scope for shallow discourse pars-ing.
In Proceedings of the 7th International Confer-ence on Language Resources and Evaluation (LREC2010).Rashmi Prasad, Aravind Joshi, and Bonnie Webber.2010b.
Realization of discourse relations by othermeans: Alternative lexicalizations.
In Proceed-ings, International Conf.
on Computational Linguis-tics (COLING).Rashmi Prasad, Susan McRoy, Nadya Frid, AravindJoshi, and Hong Yu.
2011.
The Biomedical Discourse52Relation Bank.
BMC Bioinformatics, 12(188):18pages.
http://www.biomedcentral.com/1471-2015/12/188.Matthew Purver, Tom Griffiths, K.P.
Ko?rding, and JoshuaTenenbaum.
2006.
Unsupervised topic modelling formulti-party spoken discourse.
In Proceedings, Inter-national Conf.
on Computational Linguistics (COL-ING) and the Annual Meeting of the Association forComputational Linguistics, pages 17?24.Matthew Purver.
2011.
Topic segmentation.
In GokhanTur and Renato de Mori, editors, Spoken LanguageUnderstanding: Systems for Extracting Semantic In-formation from Speech.
Wiley, Hoboken NJ.Patrick Ruch, Celia Boyer, Christine Chichester, ImadTbahriti, Antoine Geissbu?hler, Paul Fabry, and et al2007.
Using argumentation to extract key sentencesfrom biomedical abstracts.
International Journal ofMedical Informatics, 76(2?3):195?200.David Rumelhart.
1975.
Notes on a schema for stories.In Dan Bobrow and Alan Collins, editors, Representa-tion and Understanding: Studies in Cognitive Science.Academic Press, New York.Magdalena Rysova.
2012.
Alternative lexicalizations ofdiscourse connectives in czech.
In Proc.
8th Int?l Conf.Language Resources and Evaluation (LREC 2012).Roger Schank and Robert Abelson.
1977.
Scripts, Plans,Goals and Understanding: an Inquiry into HumanKnowledge Structures.
Lawrence Erlbaum, HillsdaleNJ.Penni Sibun.
1992.
Generating text without trees.
Com-putational Intelligence, 8(1):102?122.Manfred Stede.
2004.
The Potsdam Commentary Cor-pus.
In ACL Workshop on Discourse Annotation,Barcelona, Spain, July.Manfred Stede.
2008.
RST revisted: Disentangling nu-clearity.
In Cathrine Fabricius-Hansen and WiebkeRamm, editors, ?Subordination?
versus ?Coordination?in Sentence and Text, pages 33?59.
John Benjamins,Amsterdam.Manfred Stede.
2012.
Discourse Processing.
Morgan &Claypool Publishers.Michael Strube.
2007.
Corpus-based and ma-chine learning approaches to anaphora resolution.In Monika Schwarz-Friesel, Manfred Consten, andMareile Knees, editors, Anaphors in Text: Cognitive,formal and applied approaches to anaphoric refer-ence, pages 207?222.
John Benjamins Publishing.Joel Tetreault.
2001.
A corpus-based evaluation of cen-tering and pronoun resolution.
Computational Lin-guistics, 27(4):507?520.Simone Teufel and Marc Moens.
2002.
Summariz-ing scientific articles - experiments with relevance andrhetorical status.
Computational Linguistics, 28:409?445.Simone Teufel, Advaith Siddharthan, and Colin Batche-lor.
2009.
Towards discipline-independent argumen-tative zoning: evidence from chemistry and compu-tational linguistics.
In Proceedings, Conference onEmpirical Methods in Natural Language Processing,pages 1493?1502.Simone Teufel.
1999.
Argumentative Zoning: Informa-tion Extraction from Scientific Text.
Ph.D. thesis, Uni-versity of Edinburgh.Gian Lorenzo Thione, Martin van den Berg, LiviaPolanyi, and Chris Culy.
2004.
Hybrid text summa-rization: combining external relevance measures withstructural analysis.
In Proceedings of the ACL 2004Workshop Text Summarization Branches Out.Sara Tonelli, Guiseppe Riccardi, Rashmi Prasad, andAravind Joshi.
2010.
Annotation of discourse re-lations for conversational spoken dialogs.
In Proc.7th Int?l Conf.
Language Resources and Evaluation(LREC 2010).Nynke van der Vliet, Ildiko?
Berzla?novich, Gosse Bouma,Markus Egg, and Gisela Redeker.
2011.
Building adiscourse-annotated Dutch text corpus.
In BochumerLinguistische Arbeitsberichte, pages 157?171.Steven Vere and Timothy Bickmore.
1990.
A basicagent.
Computational Intelligence, 6(1):41?60.Yannick Versley.
2010.
Discovery of ambiguous and un-ambiguous discourse connectives via annotation pro-jection.
In Workshop on the Annotation and Exploita-tion of Parallel Corpora (AEPC).
NODALIDA.Marilyn Walker, Aravind Joshi, and Ellen Prince.
1997.Centering in Discourse.
Oxford University Press, Ox-ford, England.Bonnie Webber and Aravind Joshi.
1998.
Anchor-ing a lexicalized tree-adjoining grammar for discourse.In Coling/ACL Workshop on Discourse Relations andDiscourse Markers, pages 86?92, Montreal, Canada.Bonnie Webber, Markus Egg, and Valia Kordoni.
2012.Discourse structure and language technology.
NaturalLanguage Engineering.Ben Wellner and James Pustejovsky.
2007.
Automati-cally identifying the arguments of discourse connec-tives.
In Proceedings of the 2007 Conference onEmpirical Methods in Natural Language Processing(EMNLP-07).Ben Wellner.
2008.
Sequence Models and RankingMethods for Discourse Parsing.
Ph.D. thesis, Bran-deis University.Janyce Wiebe.
1993.
Issues in linguistic segmentation.In Workshop on Intentionality and Structure in Dis-course Relations, Association for Computational Lin-guistics, pages 148?151, Ohio StateUniversity.Terry Winograd.
1973.
A procedural model of languageunderstanding.
In Roger Schank and Ken Colby, ed-itors, Computer Models of Thought and Language,53pages 152?186.
W.H.
Freeman.
Reprinted in Groszet al (eds), Readings in Natural Language Processing.Los Altos CA: Morgan Kaufmann Publishers, 1986,pp.249-266.Florian Wolf and Edward Gibson.
2005.
Representingdiscourse coherence: A corpus-based study.
Compu-tational Linguistics, 31:249?287.William Woods.
1968.
Procedural semantics for aquestion-answering machine.
In Proceedings of theAFIPS National Computer Conference, pages 457?471, Montvale NJ.
AFIPS Press.William Woods.
1978.
Semantics and quantification innatural language question answering.
In Advances inComputers, volume 17, pages 1?87.
Academic Press,New York.Nianwen Xue.
2005.
Annotating discourse connectivesin the chinese treebank.
In ACL Workshop on Frontiersin Corpus Annotation II, Ann Arbor MI.Deniz Zeyrek and Bonnie Webber.
2008.
A discourse re-source for Turkish: Annotating discourse connectivesin the METU corpus.
In Proceedings of the 6th Work-shop on Asian Language Resources (ALR6).Deniz Zeyrek, U?mut Deniz Turan, Cem Bozsahin, RuketC?ak?c?, and et al 2009.
Annotating Subordinators inthe Turkish Discourse Bank.
In Proceedings of the 3rdLinguistic Annotation Workshop (LAW III).Deniz Zeyrek, Is?
?n Demirs?ahin, Ay?s??g??
Sevdik-C?all?, Hale O?gel Balaban, I?hsan Yalc?
?nkaya, andU?mut Deniz Turan.
2010.
The annotation schemeof the Turkish Discourse Bank and an evaluation ofinconsistent annotations.
In Proceedings of the 4thLinguistic Annotation Workshop (LAW III).Yuping Zhou and Nianwen Xue.
2012.
Pdtb-style dis-course annotation of chinese text.
In Proc.
50th An-nual Meeting of the ACL, Jeju Island, Korea.54
