2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 396?406,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsLeveraging supplemental representations for sequential transductionAditya BhargavaDepartment of Computer ScienceUniversity of TorontoToronto, ON, Canada, M5S 3G4aditya@cs.toronto.eduGrzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, AB, Canada, T6G 2E8kondrak@cs.ualberta.caAbstractSequential transduction tasks, such asgrapheme-to-phoneme conversion and ma-chine transliteration, are usually addressedby inducing models from sets of input-outputpairs.
Supplemental representations offer valu-able additional information, but incorporatingthat information is not straightforward.
Weapply a unified reranking approach to bothgrapheme-to-phoneme conversion and ma-chine transliteration demonstrating substantialaccuracy improvements by utilizing heteroge-neous transliterations and transcriptions of theinput word.
We describe several experimentsthat involve a variety of supplemental dataand two state-of-the-art transduction systems,yielding error rate reductions ranging from12% to 43%.
We further apply our approach tosystem combination, with error rate reductionsbetween 4% and 9%.1 IntroductionWords exist independently of writing, as abstract enti-ties shared among the speakers of a language.
Thoseabstract entities have various representations, whichin turn may have different realizations.
Orthographicforms, phonetic transcriptions, alternative transliter-ations, and even sound-wave spectrograms are allrelated by referring to the same abstract word andthey all convey information about its pronunciation.Figure 1 shows various representations of the wordDickens.
The primary (canonical) orthographic rep-resentation of the word corresponds to the languageto which the word belongs.
The secondary ortho-graphic representations in different writing scriptsare transliterations of the word, which exhibit phono-orthographyDickens????
????????????????????
?transliterations /d?k?nz/dIkInzD IH K AH N ZdIk@nzd I k x n z?transcriptionsMTL G2PFigure 1: Several NLP tasks involve conversion betweenvarious word representations.
The tasks on which we focusare shown in black.logical adaptation to the target language.
The vari-ous phonetic transcriptions consist of sequences ofphonemes representing the pronunciation of the word.Transcription schemes may differ in the number andcoverage of various phonemes, as well as the choiceof the underlying speech variety.
The spoken pro-nunciation (represented by the waveform) presents acommon latent influence on the representations.Several well-known NLP tasks involve matching,alignment, and conversion between different wordrepresentations.
Grapheme-to-phoneme conversion(G2P) aims at generating a transcription of a wordfrom its orthographic representation.
The reversetask is phoneme-to-grapheme conversion (P2G).
Ma-chine transliteration (MTL) deals with conversion be-tween orthographic representations in different writ-ing scripts; forward transliteration proceeds from theprimary representation to secondary representations,while the reverse task is called back-transliteration(BTL).
The conversion between a sound and an or-thography is the goal of text-to-speech synthesis396(TTS) and speech recognition (SR), where transcrip-tions are often used as intermediate forms.Although both MTL and G2P take orthographicrepresentations as input, the two tasks are rarely con-sidered in conjunction.
Traditionally, G2P has beeninvestigated in the context of text-to-speech systems,while MTL is of interest to the information retrievalandmachine translation communities.
In addition, un-like phonetic transcription schemes, which are oftenspecific to a particular pronunciation lexicon, writingsystems are well-standardized, with plenty of translit-eration examples available in text corpora and onthe Web (Kumaran et al, 2010b).
While the goal ofG2P is producing a maximally faithful representa-tion of the pronunciation, transliterations are ofteninfluenced by other factors, such as the phonologicalconstraints of the target language, the orthographicform in the source language, the morphological adap-tations related to the translation process, and even thesemantic connotations of the output in the case of lo-gographic scripts.
In spite of those differences, bothtranscriptions and transliterations contain valuableinformation about the pronunciation of the word.In this paper, we show that it is possible to improvethe accuracy of both G2P and MTL by incorporatingsupplemental representations of the word pronuncia-tion.
Our method is based on SVM reranking of then-best output lists of a base transduction system, withfeatures including similarity scores between repre-sentations and n-grams derived from accurate align-ments.
We describe a series of experiments in bothG2P and MTL contexts, demonstrating substantialreductions in error rate for these base tasks when aug-mented with various supplemental representations.We then further test the effectiveness of the same ap-proach for combining the results of two independentbase systems.2 Related workBecause of its crucial role in speech synthe-sis, grapheme-to-phoneme conversion has been re-searched extensively.
Most out-of-vocabulary wordsare names, which often exhibit idiosyncratic pronun-ciation (Black et al, 1998).
Excepting languageswith highly transparent orthographies, the numberof letter-to-sound rules appears to grow geometri-cally with the lexicon size, with no asymptotic limit(Kominek and Black, 2006).
A number of machinelearning approaches have been proposed for G2P, in-cluding neural networks (Sejnowski and Rosenberg,1987), instance-based learning (van den Bosch andDaelemans, 1998), pronunciation by analogy (Marc-hand and Damper, 2000), decision trees (Kienappeland Kneser, 2001), hidden Markov models (Taylor,2005), joint n-gram models (Bisani and Ney, 2008),and online discriminative learning (Jiampojamarn etal., 2008).
The current state-of-the-art is representedby the latter two approaches, which are available asthe SEQUITUR and DIRECTL+ systems, respectively.Machine transliteration has also received much at-tention (Knight and Graehl, 1998; Li et al, 2004;Sproat et al, 2006; Klementiev and Roth, 2006; Ze-lenko and Aone, 2006).
In the last few years, theNamed Entities Workshop (NEWS) Shared Tasks onTransliteration have been the forum for validatingdiverse approaches on common data sets (Li et al,2009; Li et al, 2010; Zhang et al, 2011).
Both SE-QUITUR and DIRECTL+, originally G2P systems,have been successfully adapted to MTL (Finch andSumita, 2010; Jiampojamarn et al, 2010b).Most of the research on both G2P and MTL as-sumes the existence of a homogeneous training set ofinput-output pairs.
However, following the pivot ap-proaches developed in other areas of NLP (Utiyamaand Isahara, 2007; Cohn and Lapata, 2007; Wu andWang, 2009; Snyder et al, 2009), the idea of tak-ing advantage of other-language data has recentlybeen applied to machine transliteration.
Khapra etal.
(2010) construct a transliteration system betweenlanguages A and B by composing two transliterationsystems A ?
C and C ?
B, where C is calleda bridge or pivot language, resulting in a relativelysmall drop in accuracy.
Zhang et al (2010) and Ku-maran et al (2010a) report that combinations of pivotsystems A ?
C ?
B with direct systems A ?
Bproduce better results than using the direct systemsonly.
The models, which are composed using a linearcombination of scores, utilize a single pivot languageC, and require training data between all three lan-guages A, B, and C. However, such a pivot-basedframework makes it difficult to incorporate multiplepivot languages, and has shown most promising re-sults for cases in which data for the original A?
Btask are limited.
Lastly, Finch and Sumita (2010) de-veloped an MTL approach that combined the output397input word n-best outputs re-ranked n-best listSudan sud@nsud{n?sud#nsud#nsUd#n?sud@nsupplementalrepresentationssudAnS UW D AE N??????????????
?base system re-rankerFigure 2: An overview of our approach on an example from the G2P task.
The correct output is shown in bold.of two systems using a linear combination of systemscores and a manually-tuned weight.On the G2P side, Loots and Niesler (2009) investi-gate the problem of leveraging transcriptions from adifferent dialect of English, while Bhargava and Kon-drak (2011) focus on leveraging transliterations frommultiple writing scripts.
Bhargava et al (2011) showthat the reranking method proposed by Bhargava andKondrak (2011) can increase the accuracy of MTL aswell.
In this paper, we aim to confirm the generalityof the same method by testing it on a broad range oftasks: a) leveraging transcriptions for both G2P andMTL; b) utilizing supplemental transcriptions andtransliterations simultaneously; c) improving G2P ingeneral, rather than just G2P of names; and d) com-bining different transduction systems.3 Leveraging supplemental dataIncorporating supplemental information directly intoan existing system is not always feasible.
With gener-ative approaches, one would have to find some way ofmodelling the relationship between the system inputs,outputs, and the supplemental data.
Discriminativeapproaches are not necessarily easier: DIRECTL+, adiscriminative G2P system, needs to be able to gener-ate features on-the-fly for partial grapheme-phonemesequence pairs during the decoding.
Instead, we inte-grate an existing system as a black box that generatesn-best lists of candidate outputs, resulting in a modu-lar and general post hoc approach that can be appliedto multiple tasks and settings.3.1 Task definitionThe task is to convert an input string s into a targetstring t, where both strings are representations of aword w. In G2P, s is a string of graphemes whilet consists of phonemes; in MTL, both s and t aregrapheme sequences, although in different scripts.We assume that we have a base system T (s) that at-tempts this task and produces an n-best list of outputst?1, t?2, .
.
.
, t?n for the input s. T is imperfect, i.e., thecorrect output t may appear in a position in the listother than the first.
It is reasonable to expect that sucha system also provides a list of scores correspondingto the outputs.
We further assume that we have accessto supplemental representations of w; both transliter-ations and transcriptions may serve this purpose.
Ourobjective is to improve the accuracy on the task inquestion with respect to the base system T (s).3.2 RerankingFor the purpose of exposition, we reiterate here theparticulars of the reranking approach of Bhargava andKondrak (2011) that we apply to the various tasks andsupplemental data sources.
The method uses SVMreranking of the n-best lists produced by the base sys-tem in order to to move the correct output to the topof the list using supplemental data.
SVM reranking(Joachims, 2002) facilitates the exploitation of multi-ple sources of supplemental data, as shown in Figure2.
The feature construction process is performed foreach candidate output in the n-best list, as well aseach pairing of a candidate output with a supplemen-tal representation.
The features used for rerankingmay or may not overlap with the features used by the398base system.
While we focus on the G2P and MTLtasks in this paper, this method is general enough asto potentially be applied to other sequence predictiontasks.3.3 AlignmentIn order to construct the feature vectors, we needthe alignments between the alternative representa-tions of the same word.
For the alignment of supple-mental data with candidate outputs, we apply M2M-ALIGNER (Jiampojamarn et al, 2007).
We use thesame method for the alignment between the input andthe candidate outputs, unless the base system alreadyprovides this information.M2M-ALIGNER is a generalization of the learnededit distance algorithm of Ristad and Yianilos (1998).It iteratively refines the alignment of a set ofstring pairs in an unsupervised manner using theexpectation-maximization (EM) approach.
In addi-tion to the alignment, M2M-ALIGNER produces analignment probability, which reflects the similaritybetween two strings.
Intuitively, if two strings containsymbols or n-grams that often co-occur in the train-ing data, their alignment score will be higher.
Thestrings in question are often of completely differentscripts, which precludes the application of standardsimilarity measures such as Levenshtein distance.3.4 Score featuresThe similarity of candidate outputs to alternative rep-resentations of a word is probably the most intuitivefeature for reranking.
We include a real-valued simi-larity feature for each pairing between a supplementalrepresentation and a candidate output, which is setaccording to the M2M-ALIGNER alignment score.Another important set of features are the confi-dence scores assigned to each candidate output bythe base system.
In addition to the original scores, wealso include a set of features that indicate the differ-ences between scores for all pairs of outputs in then-best list.
This allows the reranker to incorporate anotion of relative confidence with respect to the othercandidate outputs.
Similarly, we compute differencesbetween the similarity scores of candidate outputsand supplemental representations.3.5 N -gram featuresFollowing (Jiampojamarn et al, 2010a), we includeseveral types of n-gram features.
The features aredefined on substrings occurring in pairs of alignedstrings.
Each feature is binary, indicating the presenceor absence of the particular feature type in the givenaligned pair, which could be either the original basesystem?s input and output, or else a candidate outputand a supplemental representation.We can divide the n-gram features into four cate-gories.
Context features bind an output symbol withinput n-grams in a focus window centred around theinput-output alignment; the input n-grams representthe context in which the output character is gener-ated.
Markov features are n-grams of output symbols,which allow previously generated output charactersto influence the current output character.
Linear chainfeatures associate the context and Markov features.Joint n-gram features combine aligned input and out-put n-grams of the same length on both sides.In the standard string transduction task, the outputstring t is generated incrementally from the inputs.
In contrast, in the reranking setting, both stringsare complete and available.
This allows us to reversethe direction of the context and linear chain features,allowing us to associate output n-grams with singleinput symbols.
In addition, we can apply those fea-tures in both directions across candidate outputs andsupplemental representations, further increasing theamount of information provided to the reranker.4 ExperimentsOur experiments aim at comprehensive evaluationof the reranking approach on both MTL and G2Ptasks, employing various supplemental representa-tions.
Relevant code and scripts associated with ourexperimental results are available online1.4.1 DataWe extract transcriptions from two lexica: Combilex(Richmond et al, 2009), which includes both Re-ceived Pronunciation (RP) and General American(GA) pronunciation variants, and CELEX (Baayen etal., 1996), which includes RP only.
After discardingduplicates and letter diacritics, the total number of1http://www.cs.toronto.edu/?aditya/g2p-tl-rr399Language Corpus size Japanese OverlapBengali 13,624 2,152Chinese 40,214 14,056Hebrew 10,501 3,997Hindi 13,427 2,507Japanese 28,013 ?Kannada 11,540 2,170Korean 7,778 7,733Persian 12,386 4,047Tamil 11,642 2,205Thai 28,932 10,378Table 1: The number of unique entries in each translit-eration corpus, and the number of common single-wordentries (overlap) with the Japanese corpus.word-transcription pairs are 114,094 for Combilex,and 66,859 for CELEX.
We use 10% of the data fordevelopment, 10% for testing, and the remaining 80%for training.
The development set is merged with thetraining set for final testing.Our transliteration data come from the shared tasksof the 2011 NEWS workshop (Zhang et al, 2011).The number of entries in each transliteration corpusis shown in the middle column of Table 1.4.2 Base systemsIn order to verify the generality of our approach,we perform all experiments using two different basetransduction systems described in Section 2: SE-QUITUR and DIRECTL+.
Both systems are set toprovide 10-best output lists along with scores foreach output.2 SEQUITUR is modified to providelog-probabilities instead of regular probabilities.
DI-RECTL+ is run with the complete set of featuresdescribed by Jiampojamarn et al (2010a).
Systemparameters, such as maximum number of iterations,are determined during development.M2M-ALIGNER is used throughout for the align-ment of various representations.
The aligner is trainedon an intersection of a relevant pair of data sets.
Forexample, the intersection of the English-to-Japaneseand English-to-Hindi corpora on the basis of common2While running times prevented us from extensively ana-lyzing reranking performance vs. n-best list size, our initialtests produced almost identical results for n = 5, n = 10, andn = 20.entries on the English side yields a corpus matchingJapanese transliterations with Hindi transliterations.M2M-ALIGNER, after having been trained on thiscorpus, is able to produce a similarity score for anarbitrary Japanese-Hindi pair.
We set a lower limitof ?100 on the M2M-ALIGNER log-probabilities,and use the default of 2-2 alignments; deletions areenabled for the supplemental data side of the align-ment.4.3 MTL experimentsWhen faced with the task of transliterating a wordfrom the original script to a secondary script, wewould like to leverage the information encoded intransliterations of the same word that are availablein other scripts.
For example, consider the problemof automatically generating a Wikipedia stub article3in Hindi about guitarist John Petrucci.
We assumethat we have access to an MTL system trained on theEnglish-Hindi transliterations, but we also want totake advantage of the existing transliterations of thename that are easy to extract from the correspondingarticles on the topic in Japanese and other languages.In this case, the orthography of the last name reflectsits Italian origins, but the pronunciation depends onits degree of assimilation to English phonology.
Thistype of information is often difficult to determineeven for humans, and we posit that it may be inferredfrom other transliterations.Similarly, phonetic transcriptions more directly en-code the pronunciation and thus present an importantresource for exploitation.
In fact, some transliterationsystems use a phonetic transcription as an interme-diate representation (Knight and Graehl, 1998), al-though these methods do not generally fare as wellas those that perform the transliteration process di-rectly (Al-Onaizan and Knight, 2002; Li et al, 2009).Transcriptions are often available; larger pronuncia-tion dictionaries contain tens of thousands of entries,including some proper names (for which machinetransliteration is most relevant), and many names inWikipedia are accompanied by an IPA transcription.Our first experiment aims at improving the translit-eration accuracy from English to Japanese Katakana.The English-Japanese corpus has one of the largestoverlaps (number of entries with a common input)3A stub article is a skeleton article with little content.400SEQUITUR DIRECTL+Acc.
ERR Acc.
ERRBASE 49.6 51.1RERANKED 56.2 13.5 57.3 12.7ORACLE 85.0 70.3 80.4 60.0Table 2: Word accuracies and error rate reductions (ERR)in percentages for English-to-Japanese MTL augmentedby corresponding transliterations from other languages.BASE is the base system while RERANKED represents thesame system with its output reranked using supplementaltransliterations.
ORACLE represents an oracle reranker.with the other transliteration and transcription cor-pora, the former of which is shown in Table 1.
Intotal, there are 18,505 entries for which at least onetransliteration from a non-Japanese language is avail-able and 6,288 for which at least one transcription isavailable.
The reranker is trained on an intersectionof the English-Japanese training set and the supple-mental data; similarly, the reranking test set is anintersection of the English-Japanese test set and thesupplemental data.
Note that we compute word ac-curacy on these intersected sets, so the results of thebase systems that we report here may not representtheir performance on the full data set.Table 2 shows the results4 on the test set of 1,891entries, including the performance of an oracle (per-fect) reranker for comparison.
This same approachapplied to the English-to-Hindi transliteration taskyields an error rate reduction of 9% over the baseperformance of DIRECTL+ (Bhargava et al, 2011)5,which confirms that our reranking method?s applica-bility is not limited to a particular language.In the second experiment, instead of supplementaltransliterations, we use supplemental transcriptionsfrom the RP and GA Combilex corpora as well asCELEX.
The number of common elements with theEnglish-Japanese transliteration corpus was 6,288for Combilex and 2,351 for CELEX; in total, therewere 6,384 transliteration entries for which at least4Unless otherwise noted, all improvements reported in thispaper are statistically significant with p < 0.01 using the McNe-mar test.5Note that this result is computed over the full English-Hindidata set, so is in fact slightly diluted compared to the results wepresent here.SEQUITUR DIRECTL+Acc.
ERR Acc.
ERRBASE 57.9 58.6RERANKED 65.6 18.4 63.9 12.8ORACLE 89.9 51.5 84.6 62.6Table 3: Word accuracies and error rate reductions (ERR)in percentages for English-to-Japanese MTL augmentedby corresponding transcriptions.one transcription was available.
Table 3 shows theresults, giving a similar error rate reduction as forusing supplemental transliterations.Surprisingly, if we proceed to the next logical stepand use both transcriptions and transliterations assupplemental representations simultaneously, the er-ror rate reduction is slightly lower than in the abovetwo experiments.
This difference is so small as tobe statistically insignificant.
We have no convincingexplanation for this phenomenon, although we notethat, in general, significant heterogeneity in data canincrease the difficulty of a given task.4.4 G2P experimentsConsider the example of an automatic speech synthe-sis system tasked with generating an audio version ofa news article that contains foreign names.
Often, for-eign versions of the same news article already exist;in these, the namewill have been transliterated.
Thesetransliterations could then be leveraged to guide thesystem?s pronunciation of the name.
The same is con-ceivable of other types of words, although translitera-tions are generally mostly available for names only.On the other hand, transcription schemes are notconsistent across different pronunciation lexica.
Theirphonemic inventories often differ, and it is not alwayspossible to construct a consistent mapping betweenthem.
In addition, because of pronunciation variationand dialectal differences, a substantial fraction oftranscriptions fail to match across dictionaries.
Nev-ertheless, if a phonetic transcription is already avail-able, even in an alternative format, it could facilitatethe task of generating a new pronunciation.The first G2P experiment concerns the applicationof supplemental transcriptions.
The goal is to quan-tify the improvements achieved using our reranking401approach, and to compare reranking to two othermethods of utilizing supplemental transcriptions, towhich we refer as MERGE and P2P, respectively.MERGE implements the most intuitive approachof merging different lexica into a single training set.In order to make this work, we first need to makesure that all data is converted to a single transcriptionscheme.
Combilex and CELEX make different dis-tinctions among phonemes, making it unclear howsome phonemes might be mapped from CELEX intoCombilex; fortuitously, the opposite conversion ismore agreeable.6 This allows us to convert Combilexto CELEX?s format via a simple rule-based scriptand then merge the two corpora together.
This pro-vides an alternative method against which we cancompare our reranking-based approach which wouldtreat Combilex as a source of supplemental represen-tations.P2P is a phoneme-to-phoneme conversion ap-proach inspired by the work of Loots and Niesler(2009).
In that approach, a phoneme-to-phonememodel is derived from a training set of phonetic tran-scription pairs representing two different pronuncia-tion lexicons.
We use such model to convert the Com-bilex transcriptions to the scheme used by CELEXfor the words that are missing from CELEX.
WhereLoots and Niesler (2009) use decision trees for boththe base system and the corpus converter, we use themuch higher-performing state-of-the-art SEQUITURand DIRECTL+ systems.The two transcription corpora have 15,028 en-tries in common.
As with the MTL experiments, thereranker is trained on an intersection of the CombilexG2P data and the supplemental data.The results on the intersected set of 1,498 wordsare shown in Table 4.
We can see that merging thecorpora provides a clear detriment in performancefor data where an alternative transcription is avail-able from another corpus.
Even if we look at the fullCELEX test set (as opposed to the intersected subsetused in Table 4), DIRECTL+ trained only on CELEXachieves 93.0% word accuracy on the CELEX testset where DIRECTL+ trained on CELEX mergedwith Combilex achieves 87.3%.
Evidently, the dis-6In particular, Combilex distinguishes between [l] and thevelarized (?dark?)
[ l&].
These can be collapsed into the single/l/ phoneme for CELEX, but it is not clear how to handle theconversion in the reverse direction.SEQUITUR DIRECTL+Acc.
ERR Acc.
ERRBASE 87.3 88.1MERGE 74.2 ?
71.6 ?P2P 85.7 ?
87.0 ?RERANKED 92.7 42.9 92.0 32.6ORACLE 97.6 81.2 96.7 72.5Table 4: Word accuracies and error rate reductions (ERR)in percentages for CELEX G2P augmented by Combilextranscriptions.parate conventions of the two corpora ?confuse?
thebase G2P systems.
In contrast, our reranker performswell, yielding spectacular error reductions of 32%and 42%.The differences between the two corpora accountfor the inadequate performance of the P2P approach.Inducing a full transduction model requires muchmore training data that simply reranking the exist-ing outputs, but in this case models for these twoapproaches (P2P and reranking) are trained on thesame amount of data.
Furthermore, when the supple-mental transcription is radically different from then-best outputs, the alignment simply fails, and thereranking approach gracefully falls back to the origi-nal G2P model.
In contrast, the P2P approach has nosuch option.It may be interesting to note what happens whenthe P2P model is replaced with our rule-basedCombilex-to-CELEX converter.
Such an approachhas the advantage of being fast and not dependent onthe training of any base system.
However, it achievesonly 64.8% word accuracy, which is lower than anyof the results in Table 4.
Clearly, a simple mappingscript fails to capture the differences between thecorpora.Turning to supplemental transliterations, Bhargavaand Kondrak (2011) have already shown that supple-mental transliterations can improve G2P accuracy onnames.
It is interesting to verify whether this conclu-sion also applies to other types of words that occurin the G2P data set.
Performing this test with DI-RECTL+ as the base system shows good error ratereduction on names (about 12%) as reported, but amuch smaller statistically insignificant error rate re-402duction on core vocabulary words (around 2%).
Inother words, the supplemental transliterations areable to help only for names.This discrepancy is attributable to the fact thatnames (and, more generally, named entities) are theraison d?e?tre of transliterations.
Because the pro-cess of transliteration occurs primarily for namesthat must be ?translated?
phonetically, we expecttransliterations?
utility as supplemental representa-tions to apply mostly for names.
The smaller num-ber of transliterations for core vocabulary words alsomakes it difficult for any system to learn how to applytransliterations of such words.4.5 Base system mattersWhile our SVM reranking approach demonstratessignificant improvements for all tasks and all testedbase systems, the magnitude of the performance in-crease is dependent on the base system.
In particular,we see a common thread recurring throughout allexperiments: SEQUITUR sees higher improvementsthan does DIRECTL+.
Although reranking treats thebase system as a black box, we are limited by theamount of room for improvement available in thebase system?s outputs.
Our results above show thatthe performance of an oracle reranker (a rerankerthat automatically selects the correct output fromthe n-best list) is consistently higher for SEQUITURthan for DIRECTL+.
Higher oracle reranker scoresindicate greater reranking potential, and we observea corresponding higher error reduction, sometimesleading SEQUITUR to outperform DIRECTL+ afterreranking despite having been the lower performerprior to reranking.We hypothesize that another reason for the greaterinfluence of reranking on SEQUITUR is the fact thatthe reranker?s features are related to those used inDIRECTL+.
Because SEQUITUR implements a dia-metrically different, generative approach to transduc-tion, it benefits more from reranking.
However, DI-RECTL+ still sees significant performance increasesdespite the feature similarity, which demonstratesthat the supplemental representations do provide use-ful additional information.4.6 System combinationAlthough the reranking approach was developed forthe purpose of leveraging supplemental data, it canSEQUITUR DIRECTL+Acc.
ERR Acc.
ERRBASE 45.5 47.3LINCOMB 49.4 7.2 49.4 4.0RERANKED 50.2 8.7 49.2 3.7ORACLE 82.4 67.7 77.3 56.9Table 5: Word accuracies and error rate reductions (ERR)in percentages for English-to-Japanese MTL augmentedby predicted transliterations from the other base system.also increase the accuracy when no genuine supple-mental data is available.
The idea is to perform sys-tem combination by treating the output of one ofthe systems as the supplemental data for the othersystem, effectively casting the system combinationproblem into our reranking framework.
In our lastexperiment, we test the combination of DIRECTL+and SEQUITUR for English-to-Japanese MTL by des-ignating either of them as the base system.
Since thesupplemental data are generated, we are not limitedto a particular subset, and can conduct the experimenton the entire English-to-Japanese set, with the test sethaving 2,801 entries.
For comparison, we also test alinear combination of the (normalized) system scoreswith a manually tuned weight parameter (LINCOMB).This baseline is similar to the system combinationmethod of Finch and Sumita (2010).Table 5 contains the results for English-to-Japanese transliterations, which indicate a significantincrease in accuracy in both cases, thereby demon-strating the viability of our approach for system com-bination.
This experiment extends the system com-bination result on English-to-Hindi transliterationreported by Bhargava et al (2011), in which DI-RECTL+ served as the base system while SEQUITURprovided the supplemental data.
The system in ques-tion yielded nearly a 4% error rate reduction, whichmade it the top-ranking submission at the NEWS2011 Shared Task on Transliteration.On the other hand, LINCOMB turns out to be astrong baseline, which is evidenced by the fact thatthe differences between our reranking approach andLINCOMB are statistically insignificant.
This is likelybecause LINCOMB can take advantage of the fulln-best lists provided by both systems, whereas the403reranking approach uses only the top-1 result fromthe ?supplemental?
system.
Combining the two n-best lists in this way also gives a higher oracle scoreof 86.4%, suggesting that this may be a good andcomputationally cheap first step prior to rerankingusing proper supplemental data as described above.5 Future workWe plan on investigating a more parsimoniousmethod of incorporating supplemental data.
Thereare two aspects to this.
First, while our experiments inthis paper treated base systems as black boxes for thepurposes of examining the effect of the supplemen-tal data in isolation, reranking is limited by its posthoc nature.
After all, if the correct output does notappear in the base systems?
n-best list, even a perfectreranker would be unable to find it.
Incorporating thesupplemental data earlier in the process would allowus to overcome this limitation at the expense of beinga solution specific to the base system.Second, we would like to be able to incorporategeneral supplemental information rather than beinglimited by the existence of relevant data.
In partic-ular, a good transliteration model should encode ageneral version of the information provided by a sin-gle transliteration, so being able to apply that infor-mation would allow us to overcome our dependenceon existing data as well as provide more potentiallyuseful information even when a transliteration or tran-scription already exists.Finally, we plan on examining other potential sup-plemental resources.
Given the success of our ap-proach in the face of sometimes-noisy transliterationdata7, other noisy data may be applicable as well.For example, IPA transcriptions could be mined fromWikipedia despite the fact that different transcrip-tions may have been written by different people.
Sim-ilarly, difficult-to-pronounce names or words are of-ten accompanied by ad hoc approximately-phoneticre-spellings, which may also prove useful.6 ConclusionIn this paper, we examined the relevance of alter-native, supplemental representations for the tasks7Jiampojamarn et al (2009) found a significant increase inEnglish-to-Hindi transliteration performance after applying asimple rule-based cleaning script.of grapheme-to-phoneme conversion and machinetransliteration, both of which have pronunciationas an important underlying influence.
We appliedan SVM reranking approach that leverages the sup-plemental data using features constructed from n-grams as well as from similarity and system scores.The approach yielded excellent improvements whenused with both the SEQUITUR and DIRECTL+ basesystems.
Over the state-of-the-art DIRECTL+, weachieved significant error rate reductions of 13%for English-to-Japanese MTL using supplementaltransliterations, 13% using supplemental transcrip-tions, and 33% for English G2P using supplementaltranscriptions.
For system combination, we found asmaller but still significant error rate reduction of 4%.The fact that the improvements vary systematicallyby base system help confirm that the supplementaldata do provide inherently useful information.We can also take a step back to take a broaderlook at our approach.
It applies similar features asthose used in the standard generation task in a new,orthogonal direction (supplemental data) with suc-cessful results.
This notion is general enough that itmay potentially be applicable to other tasks, such aspart-of-speech tagging or machine translation.AcknowledgementsWe thank Sittichai Jiampojamarn and Shane Bergsmafor helpful discussions.
This research was supportedby the Natural Sciences and Engineering ResearchCouncil of Canada.ReferencesYaser Al-Onaizan and Kevin Knight.
2002.
Machinetransliteration of names in Arabic texts.
In Proceed-ings of the ACL-02 Workshop on Computational Ap-proaches to Semitic Languages, Philadelphia, Penn-sylvania, USA, July.
Association for ComputationalLinguistics.R.
Harald Baayen, Richard Piepenbrock, and Leon Gulik-ers.
1996.
The CELEX2 lexical database.
LDC96L14.Aditya Bhargava and Grzegorz Kondrak.
2011.
Howdo you pronounce your name?
Improving G2P withtransliterations.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies, pages 399?408,Portland, Oregon, USA, June.
Association for Compu-tational Linguistics.404Aditya Bhargava, Bradley Hauer, and Grzegorz Kondrak.2011.
Leveraging transliterations from multiple lan-guages.
In Proceedings of the 3rd Named EntitiesWorkshop (NEWS 2011), pages 36?40, Chiang Mai,Thailand, November.
Asian Federation of Natural Lan-guage Processing.Maximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conversion.Speech Communication, 50(5):434?451, May.Alan W. Black, Kevin Lenzo, and Vincent Pagel.
1998.Issues in building general letter to sound rules.
In TheThird ESCA/COCOSDA Workshop (ETRW) on SpeechSynthesis, Jenolan Caves House, Blue Mountains, NewSouth Wales, Australia, November.Trevor Cohn and Mirella Lapata.
2007.
Machine trans-lation by triangulation: Making effective use of multi-parallel corpora.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 728?735, Prague, Czech Republic, June.Association for Computational Linguistics.Andrew Finch and Eiichiro Sumita.
2010.
Transliterationusing a phrase-based statistical machine translation sys-tem to re-score the output of a joint multigram model.In Proceedings of the 2010 Named Entities Workshop,pages 48?52, Uppsala, Sweden, July.
Association forComputational Linguistics.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden Markov models to letter-to-phoneme con-version.
In Human Language Technologies 2007: TheConference of the North American Chapter of the As-sociation for Computational Linguistics; Proceedingsof the Main Conference, pages 372?379, Rochester,New York, USA, April.
Association for ComputationalLinguistics.Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kon-drak.
2008.
Joint processing and discriminative train-ing for letter-to-phoneme conversion.
In Proceedings ofACL-08: HLT, pages 905?913, Columbus, Ohio, USA,June.
Association for Computational Linguistics.Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou, Ken-neth Dwyer, and Grzegorz Kondrak.
2009.
DirecTL:a language independent approach to transliteration.
InProceedings of the 2009 Named Entities Workshop:Shared Task on Transliteration (NEWS 2009), pages 28?31, Suntec, Singapore, August.
Association for Com-putational Linguistics.Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kon-drak.
2010a.
Integrating joint n-gram features intoa discriminative training framework.
In Human Lan-guage Technologies: The 2010 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, pages 697?700, Los Ange-les, California, USA, June.
Association for Computa-tional Linguistics.Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma,Aditya Bhargava, Qing Dou, Mi-Young Kim, and Grze-gorz Kondrak.
2010b.
Transliteration generation andmining with limited training resources.
In Proceedingsof the 2010 Named Entities Workshop, pages 39?47,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Thorsten Joachims.
2002.
Optimizing search enginesusing clickthrough data.
In Proceedings of the EighthACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, pages 133?142, Edmon-ton, Alberta, Canada.
Association for Computing Ma-chinery.Mitesh M. Khapra, A Kumaran, and Pushpak Bhat-tacharyya.
2010.
Everybody loves a rich cousin: Anempirical study of transliteration through bridge lan-guages.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages420?428, Los Angeles, California, June.
Associationfor Computational Linguistics.Anne K. Kienappel and Reinhard Kneser.
2001.
De-signing very compact decision trees for grapheme-to-phoneme transcription.
In EUROSPEECH-2001, pages1911?1914, Aalborg, Denmark, September.Alexandre Klementiev and Dan Roth.
2006.
Namedentity transliteration and discovery from multilingualcomparable corpora.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, MainConference, pages 82?88, New York City, USA, June.Association for Computational Linguistics.Kevin Knight and Jonathan Graehl.
1998.
Machinetransliteration.
Computational Linguistics, 24(4):599?612, December.John Kominek and Alan W. Black.
2006.
Learning pro-nunciation dictionaries: Language complexity and wordselection strategies.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL, MainConference, pages 232?239, New York City, New York,USA, June.
Association for Computational Linguistics.A.
Kumaran, Mitesh M. Khapra, and Pushpak Bhat-tacharyya.
2010a.
Compositional machine translit-eration.
9(4):13:1?13:29, December.A Kumaran, Mitesh M. Khapra, and Haizhou Li.
2010b.Report of news 2010 transliteration mining shared task.In Proceedings of the 2010 Named Entities Workshop,pages 21?28, Uppsala, Sweden, July.
Association forComputational Linguistics.Haizhou Li, Min Zhang, and Jian Su.
2004.
A jointsource-channel model for machine transliteration.
InProceedings of the 42nd Meeting of the Association405for Computational Linguistics (ACL?04), Main Volume,pages 159?166, Barcelona, Spain, July.Haizhou Li, A Kumaran, Vladimir Pervouchine, and MinZhang.
2009.
Report of NEWS 2009 machine translit-eration shared task.
In Proceedings of the 2009 NamedEntities Workshop: Shared Task on Transliteration(NEWS 2009), pages 1?18, Suntec, Singapore, August.Association for Computational Linguistics.Haizhou Li, A Kumaran, Min Zhang, and Vladimir Per-vouchine.
2010.
Report of NEWS 2010 transliterationgeneration shared task.
In Proceedings of the 2010Named Entities Workshop, pages 1?11, Uppsala, Swe-den, July.
Association for Computational Linguistics.Linsen Loots and Thomas R. Niesler.
2009.
Data-drivenphonetic comparison and conversion between southafrican, british and american english pronunciations.
InProceedings of Interspeech, Brighton, UK, September.Yannick Marchand and Robert I. Damper.
2000.
A multi-strategy approach to improving pronunciation by anal-ogy.
Computational Linguistics, 26(2):195?219, June.Korin Richmond, Robert Clark, and Sue Fitt.
2009.
Ro-bust LTS rules with the Combilex speech technologylexicon.
In Proceedings of Interspeech, pages 1295?1298, Brighton, UK, September.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learningstring edit distance.
IEEE Transactions on PatternRecognition and Machine Intelligence, 20(5):522?532,May.Terrence J. Sejnowski and Charles R. Rosenberg.
1987.Parallel networks that learn to pronounce english text.Complex Systems, 1(1):145?168.Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, andRegina Barzilay.
2009.
Adding more languages im-proves unsupervised multilingual part-of-speech tag-ging: a bayesian non-parametric approach.
In Pro-ceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages83?91, Boulder, Colorado, USA, June.
Association forComputational Linguistics.Richard Sproat, Tao Tao, and ChengXiang Zhai.
2006.Named entity transliteration with comparable corpora.In Proceedings of the 21st International Conferenceon Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics,pages 73?80, Sydney, Australia, July.
Association forComputational Linguistics.Paul Taylor.
2005.
Hidden Markov models for graphemeto phoneme conversion.
In Proceedings of Interspeech,pages 1973?1976, Lisbon, Portugal, September.Masao Utiyama and Hitoshi Isahara.
2007.
A comparisonof pivot methods for phrase-based statistical machinetranslation.
In Human Language Technologies 2007:The Conference of the North American Chapter of theAssociation for Computational Linguistics; Proceed-ings of theMain Conference, pages 484?491, Rochester,New York, USA, April.
Association for ComputationalLinguistics.van den Bosch and Walter Daelemans.
1998.
Do notforget: Full memory in memory-based learning ofword pronunciation.
In D.M.W.
Powers, editor, NeM-LaP3/CoNLL98: NewMethods in Language Processingand Computational Natural Language Learning, pages195?204, Sydney, Australia.
Association for Computa-tional Linguistics.Hua Wu and Haifeng Wang.
2009.
Revisiting pivot lan-guage approach for machine translation.
In Proceed-ings of the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages154?162, Suntec, Singapore, August.
Association forComputational Linguistics.Dmitry Zelenko and Chinatsu Aone.
2006.
Discrimina-tive methods for transliteration.
In Proceedings of the2006 Conference on Empirical Methods in Natural Lan-guage Processing, pages 612?617, Sydney, Australia,July.
Association for Computational Linguistics.Min Zhang, Xiangyu Duan, Vladimir Pervouchine, andHaizhou Li.
2010.
Machine transliteration: Leveragingon third languages.
In Coling 2010: Posters, pages1444?1452, Beijing, China, August.
Coling 2010 Orga-nizing Committee.Min Zhang, Haizhou Li, A Kumaran, and Ming Liu.
2011.Report of NEWS 2011 machine transliteration sharedtask.
In Proceedings of the 3rd Named Entities Work-shop (NEWS 2011), pages 1?13, Chiang Mai, Thailand,November.
Asian Federation of Natural Language Pro-cessing.406
