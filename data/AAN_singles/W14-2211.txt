Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 77?85,Baltimore, Maryland, USA, 26 June 2014.c?2014 Association for Computational LinguisticsSeedLing: Building and using a seed corpusfor the Human Language ProjectGuy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer, and Michaela RegneriUniversit?at des Saarlandes66123 Saarbr?ucken, Germany{emerson, liling, susfert, apalmer, regneri}@coli.uni-saarland.deAbstractA broad-coverage corpus such as the Hu-man Language Project envisioned by Ab-ney and Bird (2010) would be a powerfulresource for the study of endangered lan-guages.
Existing corpora are limited inthe range of languages covered, in stan-dardisation, or in machine-readability.
Inthis paper we present SeedLing, a seedcorpus for the Human Language Project.We first survey existing efforts to compilecross-linguistic resources, then describeour own approach.
To build the foundationtext for a Universal Corpus, we crawl andclean texts from several web sources thatcontain data from a large number of lan-guages, and convert them into a standard-ised form consistent with the guidelinesof Abney and Bird (2011).
The result-ing corpus is more easily-accessible andmachine-readable than any of the underly-ing data sources, and, with data from 1451languages covering 105 language fami-lies, represents a significant base corpusfor researchers to draw on and add to inthe future.
To demonstrate the utility ofSeedLing for cross-lingual computationalresearch, we use our data in the test appli-cation of detecting similar languages.1 IntroductionAt the time of writing, 7105 living languagesare documented in Ethnologue,1but Simons andLewis (2011) calculated that 37% of extant lan-guages were at various stages of losing trans-misson to new generations.
Only a fractionof the world?s languages are well documented,fewer have machine-readable resources, and feweragain have resources with linguistic annotations1http://www.ethnologue.com(Maxwell and Hughes, 2006) - so the time to workon compiling these resources is now.Several years ago, Abney and Bird (2010; 2011)posed the challenge of building a Universal Cor-pus, naming it the Human Language Project.
Sucha corpus would include data from all the world?slanguages, in a consistent structure, facilitatinglarge-scale cross-linguistic processing.
The chal-lenge was issued to the computational linguisticscommunity, from the perspective that the languageprocessing, machine learning, and data manipula-tion and management tools well-known in com-putational linguistics must be brought to bear onthe problems of documentary linguistics, if weare to make any serious progress toward build-ing such a resource.
The Universal Corpus asenvisioned would facilitate broadly cross-lingualnatural language processing (NLP), in particulardriving innovation in research addressing NLP forlow-resource languages, which in turn supportsthe language documentation process.We have accepted this challenge and have be-gun converting existing resources into a formatconsistent with Abney and Bird?s specifications.We aim for a collection of resources that includesdata: (a) from as many languages as possible, and(b) in a format both in accordance with best prac-tice archiving recommendations and also readilyaccessible for computational methods.
Of course,there are many relevant efforts toward producingcross-linguistic resources, which we survey in sec-tion 2.
To the best of our knowledge, though, noexisting effort meets these two desiderata to theextent of our corpus, which we name SeedLing: aseed corpus for the Human Language Project.To produce SeedLing, we have drawn on fourweb sources, described in section 3.2.
To bringthe four resources into a common format anddata structure (section 3.1), each required differ-ent degrees and types of cleaning and standardis-ation.
We describe the steps required in section 4,77presenting each resource as a separate mini-casestudy.
We hope that the lessons we learned inassembling our seed corpus can guide future re-source conversion efforts.
To that end, many of theresources described in section 2 are candidates forinclusion in the next stage of building a UniversalCorpus.We believe the resulting corpus, which atpresent covers 1451 languages from 105 languagefamilies, is the first of its kind: large enough andconsistent enough to allow broadly multilinguallanguage processing.
To test this claim, we useSeedLing in a sample application (section 5): thetask of language clustering.
With no additionalpre-processing, we extract surface-level features(frequencies of character n-grams and words) toestimate the similarity of two languages.
Unlikemost previous approaches to the task, we makeno use of resources curated for linguistic typol-ogy (e.g.
values of typological features as inWALS (Dryer and Haspelmath, 2013), Swadeshword lists).
Despite our approach being highlydependent on orthography, our clustering perfor-mance matches the results obtained by Georgiet al.
(2010) using typolological features, whichdemonstrates SeedLing?s utility in cross-linguisticresearch.2 Related WorkIn this section, we review existing efforts to com-pile multilingual machine-readable resources.
Al-though some commercial resources are available,we restrict attention to freely accessible data.2Traditional archives.
Many archives exist tostore the wealth of traditional resources producedby the documentary linguistics community.
Suchdocuments are increasingly being digitised, orproduced in a digital form, and there are a numberof archives which now offer free online access.Some archives aim for a universal scope, suchas The Language Archive (maintained by theMax Planck Institute of Psycholinguistics), Col-lection Pangloss (maintained by LACITO), andThe Endangered Languages Archive (maintainedby SOAS).
Most archives are regional, includingAILLA, ANLA, PARADISEC, and many others.However, there are two main problems commonto all of the above data sources.
Firstly, the data2All figures given below were correct at the time of writ-ing, but it must be borne in mind that most of these resourcesare constantly growing.is not always machine readable.
Even where thedata is available digitally, these often take the formof scanned images or audio files.
While both canprovide invaluable information, they are extremelydifficult to process with a computer, requiring animpractical level of image or video pre-processingbefore linguistic analysis can begin.
Even textualdata, which avoids these issues, may not be avail-able in a machine-readable form, being stored aspdfs or other opaque formats.
Secondly, when datais machine readable, the format can vary wildly.This makes automated processing difficult, espe-cially if one is not aware of the details of eachproject.
Even when metadata standards and en-codings agree, there can be idiosyncractic markupor non-linguistic information, such as labels forspeakers in the transcript of a conversation.We can see that there is still much work to bedone by individual researchers in digitising andstandardising linguistic data, and it is outside ofthe scope of this paper to attempt this for the abovearchives.
Guidelines for producing new materi-als are available from the E-MELD project (Elec-tronic Metastructure for Endangered LanguagesData), which specifically aimed to deal with theexpanding number of standards for linguistic data.It gives best practice recommendations, illustratedwith eleven case studies, and provides input toolswhich link to the GOLD ontology language, andthe OLAC metadata set.
Further recommenda-tions are given by Bird and Simons (2003), whodescribe seven dimensions along which the porta-bility of linguistic data can vary.
Various tools areavailable from The Language Archive at the MaxPlanck Institute for Psycholinguistics.Many archives are part of the Open LanguageArchive Community (OLAC), a subcommunityof the Open Archives Initiative.
OLAC main-tains a metadata standard, based on the 15-elementDublin Core, which allows a user to searchthrough all participating archives in a unified fash-ion.
However, centralising access to disparate re-sources, while of course extremely helpful, doesnot solve the problem of inconsistent standards.Indeed, it can even be hard to answer simple ques-tions like ?how many languages are represented?
?In short, while traditional archives are invalu-able for many purposes, for large-scale machineprocessing, they leave much to be desired.Generic corpus collections.
Some corpus col-lections exist which do not focus on endangered78languages, but which nonetheless cover an in-creasing number of languages.MetaShare (Multilingual Europe TechnologyAlliance) provides data in a little over 100 lan-guages.
While language codes are used, they havenot been standardised, so that multiple codes areused for the same language.
Linguistic Data Con-sortium (LDC) and the European Language Re-sources Association (ELRA) both offer data inmultiple languages.
However, while large in size,they cover only a limited number of languages.Furthermore, the corpora they contain are storedseparately, making it difficult to access data ac-cording to language.Parallel corpora.
The Machine Translationcommunity has assembled a number of parallelcorpora, which are crucial for statistical machinetranslation.
The OPUS corpus (Tiedemann, 2012)subsumes a number of other well-known parallelcorpora, such as Europarl, and covers documentsfrom 350 languages, with various language pairs.Web corpora.
There has been increasing inter-est in deriving corpora from the web, due to thepromise of large amounts of data.
The majorityof web corpora are however aimed at either one ora small number of languages, which is perhaps tobe expected, given that the majority of online textis written in a handful of high-resource languages.Nonetheless, there have been a few efforts to applythe same methods to a wider range of languages.HC Corpora currently provides download ofcorpora in 68 different language varieties, whichvary in size from 2M to 150M words.
The cor-pora are thus of a respectable size, but only 1% ofthe world?s languages are represented.
A furtherdifficulty is that languages are named, without thecorresponding ISO language codes.The Leipzig Corpora Collection (LCC)3(Bie-mann et al., 2007) provides download of corporain 117 languages, and dictionaries in a number ofothers, bringing the total number of representedlanguages up to 230.
The corpora are large, read-ily available, in plain-text, and labelled with ISOlanguage codes.The Cr?ubad?an Project aims to crawl the web fortext in low-resource languages, and data is cur-rently available for 1872 languages.
This rep-resents a significant portion of the world?s lan-guages; unfortunately, due to copyright restric-3http://corpora.uni-leipzig.detions, only lists of n-grams and their frequenciesare publically available, not the texts themselves.While the breadth of languages covered makes thisa useful resource for cross-linguistic research, thelack of actual texts means that only a limited rangeof applications are possible with this data.Cross-linguistic projects.
Responding to thecall to document and preserve the world?s lan-guages, highly cross-linguistic projects havesprung up, striving towards the aim of universality.Of particular note are the Endangered LanguagesProject, and the Rosetta Project.
These projectsare to be praised for their commitment to univer-sality, but in their current forms it is difficult to usetheir data to perform large-scale NLP.3 The Data3.1 Universal Corpus and Data StructureBuilding on their previous paper, Abney and Bird(2011) describe the data structure they envisagefor a Universal Corpus in more detail, and we aimto adopt this structure where possible.
Two typesof text are distinguished:Aligned texts consist of parallel documents,aligned at the document, sentence, or word level.Note that monolingual documents are viewed asaligned texts only tied to a single language.Analysed texts, in addition to the raw text, con-tain more detailed annotations including parts ofspeech, morphological information, and syntacticrelations.
This is stored as a table, where rows rep-resent words, and columns represent: documentID, language code, sentence ID, word ID, word-form, lemma, morphological information, part ofspeech, gloss, head/governor, and relation/role.Out of our data sources, three can be straight-forwardly represented in the aligned text struc-ture.
However, ODIN contains richer annotations,which are in fact difficult to fit into Abney andBird?s proposal, and which we discuss in section3.2 below.3.2 Data SourcesAlthough data size matters in general NLP, uni-versality is the top priority for a Universal Corpus.We focus on the following data sources, becausethey include a large number of languages, includeseveral parallel texts, and demonstrate a variety ofdata types which a linguist might encounter (struc-tured, semi-structured, unstructured): the Online79Langs.
Families Tokens SizeODIN 1,270 100 351,161 39 MBOmniglot 129 20 31,318 677 KBUDHR 352 46 640,588 5.2 MBWikipedia 271 21 37 GBCombined 1,451 105Table 1: Corpus CoverageDatabase of Interlinear Text (ODIN), the Om-niglot website, the Universal Declaration of Hu-man Rights (UHDR), and Wikipedia.Our resulting corpus runs the full gamut of texttypes outlined by Abney and Bird, ranging fromsingle-language text (Wikipedia) to parallel text(UDHR and Omniglot) to IGTs (ODIN).
Table 1gives some coverage statistics, and we describeeach source in the following subsections.
For 332languages, the corpus contains data from morethan one source.Universal Declaration of Human Rights.
TheUniversal Declaration of Human Rights (UDHR)is a document released by the United Nations in1948, and represents the first global expression ofhuman rights.
It consists of 30 articles, amountingto about four pages of text.
This is a useful doc-ument for NLP, since it has been translated into awide variety of languages, providing a highly par-allel text.Wikipedia.
Wikipedia is a collaboratively-edited encyclopedia, appealing to use for NLPbecause of its large size and easy availability.At the time of writing, it contained 30.8 millionarticles in 286 languages, which provides asizeable amount of monolingual text in a fairlywide range of languages.
Text dumps are maderegularly available, and can be downloaded fromhttp://dumps.wikimedia.org.Omniglot.
The Omniglot website4is an onlineencyclopedia of writing systems and languages.We extract information from pages on ?Useful for-eign phrases?
and the ?Tower of Babel?
story, bothof which give us parallel data in a reasonably largenumber of languages.ODIN.
ODIN (The Online Database of Inter-linear Text) is a repository of interlinear glossedtexts (IGTs) extracted from scholarly documents(Lewis, 2006; Lewis and Xia, 2010).
Compared toother resources, it is notable for the breadth of lan-4http://www.omniglot.comguages included and the level of linguistic annota-tion.
An IGT canonically consists of three lines:(i) the source, a sentence in a target language, (ii)the gloss, an analysis of each source element, and(iii) the translation, done at the sentence level.
Thegloss line can additionally include a number of lin-guistic terms, which means that the gloss is writtenin metalanguage rather than natural language.
InODIN, translations are into English, and glossesare written in an English-based metalanguage.
Anaccepted set of guidelines are given by the LeipzigGlossing Rules,5where morphemes within wordsare separated by hyphens (or equal signs, for cli-tics), and the same number of hyphens should ap-pear in each word of the source and gloss.The data from ODIN poses the first obstacle tostraightforwardly adopting Abney and Bird?s pro-posal.
The suggested data structure is aligned atthe word level, and includes a specific list of rel-evant features which should be used to annotatewords.
When we try to adapt IGTs into this for-mat, we run into certain problems.
Firstly, thereis the problem that the most fundamental unit ofanalysis according to the Leipzig Glossing Rulesis the morpheme, not the word.
Ideally, we shouldencode this information explicitly in a UniversalCorpus, assigning a unique identifier to each mor-pheme (instead of, or in addition to each word).Indeed, Haspelmath (2011) argues that there is nocross-linguistically valid definition of word, whichundermines the central position of words in theproposed data structure.Secondly, it is unclear how to represent thegloss.
Since the gloss line is not written in a natu-ral language, we cannot treat it as a simple trans-lation.
However, it is not straightforward to incor-porate it into the proposed structure for analysedtexts, either.
One possible resolution is to moveall elements of the gloss written in capital letters tothe MORPH field (as functional elements are usu-ally annotated in this way), and all remaining el-ements to the GLOSS field.
However, this losesinformation, since we no longer know which mor-pheme has which meaning.
To keep all informa-tion encoded in the IGT, we need to modify Abneyand Bird (2011)?s proposal.The simplest solution we can see is to allowmorphemes to be a level of structure in the Uni-versal Corpus, just as documents, sentences, and5http://www.eva.mpg.de/lingua/resources/glossing-rules.php80Figure 1: Heatmap of languages in SeedLing according to endangerment statuswords already are.
The overall architecture re-mains unchanged.
We must then decide how torepresent the glosses.Even though glosses in ODIN are based onEnglish, having been extracted from English-language documents, this is not true of IGTs ingeneral.
For example, it is common for documen-tary linguists working on indigenous languages ofthe Americas to provide glosses and translationsbased on Spanish.
For this reason, we believe itwould be wise to specify the language used to pro-duce the gloss.
Since it is not quite the languageitself, but a metalanguage, one solution would beto use new language codes that make it clear boththat a metalanguage is being used, and also whatnatural language it is based on.
The five-lettercode gloss cannot be confused with any codein any version of ISO 639 (with codes of lengthtwo to four).
Following the convention that sub-varieties of a language are indicated with suffixes,we can append the code of the natural language.For example, glosses into English and Spanish-based metalanguages would be given the codesgloss-eng and gloss-spa, respectively.One benefit of this approach is that glossed textsare treated in exactly the same way as paralleltexts.
There is a unique identifier for each mor-pheme, and glosses are stored under this identifierand the corresponding gloss code.
Furthermore,to motivate the important place of parallel texts ina Universal Corpus, Abney and Bird view trans-lations into a high-resource reference language asa convenient surrogate of meaning.
By the samereasoning, we can use glosses to provide a moredetailed surrogate of meaning, only written in ametalanguage instead of a natural one.3.3 Representation and UniversalityAccording to Ethnologue, there are 7105 liv-ing languages, and 147 living language families.Across all our data sources, we manage to cover1451 languages in 105 families, which represents19.0% of the world?s languages.
To get a bet-ter idea of the kinds of languages represented,we give a breakdown according to their EGIDSscores (Expanded Graded Intergenerational Dis-ruption Scale) (Lewis and Simons, 2010) in Fig-ure 1.
The values in each cell have been coloredaccording to proportion of languages represented,with green indicating good coverage and red poor.It?s interesting to note that vigorous languages (6a)are poorly represented across all data sources, andworse than more endangered categories.
In termsof language documentation, vigorous languagesare less urgent goals than those in categories 6band up, but this highlights an unexpected gap inlinguistic resources.4 Data Clean-Up, Consistency, andStandardisationConsistency in data structures and formatting isessential to facilitate use of data in computationallinguistics research (Palmer et al., 2010).
In thefollowing subsections, we describe the process-ing required to convert the data into a standardisedform.
We then discuss standardisation of languagecodes and file formats.814.1 Case StudiesUDHR.
We used the plain-text UDHR filesavailable from the Unicode website6which usesUTF-8 encoding for all languages.
The first fourlines of each file record metadata, and the rest isthe translation of the UDHR.
This dataset is ex-tremely clean, and simply required segmentationinto sentences.Wikipedia.
One major issue with using theWikipedia dump is the problem of separating textfrom abundant source-specific markup.
To con-vert compressed Wikipedia dumps to textfiles, weused the WikiExtractor7tool.
After conversioninto textfiles, we used several regular expressionsto delete residual Wikipedia markup and so-called?magic words?.8Omniglot.
The main issue with extracting theOmniglot data is that the pages are designed tobe human-readable, not machine-readable.
Clean-ing this data required parsing the HTML source,and extracting the relevant content, which requireddifferent code for the two types of page we con-sidered (?Useful foreign phrases?
and ?Tower ofBabel?).
Even after automatic extraction, somenoise in the data remained, such as explanatorynotes given in parentheses, which are written inEnglish and not the target language.
Even thoughthe total amount of data here is small compared toour other sources, the amount of effort requiredto process it was not, because of these idiosyn-cracies.
We expect that researchers seeking toconvert data from human-readable to machine-readable formats will encounter similar problems,but unfortunately there is unlikely to be a one-size-fits-all solution to this problem.ODIN.
The ODIN data is easily accessible inXML format from the online database9.
Datafor each language is saved in a separate XMLfile and the IGTs are encoded in tags of the form<igt><example>...</example></igt>.For example, the IGT in Figure 2 is representedby the XML snippet in Figure 3.The primary problem in extracting the data is alack of consistency in the IGTs.
In the above ex-6http://unicode.org/udhr/d7http://medialab.di.unipi.it/wiki/Wikipedia_Extractor8http://en.wikipedia.org/wiki/Help:Magic_words9http://odin.linguistlist.org/download21 a. o lesu mai2sg return here?You return here.
?Figure 2: Fijian IGT from ODIN<igt><example><line>21 a. o lesu mai</line><line>2sg return here</line><line>?You return here.
?</line></example></igt>Figure 3: Fijian IGT in ODIN?s XML formatamples, the sentence is introduced by a letter ornumber, which needs to be removed; however, theform of such indexing elements varies.
In addi-tion, the source line in Figure 4 includes two typesof metadata: the language name, and a citation,both of which introduce noise.
Finally, extrane-ous punctuation such as the quotation marks in thetranslation line need to be removed.
We used regu-lar expressions for cleaning lines within the IGTs.4.2 Language CodesAs Xia et al.
(2010) explain, language names donot always suffice to identify languages, sincemany names are ambiguous.
For this reason, setsof language codes exist to more accurately identifylanguages.
We use ISO 639-310as our standard setof codes, since it aims for universal coverage, andhas widespread acceptance in the community.
Thedata from ODIN and the UDHR already used thisstandard.To facilitate the standardization of languagecodes, we have written a python API that can beused to query information about a language or acode, fetching up-to-date information from SILInternational (which maintains the ISO 639-3 codeset), as well as from Ethnologue.Wikipedia uses its own set of language codes,most of which are in ISO 639-1 or ISO 639-3.The older ISO 639-1 codes are easy to recognise,being two letters long instead of three, and canbe straightforwardly converted.
However, a smallnumber of Wikipedia codes are not ISO codes atall - we converted these to ISO 639-3, following10http://www-01.sil.org/iso639-3/default.asp82<igt><example><line>(69) na-Na-tmi-kwalca-tYimas (Foley 1991)</line><line>3sgA-1sgO-say-rise-PERF</line><line>?She woke me up?
(by verbal action)</line></example></igit>Figure 4: Yimas IGT in ODIN?s XML formatdocumentation from the Wikimedia Foundation.11Omniglot does not give codes at all, but only thelanguage name.
To resolve this issue, we automat-ically converted language names to codes using in-formation from the SIL website.Some languages have more than one orthog-raphy.
For example, Mandarin Chinese is writ-ten with either traditional or simplified charac-ters; Serbian is written with either the Cyrillic orthe Roman alphabet.
For cross-linguistic NLP, itcould be helpful to have standard codes to identifyorthographies, but at present none exist.4.3 File FormatsIt is important to make sure that the data we havecompiled will be available to future researchers,regardless of how the surrounding infrastructurechanges.
Bird and Simons (2003) describe a set ofbest practices for maintaining portability of digi-tal information, outlining seven dimensions alongwhich this can vary.
Following this advice, wehave ensured that all our data is available as plain-text files, with UTF-8 encoding, labelled with therelevant ISO 639-3 code.
Metadata is stored sepa-rately.
This allows users to easily process the datausing the programming language or software oftheir choice.To allow access to the data following Abneyand Bird?s guidelines, as discussed in section 3,we have written an API, which we distribute alongwith the data.
Abney and Bird remain agnosticto the specific file format used, but if an alterna-tive format would be preferred, the data wouldbe straightfoward to convert since it can be ac-cessed according to these guidelines.
As exam-ples of functionality, our API allows a user to fetchall sentences in a given language, or all sentencesfrom a given source.11http://meta.wikimedia.org/wiki/Special_language_codes5 Detecting Similar LanguagesTo exemplify the use of SeedLing for compu-tational research on low-resource languages, weexperiment with automatic detection of similarlanguages.
When working on endangered lan-guages, documentary and computational linguistsalike face a lack of resources.
It is often helpful toexploit lexical, syntactic or morphological knowl-edge of related languages.
For example, similarhigh-resource languages can be used in bootstrap-ping approaches, such as described by Yarowskyand Ngai (2001) or Xia and Lewis (2007).Language classification can be carried out invarious ways.
Two common approaches are ge-nealogical classification, mapping languages ontofamily trees according to their historical related-ness (Swadesh, 1952; Starostin, 2010); and ty-pological classification, grouping languages ac-cording to linguistic features (Georgi et al., 2010;Daum?e III, 2009).
Both of these approaches re-quire linguistic analysis.
By contrast, we usesurface features (character n-gram and word uni-gram frequencies) extracted from SeedLing, andapply an off-the-shelf hierarchical clustering al-gorithm.12Specifically, each language is repre-sented as a vector of frequencies of character bi-grams, character trigrams, and word unigrams.Each of these three components is normalised tounit length.
Data was taken from ODIN, Om-niglot, and the UDHR.Experimental Setup.
We first perform hierar-chical clustering, which produces a tree structure:each leaf represents a language, and each nodea cluster.
We use linkage methods, which recur-sively build the tree starting from the leaves.
Ini-tially, each language is in a separate cluster, thenwe iteratively find the closest two clusters andmerge them.
Each time we do this, we take thetwo corresponding subtrees, and introduce a newnode to join them.We define the distance between two clusters byconsidering all possible pairs of languages, withone from each cluster, and taking the largest dis-tance.
We experimented with other ways to de-fine the distance between clusters, but results werepoor and we omit results for brevity.To ease evaluation, we produce a partitionalclustering, by stopping when we reach a certainnumber of clusters, set in advance.12http://www.scipy.org83Precision Recall F-scoreSeedLing 0.255 0.205 0.150Base.
1: random 0.184 0.092 0.068Base.
2: together 0.061 1.000 0.112Base.
3: separate 1.000 0.086 0.122Table 2: Clustering compared with baselinesFigure 5: Performance against number of clustersEvaluation.
We compare our clustering to thelanguage families in Ethnologue.
However, thereare many ways to evaluate clustering quality.Amig?o et al.
(2009) propose a set of criteria whicha clustering evaluation metric should satisfy, anddemonstrate that most popular metrics fail to sat-isfy at least one of these criteria.
However, theyprove that all criteria are satisfied by the BCubedmetric, which we therefore adopt.
To calculate theBCubed score, we take the induced cluster andgold standard class for each language, and cal-culate the F-score of the cluster compared to theclass.
These F-scores are then averaged across alllanguages.In Table 2, we set the number of clusters to be105, the number of language families in our data,and compare this with three baselines: a randombaseline (averaged over 20 runs); putting all lan-guages in a single cluster; and putting each lan-guage in a separate cluster.
Our clustering outper-forms all baselines.
It is worth noting that pre-cision is higher than recall, which is perhaps ex-pected, given that related languages using wildlydiffering orthographies will appear distinct.To allow a closer comparison with Georgi et al.
(2010), we calculate pairwise scores - i.e.
consid-ering if pairs of languages are in the same clusteror the same class.
For 105 clusters, we achievea pairwise f-score of 0.147, while Georgi et al.report 0.140.
The figures are not quite compa-rable since we are evaluating over a different setof languages; nonetheless, we only use surfacefeatures, while Georgi et al.
use typological fea-tures from WALS.
This suggests the possibility forcross-linguistic research to be conducted based onshallow features.In Figure 5, we vary the number of clusters.
Thehighest f-score is obtained for 199 clusters.
Thereis a notable jump in performance between 98 and99, just before the true number of families, 105.Interpreting the clusters directly is difficult, be-cause they are noisy.
However, the distribution ofcluster sizes mirrors the true distribution - for 105clusters, we have 48 clusters of size 1 or 2, withthe largest cluster of size 130; while in our goldstandard, there are 51 families with only 1 or 2languages in the data, with the largest of size 150.6 Conclusion and OutlookIn this paper, we have described the creation ofSeedLing, a foundation text for a Universal Cor-pus, following the guidelines of Abney and Bird(2010; 2011).
To do this, we cleaned and standard-ised data from several multilingual data sources:ODIN, Omniglot, the UDHR, Wikipedia.
Theresulting corpus is more easily machine-readablethan any of the underlying data sources, and hasbeen stored according to the best practices sug-gested by Bird and Simons (2003).
At present,SeedLing has data from 19% of the world?s liv-ing languages, covering 72% of language families.We believe that a corpus with such diversity of lan-guages, uniformity of format, cleanliness of data,and ease of access provides an excellent seed for aUniversal Corpus.
It is our hope that taking stepstoward creating this resource will spur both furtherdata contributions and interesting computationalresearch with cross-linguistic or typological per-spectives; we have here demonstrated SeedLing?sutility for such research by using the data to per-form language clustering, with promising results.SeedLing (data, API and documentation) is cur-rently available via a GitHub repository.13Wehave yet to fully address questions of long-termaccess, and we welcome ideas or collaborationsalong these lines.13https://github.com/alvations/SeedLing84AcknowledgementsWe thank the three anonymous reviewers for theirhelpful comments.
This research was supportedin part by the Cluster of Excellence ?Multi-modalComputing and Interaction?
in the German Excel-lence Initiative.ReferencesSteven Abney and Steven Bird.
2010.
The Hu-man Language Project: Building a Universal Cor-pus of the world?s languages.
In Proceedings of the48th Annual Meeting of the Association for Com-putational Linguistics, pages 88?97.
Association forComputational Linguistics.Steven Abney and Steven Bird.
2011.
Towards a datamodel for the Universal Corpus.
In Proceedings ofthe 4th Workshop on Building and Using Compa-rable Corpora: Comparable Corpora and the Web,pages 120?127.
Association for Computational Lin-guistics.Enrique Amig?o, Julio Gonzalo, Javier Artiles, and Fe-lisa Verdejo.
2009.
A comparison of extrinsicclustering evaluation metrics based on formal con-straints.
Information retrieval, 12(4):461?486.Chris Biemann, Gerhard Heyer, Uwe Quasthoff, andMatthias Richter.
2007.
The Leipzig CorporaCollection-monolingual corpora of standard size.Proceedings of Corpus Linguistic 2007.Steven Bird and Gary Simons.
2003.
Seven dimen-sions of portability for language documentation anddescription.
Language, pages 557?582.Hal Daum?e III.
2009.
Non-parametric bayesian areallinguistics.
In Proceedings of human language tech-nologies: The 2009 annual conference of the northamerican chapter of the association for computa-tional linguistics, pages 593?601.
Association forComputational Linguistics.Matthew S. Dryer and Martin Haspelmath, editors.2013.
WALS Online.
Max Planck Institute for Evo-lutionary Anthropology, Leipzig.Ryan Georgi, Fei Xia, and William Lewis.
2010.Comparing language similarity across genetic andtypologically-based groupings.
In Proceedings ofthe 23rd International Conference on Computa-tional Linguistics, pages 385?393.
Association forComputational Linguistics.Martin Haspelmath.
2011.
The indeterminacy of wordsegmentation and the nature of morphology and syn-tax.
Folia Linguistica, 45(1):31?80.M Paul Lewis and Gary F Simons.
2010.
Assessingendangerment: expanding fishman?s GIDS.
Revueroumaine de linguistique, 2:103?119.William D Lewis and Fei Xia.
2010.
DevelopingODIN: A multilingual repository of annotated lan-guage data for hundreds of the world?s languages.Literary and Linguistic Computing, 25(3):303?319.William D Lewis.
2006.
ODIN: A model for adapt-ing and enriching legacy infrastructure.
In e-Scienceand Grid Computing, 2006. e-Science?06.
SecondIEEE International Conference on, pages 137?137.IEEE.Mike Maxwell and Baden Hughes.
2006.
Frontiers inlinguistic annotation for lower-density languages.
InProceedings of the workshop on frontiers in linguis-tically annotated corpora 2006, pages 29?37.
Asso-ciation for Computational Linguistics.Alexis Palmer, Taesun Moon, Jason Baldridge, KatrinErk, Eric Campbell, and Telma Can.
2010.
Compu-tational strategies for reducing annotation effort inlanguage documentation.
Linguistic Issues in Lan-guage Technology, 3.Gary F Simons and M Paul Lewis.
2011.
The world?slanguages in crisis: A 20-year update.
In 26thLinguistic Symposium: Language Death, Endanger-ment, Documentation, and Revitalization.
Univer-sity of Wisconsin, Milwaukee, pages 20?22.George Starostin.
2010.
Preliminary lexicostatistics asa basis for language classification: a new approach.Journal of Language Relationship, 3:79?117.Morris Swadesh.
1952.
Lexico-statistic dating of pre-historic ethnic contacts: with special reference tonorth american indians and eskimos.
Proceedings ofthe American philosophical society, pages 452?463.J?org Tiedemann.
2012.
Parallel data, tools and inter-faces in OPUS.
In LREC, pages 2214?2218.Fei Xia and William D Lewis.
2007.
Multilingualstructural projection across interlinear text.
In HLT-NAACL, pages 452?459.Fei Xia, Carrie Lewis, and William D Lewis.
2010.The problems of language identification withinhugely multilingual data sets.
In LREC.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual pos taggers and np bracketers via robustprojection across aligned corpora.
In Proceedingsof NAACL-2001, pages 200?207.85
