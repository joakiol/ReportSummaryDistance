Implementing Weighted Abduction in Markov LogicJames BlytheUSC ISIblythe@isi.eduJerry R. HobbsUSC ISIhobbs@isi.eduPedro DomingosUniversity of Washingtonpedrod@cs.washington.eduRohit J. KateUniversity of Wisconsin-Milwaukeekaterj@uwm.eduRaymond J. MooneyUniversity of Texas at Austinmooney@cs.utexas.eduAbstractAbduction is a method for finding the best explanation for observations.
Arguablythe most advanced approach to abduction, especially for natural language processing, isweighted abduction, which uses logical formulas with costs to guide inference.
But ithas no clear probabilistic semantics.
In this paper we propose an approach that imple-ments weighted abduction in Markov logic, which uses weighted first-order formulas torepresent probabilistic knowledge, pointing toward a sound probabilistic semantics forweighted abduction.
Application to a series of challenge problems shows the power andcoverage of our approach.1 IntroductionAbduction is inference to the best explanation.1 Typically, one uses it to find the best hypothesis ex-plaining a set of observations, e.g., in diagnosis and plan recognition.
In natural language processing thecontent of an utterance can be viewed as a set of observations, and the best explanation then constitutesthe interpretation of the utterance.
Hobbs et al [7] described a variety of abduction called ?weightedabduction?
for interpreting natural language discourse.
The key idea was that the best interpretation ofa text is the best explanation or proof of the logical form of the text, allowing for assumptions.
Whatcounted as ?best?
was defined in terms of a cost function which favored proofs with the fewest number ofassumptions and the most salient and plausible axioms, and in which the pervasive redundancy implicitin natural language discourse was exploited.
It was argued in that paper that such interpretation problemsas coreference and syntactic ambiguity resolution, determining the specific meanings of vague predicatesand lexical ambiguity resolution, metonymy resolution, metaphor interpretation, and the recognition ofdiscourse structure could be seen to ?fall out?
of the best abductive proof.Specifically, weighted abduction has the following features:1.
In a goal expression consisting of an existentially quantified conjunction of positive literals, eachliteral is given a cost that represents the utility of proving that literal as opposed to assuming it.That is, a low cost on a literal will make it more likely for it to be assumed, whereas a high costwill result in a greater effort to find a proof.1We are indebted to Jesse Davis, Parag Singla and Marc Sumner for discussions about this work.
This research wassupported in part by the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air ForceResearch Laboratory (AFRL) prime contract no.
FA8750-09-C-0172, in part by the Office of Naval Research under contractno.
N00014-09-1-1029, and in part by the Army Research Office under grant W911NF-08-1-0242.
Any opinions, findings, andconclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view ofthe DARPA, AFRL, ONR, ARO, or the US government.552.
Costs are passed back across the implication in Horn clauses according to weights on the conjunctsin the antecedents.
Specifically, if a consequent costs $c and the weight on a conjunct in theantecedent is v, then the cost on that conjunct will be $vc.
Note that if the weights add up to lessthan one, backchaining on the rule will be favored, as the cost of the antecedent will be less thanthe cost of the consequent.
If the weights add up to more than one, backchaining will be disfavoredunless a proof can be found for one or more of the conjuncts in the antecedent, thereby providingpartial evidence for the consequent.3.
Two literals can be factored or unified, where the result is given the minimum cost of the two,providing no contradiction would result.
This is a frequent mechanism for coreference resolution.In practice, only a shallow or heuristic check for contradiction is done.4.
The lowest-cost proof is the best interpretation, or the best abductive proof of the goal expression.However, there are two significant problems with weighted abduction as it was originally presented.First, it required a large knowledge base of commonsense knowledge.
This was not available whenweighted abduction was first described, but since that time there have been substantial efforts to build upknowledge bases for various purposes, and at least two of these have been used with promising resultsin an abductive setting?Extended WordNet [6] for question-answering and FrameNet [11] for textualinference.The second problem with weighted abduction was that the weights and costs did not have a prob-abilistic semantics.
This, for example, hampers automatic learning of weights from data or existingresources.
That is the issue we address in the present paper.In the last decade and a half, a number of formalisms for adding uncertain reasoning to predicate logichave been developed that are well-founded in probability theory.
Among the most widely investigatedis Markov logic [14, 4].
In this paper we show how weighted abduction can be implemented in Markovlogic.
This demonstrates that Markov logic networks can be used as a powerful mechanism for interpret-ing natural language discourse, and at the same time provides weighted abduction with something like aprobabilistic semantics.In Section 2 we briefly describe Markov logic and Markov logic networks.
Section 3 then describeshow weighted abduction can be implemented in Markov logic.
In Section 4 we describe experiments inwhich fourteen published examples of the use of weighted abduction in natural language understandingare implemented in Markov logic networks, with good results.
Section 5 on current and future directionsbriefly describes an ongoing experiment in which we are attempting to scale up to apply this procedureto the textual inference problem with a knowledge base derived from FrameNet with tens of thousandsof axioms.2 Markov Logic Networks and Related WorkMarkov logic [14, 4] is a recently developed theoretically sound framework for combining first-orderlogic and probabilistic graphical models.
A traditional first-order knowledge base can be seen as a set ofhard constraints on the set of possible worlds: if a world violates even one formula, its probability is zero.In order to soften these constraints, Markov logic attaches a weight to each first-order logic formula inthe knowledge base.
Such a set of weighted first-order logic formulae is called a Markov logic network(MLN).
A formula?s weight reflects how strong a constraint it imposes on the set of possible worlds: thehigher the weight, the lower the probability of a world that violates it; however, that probability need notbe zero.
An MLN with all infinite weights reduces to a traditional first-order knowledge base with onlyhard constraints.56Formally, an MLN L is a set of formula?weight pairs (Fi, wi).
Given a set of constants, it definesa joint probability distribution over a set of boolean variables X = (X1, X2...) corresponding to thepossible groundings (using the given constants) of the literals present in the first-order formulae:P (X = x) = 1Z exp(?iwini(x))where ni(x) is the number of true groundings of Fi in x and Z is a normalization term obtained bysumming P (X = x) over all values of X .Semantically, an MLN can be viewed as a set of templates for constructing Markov networks [12],the undirected counterparts of Bayesian networks.
An MLN and a set of constants produce a Markovnetwork in which each ground literal is a node and every pair of ground literals that appear together insome grounding of some formula are connected by an edge.
Different sets of constants produce differentMarkov networks; however, there are certain regularities in their structure and parameters.
For example,all groundings of the same formula have the same weight.Probabilistic inference for an MLN (such as finding the most probable truth assignment for a givenset of ground literals, or finding the probability that a particular formula holds) can be performed byfirst producing the ground Markov network and then using well known inference techniques for Markovnetworks, like Gibbs sampling.
Given a knowledge base as a set of first-order logic formulae, and adatabase of training examples each consisting of a set of true ground literals, it is also possible to learnappropriate weights for the MLN formulae which maximize the probability of the training data.
An open-source software package for MLNs, called Alchemy 2, is also available with many built-in algorithmsfor performing inference and learning.Much of the early work on abduction was done in a purely logical framework (e.g., [13, 3, 9, 10].Typically the choice between alternative explanations is made on the basis of parsimony; the shortestproofs with the fewest assumptions are favored.
However, a significant limitation of these purely logicalapproaches is that they are unable to reason under uncertainty or estimate the likelihood of alternativeexplanations.
A probabilistic form of abduction is needed in order to account for uncertainty in thebackground knowledge and to handle noisy and incomplete observations.In Bayesian networks [12] background knowledge with its uncertainties is encoded in a directedgraph.
Then, given a set of observations, probabilistic inference over the graph structure is done tocompute the posterior probability of alternative explanations.
However, Bayesian networks are based onpropositional logic and cannot handle structured representations, hence preventing their use in situations,characteristic of natural language processing, that involve an unbounded number of entities with a varietyof relations between them.In recent years there have been a number of proposals attempting to combine the probabilistic natureof Bayesian networks with structured first-order representations.
It is impossible here to review this liter-ature here.
A a good review of much of it can be found in [5], and in [14] there are detailed comparisonssof various models to MLNs.Charniak and Shimony [2] define a variant of weighted abduction, called ?cost-based abduction?
inwhich weights are attached to terms rather than to rules or to antecedents in rules.
Thus, the term Pihas the same cost whatever rule it is used in.
The cost of an assignment to the variables in the domainis the sum of the costs of the variables that are true in the assignment.
Charniak and Shimony providea probabilistic semantics for their approach by showing how to construct a Bayesian network from adomain such that a most probable explanation solution to the Bayes net corresponds to a lowest-costsolution to the abduction problem.
However, in natural language applications the utility of proving aproposition can vary by context; weighted abduction accomodates this, whereas cost-based abductiondoes not.2http://alchemy.cs.washington.edu573 Weighted Abduction and MLNsKate and Mooney [8] show how logical abduction can be implemented in Markov logic networks.
Theyuse forward inference in MLNs to perform abduction by adding clauses with reverse implications.
Uni-versally quantified variables from the left hand side of rules are converted to existentially quantifiedvariables in the reversed clause.
For example, suppose we have the following rule saying that mosquitobites transmit malaria:mosquito(x) ?
infected(x,Malaria) ?
bite(x, y) ?
infected(y,Malaria)This would be translated into the soft rule[w] infected(y,Malaria) ?
?x[mosquito(x) ?
infected(x,Malaria) ?
bite(x, y)]Where there is more than one possible explanation, they include a closure axiom saying that one of theexplanations must hold.
Since blood transfusions also cause malaria, they have the hard ruleinfected(y,Malaria) ?
?x[mosquito(x) ?
infected(x,Malaria) ?
bite(x, y)]?
?x[infected(x,Malaria) ?
transfuse(Blood, x, y)].Kate and Mooney also add a soft mutual exclusivity clause that states that no more than one of thepossible explanations is true.In translating between weighted abduction and Markov logic, we need similarly to specify the axiomsin Markov logic that correspond to a Horn clause axiom in weighted abduction.
In addition, we need todescribe the relation between the numbers in weighted abduction and the weights on the Markov logicaxioms.
Hobbs et al [7] give only broad, informal guidelines about how the numbers correspond toprobabilities.
In this development, we elaborate on how the numbers can be defined more preciselywithin these guidelines in a way that links with the weights in Markov logic, thereby pointing to aprobabilistic semantics for the weighted abduction numbers.There are two sorts of numbers in weighted abduction?the weights on conjuncts in the antecedentsof Horn clause axioms, and the costs on conjuncts in goal expressions, which are existentially quantifiedconjunctions of positive literals.
We deal first with the weights, then with the costs.The space of events over which probabilities are taken is the set of proof graphs constituting the bestinterpretations of a set of texts in a corpus.
Thus, by the probability of p(x) given q(x), we mean theprobability that p(x) will occur in a proof graph in which q(x) occurs.The translation from weighted abduction axioms to Markov logic axioms can be broken into twosteps.
First we consider the ?or?
node case, determining the relative costs of axioms that have the sameconsequent.
Then we look at the ?and?
node case, determining how the weights should be distributedacross the conjuncts in the antecedent of a Horn clause, given the total weight for the antecedent.Weights on Antecedents in Axioms.
First consider a set of Horn clause axioms all with the sameconsequent, where we collapse the antecedent into a single literal, and for simplicity allow x to stand forall the universally quantified variables in the antecedent, and assume the consequent to have only thosevariables.
That is, we convert all axioms of the formp1(x) ?
.
.
.
?
q(x)into axioms of the formAi(x) ?
q(x), where p1(x) ?
.
.
.
?
Ai(x)To convert this into Markov logic, we first introduce the hard constraintAi(x) ?
q(x).In addition, given a goal of proving q(x), in weighted abduction we will want to backchain on at least(and usually at most) one of these axioms or we will want simply to assume q(x).
Thus, we can introduceanother hard constraint with the disjunction of these antecedents as well as a literal AssumeQ(x) thatmeans q(x) is assumed rather than proved.58q(x) ?
A1(x) ?
A2(x) ?
.
.
.
?
An(x) ?
AssumeQ(x).Then we need to introduce soft constraints to indicate that each of these disjuncts is a possible explana-tion, or proof, of q(x), with an associated probability, or weight.
[wi] q(x) ?
Ai(x), .
.
.
[w0] q(x) ?
AssumeQ(x)The probability that AssumeQ(x) is true is the conditional probability P0 that none of the antecedentsis true given that q(x) is true.P0 = P (?
[A1(x) ?
A2(x) ?
.
.
.
?
An(x)] | q(x))In weighted abduction, when the antecedent weight is greater than one, we prefer assuming the conse-quent to assuming the antecedent.
When the antecedent weight is less than one we prefer to assume theantecedent.
If the probability that an antecedent Ai(x) is the explanation of q(x) is greater than P0, itshould be given a weighted abduction weight vi less than 1, making it more likely to be chosen.3 Cor-respondingly, if it is less than P0, it should be given a weight vi greater than 1, making it less likelyto be chosen.
In general, the weighted abduction weights should be in reverse order of the conditionalprobabilities Pi that Ai(x) is the explanation of q(x).Pi = P (Ai(x) | q(x))If we assign the weights vi in weighted abduction to bevi = logPilogP0then this is consistent with informal guidelines in [7] on the meaning of these weights.
We use the logsof the probabilities rather than the probabilities themselves to moderate the effect of one axiom beingvery much more probable than any of the others.Kate and Mooney [8], in their translation of logical abduction into Markov logic, also include softconstraints stipulating that the different possible explanations Ai(x) are normally mutually exclusive.We do not do that here, but we get a kind of soft mutual exclusivity constraint by virtue of the axiomsbelow that levy a cost for any literal that is taken to be true.
In general, more parimonious explanationswill be favored.Nevertheless, in most cases a single explanation will suffice.
When this is true, the probability ofAi(x) holding when q(x) holds is ewiZ .
Then a reasonable approximation for the relation between theweighted abduction weights vi and the Markov logic weights wi iswi = ?vilogP0Weights on Conjuncts in Antecedents.
Next consider how cost is spread across the conjuncts in theantecedent of a Horn clause in weighted abduction.
Here we use u?s to represent the weighted abductionweights on the conjuncts.p1(x)u1 ?
p2(x)u2 ?
... ?
A(x)The u?s should somehow represent the semantic contribution of each conjunct to the conclusion.
That is,given that the conjunct is true, what is the probability that it is part of an explanation of the consequent?Conjuncts with a higher such probability should be given higher weights u; they play a more significantrole in explaining A(x).Let Pi be the conditional probability of the consequent given the ith conjunct in the antecedent.Pi = P (A(x)|pi(x))and let Z be a normalization factor.Z = ?ni=1 Pi3We use vi for these weighted abduction weights and wi for Markov logic weights.59Let v be the weight of the entire antecedent as determined above.Then it is consistent with the guidelines in [7] to define the weights on the conjuncts as follows:ui = vPiZThe weights ui will sum to v and each will correspond to the semantic contribution of its conjunct to theconsequent.In Markov logic, weights apply only to axioms as a whole, not parts of axioms.
Thus, the singleaxiom above must be decomposed into one axiom for each conjunct and the dependencies must bewritten as[wi] pi(x) ?
A(x), .
.
.The relation between the weighted abduction weights ui and the Markov logic weights wi can beapproximated byui = ve?wiZCosts on Goals.
The other numbers in weighted abduction are the costs associated with the conjunctsin the goal expression.
In weighted abduction these costs function as utilities.
Some parts of the goalexpression are more important to interpret correctly than others; we should try harder to prove theseparts, rather than simply assuming them.
In language it is important to recognize the referential anchorof an utterance in shared knowledge.
Thus, those parts of a sentence most likely to provide this anchorhave the highest utility.
If we simply assume them, we lose their connection with what is already known.Those parts of a sentence most likely to be new information will have a lower cost, because we usuallywould not be able to prove them in any case.Consider the two sentencesThe smart man is tall.The tall man is smart.The logical form for each of them will be(?x)[smart(x) ?
tall(x) ?man(x)]In weighted abduction, an interpretation of the sentence is a proof of the logical form, allowing assump-tions.
In the first sentence we want to prove smart(x) to anchor the sentence referentially.
Then tall(x)is new information; it will have to be assumed.
We will want to have a high cost on smart(x) to forcethe proof procedure to find this referential anchor.
The cost on tall(x) will be low, to allow it to beassumed without expending too much effort in trying to locate that fact in shared knowledge.In the second sentence, the case is the reverse.Let?s focus on the first sentence and assume we know that educated people are smart and big peopleare tall, and furthermore that John is educated and Bill is big.educated(x)1.2 ?
smart(x)big(x)1.2 ?
tall(x)educated(J), big(B)In weighted abduction, the best interpretation will be that the smart man is John, because he is educated,and we pay the cost for assuming he is tall.
The interpretation we want to avoid is one that says x is Bill;he is tall because he is big, and we pay the cost of assuming he is smart.
Weighted abduction with itsdifferential costs on conjuncts in the goal expression favors the first and disfavors the second.In weighted abduction, only assumptions cost; literals that are proved cost nothing.
When the aboveaxioms are translated into Markov logic, it would be natural to capture the differential costs by attaching anegative weight to smart(x) to model the cost associated with assuming it.
However, this weight wouldapply to any assignment in which smart(J) is true, regardless of whether it was assumed, derived from60an assumed fact, or derived from a known fact.
A potential solution might be to attach the negative weightto AssumeSmart(x).
But the first axiom above allows us to bypass the negative weight on smart(x).We can hypothesize that x is Bill, pay a low cost on AssumeEducated(B), derive smart(B), and getthe wrong assignment.
Thus it is not enough to attach a negative weight to high-cost conjuncts in thegoal expression.
This negative weight would have to be passed back through the whole knowledge base,making the complexity of setting the weights at problem time in the MLN knowledge base equal to thecomplexity of running the inference problem.An alternative solution, which avoids this problem when the forward inferences are exact, is to usea set of predicates that express knowing a fact without any assumptions.
In the current example, wewould add Ksmart(x) for knowing that an entity is smart.
The facts asserted in the data base are nowKeducated(J) and Kbig(B).
For each hard axiom involving non-K predicates, we have a correspond-ing axiom that expresses the relation between the K-predicates, and we have a soft axiom allowing us tocross the border between the K predicates and their non-K counterparts.Keducated(x) ?
Ksmart(x)., .
.
.
[w] Ksmart(x) ?
smart(x), .
.
.Here the positive weight w attached is chosen to counteract the negative weight we would attach tosmart(x) to reflect the high cost of assuming it.This removes the weight associated with assuming smart(x) regardless of the inference path thatleads to knowing smart(x) (KSmart(x))).
Further, this translation takes linear time in the size ofthe goal expression to compute, since we do not need to know the equivalent weighted abduction costassigned to the possible antecedents of smart(x).If the initial facts do not include KEducated(B) and instead educated(B) must be assumed, thenthe negative weight associated with smart(B) is still present.
In this solution, there is no danger thatthe inference process can by-pass the cost of assuming smart(B), since it is attached to the requiredpredicate and can only be removed by inferring KSmart(B).Finally, there is a tendency in Markov logic networks for assignments of high probability for proposi-tions for which there is no evidence one way or the other.
To suppress this, we associate a small negativeweight with every predicate.
In practice, it has turned out that a weight of ?1 effectively suppresses thisbehavior.4 Experimental ResultsWe have tested our approach on a set of fourteen challenge problems from [7] and subsequent papers,designed to exercise the principal features of weighted abduction and show its utility for solving naturallanguage interpretation problems.
The knowledge bases used for each of these problems are sparse,consisting of only the axioms required for solving the problems plus a few distractors.An example of a relatively simple problem is #5 in the table below, resolving ?he?
in the textI saw my doctor last week.
He told me to get more exercise.where we are given a knowledge base that says a doctor is a person and a male person is a ?he?.
Solvingthe problem requires assuming the doctor is male.
(?x)[doctor(x)1.2 ?
person(x)](?x)[male(x).6 ?
person(x).6 ?
he(x)]The logical form fragment to prove is (?x)he(x), where we know doctor(D).A problem of intermediate difficulty (#7) is resolving the three lexical ambiguities in the sentenceThe plane taxied to the terminal.61where we are given a knowledge base saying that airplanes and wood smoothers are planes, planesmoving on the ground and people taking taxis are both described as ?taxiing?, and computer terminalsand airport terminals are both terminals.An example of a difficult problem is #12, finding the coherence relation, thereby resolving the pro-noun ?they?, between the sentencesThe police prohibited the women from demonstrating.
They feared violence.The axioms specify relations between fearing, not wanting, and prohibiting, as well as the defeasibletransitivity of causality and the fact that a causal relation between sentences makes the discourse coher-ent.The weights in the axioms were mostly distributed evenly across the conjuncts in the antecedents andsummed to 1.2.For each of these problems, we compare the performance of the method described here with a man-ually constructed gold standard and also with a method based on Kate and Mooney?s (KM) approach.In this method, weights were assigned to the reversed clauses based on the negative log of the sum ofweights in the original clause.
This approach does not capture different weights for different antecedentsof the same rule, and so has less fidelity to weighted abduction than our approach.
In each case, we usedAlchemy?s probabilistic inference to determine the most probable explanation (MPE) [12].In some of the problems the system should make more than one assumption, so there are 22 assump-tions in total over all 14 problems in the gold standard.
Using our method, 18 of the assumptions werefound, while 15 were found using the KM method.
Table 1 shows the number of correct assumptionsfound and the running time for the two approaches for each problem.
Our method in particular providesgood coverage, with a recall of over 80% of the assumptions made in the gold standard.
It has a shorterrunning time overall, approximately 5.3 seconds versus 8.7 seconds for the reversal method.
This islargely due to one problem in the test set, problem #9, where the running time for the KM method isrelatively high because the technique finds a less sparse network, leading to larger cliques.
There weretwo problems in the test set that neither approach could solve.
One of these contains predicates that havea large number of arguments, leading to large clique sizes.5 Current and Future DirectionsIn other work [11] we are experimenting with using weighted abduction with a knowledge base with tensof thousands of axioms derived from FrameNet for solving problems in recognizing textual entailment(RTE2) from the Pascal dataset [1].
For a direct comparison between standard weighted abduction andthe Markov logic approach described here, we are also experimenting with using the latter on the sametask with the same knowledge base.For each text-hypothesis pair, the sentences are parsed and a logical form is produced.
The output forthe first sentence forms the specific knowledge the system has while the output for the second sentenceis used as the target to be explained.
If the cost of the best explanation is below a threshold we take thetarget sentence to be true given the initial information.It is a major challenge to scale our approach to handle all the problems from the RTE2 developmentand test sets.
We are not yet able to address the most complex of these using inference in Markov logicnetworks.
However, we have devised a number of pre-processing steps to reduce the complexity of theresultant network, which significantly increase the number of problems that are tractable.The FrameNet knowledge base contains a large number of axioms with general coverage.
For anyindividual entailment problem, most of them are irrelevant and can be removed after a simple graphicalanalysis.
We are able to remove more irrelevant axioms and predicates with an iterative approach that in62Our Method KM Method GoldProblem score seconds score seconds standard1 3 300 3 16 32 1 250 1 265 13 1 234 1 266 14 2 234 2 203 25 1 218 1 218 16 1 218 0 265 17 3 300 3 218 38 1 200 1 250 19 2 421 0 5000 210 1 2500 1 1500 311 0 0 112 0 0 113 1 250 1 250 114 1 219 1 219 1Total 18 5344 15 8670 22Table 1: Performance on each problem in our test set, comparing two encodings of weighted abductioninto Markov logic networks and a gold standard.each iteration both drops axioms that are shown to be irrelevant and simplifies remaining axioms in sucha way as not to change the probability of entailment.We also simplify predications by removing unnecessary arguments.
The most natural way to convertFrameNet frames to axioms is to treat a frame as a predicate whose arguments are the frame elements forall of its roles.
After converting to Markov logic, this results in rules having large numbers of existentiallyquantified variables in the consequent.
This can lead to a combinatorial explosion in the number ofpossible ground rules.
Many of the variables in the frame predicate are for general use and can be prunedin the particular entailment.
Our approach essentially creates abstractions of the original predicates thatpreserve all the information that is relevant to the current problem but greatly reduces the number ofground instances to consider.Before implementing these pre-processing steps, only two or three problems could be run to com-pletion on a Macbook Pro with 8 gigabytes of RAM.
After making them, 28 of the initial 100 problemscould be run to completion.Work on this effort continues.6 SummaryWeighted abduction is a logical reasoning framework that has been successfully applied to solve a num-ber of interesting and important problems in computational natural-language semantics ranging fromword sense disambiguation to coreference resolution.
However, its method for representing and combin-ing assumption costs to determine the most preferred explanation is ad hoc and without a firm theoreticalfoundation.
Markov Logic is a recently developed formalism for combining first-order logic with prob-abilistic graphical models that has a well-defined formal semantics in terms of specifying a probabilitydistribution over possible worlds.
This paper has presented a method for mapping weighted abduction63to Markov logic, thereby providing a sound probabilistic semantics for the approach and also allowingit to exploit the growing toolbox of inference and learning algorithms available for Markov logic.
Com-plementarily, it has also demonstrated how Markov logic can thereby be applied to help solve importantproblems in computational semantics.References[1] Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpek-tor.
The second pascal recognising textual entailment challenge.
In Proceedings of the Second PASCALChallenges Workshop on Recognising Textual Entailment, Venice, Italy, 2006.
[2] Eugene Charniak and Solomon E. Shimony.
Cost-based abduction and map explanation.
Artificial ArtificialIntelligence Journal, 66(2):345?374, 1994.
[3] P. T. Cox and T. Pietrzykowski.
Causes for events: Their computation and applications.
In J. Siekmann,editor, 8th International Conference on Automated Deduction (CADE-8), Berlin, 1986.
Springer-Verlag.
[4] P. Domingos and D. Lowd.
Markov Logic: An Interface Layer for Artificial Intelligence.
Morgan & Claypool,San Rafael, CA, 2009.
[5] L. Getoor and B. Taskar, editors.
Introduction to Statistical Relational Learning.
MIT Press, Cambridge,MA, 2007.
[6] S. Harabagiu and D.I.
Moldovan.
Lcc?s question answering system.
In 11th Text Retrieval Conference,TREC-11, Gaithersburg, MD., 2002.
[7] Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt, and Paul A. Martin.
Interpretation as abduction.
Artifi-cial Intelligence, 63(1-2):69?142, 1993.
[8] Rohit Kate and Ray Mooney.
Probabilistic abduction using markov logic networks.
In IJCAI 09 Workshopon Plan, Activity and Intent Recognition, 2009.
[9] Hector J. Levesque.
A knowledge-level account of abduction.
In Eleventh International Joint Conference onArtificial Intelligence, volume 2, pages 1061?1067, Detroit, Michigan, 1989.
[10] Hwee Tou Ng and Raymond J. Mooney.
The role of coherence in constructing and evaluating abductiveexplanations.
In P. O?Rorke, editor, Working Notes, AAAI Spring Symposium on Automated Abduction,Stanford, California, March 1990.
[11] E. Ovchinnikova, N. Montazeri, T. Alexandrov, J. Hobbs, M. McCord, and R. Mulkar-Mehta.
Abductivereasoning with a large knowledge base for discourse processing.
In Proceedings of the 9th InternationalConference on Computational Semantics, Oxford, United Kingdom, 2011.
[12] J. Pearl.
Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.
Morgan Kaufmann,San Francisco, CA, 1988.
[13] Harry E. Pople.
On the mechanization of abductive logic.
In Third International Joint Conference on ArtificialIntelligence, pages 147?152, Stanford, California, August 1973.
[14] M. Richardson and P. Domingos.
Markov logic networks.
Machine Learning, 62:107?136, 2006.64
