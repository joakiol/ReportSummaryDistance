GOATS TO SHEEP: CAN RECOGNITIONRATE BE IMPROVED FOR POOR TANGORA SPEAKERS?Catalina M. Dan.isUser Interface InstituteIBM Thomas J. Watson Research CenterYorktown Heights, NY 10598ABSTRACTThis paper eports on a study of recognition performance for a group of new users during their first monthof experience with the TANGORA system.
TANGORA is a 20,000 word, speaker dependent,isolated-word system which transcribes speech input into text in real-time.
Twelve users, six males and sixfemales, participated in 21 sessions each, during which they read aloud unrelated sentences selected from acorpus of office correspondence.
Their goal was to develop a speaking style which minimizedTANGORA's recognition error.
Hypotheses were generated about users' speech abits which may havelead to increased recognition error and suggestions were made to them on how to modify their speaking styleaccordingly.
On average, recognition errors decreased by 33% from the first to the fourth week.
Somecharacteristics of successful speakers have been identified.INTRODUCTIONThere is a great deal of variability in the accuracy with which users of large vocabulary automatic speechrecognition (hereafter ASR) systems are recognized.
In a typical finding, Brown, Vosburgh & Canetti (inpreparation) reported that recognition error for a group of first time users of a 20,000 word ASR systemvaried from 2.0% to 14%.
Two conclusions may be drawn from such results.
First, the technology is goodenough to produce a high degree of recognition accuracy for some speakers.
Second, there are somespeakers who encounter severe problems and, for them, the technology is probably not usable.
Thisresearch was motivated by the latter group.
It is concerned with whether ecognition accuracy can beimproved through behavioral means for speakers who are initially poorly recogniT.ed by an ASR system.Can a user modify his or her speaking style in ways which will be acceptable to the user and will result ina significant improvement in recognition, thereby making ASR systems more widely usable?IBM's experimental TANGORA system, implemented on the Personal Computer AT, was used in thisinvestigation.
This system functions in real-time and has the capacity to recognize 20,000 words.TANGORA is an isolated word system; this requires that users pause briefly between words.
Further, itis a speaker-dependent system and must be "trained" to the user's voice.
Such a system is most accuratewhen it has a description or model of the acoustic haracteristics of a user's voice.
This speaker model isgenerated by TANGORA from a sample (1200-2400 words) of the user's peech, collected uring a "trainingsession."
A description of the TANGORA system can be found in Averbuch et al, (1986).This investigation had four general goals.
The first was to investigate r cognition performance for a groupof new users during their first month of experience with the TANGORA system.
The focus was ondetermining the rate and amount of improvement, if any, in recognition accuracy.
It is an important, butunanswered question, whether poor ASR speakers can improve substantially with experience.
The secondgoal was to determine whether e-training TANGORA after users have had experience speaking inisolated-word mode is a useful strategy for improving recognition performance.
One might expect hatexperience with an ASR system leads users to modify their speaking style.
Consequently, use of anup-to-date speaker model which reflects these changes might result in improved recognition accuracy.
Thethird goal of this study was to identify those aspects of a user's speaking style which resulted in errors by145the TANGORA system.
A description of these problems would serve as the basis for suggestions to theuser on how to modify his or her speaking style in order to produce more accurate recognition performance.The final goal was to characterize speakers who are recognized accurately by TANGORA.METHODTwelve users (six males, six females) participated in 21 sessions each.
Their task was to produce speechwhich would be recognized by TANGORA with a high degree of accuracy.
To this end, users wereencouraged to experiment with their speaking style and to use the feedback provided by recognition errorsto shape their speaking style.
In the first session, users were given a basic explanation of how their speechwould be recognized by the TANGORA system.
The importance of clear and consistent speech wasstressed.
In addition, they were given 30 minutes of experience talking in isolated-word mode with anotheruser's model.The remaining 20 sessions consisted of four iterations of a five session sequence (see Figure 1).
The firstsession in each sequence was devoted to training the system.
The user read aloud, in isolated-word mode,a 2400 word (171 sentence) text.
A model of the speaker's voice was computed from the speech samplecollected uring these training sessions.
Each session lasted approximately one hour.CONTENT SESSION #Introduction ITraining of System - model I 2Practice A 3Practice B 4Test I - model I 5Test 2 - model I 6Feedback; Training of System - model 2 7Practice A 8Practice B 9Test I - model 2 I0Test 2 - model 2 11Feedback; Training of System - model 3 12Practice A 13Practice B 14Test I - model 3 15Test 2 - model I 16Feedback; Training of System - model 4 17Practice A 18Practice B 19Test I - model 4 20Test 2 - model 2 21Figure 1.
Sequence of experimental sessions.Order of sessions 15 & 16 and 20 & 21 was counter-balanced across users.In the first two weeks of the study, the speaker model which resulted from a training session was used byTANGORA to decode the speech produced uring the following four sessions in the five session sequence.146In each of the final two weeks, the newly created speaker model was used in next three sessions only.
Thefourth session was decoded against a model generated uring an earlier week, as described below.Two practice sessions followed a training session.
Users were given lists of 20 unrelated sentences, electedfrom a corpus of office correspondence, to read aloud as input to the system.
They were instructed toexperiment with their speaking style and to try to develop a style which would be successfully recognizedby TANGORA.
In order to facilitate this process, users immediately re-read a sentence if it was notperfectly recognized, up to a total of four times.
They attempted to use the feedback from misrecognizedwords to selectively modify their speaking styles.
The final two sessions in each sequence were devoted totests: Users were given 40 or 50 sentence lists (also office correspondence) to read aloud to the system andwere instructed to use what they had determined to be a "good" speaking style in an effort to produce perfectrecognition.
They read each sentence only once.
It should be noted that all words in both the practice andthe test sentences were included in TANGORA's vocabulary and that both practice and test sentence setswere carefully controlled for sentence l ngth and perplexity.Prior to the second, third and fourth training sessions, each user's performance was analyzed by theexperimenter who generated hypotheses about the user's speech abits which may have caused him or herto be poorly recognized by TANGORA.
These hypotheses were described to the user and suggestions weremade on how the user might modify his or her speaking style.In order to determine whether e-training the system would improve recognition accuracy, decoding of eachuser's speech was done against both the current and an older speaker model during weeks 3 and 4.
Thus,during the third week, users completed one test session with the newly generated speaker model and onewith the model generated at the beginning of the first week.
Similarly, the model from the fourth week wascompared against he one generated uring the second week.
If training (which includes the effect ofpractice) rather than practice alone is the means whereby accuracy is improved, then the following resultsshould be obtained: (1) accuracy during the third and fourth weeks should be better with each week'scurrent model than with the model which had been generated two weeks earlier, and (2) accuracy duringthe third week with the third week's model should be better than accuracy from the first week with the firstweek's model and similarly, better during the fourth week with the fourth week's model than in the secondweek.RESULTSInitial performance for this group of users was comparable to previous results with the TANGORA system.Error rate for the first day of practice with the system ranged from 4.5% to 14.0%, with an average of 8.6%.This replicates the findings for first day performance r ported by Brown et at.
(in preparation).To address the issue of changes in recognition performance over the four week period, error rate for eachweek was computed by averaging data from all sessions obtained with a given speaker model, when thatmodel was current.
That is, for weeks one and two, averages were taken over Practice Session 1, PracticeSession 2, Test Session 1 and Test Session 2.
Whereas in Weeks 3 and 4, averages were taken over the twoPractice sessions and only one Test session.
These data were then averaged over all 12 users.
The resultantaverage rror rate for the first week was 8.4%.
It dropped to 7.5% in the second week, to 6.4% in the thirdweek and to 5.6% in the final week.
Thus, there was a 33% reduction in error rate from the first to thefourth week (see Figure 2).
There was no reduction in error within a week.
That is, performance wasconstant over the four (Weeks 1 & 2) or three (Weeks 3 & 4) sessions in which each speaker model wasused as a current model.
Data were collapsed over all four weeks and all users to produce an average rrorrate for the first day, for the Second day, for the third day and for the fourth day.
These error rates were,respectively, 6.1%, 5.9%, 6.3% and 6.2%.Recognition accuracy for 11 of the 12 users improved from the first to the fourth week.
Figure 3 shows firstweek error rate plotted against final week error rate for each user.
The diagonal ine represents no147improvement.
As can be seen from the figure, only one user fell at or above this line.
Further, eight of the12 users obtained an error rate under six percent by the end of the study.
Whereas, during the first week,10~i| .8-4-!
!
!
I1 | 8 4geekFigure 2: Recognition error at the four weeks, averaged over all users.only three users had error rates between 5.0% and 6.0%; the error for the remaining nine users fell between6.0% and 16.0%.
Four speakers completed the study with an error rate between 6.8% and 8.3%.16-14;18-'~ 11,!
1o,ii:!i 2z;0 ~.
.
.
.
.
.
.
.
.
.
;, ' ;s '  ' o I e a 4 o 8 v 8 o to It  t416| Pa~oiplit.lon \]h'ror - geek  IFigure 3: First week error rate vs fourth week error rate for each user.148Re-training proved to be a successful technique for decreasing error rate (see Figure 4).
During the thirdweek, error rate for the one test session in which the current (i.e., third week) speaker model was used was6.9%.
However, use of the older speaker model (i.e., the one generated uring the first week) during thethird week produced an error rate of 10.3%.
A similar pattern was observed uring the fourth week.
Errorrate with the current, fourth week, model was 5.7%.
It increased to 8.0% when the model from the secondweek was used.i'\]Vet.It 3 1leek 4J ?
*, e  * i?
?
??
?
?o e i, * e i?
?
?~ e  ?
,o *  ?~ e  ?
,, e  ?
,?
?
?p*  e ,e e ?~ e  ?
,t ?
?
,?
e *e ?
?t m e ,a a m~ cumnt\ [ \ ]  OldFigure 4.
Effect of re-training manipulation.A number of speech abits brought by users to the ASR situation were identified as contributing to poorrecognition by TANGORA.
These included: (a) a too fast speech rate, (b) failure to pause between words,(c) hyper-correct articulation of the final phoneme in words, and (d) incomplet  articulation of the firstphoneme in words.
Suggestions on how to modify speaking style were made to users and, in some cases,dramatic decreases in recognition error followed.
Speaking at a too fast rate, which resulted in theproduction of words which were not clearly articulated, was frequently observed with these users.
The errorwas easily corrected by slowing down.
Only one user had pervasive difficulties pausing between words.
Intrying to overcome this problem, in response to feedback, he developed the habit of emphasizing the finalphoneme in words.
This, referred to here as hyper-articulation, resulted in substitution errors composedof the word spoken by the user plus an unintended word ending (e.g., hearT - > hearts; detail - > detailed).Unclear or too short articulation of the first phoneme in words, particularly for words with unstressed initialsyllables, frequently resulted in errors as well.
Most users were able to modify their speaking style inresponse to feedback about types of recognition errors the TANGORA system was making.
Thesebehavioral interventions were less successful for the four speakers who completed the study with the highesterror rate (between 6.8% and 8.3%).
Further analysis of their speech is needed to determine why this wasthe case.DISCUSSIONThe data presented here speak to four points.
First, the large range in initial error rate observed for the newusers in this and previous tudies uggests that large vocabulary ASR systems uch as the TANGORA arenot "walk-up and use" systems.
Most users in this study had to modify the way they spoke in order to berecognized well.
It is encouraging, however, that considerable improvement was realized by making changesat the behavioral level.
Users discovered some of the changes themselves and were also able to implementsuggestions made by the experimenter.
This resulted in a decrease in recognition error of 33% from the firstto the fourth week.149Re-training on a weekly basis was instrumental in decreasing error rate.
The relative contribution ofpractice and of a better speaker model in the observed improvement can not be determined from these datasince the later models were produced by more practiced speakers.
It is clear, however, that practice alone,without re-training will not result in performance as good as that which results from practice plusre-training.
As the Week 3 and Week 4 test pairs have shown, decoding the speech from a user in a morepracticed state against a model generated earlier, when recognition performance was worse, produces adecrement in performance relative to decoding against a current model.
The failure to find anyimprovement in performance within a week (i.e., with the same speaker model) provides further support forthe importance of re-training in decreasing recognition error.The tentative characterization f a "good" TANGORA speaker which has emerged from this study is onewho speaks at a fairly slow (approximately 70words per minute), evenly paced rate and articulates clearly,particularly at the beginning of words.
The fact that the speech of some users was still not being recoEnizedwell at the end of the fourth week suggests that some modifications at the system level may be needed aswell in order to make TANGORA generally usable.From the standpoint of developing an application using large-vocabulary ASR technology, this study arguesfor the importance of including tests with "live" users in investigations of recognition accuracy for suchsystems.
It is necessary to provide systems designers with an accurate, realistic characterization f theirsystem and there are aspects of speaking style which emerge when naive users interact with an ASR system,which probably cannot be captured using "canned" speech.
First, users clearly modify their speaking stylein response to the feedback provided by recognition accuracy in the testing situation.
The extent and natureof such adaptation by the user will provide valuable feedback to the designers of the system.
Second, it isimportant to sample users under conditions of everyday use in order to capture the variability in the qualitywhich exists in normal speech.
Factors such as alertness, anxiety, and illness affect voice quality and ASRtechnology must be robust with respect to them if it is to be usable.AcknowledgmentsI would like to thank Norman Brown for many discussions at all stages of this project and Linda Jaynesfor her assistance in data collection.
My thanks to the Speech Recognition Group at the T. J. WatsonResearch Center, particularly Ken Davies, for providing technical support as well as informative discussionsabout TANGORA.ReferencesAverbuch, A., Bahl, L., Bakis, R., Brown, P., Cole, A., Daggett, G., Das, S., Davies, K., DeGennaro, S.,de Souza, P., Epstein, E., Farleigh, D., Jelinek, F., Katz, S., Lewis, B., Mercer, R., Nadas, A.Nahamoo, D., Shichman, G., & SpineUi, P. (1986).
An IBM PC-based large-vocabularyisolated-utterance speech recognizer.
(Research Report RC No.
58679).
Yorktown Heights, NY:IBM, Thomas J. Watson Research Center.Brown, N. R., Vosburgh, A. M., & Canetti, S. (in preparation).
Factors affecting the recognition accuracyof a large-vocabulary voice recognition system.150
