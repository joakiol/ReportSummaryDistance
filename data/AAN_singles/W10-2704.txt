Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 19?24,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics?Hello Emily, how are you today?
?Personalised dialogue in a toy to engage childrenCarole AdamRMIT UniversityMelbourne, Australia.carole.adam.rmit@gmail.comLawrence CavedonRMIT UniversityMelbourne, Australia.lawrence.cavedon@rmit.edu.auLin PadghamRMIT UniversityMelbourne, Australia.lin.padgham@rmit.edu.auAbstractIn line with the growing interest in conver-sational agents as companions, we are de-veloping a toy companion for children thatis capable of engaging interactions and ofdeveloping a long-term relationship withthem, and is extensible so as to evolve withthem.
In this paper, we investigate the im-portance of personalising interaction bothfor engagement and for long-term relation-ship development.
In particular, we pro-pose a framework for representing, gath-ering and using personal knowledge aboutthe child during dialogue interaction.
11 IntroductionIn recent years there has been an increasing in-terest in so-called Companion agents: agents thatare intelligent, and built to interact naturally (viaspeech and other modalities) with their user over aprolonged period of time, personalising the inter-action to them and developing a relationship withthem.
The EU Companions project2 is the mostwell known such project, with applications suchas a companion for the elderly (Field et al, 2009),and a health and fitness companion (Stahl et al,2009).
In our work, together with industry part-ners, we are developing a speech-enabled compan-ion toy for children.
While there are many ?smarttoys?
on the market, as far as we are aware ourwork is unique in attempting to develop a ?com-panion toy?
for a child, evolving with them overa long period of time.
As with other projects onintelligent companions, a crucial task is to build along-term relationship with the user, by a series ofinteractions over time, that the user experiences asengaging and valuable.1A slightly longer version of this paper is currently underreview elsewhere.
If both papers are accepted for publicationwe will modify to ensure that they expand different aspects.2See www.companions-project.org.According to models of the ?enjoyability?
ofhuman-computer interaction (Brandtzaeg et al,2006), there are three main features making an in-teractive system engaging for the user: the usershould feel in control of the interaction (whichincludes being able to customise it and gettingtimely feedback); the demands on the user shouldbe adapted to their capabilities, i.e.
the interactionshould be challenging and surprising but not over-whelming; and the system should support socialinteraction rather than isolating the user.
Anotherimportant aspect of any engaging interaction is forit to be personalised, i.e.
customised to the par-ticular interlocutor and their environment.
Otherimportant features for engagement include coher-ence of the dialogue, emotional management, andpersonality.
In this paper we focus specifically onthe issue of appropriate personalisation of interac-tions with a child, and how to realise this.Existing personalised systems mainly have atask-oriented focus, i.e.
they aim at building auser profile and using it to facilitate the user?s task(e.g.
Web navigation assistants or product recom-mendation systems (Abbattista et al, 2003)), andat being user-configurable.
On the contrary weaim at personalising the interaction to build a re-lationship and engage a child.
The main noveltiesof our system are that: it is not task-oriented; itis specifically designed for children; and its be-haviour is derived from actual interaction data.
In-deed, in order to understand the kinds of person-alisation occurring in natural dialogues with chil-dren, we have analysed corpora of children?s dia-logues (MacWhinney, 1995; MacWhinney, 2000).We have then developed a framework that enablesthe implementation of a number of these person-alised behaviours within our intelligent toy.The contribution of this paper is the identifi-cation of different kinds of personalisation be-haviours in dialogue with children, based on actualdata, plus the framework to realise these withinan implemented system.192 Personalisation behaviours2.1 Corpus analysisWe have analysed examples of children-adult di-alogues (mainly from the CHILDES database(MacWhinney, 1995; MacWhinney, 2000); onedialogue from a forthcoming study performedwith a puppet as part of this project) in order todetermine the types of behaviours that adults useto personalise their interaction with a child.Relation to selfA first observation is that children often try to re-late conversation to themselves.
This is illustratedby this conversation between a girl (G) and hermother (M) about a visit to the doctor.G What?s polio?M An illness that makes you crippled.
That?s why you getall those injections and... A long time ago, kiddies, kid-dies used to die with all that things.G will I ?M hmm.
You aren?t going to die.Personal questionsAdults also often ask the child questions aboutthemselves.
This dialogue illustrates a conversa-tion between an adult (A) and a child (C) about C?sholidays.
Notice that the questions are adapted tothe context (ask about holidays in summer).A Did you go on vacation over the summer?
Did you?A Where?d you go?
To the beach?C Yes.A Yeah?
Did you go by yourself?
No.
Why laugh?
Youcould go by yourself.A Do you have brothers and sisters?C Just a little sister.A A sister?
Did she go too?
On vacation?Child controlEven if the adult is asking the questions, the childretains some control over the interaction.
The fol-lowing dialogue between a boy (B) and his grand-mother (G) shows how the adult follows the childwhen he switches away from a disliked topic.
Thisdialogue also shows the adult commenting on thechild?s tastes based on her knowledge of them.G how are you getting on in school?B we?re not going to go shopping today.G eh?B shopping today.G ...B and chips.G going to have chips?B mm.G you likes that.ReciprocityAnother way for the adult to learn personal infor-mation about the child without asking questionsis to confide personal information first, which en-courages the child to reciprocate.
In this dialoguebetween a child (C) and a puppet (P) controlledby an adult, P confides personal information (itstastes), which leads the child to do the same.P My favourite drink is lemon.
Lemon soft drink.
I likethat.C Mine is orange juice.P mmhm.
Orange one?
You like the orange one?C Orange juice (nodding)Recalling shared activitiesAnother form of personalisation is recalling pastshared activities.
In the following dialogue, amother (M) reads a book to her child (C); whena picture of a snowman appears in the book sherecalls the child recently making one with her.M what did we make outside here today?C um I don?t know.M did we make a man?C yeah.M a snowman?C yeah.Child?s preferencesAnother way to personalise interaction is to recalla child?s preferences.
For example this dialogueinvolves a child (C) and an interrogator (I) wantingto record a story.
Here the child corrects incorrectknowledge; this update should be remembered.I Do you wanna tell a story?C No.
I won?t.I No, you don?t.I You told me down there that you like stories.C No, I hate stories.Child?s agendaParents may also use knowledge about a child?sagenda (i.e.
planned future activities, school, etc.
)and make relevant and timely comments about it.In this dialogue a mother (M) and her friend (F)talk with a boy (B) about his next school day, whenhe is supposed to see chicken eggs hatching.F Oh you?re going to see the little chicks tomorrow areyou.
You?ll have to tell me what it?s like.
I haven?tnever seen any.B I I haven?t either.F I haven?t.M We?ve seen them on the tellie, haven?t we?F I haven?t seen those little ones.M haven?t you?F So you?ll have to tell me.M Have you seen them on the tellie?B mm [= yes].We notice again that when the mother?s friendconfides some information (she never saw that),the child reciprocates (he neither).
Moreover themother again shows memory of past activities(seeing something on television).202.2 Personalisation strategiesBased on our analysis of adult-children dialoguecorpora, we have designed a number of strategiesto allow our toy to generate these kinds of person-alised interactions with the child.
These strategiesfit into two categories: strategies for gatheringpersonal information, and strategies for exploitingpersonal information.Information gatheringThe Toy can gather and then use different types ofinformation: (1) personal information (e.g.
fam-ily, friends, pets); (2) preferences (e.g.
favouritemovie, favourite food); (3) agenda (plays foot-ball on Saturday, has maths every Thursday);(4) activity-specific information (preferred stories,current level of quiz difficulty); (5) interaction en-vironment (e.g.
time, day, season, weather).The easiest strategy to gather this informationis to explicitly query the child.
These queries haveto be made opportunistically, e.g.
when matchingthe current conversational topic, so as to seam-lessly integrate information gathering into a con-versation.
Other strategies include confiding per-sonal information to make the child reciprocateand confide similar information; or extracting per-sonal information from spontaneous child?s input.These strategies are useful so as to avoid askingtoo many questions, which would dirupt the con-versation flow and could annoy the child.Information exploitationOne of the challenges for using the gathered per-sonal information in a conversation is to deter-mine the appropriate opportunities to do so.
Thepersonal information can be used to engage thechild in various ways, reproducing the types of be-haviours illustrated above.
In particular, our toyhas the following information exploiting strate-gies: (1) use child?s name; (2) insert commentsusing personal information; (3) ask about daily ac-tivities; (4) adapt interaction (e.g.
greetings) to thecontext (e.g.
time of day); (5) take child?s prefer-ences into account in topic or activity selection.3 The Toy architecture: overviewThis section outlines the general architecture ofthe toy.
The integration of our personalisationframework is detailed in Section 4.The central component of the Toy is the Dia-logue Manager (DM) which is made up of twocomponents: the input/output manager (IOM) re-ceives input from Automatic Speech Recognition(ASR)3 and sends output to Text-to-Speech (TTS);the Semantic Interaction Manager (SIM) receivesinput from IOM, generates the toy?s response andsends it back to IOM (see Figure 1).Figure 1: Architecture of the ToyOur current approach to ASR and utterance pro-cessing is grammar-based: on sending an out-put utterance for synthesis, the DM loads into thespeech recogniser a parameterised grammar speci-fying the set of expected user responses to this out-put.
The DM is multi-domain and extensible viadomain modules, designed to handle utterancesabout a particular domain, and encapsulating datarequired for this: a knowledge-base segment; a setof conversational fragments (see Section 3.2.2); acollection of the topics it is designed to handle;and an entry grammar to assign a topic to inputs.3.1 Input Output ManagerThe IOM is implemented using a BDI agent-oriented methodology, with dialogue processing?strategies?
built as plans.
For example, there areplans designed to handle errors or low-confidenceresults from speech recognition; plans to handleutterance content and update the information state;and plans to manage concurrent conversationalthreads and select which of a number of candidateresponses to output.3.2 Semantic Interaction ManagerThe Semantic Interaction Manager (SIM) is acomponent designed to manage flexible conver-sational flow.
The SIM maintains an agenda ofthings to say.
When an input is received fromthe IOM, it is pre-processed to generate an in-put analysis that informs the further stages of the3We have mainly used SRI?s Dynaspeak system which isdesigned for small computational platforms.21SIM plan.
In particular the input is then eitherdispatched to an existing ongoing activity if itmatches its expected answers, or an appropriatenew activity is created.
The chosen activity se-lects a conversational fragment in the topic net-work corresponding to its topic, and writes it inthe conversational agenda.
Finally the output isgenerated from the agenda and sent to the IOM.3.2.1 The conversational agendaThe conversational agenda maintained by the SIMhas two main parts.
The history represents the pastinteraction and stores past questions under discus-sion (QUD) (Ginzburg, 1997) with their receivedanswer.
The stack represents the future interac-tion and lists QUD to be asked next, in order.
Theagenda also stores the current ongoing activities(Section 3.2.3), making it possible to switch backand forth between them.3.2.2 Conversational fragmentsIn our system, we use pre-scripted pieces of dia-logue that we call conversational fragments.
Thedesigners of domain modules will provide a topicnetwork describing its domain, with nodes beingthe possible topics, having links with other topics,and providing a pool of fragments to possibly usewhen talking about this topic.
Each fragment hasan applicability condition, and provides the text ofan output as well as a list of expected answer pat-terns with associated processing (e.g.
giving feed-back) applied when the child?s response matches.This representation obviates the need for fullnatural language generation (NLG) by provid-ing semi-scripted outputs, and also informs thegrammar-based ASR by providing a list of ex-pected child answers.
Moreover it allows the Toyto generate quite flexible interactions by switchingbetween topics and using fragments in any order.3.2.3 ActivitiesWhen interacting with the child, the Toy suggestspossible activities (e.g.
quiz, story) about the avail-able topics.
Each type of activity uses specifictypes of fragments (e.g.
quiz questions with ex-pected (in)correct answers; story steps with ex-pected questions) and has particular success andfailure conditions (e.g.
a number of (in)correct an-swers for a quiz; or reaching the end for a story).This concept of activity helps to keep the dia-logue cohesive, while allowing flexibility.
It alsomeets the requirement that an engaging interactionshould be demanding for the child while stayingcontrolled by them.
Indeed a number of activitiescan be listed in the agenda at the same time, be-ing resumed or paused to allow switching betweenthem (e.g.
to follow the child?s topic requests or toinsert personalised contributions).4 The toy personalisation frameworkWe now describe our framework for implementingthe personalisation strategies specified earlier.4.1 The personalisation frameAll the information that our toy needs to person-alise an interaction is gathered using a structurecalled the personalisation frame.
This structure istailored to the requirements imposed by our archi-tecture, namely the grammar-based speech recog-nition and the absence of natural language pro-cessing.
It consists of: (1) a static list of per-sonal information fields (e.g.
child name, age); (2)a static indexed list of rules specifying when it isappropriate to insert personal comments or ques-tions in the interaction; (3) a dynamic child pro-file, storing the current values of (some) personalinformation fields, updated during interaction.Personal information fields (PIFs)Each personal information field contains: a list ofpossible values for this field (informing the ASRgrammar); and a grammar of specific ways inwhich the child may spontaneously provide infor-mation relevant to this field (allowing the toy tointerpret such input and extract the value).For example the field ?favourite animal?
has alist of animals as its values, and its grammar con-tains patterns such as ?My favourite animal is X?or ?I love X?
(where the variable X ranges overthe possible values of this field).Personalisation rulesEach personalisation rule specifies the opportunitythat triggers it, and the text of the output.
Thetext of personalisation comments and questions isscripted, and used to automatically generate con-versation fragments from the frame.
Commentrules also specify the list of personal informationfields that are used in the text of the comment,while Question rules specify the name of the fieldset by their answer and a grammar of expected an-swers, with their interpretation in terms of whichvalue the corresponding field should receive.22For example, there may be a comment rule re-ferring to the field pet type, enabling the output?I know you have a pet type?
when the keywordpet type is detected.
There may also be a ques-tion rule for asking ?What is your favourite ani-mal??
when talking about the zoo; expected an-swers would include ?I like A?
; so if the child an-swers ?I like tigers?
then the favourite animalfield would receive the value ?tigers?
as a result.OpportunitiesPersonalisation must be integrated into the con-versational management so as not to disrupt dia-logue (i.e.
the toy should still maintain a coherentinteraction).
It is thus important to accurately de-tect appropriate opportunities to insert personali-sation side-talk.
There are three types of oppor-tunities that can trigger the personalisation rules:(1) keyword opportunities (a particular keywordappears in the child?s input, e.g.
the child uses theword ?mother?
); (2) topic opportunities (the in-teraction is focused on a particular topic, e.g.
thechild is talking about koalas); (3) activity op-portunities (a particular activity is in a particularstate, e.g.
start of a story).The following sections describe how this per-sonalisation frame is used in the ConversationManager process to personalise the conversationthat is generated: we first outline the full process,before giving details about the steps where the per-sonalisation frame is used.4.2 Personalised input handlingThe following algorithm is the result of the inte-gration of personalisation into the response gen-eration plan of the SIM.
Steps manipulating thepersonalisation frame will be detailed below.1.
Initialisation (load child profile,update environment description);2.
Input reception (from IOM):3.
Input analysis (preprocess input,detect opportunities);4.
Profile update;5.
Input dispatching (to selectedactivity);6.
Activity progressing (fragmentselection);7.
Personalisation generation (generatefragment from best applicabletriggered rule);8.
Agenda processing (prioritisationof activity vs personalisationfragments);9.
Personalisation of output (detectionof opportunities, modification ofoutput);10.
Output generation (sent to IOM);11.
End turn (save profile).Fragment selection (step 6)Fragment selection is personalised in two ways.First, some fragments have applicability condi-tions concerning the interaction context and thechild?s profile.
For example a fragment such as?Hi, what?s your name??
is only applicable ifthe toy does not know the child?s name.
A greet-ing fragment such as ?Hi!
How was school to-day??
is only applicable at the end of a schoolday.
Other greeting fragments are available for dif-ferent contexts.
Second, some fragments have anadaptable content, using variables referring to thechild?s profile and to the context.
These fragmentsare only applicable if the value of these variables isknown and can be used to instantiate the variablewhen generating output.
For example a fragmentwith the text ?Hello child name!
How are you?
?is applicable once the child?s name is known.
Ora fragment saying ?I know you have a pet typecalled pet name.?
will be instantiated as ?I knowyou have a cat called Simba?.Personalisation fragments generation (step 7)When an opportunistic rule in the personalisationframe is triggered, its applicability is checked:comment rules are only applicable if the fieldsused have a value; question rules are only appli-cable if the field set has no value.
Then the appli-cable rule of highest priority is used to generate apersonalisation fragment.
Its topic is the currenttopic provided in the input analysis; its type is ei-ther ?personal question?
or ?personal comment?
;and its text is as specified in the rule.
Commentfragments have no additional applicability condi-tion and no expected answers.
Question fragmentsreceive the generic expected answers specified inthe rule, instantiated with the possible values ofthe field set by this question; the process associ-ated with them consists in setting the value of thisfield to the value extracted from the input; the de-fault process stores the full input as the value.For example with the question rule ?What isyour favourite animal??
shown above, the gener-ated fragment will expect answers such as ?I liketigers?, ?I like giraffes?, etc.
If a matching an-swer is received, then the corresponding animal isstored as the child?s favourite one in their profile.Prioritisation (step 8)When updating the agenda, several situations canarise depending on the relative priorities of person-alising the interaction vs continuing the current ac-23tivity.
If the activity can be disrupted at this point,personalisation question fragments can be addedon top of the stack in the agenda, while commentscan be appended to the activity output; if the per-sonalisation fragment has too low priority to dis-rupt the activity, then it is dropped.
This priorityof personalisation depends in particular on the pri-ority of the triggered rule and on the time sincepersonalisation was last inserted.5 ConclusionThis framework for personalisation has been im-plemented in our toy using the Java-based agentplatform Gorite (Ronnquist, 2008).
The followingis an example of the type of dialogues we intendto generate with it (T is the Toy and C a child); itillustrates a number of our personalisation strate-gies.
Our infrastructure technically allows it tohappen, however we still need to add more con-tent (domain modules and fragments in them) tomake it actually happen; we are working on writ-ing such content, as well as on providing tools tomake it easier for designers to write this content inthe future.C Hi thereT Hello Emily!
[Use child?s name]T What did you do on such a sunny week-end?
[Context-adaptation]C I went to the zoo!T Great!
That must have been fun.
Which animals didyou see?C I saw tigersT Tigers are cats, but much bigger than your cat Simba.What else did you see?C Koalas!T Oh, that?s your favourite animal, isn?t it?
[Personal comment]C YesT You must have been really happy.
My favourite ani-mal is orangutan, did you see any?
[Confidepersonal information]C NoT Pity... Allright, enough chatting.
I know you lovestories.
Do you want to hear a story about tigers?
[Choose favourite activity]The ASR is not functional yet due to the spe-cific challenges of recognizing children voices, sofor now we are only experimenting with a textualinterface.
This may look similar to a chatbot buthas additional functionalities such as playing ac-tivities, and maintaining a context of interaction,including the history of the past interaction (in or-der not to repeat itself), physical context (to tai-lor interaction to the date, time, weather...), anda profile of the user (to personalise interaction tothem).
Contrarily to a chatbot which is designedfor short-term interactions, we expect such a com-panion agent to be able to develop a long-term re-lationship with the user.
This will be tested with aWizard of Oz setting before our industrial partnerprovides us with a children-specific ASR.The dialogue above is obviously not as rich aschild-mother interactions from the CHILDES cor-pus; in particular it lacks the recognition of emo-tions and expression of empathy that is essentialin human interactions.
Therefore future directionsfor research include detecting the child?s emotions(we have been experimenting with OpenEar (Ey-ben et al, 2009) to detect emotions from voice);reasoning about detected emotions, using an exist-ing BDI model of emotions (Adam, 2007); helpingthe child to cope with them, in particular by show-ing empathy; and endowing the toy with its ownpersonality (Goldberg, 1993).6 AcknowledgementsThis project is supported by the Australian Re-search Council, and RealThing Pty Ltd. underLinkage Grant LP0882013ReferencesF.
Abbattista, G. Catucci, M. Degemmis, P. Lops, G. Semer-aro, and F. Zambetta.
2003.
A framework for the devel-opment of personalized agents.
In KES.C.
Adam.
2007.
Emotions: from psychological theories tological formalisation and implementation in a BDI agent.Ph.D.
thesis, INP Toulouse, France.P.
B. Brandtzaeg, A. Folstad, and J. Heim.
2006.
Enjoyment:Lessons from karasek.
In M. A. Blythe, K. Overbeeke,A.
F. Monk, and P. C. Wright, editors, Funology: FromUsability to Enjoyment.
Springer.F.
Eyben, M. Wollmer, and B. Schuller.
2009. openEAR:Introducing the Munich open-source emotion and affectrecognition toolkit.
In ACII, Amsterdam.D.
Field, R. Catizone, W. Cheng, A. Dingli, S. Worgan, L. Ye,and Y. Wilks.
2009.
The senior companion: a semanticweb dialogue system.
(demo).
In AAMAS.J.
Ginzburg.
1997.
Resolving questions I and II.
Linguisticsand Philosophy, 17 and 18.L.
R. Goldberg.
1993.
The structure of phenotypic personal-ity traits.
American Psychologist, 48:26?34.B.
MacWhinney.
1995.
The CHILDES Database.B.
MacWhinney.
2000.
The CHILDES project: Tools foranalyzing talk.
Lawrence Erlbaum Associates.R.
Ronnquist.
2008.
The goal oriented teams (gorite) frame-work.
In Programming Multi-Agent Systems, volumeLNCS 4908, pages 27?41.
Springer.O.
Stahl, B. Gamback, M. Turunen, and J. Hakulinen.
2009.A mobile health and fitness companion demonstrator.
InEACL.24
