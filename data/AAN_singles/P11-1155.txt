Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1546?1555,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsUsing Bilingual Information for Cross-Language DocumentSummarizationXiaojun WanInstitute of Compute Science and Technology, Peking University, Beijing 100871, ChinaKey Laboratory of Computational Linguistics (Peking University), MOE, Chinawanxiaojun@icst.pku.edu.cnAbstractCross-language document summarization is de-fined as the task of producing a summary in atarget language (e.g.
Chinese) for a set ofdocuments in a source language (e.g.
English).Existing methods for addressing this task makeuse of either the information from the originaldocuments in the source language or the infor-mation from the translated documents in thetarget language.
In this study, we propose to usethe bilingual information from both the sourceand translated documents for this task.
Twosummarization methods (SimFusion andCoRank) are proposed to leverage the bilingualinformation in the graph-based ranking frame-work for cross-language summary extraction.Experimental results on the DUC2001 datasetwith manually translated reference Chinesesummaries show the effectiveness of the pro-posed methods.1 IntroductionCross-language document summarization is de-fined as the task of producing a summary in a dif-ferent target language for a set of documents in asource language (Wan et al, 2010).
In this study,we focus on English-to-Chinese cross-languagesummarization, which aims to produce Chinesesummaries for English document sets.
The task isvery useful in the field of multilingual informationaccess.
For example, it is beneficial for most Chi-nese readers to quickly browse and understandEnglish news documents or document sets by read-ing the corresponding Chinese summaries.A few pilot studies have investigated the task inrecent years and exiting methods make use of ei-ther the information in the source language or theinformation in the target language after using ma-chine translation.
In particular, for the task of Eng-lish-to-Chinese cross-language summarization, onemethod is to directly extract English summary sen-tences based on English features extracted from theEnglish documents, and then automatically trans-late the English summary sentences into Chinesesummary sentences.
The other method is to auto-matically translate the English sentences into Chi-nese sentences, and then directly extract Chinesesummary sentences based on Chinese features.
Thetwo methods make use of the information fromonly one language side.However, it is not very reliable to use only theinformation in one language, because the machinetranslation quality is far from satisfactory, and thusthe translated Chinese sentences usually containsome errors and noises.
For example, the Englishsentence ?Many destroyed power lines are thoughtto be uninsured, as are trees and shrubs uprootedacross a wide area.?
is automatically translatedinto the Chinese sentence ??????????????????????????????????????
by using Google Translate1 ,but the Chinese sentence contains a few translationerrors.
Therefore, on the one side, if we rely onlyon the English-side information to extract Chinese1 http://translate.google.com/.
Note that the translation serviceis updated frequently and the current translation results may bedifferent from that presented in this paper.1546summary sentences, we cannot guarantee that theautomatically translated Chinese sentences for sa-lient English sentences are really salient whenthese sentences may contain many translation er-rors and other noises.
On the other side, if we relyonly on the Chinese-side information to extractChinese summary sentences, we cannot guaranteethat the selected sentences are really salient be-cause the features for sentence ranking based onthe incorrectly translated sentences are not veryreliable, either.In this study, we propose to leverage both the in-formation in the source language and the informa-tion in the target language for cross-languagedocument summarization.
In particular, we pro-pose two graph-based summarization methods(SimFusion and CoRank) for using both English-side and Chinese-side information in the task ofEnglish-to-Chinese cross-document summarization.The SimFusion method linearly fuses the English-side similarity and the Chinese-side similarity formeasuring Chinese sentence similarity.
TheCoRank method adopts a co-ranking algorithm tosimultaneously rank both English sentences andChinese sentences by incorporating mutual influ-ences between them.We use the DUC2001 dataset with manuallytranslated reference Chinese summaries for evalua-tion.
Experimental results based on the ROUGEmetrics show the effectiveness of the proposedmethods.
Three important conclusions for this taskare summarized below:1) The Chinese-side information is more benefi-cial than the English-side information.2) The Chinese-side information and the Eng-lish-side information can complement eachother.3) The proposed CoRank method is more reli-able and robust than the proposed SimFusionmethod.The rest of this paper is organized as follows:Section 2 introduces related work.
In Section 3, wepresent our proposed methods.
Evaluation resultsare shown in Section 4.
Lastly, we conclude thispaper in Section 5.2 Related Work2.1 General Document SummarizationDocument summarization methods can be extrac-tion-based, abstraction-based or hybrid methods.We focus on extraction-based methods in thisstudy, and the methods directly extract summarysentences from a document or document set byranking the sentences in the document or documentset.In the task of single document summarization,various features have been investigated for rankingsentences in a document, including term frequency,sentence position, cue words, stigma words, andtopic signature (Luhn 1969; Lin and Hovy, 2000).Machine learning techniques have been used forsentence ranking (Kupiec et al, 1995; Amini andGallinari, 2002).
Litvak et al (2010) present a lan-guage-independent approach for extractive summa-rization based on the linear optimization of severalsentence ranking measures using a genetic algo-rithm.
In recent years, graph-based methods havebeen proposed for sentence ranking (Erkan andRadev, 2004; Mihalcea and Tarau, 2004).
Othermethods include mutual reinforcement principle(Zha 2002; Wan et al, 2007).In the task of multi-document summarization,the centroid-based method (Radev et al, 2004)ranks the sentences in a document set based onsuch features as cluster centroids, position andTFIDF.
Machine Learning techniques have alsobeen used for feature combining (Wong et al,2008).
Nenkova and Louis (2008) investigate theinfluences of input difficulty on summarizationperformance.
Pitler et al (2010) present a system-atic assessment of several diverse classes of met-rics designed for automatic evaluation of linguisticquality of multi-document summaries.
Celikyilmazand Hakkani-Tur (2010) formulate extractivesummarization as a two-step learning problem bybuilding a generative model for pattern discoveryand a regression model for inference.
Aker et al(2010) propose an A* search algorithm to find thebest extractive summary up to a given length, andthey propose a discriminative training algorithmfor directly maximizing the quality of the bestsummary.
Graph-based methods have also beenused to rank sentences for multi-document summa-rization (Mihalcea and Tarau, 2005; Wan andYang, 2008).15472.2 Cross-Lingual Document Summariza-tionSeveral pilot studies have investigated the task ofcross-language document summarization.
The ex-isting methods use only the information in eitherlanguage side.
Two typical translation schemes aredocument translation or summary translation.
Thedocument translation scheme first translates thesource documents into the corresponding docu-ments in the target language, and then extractssummary sentences based only on the informationon the target side.
The summary translation schemefirst extracts summary sentences from the sourcedocuments based only on the information on thesource side, and then translates the summary sen-tences into the corresponding summary sentencesin the target language.For example Leuski et al (2003) use machinetranslation for English headline generation forHindi documents.
Lim et al (2004) propose togenerate a Japanese summary by using Koreansummarizer.
Chalendar et al (2005) focus on se-mantic analysis and sentence generation techniquesfor cross-language summarization.
Orasan andChiorean (2008) propose to produce summarieswith the MMR method from Romanian news arti-cles and then automatically translate the summariesinto English.
Cross language query based summa-rization has been investigated in (Pingali et al,2007), where the query and the documents are indifferent languages.
Wan et al (2010) adopt thesummary translation scheme for the task of Eng-lish-to-Chinese cross-language summarization.They first extract English summary sentences byusing English-side features and the machine trans-lation quality factor, and then automatically trans-late the English summary into Chinese summary.Other related work includes multilingual summari-zation (Lin et al, 2005; Siddharthan and McKe-own, 2005), which aims to create summaries frommultiple sources in multiple languages.3 Our Proposed MethodsAs mentioned in Section 1, existing methods relyonly on one-side information for sentence ranking,which is not very reliable.
In order to leveragingboth-side information for sentence ranking, wepropose the following two methods to incorporatethe bilingual information in different ways.3.1 SimFusionThis method uses the English-side information forChinese sentence ranking in the graph-basedframework.
The sentence similarities in the twolanguages are fused in the method.
In other words,when we compute the similarity value between twoChinese sentences, the similarity value between thecorresponding two English sentences is used bylinear fusion.
Since sentence similarity evaluationplays a very important role in the graph-basedranking algorithm, this method can leverage both-side information through similarity fusion.Formally, given the Chinese document set Dcntranslated from an English document set, letGcn=(Vcn, Ecn) be an undirected graph to reflect therelationships between the sentences in the Chinesedocument set.
Vcn is the set of vertices and eachvertex scni in Vcn represents a Chinese sentence.
Ecnis the set of edges.
Each edge ecnij in Ecn is associ-ated with an affinity weight f(scni, scnj) between sen-tences scni and scnj (i?j).
The weight is computed bylinearly combining the similarity value simcosine(scni,scnj) between the Chinese sentences and the simi-larity value simcosine(seni, senj) between the corre-sponding English sentences.
),()1(),(),( coscosenjeniinecnjcniinecnjcni sssimsssimssf ?
?+?= ?
?where senj and seni are the source English sentencesfor scnj and scni.
??
[0, 1] is a parameter to controlthe relative contributions of the two similarity val-ues.
The similarity values simcosine(scni, scnj) andsimcosine(seni, senj) are computed by using the stan-dard cosine measure.
The weight for each term iscomputed based on the TFIDF formula.
For Chi-nese similarity computation, Chinese word seg-mentation is performed.
Here, we have f(scni,scnj)=f(scnj, scni) and let f(scni, scni)=0 to avoid selftransition.
We use an affinity matrix Mcn to de-scribe Gcn with each entry corresponding to theweight of an edge in the graph.
Mcn=(Mcnij)|Vcn|?|Vcn|is defined as Mcnij=f(scni,scnj).
Then Mcn is normal-ized to cnM~  to make the sum of each row equal to 1.Based on matrix cnM~ , the saliency score Info-Score(scni) for sentence scni can be deduced fromthose of all other sentences linked with it and it canbe formulated in a recursive form as in the PageR-ank algorithm:1548???+?
?=iall jcnjicnjcni nMsInfoScoresInfoScore)1(~)()(?
?where n is the sentence number, i.e.
n= |Vcn|.
?
isthe damping factor usually set to 0.85, as in thePageRank algorithm.For numerical computation of the saliencyscores, we can iteratively run the above equationuntil convergence.For multi-document summarization, some sen-tences are highly overlapping with each other, andthus we apply the same greedy algorithm in Wan etal.
(2006) to penalize the sentences highly overlap-ping with other highly scored sentences, and fi-nally the salient and novel Chinese sentences aredirectly selected as summary sentences.3.2 CoRankThis method leverages both the English-side in-formation and the Chinese-side information in aco-ranking way.
The source English sentences andthe translated Chinese sentences are simultane-ously ranked in a unified graph-based algorithm.The saliency of each English sentence relies notonly on the English sentences linked with it, butalso on the Chinese sentences linked with it.
Simi-larly, the saliency of each Chinese sentence reliesnot only on the Chinese sentences linked with it,but also on the English sentences linked with it.More specifically, the proposed method is based onthe following assumptions:Assumption 1: A Chinese sentence would besalient if it is heavily linked with other salient Chi-nese sentences; and an English sentence would besalient if it is heavily linked with other salient Eng-lish sentences.Assumption 2: A Chinese sentence would besalient if it is heavily linked with salient Englishsentences; and an English sentence would be sali-ent if it is heavily linked with salient Chinese sen-tences.The first assumption is similar to PageRankwhich makes use of mutual ?recommendations?between the sentences in the same language to ranksentences.
The second assumption is similar toHITS if the English sentences and the Chinese sen-tences are considered as authorities and hubs, re-spectively.
In other words, the proposed methodaims to fuse the ideas of PageRank and HITS in aunified framework.
The mutual influences betweenthe Chinese sentences and the English sentencesare incorporated in the method.Figure 1 gives the graph representation for themethod.
Three kinds of relationships are exploited:the CN-CN relationships between Chinese sen-tences, the EN-EN relationships between Englishsentences, and the EN-CN relationships betweenEnglish sentences and Chinese sentences.Formally, given an English document set Den andthe translated Chinese document set Dcn, let G=(Ven,Vcn, Een, Ecn, Eencn) be an undirected graph to reflectall the three kinds of relationships between the sen-tences in the two document sets.
Ven ={seni | 1?i?n}is the set of English sentences.
Vcn={scni | 1?i?n} isthe set of Chinese sentences.
scni is the correspond-ing Chinese sentence translated from seni.
n is thenumber of the sentences.
Een is the edge set to re-flect the relationships between the English sen-tences.
Ecn is the edge set to reflect therelationships between the Chinese sentences.
Eencnis the edge set to reflect the relationships betweenthe English sentences and the Chinese sentences.Based on the graph representation, we compute thefollowing three affinity matrices to reflect the threekinds of sentence relationships:Figure 1.
The three kinds of sentence relationships1) Mcn=(Mcnij)n?n:  This affinity matrix aims toreflect the relationships between the Chinese sen-tences.
Each entry in the matrix corresponds to thecosine similarity between the two Chinese sen-tences.?????
?=otherwise,j,  if isssimMcnjcniinecnij0),(cosEnglish SentencesCN-CNEN-ENEN-CNChinese sentences1549Then Mcn is normalized to cnM~  to make thesum of each row equal to 1.2) Men=(Meni,j)n?n: This affinity matrix aims toreflect the relationships between the English sen-tences.
Each entry in the matrix corresponds to thecosine similarity between the two English sen-tences.?????
?=otherwise,j,  if isssimMenjeniineenij0),(cosThen Men is normalized to enM~  to make thesum of each row equal to 1.3) Mencn=(Mencnij)n?n: This affinity matrix aims toreflect the relationships between the English sen-tences and the Chinese sentences.
Each entryMencnij in the matrix corresponds to the similaritybetween the English sentence seni and the Chinesesentence scnj.
It is hard to directly compute thesimilarity between the sentences in different lan-guages.
In this study, the similarity value is com-puted by fusing the following two similarity values:the cosine similarity between the sentence seni andthe corresponding source English sentence senj forscnj, and the cosine similarity between the corre-sponding translated Chinese sentence scni for seniand the sentence scnj.
We use the geometric meanof the two values as the affinity weight.
),(),( coscoscnjcniineenjeniineencnij sssimsssimM ?=Note that we have Mencnij=Mencnji andMencn=(Mencn)T. Then Mencn is normalized to encnM~to make the sum of each row equal to 1.We use two column vectors u=[u(scni)]n?1 and v=[v(senj)]n?1 to denote the saliency scores of theChinese sentences and the English sentences, re-spectively.
Based on the three kinds of relation-ships, we can get the following four assumptions:??
j cnjcnjicni suMsu )(~)(??
i enienijenj svMsv )(~)(??
j enjencnjicni svMsu )(~)(??
i cniencnijenj suMsv )(~)(After fusing the above equations, we can obtainthe following iterative forms:??
+= j enjencnjij cnjcnjicni svM?suM?su )(~)(~)(??
+= i cniencniji enienijenj suM?svM?sv )(~)(~)(And the matrix form is:vMuMu cn TencnT ??
)~()~( +=uMvMv en TencnT ??
)~()~( +=where ?
and ?
specify the relative contributions tothe final saliency scores from the information inthe same language and the information in the otherlanguage and we have ?+?=1.For numerical computation of the saliencyscores, we can iteratively run the two equationsuntil convergence.
Usually the convergence of theiteration algorithm is achieved when the differencebetween the scores computed at two successiveiterations for any sentences and words falls belowa given threshold.
In order to guarantee the con-vergence of the iterative form, u and v are normal-ized after each iteration.After we get the saliency scores u for the Chi-nese sentences, we apply the same greedy algo-rithm for redundancy removing.
Finally, a fewhighly ranked sentences are selected as summarysentences.4 Experimental Evaluation4.1 Evaluation SetupThere is no benchmark dataset for English-to-Chinese cross-language document summarization,so we built our evaluation dataset based on theDUC2001 dataset by manually translating the ref-erence summaries.DUC2001 provided 30 English document setsfor generic multi-document summarization.
Theaverage document number per document set was10.
The sentences in each article have been sepa-rated and the sentence information has been storedinto files.
Three or two generic reference Englishsummaries were provided by NIST annotators foreach document set.
Three graduate students wereemployed to manually translate the reference Eng-lish summaries into reference Chinese summaries.Each student manually translated one third of thereference summaries.
It was much easier and morereliable to provide the reference Chinese summa-ries by manual translation than by manual summa-rization.1550ROUGE-2Average_FROUGE-WAverage_FROUGE-LAverage_FROUGE-SU4Average_FBaseline(EN) 0.03723 0.05566 0.13259 0.07177Baseline(CN) 0.03805 0.05886 0.13871 0.07474SimFusion  0.04017 0.06117 0.14362 0.07645CoRank  0.04282 0.06158 0.14521 0.07805Table 1: Comparison ResultsAll the English sentences in the document setwere automatically translated into Chinese sen-tences by using Google Translate, and the StanfordChinese Word Segmenter2 was used for segment-ing the Chinese documents and summaries intowords.
For comparative study, the summary lengthwas limited to five sentences, i.e.
each Chinesesummary consisted of five sentences.We used the ROUGE-1.5.5 (Lin and Hovy,2003) toolkit for evaluation, which has beenwidely adopted by DUC and TAC for automaticsummarization evaluation.
It measured summaryquality by counting overlapping units such as then-gram, word sequences and word pairs betweenthe candidate summary and the reference summary.We showed three of the ROUGE F-measure scoresin the experimental results: ROUGE-2 (bigram-based), ROUGE-W (based on weighted longestcommon subsequence, weight=1.2), ROUGE-L(based on longest common subsequences), andROUGE-SU4 (based on skip bigram with a maxi-mum skip distance of 4).
Note that the ROUGEtoolkit was performed for Chinese summaries afterusing word segmentation.Two graph-based baselines were used for com-parison.Baseline(EN): This baseline adopts the sum-mary translation scheme, and it relies on the Eng-lish-side information for English sentence ranking.The extracted English summary is finally auto-matically translated into the corresponding Chinesesummary.
The same sentence ranking algorithmwith the SimFusion method is adopted, and theaffinity weight is computed based only on the co-sine similarity between English sentences.Baseline(CN): This baseline adopts the docu-ment translation scheme, and it relies on the Chi-nese-side information for Chinese sentence ranking.The Chinese summary sentences are directly ex-tracted from the translated Chinese documents.The same sentence ranking algorithm with theSimFusion method is adopted, and the affinity2 http://nlp.stanford.edu/software/segmenter.shtmlweight is computed based only on the cosine simi-larity between Chinese sentences.For our proposed methods, the parameter val-ues are empirically set as ?=0.8 and ?=0.5.4.2 Results and DiscussionTable 1 shows the comparison results for our pro-posed methods and the baseline methods.
Seenfrom the tables, Baseline(CN) performs better thanBaseline(EN) over all the metrics.
The results dem-onstrate that the Chinese-side information is morebeneficial than the English-side information forcross-document summarization, because the sum-mary sentences are finally selected from the Chi-nese side.
Moreover, our proposed two methodscan outperform the two baselines over all the met-rics.
The results demonstrate the effectiveness ofusing bilingual information for cross-languagedocument summarization.
It is noteworthy that theROUGE scores in the table are not high due to thefollowing two reasons: 1) The use of machinetranslation may introduce many errors and noisesin the peer Chinese summaries; 2) The use of Chi-nese word segmentation may introduce morenoises and mismatches in the ROUGE evaluationbased on Chinese words.We can also see that the CoRank method canoutperform the SimFusion method over all metrics.The results show that the CoRank method is moresuitable for the task by incorporating the bilingualinformation into a unified ranking framework.In order to show the influence of the value of thecombination parameter ?
on the performance of theSimFusion method, we present the performancecurves over the four metrics in Figures 2 through 5,respectively.
In the figures, ?
ranges from 0 to 1,and ?=1 means that SimFusion is the same withBaseline(CN), and ?=0 means that only English-side information is used for Chinese sentence rank-ing.
We can see that when ?
is set to a value largerthan 0.5, SimFusion can outperform the two base-lines over most metrics.
The results show that ?can be set in a relatively wide range.
Note that1551?>0.5 means that SimFusion relies more on theChinese-side information than on the English-sideinformation.
Therefore, the Chinese-side informa-tion is more beneficial than the English-side in-formation.In order to show the influence of the value of thecombination parameter ?
on the performance of theCoRank method, we present the performancecurves over the four metrics in Figures 6 through 9,respectively.
In the figures, ?
ranges from 0.1 to0.9, and a larger value means that the informationfrom the same language side is more relied on, anda smaller value means that the information fromthe other language side is more relied on.
We cansee that CoRank can always outperform the twobaselines over all metrics with different value of ?.The results show that ?
can be set in a very widerange.
We also note that a very large value or avery small value of ?
can lower the performancevalues.
The results demonstrate that CoRank relieson both the information from the same languageside and the information from the other languageside for sentence ranking.
Therefore, both the Chi-nese-side information and the English-side infor-mation can complement each other, and they arebeneficial to the final summarization performance.Comparing Figures 2 through 5 with Figures 6through 9, we can further see that the CoRankmethod is more stable and robust than the Sim-Fusion method.
The CoRank method can outper-form the SimFusion method with most parametersettings.
The bilingual information can be betterincorporated in the unified ranking framework ofthe CoRank method.Finally, we show one running example for thedocument set D59 in the DUC2001 dataset.
Thefour summaries produced by the four methods arelisted below:Baseline(EN): ??????
24??????????????????????????????????????????????????????????????????????????????????????????????????????????????
JT8D ???
?-200 ??????????????????????????
?1988 ?
7????????
DC-10?????????????????????????
112?
?Baseline(CN): ????????????????
1987?
8 ?
16 ???????
156 ???????????????????????????????????????????????
MD-82???
1985??
1986???????????????????????????
24 ??????????????????????
4 ???????????????????????????????????????????
200 ??
JT8D ????????????????????????????????????????????
?SimFusion: ????????????????
1987?
8?
16 ???????
156 ??????????????????????????????????
24 ???????????????????????????????????????????????????????????????????????????????????????????????????????
MD-82???
1985??
1986????????????????????
?CoRank : ??????
24 ????????????????????????????????????
1987 ?
8?
16 ???????
156 ???????????????????????????????????????????????????????????????????????????????????????????????
1979 ??????????????????????????????
?5 Conclusion and Future WorkIn this paper, we propose two methods (SimFusionand CoRank) to address the cross-language docu-ment summarization task by leveraging the bilin-gual information in both the source and targetlanguage sides.
Evaluation results demonstrate theeffectiveness of the proposed methods.
The Chi-nese-side information is validated to be more bene-ficial than the English-side information, and theCoRank method is more robust than the SimFusionmethod.In future work, we will investigate to use themachine translation quality factor to further im-prove the fluency of the Chinese summary, as inWan et al (2010).
Though our attempt to useGIZA++ for evaluating the similarity betweenChinese sentences and English sentences failed, wewill exploit more advanced measures based on sta-tistical alignment model for cross-language simi-larity computation.AcknowledgmentsThis work was supported by NSFC (60873155),Beijing Nova Program (2008B03) and NCET(NCET-08-0006).
We thank the three students fortranslating the reference summaries.
We also thankthe anonymous reviewers for their useful com-ments.15520.030.0320.0340.0360.0380.040.0420 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-2(F)SimFusion Baseline(EN) Baseline(CN)Figure 2.
ROUGE-2(F) vs. ?
for SimFusion0.0520.0530.0540.0550.0560.0570.0580.0590.060.0610.0620 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-W(F)SimFusion Baseline(EN) Baseline(CN)Figure 3.
ROUGE-W(F) vs. ?
for SimFusion0.1250.1270.1290.1310.1330.1350.1370.1390.1410.1430.1450 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-L(F)SimFusion Baseline(EN) Baseline(CN)Figure 4.
ROUGE-L(F) vs. ?
for SimFusion0.0640.0660.0680.070.0720.0740.0760.0780 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?ROUGE-SU4(F)SimFusion Baseline(EN) Baseline(CN)Figure 5.
ROUGE-SU4(F) vs. ?
for SimFusion0.0360.0370.0380.0390.040.0410.0420.0430.0440.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9?ROUGE-2(F)CoRank Baseline(EN) Baseline(CN)Figure 6.
ROUGE-2(F) vs. ?
for CoRank0.0550.0560.0570.0580.0590.060.0610.0620.0630.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9?ROUGE-W(F)CoRank Baseline(EN) Baseline(CN)Figure 7.
ROUGE-W(F) vs. ?
for CoRank0.130.1320.1340.1360.1380.140.1420.1440.1460.1480.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9?ROUGE-L(F)CoRank Baseline(EN) Baseline(CN)Figure 8.
ROUGE-L(F) vs. ?
for CoRank0.070.0710.0720.0730.0740.0750.0760.0770.0780.0790.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9?ROUGE-SU4(F)CoRank Baseline(EN) Baseline(CN)Figure 9.
ROUGE-SU4(F) vs. ?
for CoRank1553ReferencesA.
Aker, T. Cohn, and R. Gaizauskas.
2010.
Multi-document summarization using A* search anddiscriminative training.
In Proceedings ofEMNLP2010.M.
R. Amini, P. Gallinari.
2002.
The Use of Unla-beled Data to Improve Supervised Learning forText Summarization.
In Proceedings ofSIGIR2002.G.
de Chalendar, R. Besan?on, O. Ferret, G. Gre-fenstette, and O. Mesnard.
2005.
Crosslingualsummarization with thematic extraction, syntac-tic sentence simplification, and bilingual genera-tion.
In Workshop on Crossing Barriers in TextSummarization Research, 5th International Con-ference on Recent Advances in Natural Lan-guage Processing  (RANLP2005).A.
Celikyilmaz and D. Hakkani-Tur.
2010.
A hy-brid hierarchical model for multi-documentsummarization.
In Proceedings of ACL2010.G.
ErKan, D. R. Radev.
LexPageRank.
2004.
Pres-tige in Multi-Document Text Summarization.
InProceedings of EMNLP2004.D.
Klein and C. D. Manning.
2002.
Fast Exact In-ference with a Factored Model for Natural Lan-guage Parsing.
In Proceedings of NIPS2002.J.
Kupiec, J. Pedersen, F. Chen.
1995.
A.TrainableDocument Summarizer.
In Proceedings ofSIGIR1995.A.
Leuski, C.-Y.
Lin, L. Zhou, U. Germann, F. J.Och, E. Hovy.
2003.
Cross-lingual C*ST*RD:English access to Hindi information.
ACMTransactions on Asian Language InformationProcessing, 2(3): 245-269.J.-M. Lim, I.-S. Kang, J.-H. Lee.
2004.
Multi-document summarization using cross-languagetexts.
In Proceedings of NTCIR-4.C.
Y. Lin, E. Hovy.
2000.
The Automated Acquisi-tion of Topic Signatures for Text Summarization.In Proceedings of the 17th Conference on Com-putational Linguistics.C.-Y.
Lin and E.H. Hovy.
2003.
AutomaticEvaluation of Summaries Using N-gram Co-occurrence Statistics.
In Proceedings of HLT-NAACL -03.C.-Y.
Lin, L. Zhou, and E. Hovy.
2005.
Multilin-gual summarization evaluation 2005: automaticevaluation report.
In Proceedings of MSE (ACL-2005 Workshop).M.
Litvak, M. Last, and M. Friedman.
2010.
Anew approach to improving multilingual sum-marization using a genetic algorithm.
In Pro-ceedings of ACL2010.H.
P. Luhn.
1969.
The Automatic Creation of lit-erature Abstracts.
IBM Journal of Research andDevelopment, 2(2).R.
Mihalcea, P. Tarau.
2004.
TextRank: BringingOrder into Texts.
In Proceedings ofEMNLP2004.R.
Mihalcea and P. Tarau.
2005.
A language inde-pendent algorithm for single and multiple docu-ment summarization.
In Proceedings ofIJCNLP-05.A.
Nenkova and A. Louis.
2008.
Can you summa-rize this?
Identifying correlates of input diffi-culty for generic multi-document summarization.In Proceedings of ACL-08:HLT.A.
Nenkova, R. Passonneau, and K. McKeown.2007.
The Pyramid method: incorporating hu-man content selection variation in summariza-tion evaluation.
ACM Transactions on Speechand Language Processing (TSLP), 4(2).C.
Orasan, and O.
A. Chiorean.
2008.
Evaluationof a Crosslingual Romanian-English Multi-document Summariser.
In Proceedings of 6thLanguage Resources and Evaluation Confer-ence (LREC2008).P.
Pingali, J. Jagarlamudi and V. Varma.
2007.Experiments in cross language query focusedmulti-document summarization.
In Workshop onCross Lingual Information Access Addressingthe Information Need of Multilingual Societiesin IJCAI2007.E.
Pitler, A. Louis, and A. Nenkova.
2010.
Auto-matic evaluation of linguistic quality in multi-document summarization.
In Proceedings ofACL2010.D.
R. Radev, H. Y. Jing, M. Stys and D. Tam.2004.
Centroid-based summarization of multipledocuments.
Information Processing and Man-agement, 40: 919-938.1554A.
Siddharthan and K. McKeown.
2005.
Improv-ing multilingual summarization: using redun-dancy in the input to correct MT errors.
InProceedings of HLT/EMNLP-2005.X.
Wan, H. Li and J. Xiao.
2010.
Cross-languagedocument summarization based on machinetranslation quality prediction.
In Proceedings ofACL2010.X.
Wan, J. Yang and J. Xiao.
2006.
Using cross-document random walks for topic-focusedmulti-documetn summarization.
In Proceedingsof WI2006.X.
Wan and J. Yang.
2008.
Multi-document sum-marization using cluster-based link analysis.
InProceedings of SIGIR-08.X.
Wan, J. Yang and J. Xiao.
2007.
Towards anIterative Reinforcement Approach for Simulta-neous Document Summarization and KeywordExtraction.
In Proceedings of ACL2007.K.-F. Wong, M. Wu and W. Li.
2008.
Extractivesummarization using supervised and semi-supervised learning.
In Proceedings ofCOLING-08.H.
Y. Zha.
2002.
Generic Summarization and Key-phrase Extraction Using Mutual ReinforcementPrinciple and Sentence Clustering.
In Proceed-ings of SIGIR2002.1555
