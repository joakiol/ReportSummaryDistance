Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 85?90,Sydney, July 2006. c?2006 Association for Computational LinguisticsClavius: Bi-Directional Parsing for Generic Multimodal InteractionFrank RudziczCentre for Intelligent MachinesMcGill UniversityMontre?al, Canadafrudzi@cim.mcgill.caAbstractWe introduce a new multi-threadedparsing algorithm on unification grammarsdesigned specifically for multimodalinteraction and noisy environments.By lifting some traditional constraints,namely those related to the orderingof constituents, we overcome severaldifficulties of other systems in thisdomain.
We also present several criteriaused in this model to constrain the searchprocess using dynamically loadablescoring functions.
Some early analyses ofour implementation are discussed.1 IntroductionSince the seminal work of Bolt (Bolt, 1980), themethods applied to multimodal interaction (MMI)have diverged towards unreconcilable approachesretrofitted to models not specifically amenable tothe problem.
For example, the representationaldifferences between neural networks, decisiontrees, and finite-state machines (Johnston andBangalore, 2000) have limited the adoption ofthe results using these models, and the typicalreliance on the use of whole unimodal sentencesdefeats one of the main advantages of MMI - theability to constrain the search using cross-modalinformation as early as possible.CLAVIUS is the result of an effort to combinesensing technologies for several modality types,speech and video-tracked gestures chief amongthem, within the immersive virtual environment(Boussemart, 2004) shown in Figure 1.
Its purposeis to comprehend multimodal phrases such as?put this ?
here ?
.
?, for pointing gestures ?,in either command-based or dialogue interaction.CLAVIUS provides a flexible, and trainablenew bi-directional parsing algorithm on multi-dimensional input spaces, and produces modality-independent semantic interpretation with a lowcomputational cost.Figure 1: The target immersive environment.1.1 Graphical Models and UnificationUnification grammars on typed directed acyclicgraphs have been explored previously in MMI,but typically extend existing mechanisms notdesigned for multi-dimensional input.
Forexample, both (Holzapfel et al, 2004) and(Johnston, 1998) essentially adapt Earley?s chartparser by representing edges as sets of referencesto terminal input elements - unifying these as newedges are added to the agenda.
In practice thishas led to systems that analyze every possiblesubset of the input resulting in a combinatorialexplosion that balloons further when consideringthe complexities of cross-sentential phenomenasuch as anaphora, and the effects of noise anduncertainty on speech and gesture tracking.
Wewill later show the extent to which CLAVIUSreduces the size of the search space.85Directed graphs conveniently representboth syntactic and semantic structure, and allpartial parses in CLAVIUS , including terminal-level input, are represented graphically.
Fewrestrictions apply, except that arcs labelledCAT and TIME must exist to represent thegrammar category and time spanned by theparse, respectively1.
Similarly, all grammar rules,?i : LHS ??
RHS1 RHS2 ... RHSr, aregraphical structures, as exemplified in Figure 2.Figure 2: ?1 : OBJECT REFERENCE ?
?NP click {where(NP :: f1) = (click :: f1)}, withNP expanded by ?2 : NP ??
DT NN.1.2 Multimodal Bi-Directional ParsingOur parsing strategy combines bottom-up andtop-down approaches, but differs from otherapproaches to bi-directional chart parsing (Rocio,1998) in several key respects, discussed below.1.2.1 Asynchronous Collaborating ThreadsA defining characteristic of our approach isthat edges are selected asynchronously by twoconcurrent processing threads, rather than seriallyin a two-stage process.
In this way, we candistribute processing across multiple machines,or dynamically alter the priorities given to eachthread.
Generally, this allows for a more dynamicprocess where no thread can dominate the other.
Intypical bi-directional chart parsing the top-downcomponent is only activated when the bottom-upcomponent has no more legal expansions (Ageno,2000).1.2.2 Unordered ConstituentsAlhough evidence suggests that deicticgestures overlap or follow corresponding spokenpronomials 85-93% of the time (Kettebekov et al1Usually this timespan corresponds to the real-timeoccurrence of a speech or gestural event, but the actualsemantics are left to the application designer2002), we must allow for all possible permutationsof multi-dimensional input - as in ?put ?
this ?here.?
vs. ?put this ?
here ?
.
?, for example.We therefore take the unconvential approachof placing no mandatory ordering constraints onconstituents, hence the rule ?abc : A ??
B Cparses the input ?
C B?.
We show how we caneasily maintain regular temporal ordering in ?3.5.1.2.3 Partial QualificationWhereas existing bi-directional chart parsersmaintain fully-qualified edges by incrementallyadding adjacent input words to the agenda,CLAVIUS has the ability to construct parses thatinstantiate only a subset of their constituents,so ?abc also parses the input ?B?, for example.Repercussions are discussed in ?3.4 and ?4.2 The AlgorithmCLAVIUS expands parses according to a best-firstprocess where newly expanded edges are orderedaccording to trainable criteria of multimodallanguage, as discussed in ?3.
Figure 3 shows acomponent breakdown of CLAVIUS ?s softwarearchitecture.
The sections that follow explainthe flow of information through this system fromsensory input to semantic interpretation.Figure 3: Simplified information flow betweenfundamental software components.2.1 Lexica and PreprocessingEach unique input modality is asynchronouslymonitored by one of T TRACKERS, each sendingan n-best list of lexical hypotheses to CLAVIUS forany activity as soon as it is detected.
For example,a gesture tracker (see Figure 4a) parametrizes thegestures preparation, stroke/point, and retraction(McNeill, 1992), with values reflecting spatialpositions and velocities of arm motion, whereas86our speech tracker parametrises words with part-of-speech tags, and prior probabilities (see Figure4b).
Although preprocessing is reduced to theidentification of lexical tokens, this is moreinvolved than simple lexicon lookup due to themodelling of complex signals.Figure 4: Gestural (a) and spoken (b) ?words?.2.2 Data StructuresAll TRACKERS write their hypotheses directlyto the first of three SUBSPACES that partitionall partial parses in the search space.
The firstis the GENERALISER?s subspace, ?
[G], whichis monitored by the GENERALISER thread -the first part of the parser.
All new parsesare first written to ?
[G] before being moved tothe SPECIFIER?s active and inactive subspaces,?
[SAct], and ?
[SInact], respectively.
Subspaces areoptimised for common operations by organisingparses by their scores and grammatical categoriesinto depth-balanced search trees having the heapproperty.
The best partial parse in each subspacecan therefore be found in O(1) amortised time.2.3 GeneralisationThe GENERALISER monitors the best partialparse, ?g, in ?
[G], and creates new parses ?ifor all grammar rules ?i having CATEGORY(?g)on the right-hand side.
Effectively, these newparses are instantiations of the relevant ?i, withone constituent unified to ?g.
This providesthe impetus towards sentence-level parses, assimplified in Algorithm 1 and exemplified inFigure 5.
Naturally, if rule ?i has more than oneconstituent (c > 1) of type CATEGORY(?g), thenc new parses are created, each with one of thesebeing instantiated.Since the GENERALISER is activated as soon asinput is added to ?
[G], the process is interactive(Tomita, 1985), and therefore incorporates theassociated benefits of efficiency.
This is contrastedwith the all-paths bottom-up strategy in GEMINI(Dowding et al 1993) that finds all admissableedges of the grammar.Algorithm 1: Simplified GeneralisationData: Subspace ?
[G], grammar ?while data remains in ?
[G] do?g := highest scoring graph in ?
[G]foreach rule ?i s.t.
Cat (?g) ?
RHS(?i)do?i := Unify (?i, [?
?RHS ?
?
?g])if ?
?i thenApply Score (?i) to ?iInsert ?i into ?
[G]Move ?g into ?
[SAct]Figure 5: Example of GENERALISATION.2.4 SpecificationThe SPECIFIER thread provides the impetustowards complete coverage of the input, assimplified in Algorithm 2 (see Figure 6).
Itcombines parses in its subspaces that have thesame top-level grammar expansion but differentinstantiated constituents.
The resulting parsemerges the semantics of the two original graphsonly if unification succeeds, providing a hardconstraint against the combination of incongruousinformation.
The result, ?, of specification mustbe written to ?
[G], otherwise ?
could never appearon the RHS of another partial parse.
We show howassociated vulnerabilities are overcome in ?3.2and ?3.4.Specification is commutative and will alwaysprovide more information than its constituentgraphs if it does not fail, unlike the ?overlay?87method of SMARTKOM (Alexandersson andBecker, 2001), which basically provides asubsumption mechanism over backgroundknowledge.Algorithm 2: Simplified SpecificationData: Subspaces ?
[SAct] and ?
[SInact]while data remains in ?
[SAct] do?s := highest scoring graph in ?
[SAct]?j := highest scoring graph in ?[SInact]s.t.
Cat (?j) = Cat (?s)while ?
?j do?i := Unify (?s,?j)if ?
?i thenApply Score (?i) to ?iInsert ?i into ?
[G]?j := next highest scoring graph from?
[SInact] s.t.
Cat (?j) = Cat (?s); // Optionally stop after Iiterations, for some IMove ?s into ?
[SInact]Figure 6: Example of SPECIFICATION.2.5 CognitionThe COGNITION thread monitors the bestsentence-level hypothesis, ?B , in ?
[SInact],and terminates the search process once ?B hasremained unchallenged by new competing parsesfor some period of time.Once found, COGNITION communicates ?B tothe APPLICATION.
Both COGNITION and theAPPLICATION read state information from theMySQL WORLD database, as discussed in ?3.5,though only the latter can modify it.3 Applying Domain-Centric KnowledgeUpon being created, all partial parses are assigneda score approximating its likelihood of being partof an accepted multimodal sentence.
The scoreof partial parse ?, SCORE(?)
=|S|?i=0?i?i(?
),is a weighted linear combination of independentscoring modules (KNOWLEDGE SOURCES).
Eachmodule presents a score function ?i : ?
?
<[0..1]according to a unique criterion of multimodallanguage, weighted by ?i, also on <[0..1].
Somemodules provide ?hard constraints?
that canoutright forbid unification, returning ?i = ?
?in those cases.
A subset of the criteria we haveexplored are outlined below.3.1 Temporal Alignment (?1)By modelling the timespans of parses asGaussians, where ?
and ?
are determined by themidpoint and 12 the distance between the twoendpoints, respectively - we can promote parseswhose constituents are closely related in timewith the symmetric Kullback-Leibler divergence,DKL(?1,?2) =(?21??22)2+((?1?
?2)(?21+?22))24?21?22.Therefore, ?1 promotes more locally-structuredparses, and co-occuring multimodal utterances.3.2 Ancestry Constraint (?2)A consequence of accepting n-best lexicalhypotheses for each word is that we risk unifyingparses that include two competing hypotheses.For example, if our speech TRACKER produceshypotheses ?horse?
and ?house?
for ambiguousinput, then ?2 explicitly prohibits the parse ?thehorse and the house?
with flags on lexical content.3.3 Probabilistic Grammars (?3)We emphasise more common grammaticalconstructions by augmenting each grammarrule with an associated probability, P (?i),and assigning ?3(?)
= P (RULE(?))
??
?c=constituent of ?
?3(?c) where RULE is thetop-level expansion of ?.Probabilities are trainable by maximumlikelihood estimation on annotated data.
Withinthe context of CLAVIUS , ?3 promotes theprocessing of new input words and shallowerparse trees.883.4 Information Content (?4), Coverage (?5)The ?4 module partially orders parses bypreferring those that maximise the joint entropybetween the semantic variables of its constituentparses.
Furthermore, we use a shifted sigmoid?5(?)
= 21+e?25 NUMWORDSIN(?
)?1, to promote parsesthat maximise the number of ?words?
in a parse.These two modules together are vital in choosingfully specified sentences.3.5 Functional Constraints (?6)Each grammar rule ?i can include constraintfunctions f : ?
?
<[0,1] parametrised by valuesin instantiated graphs.
For example, the functionT FOLLOWS(?1,?2) returns 1 if constituent ?2follows ?1 in time, and ??
otherwise, thusmaintaining ordering constraints.
Functions aredynamically loaded and executed during scoring.Since functions are embedded directly withinparse graphs, their return values can be directlyincorporated into those parses, allowing us toutilise data in the WORLD.
For example, thefunction OBJECTAT(x, y,&o) determines if anobject exists at point (x, y), as determined by apointing gesture, and writes the type of this object,o, to the graph, which can later further constrainthe search.4 Early ResultsWe have constructed a simple blocks-worldexperiment where a user can move, colour,create, and delete geometric objects using speechand pointing gestures with 74 grammar rules,25 grammatical categories, and a 43-wordvocabulary.
Ten users were recorded interactingwith this system, for a combined total of 2.5hours of speech and gesture data, and 2304multimodal utterances.
Our randomised datacollection mechanism was designed to equitablyexplore the four command types.
Test subjectswere given no indication as to the types of phraseswe expected - but were rather shown a collectionof objects and were asked to replicate it, given thefour basic types of actions.Several aspects of the parser have been tested atthis stage and are summarised below.4.1 AccuracyTable 1 shows three hand-tuned configurations ofthe module weights ?i, with ?2 = 0.0, since ?2provides a ?hard constraint?
(?3.2).Figure 7 shows sentence-level precisionachieved for each ?i on each of the four tasks,where precision is defined as the proportion ofcorrectly executed sentences.
These are comparedagainst the CMU Sphinx-4 speech recogniserusing the unimodal projection of the multimodalgrammar.
Here, conjunctive phrases such as ?Puta sphere here and colour it yellow?
are classifiedaccording to their first clause.Presently, correlating the coverage andprobabilistic grammar constraints with higherweights ( > 30%) appears to provide the bestresults.
Creation and colouring tasks appearedto suffer most due to missing or misunderstoodhead-noun modifiers (ie., object colour).
In theseexamples, CLAVIUS ranged from a ?51.7% to a62.5% relative error reduction rate over all tasks.Config ?1 ?(?
)2 ?3 ?4 ?5 ?6?1 0.4 0.0 0.3 0.1 0.1 0.1?2 0.2 0.0 0.1 0.3 0.2 0.2?3 0.1 0.0 0.3 0.3 0.15 0.15Table 1: Three weight configurations.Figure 7: Precision across the test tasks.4.2 Work ExpenditureTo test whether the best-first approachcompensates for CLAVIUS ?
looser constraints(?1.2), a simple bottom-up multichart parser(?1.1) was constructed and the average numberof edges it produces on sentences of varyinglength was measured.
Figure 8 compares thisagainst the average number of edges producedby CLAVIUS on the same data.
In particular,although CLAVIUS generally finds the parse it willaccept relatively quickly (?CLAVIUS - found?
),the COGNITION module will delay its acceptance(?CLAVIUS - accepted?)
for a time.
Further tuningwill hopefully reduce this ?waiting period?.89Figure 8: Number of edges expanded, givensentence length.5 RemarksCLAVIUS consistently ignores over 92% ofdysfluencies (eg.
?uh?)
and significant noiseevents in tracking, apparently as a result of thepartial qualifications discussed in ?1.2.3, which isespecially relevant in noisy environments.
Earlyunquantified observation also suggests that aresult of unordered constituents is that parsesincorporating lead words - head nouns, commandverbs and pointing gestures in particular - areemphasised and form sentence-level parses early,and are later ?filled in?
with function words.5.1 Ongoing WorkThere are at least four avenues open to explorationin the near future.
First, applying the parser todirected two-party dialogue will explore context-sensitivity and a more complex grammar.
Second,the architecture lends itself to further parallelism- specifically by permitting P > 1 concurrentprocessing units to dynamically decide whether toemploy the GENERALISER or SPECIFIER, basedon the sizes of shared active subspaces.We are also currently working on scoringmodules that incorporate language modelling(with discriminative training), and prosody-basedco-analysis.
Finally, we have already begun workon automatic methods to train scoring parameters,including the distribution of ?i, and module-specific training.6 AcknowledgementsFunding has been provided by la bourse demaitrisse of the fonds que?be?cois de la recherchesur la nature et les technologies.ReferencesAgeno, A., Rodriguez, H. 2000 ExtendingBidirectional Chart Parsing with a StochasticModel, in Proc.
of TSD 2000, Brno, CzechRepublic.Alexandersson, J. and Becker, T. 2001 Overlay asthe Basic Operation for Discourse Processing in aMultimodal Dialogue System in Proc.
of the 2ndIJCAI Workshop on Knowledge and Reasoning inPractical Dialogue Systems, Seattle, WA.Bolt, R.A. 1980 ?Put-that-there?
: Voice and gestureat the graphics interface in Proc.
of SIGGRAPH 80ACM Press, New York, NY.Boussemart, Y., Rioux, F., Rudzicz, F., Wozniewski,M., Cooperstock, J.
2004 A Framework for 3DVisualisation and Manipulation in an ImmersiveSpace using an Untethered Bimanual GesturalInterface in Proc.
of VRST 2004 ACM Press, HongKong.Dowding, J. et al 1993 Gemini: A Natural LanguageSystem For Spoken-Language Understanding inMeeting of the ACL, ACL, Morristown, NJ.Holzapfel, H., Nickel, K., Stiefelhagen, R. 2004Implementation and evaluation of a constraint-based multimodal fusion system for speech and 3Dpointing gestures, in ICMI ?04: Proc.
of the 6th intl.conference on Multimodal interfaces, ACM Press,New York, NY.Johnston, M. 1998 Unification-based multimodalparsing, in Proc.
of the 36th annual meeting of theACL, ACL, Morristown, NJ.Johnston, M., Bangalore, S. 2000 Finite-statemultimodal parsing and understanding in Proc.
ofthe 18th conference on Computational linguisticsACL, Morristown, NJ.Kettebekov, S., et al 2002 Prosody Based Co-analysis of Deictic Gestures and Speech in WeatherNarration Broadcast, in Workshop on MultimodalResources and Multimodal System Evaluation.
(LREC 2002), Las Palmas, Spain.McNeill, D. 1992 Hand and mind: What gesturesreveal about thought University of Chicago Pressand CSLI Publications, Chicago, IL.Rocio, V., Lopes, J.G.
1998 Partial Parsing,Deduction and Tabling in TAPD 98Tomita, M. 1985 An Efficient Context-Free ParsingAlgorithm for Natural Languages, in Proc.
NinthIntl.
Joint Conf.
on Artificial Intelligence, LosAngeles, CA.90
