Proceedings of the 5th Workshop on Important Unresolved Matters, pages 65?72,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsPruning the Search Space of a Hand-Crafted Parsing System with aProbabilistic ParserAoife CahillDublin City Universityacahill@computing.dcu.ieTracy Holloway KingPARCthking@parc.comJohn T. Maxwell IIIPARCmaxwell@parc.comAbstractThe demand for deep linguistic analysisfor huge volumes of data means that it isincreasingly important that the time takento parse such data is minimized.
In theXLE parsing model which is a hand-crafted,unification-based parsing system, most ofthe time is spent on unification, searchingfor valid f-structures (dependency attribute-value matrices) within the space of the manyvalid c-structures (phrase structure trees).We carried out an experiment to determinewhether pruning the search space at an ear-lier stage of the parsing process results inan improvement in the overall time taken toparse, while maintaining the quality of thef-structures produced.
We retrained a state-of-the-art probabilistic parser and used it topre-bracket input to the XLE, constrainingthe valid c-structure space for each sentence.We evaluated against the PARC 700 Depen-dency Bank and show that it is possible todecrease the time taken to parse by ?18%while maintaining accuracy.1 IntroductionWhen deep linguistic analysis of massive data is re-quired (e.g.
processing Wikipedia), it is crucial thatthe parsing time be minimized.
The XLE Englishparsing system is a large-scale, hand-crafted, deep,unification-based system that processes raw textand produces both constituent-structures (phrasestructure trees) and feature-structures (dependencyattribute-value matrices).
A typical breakdown ofparsing time of XLE components is Morphology(1.6%), Chart (5.8%) and Unifier (92.6%).The unification process is the bottleneck in theXLE parsing system.
The grammar generates manyvalid c-structure trees for a particular sentence: theUnifier then processes all of these trees (as packedstructures), and a log-linear disambiguation modulecan choose the most probable f-structure from theresulting valid f-structures.
For example, the sen-tence ?Growth is slower.?
has 84 valid c-structuretrees according to the current English grammar;1however once the Unifier has processed all of thesetrees (in a packed form), only one c-structure andf-structure pair is valid (see Figure 1).
In this in-stance, the log-linear disambiguation does not needto choose the most probable result.The research question we pose is whether thesearch space can be pruned earlier before unifi-cation takes place.
Bangalore and Joshi (1999),Clark and Curran (2004) and Matsuzaki et al (2007)show that by using a super tagger before (CCG andHPSG) parsing, the space required for discrimini-tive training is drastically reduced.
Supertaggingis not widely used within the LFG framework, al-though there has been some work on using hypertags(Kinyon, 2000).
Ninomiya et al (2006) propose amethod for faster HPSG parsing while maintainingaccuracy by only using the probabilities of lexicalentry selections (i.e.
the supertags) in their discrim-initive model.
In the work presented here, we con-1For example, is can be a copula, a progressive auxiliary ora passive auxiliary, while slower can either be an adjective or anadverb.65centrate on reducing the number of c-structure treesthat the Unifier has to process, ideally to one tree.The hope was that this would speed up the parsingprocess, but how would it affect the quality of the f-structures?
This is similar to the approach taken byCahill et al (2005) who do not use a hand-craftedcomplete unification system (rather an automaticallyacquired probabilistic approximation).
They parseraw text into LFG f-structures by first parsing with aprobabilistic CFG parser to choose the most proba-ble c-structure.
This is then passed to an automaticf-structure annotation algorithm which deterministi-cally generates one f-structure for that tree.The most compact way of doing this would be tointegrate a statistical component to the parser thatcould rank the c-structure trees and only pass themost likely forward to the unification process.
How-ever, this would require a large rewrite of the sys-tem.
So, we first wanted to investigate a ?cheaper?alternative to determine the viability of the pruningstrategy; this is the experiment reported in this pa-per.
This is implemented by stipulating constituentboundaries in the input string, so that any c-structurethat is incompatible with these constraints is invalidand will not be processed by the Unifier.
This wasdone to some extent in Riezler et al (2002) to au-tomatically generate training data for the log-lineardisambiguation component of XLE.
Previous workobtained the constituent constraints (i.e.
brackets)from the gold-standard trees in the Penn-II Tree-bank.
However, to parse novel text, gold-standardtrees are unavailable.We used a state-of-the-art probabilistic parser toprovide the bracketing constraints to XLE.
Theseparsers are accurate (achieving accuracy of over90% on Section 23 WSJ text), fast, and robust.The idea is that pre-parsing of the input text by afast and accurate parser can prune the c-structuresearch space, reducing the amount of work done bythe Unifier, speed up parsing and maintain the highquality of the f-structures produced.The structure of this paper is as follows: Section2 introduces the XLE parsing system.
Section 3 de-scribes a baseline experiment and based on the re-sults suggests retraining the Bikel parser to improveresults (Section 4).
Section 5 describes experimentson the development set, from which we evaluate themost successful system against the PARC 700 testCS 1: ROOTSadj[fin]S[fin]NPNPadjNPzeroN^ growthVPall[fin]VPcop[fin]Vcop[fin]isAP[pred]AslowerPERIOD.
"Growth is slower.
"'be<[68:slow]>[23:growth]'PRED'growth'PRED23SUBJ'slow<[23:growth]>'PRED[23:growth]SUBJ'more'PRED-1ADJUNCT68XCOMP47Figure 1: C- and F-Structure for ?Growth is slower.
?set (Section 6).
Finally, Section 7 concludes.2 BackgroundIn this section we introduce Lexical FunctionalGrammar, the grammar formalism underlying theXLE, and briefly describe the XLE parsing system.2.1 Lexical Functional GrammarLexical Functional Grammar (LFG) (Kaplan andBresnan, 1982) is a constraint-based theory of gram-mar.
It (minimally) posits two levels of repre-sentation, c(onstituent)-structure and f(unctional)-structure.
C-structure is represented by context-free phrase-structure trees, and captures surfacegrammatical configurations such as word order.The nodes in the trees are annotated with func-tional equations (attribute-value structure con-straints) which are resolved to produce an f-structure.
F-structures are recursive attribute-valuematrices, representing abstract syntactic functions.F-structures approximate basic predicate-argument-adjunct structures or dependency relations.
Fig-ure 1 shows the c- and f-structure for the sentence?Growth is slower.
?.66Parser Output: (S1 (S (NP (NN Growth)) (VP (AUX is) (ADJP (JJR slower))) (.
.
)))Labeled: \[S1 \[S Growth \[VP is \[ADJP slower\] \].\] \]Unlabeled:\[ \[ Growth \[ is \[ slower\] \].\] \]Figure 2: Example of retained brackets from parser output to constrain the XLE parser2.2 The XLE Parsing SystemThe XLE parsing system is a deep-grammar-basedparsing system.
The experiments reported in thispaper use the English LFG grammar constructedas part of the ParGram project (Butt et al, 2002).This system incorporates sophisticated ambiguity-management technology so that all possible syn-tactic analyses of a sentence are computed inan efficient, packed representation (Maxwell andKaplan, 1993).
In accordance with LFG the-ory, the output includes not only standard context-free phrase-structure trees (c-structures) but alsoattribute-value matrices (f-structures) that explic-itly encode predicate-argument relations and othermeaningful properties.
The f-structures can be de-terministically mapped to dependency triples with-out any loss of information, using the built-in or-dered rewrite system (Crouch et al, 2002).
XLE se-lects the most probable analysis from the potentiallylarge candidate set by means of a stochastic disam-biguation component based on a log-linear proba-bility model (Riezler et al, 2002) that works on thepacked representations.
The underlying parsing sys-tem also has built-in robustness mechanisms that al-low it to parse strings that are outside the scope ofthe grammar as a list of fewest well-formed ?frag-ments?.
Furthermore, performance parameters thatbound parsing and disambiguation can be tuned forefficient but accurate operation.
These parametersinclude at which point to timeout and return an error,the amount of stack memory to allocate, the num-ber of new edges to add to the chart and at whichpoint to start skimming (a process that guaranteesXLE will finish processing a sentence in polynomialtime by only carrying out a bounded amount of workon each remaining constituent after a time thresholdhas passed).
For the experiments reported here, wedid not fine-tune these parameters due to time con-straints; so default values were arbitrarily set and thesame values used for all parsing experiments.3 Baseline experimentsWe carried out a baseline experiment with twostate-of-the-art parsers to establish what effect pre-bracketing the input to the XLE system has on thequality and number of the solutions produced.
Weused the Bikel () multi-threaded, head-driven chart-parsing engine developed at the University of Penn-sylvania.
The second parser is that described inCharniak and Johnson (2005).
This parser uses adiscriminative reranker that selects the most proba-ble parse from the 50-best parses returned by a gen-erative parser based on Charniak (2000).We evaluated against the PARC 700 DependencyBank (King et al, 2003) which provides gold-standard analyses for 700 sentences chosen at ran-dom from Section 23 of the Penn-II Treebank.
TheDependency Bank was bootstrapped by parsing the700 sentences with the XLE English grammar, andthen manually correcting the output.
The data is di-vided into two sets, a 140-sentence development setand a test set of 560 sentences (Kaplan et al, 2004).We took the raw strings from the 140-sentencedevelopment set and parsed them with each of thestate-of-the-art probabilistic parsers.
As an upperbound for the baseline experiment, we use the brack-ets in the original Penn-II treebank trees for the 140development set.We then used the brackets from each parser out-put (or original treebank trees) to constrain the XLEparser.
If the input to the XLE parser is bracketed,the parser will only generate c-structures that respectthese brackets (i.e., only c-structures with bracketsthat are compatible with the input brackets are con-sidered during the unification stage).
Figure 2 givesan example of retained brackets from the parser out-put.
We do not retain brackets around PRN (paren-thetical phrase) or NP nodes as their structure oftendiffered too much from XLE analyses of the samephrases.
We passed pre-bracketed strings to the XLEand evaluated the output f-structures in terms of de-pendency triples against the 140-sentence subset of67Non-Fragment FragmentPenn-XLE Penn-XLE Penn-XLE Penn-XLE(lab.)
(unlab.)
(lab.)
(unlab.
)Total XLE parses (/140) 0 89 140 140F-Score of subset 0 84.11 53.92 74.87Overall F-Score 0 58.91 53.92 74.87Table 1: Upper-bound results for original Penn-II treesNon-Fragment FragmentXLE Bikel-XLE Bikel-XLE XLE Bikel-XLE Bikel-XLE(lab.)
(unlab.)
(lab.)
(unlab.
)Total XLE Parses (/140) 119 0 84 135 140 140F-Score of Subset 81.57 0 84.23 78.72 54.37 73.71Overall F-Score 72.01 0 55.06 76.13 54.37 *73.71XLE CJ-XLE CJ-XLE XLE CJ-XLE CJ-XLE(lab.)
(unlab.)
(lab.)
(unlab.
)Total XLE Parses (/140) 119 0 86 135 139 139F-Score of Subset 81.57 0 86.57 78.72 53.96 75.64Overall F-Score 72.01 0 58.04 76.13 53.48 *74.98Table 2: Bikel (2002) and Charniak and Johnson (2005) out-of-the-box baseline resultsthe PARC 700 Dependency Bank.The results of the baseline experiments are givenin Tables 1 and 2.
Table 1 gives the upper boundresults if we use the gold standard Penn treebankto bracket the input to XLE.
Table 2 compares theXLE (fragment and non-fragment) grammar to thesystem where the input is pre-parsed by each parser.XLE fragment grammars provide a back-off whenparsing fails: the grammar is relaxed and the parserbuilds a fragment parse of the well-formed chunks.We compare the parsers in terms of total numberof parses (out of 140) and the f-score of the sub-set of sentences successfully parsed.
We also com-bine these scores to give an overall f-score, wherethe system scores 0 for each sentence it could notparse.
When testing for statistical significance be-tween systems, we compare the overall f-score val-ues.
Figures marked with an asterisk are not statisti-cally significantly different at the 95% level.2The results show that using unlabeled bracketsachieves reasonable f-scores with the non-fragmentgrammar.
Using the labeled bracketing from the out-put of both parsers causes XLE to always fail whenparsing.
This is because the labels in the output ofparsers trained on the Penn-II treebank differ con-siderably from the labels on c-structure trees pro-2We use the approximate randomization test (Noreen, 1989)to test for significance.duced by XLE.
Interestingly, the f-scores for boththe CJ-XLE and Bikel-XLE systems are very sim-ilar to the upper bounds.
The gold standard upperbound is not as high as expected because the Penntrees used to produce the gold bracketed input arenot always compatible with the XLE-style trees.
Asa simple example, the tree in Figure 1 differs fromthe parse tree for the same sentence in the PennTreebank (Figure 3).
The most obvious differenceis the labels on the nodes.
However, even in thissmall example, there are structural differences, e.g.the position of the period.
In general, the larger thetree, the greater the difference in both labeling andstructure between the Penn trees and the XLE-styletrees.
Therefore, the next step was to retrain a parserto produce trees with structures the same as XLE-style trees and with XLE English grammar labels onthe nodes.
For this experiment we use the Bikel ()parser, as it is more suited to being retrained on anew treebank annotation scheme.4 Retraining the Bikel parserWe retrained the Bikel parser so that it producestrees like those outputted by the XLE parsing sys-tem (e.g.
Figure 1).
To do this, we first created atraining corpus, and then modified the parser to dealwith this new data.Since there is no manually-created treebank of68SNPNNGrowthVPVBZisADJP-PRDJJRslower?
?Figure 3: Penn Treebank tree for ?Growth is slower.
?XLE-style trees, we created one automatically fromsections 02-21 of the Penn-II Treebank.
We took theraw strings from those sections and marked up NPand SBAR constituents using the brackets from thegold standard Penn treebank.
The NP constituentsare labeled, and the SBAR unlabeled (i.e.
the SBARconstituents are forced to exist in the XLE parse, butthe label on them is not constrained to be SBAR).We also tagged verbs, adjectives and nouns, basedon the gold standard POS tags.We parsed the 39,832 marked-up sentences in thestandard training corpus and used the XLE disam-biguation module to choose the most probable c-and f-structure pair for each sentence.
Ideally wewould have had an expert choose these.
We au-tomatically extracted the c-structure trees producedby the XLE and performed some automatic post-processing.3 This resulted in an automatically cre-ated training corpus of 27,873 XLE-style trees.
The11,959 missing trees were mainly due to the XLEparses not being compatible with the bracketed in-put, but sometimes due to time and memory con-straints.Using the automatically-created training corpusof XLE-style trees, we retrained the Bikel parser onthis data.
This required adding a new language mod-ule (?XLE-English?)
to the Bikel parser, and regen-erating head-finding rules for the XLE-style trees.5 ExperimentsOnce we had a retrained version of the Bikel parserthat parses novel text into XLE-style trees, we car-ried out a number of experiments on our develop-ment set in order to establish the optimum settings3The postprocessing included removing morphological in-formation and the brackets from the original markup.All SentencesXLE Bikel-XLENon-fragment grammarLabeled bracketsTotal Parsing Time 964 336Total XLE Parses (/140) 119 77F-Score of Subset 81.57 86.11Overall F-Score 72.01 52.84Non-fragment grammarUnlabeled bracketsTotal Parsing Time 964 380Total XLE Parses (/140) 119 89F-Score of Subset 81.57 85.62Overall F-Score 72.01 59.34Fragment grammarLabeled bracketsTotal Parsing Time 1143 390Total XLE Parses (/140) 135 140F-Score of Subset 78.72 71.86Overall F-Score 76.13 71.86Fragment grammarUnlabeled bracketsTotal Parsing Time 1143 423Total XLE Parses (/140) 135 140F-Score of Subset 78.72 74.51Overall F-Score 76.13 *74.51Table 3: Bikel-XLE Initial Experimentsfor the evaluation against the PARC 700 test set.5.1 Pre-bracketingWe automatically pre-processed the raw strings fromthe 140-sentence development set.
This made sys-tematic changes to the tokens so that the retrainedBikel parser can parse them.
The changes includedremoving quotes, converting a and an to a, con-verting n?t to not, etc.
We parsed the pre-processedstrings with the new Bikel parser.We carried out four initial experiments, experi-menting with both labeled and unlabeled bracketsand XLE fragment and non-fragment grammars.
Ta-ble 3 gives the results for these experiments.
Wecompare the parsers in terms of time, total numberof parses (out of 140), the f-score of the subset ofsentences successfully parsed and the overall f-scoreif the system achieves a score of 0 for all sentencesit does not parse.
The time taken for the Bikel-XLEsystem includes the time taken for the Bikel parserto parse the sentences, as well as the time taken forXLE to process the bracketed input.Table 3 shows that using the non-fragment gram-mar, the Bikel-XLE system performs better on the69subset of sentences parsed than XLE system alone,though the results are not statistically significantlybetter overall, since the coverage is much lower.
Thenumber of bracketed sentences that can be parsedby XLE increases if the brackets are unlabeled.The table also shows that the XLE system performsmuch better than Bikel-XLE when using the frag-ment grammars.
Although the Bikel-XLE system isquite a bit faster, there is a drop in f-score; howeverthis is not statistically significant when the bracketsare unlabeled.5.2 Pre-taggingWe performed some error analysis on the output ofthe Bikel-XLE system and noticed that a consider-able number of errors were due to mis-tagging.
So,we pre-tagged the input to the Bikel parser using theMXPOST tagger (Ratnaparkhi, 1996).
The resultsfor the non-fragment grammars are presented in Ta-ble 4.
Pre-tagging with MXPOST, however, doesnot result in a statistically significantly higher re-sult than parsing untagged input, although more sen-tences can be parsed by both systems.
Pre-taggingalso adds an extra time overhead cost.No pretags MXPOST tagsXLE Bikel-XLE Bikel-XLEUnlabeledTotal Parsing Time 964 380 493# XLE Parses (/140) 119 89 92F-Score of Subset 81.57 85.62 84.98Overall F-Score 72.01 59.34 *61.11LabeledTotal Parsing Time 964 336 407# XLE Parses (/140) 119 77 80F-Score of Subset 81.57 86.11 85.87Overall F-Score 72.01 52.84 *54.91Table 4: MXPOST pre-tagged, Non-fragment gram-mar5.3 PruningThe Bikel parser can be customized to allow differ-ent levels of pruning.
The above experiments werecarried out using the default level.
We carried outexperiments with three levels of pruning.4 The re-4The default level of pruning starts at 3.5, has a maximum of4 and relaxes constraints when parsing fails.
Level 1 pruning isthe same as the default except the constraints are never relaxed.Level 2 pruning has a start value of 3.5 and a maximum valueof 3.5.
Level 3 pruning has a start and maximum value of 3.sults are given in Table 5 for the experiment withlabeled brackets and the non-fragment XLE gram-mar.
More pruning generally results in fewer andlower-quality parses.
The biggest gain is with prun-ing level 1, where the number and quality of brack-eted sentences that can be parsed with XLE remainsthe same as with the default level.
This is becauseBikel with pruning level 1 does not relax the con-straints when parsing fails and does not waste timeparsing sentences that cannot be parsed in bracketedform by XLE.Default L1 L2 L3Total Parsing Time 336 137 137 106# XLE Parses (/140) 77 77 76 75F-Score of Subset 86.11 86.11 86.04 85.87Overall F-Score 52.84 *52.84 *52.43 *52.36Table 5: Pruning with Non-fragment grammar, La-beled brackets, Levels default-35.4 Hybrid systemsAlthough pre-parsing with Bikel results in fasterXLE parsing time and high-quality f-structures(when examining only the quality of the sentencesthat can be parsed by the Bikel-XLE system), thecoverage of this system remains poor, therefore theoverall f-score remains poor.
One solution is to builda hybrid two-pass system.
During the first pass allsentences are pre-parsed by Bikel and the bracketedoutput is parsed by the XLE non-fragment gram-mar.
In the second pass, the sentences that werenot parsed during the first pass are parsed with theXLE fragment grammar.
We carried out a numberof experiments with hybrid systems and the resultsare given in Table 6.The results show that again labeled brackets re-sult in a statistically significant increase in f-score,although the time taken is almost the same as theXLE fragment grammar alone.
Coverage increasesby 1 sentence.
Using unlabeled brackets results in3 additional sentences receiving parses, and parsingtime is improved by ?12%; however the increase inf-score is not statistically significant.Table 7 gives the results for hybrid systems withpruning using labeled brackets.
The more pruningthat the Bikel parser does, the faster the system,but the quality of the f-structures begins to deteri-70XLE Bikel-XLE hybrid Bikel-XLE hybrid(frag) (labeled) (unlabeled)Total Parsing Time 1143 1121 1001Total XLE Parses (/140) 135 136 138F-Score of Subset 78.72 79.85 79.51Overall F-Score 76.13 77.61 *78.28Table 6: Hybrid systems compared to the XLE fragment grammar aloneXLE Bikel-XLE hybrid Bikel-XLE hybrid Bikel-XLE hybrid(frag) (level 1) (level 2) (level 3)Total Parsing Time 1143 918 920 885Total XLE Parses (/140) 135 136 136 136F-Score of Subset 78.72 79.85 79.79 79.76Overall F-Score 76.13 77.61 77.55 77.53Table 7: Hybrid systems with pruning compared to the XLE fragment grammar aloneorate.
The best system is the Bikel-XLE hybrid sys-tem with labeled brackets and pruning level 1.
Thissystem achieves a statistically significant increase inf-score over the XLE fragment grammar alone, de-creases the time taken to parse by almost 20% andincreases coverage by 1 sentence.
Therefore, wechose this system to perform our final evaluationagainst the PARC 700 Dependency Bank.6 Evaluation against the PARC 700We evaluated the system that performs best on thedevelopment set against the 560-sentence test set ofthe PARC 700 Dependency Bank.
The results aregiven in Table 8.
The hybrid system achieves an18% decrease in parsing time, a slight improvementin coverage of 0.9%, and a 1.12% improvement inoverall f-structure quality.XLE Bikel-XLE hybrid(frag) (labeled, prune 1)Total Parsing Time 4967 4077Total XLE Parses (/560) 537 542F-Score of Subset 80.13 80.63Overall F-Score 77.04 78.16Table 8: PARC 700 evaluation of the Hybrid systemcompared to the XLE fragment grammar alone7 ConclusionsWe successfully used a state-of-the-art probabilisticparser in combination with a hand-crafted system toimprove parsing time while maintaining the qualityof the output produced.
Our hybrid system consistsof two phases.
During phase one, pre-processed, to-kenized text is parsed with a retrained Bikel parser.We use the labeled brackets in the output to constrainthe c-structures generated by the XLE parsing sys-tem.
In the second phase, we use the XLE fragmentgrammar to parse any remaining sentences that havenot received a parse in the first phase.Given the slight increase in overall f-score per-formance, the speed up in parsing time (?18%) canjustify more complicated processing architecture forsome applications.5 The main disadvantage of thecurrent system is that the input to the Bikel parserneeds to be tokenized, whereas XLE processes rawtext.
One solution to this is to use a state-of-the-artprobabilistic parser that accepts untokenized input(such as Charniak and Johnson, 2005) and retrain itas described in Section 4.Kaplan et al (2004) compared time and accuracyof a version of the Collins parser tuned to maximizespeed and accuracy to an earlier version of the XLEparser.
Although the XLE parser was more accu-rate, the parsing time was a factor of 1.49 slower(time converting Collins trees to dependencies wasnot counted in the parse time; time to produce f-structures from c-structures was counted in the XLEparse time).
The hybrid system here narrows thespeed gap while maintaining greater accuracy.The original hope behind using the brackets toconstrain the XLE c-structure generation was that5For example, in massive data applications, if the parsingtask takes 30 days, reducing this by 18% saves more than 5days.71the brackets would force the XLE to choose onlyone tree.
However, the brackets were sometimesambiguous, and sometimes more than one valid treewas found.
In the final evaluation against the PARC700 test set, the average number of optimal solutionswas 4.05; so the log-linear disambiguation mod-ule still had to chose the most probable f-structure.However, this is considerably less to choose fromthan the average of 341 optimal solutions producedby the XLE fragment grammar for the same sen-tences when unbracketed.Based on the results of this experiment we haveintegrated a statistical component into the XLEparser itself.
With this architecture the packed c-structure trees are pruned before unification with-out needing to preprocess the input text.
The XLEc-structure pruning results in a ?30% reduction inparse time on the Wikipedia with little loss in preci-sion.
We hope to report on this in the near future.AcknowledgmentsThe research in this paper was partly funded by Sci-ence Foundation Ireland grant 04/BR/CS0370.ReferencesSrinivas Bangalore and Aravind K. Joshi.
1999.
Su-pertagging: An approach to alsmost parsing.
Com-putational Linguistics, 25(2):237?265.Dan Bikel.
Design of a Multi-lingual, Parallel-processingStatistical Parsing Engine.
In Proceedings of HLT,YEAR = 2002, pages = 24?27, address = San Diego,CA,.Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-roshi Masuichi, and Christian Rohrer.
2002.
The Par-allel Grammar Project.
In Proceedings of Workshopon Grammar Engineering and Evaluation, pages 1?7,Taiwan.Aoife Cahill, Martin Forst, Michael Burke, Mairead Mc-Carthy, Ruth O?Donovan, Christian Rohrer, Josef vanGenabith, and Andy Way.
2005.
Treebank-basedacquisition of multilingual unification grammar re-sources.
Journal of Research on Language and Com-putation, pages 247?279.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
In Proceedings of ACL, pages 173?180,Ann Arbor, Michigan.Eugene Charniak.
2000.
A maximum entropy inspiredparser.
In Proceedings of NAACL, pages 132?139,Seattle, WA.Stephen Clark and James R. Curran.
2004.
The Impor-tance of Supertagging for Wide-Coverage CCG Pars-ing .
In Proceedings of COLING, pages 282?288,Geneva, Switzerland, Aug 23?Aug 27.
COLING.Richard Crouch, Ron Kaplan, Tracy Holloway King, andStefan Riezler.
2002.
A comparison of evaluationmetrics for a broad coverage parser.
In Proceedings ofthe LREC Workshop: Beyond PARSEVAL, pages 67?74, Las Palmas, Canary Islands, Spain.Ron Kaplan and Joan Bresnan.
1982.
Lexical FunctionalGrammar, a Formal System for Grammatical Repre-sentation.
In Joan Bresnan, editor, The Mental Repre-sentation of Grammatical Relations, pages 173?281.MIT Press, Cambridge, MA.Ron Kaplan, Stefan Riezler, Tracy Holloway King,John T. Maxwell, Alexander Vasserman, and RichardCrouch.
2004.
Speed and Accuracy in Shallow andDeep Stochastic Parsing.
In Proceedings of HLT-NAACL, pages 97?104, Boston, MA.Tracy Holloway King, Richard Crouch, Stefan Riezler,Mary Dalrymple, and Ron Kaplan.
2003.
The PARC700 dependency bank.
In Proceedings of LINC, pages1?8, Budapest, Hungary.Alexandra Kinyon.
2000.
Hypertags.
In Proceedings ofCOLING, pages 446?452, Saarbru?cken.Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.2007.
Efficient HPSG Parsing with Supertagging andCFG-filtering.
In Proceedings of IJCAI, pages 1671?1676, India.John T. Maxwell and Ronald M. Kaplan.
1993.
Theinterface between phrasal and functional constraints.Computational Linguistics, 19(4):571?590.Takashi Ninomiya, Takuya Matsuzaki, Yoshimasa Tsu-ruoka, Yusuke Miyao, and Jun?ichi Tsujii.
2006.Extremely Lexicalized Models for Accurate and FastHPSG Parsing.
In Proceedings of EMNLP, pages155?163, Australia.Eric W. Noreen.
1989.
Computer Intensive Methodsfor Testing Hypotheses: An Introduction.
Wiley, NewYork.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Part-Of-Speech Tagger.
In Proceedings of EMNLP, pages133?142, Philadelphia, PA.Stefan Riezler, Tracy King, Ronald Kaplan, RichardCrouch, John T. Maxwell, and Mark Johnson.
2002.Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative EstimationTechniques.
In Proceedings of ACL, pages 271?278,Philadelphia, PA.72
