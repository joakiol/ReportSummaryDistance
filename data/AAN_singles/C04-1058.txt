Why Nitpicking Works: Evidence for Occam?s Razor in Error CorrectorsDekai WU?1 Grace NGAI?2 Marine CARPUAT?dekai@cs.ust.hk csgngai@polyu.edu.hk marine@cs.ust.hk?
Human Language Technology CenterHKUSTDepartment of Computer ScienceUniversity of Science and TechnologyClear Water Bay, Hong Kong?
Hong Kong Polytechnic UniversityDepartment of ComputingKowloonHong KongAbstractEmpirical experience and observations have shown us whenpowerful and highly tunable classifiers such as maximum en-tropy classifiers, boosting and SVMs are applied to languageprocessing tasks, it is possible to achieve high accuracies, buteventually their performances all tend to plateau out at aroundthe same point.
To further improve performance, various errorcorrection mechanisms have been developed, but in practice,most of them cannot be relied on to predictably improve per-formance on unseen data; indeed, depending upon the test set,they are as likely to degrade accuracy as to improve it.
Thisproblem is especially severe if the base classifier has alreadybeen finely tuned.In recent work, we introduced N-fold Templated Piped Cor-rection, or NTPC (?nitpick?
), an intriguing error corrector thatis designed to work in these extreme operating conditions.
De-spite its simplicity, it consistently and robustly improves the ac-curacy of existing highly accurate base models.
This paper in-vestigates some of the more surprising claims made by NTPC,and presents experiments supporting an Occam?s Razor argu-ment that more complex models are damaging or unnecessaryin practice.1 IntroductionThe investigation we describe here arose from a verycommonly discussed experience, apparently triggered bythe recent popularity of shared task evaluations that haveopened opportunities for researchers to informally com-pare their experiences ?with a common denominator?, soto speak.Among the perennial observations which are madeduring the analysis of the results is that (1) methods de-signed to ?fine-tune?
the high-accuracy base classifiersbehave unpredictably, their success or failure often ap-pearing far more sensitive to where the test set was drawnfrom, rather than on any true quality of the ?fine-tuning?,and consequently, (2) the resulting system rankings areoften unpredictable, especially as they are typically con-ducted only on a single new test set, often drawn froma single arbitrary new source of a significantly differentnature than the training sets.
One could argue that suchevaluations do not constitute a fair test, but in fact, this is1The author would like to thank the Hong Kong Research GrantsCouncil (RGC) for supporting this research in part through researchgrants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09.2The author would like to thank the Hong Kong Polytechnic Univer-sity for supporting this research in part through research grants A-PE37and 4-Z03S.where computational linguistics modeling diverges frommachine learning theory, since for any serious NLP ap-plication, such evaluations constitute a much more accu-rate representation of the real world.We believe one primary reason for this common ex-perience is that the models involved are typically al-ready operating well beyond the limits of accuracy ofthe models?
assumptions about the nature of distributionsfrom which testing samples will be drawn.
For this rea-son, even ?sophisticated?
discriminative training crite-ria, such as maximum entropy, minimum error rate, andminimum Bayes risk, are susceptible to these stabilityproblems.
There has been much theoretical work doneon error correction, but in practice, any error correctionusually lowers the performance of the combined systemon unseen data, rather than improving it.
Unfortunately,most existing theory simply does not apply.This is especially true if the base model has beenhighly tuned.
For the majority of tasks, the performanceof the trained models, after much fine tuning, tend toplateau out at around the same point, regardless of thetheoretical basis of the underlying model.
This holdstrue with most highly accurate classifiers, including max-imum entropy classifiers, SVMs, and boosting models.In addition, even though data analysis gives us some gen-eral idea as to what kinds of feature conjunctions mighthelp, the classifiers are not able to incorporate thoseinto their model (usually because the computational costwould be infeasible), and any further post-processingtends to degrade accuracy on unseen data.
The commonpractice of further improving accuracy at this point is toresort to ad hoc classifier combination methods, whichare usually not theoretically well justified and, again, un-predictably improve or degrade performance?thus con-suming vast amounts of experimental resources with rel-atively low expected payoff, much like a lottery.There are a variety of reasons for this, ranging fromthe aforementioned validity of the assumptions about thedistribution between the training and test corpora, to theabsence of a well justified stopping point for error cor-rection.
The latter problem is much more serious than itseems at first blush, since without a well-justified stop-ping criterion, the performance of the combined modelwill be much more dependent upon the distribution ofthe test set, than on any feature engineering.
Empiricalevidence for this argument can be seen from the result ofthe CoNLL shared tasks (Tjong Kim Sang, 2002)(TjongKim Sang and Meulder, 2003), where the ranking of theparticipating systems changes with the test corpora.Inspired by the repeated observations of this phe-nomenon by many participants, we decided to stop?sweeping the issue under the rug?, and undertook toconfront it head-on.
Accordingly, we challenged our-selves to design an error corrector satisfying the follow-ing criteria, which few if any existing models actuallymeet: (1) it would leverage off existing base models,while targeting their errors; (2) it would consistently im-prove accuracy, even on top of base models that alreadydeliver high accuracy; (3) it would be robust and con-servative, so as to almost never accidentally degrade ac-curacy; (4) it would be broadly applicable to any classi-fication or recognition task, especially high-dimensionalones such as named-entity recognition and word-sensedisambiguation; and (5) it would be template-driven andeasily customizable, which would enable it to target er-ror patterns beyond the base models?
representation andcomputational complexity limitations.Our goal in this undertaking was to invent as little aspossible.
We expected to make use of relatively sophis-ticated error-minimization techniques.
Thus the resultswere surprising: the simplest models kept outperform-ing the ?sophisticated?
models.
This paper attempts toinvestigate some of the key reasons why.To avoid reinventing the wheel, we originallyconsidered adapting an existing error-driven method,transformation-based learning (TBL) for this purpose.TBL seems well suited to the problem as it is inherentlyan error corrector and, on its own, has been shown toachieve high accuracies on a variety of problems (seeSection 4).
Our original goal was to adapt TBL forerror correction of high-performing models (Wu et al,2004a), with two main principles: (1) since it is not clearthat the usual assumptions made about the distributionof the training/test data are valid in such extreme oper-ating ranges, empirical observations would take prece-dence over theoretical models, which implies that (2) anymodel would have to be empirically justified by testingon a diverse range of data.
Experimental observations,however, increasingly drove us toward different goals.Our resulting error corrector, NTPC, was instead con-structed on the principle of making as few assumptions aspossible in order to robustly generalize over diverse situ-ations and problems.
One observation made in the courseof experimentation, after many attempts at fine-tuningmodel parameters, was that many of the complex theo-retical models for error correction often do not performconsistently.
This is perhaps not too surprising upon fur-ther reflection, since the principle of Occam?s Razor doesprefer simpler hypotheses over more complex ones.NTPC was introduced in (Wu et al, 2004b), where thecontroversial issues it raised generated a number of in-teresting questions, many of which were were directed atNTPC?s seeming simplicity, which seems in oppositionto the theory behind many other error correcting models.In this paper, we investigate the most commonly-askedquestions.
We illuminate these questions by contrastingNTPC against the more powerful TBL, presenting ex-periments that show that NTPC?s simple model is indeedFigure 1: Piped architecture with n-fold partitioning.key to its robustness and reliability.The rest of the paper is laid out as follows: Section 2presents an introduction to NTPC, including an overviewof its architecture.
Section 3 addresses key questions re-lated to NTPC?s architecture and presents empirical re-sults justifying its simplicity.2 N-fold Templated Piped CorrectionN-fold Templated Piped Correction or NTPC, is amodel that is designed to robustly improve the accuracyof existing base models in a diverse range of operatingconditions.
As was described above, the most challeng-ing situations for any error corrector is when the basemodel has been finely tuned and the performance hasreached a plateau.
Most of the time, any further featureengineering or error correction after that point will endup hurting performance rather than improving it.2.1 The architecture of NTPC is surprisinglysimpleOne of the most surprising things about NTPC lies inthe fact that despite its simplicity, it outperforms math-ematically much more ?sophisticated?
methods at errorcorrecting.
Architecturally, it relies on a simple rule-learning mechanism and cross-partitioning of the train-ing data to learn very conservative, cautious rules thatmake only a few corrections at a time.Figure 1 illustrates the NTPC architecture.
Prior tolearning, NTPC is given (1) a set of rule templates whichdescribe the types of rules that it is allowed to hypothe-size, (2) a single base learning model, and (3) an anno-tated training set.The NTPC architecture is essentially a sequen-tially chained piped ensemble that incorporates cross-validation style n-fold partition sets generated from thebase model.
The training set is partitioned n times inorder to train n base models.
Subsequently the n held-out validation sets are classified by the respective trainedbase models, with the results combined into a ?reconsti-tuted?
training set.
The reconstituted training set is usedby Error Corrector Learner, which learns a set of rules.Rule hypotheses are generated according to the given setof allowable templates:R = {r| r ?
H ?
?
(r) > ?min ?
 (r) = 0} (1)?
(r) =?Xj=1?r(xj ,y?j) 6=??
(r(xj , y?j), yj) (2)(r) =?Xj=1?r(xj ,y?j) 6=?1?
?
(r(xj , y?j), yj)(3)where X is a sequence of X training examples xi, Yis a sequence of reference labels yi for each examplerespectively, Y?
is a sequence of labels y?i as predictedby the base model for each example respectively, H isthe hypothesis space of valid rules implied by the tem-plates, and ?min is a confidence threshold.
Setting ?minto a relatively high value (say 15) implements the re-quirement of high reliability.
R is subsequently sortedby the ?i value of each rule ri into an ordered list of rulesR?
= (r?0, .
.
.
, r?i?1).During the evaluation phase, depicted in the lower por-tion of Figure 1, the test set is first labeled by the basemodel.
The error corrector?s rules r?i are then applied inthe order of R?
to the evaluation set.
The final classifica-tion of a sample is then the classification attained whenall the rules have been applied.2.2 NTPC consistently and robustly improvesaccuracy of highly-accurate base modelsIn previous work (Wu et al, 2004b), we presented ex-periments on named-entity identification and classifica-tion across four diverse languages, using Adaboost.MHas the base learner, which showed that NTPC was ca-pable of robustly and consistently improving upon theaccuracy of the already-highly-accurate boosting model;correcting the errors committed by the base model butnot introducing any of its own.Table 1 compares results obtained with the base Ad-aboost.MH model (Schapire and Singer, 2000) and theNTPC-enhanced model for a total of eight differentnamed-entity recognition (NER) models.
These experi-ments were performed on the CoNLL-2002 and CoNLL-2003 shared task data sets.
It can be seen that the Ad-aboost.MH base models clearly already achieve high ac-curacy, setting the bar very high for NTPC to improveupon.
However, it can also be seen that NTPC yields fur-ther F-Measure gains on every combination of task andlanguage, including English NE bracketing (Model M2)for which the base F-Measure is the highest.An examination of the rules (shown in the Appendix)can give an idea as to why NTPC manages to identifyand correct errors which were overlooked by the highlytuned base model.
NTPC?s advantage comes from twoaspects: (1) its ability to handle complex conjunctionsof features, which often reflect structured, linguisticallymotivated expectations, in the form of rule templates;and (2) its ability to ?look forward?
at classificationsfrom the right context, even when processing the sen-tence in a left-to-right direction.
The base classifier isunable to incorporate these two aspects, because (1) in-cluding complex conjunctions of features would raise thecomputational cost of searching the feature space to apoint where it would be infeasible, and (2) most classi-fiers process a sentence from left-to-right, deciding onthe class label for each word before moving on to thenext one.
Rules that exploit these advantages are eas-ily picked out in the table; many of the rules (especiallythose in the top 5 for both English and Spanish) consist ofcomplex conjunctions of features; and rules that considerthe right context classifications can be identified by thestring ?ne <num>?, where <num> is a positive integer(indicating how many words to the right).3 ExperimentsThe most commonly-raised issues about NTPC relateto the differences between NTPC and TBL (though theconceptual issues are much the same as for other error-minimization criteria, such as minimum error rate orminimum Bayes risk).
This is expected, since it wasone of our goals to reinvent as little as possible.
Asa result, NTPC does bear a superficial resemblance toTBL, both of them being error-driven learning methodsthat seek to incrementally correct errors in a corpus bylearning rules that are determined by a set of templates.One of the most frequently asked questions is whetherthe Error Corrector Learner portion of NTPC could bereplaced by a transformation-based learner.
This sectionwill investigate the differences between NTPC and TBL,and show the necessity of the changes that were incorpo-rated into NTPC.The experiments run in this section were performedon the data sets used in the CoNLL-2002 and CoNLL-2003 Named Entity Recognition shared tasks.
Thehigh-performing base model is based on AdaBoost.MH(Schapire and Singer, 2000), the multi-class generaliza-tion of the original boosting algorithm, which imple-ments boosting on top of decision stump classifiers (de-cision trees of depth one).3.1 Any Error is BadThe first main difference between NTPC and TBL, andalso what seems to be an extreme design decision onthe part of NTPC, is the objective scoring function.
Tobe maximally certain of not introducing any new errorswith its rules, the first requirement that NTPC?s objectivefunction places onto any candidate rules is that they mustnot introduce any new errors ( (r) = 0).
This is calledthe zero error tolerance principle.To those who are used to learners such astransformation-based learning and decision lists, whichallow for some degree of error tolerance, this design prin-ciple seems overly harsh and inflexible.
Indeed, for al-Table 1: NTPC consistently yields improvements on all eight different high-accuracy NER base models, across everycombination of task and language.Model Task Language Model Precision Recall F-Measure1M1 Bracketing Dutch Base 87.27 91.48 89.33Base w/ NTPC 87.44 92.04 89.68M2 Bracketing English Base 95.01 93.98 94.49Base w/ NTPC 95.23 94.05 94.64M3 Bracketing German Base 83.44 65.86 73.62Base w/ NTPC 83.43 65.91 73.64M4 Bracketing Spanish Base 89.46 87.57 88.50Base w/ NTPC 89.77 88.07 88.91M5 Classification + Bracketing Dutch Base 70.26 73.64 71.91Base w/ NTPC 70.27 73.97 72.07M6 Classification + Bracketing English Base 88.64 87.68 88.16Base w/ NTPC 88.93 87.83 88.37M7 Classification + Bracketing German Base 75.20 59.35 66.34Base w/ NTPC 75.19 59.41 66.37M8 Classification + Bracketing Spanish Base 74.11 72.54 73.32Base w/ NTPC 74.43 73.02 73.72most all models, there is an implicit assumption that thescoring function will be based on the difference betweenthe positive and negative applications, rather than on anabsolute number of corrections or mistakes.Results for eight experiments are shown in Figures 2and 3.
Each experiment compares NTPC against othervariants that allow relaxed  (r) ?
max conditions forvarious max ?
{1, 2, 3, 4,?}.
The worst curve in eachcase is for max = ??
in other words, the system thatonly considers net performance improvement, as TBLand many other rule-based models do.
The results con-firm empirically that the  (r) = 0 condition (1) gives themost consistent results, and (2) generally yields accura-cies among the highest, regardless of how long training isallowed to continue.
In other words, the presence of anynegative application during the training phase will causethe error corrector to behave unpredictably, and the morecomplex model of greater error tolerance is unnecessaryin practice.3.2 Rule Interaction is UnreliableAnother key difference between NTPC and TBL is theprocess of rule interaction.
Since TBL allows a rule touse the current classification of a sample and its neigh-bours as features, and a rule updates the current state ofthe corpus when it applies to a sample, the applicationof one rule could end up changing the applicability (ornot) of another rule.
From the point of view of a sam-ple, its classification could depend on the classificationof ?nearby?
samples.
Typically, these ?nearby?
samplesare those found in the immediately preceding or succeed-ing words of the same sentence.
This rule interaction ispermitted in both training and testing.NTPC, however, does not allow for this kind of rule in-teraction.
Rule applications only update the output clas-sification of a sample, and do not update the current stateof the corpus.
In other words, the feature values for aFigure 2: NTPC?s zero tolerance condition yields lessfluctuation and generally higher accuracy than the re-laxed tolerance variations, in bracketing experiments.
(bold = NTPC, dashed = relaxed tolerance)sample are initialized once, at the beginning of the pro-gram, and not changed again thereafter.
The rationale formaking this decision is the hypothesis that rule interac-tion is in nature unreliable, since the high-accuracy basemodel provides sparse opportunities for rule applicationand thus much sparser opportunities for rule interaction,making any rule that relies on rule interaction suspect.As a matter of fact, by considering only rules that makeno mistake during the learning phase, NTPC?s zero errortolerance already eliminates any correction of labels thatresults from rule interaction?since a label correction ona sample that results from the application of more thanone rule necessarily implies that at least one of the rulesmade a mistake.Since TBL is a widely used error-correcting method,Figure 3: NTPC?s zero tolerance condition yields lessfluctuation and generally higher accuracy than the re-laxed tolerance variations, in bracketing + classificationexperiments.
(bold = NTPC, dashed = relaxed tolerance)Figure 4: Unpredictable fluctuations on the bracket-ing task show that allowing TBL-style rule interactiondoes not yield reliable improvement over NTPC.
(bold =NTPC, dashed = rule interaction)Figure 5: Unpredictable fluctuations on the bracket-ing + classification task show that allowing TBL-stylerule interaction does not yield reliable improvement overNTPC.
(bold = NTPC, dashed = rule interaction)it is natural to speculate that NTPC?s omission of rule in-teraction is a weakness.
In order to test this question, weimplemented an iterative variation of NTPC that allowsrule interaction, where each iteration targets the residualerror from previous iterations as follows:1. i?
0,X0 ?
X2.
r?i ?
null, s?i ?
03. foreach r ?
H such that i (r) = 0?
if ?i (r) > ?
?i then r?i ?
r, ?
?i ?
?i (r)4. if ?
?i < ?min then return5.
Xi+1 ?
result of applying r?i to Xi6.
i?
i + 17. goto Step 3where?i(r) =?Xj=1?r(xij ,y?j) 6=??
(r(xij , y?j), yj)i(r) =?Xj=1?r(xij ,y?j) 6=?1?
?
(r(xij , y?j), yj)Here, incremental rule interaction is a natural conse-quence of arranging the structure of the algorithm to ob-serve the right context features coming from the basemodel, as with transformation-based learning.
In Step5 of the algorithm, the current state of the corpus is up-dated with the latest rule on each iteration.
That is, ineach given iteration of the outer loop, the learner consid-ers the corrected training data obtained by applying ruleslearned in the previous iterations, so the learner has ac-cess to the labels that result from applying the previousrules.
Since these rules may apply anywhere in the cor-pus, the learner is not restricted to using only labels fromthe left context.The time complexity of this variation is an order ofmagnitude more expensive than NTPC, due to the needto allow rule interaction using nested loops.
The orderedlist of output rules r?0 , .
.
.
, r?i?1is learned in a greedyfashion, to progressively improve upon the performanceof the learning algorithm on the training set.Results for eight experiments on this variation, shownin Figures 4 and 5, demonstrate that this expensive extracapability is rarely useful in practice and does not reli-ably guarantee that accuracy will not be degraded.
Thisis yet another illustration of the principle that, in high-accuracy error correction problems, at least, more simplemodes of operation should be preferred over more com-plex arrangements.3.3 NTPC vs. N-fold TBLAnother question on NTPC that is frequently raised iswhether or not ordinary TBL, which is after all, intrinsi-cally an error-correcting model, can be used in place ofNTPC to perform better error correction.
Figure 6 showsthe results of four sets of experiments evaluating this ap-proach on top of boosting.
As might be expected fromextrapolation from the foregoing experiments that inves-tigated their individual differences, NTPC outperformsthe more complex TBL in all cases, regardless of howlong training is allowed to continue.Figure 6: NTPC consistently outperforms error correc-tion using TBL even when n-fold partitioning is used.
(bold = NTPC, dashed = TBL with n-fold partitioning)Table 2: The more complex partition-based voted er-ror corrector degrades performance, while NTPC helps(bracketing + classification, English).Model Precision Recall F-Measure1Base 95.01 93.98 94.49Partition-BasedVoting95.07 93.79 94.43Base w/ NTPC 95.14 94.05 94.593.4 NTPC vs. Partition-Based VotingAnother valid question would be to ask if the way thatNTPC combines the results of the n-fold partitioning isoversimplistic and could be improved upon.
As was pre-viously stated, the training corpus for the error correc-tor in NTPC is the ?reconstituted training set?
gener-ated by combining the held-out validation sets after theyhave labeled with initial classifications by their respec-tive trained base models.
To investigate if NTPC couldbenefit from a more complex model, we employed vot-ing, a commonly-used technique in machine learning andnatural language processing.
As before, the training setwas partitioned and multiple base learners were trainedand evaluated on the multiple training and validation sets,respectively.
However, instead of recombining the vali-dation sets into a reconstituted training set, multiple er-ror corrector models were trained on the n partition sets.During the evaluation phase, all n error correctors wereevaluated on the evaluation set after it had been labeledby the base model, and they voted on the final output.Table 2 shows the results of using such an approachfor the bracketing + classification task on English.
Theempirical results clearly show that the more complex andtime-consuming voting model not only does not outper-fom NTPC, but in fact again degrades the performancefrom the base boosting-only model.3.5 Experiment SummaryIn our experiments, we set out to investigate whetherNTPC?s operating parameters were overly simple, andwhether more complex arrangements were necessary ordesirable.
However, empirical evidence points to the factthat, in this problem of error correction in high accuracyranges, at least, simple mechanisms will suffice to pro-duce good results?in fact, the more complex operationsend up degrading rather than improving accuracy.A valid question is to ask why methods suchas decision list learning (Rivest, 1987) as well astransformation-based learning benefit from these morecomplex mechanisms.
Though structurally similar toNTPC, these models operate in a very different environ-ment, where many initially poorly labeled examples areavailable to drive rule learning with.
Hence, it is pos-sibly advantageous to trade off some corrections withsome mistakes, provided that there is an overall posi-tive change in accuracy.
However, in an error-correctingsituation, most of the samples are already correctly la-beled, errors are few and far in between and the sparsedata problem is exacerbated.
In addition, the idea of er-ror correction implies that we should, at the very least,not do any worse than the original algorithm, and henceit makes sense to err on the side of caution and minimizeany errors created, rather than hoping that a later rule ap-plication will undo mistakes made by an earlier one.Finally, note that the same point applies to many othermodels where training criteria like minimum error rateare used, since such criteria are functions of the trade-off between correctly and incorrectly labeled examples,without zero error tolerance to compensate for the sparsedata problem.4 Previous Work4.1 Boosting and NERBoosting (Freund and Schapire, 1997) has been success-fully applied to several NLP problems.
In these NLPsystems boosting is typically used as the ultimate stagein a learned system.
For example, Shapire and Singer(2000) applied it to Text Categorization while Escud-ero et al(2000) used it to obtain good results on WordSense Disambiguation.
More closely relevant to the ex-periments described here in, two of the best-performingthree teams in the CoNLL-2002 Named Entity Recog-nition shared task evaluation used boosting as their basesystem (Carreras et al, 2002)(Wu et al, 2002).However, precedents for improving performance af-ter boosting are few.
At the CoNLL-2002 shared tasksession, Tjong Kim Sang (unpublished) described an ex-periment using voting to combine the NER outputs fromthe shared task participants which, predictably, producedbetter results than the individual systems.
A couple ofthe individual systems were boosting models, so in somesense this could be regarded as an example.Tsukamoto et al(2002) used piped AdaBoost.MHmodels for NER.
Their experimental results were some-what disappointing, but this could perhaps be attributableto various reasons including the feature engineering ornot using cross-validation sampling in the stacking.AppendixThe following examples show the top 10 rules learned for English and Spanish on the bracketing + classification task.
(Models M6 and M8)Englishne -2=ZZZ ne -1=ZZZ word:[1,3]=21 nonnevocab 0=inNonNeVocab nevocab 0=inNeVocab captype 0=firstword-firstupper => ne=I-ORGne 1=O ne 2=O word -1=ZZZ nonnevocab 0=inNonNeVocab nevocab 0=not-inNeVocab captype 0=firstword-firstupper => ne=Ocaptype 0=notfirstword-firstupper captype -1=firstword-firstupper captype 1=number nonnevocab 0=inNonNeVocab nevocab 0=inNeVocab ne 0=I-LOC => ne=I-ORGne -1=ZZZ ne 0=I-ORG word 1=, nonnevocab 0=not-inNonNeVocab nevocab 0=not-inNeVocab captype 0=allupper => ne=I-LOCne 0=I-PER word:[1,3]=0 nonnevocab 0=not-inNonNeVocab nevocab 0=not-inNeVocab captype 0=notfirstword-firstupper => ne=I-ORGne 0=I-ORG ne 1=O ne 2=O nonnevocab 0=inNonNeVocab nevocab 0=not-inNeVocab captype 0=alllower => ne=One 0=I-PER ne 1=I-ORG => ne=I-ORGne -1=ZZZ ne 0=I-PER word:[-3,-1]=ZZZ word:[1,3]=1 => ne=I-ORGne 0=I-ORG word:[-3,-1]=spd => ne=B-ORGne -1=I-ORG ne 0=I-PER word:[1,3]=1 => ne=I-ORGSpanishwcaptype 0=alllower ne -1=I-ORG ne 0=I-ORG ne 1=O => ne=OcaptypeLex -1=inLex captypeGaz -1=not-inGaz wcaptype -1=alllower ne -1=O ne 0=O captypeLex 0=not-inLex captypeGaz 0=not-inGaz wcaptype 0=noneed-firstupper => ne=I-ORGwcaptype 0=noneed-firstupper wcaptype -1=noneed-firstupper wcaptype 1=alllower captypeLex 0=not-inLex captypeGaz 0=not-inGaz ne 0=O => ne=I-ORGne 0=O word 0=efe => ne=I-ORGne -1=O ne 0=O word 1=Num word 2=.
captypeLex 0=not-inLex captypeGaz 0=not-inGaz wcaptype 0=allupper => ne=I-MISCpos -1=ART pos 0=NCF wcaptype 0=noneed-firstupper ne -1=O ne 0=O => ne=I-ORGwcaptype 0=alllower ne 0=I-PER ne 1=O ne 2=O => ne=One 0=O ne 1=I-MISC word 2=Num captypeLex 0=not-inLex captypeGaz 0=not-inGaz wcaptype 0=allupper => ne=I-MISCne 0=I-LOC word:[-3,-1]=universidad => ne=I-ORGne 1=O ne 2=O word 0=de captypeLex 0=not-inLex captypeGaz 0=inGaz wcaptype 0=alllower => ne=OThe AdaBoost.MH base model?s high accuracy setsa high bar for error correction.
Aside from brute-forceen masse voting of the sort at CoNLL-2002 describedabove, we do not know of any existing post-boostingmodels that improve rather than degrade accuracy.
Weaim to further improve performance, and propose usinga piped error corrector.4.2 Transformation-based LearningTransformation-based learning (Brill, 1995), or TBL, isone of the most successful rule-based machine learningalgorithms.
The central idea of TBL is to learn an or-dered list of rules, each of which evaluates on the re-sults of those preceding it.
An initial assignment is madebased on simple statistics, and then rules are greedilylearned to correct the mistakes, until no net improvementcan be made.Transformation-based learning has been used to tacklea wide range of NLP problems, ranging from part-of-speech tagging (Brill, 1995) to parsing (Brill, 1996) tosegmentation and message understanding (Day et al,1997).
In general, it achieves state-of-the-art perfor-mances and is fairly resistant to overtraining.5 ConclusionWe have investigated frequently raised questions aboutN-fold Templated Piped Correction (NTPC), a general-purpose, conservative error correcting model, which hasbeen shown to reliably deliver small but consistent gainson the accuracy of even high-performing base modelson high-dimensional NLP tasks, with little risk of acci-dental degradation.
Experimental evidence shows thatwhen error-correcting high-accuracy base models, sim-ple models and hypotheses are more beneficial than com-plex ones, while the more complex and powerful modelsare surprisingly unreliable or damaging in practice.ReferencesEric Brill.
Transformation-based error-driven learning and natural language pro-cessing: A case study in part of speech tagging.
Computational Linguistics,21(4):543?565, 1995.Eric Brill.
Recent Advances in Parsing Technology, chapter Learning to Parsewith Transformations.
Kluwer, 1996.Xavier Carreras, Llu?
?s Ma`rques, and Llu?
?s Padro?.
Named entity extraction usingadaboost.
In Dan Roth and Antal van den Bosch, editors, Proceedings ofCoNLL-2002, pages 167?170.
Taipei, Taiwan, 2002.David Day, John Aberdeen, Lynette Hirshman, Robyn Kozierok, Patricia Robin-son, and Marc Vilain.
Mixed initiative development of language processingsystems.
In Proceedings of the Fifth Conference on Applied Natural LanguageProcessing, Washington, D.C., March 1997.
Association of ComputationalLinguistics.Gerard Escudero, Lluis Marquez, and German Rigau.
Boosting applied to wordsense disambiguation.
In European Conference on Machine Learning, pages129?141, 2000.Yoram Freund and Robert E. Schapire.
A decision-theoretic generalization ofon-line learning and an application to boosting.
In Journal of Computer andSystem Sciences, 55(1), pages 119?139, 1997.Ronald L. Rivest.
Learning decision lists.
Machine Learning, 2(3):229?246,1987.Robert E. Schapire and Yoram Singer.
Boostexter: A boosting-based system fortext categorization.
Machine Learning, 2(3):135?168, 2000.Erik Tjong Kim Sang and Fien Meulder.
Introduction to the conll-2003 sharedtask: Language-independent named entity recognition.
In Walter Daelemansand Miles Osborne, editors, Proceedings of CoNLL-2003.
Edmonton, Canada,2003.Erik Tjong Kim Sang.
Introduction to the conll-2002 shared task: Language-independent named entity recognition.
In Dan Roth and Antal van den Bosch,editors, Proceedings of CoNLL-2002, pages 155?158.
Taipei, Taiwan, 2002.Koji Tsukamoto, Yutaka Mitsuishi, and Manabu Sassano.
Learning with multiplestacking for named entity recognition.
In Dan Roth and Antal van den Bosch,editors, Proceedings of CoNLL-2002, pages 191?194.
Taipei, Taiwan, 2002.Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, and Yongsheng Yang.Boosting for named entity recognition.
In Dan Roth and Antal van den Bosch,editors, Proceedings of CoNLL-2002, pages 195?198.
Taipei, Taiwan, 2002.Dekai Wu, Grace Ngai, and Marine Carpuat.
N-fold templated piped correc-tion.
In First International Joint Conference on Natural Language Processing(IJCNLP-2004), pages 632?637.
Hainan Island, China, March 2004.Dekai Wu, Grace Ngai, and Marine Carpuat.
Raising the bar: Stacked conserva-tive error correction beyond boosting.
In Fourth International Conference onLanguage Resources and Evaluation (LREC-2004).
Lisbon, May 2004.
