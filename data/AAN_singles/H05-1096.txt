Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 763?770, Vancouver, October 2005. c?2005 Association for Computational LinguisticsWord-Level Confidence Estimation for Machine Translationusing Phrase-Based Translation ModelsNicola Ueffing and Hermann NeyLehrstuhl fu?r Informatik VI, Computer Science DepartmentRWTH Aachen UniversityD-52056 Aachen, Germany{ueffing,ney}@informatik.rwth-aachen.deAbstractConfidence measures for machine transla-tion is a method for labeling each word inan automatically generated translation ascorrect or incorrect.
In this paper, we willpresent a new approach to confidence es-timation which has the advantage that itdoes not rely on system output such as N -best lists or word graphs as many otherconfidence measures do.
It is, thus, appli-cable to any kind of machine translationsystem.Experimental evaluation has been per-formed on translation of technical manu-als in three different language pairs.
Re-sults will be presented for different ma-chine translation systems to show that thenew approach is independent of the under-lying machine translation system whichgenerated the translations.
To the bestof our knowledge, the performance of thenew confidence measure is better than thatof any existing confidence measure.1 IntroductionThe work presented in this paper deals with con-fidence estimation for machine translation (MT).Since sentences produced by a machine translationsystem are often incorrect but may contain correctparts, a method for identifying those correct partsand finding possible errors is desirable.
For this pur-pose, each word in the generated target sentence isassigned a value expressing the confidence that it iscorrect.Confidence measures have been extensively stud-ied for speech recognition, but are not well knownin other areas.
Only recently have researchersstarted to investigate confidence measures for ma-chine translation (Blatz et al, 2004; Gandrabur andFoster, 2003; Quirk, 2004; Ueffing et al, 2003).We apply word confidence measures in MT as fol-lows: For a given translation generated by a machinetranslation system, we determine a confidence valuefor each word and compare it to a threshold.
Allwords whose confidence is above this threshold aretagged as correct and all others are tagged as incor-rect translations.
The threshold is optimized on adistinct development set beforehand.Possible applications for confidence measures in-clude?
post-editing, where words with low confidencecould be marked as potential errors,?
improving translation prediction accuracy intrans-type-style interactive machine transla-tion (Gandrabur and Foster, 2003; Ueffing andNey, 2005),?
combining output from different machinetranslation systems: hypotheses with low confi-dence can be discarded before selecting one ofthe system translations (Akiba et al, 2004), orthe word confidence scores can be used for gen-erating new hypotheses from the output of dif-ferent systems (Jayaraman and Lavie, 2005), orthe sentence confidence value can be employedfor re-ranking (Blatz et al, 2003).In this paper, we will present several approachesto word-level confidence estimation and develop anew phrase-based confidence measure which is in-dependent of the machine translation system which763generated the translation.
The paper is organized asfollows: In section 2, we will briefly review the sta-tistical approach to machine translation.
The phrase-based translation system, which serves as basis forthe new confidence measure, will be presented insection 2.2.
Section 3 will give an overview of re-lated work on confidence estimation for statisticalmachine translation (SMT).
In section 4, we willdescribe methods for confidence estimation whichmake use of SMT system output such as wordgraphs and N -best lists.
In section 5, we will presentthe new phrase-based confidence measure.
Section 6contains a short description of an IBM-1 based con-fidence measure to which we will compare the othermeasures.
Experimental evaluation and comparisonof the different confidence measures will be shownin section 7, and section 8 will conclude the paper.2 Statistical machine translation2.1 GeneralIn statistical machine translation, the translation ismodeled as a decision process: Given a source stringfJ1 = f1 .
.
.
fj .
.
.
fJ , we seek the target string eI1 =e1 .
.
.
ei .
.
.
eI with maximal posterior probability:e?I?1 = argmaxI,eI1{Pr(eI1 | fJ1 )}(1)= argmaxI,eI1{Pr(fJ1 | eI1) ?
Pr(eI1)}Through this decomposition of the probability, weobtain two knowledge sources: the translationmodel Pr(fJ1 | eI1) and the language model Pr(eI1).Both of them can be modeled independently of eachother.
The translation model is responsible for link-ing the source string fJ1 and the target string eI1,i.e.
it captures the semantics of the sentence.
Thetarget language model captures the well-formednessor the syntax in the target language.
Nowadays,most of the state-of-the-art SMT systems are basedon bilingual phrases (Bertoldi et al, 2004; Koehnet al, 2003; Och and Ney, 2004; Tillmann, 2003;Vogel et al, 2004; Zens and Ney, 2004).
Note thatthose phrases are sequences of words in the two lan-guages and not necessarily phrases in the linguisticsense.
A more detailed description of a phrase-basedapproach to statistical machine translation will begiven in section 2.2.2.2 Review of phrase-based translation systemFor the confidence measures which will be intro-duced in section 5, we use a state-of-the-art phrase-based approach as described in (Zens and Ney,2004).
The key elements of this translation approachare bilingual phrases, i.e.
pairs of source and targetlanguage phrases where a phrase is simply a con-tiguous sequence of words.
These bilingual phrasesare extracted from a word-aligned bilingual trainingcorpus.We will present the equations for a mono-tone search here in order to keep the equa-tions simple.
Let (jK0 , iK0 ) be a segmentation ofthe source sentence into phrases, with the cor-responding (bilingual) phrase pairs (f?k, e?k) =(f jkjk?1+1, eikik?1+1), k = 1, .
.
.
,K. The phrase-based approach to SMT is then expressed by the fol-lowing equation:e?I?1 = argmaxjK0 ,iK0 ,I,eI1{ I?i=1[c1 ?
p(ei | ei?1i?2)?1](2)?K?k=1[c2 ?
p(f?k | e?k)?2 ?
p(e?k | f?k)?3?jk?j=jk?1+1p(fj | e?k)?4 ?ik?i=ik?1+1p(ei | f?k)?5]},where p(f?k | e?k) and p(e?k | f?k) are the phrase lexiconmodels in both translation directions.
The phrasetranslation probabilities are computed as a log-linearinterpolation of the relative frequencies and theIBM-1 probability.
The single word based lexiconmodels are denoted as p(fj | e?k) and p(ei | f?k), re-spectively.
p(fj | e?k) is defined as the IBM-1 modelprobability of fj over the whole phrase e?k, andp(ei | f?k) is the inverse model, respectively.c1 is the so-called word penalty, and c2 is thephrase penalty, assigning constant costs to each tar-get language word/phrase.
The language modelis a trigram model with modified Kneser-Ney dis-counting and interpolation (Stolcke, 2002).
Thesearch determines the target sentence and segmen-tation which maximize the objective function.As equation 2 shows, the sub-models are com-bined via weighted log-linear interpolation.
Themodel scaling factors ?1, .
.
.
, ?5 and the word andphrase penalties are optimized with respect to someevaluation criterion (Och, 2003), e.g.
BLEU score.7643 Confidence measures for SMT3.1 Related workIn this paper, we will present a new approach toword-level confidence estimation which makes ex-plicit use of a phrase-based translation model.
Mostof the word-level confidence measures which havebeen presented in the literature so far are eitherbased on relatively simple translation models suchas IBM-1 (Blatz et al, 2003) or make use of infor-mation provided by the SMT system such as N -bestlists or word graphs (Blatz et al, 2003; Gandraburand Foster, 2003; Ueffing et al, 2003).
In contrastto this, our method is based on a state-of-the-artstatistical machine translation model, but neverthe-less is independent of the machine translation sys-tem which generates the translation hypotheses.The word-level confidence measures whichshowed the best performance in comparative experi-ments (Blatz et al, 2003) are word posterior prob-abilities and the IBM-1 based measure.
Our newconfidence measure will be compared to those ap-proaches in section 7.3.3.2 Word posterior probabilitiesThe confidence of a target word can be expressed byits posterior probability, i.e.
the probability of theword to occur in the target sentence, given the sourcesentence.
Consider a target word e occurring in thesentence in position i1.
The posterior probability ofthis event can be determined by summing over allpossible target sentences eI1 containing the word e inposition i:pi(e, fJ1 ) =?I,eI1: ei=ep(eI1, fJ1 ) (3)This value has to be normalized in order to ob-tain a probability distribution over all possible targetwords:pi(e | fJ1 ) =pi(e, fJ1 )?e?pi(e?, fJ1 )(4)1This is a rather strict assumption, because the position of aword in the target sentence can differ largely due to reorderingsin the translation process.
We present this variant here to keepthe notation simple.
Improved methods will be shown in thefollowing sections.4 System based confidence measuresIn this section, we will present confidence measureswhich are based on N -best lists or word graphs gen-erated by the SMT system.
Those are representa-tions of the space of the most likely translations ofthe source sentence.The summation given in equation 3 is performedover all sentences which are contained in the N -bestlist or word graph.
For a more detailed description,see (Ueffing et al, 2003).4.1 Word graph based approachThe word posterior probability pi(e | fJ1 ) can becalculated over a word graph using the forward-backward algorithm.Let n?, n be nodes in a word graph, and (n?, n) thedirected edge connecting them.
The edge is anno-tated with a target word which we denote by e(n?, n)and the probability which this word contributes tothe overall sentence probability, denoted by p(n?, n).The forward probability ?i(n?, n) of an edge isthe probability of reaching this edge from the sourceof the graph, where the word e(n?, n) is the i-th wordon the path.
It can be obtained by summing the prob-abilities of all incoming paths of length i?
1, whichallows for recursive calculation.
This leads to thefollowing formula:?i(n?, n) = p(n?, n) ??n???i?1(n?
?, n?)
.The backward probability expresses the probabil-ity of completing a sentence from the current edge,i.e.
of reaching the sink of the graph.
It can be de-termined recursively in descending order of i as fol-lows:?i(n?, n) = p(n?, n) ??n?
?i+1(n, n?)
.Using the forward-backward algorithm, the wordposterior probability of word e in position i is de-termined by combining the forward and backwardprobabilities of all edges which are annotated withe.
This yieldspi(e, fJ1 ) =?
(n?,n) : e(n?,n)=e?i(n?, n) ?
?i(n?, n)p(n?, n) .
(5)Note that (for computational reasons) the termp(n?, n) is included both in the forward and in the765backward probability so that we have to divide theproduct by this term.To obtain a posterior probability, a normalization,as shown in equation 4, has to be performed.
Thenormalization term ?
:= ?e?pi(e?, fJ1 ) correspondsto the probability mass contained in the word graphand can be calculated by summing the backwardprobabilities of all outgoing edges leaving the sources of the graph:?
=?
(s,n)?1(s, n) .As stated above, the position of word e in the tar-get sentence can vary due to reorderings in the trans-lation process.
Therefore, we would like to relaxthe condition that e has to occur exactly in positioni.
This can be achieved by introducing a windowof size t over the neighboring target positions andcomputing the sum of the word posterior probabili-ties over all positions i ?
t, .
.
.
, i, .
.
.
, i + t. In ourexperiments we found that a window over ?3 posi-tions yields the best performance.4.2 N -best list based approachN -best lists are an alternative representation of thespace of translation hypotheses.
They have the ad-vantage that the Levenshtein alignment between ahypothesis and all sentences contained in the list canbe performed easily.
This makes it possible to con-sider not only target sentences, which contain theword e exactly in a position i (as given in equa-tion 3), but to allow for some variation.Let L(eI1, e?I?1) be the Levenshtein alignment be-tween sentences eI1 and e?I?1.
Then, Li(eI1, e?I?1) denotesthe Levenshtein alignment of word ei, i.e.
the wordin sentence e?I?1 which ei is Levenshtein-aligned to.The word posterior probability is then calculatedby summing over all target sentences containingword e in a position which is Levenshtein-alignedto i:pi(e|fJ1 , I, eI1) =pi(e, fJ1 , I, eI1)?e?pi(e?, fJ1 , I, eI1),wherepi(e, fJ1 , I, eI1) =?I?,e?I?1: Li(eI1,e?I?1)=ep(e?I?1, fJ1 ) .
(6)The confidence of word e then depends on the sourcesentence fJ1 as well as the target sentence eI1, be-cause the whole target sentence is relevant for theLevenshtein alignment.5 Phrase-based confidence measuresIn contrast to the approaches presented in section 4,the phrase-based confidence measures do not not usethe context information at the sentence level, butonly at the phrase level.
We want to determine asort of marginal probability Q(e, fJ1 ).
Therefore,we extract all source phrases f j+sj which occur inthe given source sentence.
For such source phrases,we find the possible translations ei+ti in the bilin-gual phrase lexicon.
The confidence of target worde is then calculated by summing over all phrase pairs(f j+sj , ei+ti ) where the target part ei+ti contains theword e.Let p(ei+ti ) be the language model score of thetarget phrase together with the word penalty c1, i.e.p(ei+ti ) =i+t?i?=ic1 ?
p(ei?
| ei??1i?
?2)?1 .Analogously, define p(f j+sj , ei+ti ) as the score of thephrase pair which consists of the phrase penalty andthe phrase and word lexicon model scores (cf.
sec-tion 2.2).
Following equation 2, the (unnormalized)confidence is then determined as:Q(e, fJ1 ) =J?j=1min{smax,J?j}?s=0(7)?ei+ti : e ?
ei+tip(ei+ti ) ?
p(f j+sj , ei+ti ) ,where s ?
smax and t are source and target phraselengths, smax being the maximal source phraselength.In equation 7, the language model only deter-mines the probability of the words within the tar-get part of the phrase, and not across the phraseboundaries, because we consider only the single tar-get phrases without context.
Therefore, we assumedthat the language model would not have much influ-ence on the confidence estimation and also investi-gated a model without a language model.
The sameholds for word and phrase penalty: In the translationprocess they are useful for adjusting the length of the766generated target hypothesis and for assigning moreweight to longer phrases.
Since this does not makemuch sense in our setting, we also investigated con-fidence estimation without word and phrase penalty.Note that the value calculated in equation 7 isnot normalized.
In order to obtain a word posteriorprobability, we divide this value by the sum over the(unnormalized) confidence of all target words:pphr(e | fJ1 ) =Q(e, fJ1 )?e?Q(e?, fJ1 ).
(8)Unlike the word posterior probabilities presentedin the previous section, this value is completely in-dependent of the target sentence position in whichthe word e occurs.As stated in section 2.2, the scaling factors of thedifferent sub-models and the penalties in the trans-lation system are optimized with respect to someevaluation criterion.
But since the values which areoptimal for translation are not necessarily optimalfor confidence estimation, we perform optimizationhere as well: We train the probability models on thetraining corpus, estimate the word confidences onthe development corpus, and optimize the scalingfactors with respect to the classification error ratedescribed in section 7.2.
The optimization is per-formed with the Downhill Simplex algorithm (Presset al, 2002).6 IBM-1 based approachAnother type of confidence measure which does notrely on system output and is thus applicable to anykind of machine translation system is the IBM-1model based confidence measure which was intro-duced in (Blatz et al, 2003).
We modified this con-fidence measure because we found that the averagelexicon probability used there is dominated by themaximum.
Therefore, we determine the maximaltranslation probability of the target word e over thesource sentence words:pIBM?1(e|fJ1 ) = maxj=0,...,J p(e|fj) , (9)where f0 is the ?empty?
source word (Brown et al,1993).
The probabilities p(e|fj) are word-based lex-icon probabilities.Investigations on the use of the IBM-1 modelfor word confidence measures showed promising re-sults (Blatz et al, 2003; Blatz et al, 2004).
Thus,we apply this method here in order to compare it tothe other types of confidence measures.7 Experiments7.1 Experimental settingThe experiments were performed on three differentlanguage pairs.
All corpora were compiled in the EUproject TransType2; they consist of technical manu-als.
The corpus statistics are given in table 1.
TheSMT systems that the confidence estimation wasperformed for were trained on these corpora.
Thesame holds for the probability models that were usedto estimate the word confidences.We used several (S)MT systems for testing theconfidence measures.
A detailed analysis will begiven for two of them; the so-called alignment tem-plate system (Och and Ney, 2004), (denoted as ATin the tables) and the phrase-based translation sys-tem described in section 2.2 (denoted as PBT in thetables).
They are both state-of-the-art SMT systems.We produced single best translations, word graphsand N -best lists on all three language pairs usingthese systems.
The translation quality in terms ofWER, PER (position independent word error rate),BLEU and NIST score is given in tables 2 and 3.We see that the best results are obtained on Spanishto English translation, followed by French to Englishand German to English.Two more translation systems were used for com-parative experiments: One is a statistical MT systemwhich is based on a finite state architecture (FSA).For a description of this system, see (Kanthak et al,2005).
Additionally, we used translations generatedby Systran2.
Table 3 presents the translation errorrates and scores for all systems on the German ?English test corpus.
These hypotheses were usedto investigate whether the phrase-based confidencemeasures perform well independently of the transla-tion system.All three SMT systems (AT, PBT and FSA) showvery similar performance on the German ?
Englishtest corpus.
The fact that Systran generates transla-tions of much lower quality is due to the fact that thetechnical manuals are very specific in terminology,and the SMT systems have been trained on similarcorpora.2http://babelfish.altavista.com/tr, June 2005767Table 1: Statistics of the training, development and test corpora.French English Spanish English German EnglishTRAIN Sentences 53 046 55 761 49 376Running Words 680 796 628 329 752 606 665 399 537 464 589 531Vocabulary 15 632 13 816 11 050 7 956 23 845 13 223DEV Sentences 994 1 012 964Running Words 11 674 10 903 15 957 14 278 10 462 10 642OOVs 184 141 54 27 147 29TEST Sentences 984 1 125 996Running Words 11 709 11 177 10 106 8 370 11 704 12 298OOVs 204 201 69 49 485 141Table 2: Translation quality of systems AT and PBTon the test corpora described in table 1.AT PBTS?E F?E S?E F?EWER[%] 29.6 54.8 26.1 54.9PER[%] 20.1 43.7 17.5 43.4BLEU[%] 63.4 31.5 66.9 31.3NIST 8.80 6.64 8.98 6.62Table 3: Translation quality of all MT systems onthe German ?
English test corpus.AT PBT FSA SystranWER[%] 62.7 61.6 63.2 79.2PER[%] 49.8 49.6 50.4 66.4BLEU[%] 26.6 25.7 26.5 12.0NIST 5.92 5.72 5.79 4.09To determine the true class of each word in a gen-erated translation hypothesis, we use the word er-ror rate (WER).
That is, a target word is consideredcorrect if it is aligned to itself in the Levenshteinalignment between hypothesis and reference trans-lation(s).
We also investigated PER based classifi-cation, but since the tendencies of the results weresimilar, we omit them here.7.2 Evaluation metricsAfter computing the confidence measure, each gen-erated word is tagged as either correct or false, de-pending on whether its confidence exceeds the tag-ging threshold that has been optimized on the devel-opment set beforehand.
The performance of the con-fidence measure is evaluated using the ClassificationError Rate (CER).
This is defined as the number ofincorrect tags divided by the total number of gener-ated words in the translated sentence.
The baselineCER is determined by assigning the most frequentclass to all translations.
In the case that the most fre-quent class is ?correct?
(meaning at least half of thewords in the generated translation are correct w.r.t.to WER), this is the number of substitutions and in-sertions, divided by the number of generated words.The CER strongly depends on the tagging threshold.Therefore, the tagging threshold is adjusted before-hand (to minimize CER) on a development corpusdistinct to the test set.7.3 Experimental resultsTable 4 shows the performance of all different con-fidence measures on the hypotheses generated bythe alignment template system and the phrase-basedsystem.
For the baseline CER, we determined the90%- and 99%-confidence intervals using the boot-strap estimation method described in (Bisani andNey, 2004)3.
We see that, in all settings but one, theword graph and the N -best list based method out-perform the IBM-1 based confidence measure.
OnFrench ?
English, the improvement over the base-line is significant at the 1%-level for these methods,whereas on Spanish ?
English this is only the caseat 10%.
The performance of the N -best list basedapproach is better than that of the word graph based3The tool is freely available from http://www-i6.informatik.rwth-aachen.de/web/Software/index.html768confidence measures for the alignment template sys-tem.
This is probably due to the fact that the formercan take the Levenshtein alignment into account andthus estimate the word confidence more reliably.The phrase-based confidence measures show aperformance which is clearly better than that of theother methods.
We obtain a relative improvement ofup to 7.8% over the best existing method on theselanguage pairs.
The improvement over the baselineis significant even at the 1%-level in all cases.When analyzing the impact of the different sub-models in the phrase-based approach, we found thatthe language model does not have much impact onthe confidence estimation.
There are only slightvariations in the CER if the model is omitted.
Theword and phrase penalty on the other hand seem tobe important (with one exception in the first setting).The evaluation of the system-independent confi-dence measures (i.e.
those based on IBM-1 andthe new phrase-based method we presented) for fourdifferent translation systems is shown in table 5.
Wesee that, for all of them, the phrase-based approachoutperforms the IBM-1 based method significantly.The largest gain in terms of CER is achieved for theSystran translations: 23.8% relative over the IBM-1based measure.8 Conclusion and outlookWe presented a new approach to word-level con-fidence estimation for machine translation whichmakes use of bilingual phrases.
By using modelsfrom a state-of-the-art phrase-based statistical ma-chine translation system, the word confidences areestimated only on the basis of single best systemoutput.
Unlike other confidence measures, this doesnot rely on information from the machine translationsystem which generated the translation.Experimental evaluation on three different lan-guage pairs and on output from structurally differ-ent translation systems showed that the new confi-dence measures perform better than existing confi-dence measures in all cases.
The application on out-put from different MT systems yielded a significantreduction of the error rate over the existing mea-sures.
This proves that the method is well-suited forword confidence estimation on statistical as well asnon-statistical MT systems.The task investigated in this work was a text trans-lation task in the domain of technical manuals.
Weare currently investigating the use of word-level con-fidence measures on data from the European parlia-ment.
It will be interesting to see whether a similarperformance can be achieved on this large vocabu-lary speech translation task.AcknowledgementThis work was partly funded by the European Unionunder the RTD project TransType2 (IST?2001?32091), and under the integrated project TC-STAR?
Technology and Corpora for Speech to SpeechTranslation (IST-2002-FP6-506738).ReferencesY.
Akiba, E. Sumita, H. Nakaiwa, S. Yamamoto, andH.
G. Okuno.
2004.
Using a mixture of n-best listsfrom multiple MT systems in rank-sum-based con-fidence measure for MT outputs.
In Proc.
CoLing,pages 322?328, August.N.
Bertoldi, R. Cattoni, M. Cettolo, and M. Federico.2004.
The ITC-irst statistical machine translation sys-tem for IWSLT-2004.
In Proc.
IWSLT, pages 51?58,Kyoto, Japan, September.M.
Bisani and H. Ney.
2004.
Bootstrap estimatesfor confidence intervals in asr performance evalua-tionx.
In IEEE International Conference on Acoustics,Speech, and Signal Processing, pages 409?412, Mon-treal, Canada, May.J.
Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,C.
Goutte, A. Kulesza, A. Sanchis, and N. Ueffing.2003.
Confidence estimation for machine transla-tion.
Final report, JHU/CLSP Summer Workshop.http://www.clsp.jhu.edu/ws2003/groups/estimate/.J.
Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte,A.
Kulesza, A. Sanchis, and N. Ueffing.
2004.Confidence estimation for machine translation.
InProc.
CoLing, pages 315?321, Geneva, Switzerland,August.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
Computa-tional Linguistics, 19(2):263?311, June.S.
Gandrabur and G. Foster.
2003.
Confidence estima-tion for text prediction.
In Proc.
CoNLL, pages 95?102, Edmonton, Canada, May.S.
Jayaraman and A. Lavie.
2005.
Multi-engine ma-chine translation guided by explicit word matching.769Table 4: CER for different confidence measures, reference based on WER.
Hypotheses from the alignmenttemplate system and the phrase-based system.
The best value is printed in bold.alignment template system phrase-based systemModel S ?
E F ?
E S ?
E F ?
EBaseline 20.8 42.5 19.2 42.799%-confidence interval [18.8,22.7] [40.1,44.7] [17.2,21.2] [40.4,45.0]90%-confidence interval [19.6,22.1] [40.9,43.9] [17.9,20.5] [41.2,44.2]Word graphs from the system (eq.
5) 20.1 32.9 17.9 30.5N -best lists from the system (eq.
6) 19.8 31.9 17.9 30.9phrase-based (eq.
8) 17.5 30.2 16.5 30.0without language model 17.4 30.3 16.5 30.3without word and phrase penalty 17.5 30.6 16.9 30.5IBM-1 (eq.
9) 20.0 34.1 18.3 35.1Table 5: CER for different confidence measures on the German?
English test set, reference based on WER.Hypotheses from different MT systems.Model AT PBT FSA SystranBaseline 49.2 48.4 46.6 37.499%-confidence interval [48.6,53.1] [45.9,50.7] [44.2,49.0] [36.0,38.9]phrase-based (eq.
8) 27.6 26.4 30.2 24.3IBM-1 (eq.
9) 32.8 32.8 37.0 31.9In Proc.
EAMT, pages 143?152, Budapest, Hungary,May.S.
Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney.2005.
Novel reordering approaches in phrase-basedstatistical machine translation.
In ACL 2005 ?Proc.
Workshop on Building and Using Parallel Texts:Data-Driven Machine Translation and Beyond, pages167?174, Ann Arbor, Michigan, June.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
HLT-NAACL, pages127?133, Edmonton, Canada, May/June.F.
J. Och and H. Ney.
2004.
The alignment templateapproach to statistical machine translation.
Computa-tional Linguistics, 30(4):417?449, December.F.
J. Och.
2003.
Minimum error rate training in statisticalmachine translation.
In Proc.
ACL, pages 160?167,Sapporo, Japan, July.W.
H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P.Flannery.
2002.
Numerical Recipes in C++.
Cam-bridge University Press, Cambridge, UK.C.
Quirk.
2004.
Training a sentence-level machine trans-lation confidence metric.
In Proc.
LREC, pages 825?828, Lisbon, Portugal, May.A.
Stolcke.
2002.
SRILM ?
an extensible language mod-eling toolkit.
In Proc.
ICSLP, volume 2, pages 901?904, Denver.C.
Tillmann.
2003.
A projection extension algorithmfor statistical machine translation.
In Proc.
EMNLP,pages 1?8, Sapporo, Japan, July.N.
Ueffing and H. Ney.
2005.
Application of word-levelconfidence measures in interactive statistical machinetranslation.
In Proc.
EAMT, pages 262?270, Budapest,Hungary, May.N.
Ueffing, K. Macherey, and H. Ney.
2003.
Confi-dence Measures for Statistical Machine Translation.In Proc.
MT Summit IX, pages 394?401, New Orleans,LA, September.S.
Vogel, S. Hewavitharana, M. Kolss, and A. Waibel.2004.
The ISL statistical translation system for spokenlanguage translation.
In Proc.
IWSLT, pages 65?72,Kyoto, Japan, September.R.
Zens and H. Ney.
2004.
Improvements in phrase-based statistical machine translation.
In Proc.
HLT-NAACL, pages 257?264, Boston, MA, May.770
