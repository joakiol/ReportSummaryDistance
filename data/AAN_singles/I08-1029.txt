Automatic Prosodic Labeling with Conditional Random Fields and RichAcoustic FeaturesGina-Anne LevowUniversity of ChicagoDepartment of Computer Science1100 E. 58th St.Chicago, IL 60637 USAlevow@cs.uchicago.eduAbstractMany acoustic approaches to prosodic la-beling in English have employed only lo-cal classifiers, although text-based classifi-cation has employed some sequential mod-els.
In this paper we employ linear chain andfactorial conditional random fields (CRFs)in conjunction with rich, contextually-basedprosodic features, to exploit sequential de-pendencies and to facilitate integration withlexical features.
Integration of lexical andprosodic features improves pitch accent pre-diction over either feature set alne, and forlower accuracy feature sets, factorial CRFmodels can improve over linear chain basedprediction of pitch accent.1 IntroductionProsody plays a crucial role in language understand-ing.
In addition to the well-known effects in tonelanguages such as Chinese, prosody in English alsoplays a significant role, where pitch accents canindicate given/new information status, and bound-ary tones can distinguish statements from yes-noquestions.
However, recognition of such prosodicfeatures poses significant challenges due to differ-ences in surface realization from the underlyingform.
In particular, context plays a significant rolein prosodic realization.
Contextual effects due ar-ticulatory constraints such maximum speed of pitchchange (Xu and Sun, 2002) from neighboring sylla-bles and accents can yield co-articulatory effects atthe intonational level, analogous to those at the seg-mental level.
Recent phonetic research (Xu, 1999;Sun, 2002; Shen, 1990) has demonstrated the im-portance of coarticulation for tone and pitch accentrecognition.
In addition context affects interpreta-tion of prosodic events; an accent is viewed as highor low relative to the speaker?s pitch range and alsorelative to adjacent speech.Some recent acoustically focused approaches(Sun, 2002; Levow, 2005) to tone and pitch accentrecognition have begun to model and exploit thesecontextual effects on production.
Following the Par-allel Encoding and Target Approximation (PENTA)(Xu, 2004), this work assumes that the prosodic tar-get is exponentially approached during the course ofsyllable production, and thus the target is best ap-proximated in the later portion of the syllable.
Othercontextual evidence such as relative pitch height orband energy between syllables has also been em-ployed (Levow, 2005; Rosenberg and Hirschberg,2006).
Interestingly, although earlier techniques(Ross and Ostendorf, 1994; Dusterhoff et al, 1999)employed Hidden Markov Models, they did not ex-plicitly model these coarticulatory effects, and re-cent approaches have primarily employed local clas-sifiers, such as decision trees (Sun, 2002; Rosenbergand Hirschberg, 2006) or Support Vector Machines(Levow, 2005).Another body of work on pitch accent recog-nition has focused on exploitation of lexical andsyntactic information to predict ToBI labels, forexample for speech synthesis.
These approachesexplored a range of machine learning techniquesfrom local classifiers such as decision trees (Sun,2002) and RIPPER (Pan andMcKeown, 1998) to se-quence models such as Conditional Random Fields217(CRFs)(Gregory and Altun, 2004) more recently.The systems often included features that captured lo-cal or longer range context, such as n-gram probabil-ities, neighboring words, or even indicators of priormention.
(Chen et al, 2004; Rangarajan Sridhar etal., 2007) explored the integration of based prosodicand lexico-syntactic evidence in GMM-based andmaximum entropy models respectively.Here we explore the use of contextual acous-tic and lexical models within a sequence learningframework.
We analyze the interaction of differ-ent feature types on prediction of prosodic labels us-ing linear-chain CRFs.
We demonstrate improvedrecognition by integration of textual and acousticcues, well-supported by the sequence model.
Finallywe consider the joint prediction of multiple prosodiclabel types, finding improvement for joint modelingin the case of feature sets with lower initial perfor-mance.We begin by describing the ToBI annotation taskand our experimental data.
We then discuss thechoice of conditional random fields and the use oflinear chain and factorial models.
Section 4 de-scribes the contextual acoustic model and text-basedfeatures.
Section 5 presents the experimental struc-ture and results.
We conclude with a brief discussionof future work.2 DataWe employ a subset of the Boston Radio News Cor-pus (Ostendorf et al, 1995), employing data fromspeakers f1a, f2b, m1b, and m2b, for experimen-tal consistency with (Chen et al, 2004; Rangara-jan Sridhar et al, 2007).
The corpus includes pitchaccent, phrase and boundary tone annotation in theToBI framework (Silverman et al, 1992) alignedwith manual transcription and manual and automaticsyllabification of the materials.
Each word wasalso manually part-of-speech tagged.
The data com-prises over forty thousand syllables, with speakerf2b accounting for just over half the data.
Fol-lowing earlier research (Ostendorf and Ross, 1997;Sun, 2002), we collapse the ToBI pitch accent labelsto four classes: unaccented, high, low, and down-stepped high for experimentation, removing distinc-tions related to bitonal accents.
We also consider thebinary case of distinguishing accented from unac-cented syllables, (Gregory and Altun, 2004; Rosen-berg and Hirschberg, 2006; Ananthakrishnan andNarayanan, 2006).
For phrase accents and bound-ary tones, we consider only the binary distinctionbetween phrase accent/no phrase accent and bound-ary tone/no boundary tone.All experiments evaluate automatic prosodic la-beling at the syllable level.3 Modeling with Linear-Chain andFactorial CRFsMost prior acoustically based approaches toprosodic labeling have used local classifiers.
How-ever, on phonological grounds, we expect that cer-tain label sequences will be much more probablethan others.
For example, sequences of multiplehigh accents are relatively uncommon in contrast tothe case of an unaccented syllable preceding an ac-cented one.
This characteristic argues for a modelwhich encodes and exploits inter-label dependen-cies.
Furthermore, under the ToBI labeling guide-lines, the presence of a boundary tone dictates theco-occurrence of a phrase accent label.
To capturethese relations between labels of different types, wealso consider factorial models.Conditional Random Fields (Lafferty et al, 2001)are a class of graphical models which are undirectedand conditionally trained.
While they can repre-sent long term dependencies, most applications haveemployed first-order linear chains for language andspeech processing tasks including POS tagging, sen-tence boundary detection (Liu et al, 2005), andeven text-oriented pitch accent prediction(Gregoryand Altun, 2004).
The models capture sequentiallabel-label relations, but unlike HMMs, the condi-tionally trained model can more tractably supportlarger text-based feature sets.
Factorial CRFs (Sut-ton, 2006; McCallum et al, 2003) augment the lin-ear sequence model with additional cotemporal la-bels, so that multiple (factors) labels are predictedat each time step and dependencies between themcan be modeled.
Examples of linear-chain and fac-torial CRFs appear in Figure 1.
In the linear chainexample, the fi items correspond to the features andthe yi to labels to be predicted, for example prosodicand text features and pitch accent labels respectively.The vertical lines correspond to the dependencies218y1 y2 y3f1 f2 f3z1 z2 z3y1 y2 y3x1 x2 x3f1 f2 f3Figure 1: Linear-chain CRF (top) and Two-levelFactorial CRF (bottom).between the features and labels; the horizontal linesindicate the dependencies between the labels in se-quence.
In the factorial CRF example, the fi againrepresent the features, while the xi, yi, and zi repre-sent the boundary tone, phrase accent, and pitch ac-cent labels that are being predicted.
The horizontalarcs again model the sequential bigram label-labeldependencies between labels of the same class; thevertical arcs model the dependencies between boththe features and labels, and bigram dependencies be-tween the labels of each of the different pairs of fac-tors.
Thus, we jointly predict pitch accent, phraseaccent, and boundary tone and, the prediction ofeach label depends on the features, the other labelspredicted for the same syllable, and the sequentiallabel of the same class.
So, pitch accent predictiondepends on the features, pitch accent predicted forthe neighboring syllable, and phrase and boundarytone predictions for the current syllable.We employ the Graphical Models for Mallet(GRMM) implementation (Sutton, 2006), adaptedto also support the real-valued acoustic features re-quired for these experiments; in some additionalcontrastive experiments on zero order models, wealso employ the Mallet implementation (McCallum,2002).
We employ both linear chain and three-levelfactorial CRFs, as above, to perform prosodic label-ing.4 Feature RepresentationWe exploit both lexical and prosodic features forprosodic labeling of broadcast news speech.
In par-ticular, in contrast to (Gregory and Altun, 2004), weemploy a rich acoustic feature set, designed to cap-ture and compensate for coarticulatory influences onaccent realization, in addition to word-based fea-tures.4.1 Prosodic FeaturesUsing Praat?s (Boersma, 2001) ?To pitch?
and ?Tointensity?
functions and the phoneme, syllable, andword alignments provided in the corpus, we extractacoustic features for the region of interest.
This re-gion corresponds to the syllable nucleus in English.For all pitch and intensity features, we compute per-speaker z-score normalized log-scaled values.Recent phonetic research (Xu, 1997; Shih andKochanski, 2000) has identified significant effectsof carryover coarticulation from preceding adjacentsyllable tones.
To minimize these effects consistentwith the pitch target approximation model (Xu et al,1999), we compute slope features based on the sec-ond half of this region, where this model predictsthat the underlying pitch height and slope targets ofthe syllable will be most accurately approached.For each syllable, we compute the following localfeatures:?
pitch values at five points evenly spaced acrossthe syllable nucleus,?
mean and maximum pitch values,?
slope based on a linear fit to the pitch contourin the second half of the region, and?
mean and maximum intensity.We consider two types of contextualized featuresas well, to model and compensate for coarticula-tory effects from neighboring syllables.
The first setof features, referred to as ?extended features?, in-cludes the maximum and mean pitch from adjacent219syllables as well as the nearest pitch points from theadjacent syllables.
These features extend the mod-eled tone beyond the strict bounds of the syllablesegmentation.
A second set of contextual features,termed ?difference features?, captures the change infeature values between the current and adjacent syl-lables.
The resulting feature set includes:?
mean, maximum, and last two pitch valuesfrom preceding syllable,?
mean, maximum, and first value from follow-ing syllable, and?
differences in pitch mean, pitch maximum,pitch of midpoint, pitch slope, intensity mean,and intensity maximum between the currentsyllable and the preceding syllable, and be-tween the current syllable and the followingsyllable.Finally, we also employ some positional and du-rational features.
Many prosodic phenomena are af-fected by phrase or sentence position; for example,both pitch and intensity tend to decrease across anutterance, and pitch accent realization may also beaffected by cooccurring phrase accents or bound-ary tones.
As syllable duration typically increasesunder both accenting and phrase-final lengthening,this information can be useful in prosodic labeling.Finally, pause information is also associated withprosodic phrasing.
Thus, we include following fea-tures:?
two binary features indicating initial and fi-nal in a pseudo-phrase, defined as a silence-delimited interval,?
duration of syllable nucleus, and?
durations of pause preceding and following thesyllable.In prior experiments using support vector ma-chines (Levow, 2005), variants of this representa-tion achieved competitive recognition levels for bothtone and pitch accent recognition.4.2 Text-based FeaturesWe employ text-based models similar to those em-ployed by (Sun, 2002; Rangarajan Sridhar et al,2007).
For each syllable, we capture the followingmanually annotated features:?
The phonetic form of the current syllable, theprevious two syllables, and the following twosyllables,?
binary values indicating whether each of thecurrent, previous, and following syllables arelexically stressed,?
integer values indicating position in a word ofthe current, previous, and following syllables,?
the current word, the two previous words, andthe two following words, and?
the POS of the current word, of the two previ-ous words, and of the two following words.These features capture information about the currentsyllable and its lexico-syntactic context, that havebeen employed effectively in prosodic labeling ofpitch accent, phrase accent, and boundary tone.5 ExperimentsWe explore a range of issues in the experimentsreported below.
We hope to assess the impactof feature set and acoustic and text-based fea-ture integration in the Conditional Random Fieldmodels.
We compare their individual effective-ness as well as the effect of combined featuresets on labeling.
In particular, we consider boththe binary accented/unaccented assignment task forpitch accent and the four way - high/downsteppedhigh/low/unaccented - contrast to compare effective-ness in problems of different difficulty.
We furtherconsider the effect of sequence and factorial model-ing on pitch accent recognition.
All experiments areconducted using a leave-one-out evaluation proce-dure following (Chen et al, 2004), training on allbut one speaker and then testing on that held-outspeaker, reporting the average across the tests onheld-out data.
Because speaker f2b contributes sucha large portion of the data, that speaker is never leftout.On this split, the best word-based accuracy incor-porating both prosodic and lexico-syntactic infor-mation in a maximum entropy framework is 86.0%for binary pitch accent prediction and 93.1% for220recognition of boundary status (Rangarajan Srid-har et al, 2007).
For syllable-level recognition onthis dataset, results for speaker-independent modelsreach slightly over 80% for binary pitch accent de-tection and 88% for boundary detection.
Speaker de-pendent models have achieved very high accuracy;over 87% on speaker f2b was reported by (Sun,2002) for the four-class task.5.1 Explicit Prosodic Context Features andSequence ModelsWe first assess the role of contextual prosodic fea-tures for pitch accent recognition and their inter-action with sequence models.
To minimize inter-action effects, we concentrate on recognition withprosodic features alone on the challenging four-waypitch accent problem.
As described above, we aug-mented the local syllable-based prosodic featureswith contextual features associated with the preced-ing and following syllables.
We ask whether the useof contextual features improves recognition, and,if so, which type of context, preceding or follow-ing, has the greatest impact.
We also ask whetherthe CRF models provide further improvements orcan partially or fully compensate for the lack ofexplicit context features.
To evaluate this impact,we compute four-way pitch accent recognition ac-curacy with no context features, after adding preced-ing context, after adding following context, and withboth.
We also contrast zero order and first order lin-ear chain CRFs for these conditions.
We find thatmodeling preceding context yields the greatest im-provement.
This finding is consistent with findingsin recent phonetic research that argue for a largerrole of carryover coarticulation from preceding syl-lables than of anticipatory coarticulation with fol-lowing syllables.
Furthermore, sequence modelingin the CRF also improves results, across the explicitcontext feature conditions, with improvements beingmost pronounced in cases with less effective explicitprosodic contextual features.
Results for prosodicfeatures alone appear in Table 1.
In a side exper-iment with these prosodic features, we also brieflyexplored higher-order models, but no improvementwas observed.We also assess the impact of this richer contex-tualized prosodic feature set both alone and in con-junction with the full text-based feature set, in theNo Context Full ContextProsody Two-way 78.9% 80.8%Only Four-way 74.2% 78.2%All Two-way 86.2% 86.2%Features Four-way 79% 79.7%Table 2: Impact of context prosodic features withprosody alone and all featuresfull factorial CRF framework.
We compare resultsfor pitch accent identification in both the two-wayand four-way conditions with no context and withthe full ensemble of prosodic features.
We find nodifference for the two-way, all features condition forwhich text-based features perform well alone.
How-ever, for the prosody only cases and the more chal-lenging four-way task with all features, contextualinformation yields improvements, demonstrating theutility of this richer, contextualized prosodic featurerepresentation.
These contrasts appear in Table 2.5.2 Prosodic and Text-based FeaturesWe continue by contrasting effectiveness of differ-ent feature sets in the basic linear-chain CRF casefor pitch accent recognition.
Table 3 presents theresults for prosodic, word-based, and combined fea-tures sets in both the two-way and four-way classifi-cation conditions.
Overall accuracy is quite good;in all cases, results are well above the 65% mostcommon class assignment level, and the best re-sults (86.2%) outperform any previously publishedspeaker independent syllable-based results on thisdataset.
Overall results and contrasts are found inTable 3.It is clear that the two feature sets combine veryeffectively.
In the 4-way pitch accent task, the com-bined model yields a significant 1.5% to 2.5% in-crease over the strong acoustic-only model.
In con-trast, in the binary task, both the overall effective-ness of the text-based model and its utility in com-bination with the acoustic features are enhanced,yielding a much higher individual and combined ac-curacy rate.
This contrast can be explained by thefact that the word features, such as part of speech,identify items that, as a class, are likely to be ac-cented rather then being strongly associated with aparticular tone category.
The type of accent is likely221No Context Preceding Following BothZero order 70.5% 75.2% 71.8% 76.4%First order 74.2% 75.5% 73.7% 77.1%Table 1: Prosodic Context Features and CRFsAcoustic Text Text&AcousticLinear-Chain Two-way 79.48% 84.88% 86.1%Four-way 77.06% 76.21% 79.65%Factorial CRF Two-way 80.76% 84.74% 86.2%Four-way 78.22% 77.46% 79.71%Table 3: Pitch Accent Classification with Linear-Chain (top) and factorial CRFs (bottom) , using Acoustic-only, Text-based-only, and Combined Features.
Results for two- and four-way pitch accent prediction areshown.best determined by acoustic contrast, since accenttype is closely linked to pitch height, and the localcontext and acoustic features serve to identify whichaccentable words are truly accented.
Thus, in thebinary task, the text-based features combine mosteffectively with the evidence from the acoustic fea-tures.To contrast local classifiers with the linear chainmodel with text-based features, we trained a zero or-der classifier for the pitch accent prediction case andcontrasted it with a comparable first-order linear-chain CRFs.
Here for the binary accent recognitioncase, using only text-based information, we reach anaccuracy of 84.3% for the history-free model, con-trasted with an 85.4% level obtained with a compa-rable first-order model.15.3 Factorial CRF FrameworkFinally we consider the effect of joint classificationusing the factorial CRF framework.
Here, beyondjust pitch accent assignment, we perform simultane-ous assignment of pitch accent, phrase accent andboundary tone, where each label type correspondsto a factor, implementing the desired dependencies.21This comparison was computed using the original MalletCRF package rather than GRMM, due to simpler zero ordermodel support.
This results in a small difference in the resultingscores.2The features have not been tuned specifically for phrase ac-count and boundary prediction, as explicit punctuation or sen-tence boundary features would have been useful but obviousgiveaways.
However, our goal is to assess the potential impactof combined classification, without excessive tuning.The contrasts with the linear-chain model in termsof pitch accent prediction accuracy appear in Table3.
For the binary pitch accent condition, results aresomewhat mixed.
While there is a small but not sig-nificant decrease in accuracy for the text-only binaryclassification condition, the combined case showslittle change and the prosodic case increases mod-estly.
We note in one case that joint accuracy hasrisen when the pitch accent accuracy has dropped;we speculate that some additional compensation isneeded to manage the effects of the severe classimbalance between the dominant ?no-label?
classesfor phrase accent and boundary tone and other la-bels.
For the four-way contrast between pitch accenttypes, we see small to modest gains across all featuresets, with the prosodic case improving significantly(p < 0.025).
The best results for all but the two-way text-based classification task are found with thefactorial CRF model.For phrase accent and boundary tone prediction,phrase accent accuracy reaches 91.14%, and bound-ary tone accuracy 93.72% for all features.
Text-based evidence is more effective than prosodic evi-dence in these cases, with text-based features reach-ing 91.06% for phrase accent and 92.51% andacoustic features only 86.73% and 92.37% respec-tively.
However, little change is observed with thefactorial CRF relative to a linear chain model trainedon the same instances.
The results for phrase accentand boundary tone recognition appear in Table 4.222Phrase Accent Boundary ToneProsodic 86.73% 92.37%Text 91.06% 92.51%Text+Prosodic 91.14% 93.72%Table 4: Accuracy for phrase accent and boundarytone with prosodic, text-based, and combined fea-tures6 Conclusion and Future WorkThe application of linear-chain and factorial Con-ditional Random Fields for automatic pitch accentrecognition and other prosodic labeling facilitatesmodeling of sequential dependencies as well as inte-gration of rich acoustic features with text-based ev-idence.
We plan to further investigate the model-ing of dependencies between prosodic labels and thesequential modeling for acoustic features.
Finally,we will also integrate prior work on subsyllable seg-mentation to identify the best approximation of theprosodic target with the CRF framework to producea fine-grained sequence model of prosodic realiza-tion in context.7 AcknowledgmentsThe author would like to thank Charles Sutton forproviding the GRMM implementation, Andrew Mc-Callum for the Mallet CRF implementation, and Si-wei Wang and Sonja Waxmonsky for the modifica-tions supporting real-valued features.ReferencesSankaranarayanan Ananthakrishnan and ShrikanthNarayanan.
2006.
Combining acoustic, lexical,and syntactic evidence for automatic unsupervisedprosody labeling.
In Proceedings of ICSLP 2006.P.
Boersma.
2001.
Praat, a system for doing phoneticsby computer.
Glot International, 5(9?10):341?345.K.
Chen, M. Hasegawa-Johnson, and A. Cohen.
2004.An automatic prosody labeling system using ANN-based syntactic-prosodic model and GMM-basedacoustic-prosodic model.
In Proceedings of ICASSP.K.
Dusterhoff, A.
Black, and P. Taylor.
1999.
Using de-cision trees within the tilt intonation model to predictf0 contours.
In Proc.
Of Eurospeech ?99.Michelle Gregory and Yasemin Altun.
2004.
Using con-ditional random fields to predict pitch accents in con-versational speech.
In Proceedings of the 42nd Meet-ing of the Association for Computational Linguistics(ACL?04), Main Volume, pages 677?683, Barcelona,Spain, July.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.
In Pro-ceedings of the International Conference on MachineLearning (ICML-2001).Gina-Anne Levow.
2005.
Context in multi-lingual toneand pitch accent prediction.
In Proc.
of Interspeech2005.Yang Liu, Andreas Stolcke, Elizabeth Shriberg, andMaryHarper.
2005.
Using conditional random fields forsentence boundary detection in speech.
In Proceed-ings of the 43rd Annual Meeting of the Association forComputational Linguistics (ACL?05), pages 451?458,Ann Arbor, Michigan, June.
Association for Compu-tational Linguistics.Andrew McCallum, Khashayar Rohanimanesh, andCharles Sutton.
2003.
Dynamic conditional ran-dom fields for jointly labeling multiple sequences.
InNIPS*2003 Workshop on Syntax, Semantics, Statistics.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.M.
Ostendorf and K. Ross.
1997.
A multi-level modelfor recognition of intonation labels.
In Y. Sagisaka,N.
Campbell, and N. Higuchi, editors, ComputingProsody, pages 291?308.M.
Ostendorf, P. J.
Price, and S. Shattuck-Hufnagel.1995.
The Boston University radio news corpus.Technical Report ECS-95-001, Boston University.Shimei Pan and Kathleen McKeown.
1998.
Learningintonation rules for concept to speech generation.
InProceedings of ACL/COLING-98, pages 1003?1009.Vivek Kumar Rangarajan Sridhar, Srinivas Bangalore,and Shrikanth Narayanan.
2007.
Exploiting acousticand syntactic features for prosody labeling in a maxi-mum entropy framework.
In Human Language Tech-nologies 2007: The Conference of the North AmericanChapter of the Association for Computational Linguis-tics; Proceedings of the Main Conference, pages 1?8,Rochester, New York, April.
Association for Compu-tational Linguistics.Andrew Rosenberg and Julia Hirschberg.
2006.
On thecorrelation between energy and pitch accent in read en-glish speech.
In Proceedings of ICLSP 2006.223K.
Ross and M. Ostendorf.
1994.
A dynamical systemmodel for generating f0 for synthesis.
In Proceed-ings of the ESCA/IEEE Workshop on Speech Synthesis,pages 131?134.Xiao-Nan Shen.
1990.
Tonal co-articulation in Man-darin.
Journal of Phonetics, 18:281?295.C.
Shih and G. P. Kochanski.
2000.
Chinese tone model-ing with stem-ml.
In Proceedings of the InternationalConference on Spoken Language Processing, Volume2, pages 67?70.K.
Silverman, M. Beckman, J. Pitrelli, M. Osten-dorf, C. Wightman, P. Price, J. Pierrehumbert, andJ.
Hirschberg.
1992.
ToBI: A standard for labellingEnglish prosody.
In Proceedings of ICSLP, pages867?870.Xuejing Sun.
2002.
Pitch accent prediction using ensem-ble machine learning.
In Proceedings of ICSLP-2002.Charles Sutton.
2006.
Grmm: A graphical modelstoolkit.
http://mallet.cs.umass.edu.Yi Xu and X.
Sun.
2002.
Maximum speed of pitchchange and how it may relate to speech.
Journal ofthe Acoustical Society of America, 111.C.X.
Xu, Y. Xu, and L.-S. Luo.
1999.
A pitch tar-get approximation model for f0 contours in Mandarin.In Proceedings of the 14th International Congress ofPhonetic Sciences, pages 2359?2362.Yi Xu.
1997.
Contextual tonal variations in Mandarin.Journal of Phonetics, 25:62?83.Y.
Xu.
1999.
Effects of tone and focus on the formationand alignment of f0 contours - evidence from Man-darin.
Journal of Phonetics, 27.Yi Xu.
2004.
Transmitting tone and intonation simulta-neously - the parallel encoding and target approxima-tion (PENTA) model.
In TAL-2004, pages 215?220.224
