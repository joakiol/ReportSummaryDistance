Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 531?539,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPLinefeed Insertion into Japanese Spoken Monologue for CaptioningTomohiro OhnoGraduate School ofInternational Development,Nagoya University, Japanohno@nagoya-u.jpMasaki MurataGraduate School ofInformation Science,Nagoya University, Japanmurata@el.itc.nagoya-u.ac.jpShigeki MatsubaraInformation Technology Center,Nagoya University, Japanmatubara@nagoya-u.jpAbstractTo support the real-time understanding ofspoken monologue such as lectures andcommentaries, the development of a cap-tioning system is required.
In monologues,since a sentence tends to be long, eachsentence is often displayed in multi lineson one screen, it is necessary to insertlinefeeds into a text so that the text be-comes easy to read.
This paper proposesa technique for inserting linefeeds into aJapanese spoken monologue text as an el-emental technique to generate the read-able captions.
Our method appropriatelyinserts linefeeds into a sentence by ma-chine learning, based on the informationsuch as dependencies, clause boundaries,pauses and line length.
An experiment us-ing Japanese speech data has shown the ef-fectiveness of our technique.1 IntroductionReal-time captioning is a technique for support-ing the speech understanding of deaf persons, el-derly persons, or foreigners by displaying tran-scribed texts of monologue speech such as lec-tures.
In recent years, there exist a lot of re-searches about automatic captioning, and the tech-niques of automatic speech recognition (ASR)aimed for captioning have been developed (Bou-lianne et al, 2006; Holter et al, 2000; Imai etal., 2006; Munteanu et al, 2007; Saraclar et al,2002; Xue et al, 2006).
However, in order to gen-erate captions which is easy to read, it is importantnot only to recognize speech with high recognitionrate but also to properly display the transcribedtext on a screen (Hoogenboom et al, 2008).
Es-pecially, in spoken monologue, since a sentencetends to be long, each sentence is often displayedas a multi-line text on a screen.
Therefore, properlinefeed insertion for the displayed text is desiredso that the text becomes easy to read.Until now, there existed few researches abouthow to display text on a screen in automatic cap-tioning.
As the research about linefeed insertion,Monma et al proposed a method based on pat-terns of a sequence of morphemes (Monma etal., 2003).
However, the target of the research isclosed-captions of Japanese TV shows, in whichless than or equal to 2 lines text is displayed ona screen and the text all switches to other text ata time.
In the work, the highest priority concepton captioning is that one screen should be filledwith as much text as possible.
Therefore, a se-mantic boundary in a sentence is hardly taken intoaccount in linefeed insertion, and the readabilityof the caption is hardly improved.This paper proposes a technique for insertinglinefeeds into transcribed texts of Japanese mono-logue speech as an elemental technique to gener-ate readable captions.
We assume that a screen fordisplaying only multi-line caption is placed to pro-vide the caption information to the audience on thesite of a lecture.
In our method, the linefeeds areinserted into only the boundaries between bunset-sus1, and the linefeeds are appropriately insertedinto a sentence by machine learning, based on theinformation such as morphemes, dependencies2,clause boundaries, pauses and line length.We conducted an experiment on inserting line-feeds by using Japanese spoken monologue data.As the results of inserting linefeeds for 1,714 sen-tences, the recall and precision of our method were82.66% and 80.24%, respectively.
Our methodimproved the performance dramatically compared1Bunsetsu is a linguistic unit in Japanese that roughly cor-responds to a basic phrase in English.
A bunsetsu consists ofone independent word and zero or more ancillary words.2A dependency in Japanese is a modification relation inwhich a modifier bunsetsu depends on a modified bunsetsu.That is, the modifier bunsetsu and the modified bunsetsu workas modifier and modifyee, respectively.531Figure 1: Caption display of spoken monologuewith four baseline methods, which we establishedfor comparative evaluation.
The effectiveness ofour method has been confirmed.This paper is organized as follows: The nextsection describes our assumed caption and the pre-liminary analysis.
Section 3 presents our linefeedinsertion technique.
An experiment and discussionare reported in Sections 4 and 5, respectively.
Fi-nally, Section 6 concludes the paper.2 Linefeed Insertion for SpokenMonologueIn our research, in an environment in which cap-tions are displayed on the site of a lecture, we as-sume that a screen for displaying only captions isused.
In the screen, multi lines are always dis-played, being scrolled line by line.
Figure 1 showsour assumed environment in which captions aredisplayed.As shown in Figure 2, if the transcribed text ofspeech is displayed in accordance with only thewidth of a screen without considering the properpoints of linefeeds, the caption is not easy to read.Especially, since the audience is forced to readthe caption in synchronization with the speaker?sutterance speed, it is important that linefeeds areproperly inserted into the displayed text in consid-eration of the readability as shown in Figure 3.To investigate whether the line insertion facili-tates the readability of the displayed texts, we con-ducted an experiment using the transcribed text oflecture speeches in the Simultaneous Interpreta-tion Database (SIDB) (Matsubara et al, 2002).
Werandomly selected 50 sentences from the data, andthen created the following two texts for each sen-tence based on two different concepts about line-feed insertion.
?1?Text into which linefeeds were forcibly in-serted once every 20 characters??????????????????????????????????????????????????????????????????????????????????????????????????
?For example, environmental problem,population problem, AIDS problem andso on, a lot of global-scale problemshave occurred, and unfortunately,these problems seem to continueduring 21st century or to becomeworse if we look through blue glasses.Figure 2: Caption of monologue speech???????????????????????????????????????????????????????????????????????????????????????????????????
(For example, environmental problem)(population problem)(AIDS problem and so on)a lot of global-scale problemshave occurred(and unfortunately, these problems)(to continue during also 21st century)(or if we look through blue glasses)(seems to become worse)Figure 3: Caption into which linefeeds are prop-erly inserted495049374036434834491 2 3 4 5 6 7 8 9 10?1?
Forcible insertion of linefeeds?2?
Proper insertion of linefeedssubject ID# of sentences50454035302520151050Figure 4: Result of investigation of effect of line-feed insertion into transcription?2?Text into which linefeeds were properlyinserted in consideration of readability byhand3Figure 2 and 3 show examples of the text (1) and(2), respectively.
10 examinees decided which ofthe two texts was more readable.
Figure 4 showsthe result of the investigation.
The ratio that eachexaminee selected text (2) was 87.0% on average.There was no sentence in the text group (1) whichwas selected by more than 5 examinees.
Theseindicates that a text becomes more readable byproper insertion of linefeeds.Here, since a bunsetsu is the smallest seman-tically meaningful language unit in Japanese, ourmethod adopts the bunsetsu boundaries as the can-didates of points into which a linefeed is inserted.In this paper, hereafter, we call a bunsetsu bound-ary into which a linefeed is inserted a linefeedpoint.33 persons inserted linefeeds into the 50 sentences by dis-cussing where to insert the linefeeds.532Table 1: Size of analysis datasentence 221bunsetsu 2,891character 13,899linefeed 883character per line 13.23 Preliminary Analysis about LinefeedPointsIn our research, the points into which linefeedsshould be inserted is detected by using machinelearning.
To find the effective features, we investi-gated the spoken language corpus.
In our investi-gation, we used Japanese monologue speech datain the SIDB (Matsubara et al, 2002).
The datais annotated by hand with information on mor-phological analysis, bunsetsu segmentation, de-pendency analysis, clause boundary detection, andlinefeeds insertion.
Table 1 shows the size of theanalysis data.
Among 2,670 (= 2, 891?221) bun-setsu boundaries, which are candidates of linefeedpoints, there existed 833 bunsetsu boundaries intowhich linefeeds were inserted, that is, the ratio oflinefeed insertion was 31.2%.The linefeeds were inserted by hand so that themaximum number of characters per line is 20.
Weset the number in consideration of the relation be-tween readability and font size on the display.
Inthe analysis, we focused on the clause boundary,dependency relation, line length, pause and mor-pheme of line head, and investigated the relationsbetween them and linefeed points.3.1 Clause Boundary and Linefeed PointSince a clause is one of semantically meaningfullanguage units, the clause boundary is consideredto be a strong candidate of a linefeed point.
In theanalysis data, there existed 969 clause boundariesexcept sentence breaks.
Among them, 490 werethe points into which linefeeds were inserted, thatis, the ratio of linefeed insertion was 51.1%.
Thisratio is higher than that of bunsetsu boundaries.This indicates that linefeeds tend to be insertedinto clause boundaries.We investigated the ratio of linefeed insertionabout 42 types4 of clause boundaries, which wereseen in the analysis data.
Table 2 shows the top 104In our research, we used the types of clause boundariesdefined by the Clause Boundary Annotation Program (Kash-ioka and Maruyama, 2004).Table 2: Ratio of linefeed insertion for clauseboundary typetype of ratio of linefeedclause boundary insertion (%)topicalized element-wa 50.8discourse marker 12.0quotational clause 22.1adnominal clause 23.3compound clause-te 90.2supplement clause 68.0compound clause-ga 100.0compound clause-keredomo 100.0condition clause-to 93.5adnominal clause-toiu 27.3clause boundary types about the occurrence fre-quency, and each ratio of linefeed insertion.
Inthe case of ?compound clause-ga?
and ?compoundclause-keredomo,?
the ratio of linefeed insertionwas 100%.
On the other hand, in the case of ?quo-tational clause,?
?adnominal clause?
and ?adnomi-nal clause-toiu,?
the ratio of linefeed insertion wasless than 30%.
This means that the likelihood oflinefeed insertion is different according to the typeof the clause boundary.3.2 Dependency Structure and LinefeedPointWhen a bunsetsu depends on the next bunsetsu, itis thought that a linefeed is hard to be inserted intothe bunsetsu boundary between them because thesequence of such bunsetsus constitutes a semanti-cally meaningful unit.
In the analysis data, thereexisted 1,459 bunsetsus which depend on the nextbunsetsu.
Among the bunsetsu boundaries rightafter them, 192 were linefeed points, that is, theratio of linefeed insertions was 13.2%.
This ra-tio is less than half of that for all the bunsetsuboundaries.
On the other hand, when the bunsetsuboundary right after the bunsetsu which does notdepend on the next bunsetsu, the ratio of linefeedinsertion was 52.7%.Next, we focused on the type of the dependencyrelation, by which the likelihood of linefeed inser-tion is different.
For example, when the bunsetsuboundary right after a bunsetsu on which the finalbunsetsu of an adnominal clause depends, the ra-tio of linefeed insertion was 43.1%.
This ratio ishigher than that for all the bunsetsu boundaries.In addition, we investigated the relation be-533??????????????????????????????????????
:  dependency relation?
bunsetsu[Dependency structure][Result of linefeed insertion in the analysis data]A writer of the magazine in whichonly old domestic cars are coveredasks to get a story about my car??
???????????
???
???
??
??
?????????????
?onlydomestic carsin whichare coveredoldof themagazineawritermy carto get astory aboutaskFigure 5: Relation between dependency structureand linefeed pointstween a dependency structure and linefeed points,that is, whether the dependency structure is closedwithin a line or not.
Here, a line whose depen-dency structure is closed means that all bunsetsus,except the final bunsetsu, in the line depend on oneof bunsetsus in the line.
Since, in many of seman-tically meaningful units, the dependency structureis closed, the dependency structure of a line is con-sidered to tend to be closed.
In the analysis data,among 883 lines, 599 lines?
dependency structureswere closed.Figure 5 shows the relation between depen-dency structure and linefeed points.
In this exam-ple, linefeeds are not inserted right after bunset-sus which depend on the next bunsetsu (e.g.
???
(my)?
and ???
(car)?).
Instead, a linefeed isinserted right after a bunsetsu which does not de-pend on the next bunsetsu (????
(a writer)?
).In addition, the dependency structure in each lineis closed.3.3 Line Length and Linefeed PointAn extremely-short line is considered to be hardlygenerated because the readability goes down if thelength of each line is very different.
In the analysisdata, a line whose length is less than or equal to 6characters occupied only 7.59% of the total.
Thisindicates that linefeeds tend to be inserted into theplace where a line can maintain a certain length.3.4 Pause and Linefeed PointIt is thought that a pause corresponds to a syn-tactic boundary.
Therefore, there are possibilitythat a linefeed becomes more easily inserted intoa bunsetsu boundary at which a pause exists.
Inour research, a pause is defined as a silent intervalequal to or longer than 200ms.
In the analysis data,among 748 bunsetsu boundaries at which a pauseexists, linefeeds were inserted into 471 bunsetsuboundaries, that is, the ratio of linefeed insertionwas 62.97%.
This ratio is higher than that for allthe bunsetsu boundaries, thus, we confirmed thatlinefeeds tend to be inserted into bunsetsu bound-aries at which a pause exists.3.5 Morpheme Located in the Start of a LineThere exist some morphemes which are unlikelyto become a line head.
We investigated the ratiothat each leftmost morpheme of all the bunsetsusappears at a line head.
Here, we focused on thebasic form and part-of-speech of a morpheme.
Themorphemes which appeared 20 times and of whichthe ratio of appearance at a line head was less than10% were as follows:?
Basic form:???
(think) [2/70]?, ???
(problem)[0/42]?, ???
(do) [3/33]?, ???
(become)[2/32]?????
(necessary) [1/21]??
Part-of-speech:noun-non independent-general [0/40]?noun-nai adjective stem [0/40]?noun-non independent-adverbial [(0/27]If the leftmost morpheme of a bunsetsu is one ofthese, it is thought that a linefeed is hardly insertedright after the bunsetsu.4 Linefeed Insertion TechniqueIn our method, a sentence, on which morphologi-cal analysis, bunsetsu segmentation, clause bound-ary analysis and dependency analysis are per-formed, is considered the input.
Our method de-cides whether or not to insert a linefeed into eachbunsetsu boundary in an input sentence.
Underthe condition that the number of characters in eachline has to be less than or equal to the maximumnumber of characters per line, our method identi-fies the most appropriate combination among allcombinations of the points into which linefeedscan be inserted, by using the probabilistic model.In this paper, we describe an input sentencewhich consists of n bunsetsus as B = b1 ?
?
?
bn,and the result of linefeeds insertion as R =r1 ?
?
?
rn.
Here, ri is 1 if a linefeed is inserted rightafter bunsetsu bi, and is 0 otherwise.
We describea sequence of bunsetsus in the j-th line among them lines created by dividing an input sentence asLj = bj1 ?
?
?
bjnj (1 ?
j ?
m), and then, rjk = 0 ifk ?= nj , and rjk = 1 otherwise.5344.1 Probabilistic Model for LinefeedInsertionWhen an input sentenceB is provided, our methodidentifies the result of linefeeds insertionR, whichmaximizes the conditional probability P (R|B).Assuming that whether or not a linefeed is insertedright after a bunsetsu is independent of other line-feed points except the linefeed point of the start ofthe line which contains the bunsetsu, P (R|B) canbe calculated as follows:P (R|B) (1)= P (r11 = 0, ?
?
?
, r1n1 = 1, ?
?
?
, rm1 = 0, ?
?
?
, rmnm = 1|B)?= P (r11 = 0|B) ?
P (r12 = 0|r11 = 0, B) ?
?
?
?
?P (r1n1 = 1|r1n1?1 = 0, ?
?
?
, r11 = 0, B) ?
?
?
?
?P (rm1 = 0|rm?1nm?1 = 1, B) ?
?
?
?
?P (rmm = 1|rmnm?1 = 0, ?
?
?
, rm1 = 0, rm?1nm?1 = 1, B)where P (rjk = 1|rjk?1 = 0, ?
?
?
, rj1 = 0, rj?1nj?1 =1, B) is the probability that a linefeed is insertedright after a bunsetsu bjk when the sequence ofbunsetsus B is provided and the linefeed point ofthe start of the j-th line is identified.
Similarly,P (rjk = 0|rjk?1 = 0, ?
?
?
, rj1 = 0, rj?1nj?1 = 1, B)is the probability that a linefeed is not insertedright after a bunsetsu bjk.
These probabilities areestimated by the maximum entropy method.
Theresult R which maximizes the conditional proba-bility P (R|B) is regarded as the most appropriateresult of linefeed insertion, and calculated by dy-namic programming.4.2 Features on Maximum Entropy MethodTo estimate P (rjk = 1|rjk?1 = 0, ?
?
?
, rj1 =0, rj?1nj?1 = 1, B) and P (rjk = 0|rjk?1 =0, ?
?
?
, rj1 = 0, rj?1nj?1 = 1, B) by the maximumentropy method, we used the following featuresbased on the analysis described in Section 2.2.Morphological information?
the rightmost independent morpheme (a part-of-speech, an inflected form) and rightmostmorpheme (a part-of-speech) of a bunsetsu bjkClause boundary information?
whether or not a clause boundary exists rightafter bjk?
a type of the clause boundary right after bjk (ifthere exists a clause boundary)Dependency information?
whether or not bjk depends on the next bun-setsu?
whether or not bjk depends on the final bun-setsu of a clause?
whether or not bjk depends on a bunsetsu towhich the number of characters from the startof the line is less than or equal to the maxi-mum number of characters?
whether or not bjk is depended on by the finalbunsetsu of an adnominal clause?
whether or not bjk is depended on by the bun-setsu located right before it?
whether or not the dependency structure ofa sequence of bunsetsus between bjk and bj1,which is the first bunsetsu of the line, isclosed?
whether or not there exists a bunsetsu whichdepends on the modified bunsetsu of bjk,among bunsetsus which are located after bjkand to which the number of characters fromthe start of the line is less than or equal to themaximum number of charactersLine length?
any of the following is the class into whichthe number of characters from the start of theline to bjk is classified?
less than or equal to 2?
more than 2 and less than or equal to 6?
more than 6Pause?
whether or not a pause exists right after bjkLeftmost morpheme of a bunsetsu?
whether or not the basic form or part-of-speech of the leftmost morpheme of the nextbunsetsu of bjk is one of the morphemes enu-merated in Section 3.5.5 ExperimentTo evaluate the effectiveness of our method, weconducted an experiment on inserting linefeeds byusing discourse speech data.5.1 Outline of ExperimentAs the experimental data, we used the transcribeddata of Japanese discourse speech in the SIDB(Matsubara et al, 2002).
All the data are anno-tated with information on morphological analysis,clause boundary detection and dependency anal-ysis by hand.
We performed a cross-validationexperiment by using 16 discourses.
That is, we535repeated the experiment, in which we used onediscourse from among 16 discourses as the testdata and the others as the learning data, 16 times.However, since we used 2 discourse among 16discourses as the preliminary analysis data, weevaluated the experimental result for the other 14discourses (1,714 sentences, 20,707 bunsetsus).Here, we used the maximum entropy method tool(Zhang, 2008) with the default options except ?-i2000.
?In the evaluation, we obtained recall, precisionand the ratio of sentences into which all linefeedpoints were correctly inserted (hereinafter calledsentence accuracy).
The recall and precision arerespectively defined as follows.recall = # of correctly inserted LFs# of LFs in the correct dataprecision = # of correctly inserted LFs# of automatically inserted LFsFor comparison, we established the followingfour baseline methods.1.
Linefeeds are inserted into the rightmost bun-setsu boundaries among the bunsetsu bound-aries into which linefeeds can be inserted sothat the length of the line does not exceedthe maximum number of characters (Line-feed insertion based on bunsetsu bound-aries).2.
Linefeeds are inserted into the all clauseboundaries (Linefeed insertion based onclause boundaries).3.
Linefeeds are inserted between adjacent bun-setsus which do not depend on each other(Linefeed insertion based on dependencyrelations).4.
Linefeeds are inserted into the all bunsetsuboundaries in which a pause exists (Linefeedinsertion based on pauses).In the baseline 2, 3 and 4, if each condition is notfulfilled within the maximum number of charac-ters, a linefeed is inserted into the rightmost bun-setsu boundary as well as the baseline 1.In the experiment, we defined the maximumnumber of characters per line as 20.
The cor-rect data of linefeed insertion were created by ex-perts who were familiar with displaying captions.There existed 5,497 inserted linefeeds in the 14discourses, which were used in the evaluation.Table 3: Experimental resultsrecall (%) precision (%) F-measureour method 82.66 80.24 81.43(4,544/5,497) (4,544/5,663)baseline 1 27.47 34.51 30.59(1,510/5,497) (1,510/4,376)baseline 2 69.34 48.65 57.19(3,812/5,497) (3,812/7,834)baseline 3 89.48 53.73 67.14(4,919/5,497) (4,919/9,155)baseline 4 69.84 55.60 61.91(3,893/5,497) (3,893/6,905)5.2 Experimental ResultTable 3 shows the experimental results of the base-lines and our method.
The baseline 1 is very sim-ple method which inserts linefeeds into the bun-setsu boundaries so that the length of the line doesnot exceed the maximum number of characters perline.
Therefore, the recall and precision were thelowest.In the result of baseline 2, the precision waslow.
As described in the Section 3.1, the degreein which linefeeds are inserted varies in differ-ent types of clause boundaries.
In the baseline2, because linefeeds are also inserted into clauseboundaries which have the tendency that linefeedsare hardly inserted, the unnecessary linefeeds areconsidered to have been inserted.The recall of baseline 3 was very high.
Thisis because, in the correct data, linefeeds werehardly inserted between two neighboring bunset-sus which are in a dependency relation.
However,the precision was low, because, in the baseline3, linefeeds are invariably inserted between twoneighboring bunsetsus which are not in a depen-dency relation.In the baseline 4, both the recall and precisionwere not good.
The possible reason is that the bun-setsu boundaries at which a pause exists do notnecessarily correspond to the linefeed points.On the other hand, the F-measure and the sen-tence accuracy of our method were 81.43 and53.15%, respectively.
Both of them were highestamong those of the four baseline, which showedan effectiveness of our method.5.3 Causes of Incorrect Linefeed InsertionIn this section, we discuss the causes of the in-correct linefeed insertion occurred in our method.Among 1,119 incorrectly inserted linefeeds, themost frequent cause was that linefeeds were in-536?????????????????????????
?That is the period which I callthe first period without apologyFigure 6: Example of incorrect linefeed insertionin ?adnominal clause.????????????????????????????????????????????????????
(about how detail I can speak)(I have a concern)(from serious story to easy story )(I want to speak)Figure 7: Example of extra linefeed insertionserted into clause boundaries of a ?adnominalclause?
type.
The cause occupies 10.19% of thetotal number of the incorrectly inserted linefeeds.In the clause boundaries of the ?adnominal clause?type, linefeeds should rarely be inserted funda-mentally.
However, in the result of our method,a lot of linefeeds were inserted into the ?adnomi-nal clause.?
Figure 6 shows an example of thoseresults.
In this example, a linefeed is inserted intothe ?adnominal clause?
boundary which is locatedright after the bunsetsu ?????
(call).?
The se-mantic chunk ?????????????
(is theperiod which I call)?
is divided.As another cause, there existed 291 linefeedswhich divide otherwise one line according to thecorrect data into two lines.
Figure 7 shows an ex-ample of the extra linefeed insertion.
Although, inthe example, a linefeed is inserted between ???????????????
(about how detail Ican speak)?
and ??????
(I have a concern),?the two lines are displayed in one line in the cor-rect data.
It is thought that, in our method, line-feeds tend to be inserted even if a line has space tospare.6 DiscussionIn this section, we discuss the experimental resultsdescribed in Section 5 to verify the effectivenessof our method in more detail.6.1 Subjective Evaluation of LinefeedInsertion ResultThe purpose of our research is to improve the read-ability of the spoken monologue text by our line-feed insertion.
Therefore, we conducted a subjec-tive evaluation of the texts which were generatedby the above-mentioned experiment.In the subjective evaluation, examinees lookedat the two texts placed side-by-side between whichthe only difference is linefeed points, and then se-3534404539484547 47441 2 3 4 5 6 7 8 9 10Baseline 3Our methodsubject ID# of sentences50454035302520151050Figure 8: Result of subjective evaluationlected the one which was felt more readable.
Here,we compared our method with the baseline 3, ofwhich F-measure was highest among four base-lines described in Section 5.1.
Ten examineesevaluated 50 pairs of the results generated fromthe same 50 randomly selected sentences.Figure 8 shows the result of subjective evalua-tion.
This graph shows the number of each methodselected by each examinee.
The ratio that ourmethod was selected was 94% in the highest case,and 68% even in the lowest case.
We confirmedthe effectiveness of our method for improving thereadability of the spoken monologue text.On the other hand, there existed three sentencesfor which more than 5 examinees judged that theresults of baseline 3 were more readable than thoseof our method.
From the analysis of the three sen-tences, we found the following phenomena causedtext to be less readable?
Japanese syllabary characters (Hiragana) aresuccessionally displayed across a bunsetsuboundary.?
The length of anteroposterior lines is ex-tremely different each other.Each example of the two causes is shown inFigure 9 and 10, respectively.
In Figure 9, abunsetsu boundary existed between Japanese syl-labary characters ??????
(I)?
and ?????
(if truth be told)?
and these characters are succes-sionally displayed in the same line.
In these cases,it becomes more difficult to identify the bunsetsuboundary, therefore, the text is thought to becomedifficult to read.
In Figure 10, since the length ofthe second line is extremely shorter than the firstline or third line, the text is thought to become dif-ficult to read.537????????????????????????????????????????
(Actually, I, if truth be told, I)when I was a college student,(I) used to dodge  my train fare and(be caught )Actually, I, if truth be told, I used to dodge my train fare and be caughtwhen I was a college student.Figure 9: Example of succession of hiragana?????????????????????????????????????????????????????
?I, the energy resources of whichthe remaining amount became littlein which humans who are in the pastand future fight(wrote a science-fiction novel)(over)I wrote a science-fiction novel, in which humans who are in the past and futurefight over the energy resources of which the remaining amount became little.Figure 10: Lines that have extremely differentlengthTable 4: Other annotator?s resultsrecall (%) precision (%) F-measureby human 89.82 (459/511) 89.82 (459/511) 89.82our method 82.19 (420/511) 81.71 (420/514) 81.956.2 Comparison with Linefeeds Inserted byHumanThe concept of linefeed insertion for making thecaption be easy to read varies by the individual.When multiple people insert linefeeds for the sametext, there is possibility that linefeeds are insertedinto different points.Therefore, for one lecture data (128 sentences,511 bunsetsus) in the experimental data, we con-ducted an experiment on linefeed insertion by anannotator who was not involved in the construc-tion of the correct data.
Table 4 shows the re-call and the precision.
The second line showsthe result of our method for the same lecturedata.
In F-measure, our method achieved 91.24%(81.95/89.82) of the result by the human annotator.6.3 Performance of Linefeed Insertion Basedon Automatic Natural Language AnalysisIn the experiment described in Section 5, we usedthe linguistic information provided by human asthe features on the maximum entropy method.However, compared with baseline 1, our methoduses a lot of linguistic information which shouldbe provided not by human but by natural languageanalyzers under the real situation.
Therefore, tofairly evaluate our method and four baselines, weconducted an experiment on linefeed insertion byusing the automatically provided information onclause boundaries and dependency structures5.5We used CBAP (Kashioka and Maruyama, 2004) asa clause boundary analyzer and CaboCha (Kudo and Mat-sumoto, 2002) with default learning data as a dependencyparser.Table 5: Experimental results when information offeatures are automatically providedrecall (%) precision (%) F-measureour method 77.37 75.04 76.18(4,253/5,497) (4,253/5,668)baseline 1 27.47 34.51 30.59(1,510/5,497) (1,510/4,376)baseline 2 69.51 48.63 57.23(3,821/5,497) (3,821/7,857)baseline 3 84.01 52.03 64.26(4,618/5,497) (4,618/8,876)baseline 4 69.84 55.60 61.91(3,893/5,497) (3.893/6,905)Table 5 shows the result.
Compared with Table3, it shows the decreasing rate of the performanceof our method was more than those of four base-lines which use simply only basic linguistic infor-mation.
However, the F-measure of our methodwas more than 10% higher than those of four base-lines.7 ConclusionThis paper proposed a method for inserting line-feeds into discourse speech data.
Our method caninsert linefeeds so that captions become easy toread, by using machine learning techniques on fea-tures such as morphemes, dependencies, clauseboundaries, pauses and line length.
An experi-ment by using transcribed data of Japanese dis-course speech showed the recall and precision was82.66% and 80.24%, respectively, and we con-firmed the effectiveness of our method.In applying the linefeed insertion technique topractical real-time captioning, we have to considernot only the readability but also the simultaneity.Since the input of our method is a sentence whichtends to be long in spoken monologue, in the fu-ture, we will develop more simultaneous a tech-nique in which the input is shorter than a sentence.In addition, we assumed the speech recognitionsystem with perfect performance.
To demonstratepracticality of our method for automatic speechtranscription, an experiment using a continuousspeech recognition system will be performed inthe future.AcknowledgmentsThis research was partially supported by theGrant-in-Aid for Scientific Research (B) (No.20300058) and Young Scientists (B) (No.21700157) of JSPS, and by The Asahi GlassFoundation.538ReferencesG.
Boulianne, J.-F. Beaumont, M. Boisvert,J.
Brousseau, P. Cardinal, C. Chapdelaine,M.
Comeau, P. Ouellet, and F. Osterrath.
2006.Computer-assisted closed-captioning of live TVbroadcasts in French.
In Proceedings of 9th Interna-tional Conference on Spoken Language Processing,pages 273?276.T.
Holter, E. Harborg, M. H. Johnsen, and T. Svendsen.2000.
ASR-based subtitling of live TV-programs forthe hearing impaired.
In Proceedings of 6th Interna-tional Conference on Spoken Language Processing,volume 3, pages 570?573.R.
B. Hoogenboom, K. Uehara, T. Kanazawa,S.
Nakano, H. Kuroki, S. Ino, and T. Ifukube.
2008.An application of real-time captioning system usingautomatic speech recognition technology to collegeefl education for deaf and hard-of-hearing students.Gunma University Annual Research Reports, Cul-tural Science Series, 57.T.
Imai, S. Sato, A. Kobayashi, K. Onoe, andS.
Homma.
2006.
Online speech detectionand dual-gender speech recognition for captioningbroadcast news.
In Proceedings of 9th InternationalConference on Spoken Language Processing, pages1602?1605.H.
Kashioka and T. Maruyama.
2004.
Segmentation ofsemantic units in Japanese monologues.
In Proceed-ings of ICSLT2004 and Oriental-COCOSDA2004,pages 87?92.T.
Kudo and Y. Matsumoto.
2002.
Japanese depen-dency analysis using cascaded chunking.
In Pro-ceedings of 6th Conference on Computational Natu-ral Language Learning, pages 63?69.S.
Matsubara, A. Takagi, N. Kawaguchi, and Y. Ina-gaki.
2002.
Bilingual spoken monologue corpusfor simultaneous machine interpretation research.In Proceedings of 3rd International Conference onLanguage Resources and Evaluation, pages 153?159.T.
Monma, E. Sawamura, T. Fukushima, I. Maruyama,T.
Ehara, and K. Shirai.
2003.
Automatic closed-caption production system on TV programs forhearing-impaired people.
Systems and Computersin Japan, 34(13):71?82.C.
Munteanu, G. Penn, and R. Baecker.
2007.
Web-based language modelling for automatic lecture tran-scription.
In Proceedings of 8th Annual Conferenceof the International Speech Communication Associ-ation, pages 2353?2356.M.
Saraclar, M. Riley, E. Bocchieri, and V. Gof-fin.
2002.
Towards automatic closed captioning:Low latency real time broadcast news transcription.In Proceedings of 7th International Conference onSpoken Language Processing, pages 1741?1744.J.
Xue, R. Hu, and Y. Zhao.
2006.
New improvementsin decoding speed and latency for automatic caption-ing.
In Proceedings of 9th International Conferenceon Spoken Language Processing, pages 1630?1633.L.
Zhang.
2008.
Maximum entropy mod-eling toolkit for Python and C++.
http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.
[Online; accessed1-March-2008].539
