Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 243?248,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics?Let Everything Turn Well in Your Wife?
:Generation of Adult Humor Using Lexical ConstraintsAlessandro ValituttiDepartment of Computer Scienceand HIITUniversity of Helsinki, FinlandHannu ToivonenDepartment of Computer Scienceand HIITUniversity of Helsinki, FinlandAntoine DoucetNormandy University ?
UNICAENGREYC, CNRS UMR?6072Caen, FranceJukka M. ToivanenDepartment of Computer Scienceand HIITUniversity of Helsinki, FinlandAbstractWe propose a method for automated gen-eration of adult humor by lexical replace-ment and present empirical evaluation re-sults of the obtained humor.
We proposethree types of lexical constraints as build-ing blocks of humorous word substitu-tion: constraints concerning the similarityof sounds or spellings of the original wordand the substitute, a constraint requiringthe substitute to be a taboo word, and con-straints concerning the position and con-text of the replacement.
Empirical ev-idence from extensive user studies indi-cates that these constraints can increasethe effectiveness of humor generation sig-nificantly.1 IntroductionIncongruity and taboo meanings are typical ingre-dients of humor.
When used in the proper context,the expression of contrasting or odd meanings caninduce surprise, confusion or embarrassment and,thus, make people laugh.
While methods fromcomputational linguistics can be used to estimatethe capability of words and phrases to induce in-congruity or to evoke taboo meanings, computa-tional generation of humorous texts has remaineda great challenge.In this paper we propose a method for auto-mated generation of adult humor by lexical re-placement.
We consider a setting where a shorttext is provided to the system, such as an instantmessage, and the task is to make the text funny byreplacing one word in it.
Our approach is basedon careful introduction of incongruity and taboowords to induce humor.We propose three types of lexical constraintsas building blocks of humorous word substitu-tion.
(1) The form constraints turn the text intoa pun.
The constraints thus concern the similarityof sounds or spellings of the original word and thesubstitute.
(2) The taboo constraint requires thesubstitute to be a taboo word.
This is a well-knownfeature in some jokes.
We hypothesize that the ef-fectiveness of humorous lexical replacement canbe increased with the introduction of taboo con-straints.
(3) Finally, the context constraints con-cern the position and context of the replacement.Our assumption is that a suitably positionedsubstitution propagates the tabooness (definedhere as the capability to evoke taboo meanings)to phrase level and amplifies the semantic con-trast with the original text.
Our second concretehypothesis is that the context constraints furtherboost the funniness.We evaluated the above hypotheses empiricallyby generating 300 modified versions of SMS mes-sages and having each of them evaluated by 90subjects using a crowdsourcing platform.
Theresults show a statistically highly significant in-crease of funniness and agreement with the use ofthe humorous lexical constraints.The rest of this paper is structured as follows.In Section 2, we give a short overview of theoreti-cal background and related work on humor gener-ation.
In Section 3, we present the three types ofconstraints for lexical replacement to induce hu-mor.
The empirical evaluation is presented in Sec-tion 4.
Section 5 contains concluding remarks.2432 BackgroundHumor, Incongruity and Tabooness A set oftheories known as incongruity theory is probablythe most influential approach to the study of hu-mor and laughter.
The concept of incongruity, firstdescribed by Beattie (1971), is related to the per-ception of incoherence, semantic contrast, or inap-propriateness, even though there is no precise andagreed definition.
Raskin (1985) formulated theincongruity concept in terms of script opposition.This has been developed further, into the Gen-eral Theory of Verbal Humor (Attardo and Raskin,1991).
A cognitive treatment of incongruity in hu-mor is described by Summerfelt et al (2010).One specific form of jokes frequently discussedin the literature consists of the so called forcedreinterpretation jokes.
E.g.
:Alcohol isn?t a problem, it?s a solution...Just ask any chemist.In his analysis of forced reinterpretation jokes,Ritchie (2002) emphasises the distinction betweenthree different elements of the joke processing:CONFLICT is the initial perception of incompati-bility between punchline and setup according tothe initial obvious interpretation; CONTRAST de-notes the perception of the contrastive connec-tion between the two interpretations; while INAP-PROPRIATENESS refers to the intrinsic oddness ortabooness characterising the funny interpretation.All three concepts are often connected to the no-tion of incongruity.In his integrative approach to humor theories,Martin (2007) discusses the connection betweentabooness and incongruity resolution.
In partic-ular, he discusses the salience hypothesis (Gold-stein et al, 1972; Attardo and Raskin, 1991), ac-cording to which ?the purpose of aggressive andsexual elements in jokes is to make salient the in-formation needed to resolve the incongruity?.Humor Generation In previous research oncomputational humor generation, puns are oftenused as the core of more complex humorous texts,for example as punchlines of simple jokes (Raskinand Attardo, 1994; Levison and Lessard, 1992;Venour, 1999; McKay, 2002).
This differs fromour setting, where we transform an existing shorttext into a punning statement.Only few humor generation systems have beenempirically evaluated.
The JAPE program (Bin-sted et al, 1997) produces specific types of pun-ning riddles.
HAHAcronym (Stock and Strap-parava, 2002) automatically generates humorousversions of existing acronyms, or produces a newfunny acronym, starting with concepts providedby the user.
The evaluations indicate statisticalsignificance, but the test settings are relatively spe-cific.
Below, we will present an approach to eval-uation that allows comparison of different systemsin the same generation task.3 Lexical Constraints for HumorousWord SubstitutionThe procedure gets as input a segment of Englishtext (e.g.
: ?Let everything turn well in your life!?
).Then it performs a single word substitution (e.g:?life??
?wife?
), and returns the resulting text.
Tomake it funny, the word replacement is performedaccording to a number of lexical constraints, to bedescribed below.
Additionally, the text can be ap-pended with a phrase such as ?I mean ?life?
not?wife?.?
The task of humor generation is thus re-duced to a task of lexical selection.
The adoptedtask for humor generation is an extension of theone described by Valitutti (2011).We define three types of lexical constraints forthis task, which will be described next.3.1 Form ConstraintsForm constraints (FORM) require that the originalword and its substitute are similar in form.
Thisturns the text given as input into a kind of pun,?text which relies crucially on phonetic similarityfor its humorous effect?
(Ritchie, 2005).Obviously, simply replacing a word potentiallyresults in a text that induces ?conflict?
(and con-fusion) in the audience.
Using a phonetically sim-ilar word as a replacement, however, makes thestatement pseudo-ambiguous, since the originalintended meaning can also be recovered.
Therethen are two ?conflicting?
and ?contrasting?
inter-pretations ?
the literal one and the original one ?increasing the likelihood of humorous incongruity.Requiring the substitute to share part-of-speechwith the original word works in this direction too,and additionally increases the likelihood that theresulting text is a valid English statement.244Implementation We adopt an extended defini-tion of punning and also consider orthographicallysimilar or rhyming words as possible substitutes.Two words are considered orthographicallysimilar if one word is obtained with a single char-acter deletion, addition, or replacement from theother one.We call two words phonetically similar if theirphonetic transcription is orthographically similaraccording to the above definition.Two words rhyme if they have same positions oftonic accent, and if they are phonetically identicalfrom the most stressed syllable to the end of theword.Our implementation of these constraints usesthe WordNet lexical database (Fellbaum, 1998)and CMU pronunciation dictionary1.
The lat-ter also provides a collection of words not nor-mally contained in standard English dictionaries,but commonly used in informal language.
This in-creases the space of potential replacements.
Weuse the TreeTagger2 POS tagger in order to con-sider only words with the same part-of-speech ofthe word to be replaced.3.2 Taboo ConstraintTaboo constraint (TABOO) requires that the sub-stitute word is a taboo word or frequently usedin taboo expressions, insults, or vulgar expres-sions.
Taboo words ?represent a class of emo-tionally arousing references with respect to bodyproducts, body parts, sexual acts, ethnic or racialinsults, profanity, vulgarity, slang, and scatology?
(Jay et al, 2008), and they directly introduce ?in-appropriateness?
to the text.Implementation We collected a list of 700taboo words.
A first subset contains words man-ually selected from the domain SEXUALITY ofWordNet-Domains (Magnini and Cavaglia`, 2000).A second subset was collected from the Web, andcontains words commonly used as insults.
Finally,a third subset was collected from a website post-ing examples of funny autocorrection mistakes3and includes words that are not directly referringto taboos (e.g.
: ?stimulation?)
or often retrieved in1available at http://www.speech.cs.cmu.edu/cgi-bin/cmudict2available at http://www.ims.unistuttgart.de/projekte/corplex/TreeTagger3http://www.damnyouautocorrect.comjokes evoking taboo meanings (e.g.
: ?wife?
).3.3 Contextual ConstraintsContextual constraints (CONT) require that thesubstitution takes place at the end of the text, andin a locally coherent manner.By local coherence we mean that the substituteword forms a feasible phrase with its immediatepredecessor.
If this is not the case, then the textis likely to make little sense.
On the other hand,if this is the case, then the taboo meaning is po-tentially expanded to the phrase level.
This in-troduces a stronger semantic ?contrast?
and thusprobably contributes to making the text funnier.The semantic contrast is potentially even strongerif the taboo word comes as a surprise in the endof a seemingly innocent text.
The humorous effectthen is similar to the one of the forced reinterpre-tation jokes.Implementation Local coherence is imple-mented using n-grams.
In the case of languagesthat are read from left to right, such as English,expectations will be built by the left-context of theexpected word.
To estimate the level of expecta-tion triggered by a left-context, we rely on a vastcollection of n-grams, the 2012 Google Books n-grams collection4 (Michel et al, 2011) and com-pute the cohesion of each n-gram, by comparingtheir expected frequency (assuming word inde-pence), to their observed number of occurrences.A subsequent Student t-test allows to assign ameasure of cohesion to each n-gram (Doucet andAhonen-Myka, 2006).
We use a substitute wordonly if its cohesion with the previous word is high.In order to use consistent natural language andavoid time or location-based variations, we fo-cused on contemporary American English.
Thuswe only used the subsection of Google bigramsfor American English, and ignored all the statis-tics stemming from books published before 1990.4 EvaluationWe evaluated the method empirically usingCrowdFlower5, a crowdsourcing service.
The aimof the evaluation is to measure the potential effectof the three types of constraints on funniness oftexts.
In particular, we test the potential effect of4available at http://books.google.com/ngrams5available at http://www.crowdflower.com245adding the tabooness constraint to the form con-straints, and the potential effect of further addingcontextual constraints.
I.e., we consider three in-creasingly constrained conditions: (1) substitutionaccording only to the form constraints (FORM),(2) substitution according to both form and tabooconstraints (FORM+TABOO), and (3) substitutionaccording to form, taboo and context constraints(FORM+TABOO+CONT).One of the reasons for the choice of taboo wordsas lexical constraint is that they allows the systemto generate humorous text potentially appreciatedby young adults, which are the majority of crowd-sourcing users (Ross et al, 2010).
We applied thehumor generation method on the first 5000 mes-sages of NUS SMS Corpus6, a corpus of real SMSmessages (Chen and Kan, 2012).We carried out every possible lexical replace-ment under each of the three conditions mentionedabove, one at a time, so that the resulting mes-sages have exactly one word substituted.
We thenrandomly picked 100 such modified messages foreach of the conditions.
Table 1 shows two exampleoutputs of the humor generator under each of thethree experimental conditions.
These two exam-ples are the least funny and the funniest messageaccording to the empirical evaluation (see below).For evaluation, this dataset of 300 messageswas randomly divided into groups of 20 mes-sages each.
We recruited 208 evaluators usingthe crowdsourcing service, asking each subject toevaluate one such group of 20 messages.
Eachmessage in each group was judged by 90 differentparticipants.We asked subjects to assess individual messagesfor their funniness on a scale from 1 to 5.
For theanalysis of the results, we then measured the effec-tiveness of the constraints using two derived vari-ables: the Collective Funniness (CF) of a messageis its mean funniness, while its Upper Agreement(UA(t)) is the fraction of funniness scores greaterthan or equal to a given threshold t. To rank thegenerated messages, we take the product of Col-lective Funniness and Upper Agreement UA(3)and call it the overall Humor Effectiveness (HE).In order to identify and remove potential scam-mers in the crowdsourcing system, we simplyasked subjects to select the last word in the mes-6available at http://wing.comp.nus.edu.sg/SMSCorpussage.
If a subject failed to answer correctly morethan three times all her judgements were removed.As a result, 2% of judgments were discarded asuntrusted.
From the experiment, we then havea total of 26 534 trusted assessments of mes-sages, 8 400 under FORM condition, 8 551 un-der FORM+TABOO condition, and 8 633 underFORM+TABOO+CONT condition.The Collective Funniness of messages in-creases, on average, from 2.29 under con-dition FORM to 2.98 when the taboo con-straint is added (FORM+TABOO), and further to3.20 when the contextual constraints are added(FORM+TABOO+CONT) (Table 2).
The UpperAgreement UA(4) increases from 0.18 to 0.36 andto 0.43, respectively.We analyzed the distributions of CollectiveFunniness values of messages, as well as thedistributions of their Upper Agreements (forall values from UA(2) to UA(5)) under thethree conditions.
According to the one-sidedWilcoxon rank-sum test, both Collective Funni-ness and all Upper Agreements increase fromFORM to FORM+TABOO and from FORM+TABOOto FORM+TABOO+CONT statistically significantly(in all cases p < .002).
Table 3 shows p-valuesassociated with all pairwise comparisons.5 ConclusionsWe have proposed a new approach for the studyof computational humor generation by lexical re-placement.
The generation task is based on a sim-ple form of punning, where a given text is modi-fied by replacing one word with a similar one.We proved empirically that, in this setting, hu-mor generation is more effective when using a listof taboo words.
The other strong empirical re-sult regards the context of substitutions: using bi-grams to model people?s expectations, and con-straining the position of word replacement to theend of the text, increases funniness significantly.This is likely because of the form of surprise theyinduce.
At best of our knowledge, this is the firsttime that these aspects of humor generation havebeen successfully evaluated with a crowdsourcingsystem and, thus, in a relatively quick and eco-nomical way.The statistical significance is particularly high,even though there were several limitations in theexperimental setting.
For example, as explainedin Section 3.2, the employed word list was built246Experimental Condition Text Generated by the System CF UA(3) HEFORM Oh oh...Den muz change plat liao...Go back have yan jiu again... 1.68 0.26 0.43Not ?plat?...
?plan?.FORM Jos ask if u wana melt up?
?meet?
not ?melt?!
2.96 0.74 2.19FORM+TABOO Got caught in the rain.Waited half n hour in the buss stop.
2.06 0.31 0.64Not ?buss?...?bus?
!BASE+TABOO Hey pple... $ 700 or $ 900 for 5 nights...Excellent masturbation 3.98 0.85 3.39wif breakfast hamper!!!
Sorry I mean ?location?FORM+TABOO+CONT Nope...Juz off from berk...
Sorry I mean ?work?
2.25 0.39 0.87FORM+TABOO+CONT I?ve sent you my fart..
I mean ?part?
not ?fart?...
4.09 0.90 3.66Table 1: Examples of outputs of the system.
CF: Collective Funniness; UA(3): Upper Agreement; HE:Humor Effectiveness.Experimental ConditionsFORM FORM+TABOO FORM+TABOO+CONTCF 2.29 ?
0.19 2.98 ?
0.43 3.20 ?
0.40UA(2) 0.58 ?
0.09 0.78 ?
0.11 0.83 ?
0.09UA(3) 0.41 ?
0.07 0.62 ?
0.13 0.69 ?
0.12UA(4) 0.18 ?
0.04 0.36 ?
0.13 0.43 ?
0.13UA(5) 0.12 ?
0.02 0.22 ?
0.09 0.26 ?
0.09Table 2: Mean Collective Funniness (CF) and Upper Agreements (UA(?))
under the three experimentalconditions and their standard deviations.HypothesesFORM?
FORM+TABOO FORM+TABOO?
FORM+TABOO+CONTCF 10?15 9?
10?5UA(2) 10?15 1?
10?15UA(3) 10?15 7?
10?5UA(4) 10?15 2?
10?4UA(5) 10?15 2?
10?3Table 3: P-values resulting from the application of one-sided Wilcoxon rank-sum test.from different sources and contains words not di-rectly referring to taboo meanings and, thus, notwidely recognizable as ?taboo words?.
Further-more, the possible presence of crowd-workingscammers (only partially filtered by the gold stan-dard questions) could have reduced the statisticalpower of our analysis.
Finally, the adopted humorgeneration task (based on a single word substitu-tion) is extremely simple and the constraints mighthave not been sufficiently capable to produce a de-tectable increase of humor appreciation.The statistically strong results that we obtainedcan make this evaluation approach attractive forrelated tasks.
In our methodology, we focused at-tention to the correlation between the parametersof the system (in our case, the constraints used inlexical selection) and the performance of humorgeneration.
We used a multi-dimensional mea-sure of humorous effect (in terms of funniness andagreement) to measure subtly different aspects ofthe humorous response.
We then adopted a com-parative setting, where we can measure improve-ments in the performance across different systemsor variants.In the future, it would be interesting to usea similar setting to empirically investigate moresubtle ways to generate humor, potentially withweaker effects but still recognizable in this set-ting.
For instance, we would like to investigatethe use of other word lists besides taboo domainsand the extent to which the semantic relatednessitself could contribute to the humorous effect.The current techniques can be improved, too,in various ways.
In particular, we plan to extendthe use of n-grams to larger contexts and considermore fine-grained tuning of other constraints, too.One goal is to apply the proposed methodologyto isolate, on one hand, parameters for inducingincongruity and, on the other hand, parameters formaking the incongruity funny.Finally, we are interested in estimating the prob-ability to induce a humor response by using differ-ent constraints.
This would offer a novel way tointentionally control the humorous effect.247ReferencesS.
Attardo and V. Raskin.
1991.
Script theory re-vis(it)ed: joke similarity and joke representationmodel.
Humour, 4(3):293?347.J.
Beattie.
1971.
An essay on laughter, and ludicrouscomposition.
In Essays.
William Creech, Edinburgh,1776.
Reprinted by Garland, New York.K.
Binsted, H. Pain, and G. Ritchie.
1997.
Children?sevaluation of computer-generated punning riddles.Pragmatics and Cognition, 2(5):305?354.T.
Chen and M.-Y.
Kan. 2012.
Creating a live, publicshort message service corpus: The nus sms corpus.Language Resources and Evaluation, August.
pub-lished online.A.
Doucet and H. Ahonen-Myka.
2006.
Probabilityand expected document frequency of discontinuedword sequences, an efficient method for their exactcomputation.
Traitement Automatique des Langues(TAL), 46(2):13?37.C.
Fellbaum.
1998.
WordNet.
An Electronic LexicalDatabase.
The MIT Press.J.
H. Goldstein, J. M. Suls, and S.Anthony.
1972.
En-joyment of specific types of humor content: Moti-vation or salience?
In J. H. Goldstein and P. E.McGhee, editors, The psychology of humor: The-oretical perspectives and empirical issues, pages159?171.
Academic Press, New York.T.
Jay, C. Caldwell-Harris, and K. King.
2008.
Recall-ing taboo and nontaboo words.
American Journal ofPsychology, 121(1):83?103, Spring.M.
Levison and G. Lessard.
1992.
A system for nat-ural language generation.
Computers and the Hu-manities, 26:43?58.B.
Magnini and G. Cavaglia`.
2000.
Integrating sub-ject field codes into wordnet.
In Proc.
of the 2nd In-ternational Conference on Language Resources andEvaluation (LREC2000), Athens, Greece.R.
A. Martin.
2007.
The Psychology of Humor: AnIntegrative Approach.
Elsevier.J.
McKay.
2002.
Generation of idiom-based witticismsto aid second language learning.
In (Stock et al,2002).J.-B.
Michel, Y. K. Shen, A. P. Aiden, A. Veres,M.
K. Gray, The Google Books Team, J. P. Pick-ett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant,S.
Pinker, M. A. Nowak, and E. L. Aiden.
2011.Quantitative analysis of culture using millions ofdigitized books.
Science, 331(6014):176?182.V.
Raskin and S. Attardo.
1994.
Non-literalness andnon-bona-fide in language: approaches to formaland computational treatments of humor.
Pragmat-ics and Cognition, 2(1):31?69.V.
Raskin.
1985.
Semantic Mechanisms of Humor.Dordrecht/Boston/Lancaster.G.
Ritchie.
2002.
The structure of forced interpretationjokes.
In (Stock et al, 2002).G.
Ritchie.
2005.
Computational mechanisms for pungeneration.
In Proceedings of the 10th EuropeanNatural Language Generation Workshop, Aberdeen,August.J.
Ross, I. Irani, M. S. Silberman, A. Zaldivar, andB.
Tomlinson.
2010. Who are the crowdworkers?
:Shifting demographics in amazon mechanical turk.In Proc.
of the ACM CHI Conference.O.
Stock and C. Strapparava.
2002.
HAHAcronym:Humorous agents for humorous acronyms.
In (Stocket al, 2002).O.
Stock, C. Strapparava, and A. Nijholt, editors.
2002.Proceedings of the The April Fools Day Workshopon Computational Humour (TWLT20), Trento.H.
Summerfelt, L. Lippman, and I. E. Hyman Jr.2010.
The effect of humor on memory: Constrainedby the pun.
The Journal of General Psychology,137(4):376?394.A.
Valitutti.
2011.
How many jokes are really funny?towards a new approach to the evaluation of com-putational humour generators.
In Proc.
of 8th Inter-national Workshop on Natural Language Processingand Cognitive Science, Copenhagen.C.
Venour.
1999.
The computational generation of aclass of puns.
Master?s thesis, Queen?s University,Kingston, Ontario.248
