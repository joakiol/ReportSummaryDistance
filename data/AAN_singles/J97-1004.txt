Developing and Empirically EvaluatingRobust Explanation Generators: TheKNIGHT ExperimentsJ ames  C. Lester"North Carolina State UniversityBruce W. Porter*University of Texas at AustinTo explain complex phenomena, n explanation system must be able to select information from aformal representation f domain knowledge, organize the selected information into multisenten-tial discourse plans, and realize the discourse plans in text.
Although recent years have witnessedsignificant progress in the development ofsophisticated computational mechanisms for explana-tion, empirical results have been limited.
This paper eports on a seven-year effort o empiricallystudy explanation generation from semantically rich, large-scale knowledge bases.
In particular,it describes KNIGHT, a robust explanation system that constructs multisentential nd multi-paragraph explanations from the Biology Knowledge Base, a large-scale knowledge base in thedomain of botanical anatomy, physiology, and development.
We introduce the Two-Panel evalua-tion methodology and describe how KNIGHT'S performance was assessed with this methodology inthe most extensive mpirical evaluation conducted on an explanation system.
In this evaluation,KNIGHT scored within "half a grade" of domain experts, and its performance exceeded that of oneof the domain experts.1.
IntroductionIn the course of their daily affairs, scientists explain complex phenomena--both toone another and to lay people--in a manner that facilitates clear communication.
Sim-ilarly, physicians, lawyers, and teachers are equally facile at generating explanationsin their respective areas of expertise.
In an effort to computationalize this critical abil-ity, research in natural anguage generation has addressed a broad range of issuesin automatically constructing text from formal representations of domain knowledge.Research on text planning (Hovy 1993; Maybury 1992; McCoy 1989, 1990; McKeown1985; Paris 1988) has developed techniques for determining the content and organi-zation of many genres, and explanation generation (Cawsey 1992; McKeown, Wish,and Matthews 1985; Moore 1995) in particular has been the subject of intense investi-gation.
In addition to exploring a panorama of application domains, the explanationcommunity has begun to assemble these myriad designs into a coherent framework.As a result, we have begun to see a crystalization of the major components, as wellas detailed analyses of their roles in explanation (Suthers 1991).Despite this success, empirical results in explanation generation are limited.
Al-though techniques for developing and evaluating robust explanation generation shouldyield results that are more conclusive than those produced by prototype, "proof-of-* Department of Computer Science, Box 8206, North Carolina State University, Raleigh, NC 27695-8206.E-marl: lester@adm.csc.ncsu.edut Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712-1188.
E-mail:porter@cs.utexas.edu(~) 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 1concept" systems, with only a few notable xceptions (Cawsey 1992; Hovy 1990; Ku-kich 1983; Mittal 1993; Robin 1994), most work has adopted aresearch methodology inwhich a proof-of-concept system is constructed and its operation is analyzed on a fewexamples.
While isolating one or a small number of problems enables researchers toconsider particular issues in detail, it is difficult o gauge the scalability and robustnessof a proposed approach.A critical factor contributing to the dearth of empirical results is the absence ofsemantically rich, large-scale knowledge bases (KBs).
Knowledge bases housing tensof thousands of different concepts and hundreds of different relations could furnishample raw materials for empirical study, but no work in explanation generation hasbeen conducted or empirically evaluated in the context of these knowledge bases.To empirically study explanation generation from semantically rich, large-scaleknowledge bases, we undertook a seven-year experiment.
First, our domain experts(one employed full-time) constructed the Biology Knowledge Base (Porter et al 1988),a very large structure representing more than 180,000 facts about botanical anatomy,physiology, and development.
Second, we designed, implemented, and empiricallyevaluated KNIGHT (Lester 1994), a robust explanation system that extracts informationfrom the Biology Knowledge Base, organizes it, and realizes it in multisentential andmultiparagraph expository explanations of complex biological phenomena.
Third, wedeveloped a novel evaluation methodology for gauging the effectiveness of explana-tion systems and employed this methodology to evaluate KNIGHT.This paper describes the lessons learned during the course of the "KNIGHT ex-periments."
In the spirit of EDGE (Cawsey 1992) and PAULINE (Hovy 1990), whichsynthesize work in interactive xplanation systems and generational pragmatics, re-spectively, KNIGHT addresses a broad range of issues, all in the context of semanticallyrich, large-scale knowledge bases:?
Robust Knowledge-Base Access: KNIGHT exploits a library of robustknowledge-base access methods that insulate discourse planners fromthe idiosyncracies and errors in knowledge bases.
These "viewconstruction" methods electively extract coherent packets ofpropositions about the structure and function of objects, the changesmade to objects by processes, and the temporal attributes and temporaldecompositions of processes.?
Discourse-Knowledge Engineering: Discourse-knowledge engineers, i.e.,knowledge ngineers who encode discourse knowledge, should be ableto inspect and easily modify discourse-planning specifications for rapiditerative refinement.
The Explanation Design Package (EDP) formalismis a convenient, schema-like (McKeown 1985; Paris 1988) programminglanguage for text planning.
Because the EDP formalism is a hybrid of thedeclarative and procedural paradigms, discourse-knowledge engineerscan easily understand EDPs, modify them, and use them to representnew discourse knowledge.
EDPS have been used by KNIGHT to generatehundreds of expository explanations ofbiological objects and processes.?
Explanation Planning: KNIGHT employs a robust explanation planner thatselects EDPS and applies them to invoke knowledge-base accessors.
Theexplanation planner considers the desired length of explanations and therelative importance of subtopics as it constructs explanation plansencoding content and organization.?
Functional Realization: KNIGHT's functional realization system (Callaway66Lester and Porter Robust Explanation Generatorsand Lester 1995) is built on top of a unification-based surface generatorwith a large systemic grammar (Elhadad 1992).To assess KNIGHT'S performance, we developed the Two-Panel evaluation meth-odology for natural anguage generation and employed it in the most extensive andrigorous empirical evaluation ever conducted on an explanation system.
In this study,KNIGHT constructed explanations on randomly chosen topics from the Biology Knowl-edge Base.
A panel of domain experts was instructed to produce explanations onthese same topics, and both KNIGHT'S explanations and the explanations produced bythis panel were submitted to a second panel of domain experts.
The second panelthen graded all of the explanations on several dimensions with an A-F scale.
KNIGHTscored within approximately half a grade of the domain experts, and its performanceexceeded that of one of the domain experts.This paper is structured as follows: The task of explanation generation is charac-terized and the Biology Knowledge Base is described.
A brief description of KNIGHT'sknowledge-base access methods is followed by (1) a description of the EDP language,(2) KNIGHT'S explanation planner, and (3) an overview of the realization techniques.The empirical evaluation is then discussed in some detail.
The paper concludes withdiscussions of related work and future research directions.2.
The Task of Explanation GenerationExplanation generation is the task of extracting information from a formal represen-tation of knowledge, imposing an organization on it, and realizing the informationin text.
An explanation system must be able to map from a formal representation fdomain knowledge (i.e., one which can be used for automated reasoning, such asthe predicate calculus) to a textual representation f domain knowledge.
Because ofthe significant differences in formal and textual representational schemes, successfullybridging the gap between them is one of the major challenges faced by an explanationsystem.To communicate complex ideas, an explanation system should be able to produceextended explanations such as those in Figure 1, which shows several explanationsproduced by KNIGHT from the domain of botanical anatomy, physiology, and devel-opment.
Note that each of these is a multisentential explanation; the first is a multi-paragraph explanation.
These explanations are expository: in contrast o causal expla-nations produced by automated reasoning systems, expository explanations describedomain phenomena, such as anatomical structures and physiological processes.Explanation generation is typically decomposed into two subtasks, explanationplanning and realization.
Explanation planning itself has two subtasks: content deter-ruination, in which knowledge structures are extracted from a knowledge base, andorganization, in which the selected knowledge structures are arranged in a manner ap-propriate for communication i natural anguage.
To perform these tasks successfully,an explanation planner must have access to discourse knowledge, which informs its de-cisions about the content and organization of textual explanations.
The organizationalaspect of discourse knowledge plays a particularly important role in the constructionof extended explanations.
Our work focuses on content determination and organiza-tion and de-emphasizes issues in realization.
However, to more cleanly evaluate theexplanation planning work, we have developed a robust realization system that isbuilt on FUF (Elhadad 1992), a unification-based implementation of a large systemicgrammar.67Computational Linguistics Volume 23, Number 1Question: What happens during embryo sac formation?Response: Embryo sac formation is a kind of female gametophyte formation.During embryo sac formation, the embryo sac is formed from themegaspore mother cell.
Embryo sac formation occurs in the ovule.Embryo sac formation is a step of angiosperm sexual reproduction.It consists of megasporogenesis and embryo sac generation.During megasporogenesis, themegaspore mother cell divides in thenucellus to form 4 megaspores.
During embryo sac generation, theembryo sac is generated from the megaspore.Question: What happens during pollen tube growth?Response: Pollen tube growth is a step of angiosperm sexual reproduction.It consists of sperm cell generation and sperm cell transport.During sperm cell generation, the pollen generative cell dividesto form 2 angiosperm sperm cells.
During sperm cell transport, 2angiosperm sperm cells are transported from the pollen tube to theembryo sac.Question: What is a spore?Response: The spore is a kind of haploid cell.
4 spores are produced from thespore mother cell during sporogenesis.
The spore divides to form 2plant gametes during gametogenesis.
Gametogenesis is a step ofgametophyte d velopment.Question: What is a root system?Response: The root system is part of the plant and is connected to themainstem.
It is below the hypocotyl and is surrounded by therhizosphere.
The subregions of the root system include themeristem, which is where root system growth occurs.Figure 1Explanations produced by K NIGHT from the Biology Knowledge Base.2.1 Evaluation Criteria and DesiderataEvaluating the performance ofexplanation systems i a critical and nontrivial problem.Although gauging the performance of explanation systems is inherently difficult, fiveevaluation criteria can be applied.?
Coherence: A global assessment of the overall quality of the explanationsgenerated by a system.?
Content: The extent o which the information is adequate and focused.?
Organization: The extent o which the information is well organized.68Lester and Porter Robust Explanation Generators?
Writing style: The quality of the prose.?
Correctness: For scientific explanations, the extent o which theexplanations are in accord with the established scientific record.In addition to performing well on the evaluation criteria, if explanation systemsare to make the difficult transition from research laboratories to field applications,we want them to exhibit two important properties, both of which significantly af-fect scalability.
First, these systems' representation f discourse knowledge should beeasily inspected and modified.
To develop explanation systems for a broad range ofdomains, tasks, and question types, discourse-knowledge engineers must be able tocreate and efficiently debug the discourse knowledge that drives the systems' behavior.The second property that explanation systems hould exhibit is robustness.
Despitethe complex and possibly malformed representational structures that an explanationsystem may encounter in its knowledge base, it should be able to cope with thesestructures and construct reasonably well-formed explanations.2.2 Semantically Rich, Large-Scale Knowledge BasesGiven the state of the art in explanation generation, the field is now well positionedto explore what may pose its greatest challenge and at the same time may result in itshighest payoff: generating explanations from semantically rich, large-scale knowledgebases.
Large-scale knowledge bases encode information about domains that cannotbe reduced to a small set of principles or axioms.
For example, the field of humananatomy and physiology encompasses a body of knowledge so immense that manyyears of study are required to assimilate only one of its subfields, such as immunology.Large-scale knowledge bases are currently being constructed for many applications,and the ability to generate xplanations from these knowledge bases for a broad rangeof tasks such as education, design, and diagnosis is critical.Large-scale knowledge bases whose representations are semantically rich are par-ticularly intriguing.
These knowledge bases consist of highly interconnected networksof (at least) tens of thousands of facts.
Hence, they represent information not onlyabout a large number of concepts but also about a large number of relationshipsthat hold between the concepts.
One such knowledge base is the Biology KnowledgeBase (Porter et al 1988), an immense structure ncoding information about botanicalanatomy, physiology, and development.
One of the largest knowledge bases in exis-tence, it is encoded in the KM frame-based knowledge representation language.
1 KMprovides the basic functionalities of other frame-based representation languages andis accompanied by a graphical user interface, KNED, for entering, viewing, and editingframe-based structures (Eilerts 1994).The backbone of the Biology Knowledge Base is its taxonomy, which is a largehierarchical structure of biological objects and biological processes.
In addition to theobjects and processes, the taxonomy includes the hierarchy of relations that may ap-pear on concepts.
The relation taxonomy provides a useful organizing structure forencoding information about "second order" relations, i.e., relations among all of thefirst order relations.Figure 2 depicts the Biology Knowledge Base's representation of embryo sac for-mation.
This is a typical fragment of its semantic network.
Each of the nodes in thisnetwork is a concept, e.g., megaspore mother cell, which we refer to as a unit or a frame.1 A detailed escription ofthe semantics ofthe representation la guage may be found in Chapter 2 of(Acker 1992).69Computational Linguistics Volume 23, Number 1IAepr?duD"?nlspec ~ ir Si~ aametophytel I Plant Sexual Gametophyte Format on \] Reproduction Generationspecl r--- -~, spec/ spec~spec i Fem ae_Gametopvhyte ~Car)ell ~,t, F?rmati?nx I part-of \[An~?d#erdr~cSoexual I I F e m al(~eGear a~eot ?
Ph Yt e \[, Sporogenesis , ~ ~ - ~ /  ~/ specX \]contains / ,/ ~ ~ / subevent spec \ // x Iooat,oy \/ MeoasDore formed-from ?
Embryo Sacl formed .
~ \e r-'~?l ~ : P l ?
c a ~  4Figure 2A representation fembryo sac formation.Each of the arcs is a relation in the knowledge base.
For example, the location for em-bryo sac formation is the concept ovule.
We refer to these relations as slots or attributesand to the units that fill these slots, e.g., ovule, as values.
In addition, we call a struc-ture of the form (Unit Slot Value) a triple.
The Biology Knowledge Base currentlycontains more than 180,000 explicitly represented triples, and its deductive closure issignificantly larger.We chose biology as a domain for three reasons.
First, it required us to grapplewith difficult representational problems.
Unlike a domain such as introductory geom-etry, biology cannot be characterized by a small set of axioms.
Second, biology is nota "single-task" subject.
Unlike the knowledge bases of conventional expert systems,e.g., MYCIN (Buchanan and Shortliffe 1984), the Biology Knowledge Base is not com-mitted to any particular task or problem-solving method.
Rather, it encodes generalknowledge that can support diverse tasks and methods such as tutoring students,performing diagnosis, and organizing reference materials.
For example, in additionto its use in explanation generation, it has been used as the basis for an automatedqualitative model builder (Rickel and Porter 1994) for qualitative reasoning.
Finally,we chose biology because of the availability of local domain experts at the Universityof Texas at Austin.It is important to note that the authors and the domain experts entered into a "con-tractual agreement" with regard to representational structures in the Biology Knowl-edge Base.
To eliminate all requests for representational modifications that would skewthe knowledge bas e to the task of explanation generation, the authors entered into thisagreement: hey could request representational changes only if knowledge was incon-70Lester and Porter Robust Explanation Generatorssistent or missing.
This facilitated a unique experiment in which the representationalstructures were not tailored to the task of explanation generation.3.
Accessing Semantically Rich, Large-Scale Knowledge BasesTo perform well, an explanation system must select from a knowledge base preciselythat information eeded to answer users' questions with coherent and complete xpla-nations.
Given the centrality of content determination for explanation generation, it isinstructive to distinguish two types of content determination, both of which play keyroles in an explanation system's behavior: Local content determination is the selectionof relatively small knowledge structures, each of which will be used to generate oneor two sentences; global content determination is the process of deciding which ofthese structures to include in an explanation.There are two benefits of interposing a knowledge-base-accessing ystem betweenan explanation planner, which performs global content determination, and a knowl-edge base.
First, it keeps the explanation planner at arm's length from the repre-sentation of domain knowledge, thereby making the planner less dependent on theparticular epresentational conventions of the knowledge base and more robust in theface of errors.
In addition, it can help build explanations that are coherent.
Studies ofcoherence have focused on one aspect of coherence, cohesion, which is determinedby the overall organization and realization of the explanation (Grimes 1975; Hallidayand Hassan 1976; Hobbs 1985; Joshi and Weinstein 1981).
However, the question "Toinsure coherence, how should the content of individual portions of an explanationbe selected?"
is equally important.
Halliday and Hassan (1976) term this aspect ofcoherence semantic unity.
There are at least two approaches to achieving semanticunity: either "packets" of propositions must be directly represented in the domainknowledge, or a knowledge-base-accessing ystem must be able to extract them atruntime.One type of coherent knowledge packet is a view.
For example, the concept pho-tosynthesis can be viewed as either a production process or an energy transductionprocess.
Viewed as production, it would be described in terms of its raw materialsand products: "During photosynthesis, a chloroplast uses water and carbon dioxideto make oxygen and glucose."
Viewed as energy transduction, it would be describedin terms of input energy forms and output energy forms: "During photosynthesis, achloroplast converts light energy to chemical bond energy."
The view that is taken ofa concept has a significant effect on the content hat is selected for its description.
Ifan explanation system could (a) invoke a knowledge-base-accessing ystem to selectviews, and (b) translate the views to natural anguage (Figure 3), it would be well onits way to producing coherent explanations.As a building block for the KNIGHT explanation system, we designed and im-plemented a robust KB-accessing system that extracts views (Acker 1992; McCoy 1989;McKeown, Wish, and Matthews 1985; Souther et al, 1989; Swartout 1983; Suthers 1988,1993) of concepts represented in a knowledge base.
Each view is a coherent subgraphof the knowledge base describing the structure and function of objects, the changemade to objects by processes, and the temporal attributes and temporal decomposi-tions of processes.
Each of the nine accessors in our library (Table 1) can be appliedto a given concept (the concept of interest) to retrieve a view of that concept.
Thereare three classes of accessors: those that are applicable to all concepts (As-Kind-Of andFunctional), those that are applicable to objects (Partonomic-Connection and Substruc-tural), and those that are applicable to processes (Auxiliary-Process--which includes71Computational Linguistics Volume 23, Number 1ViewAccess RequestKnowledge Base Access~I ~(~n~ raw-material iChlor!pPl~icer pr?duct ~I-INatural Language Generation I I"During photosynthesis, water and carbon dioxide are converted by the chloroplast into xygen and glucose.
"Figure 3Accessing and translating a view of photosynthesis.Causal, Modulatory, Temporal, and Locational subtypes--Participants, Core-Connection, 2Subevent, and Temporal-Step).
In addition to these "top level" accessors, the library alsoprovides a collection of some 20 "utility" accessors that extract particular aspects ofviews previously constructed by the system.
3To illustrate, the Participants accessor extracts information about he "actors" of thegiven process.
For example, some of the actors in the photosynthesis process are chloro-plasts, light, chlorophyll, carbon dioxide, and glucose.
By specifying a reference process--the second argument of the Participants accessor--the external agent can request aviewof the process from the perspective of the reference process.
For example, if the systemapplies the Participants accessor with photosynthesis as the concept of interest and pro-duction as the reference process, then the accessor will extract information about theproducer (chloroplast), the raw materials (water and carbon dioxide), and the products(oxygen and glucose).
In contrast, if the system applies the Participants accessor withphotosynthesis as the concept of interest but with energy transduction as the referenceprocess, then it would extract information about the transducer (chlorophyll), the en-ergy provider (a photon), the input energy form (light), and the output energy form(chemical bond energy).
By selecting different reference concepts, different informationabout a particular process will be returned.In addition to coherence, robustness i an important design criterion.
We definerobustness as the ability to gracefully cope with the complex representational struc-2 The Core-Connection accessor determines the relation between a process and a core concept.
A coreconcept is one which is particularly central to a domain.
For example, in biology, processes such as"development" and "reproduction" play central roles in many physiological explanations.
During thedesign of a KB-accessing system, the domain-knowledge engineer selects the core concepts and flagsthese concepts in the knowledge base.3 For a more comprehensive d scription of the accessors, ee Lester (1994).72Lester and Porter Robust Explanation GeneratorsTable 1Library of knowledge-base accessors.KB accessor Arguments Description of ViewAs-Kind-Of concept Finds view of concept as a kind ofreference reference concept.Auxiliary-Process process Finds temporal, causal, or locationalview-type information about process as specified byview-type.Participants process Finds "actor-oriented" view of process asreference viewed from the perspective of referenceprocess.Core-Connection process Finds the connection between processand a "core" process.Functional object Finds functional view ofprocess object with respect to process.Partonomic- object Finds the connection from object o aConnection "superpart" ofthe object in the"partonomy.
"Subevent processSubstructural objectTemporal-Step processFinds view of "steps" of process.Finds structural view of parts of object.Finds view of process with respect toanother process of which process is a"step.
"tures encountered in large-scale knowledge bases without failing (halting execution).The KB accessors achieve robust performance in four ways:?
Omission Toleration: They do not assume that essential information willactually appear on a given concept in the knowledge base.?
Type Checking: They employ a type-checking system that exploits theknowledge base's taxonomy.?
Error Handling: When they detect an irregularity, they return appropriateerror codes to the explanation planner.?
Term Accommodation: They tolerate specialized (and possiblyunanticipated) representational vocabulary by exploiting the relationtaxonomy.The following four techniques operate in tandem to achieve robustness.
First, tocope with knowledge structures that contain additional, unexpected information, theKB accessors were designed to behave as "masks."
When they are applied to partic-ular structures in a knowledge base, the accessors mask out all attributes that theywere not designed to seek.
Hence, they are unaffected by inappropriate attributes thatwere installed on a concept erroneously.
Second, sometimes a domain-knowledge en-gineer installs inappropriate values on legal attributes.
When the accessors encounterattributes with inappropriate values, they prevent fatal errors from occurring by em-ploying a rigorous type-checking system.
For example, suppose a domain-knowledgeengineer had erroneously installed an object as one of the subevents of a process.The type-checking system detects the problem.
Third, when problems are detected,the nature of the error is noted and reported to the explanation planner.
Because the73Computational Linguistics Volume 23, Number 1planner can reason about the types of problems, it can properly attend to them byexcising the offending content from the explanation it is constructing.
The KB accessorlibrary currently uses more than 25 different error codes to report error conditions.For example, it will report no superevent available if the "parent" event of a processhas not been included.
Fourth, the KB accessors exhibit immunity to modificationsof the representational vocabulary by the domain-knowledge engineer.
For example,given an object, the Substructural accessor inspects the object to determine its parts.Rather than merely examining the attribute parts on the given object, the Substructuralaccessor examines all known attributes that bear the parts relation to other objects.These attributes include has basic unit, layers, fused parts, and protective components.
TheSubstructural ccessor recognizes that each of these attributes are partonomic relationsby exploiting the knowledge base's relation taxonomy.By using these techniques together, we have developed a KB-accessing system thathas constructed several thousand views without failing.
Moreover, the view types onwhich the accessors are based performed well in a preliminary empirical study (Ackerand Porter 1994), and evaluations of the KB accessors' ability to construct coherentviews, as measured by domain experts' ratings of KNIGHT'S explanations (Section 8),are encouraging.4.
A Programming Language for Discourse KnowledgeSince the time of Aristotle, a central tenet of rhetoric has been that a rich structureunderlies text.
This structure shapes a text's meaning and assists its readers in deci-phering that meaning.
For almost wo decades, computational linguists have studiedthe problem of automatically inducing this structure from a given text.
Research inexplanation planning addresses the inverse problem: automatically creating this struc-ture by selecting facts from a knowledge base and subsequently using these facts toproduce text.
To automatically construct explanation plans (trees that encode the hier-archical structure of texts, as well as their content \[Grosz and Sidner 1986; Mann andThompson 1987\]), an explanation system must possess discourse knowledge (knowl-edge about what characterizes a clear explanation).
This discourse knowledge nablesit to make decisions about what information to include in its explanations and howto organize the information.It is important to emphasize the following distinction between discourse knowl-edge and explanation plans: discourse knowledge specifies the content and organiza-tion for a class of explanations, e.g., explanations of processes, whereas explanationplans specify the content and organization for a specific explanation, e.g., an expla-nation of how photosynthesis produces ugar.
Discourse-knowledge engineers buildrepresentations of discourse knowledge, and this discourse knowledge is then usedby a computational module to automatically construct explanation plans, which arethen interpreted by a realization system to produce natural anguage.The KB-accessing system described above possesses discourse knowledge in theform of KB accessors.
Applying this discourse knowledge, the system retrieves viewsfrom the knowledge base.
Although this ability to perform local content determina-tion is essential, it is insufficient; given a query posed by a user, the generator mustbe able to choose multiple KB accessors, provide the appropriate arguments to theseaccessors, and organize the resulting views.
Hence, in addition to discourse knowl-edge about local content determination, an explanation system that produces multi-paragraph explanations must also possess knowledge about how to perform globalcontent determination and organization.
This section sets forth two design require-ments for a representation f discourse knowledge, desclibes the Explanation Design74Lester and Porter Robust Explanation GeneratorsPackage formalism, which was designed to satisfy these requirements, and discusseshow EDPs can be used to encode discourse knowledge.4.1 Requirements for a Discourse-Knowledge RepresentationOur goal is to develop a representation of discourse knowledge that satisfies tworequirements: It should be expressive, and it should facilitate fficient representation fdiscourse knowledge by discourse-knowledge engineers.
4 Each of these considerationsare discussed in turn, followed by a representation that satisfies these criteria.Expressiveness.
A representation f discourse knowledge must permit discourse-know-ledge engineers to state how an explanation planner should:?
select propositions from a knowledge base by extracting views,?
control the amount of detail in an explanation, i.e., if a user requests thatterse explanations be generated, the explanation planner should selectonly the most important propositions,?
consider contextual conditions when determining which propositions toinclude,?
order the propositions, and?
group the propositions into appropriate segments, e.g., paragraphs.The first three aspects of expressiveness are concerned with content determina-tion.
To effectively express what content should be included in explanations, a rep-resentation of discourse knowledge should enable discourse-knowledge engineers toencode specifications about how to choose propositions about particular topics, theimportance of those topics, and ufider what conditions the propositions associatedwith the topics should be included.
These "inclusion conditions" govern the circum-stances under which the explanation planner will select particular classes of propo-sitions from the knowledge base when constructing an explanation.
For example, adiscourse-knowledge engineer might express the rule: "The system should communi-cate the location of a process if and only if the user of the system is familiar with theobject where the process occurs."
As the explanation planner uses this knowledge toconstruct a response, it can determine if the antecedent of the rule ("the user of thesystem is familiar with the object where the process occurs") is satisfied by the currentcontext; if the antecedent is satisfied, then the explanation planner can include in theexplanation the subtopics associated with the rule's consequent.The final two aspects of expressiveness (ordering and grouping of propositions)are concerned with organization.
To encode organizational knowledge, a representa-tion of discourse knowledge should permit discourse-knowledge engineers to encodetopic/subtopic relationships.
For example, the subtopics of a process description mightinclude (1) a categorical description of the process (describing taxonomically what kindof process it is), (2) how the actors of the process interact, and (3) the location of theprocess.A representation should be sufficiently expressive that it can be used to encodethe kinds of discourse knowledge discussed above, and it should be applicable to4 While expressiveness and knowledge engineering are the criteria we address, others are also ofconsiderable importance, e.g., soundness and completeness of discourse planners.75Computational Linguistics Volume 23, Number 1representing discourse knowledge for a broad range of discourse genres and domains.However, discourse knowledge does not specify what syntactic structure to imposeon a sentence, nor does it lend any assistance in making decisions about matters uchas pronominalization, ellipsis, or lexical choice.
These decisions are delegated to therealization system.Discourse-Knowledge Engineering.
For a given query type, domain, and task, a discourse-knowledge ngineer must be able to represent the discourse knowledge needed by anexplanation system for responding to questions of that type in that domain about thattask.
Pragmatically, to represent discourse knowledge for a broad range of queries,domains, and tasks, a formalism must facilitate efficient representation f discourseknowledge.
Kittredge, Korelsky, and Rarnbow (1991) have observed that representingnew domain-dependent discourse knowledge--they term it domain communicationknowledge--is required to create advanced iscourse generators, e.g., those for spe-cial purpose report planning.
Therefore, ease of creation, modification, and reuse areimportant goals for the design of a discourse formalism.
For example, to build anexplanation system for the domain of physics, a discourse-knowledge engineer couldeither build an explanation system de novo or modify an existing system.
On theface of it, the second alternative involves less work and is preferable, but designingexplanation systems that can be easily modified is a nontrivial task.
In the case ofphysics, a discourse-knowledge engineer may need to modify an existing explanationsystem so that it can produce xplanations appropriate for mathematical explanations.To do so, the discourse-knowledge engineer would ideally take an off-the-shelf expla-nation generator and add discourse knowledge about how to explain mathematicalinterpretations of the behavior of physical systems.
Because of the central role playedby discourse-knowledge engineers, a representation f discourse knowledge shouldbe designed to minimize the effort required to understand, modify, and represent newdiscourse knowledge.4.2 Explanation Design PackagesExplanation Design Packages emerged from an effort to accelerate the representationof discourse knowledge without sacrificing expressiveness.
Our previous explanationgenerators employed a representation f discourse knowledge that was coded directlyin Lisp (Lester and Porter 1991a, 1991b).
Although this approach worked well forsmall prototype xplanation systems, it proved unsatisfactory for building fully func-tioning explanation systems.
In particular, it was very difficult to maintain and extenddiscourse knowledge xpressed irectly in code.Although EDPs are more schema-like than plan-based approaches and consequentlydo not permit an explanation system to reason about the goals fulfilled by particulartext segments, 5 they have proven enormously successful for discourse-knowledge en-gineering.
EDPs give discourse-knowledge engineers an appropriate set of abstractionsfor specifying the content and organization of explanations.
They combine a frame-based representation language with embedded procedural constructs.
To mirror thestructure of expository texts, an EDP contains a hierarchy of nodes, which provides theglobal organization of explanations.
EDPs are schema-like (McKeown 1985; Paris 1988)structures that include constructs found in traditional programming languages.
Justas prototypical programming languages offer conditionals, iterative control structures,and procedural abstraction, EDPS offer discourse-knowledge engineers counterparts of5 See Section 9for a discussion ofthis disadvantage.76Lester and Porter Robust Explanation GeneratorsTable 2EDP node attributes.Node TypeExpositionAttributesChildrenAttribute Value(s)<Topics)Topic ChildrenCentralityInclusion ConditionLocal Variables(Content Specifications){Low, Medium, High}<Variable Boolean Expression)((Var) , <Variable Expr.})
PairsContentSpecificationChildrenContent SpecificationTemplateIteration TypeIterate-OverTemplateLoop VariableIteration ConditionLocal Variables{ <Content Spec's), (Elaborations) }<Variable Expressionwith KB Accessor){Non-Iter., Iter., Conditional-Iter.
}<Variable Expression)(Var><Variable Boolean Expression)((Var} , <Variable Expr.>) PairsElaboration ChildrenCentralityInclusion ConditionLocal Variables(Content Specifications){Low, Medium, High}<Variable Boolean Expression)((Var} , <Variable Expr.))
Pairsthese constructs that are precisely customized for explanation-planning.
6 Moreover,each EDP names multiple KB accessors, which are invoked at explanation-planningtime.Because EDPS are frame-based, they can be easily viewed and edited by knowledgeengineers using the graphical tools commonly associated with frame-based languages.The EDP formalism has been implemented in the KM frame-based knowledge repre-sentation language, which is the same representational l nguage used in the BiologyKnowledge Base.
Because KM is accompanied by a graphical user interface, discourse-knowledge ngineers are provided with a development environment that facilitatesEDP construction.
This has proven to be very useful for addressing a critical problem inscaling up explanation generation: maintaining a knowledge base of discourse knowl-edge that can be easily constructed, viewed, and navigated by discourse-knowledgeengineers.EDPs have several types of nodes, where each type provides a particular set of at-tributes to the discourse-knowledge engineer (Table 2).
Note that content specificationnodes may have elaboration odes as their children, which in turn may have theirown content specification odes.
This recursive appearance of content specificationnodes permits a discourse-knowledge engineer to construct arbitrarily deep trees.
Ingeneral, a node of a particular type in an EDP is used by the explanation planner toconstruct a corresponding node in an explanation plan.
We discuss the salient aspectsof each type of node below.
7Exposition Nodes.
An exposition ode is the top-level unit in the hierarchical structureand constitutes the highest-level grouping of content.
For example, the exposition6 EDPs are Turing-equivalent.7 Representational details of EDPs are discussed in (Lester 1994).77Computational Linguistics Volume 23, Number 1node of the Explain-Process EDP has four children, Process Overview, Output-Actor-Fates,Temporal Info, and Process Details, each of which is a topic node.
Both the order andgrouping of the topic nodes named in an exposition ode are significant.
The orderspecifies the linear left-to-right organization of the topics, and the grouping specifiesthe paragraph boundaries.
The content associated with topic nodes that are groupedtogether will appear in a single paragraph in an explanation.Topic Nodes.
Topic nodes are subtopics of exposition odes, and each topic node in-cludes a representation of the conditions under which its content should be addedto an explanation.
Topic nodes have the atomic inclusion property, which enablesan explanation planner to make an "atomic" decision about whether to include--orexclude--all of the content associated with a topic node.
Atomicity permits discourse-knowledge ngineers to achieve coherence by demanding that the explanation plannereither include or exclude all of a topic's content.
At runtime, if the explanation plannerdetermines that inclusion conditions are not satisfied or if a topic is not sufficientlyimportant given space limitations (see below), it can comprehensively eliminate allcontent associated with the topic.An important aspect of discourse knowledge is the relative importance of subtopicswith respect to one another.
If an explanation's length must be limited--such as when auser has employed the verbosity preference parameter to request erse explanations--an explanation planner should be able to decide at runtime which propositions to in-clude.
EDPS permit discourse-knowledge engineers to specify the relative importanceof each topic by assigning a qualitative value (Low, Medium, or High) to its centralityattribute.Another important aspect of representing discourse knowledge is the ability toencode the conditions under which a group of propositions hould be included in anexplanation.
Discourse-knowledge engineers can express these inclusion conditionsas predicates on the knowledge base and on a user model (if one is employed).
Forexample, he or she should be able to express the condition that the content associ-ated with the Output-Actor-Fates topic should be included only if the process beingdiscussed is a conversion process.
Inclusion conditions are expressed as Boolean ex-pressions that may contain both built-in user modeling predicates and user-definedfunctions.Content Speci~cation Nodes.
Content specification odes house the high-level specifi-cations for extracting content from the knowledge base.
To fulfill this function, theyprovide constructs known as content specification expressions.
These expressions areinstantiated at runtime by the explanation planner, which then dispatches the knowl-edge base accessors named in the expressions to extract propositions from the knowl-edge base.
Content specification expressions reside in content specification odes, asin Figure 4.
When creating content specification expressions, the discourse-knowledgeengineer may name any knowledge base accessor in the KB accessor library.
For ex-ample, the Super-Structural Connection content specification in Figure 4 names a KBaccessor called Find-Partonomic-Connection, and the Process Participants Description con-tent specification ames the Make-Participants-View accessor.Although the discourse-knowledge engineer may write arbitrarily complex speci-fication expressions in which function invocations are deeply nested, these expressionscan become difficult to understand, debug, and maintain.
Just as other programminglanguages provide local variables, e.g., the binding list of a le t  statement in Lisp, sodo content specification odes.
Each time a discourse-knowledge engineer creates alocal variable, he or she creates an expression for computing the value of the local78Lester and Porter Robust Explanation GeneratorsSuper-Structural ConnectionContent-Specifications: NILIteration-Type: Non-lterativeContent-Specification-Template:((Find--Partonomic-Connection'?Primary-Concept))Participants Process DescriptionContent-Specifications: NILIteration-Type: Non-lterativeContent-Specification-Template:((Make-Participants-View'?Primary-Concept'?Reference-ProcessLocal-Variables:((?Reference-Process(Find-Ref-Conc'?Primary-Concept)))Figure 4Example content specification nodes.variable at runtime.
For example, the Process Participants Description content specifica-tion in Figure 4 employs a local variable ?Reference-Process.
The content specificationexpression associated with ?Reference-Process names the KB accessor Find-Ref-Conc andthe global variable ?Primary-Concept.
Local variables provide a means of decomposingmore complex content specification expressions into simpler ones.Elaboration Nodes.
Elaboration odes specify optional content that may be included inexplanations.
They are structurally and functionally identical to topic nodes, i.e., theyhave exactly the same attributes, and the children of elaboration odes are contentspecifications.
The distinction between elaboration odes and topic nodes is main-tained only as a conceptual id to discourse-knowledge engineers: it stands as a re-minder that topic nodes are used to specify the primary content of explanations, andelaboration nodes are used to specify supplementary content.4.3 Developing Task-Specific EDPsA discourse-knowledge engineer can use EDPS to encode discourse knowledge forhis or her application.
In our work, we focused on two types of texts that occur inmany domains: process descriptions and object descriptions.
For example, in biology,one encounters many process-oriented descriptions of physiological nd reproductivemechanisms, as well as many object-oriented descriptions of anatomy.
In the courseof our research, we informally reviewed numerous (on the order of one hundred)passages in several biology textbooks.
These passages focused on explanations of theanatomy, physiology, and reproduction of plants.
Some explanations were very terse(e.g., those that occurred in glossaries), whereas ome were more verbose (e.g., mul-tipage explanations of physiological processes).
Most of the texts also contained in-formation about other aspects of botany, such as experimental methods and historicaldevelopments; hese were omitted from the analysis.
We manually "parsed" each pas-sage into an informal language of structure, function, and process which is commonlyfound in the discourse literature; see Mann and Thompson (1987), McKeown (1985),Paris (1988), Souther et al (1989), and Suthers (1988), for example.
Our final step wasto generalize the most commonly occurring patterns into abstractions that covered asmany aspects of the passages as possible, which we then encoded in two ExplanationDesign Packages.
While this work was essential for gaining insights about biologicaltexts, it was a sketchy and preliminary effort to informally characterize their contentand organization.
A promising line of future work is to construct a large corpus of79Computational Linguistics Volume 23, Number 1parsed discourse through a formal analysis.
This will enable the natural anguagegeneration community to begin making inroads into producing discourse in the samemanner that corpus-based techniques have aided discourse understanding efforts.The EDPs resulting from the analysis, Explain-Process and Explain-Object, can beused by an explanation planner to generate xplanations about the processes and ob-jects of physical systems.
While these EDPS enable an explanation planner to generatequality explanations, we conjecture that employing a large library of specialized EDPSwould produce explanations of higher quality.
For the same reason that Kittredge,Korelsky, and Rambow (1991) note that domain-dependent discourse knowledge iscritical for special purpose discourse generation, it appears that including EDPS specificto describing particular classes of biological processes (e.g., development and repro-duction), would yield explanations whose content and organization better mirror thatof explanations produced by domain experts.
8Although we will not discuss the details of the EDPs here, it is instructive toexamine their structure and function.
The Explain-Process EDP (Figure 5) can be usedby the explanation planner to generate xplanations about the processes that physicalobjects engage in.
For example, given a query about how a biological process suchas embryo sac formation is carried out, the explanation planner can apply the Explain-Process EDP to construct an explanation plan that houses the content and organizationof the explanation.
The Explain-Process EDP has four primary topics:?
Process Overview: Explains how a process fits into a taxonomy, discussesthe role played by its actors, and discusses where it occurs.?
Process Details: Explains the steps of a process.?
Temporal Attributes: Explains how a process is related temporally to otherprocesses.?
Output-Actor-Fates: Discusses how the "products" of a process are usedby other processes.As computational linguists have known for many years, formally characterizingtexts is a very difficult, time-consuming, and error-prone process.
Because any initialdiscourse representation effort must, by necessity, be considered only a beginning, thenext step was to incrementally revise the EDPs.
The EDPs were used to automaticallyconstruct hundreds of explanations: the explanation planner used the EDPs to con-struct explanation plans, and the realization system translated these plans to naturallanguage.The resulting explanations were presented to our domain expert, who critiquedboth their content and organization, and we used these critiques to incrementally re-vise the EDPs.
The majority of revisions involved the reorganization and removal ofnodes in the EDPs.
For example, the domain expert consistently preferred a differ-ent global organization than the one encoded in the original Explain-Process EDP.
Healso preferred explanations produced by a version of the Explain-Process EDP in whichthe information that had previously been associated with a Process Significance topicwas associated with the Temporal Attributes topic.
Moreover, he found that an ActorElaborations node produced information that was "intrusive."
Some revisions involved8 While we have not explored this hypothesis in the work described here, the EDP framework can beused to test it empirically.80Lester and Porter Robust Explanation GeneratorsExpositionNodeTopicNodesExplainProcessProcessOverviewOutput ActorFates Topic Tempoml Info TopicContentNodes Output ActorsIterationProcessDetailsOutput ActorFates Iteration Subevent / LSubeventDescriptionIterationAs-Kind-OfProcess Location Description Temporal Step OfParticipantsProcessDescriptionOutput Actor / Temporal Function Subevent Connections \ Participants ContentSpec.
Content Spec.ElaborationNodes Location /PartonomicConnectionContentSpecificatonNodesloca, iooPart.
Conn.Content Spec.Figure 5The final version of the Explain-Process explanation design.modifications to particular attributes of the nodes.
For example, the inclusion con-dition on the original Output-Actor-Fates opic was TRUE.
Instead, the domain expertpreferred for explanations to include the content associated with this topic only whenthe process being described was a "conversion" process.
After approximately twentypasses through the critiquing and revision phases, EDPs were devised that producedclear explanations meeting with the domain expert's approval.5.
Planning ExplanationsExplanation planning is the task of determining the content and organization of ex-planations.
We have designed an architecture for explanation generation and imple-mented a full-scale explanation generator, KNIGHT, 9 based upon this architecture.9 All of the explanation planning algorithms, as well as the KB accessors, were implemented in LucidCommon Lisp on a DEC Station 5000.81Computational Linguistics Volume 23, Number 15.1 An Architecture for Explanation GenerationExplanation generation begins when the user poses a query, which includes averbosityspecification that comes in the form of a qualitative rating expressing the desired lengthof the explanation (Figure 6).
The query interpreter--whose capabilities have been ad-dressed only minimally in our work--translates the query to a canonical form, which ispassed, along with the verbosity specification, to the explanation planner.
Explanationplanning is a synthetic task in which multiple resources are consulted to assemble datastructures that specify the content and organization of explanations.
KNIGHT's expla-nation planner uses the following resources: the Biology Knowledge Base, ExplanationDesign Packages, the KB-accessing system, and an overlay user model.
1?The explanation planner invokes the EDP Selector, which chooses an ExplanationDesign Package from the EDP library.
The explanation planner then applies the EDP bytraversing its hierarchical structure.
For each node in the EDP, the planner determinesif it should construct a counterpart node in the explanation plan it is building.
(Recallthat the topic nodes and elaboration odes of an EDP are instantiated only when theirconditions are satisfied.)
As the plan is constructed, the explanation planner updatesthe user model to reflect he contextual changes that will result from explaining theviews in the explanation plan, attends to the verbosity specification, and invokes KBaccessors to extract information from the knowledge base.
Recall that the accessorsreturn views, which are subgraphs of the knowledge base.
The planner attaches theviews to the explanation plan; they become the plan's leaves.
Planning is completewhen the explanation planner has traversed the entire EDP.The planner passes the resulting explanation plan to the realization component(Section 6) for translation to natural anguage.
The views in the explanation plan aregrouped into paragraph clusters.
After some "semantic polishing" to improve thecontent for linguistic purposes, the realization component translates the views in theexplanation plan to sentences.
The realization system collects into a paragraph all ofthe sentences produced by the views in a particular paragraph cluster.
Explanationgeneration terminates when the realization component has translated all of the viewsin the explanation plan to natural anguage.5.2 The Explanation-Planning AlgorithmsThe EXPLAIN algorithm (Figure 7) is supplied with a query type (e.g., Describe-Process),a primary concept (e.g., embryo sac formation), and a verbosity specification (e.g., High).Its first step is to select an appropriate EDP.
The EDP library has an indexing structurethat maps a query type to the EDP that can be used to generate explanations for queriesof that type.
This indexing structure permits EDP selection to be reduced to a simplelook-up operation.
For example, given the query type Describe-Process, the EDP Selectorwill return the Explain-Process Explanation Design Package.
The planner is now in aposition to apply the selected EDP to the knowledge base.
The APPLY EDP algorithmtakes four arguments: the exposition ode of the EDP that will be applied, a newlycreated exposition ode, which will become the root of the explanation plan that willbe constructed, the verbosity specification, and the loop variable bindings.
11The planner first locates the root of the selected EDP, which is an exposition ode.Next, it creates the corresponding exposition ode for the soon-to-be-constructed ex-planation plan.
It then invokes the APPLY EDP algorithm, which is given the exposition10 As the planner constructs explanation plans, it consults an overlay user model (Carr and Goldstein1977).
KNIGHT's user-sensitive explanation generation is not addressed in this paper.
For a discussion ofthis work, see Lester and Porter (1991b) and Lester (1994).11 APPLY EDP is a recursive algorithm.
For top-level invocations, this latter parameter will always be ni l .82Lester and Porter Robust Explanation GeneratorsQueryVerbositySpecification~1 InteQr~retrYer 1Formal VerbosityQuery Specification~ ~  Explanation Knowledge Planner BaseSelector Applier Accessing ModuleEDP 1LibraryExplanationPlanNaturalLanguageExplanationRealizer ~UserModelI I  DKB AccessorLibraryKeyC) = EDP NodeO = EDP Node (Instantiated)\ [ \ ]  = KB Accessor\ [ \ ]  = ViewFigure 6 An architecture for explanation generation.83Computational Linguistics Volume 23, Number 1EXPLAIN (Query-Type, Concept, Verbosity)if legal-query (Query-Type, Concept, Verbosity) thenEDP ,-- select-edp (Query-Type)EDP-Exposition-Node ,-- get-root (EDP)New-Exposition-Node ~-- construct-node (EDP-Exposition-Node)Explanation-Plan ~ apply-edp (EDP-Exposition-Node,New-Exposition-Node, Verbosity, nil)Explanation-Leaves *-- linearize (Explanation-Plan)realize (Explanation-Leaves)Figure 7The EXPLAIN algorithm.node of the EDP to be applied, the newly created exposition ode that will become theroot of the explanation plan, the verbosity, and a list of the loop variable bindings.
12The APPLY EDP algorithm (Figure 8) and the algorithms it invokes traverse the hier-archical structure of the EDP to build an explanation plan.
Its first action is to obtainthe children of the EDP's exposition ode; these are the topic nodes of the EDP.
Foreach topic node, the EDP Applier constructs a new (corresponding) topic node for theevolving explanation plan.
The Applier must then weigh several factors in its decisionabout whether to include the topic in the explanation: inclusion, which is the inclusioncondition associated with the topic; centrality, which is the centrality rating that thediscourse-knowledge engineer has assigned to the topic; and verbosity, which is theverbosity specification supplied by the user.If the inclusion condition evaluates to FALSE, the topic should be excluded re-gardless of the other two factors.
Otherwise, the COMPUTE INCLUSION algorithm mustconsider the topic's importance and the amount of detail requested and will includethe topic in the following circumstances: the verbosity is High; the verbosity is Low butthe topic's centrality has been rated as High by the discourse-knowledge engineer; orthe verbosity is Medium and the topic's centrality has been rated as Medium or High.When the COMPUTE INCLUSION algorithm returns TRUE, the Applier obtains thechildren of the EDP's topic.
These are its content specification odes.
For each of thetopic's content specification odes, the Applier invokes the DETERMINE CONTENT al-gorithm, which itself invokes KB accessors named in the EDP's content specificationnodes.
This action extracts views from the knowledge base and attaches them to theexplanation plan.To determine the content of the information associated with elaboration odes,DETERMINE CONTENT invokes the APPLY EDP algorithm.
Because it was the APPLY EDPalgorithm that invoked DETERMINE CONTENT, this is a recursive call.
In this invocationof APPLY EDP--as opposed to the "top-level" invocation by the EXPLAIN algorithm--APPLY EDP is given an elaboration ode instead of a topic node.
By recursively in-voking APPLY EDP, DETERMINE CONTENT causes the planner to traverse the elaborationbranches of a content node.
The recursion bottoms out when the system encountersthe leaves of the EDP, i.e., content specification odes in the EDP that do not haveelaborations.Rather than merely returning a flat list of views, the EXPLAIN algorithm examinesthe paragraph specifications in the nodes of the EDP it applied.
The paragraph spec-12 The loop variable bindings are used for the EDPs' iteration construct.84Lester and Porter Robust Explanation GeneratorsAPPLY-EDP (EDP-Exposit-Node, New-Exposit-Node, Verbosity,Loop- Var-Bindings )Children-of -EDP-Exposition-Node,-- get-children (EDP-Exposition-Node)for each EDP-Topic-Node in EDP-Exposition-Node-Children doNew-Topic-Node *--- construct-node (EDP-Topic-Node)Inclusion-Condition-Expression *-- get-condition (EDP-Topic-Node)Instantiated-Inclusion-Condition*-- instantiate (Inclusion-Condition-Expression,E D P- Topic-Node,New-Topic-Node)Inclusion-Condition-Evaluation*-- eval (Instantiated-Inclusion-Condition)Centrality ,-- get-centrality (EDP-Topic-Node)Include-Topic?
~ compute-inclusion (I clusion-Condition-Evaluation,Centrality,Verbosity)if Include-Topic?
thenChildren-of-EDP-Topic-Node ~-- get-children (EDP-Topic-Node)for each EDP-Content-Specification-Nodein Children-of-EDP-Topic-Node dodetermine-content (EDP-Content-Speci~'cation-Node,New-Topic-Node,Verbosity,Loop- Var-B indings )Figure 8The EDP application algorithm.ifications of a given node organize the children of that node into paragraph clusters.The order of the paragraph clusters controls the global structure of the final textualexplanation; the order of the views in each paragraph cluster determines the orderof sentences in the final text.
13 Finally, the EXPLAIN algorithm passes the paragraphclusters to the REALIZE algorithm, which translates them to natural anguage.6.
RealizationThe explanation planner should be viewed as an automatic specification writer: itstask is to write specifications for the realization component,  which interprets the spec-ifications to produce natural language.
Although our work focuses on the design,construction, and evaluation of explanation planners, by constructing a full-scale nat-ural language generator, it becomes possible to conduct a "pure" empirical evaluationof explanation planners.
Without a realization component,  the plans produced by anexplanation planner would need to be manual ly translated to natural anguage, whichwould raise questions about the purity of the experiments.
We therefore designed andimplemented a full-scale realization component.
1413 The realization algorithm treats these groupings as suggestions that may be overridden in extenuatingcircumstances.14 During the past few years, we have developed a series of realization systems.
The first realizer, whichwas designed and implemented by the first author, was a template-based generator.
The secondrealizer, which was designed by Kathy Mitchell and the authors (Mitchell 1992), used the Penman(Mann 1983) surface generator.
The third realizer (Callaway and Lester 1995) is described briefly in thissection; it was developed by the first author and Charles Callaway.85Computational Linguistics Volume 23, Number 1((cat clause)(pro, ((type material) (lex ''reproduce'')))(patti, ((agent ((cat common)(lex '(spore'')(qualifier ((cat pp)(prep === ''from'')(np ((cut common)(lex '~cell'')(classifier ((cat noun-compound)(classifier === ''megaspore'')(head === ((mother")))(qualifier ((cat pp)(prep === ?
*in'')(np ((cat common)(lex 'Csporangium")))))))))))))(circum ((purpose ((cat clause) (position end)(keep-for no) (keep-in-order no)(pro, ((type material) (lex '(form")))(patti, ((agent ((semantics (partic agent semantics))))(affected ((cat common)(lex ('gamete'') (definite no)(classifier === ('plant'')(describer === CChaploid'')(cardinal ((value 4) (digit no)))))))))(time ((time-type ''during'')(cat common)(describer === "male" )(classifier === C'gmmetophyte'')(lex ''generation''))))))Figure 9A functional description.Realization can be decomposed into two subtasks: functional realization, con-structing functional descriptions from message specifications upplied by a planner;and surface generation, translating functional descriptions to text.
Functional descrip-tions encode both semantic information (case assignments) and structural information(phrasal constituent embeddings).
Syntactically, a functional description is a set of at-tribute and value pairs (a v) (collectively called a feature set), where a is an attribute(a feature) and v is either an atomic value or a nested feature set.
is To illustrate, Fig-ure 9 depicts a sample functional description.
The first line, (cat clause), indicatesthat what follows will be some type of verbal phrase, in this case a sentence.
Thesecond line contains the keyword pro,, which denotes that everything in its scopewill describe the structure of the entire verbal phrase.
The next structure comes underthe heading partic; this is where the thematic roles of the clause are specified.
In thisinstance, one thematic role exists in the main sentence, the agent (or subject), which isfurther defined by its lexical entry and a modifying prepositional phrase indicated bythe keyword qual i f ier .
The structure beginning with circum creates the subordinateinfinitival purpose clause.
It has two thematic roles, subject and object.
The subject hasa pointer to identify itself with the subject of the main clause while the object containsa typical noun phrase.
The feature set for the circum clause indicates the wide rangeof possibilities for placement of the clause as well as for introducing additional phrasalsubstructures into the purpose clause.To construct functional descriptions from views extracted from a knowledge base,KNIGHT employs a functional realization system (Callaway and Lester 1995).
Given a15 Functional descriptions may also employ syntactic sugar for purposes of legibility.86Lester and Porter Robust Explanation Generatorsview, the functional realizer uses its knowledge of case mappings, syntax, and lexicalinformation to construct a functional description, which it then passes to the FUFsurface generator.
The functional realizer consists of five principal components:.?
Lexicon: Physically distributed throughout the knowledge base; eachconcept frame has access to all of the lexical information relevant o itsown realization.?
Functional Description Skeleton Library: Contains a large number ofFunctional Description (FD) Skeletons, each of which encodes theassociated syntactic, semantic, and role assignments for interpreting aspecific type of message specification.?
Functional Description Skeleton Retriever: Charged with the task of selectingthe correct Functional Description Skeleton from the skeleton library.?
Noun Phrase Generator: Responsible for drawing lexical information fromthe lexicon to create a self-contained functional description representingeach noun phrase required by the FD-Skeleton processor.?
Functional Description Skeleton Processor: Gathers all of the availableinformation from the FD-Skeleton, the lexicon, and the noun phrasegenerator; produces the final functional description.When the functional realizer is given a view, its first task is to determine theappropriate FD-Skeleton to use.
Once this is accomplished, the FD-Skeleton is passedalong with the message specification to the FD-Skeleton processor.
The FD-Skeletonprocessor first determines if each of the essential descriptors is present; if any ofthese tests fail, it will note the deficiency and abort.
If the message is well-formed,the FD-Skeleton processor passes each realizable concept unit found on the messagespecification to the noun phrase generator, which uses the lexicon to create a functionaldescription representing each concept unit.
The noun phrase generator then returnseach functional description to the FD-Skeleton processor, which assigns case roles tothe (sub)functional descriptions.
The resulting functional description, which encodesthe functional structure for the entire content of the message specification, is thenpassed to the surface realizer.
Surface realization is accomplished by FUF (Elhadad1992).
Developed by Elhadad and his colleagues at Columbia, FUF is accompanied byan extensive, portable English grammar, which is "the result of five years of intensiveexperimentation in grammar writing" (p. 121) and is currently the largest "generationgrammar" in existence (Elhadad 1992).
Given a set of functional descriptions, FUFconstructs the final text.7.
Example BehaviorTo illustrate the behavior of the system, consider the concept of embryo sac formation.The semantic network in the Biology Knowledge Base that represents informationabout embryo sac formation was shown in Figure 2.
When KNIGHT is given the task ofexplaining this concept, 16 it applies the Explain-Process EDP as illustrated in Figure 5.KNIGHT first finds the topics of the Explain-Process exposition node, which areProcess Overview, Output-Actor-Fates, Temporal Information, and Process Details.
During16 In this example, KNIGHT is given a High verbosity specification.
Details of this example, as well as otherexamples, may be found in Chapter 4of (Lester 1994).87Computational Linguistics Volume 23, Number 1its traversal of this tree, it begins with Process Overview, which has a High centralityrating and an inclusion condition of TRUE.
KNIGHT executes the COMPUTE INCLUSIONalgorithm with the given verbosity of High, which returns TRUE, i.e., the informationassociated with the topic should be included.Hence, it now begins to traverse the children of this topic node, which are the As-Kind-Of-Process Description, Process Participants, and Location Description content speci-fication nodes.
For the As-Kind-Of Process Description, it computes a value for the localvariable ?Reference-Concept, which returns the valuefemalegametophyteformation.
It heninstantiates the content specification template on As-Kind-Of Process Description, whichit then evaluates.
This results in a call to the As-Kind-Of KB accessor, which producesa view.
The view produced in this execution will eventually be translated to the sen-tence, "Embryo sac formation is a kind of female gametophyte formation."
Similarly,KNIGHT instantiates the content specification expressions of Process Participants Descrip-tion and Location Description, which also cause KB accessors to be invoked; these alsoreturn views.
The first of these views will be used to produce the sentence, "Duringembryo sac formation, the embryo sac is formed from the megaspore mother cell," andthe second will produce the sentence, "Embryo sac formation occurs in the ovule.
"Next KNIGHT visits the Location Partonomic-Connection node, which is an elaborationof Location Description.
However, because its inclusion condition is not satisfied, thisbranch of the traversal halts.Next, KNIGHT visits each of the other topics of the Explain-Process exposition ode:Output-Actor-Fates, Temporal Information and Process Details.
When it visits the Output-Actor-Fates topic, the inclusion condition is not satisfied.
Because it was given a Highverbosity specification and the inclusion conditions are satisfied, both Temporal Informa-tion and Process Details are used to determine additional content.
The view constructedfrom Temporal Information will produce the sentence, "Embryo sac formation is a step ofangiosperm sexual reproduction," and the Process Details will result in the generation ofdescriptions of the steps of embryo sac formation, namely, megasporogenesis and em-bryo sac generation.
When the views in the resulting explanation plan (Figure 10) aretranslated to text by the realization system, KNIGHT produces the explanation shownin Figure 1.These algorithms have been used to generate xplanations about hundreds ofdifferent concepts in the Biology Knowledge Base.
For example, Section 2 shows otherexplanations generated by KNIGHT.
The explanation of pollen tube growth was producedby applying the Explain-Process EDP, and the explanations of spore and root system wereproduced by applying the Explain-Object EDP.8.
EvaluationTraditionally, research projects in explanation generation have not included empiricalevaluations.
Conducting a formal study with a generator has posed difficulties for atleast three reasons: the absence of large-scale knowledge bases; the problem of robust-ness; and the subjective nature of the task.
First, the field of explanation generationhas experienced a dearth of "raw materials."
The task of an explanation generator isthree-fold: to extract information from a knowledge base, to organize this information,and to translate it to natural anguage.
Unless an explanation generator has access toa sufficiently large knowledge base, the first step--and hence the second and third--cannot be carried out enough times to evaluate the system empirically.
Unfortunately,because of the tremendous cost of construction, large-scale knowledge bases are scarce.Second, even if large-scale knowledge bases were more plentiful, an explanationgenerator cannot be evaluated unless it is sufficiently robust o produce many explana-88Lester and Porter Robust Explanation GeneratorsProcessOverviewFigure 10An explanation plan for embryo sac formation: High verbosity.tions.
In very practical terms, a generator is likely to halt abruptly when it encountersunusual and unexpected knowledge structures; if this happens frequently, the systemwill generate too few explanations to enable a meaningful evaluation.
We conjecturethat most implemented explanation generators would meet with serious difficultieswhen applied to a large-scale knowledge base.Third, explanation generation is an ill-defined task.
It stands in contrast o a ma-chine learning task such as rule induction from examples.
Although one can easilycount the number of examples that an induction program classifies correctly, there isno corresponding objective metric for an explanation generator.
Ideally, we would liketo "measure" the coherence of explanations.
Although it is clear that coherence is ofparamount importance for explanation generation, there is no litmus test for it.Given these difficulties, how can one evaluate the architectures, algorithms, andknowledge structures that form the basis for an explanation generator?
The traditionalapproach as been to conduct an analytical evaluation of a system's architecture anddemonstrate hat it can produce well-formed explanations on a few examples.
Whilethis evaluation technique is important, it is not sufficient.
Three steps can be taken topromote better evaluation.
First, we can construct large-scale knowledge bases, suchas the Biology Knowledge Base.
Second, we can design and implement robust ex-planation systems that employ a representation f discourse knowledge that is easilymanipulable by discourse-knowledge engineers.
Third, to ensure that a knowledgebase is not tailored to the purposes of explanation generation, we can enter into a con-tractual agreement with knowledge ngineers; this eliminates all requests for represen-tational modifications that would skew the representation to the task of explanationgeneration.8.1 Experimental DesignThe Two-Panel evaluation methodology can be used to empirically evaluate naturallanguage generation work.
We developed this methodology, which involves two pan-89Computational Linguistics Volume 23, Number 1els of domain experts, to combat he inherent subjectivity of NLG: although multiplejudges will rarely reach a consensus, their collective opinion provides persuasive v-idence about the quality of explanations.
To ensure the integrity of the evaluationresults, a central stipulation of the methodology is that the following condition bemaintained throughout the study:Computer Blindness: None of the participants can be aware that sometexts are machine-generated or, for that matter, that a computer is inany way involved in the study.The methodology involves four steps:1.
Generation of explanations by computer.2.
Formation of two panels of domain experts.3.
Generation of explanations by one panel of domain experts.4.
Evaluation of all explanations by the second panel of domain experts.Each of these is discussed in turn.Explanation Generation: KNIGHT.
Because KNIGHT's operation is initiated when a userposes a question, the first task was to select he questions it would be asked.
To thisend, we combed the Biology Knowledge Base for concepts that could furnish topicsfor questions.
Although the knowledge base focuses on botanical anatomy, physiology,and development, i  also contains a substantial mount of information about biologicaltaxons.
Because this latter area is significantly less developed, we ruled out conceptsabout taxons.
In addition, we ruled out concepts that were too abstract (e.g., Object).We then requested KNIGHT to generate xplanations about he 388 concepts that passedthrough these filters.To thoroughly exercise KNIGHT'S organizational bilities, we were most interestedin observing its performance on longer explanations.
Hence, we eliminated explana-tions of concepts that were sparsely represented in the knowledge base.
To this end,we passed the 388 explanations through a "length filter": explanations that consistedof at least 3 sentences were retained; shorter explanations were disposed of.
17 Thisproduced 87 explanations, of which 48 described objects and 39 described processes.Finally, to test an equal number of objects and processes, we randomly chose 30 objectsand 30 processes.Two Panels of Domain Experts.
To address the difficult problem of subjectivity, we assem-bled 12 domain experts, all of whom were Ph.D. students or post-doctoral scientists inbiology.
Because we wanted to gauge KNIGHT's performance relative to humans, weassigned each of the experts to one of two panels: the Writing Panel and the JudgingPanel.
By securing the services of such a large number of domain experts, we wereable to form relatively large panels of 4 writers and 8 judges (Figure 11).
To promotehigh-quality human-generated xplanations, we assigned the 4 most experienced ex-perts to the Writing Panel.
The remaining 8experts were assigned to the Judging Panelto evaluate xplanations.17 A separate study would be to evaluate KNIGHT on very short (one-sentence and two-sentence)explanations.
However, this study would be an evaluation of how it behaves in the face of highlyincomplete knowledge rather than a fair head-to-head comparison with knowledgeable experts.90Lester and Porter Robust Explanation GeneratorsQuestions (60)=~ ~/~""  Biologist Biologist Biologist7 I I 1Explanations Explanations Explanations Explanations1Panel of JudgesBiologistExplanationsFigure 11Biologist Biologist Biologist Biologist Biologist Biologist Biologist BiologistEval!ationsThe Two-Panel methodology in the KNIGHT experiments.To minimize the effect of factors that might make it difficult for judges to compareKNIGHT's explanations with those of domain experts, we took three precautions.
First,we attempted to control for the length of explanations.
Although we could not imposehard constraints, we made suggestions about how long a typical explanation mightbe.
Second, to make the "level" of the explanations comparable, we asked writers tocompose xplanations for a particular audience, freshman biology students.
Third, sothat the general topics of discussion would be comparable, we asl<ed writers to focuson anatomy, physiology, and development.Explanation Generation: Humans.
To ensure that the difficulty of the concepts assignedto the writers were the same as those assigned to KNIGHT, the writers were given thetask of explaining exactly the same set of concepts that KNIGHT had explained.
Becausewe wanted to give writers an opportunity to explain both objects and processes, eachwriter was given an approximately equal number of objects and processes.
Each ofthe four writers was given 15 concepts to explain, and each concept was assigned toexactly one writer.
We then transcribed their handwritten explanations and put themand KNIGHT'S explanations into an identical format.
At this point, we had a pool of120 explanations: 60 of these pertained to objects (30 written by biologists and 30 by91Computational Linguistics Volume 23, Number 1KNIGHT), and the other 60 pertained to processes (also 30 written by biologists and 30by KNIGHT).Explanation Evaluation.
We then submitted the explanations to the panel of eight judges.The judges were not informed of the source of the explanations, and all of the explana-tions appeared in the same format.
Each judge was given 15 explanations to evaluate.Judges were asked to rate the explanations on several dimensions: overall quality andcoherence, content, organization, writing style, and correctness.
To provide judges witha familiar rating scale, they were asked to assign letters grades (A, B, C, D, or F) toeach explanation on each of the dimensions.
Because carefully evaluating multipledimensions of explanations i a labor-intensive task, time considerations required usto limit the number of explanations submitted to each judge.
Hence, we assigned eachjudge a set of 15 explanations.
(On average, each judge took an hour to evaluate 15 ex-planations.)
We assigned explanations to judges using an allocation policy that obeyedthe following four constraints:?
System-Human Division: Each judge received explanations that wereapproximately evenly divided between those that were produced byKNIGHT and those that were produced by biologists.?
Object-Process Division: Each judge received explanations that wereapproximately evenly divided between objects and processes.?
Single-Explanation Restriction: No judge received two explanations of thesame concept.
TM?
Multijudge Stipulation: The explanations written by each writer wereparceled out to at least two judges, i.e., rather than having one judgeevaluate one writer's explanations, that writer's explanations weredistributed among multiple judges.It is important to emphasize again that the judges were not made aware of the purposeof the experiment, nor were they told that any of the explanations were computer-generated.8.2 ResultsBy the end of the study, we had amassed a large volume of data.
To analyze it, weconverted each of the "grades" to their traditional numerical counterparts, i.e., A = 4,B = 3, C = 2, D = 1, and F = 0.
Next, we computed means and standard errors for bothKNIGHT'S and the biologists' grades.
We calculated these values for the overall qualityand coherence rating, as well as for each of the dimensions of content, organization,writing style, and correctness.
On the overall rating and on each of the dimensions,KNIGHT scored within approximately half a grade of the biologists (Table 3).
19Given these results, we decided to investigate the differences between KNIGHT'sgrades and the biologists' grades.
When we normalized the grades by defining an A tobe the mean of the biologists' grades, KNIGHT earned approximately 3.5 (a B+).
Com-paring differences in dimensions, KNIGHT performed best on correctness and content,not quite as well on writing style, and least well on organization.18 The purpose of this constraint is to promote immediate, nondeliberative r actions from the judges.
Analternate study would consist of judges consciously analyzing pairs of explanations to perform anexplicit comparative analysis.19 In the tables, :k denotes the standard error, i.e., the standard eviation of the mean.92Lester and Porter Robust Explanation GeneratorsTable 3Comprehensive analysis.Generator Overall Content Organization Writing CorrectnessKNIGHT 2.374-0.13 2.654-0.13 2.454-0.16 2.40?0.13 3.074-0.15Human 2.854-0.15 2.95+0.16 3.074-0.16 2.934-0.16 3.164-0.15Table 4Differences and significance.Overall Content Organization Writing CorrectnessDifference 0.48 0.30 0.62 0.53 0.09t statistic -2.36 -1.47 -2.73 -2.54 -0.42Significance 0.02 0.14 0.07 0.01 0.67Significant?
Yes No No Yes NoBecause the differences between KNIGHT and the biologists were narrow in somecases, we measured the statistical significance of these differences by running standardt-tests.
2?
KNIGHT's grades on the content; organization, and correctness dimensions didnot differ significantly from the biologists' (Table 4).
Of course, an insignificant differ-ence does not indicate that KNIGHT'S performance and the biologists' performance wasequivalent--an even larger sample size might have shown a significant difference--however, it serves as an indicator that KNIGHT'S performance approaches that of thebiologists on these three dimensions.To gauge how well KNIGHT generates explanations about objects--as opposed toprocesses--we computed means and standard errors for both KNIGHT's explanationsof objects and the biologists' explanations of objects.
We did the same for the ex-planations of processes.
For both objects and processes, KNIGHT scored within half agrade of the biologists.
Again, we measured the statistical significance of these dif-ferences.
Although there was a significant difference between KNIGHT and biologistson explanations of processes, KNIGHT and the biologists did not differ significantlyon explanations of objects (Tables 5 and 6).
A probable cause of this result lies in thedomain: in biology, process explanations are often more complex than object explana-tions, therefore making process explanations more challenging to generate.As a final test, we compared KNIGHT to each of the individual writers.
For a givenwriter, we assessed KNIGHT's performance relative to that writer: we compared thegrades awarded to KNIGHT and the grades awarded to the writer on explanationsgenerated in response to the same set of questions.
This analysis produced somesurprising results.
Although there were substantial differences between KNIGHT and"Writer 1," KNIGHT was somewhat closer to "Writer 2," it was very close to "Writer 3,"and its performance actually exceeded that of "Writer 4."
KNIGHT and Writers 2, 3,and 4 did not differ significantly (Table 7).20 All t-tests were unpaired, two-tailed.
The results are reported for a 0.05 level of confidence.93Computational Linguistics Volume 23, Number 1Table 5Explanation of objects.Generator GradeKNIGHT 2.65&0.19Human 2.93+0.19Difference 0.28t statistic -1.05Significance 0.30Significant?
NoTable 6Explanation of processes.Generator GradeKNIGHT 2.10+0.24Human 2.77+0.17Difference 0.67t statistic -2.23Significance 0.03Significant?
YesTable 7KNIGHT vs. individual writers.KNIGHT vs.
Writer 1 vs.
Writer 2 vs.
Writer 3 vs.
Writer 4KNIGHT 1.93i0.29 2.73+0.23 2.734-0.27 2.074-0.23Human 3.60?0.16 3.404-0.23 2.804-0.28 1.604-0.23Difference 1.67 0.67 0.07 0.47t statistic -5.16 -2.03 -0.17 1.42Significance 0.00 0.05 0.86 0.16Significant?
Yes No No No9.
Related WorkBy synthesizing a broad range of research in natural language generation, KNIGHTprovides a "start-to-finish" solution to the problem of automatically constructing ex-pository explanations from semantically rich, large-scale knowledge bases.
It intro-duces a new evaluation methodology and builds on the conceptual f ramework thathas evolved in the NLG community  over the past decade, particularly in techniquesfor knowledge-base access and discourse-knowledge representation.
We discuss eachof these in turn.Evaluation Methodologies.
With regard to evaluation, KNIGHT is perhaps most closely re-lated to five NLG projects that have been empirically evaluated: PAULINE (Hovy 1990),EDGE (Cawsey 1992), the Example Generator 21(Mittal 1993), ANA (Kukich 1983), and21 Mittal's system has no official name; we refer to it as "the Example Generator" for ease of reference.94Lester and Porter Robust Explanation GeneratorsSTREAK (Robin 1994).
By varying pragmatic information such as tone, Hovy enabledPAULINE to generate many different paragraphs on the same topic.
PAULINE'S textswere not formally analyzed by a panel of judges, and it did not produce texts on awide range of topics (it generated texts on only three different events).
However, thisproject is a significant achievement in terms of evaluation scale because of the sheernumber of texts it produced: PAULINE generated more than 100 different paragraphson the same subject.
In a second landmark evaluation, Cawsey undertook a study inwhich subjects were allowed to interact with her explanation generation system, EDGE(Cawsey 1992).
Subjects posed questions to EDGE about the operation of four circuits.Cawsey analyzed the system's behavior as the dialogues progressed, interviewed sub-jects, and used the results to revise the system.
Although EDGE does not include arealization system (other than simple templates) and it was not subjected to a tightlycontrolled, formal evaluation, it was sufficiently robust to be used interactively byeight subjects.The EXAMPLE GENERATOR (Mittal 1993), ANA (Kukich 1983), and STREAK (Robin1994) were each subjected to formal (quantitative) valuations.
Mittal developed andformally evaluated a generator that produced escriptions integrating text and exam-ples.
Rather than evaluating the explanations directly, subjects were given a quiz aboutthe concept under consideration.
22 The degree to which the experiments controlled forspecific factors, e.g., the effect of example positioning, example types, example com-plexity, and example order, is remarkable.
ANA and STREAK were both subjected toquantitative, corpus-based evaluations.
Kukich employed a corpus-based methodol-ogy to judge the coverage of ANA's knowledge structures.
STREAK, which constructssummaries of basketball games, is part of a larger effort by J. Robin, K. McKeown,and their colleagues at Columbia and Bellcore to develop robust document generationsystems (McKeown, Robin, and Kukich 1995).
It was evaluated with a corpus-basedstudy that produced estimates of STREAK's sublanguage coverage, extensibility, andthe overall effectiveness of its revision-based generation techniques.
Although neitherof these studies employed human judges to critique text quality, the rigor with whichthey were conducted has significantly raised the standards for evaluating enerationsystems.The relationship between the KNIGHT evaluation and those of its predecessors issummarized in Table 8.
KNIGHT, STREAK, and ANA were all evaluated formally, i.e.,quantitatively, while PAULINE and EDGE were evaluated informally.
The KNIGHT, EDGE,and EXAMPLE GENERATOR evaluations employed humans as judges, while the ANA andSTREAK evaluations had "artificial judges" in the form of corpora, and PAULINE wasevaluated without judges.
KNIGHT is the only system to have been evaluated in thecontext of a semantically rich, large-scale knowledge base.
KNIGHT is also the onlysystem to have been evaluated in a kind of restricted Turing test in which the qualityof its text was evaluated by humans in a head-to-head comparison against he textproduced by humans (domain experts) in response to the same set of questions.Knowledge-Base Access.
Several projects in explanation generation have exploited viewsto improve the quality of the explanations they provide.
The ADVISOR system (McKe-own, Wish, and Matthews 1985) represents views with a multiple-hierarchy knowledgebase.
ADVISOR infers a user's current goal from his or her most recent utterances anduses this goal to select a hierarchy from the multiple-hierarchy knowledge base.
The22 In a second analysis without human judges, the system developers compared selected features of theEXAMPLE GENERATOR'S output with text from textbooks and obtained encouraging results.95Computational Linguistics Volume 23, Number 1Table 8Evaluation methodologies.PAULINE EDGE EXAMPLE ANA STREAK KNIGHTGENERATORFormality Informal Informal Formal Formal Formal Formal"Judges" None Humans Humans Corpus Corpus HumansLarge-Scale KB?
No No No No No YesSystem vs. Human No No Indirect No No Yesselected view controls the content of the explanation and the reasoning that producedthat content.
In a similar vein, viewpoints in Swartout's XPLAIN (Swartout 1983) areannotations that indicate when to include a piece of knowledge in an explanation.It is preferable to construct (i.e., extract) views at runtime rather than encodingthem in a knowledge base.
If a KB-accessing system could dynamically construct views,the discourse-knowledge engineer would be freed from the task of anticipating allqueries and rhetorical situations and precompiling semantic units for each situation.KNIGHT, ROMPER (McCoy 1989), and Suthers' work (Suthers 1988, 1993) use thesetypes of views to determine the content of their explanations.
Once a perspectiveis selected, ROMPER includes in its explanations only those attributes whose saliencevalues are the highest.
In contrast o ROMPER'S views, which are domain specific, thatis, confined to the domain of financial securities, Suthers' and KNIGHT'S views aredomain independent.
Suthers set forth a set of views which can be used to selectcoherent subsets of domain knowledge: structural, functional, causal, constraint, andprocess.
He also developed a view retriever and a highly refined theory of explanationgeneration in which views play a significant role.
KNIGHT'S views are very similar toMcCoy's and Suthers' in that they define the relations and properties of a conceptthat are relevant when considering a concept from a viewpoint belonging to that viewtype (Acker 1992; Souther et al 1989).
They also provide four types of knowledge-baseaccess robustness, as discussed in Section 3.Discourse Generation.
Two principle mechanisms have been developed for generat-ing discourse: schemata and top-down planners.
23 McKeown's pioneering workon schemata marks the beginning of the "modern era" of discourse generation(McKeown 1985).
Schemata re ATN-like structures that represent naturally occurringpatterns of discourse.
For example, a schema for defining a concept includes instruc-tions to identify its superclass, to name its parts, and to list its attributes.
To constructan explanation plan, McKeown's TEXT system traverses the schemata nd sequentiallyinstantiates rhetorical predicates with propositions from a knowledge base.
Paris ex-tended schemata to generate descriptions of complex objects in a manner that is ap-propriate for the user's level of expertise (Paris 1988), and ROMPER's schemata includeinformation about the content of propositions to be selected, as well as their com-municative role.
Although schemata have been criticized because they lack flexibility,they successfully capture many aspects of discourse structure.An alternative to schemata is the top-down planning approach (Cawsey 1992;23 A third alternative, proposed by Sibun (1992), are short-range strategies that exploit relations uch asspatial proximity to guide the generator through the domain knowledge.
Though flexible, they do notaccount for extended explanations, which require a more global rhetorical structure.96Lester and Porter Robust Explanation GeneratorsHovy 1993; Maybury 1992; Moore 1995; Moore and Paris 1993; Suthers 1991).
24 Theoperators of two of these planning systems are based on Rhetorical Structure Theory(RST) (Mann and Thompson 1987).
Hovy's (1993) Structurer is a hierarchical plannerwhose operators instantiate relations from RST.
The Reactive Planner also uses RST-like operators.
However, unlike all of the preceding research--and unlike KNIGHT aswell--it offers sophisticated mechanisms for generating explanations in interactivecontexts (Moore 1995; Moore and Paris 1993).
Because the operators explicitly recordthe rhetorical effects achieved, and because the system records alternative operatorsit could have chosen, as well as assumptions it made about the user, the ReactivePlanner can respond to follow-up questions--even if they are ambiguous--in a prin-cipled manner.
A related approach as been taken by Cawsey in the EDGE system(Cawsey 1992).
EDGE has facilities for managing conversations, sousers may interruptthe system to ask questions, and EDGE can either answer the question immediately orpostpone its response.
Suthers (1991) has developed a sophisticated hybrid approachthat includes planning techniques as well as plan critics, simulation models, reorga-nization methods, and graph traversal.
By assembling these diverse mechanisms intoa single architecture, he demonstrates how the complexities of explanation planningcan be dealt with in a coherent framework.
The principal advantage of top-downplanners over schema-based generators i their ability to reason about the structure,content, and goals of explanations--as opposed to merely instantiating pre-existingplans embodied by schemata.KNIGHT'S EDPS are much more schema-like than plan-like.
Although EDPs haveinclusion conditions, which are similar to the constraint attribute of RST-based oper-ators, and they provide a centrality attribute, which enables KNIGHT to reason aboutthe inclusion of a topic if "space" is limited, EDPs do not in general permit KNIGHTto reason about the goals fulfilled by particular text segments as do plan-based sys-tems.
For example, if the expressions in an EDP'S inclusion condition are not satis-fied, KNIGHT cannot create a plan to satisfy them.
Moreover, although EDPs are effec-tive for generating explanations, achieving other communicative goals, for example,Correct-Misconception, may be beyond their capabilities.
Despite these drawbacks,EDPS have proven to be very useful as a discourse-knowledge engineering tool, a resultthat can be attributed in large part to their combining a frame-based representationwith procedural constructs.
In a sense, EDPs are schemata whose representation hasbeen fine-tuned to maximize ease of use on a large scale.10.
Future DirectionsResearch on KNIGHT suggests everal directions for future work.
First, the results ofthe evaluation call for further analysis and experimentation.
For example, an in-depthanalysis at the discourse, sentential, and lexical levels of all of the texts produced byboth the humans and the system may reveal which characteristics of the highly ratedtexts are desirable.
These in turn can be used to improve the EDPS.
On the empiricalside, a particularly intriguing kind of experiment is an ablation study.
In an ablationstudy, different aspects of the system are ablated (removed or degraded), and theeffects of the ablation on the explanations are noted.
By performing a series of theseexperiments, one can determine which aspects of the system and its representationalstructures contribute most significantly to its success.24 The planning approach, which has dominated the field for the past few years, can be traced to Appelt'swork on planning referring expressions (Appelt 1985), which itself builds on earlier work on reasonirlgabout speech acts in a planning paradigm (Cohen and Perrault 1979).97Computational Linguistics Volume 23, Number 1Second, although EDPS were employed successfully in the generation of hundredsof explanations, the fact that they have more in common with schemata than withthe operators of top-down planners is indicative of a fundamental limitation: theintentional structure of the discourse is unavailable for inference.
As a result, it isconsiderably more difficult for the system to respond to follow-up questions, reasonabout paragraph structure, perform goal-based content determination, and producediscourse cues.
This calls for the incorporation ofan intentional structure into EDPs, butmodifying EDPs to represent intention must be accomplished in a way that preservesthe "discourse-knowledge engineering" properties and does not sacrifice text quality.Moreover, KNIGHT currently employs very rudimentary pronominalization techniques.Including more sophisticated methods (Dale 1992), perhaps in concert with an inten-tional structure, should result in a significant increase in text quality.Third, the issue of portability is of considerable interest.
Porting to another domainand/or task will involve three steps.
First, after the domain knowledge has beenrepresented, a discourse-knowledge engineer will develop EDPS that are appropriatefor the new domain and task.
Second, the realization system must be extended byadding new Functional Description Skeletons.
Third, the lexicon must be created.
It isour hypothesis that because EDPs are designed for ease of creation and modification,the second and third steps will be considerably more difficult han the first.
Empiricallyexploring this hypothesis presents an interesting line of future work.Finally, one of the most fruitful areas for future work is research on animatedexplanation generation.
To this end, we have begun work on an animated pedagogicalagent (Stone and Lester 1996) that can explain complex concepts with dynamicallysequenced visual and verbal behaviors.
These kinds of systems must be able to addressissues of animated content determination a d organization, as well as determining atruntime which media should be used to realize the concepts to be communicated.11.
Conc lus ionExplanation generation is an exceedingly complex task that involves a diversity ofinteracting computational mechanisms.
An explanation system must be able to selectfrom a knowledge base precisely those facts that enable it to construct a response toa user's question, organize this information, and translate the formal representationalstructures found in knowledge bases to natural anguage.
While the traditional ap-proach to work on explanation has been to develop a proof-of-concept system andto demonstrate hat it can produce well-formed explanations on a few examples, de-veloping robust explanation generation techniques and scalable discourse knowledgerepresentations facilitates more extensive, empirical studies.To investigate the issues and problems of generating natural language xplanationsfrom semantically rich, large-scale knowledge bases, we have designed and imple-mented KNIGHT, a fully functioning explanation system that automatically constructsmultisentential and multiparagraph natural anguage xplanations.
KNIGHT has gen-erated hundreds of explanations from the Biology Knowledge Base.
It addresses amultiplicity of issues in explanation generation, ranging from knowledge-base accessand discourse planning to a new methodology for empirical evaluation.
This work hasdemonstrated that (1) separating out knowledge-base access from explanation plan-ning can enable the construction of a robust system that extracts coherent views froma semantically rich, large-scale knowledge base and (2) Explanation Design Packages,a hybrid representation f discourse knowledge that combines a frame-based rep-resentation with procedural constructs, facilitate the iterative refinement of discourseknowledge.
Combining hierarchically structured discourse objects with embedded pro-98Lester and Porter Robust Explanation Generatorscedural constructs, EDPs have been used to represent discourse knowledge about phys-ical objects and processes, and they have been tested in the generation of hundreds ofexplanations of biological concepts.To gauge the effectiveness of these techniques, we developed the Two-Panel eval-uation methodology and employed it in the evaluation of KNIGHT.
KNIGHT scoredwithin half a grade of the biologists.
There was no significant difference betweenKNIGHT's explanations and the biologists' explanations on measures of content, orga-nization, and correctness, nor was there a statistically significant difference in overallquality between KNIGHT'S explanations and those composed by three of the biologists.KNIGHT'S performance exceeded that of one of the biologists.In summary, it is encouraging that an explanation system could begin to approachthe performance ofmultiple domain experts and surpass that of one expert.
These find-ings demonstrate that an explanation system that has been given a well-representedknowledge base can construct natural language responses whose quality approximatesthat of humans.
More generally, they suggest hat we are beginning to witness the ap-pearance of computational machinery that will significantly broaden the bandwidthof human-computer communication.AcknowledgmentsWe would like to thank our principledomain expert, Art Souther, for leading theknowledge base construction effort; CharlesCallaway and the NLG students for theirwork on the realization system; Erik Eilerts,for building the knowledge-base-editingtools; Michael Elhadad, for generouslyassisting us with FUF; Peter Clark for hisassistance with the statistical nalysis; DanSuthers, Rob Holte, and Paul Cohen forinsights on the problems of evaluatingexplanation systems; the members of theBiology Knowledge Base Project: LianeAcker, Brad Blumenthal, Rich Mallory, KenMurray, and Jeff Rickel; and Peter Clark,Charles Callaway, and the anonymousreviewers whose suggestions significantlyimproved the paper.
Support for thisresearch is provided by a grant from theNational Science Foundation (IRI-9120310),a contract from the Air Force Office ofScientific Research (F49620-93-1-0239), anddonations from the Digital EquipmentCorporation.ReferencesAcker, Liane E. H. 1992.
Access Methods forLarge, Multifunctional Knowledge Bases.Ph.D.
thesis, The University of Texas atAustin.Acker, Liane E. H. and Bruce W. Porter.1994.
Extracting viewpoints fromknowledge bases.
In Proceedings oftheTwelfth International Joint Conference onArtificial Intelligence, pages 547-552.Appelt, Douglas E. 1985.
Planning englishreferring expressions.
Artificial Intelligence,26:1-33.Buchanan, Bruce G. and Edward H.Shortliffe, editors.
1984.
Rule-Based ExpertSystems: The MYCIN Experiments oftheStanford Heuristic Programming Project.Addison-Wesley, Reading, MA.Callaway, Charles B. and James C. Lester.1995.
Robust natural language generationfrom large-scale knowledge bases.
InProceedings ofthe Fourth Bar-Ilan Symposiumon Foundations of Artificial Intelligence,pages 96-105.Carr, Brian and Ira P. Goldstein.
1977.Overlays: A theory of modelling forcomputer aided instruction.
TechnicalReport AI Memo 406, MassachusettsInstitute of Technology, ArtificialIntelligence Laboratory, February.Cawsey, Alison.
1992.
Explanation andInteraction: The Computer Generation ofExplanatory Dialogues.
MIT Press,Cambridge, MA.Cohen, Philip R. and C. Raymond Perrault.1979.
Elements of a plan-based theory ofspeech acts.
Cognitive Science, 3:177-212.Dale, Robert.
1992.
Generating ReferringExpressions.
MIT Press, Cambridge, MA.Eilerts, Erik.
1994.
KnEd: An interface for aframe-based knowledge r presentation system.Master's thesis, The University of Texasat Austin, May.Elhadad, Michael.
1992.
Using Argumentationto Control Lexical Choice: A FunctionalUnification Implementation.
Ph.D. thesis,Columbia University.Grimes, Joseph E. 1975.
The Thread ofDiscourse.
Mouton, The Hague.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and the99Computational Linguistics Volume 23, Number 1structure of discourse.
ComputationalLinguistics, 12(3):175-204.Halliday, Michael A. K. and RuqaiyaHassan.
1976.
Cohesion in English.Longman, London.Hobbs, Jerry R. 1985.
On the coherence andstructure of discourse.
Technical ReportCSLI-85-37, Center for the Study ofLanguage and Information, StanfordUniversity, Stanford, CA, October.Hovy, Eduard H. 1990.
Pragmatics andnatural anguage generation.
ArtificialIntelligence, 43:153-197.Hovy, Eduard H. 1993.
Automateddiscourse generation using discoursestructure relations.
Artificial Intelligence,63:341-385.Joshi, Aravind K. and Scott Weinstein.
1981.Control of inference: The role of someaspects of discourse structure-centering.In Proceedings ofthe Seventh InternationalJoint Conference on Artificial Intelligence,pages 385-387, Cambridge, England.Kittredge, Richard, Tanya Korelsky, andOwen Rambow.
1991.
On the need fordomain communication k owledge.Computational Intelligence, 7(4):305-314.Kukich, Karen.
1983.
Knowledge-Based ReportGeneration: A Knowledge EngineeringApproach to Natural Language ReportGeneration.
Ph.D. thesis, University ofPittsburgh.Lester, James.
1994.
Generating NaturalLanguage Explanations from Large-ScaleKnowledge Bases.
Ph.D. thesis, TheUniversity of Texas at Austin.Lester, James C. and Bruce W. Porter.
1991a.A revision-based model of instructionalmulti-paragraph discourse production.
InProceedings ofthe Thirteenth CognitiveScience Society Conference, pages 796-800.Lester, James C. and Bruce W. Porter.
1991b.A student-sensitive discourse generatorfor intelligent tutoring systems.
InProceedings ofthe International Conference onthe Learning Sciences, pages 298-304,August.Mann, William C. 1983.
An overview of thePenman text generation system.
InProceedings ofthe National Conference onArtificial Intelligence, pages 261-265.Mann, William C. and Sandra A.Thompson.
1987.
Rhetorical structuretheory: A theory of text organization.Technical Report ISI/RS-87-190,USC/Information Sciences Institute,Marina del Rey, CA, June.Maybury, Mark T. 1992.
Communicativeacts for explanation generation.International Journal of Man-MachineStudies, 37(2):135-172.McCoy, Kathleen F. 1989.
Generatingcontext-sensitive responses toobject-related misconceptions.
ArtificialIntelligence, 41:157-195.McKeown, Kathleen R. 1985.
Text Generation:Using Discourse Strategies and FocusConstraints to Generate Natural LanguageText.
Cambridge University Press,Cambridge.McKeown, Kathleen, Jacques Robin, andKaren Kukich.
1995.
Generating concisenatural anguage summaries.
InformationProcessing and Management.
Special Issueon Summarization.McKeown, Kathleen R., Myron Wish, andKevin Matthews.
1985.
Tailoringexplanations for the user.
In Proceedings ofthe Ninth International Joint Conference onArtificial Intelligence, pages 794-798.Mitchell, Kathleen P. 1992.
A system togenerate natural anguage sentences forexplanations from a large knowledge base.Master's thesis, The University of Texasat Austin.
May.Mittal, Vibhu O.
1993.
Generating NaturalLanguage Descriptions with Integrated Textand Examples.
Ph.D. thesis, University ofSouthern California, September.Moore, Johanna D. 1995.
Participating inExplanatory Dialogues.
MIT Press,Cambridge, MA.Moore, Johanna D. and C6cile L. Paris.
1993.Planning text for advisory dialogues:Capturing intentional and rhetoricalinformation.
Computational Linguistics,19(4):651-694.Paris, C4cile L. 1988.
Tailoring objectdescriptions to a user's level of expertise.Computational Linguistics, 14(3):64-78,September.Porter, Bruce, James Lester, Kenneth Murray,Karen Pittman, Art Souther, Liane Acker,and Tom Jones.
1988.
AI research in thecontext of a multifunctional knowledgebase: The botany knowledge base project.Technical Report AI Laboratory AI88-88,University of Texas at Austin.Rickel, Jeff and Bruce Porter.
1994.Automated modeling for answeringprediction questions: Selecting the timescale and system boundary.
In Proceedingsof the Twelfth National Conference onArtificial Intelligence, pages 1191-1198.Robin, Jacques.
1994.
Revision-BasedGeneration of Natural Language SummariesProviding Historical Background.
Ph.D.thesis, Columbia University, December.Sibun, Penelope.
1992.
Generating textwithout rees.
Computational Intelligence,8(1):102-122, March.Souther, Art, Liane Acker, James Lester, and100Lester and Porter Robust Explanation GeneratorsBruce Porter.
1989.
Using view types togenerate xplanations in intelligenttutoring systems.
In Proceedings of theEleventh Cognitive Science SocietyConference, pages 123-130.Stone, Brian A. and James C. Lester.
1996.Dynamically sequencing an animatedpedagogical gent.
In Proceedings of theThirteenth National Conference on Artifi'cialIntelligence, pages 424-431.Suthers, Daniel D. 1988.
Providing multipleviews for explanation.
In Proceedings of theAAAI-88 Workshop on Explanation, pages12-15.Suthers, Daniel D. 1991.
A task-appropriatehybrid architecture for explanation.Computational Intelligence, 7(4):315-333.Suthers, Daniel D. 1993.
An Analysis ofExplanation and Its Implications for theDesign of Explanation Planners.
Ph.D. thesis,University of Massachusetts, February.Swartout, William R. 1983.
XPLAIN: Asystem for creating and explaining expertconsulting programs.
Artifi'cial Intelligence,21:285-325.101
