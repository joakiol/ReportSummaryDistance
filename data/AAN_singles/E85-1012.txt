NATURAL LANGUAGE PROCESSING AND THE AUTOMATIC ACQUISITION OF KNOWLEDGE:A SIMULATIVE APPROACHDanilo FUMLaboratorio di Psicologia E.E.
- Universit8 di Triestevia Tigor 22, I - 34124 Trieste (Italy)ABSTRACTThe paper presents the general design and thef i r s t  results of a research project whose longterm goal is to develop and implement ALICE, anexperimental system capable of augmenting itsknowledge base by processing natural languagetexts.
ALICE (an acronym for Automatic Learningand Inference Computerized Engine) is an attemptto model the cognitive processes that occur inhumans when they learn a series of descriptivetexts and reason about what they have learned.
Inthe paper a general overview of the system isgiven with the descrlption of its specifics, basicmethodologies, and general architecture.
Howparsing is performed in ALICE is i l lustrated byfollowing the analysis of a sample text.I.
INTRODUCTION.The capability to learn is one of the centralfeatures of intell igent behavior, and learningconstitutes one of the current hot topics inar t i f ic ia l  intelligence (Michalski, Carbonnell,and Mitchell, 1983).
Much of the work on thisf ield has dealt with induction, rule discovery,and learning by analogy or from examples, whereasmuch less effort has been dedicated to buildingsystems able to learn by processing naturallanguage texts.
As Norton (1983: 308) remarked,the general agreed-upon assumption was that "sucha capability is not 'learning' at all but merely(?)
the conversion of knowledge from onerepresentation to another".
ACquiring newKnowledge via prose comprehension is, on thecontrary, a complex activity which relies onunderstanding the l inguistic input, storing theextracted information in memory, and integratingi t  with prior knowledge for effective use.
As faras psychology is concerned, learning from writtentexts has often aroused the interest of cognitiveand educational psychologists.
Due to thelimitations of the experimental approach which hasbeen generally adopted, however, this topic hasseldom been dealt with in its entirety.
Lots ofexperiments have been carried on focusing onrestricted arguments and specific phenomena whoseexplanations too often look suspiciously ad hoc.Unfortunately, those who addressed the fu l lproblem of 'meaningful verbal learning' (e.g.Ausubel, 1963) stated their theories so vaguelythat i t  is almost impossible to express them inform of effective procedures and to implement themin computer programs.In the last few years the situation has changedand several projects (Frey, Reyle, and Rohrer,1983; Haas and Hendrix, 1983; Nishida, Kosaka, andDoshita, 1983; Norton, 1983) are now devoted todevelop computer systems which could automaticallyextract information from written texts.
Practicalapplications, besides theoretical interest,motivates this kind of research.
In the expertsystem technology, for example, the process ofdiscovering what is known to the experts of thefield in which the program must perform requirestedious and costly interactions between ~ theknowledge ngineer and those experts.
Automaticacquisition of knowledge by text understandingcould represent a way to partial ly reduce thelabor and fatigue involved in the transfer ofexpertise.The paper presents the general design and thef i r s t  results of a research project whose longterm goal is to develop and implement ALICE, anexperimental system capable of augmenting itsknowledge base by processing natural languagetexts and reasoning about them.
Particularattention is given to the simulative aspects ofthe project.
ALICE (an acronym for AutomaticLearning and Inference Computerized Engine) is anattempt to model the cognitive processes thatoccur in humans when they learn a series ofdescriptive texts and reason about what they havelearned.
Comparisons with what is Known abouthuman cognitive behavior are therefore expl ic i t lytaken into account in devising algorithms and datastructures for the system.
In the next section ageneral overview of the system is provided withthe description of its specifics, basicmethodologies, and generar architecture.
The thirdsection briefly describes the parser used in79ALICE, and how parsing is performed is i l lustratedin section four by following the analysis of asmall sample text.
Section five concludes thepaper by giving a summary of the main ideas andsome implementational details.2.
ALICE: A GENERAL OVERVIEW2.
I SpecificsThe main goal of the ALICE project is toexamine how i t  is possible to build a machinewhich could, in a psychologically plausible way,learn new facts about a given domain by analysingnatural language texts.
ALICE can operateaccording to two different ways: in learning modeand in consult mode.
In learning mode ALICE isgiven in input a series of sentences in Italianforming simple introductory scientif ic passages.The domains chosen for the in i t ia l  experimentationare elementary chemistry and electronics.
Thesystem understands the input texts and integratesthe information extracted from them with thatpreviously stored in its knowledge base.
Forchecking purposes the system outputs thesentence-by-sentence internal representation thatis added to the knowledge base.
When working inconsult mode, ALICE receives in input a questionconcerning the processed texts and returns theportion of the knowledge base containing theinformation needed to answer i t .
It should benoted that the system has no generationcapabilities; i t  does not output natural languagesentences but only the internal representation ofa small part of its knowledge base.
Anotherlimitation of the system is that i t  can deal withquestions only in a piece-meal fashion.
ALICE, inother words, lacks the dialogic capabilitiesneeded to build a graceful man-machine interface.User modelling, mixed-initiative dialogue,co-operative behavior etc.
are simply outside thescope of the project.ALICE cannot obviously understand all thesentences that is possible to express in a givenlanguage.
Unrestricted language comprehension iscurrently beyond our capabilities.
As work inar t i f i c ia l  intelligence and computationall inguistics has taught us, i t  is very d i f f i cu l t  tobuild programs that could successfully cope withl inguistic materials.
This is due to the fact thatlanguage is essentially a knowledge-based process.In understanding natural language i t  is necessaryto make a heavy reliance on world knowledge evento do very elementary operations: disambiguate themeaning of a word, identify an anaphoric referent,capture the syntactic structure of a sentence.Paradoxically i t  has been said that one cannotlearn anythingt unless (s)he almost knows i talready.
In order to avoid the danger of beingstuck in a loop ( i .e .
,  text understanding requiresa rich stock of knowledge, but in order to acquiresuch a Knowledge i t  is necessary to understandtextual material), the passages given in input,derived from programmed instruction textbooks,were kept relatively simple from the l inguist icpoint of view.As an automatic knowledge acquisition system,ALICE differs f rom other natural languageprocessors in that, by definition, its knowledgebase is incomplete.
This means that, at thebeginning, not only its conceptual coverage butalso its l inguistic (particularly lexical)capabilities are quite limited.
A great deal ofwork in learning a new subject is constituted bymastering new concepts and the terminology neededto refer to them.
When the system encounters aword for which i t  has no definition in itsdictionary, i t  should be able to learn this newword and guess at its meaning.
Doing this can beeasy when the new word is expl ic i t ly  defined inthe text but i t  can require non-trivialinferential processes i f  the new word isimplicit ly introduced by relating i t  with otherconcepts whose meaning is already known.ALICE comes preprogrammed with a fixed set ofrules enabling i t  to cover a small subset ofItal ian.
I t  also comes with seed concepts and aseed vocabulary which are to be extended as thesystem learns about the new domain.
ALICE acquiresnew knowledge by integrating the  informationextracted from the input texts with thatpreviously stored in its knowledge base.
As aresult of its operation, ALICE's conceptualcoverage increases with the number of passages ina given domain which have been understood.
ALICEis thus capable of understanding more complextexts since its encyclopedic knowledge can bebrought to be bear in the comprehension process.
Anecessary prerequisite to this accomplishment isthat parsing input texts should not be consideredas a separate activity but i t  must be integratedwith the remaining operations performed by thesystem.2.2 Knowledge Representation MethodsAn important point in the design of everyar t i f i c ia l  intelligence program is constituted bydeciding how to represent knowledge.
A goodformalism should be able to express all theknowledge needed in a given application domain,and should faci l i tate the process of acquiring newinformation.
ALICE adopts a clear distinctionbetween declarative and procedural knowledge.
Thisis a cr i t i ca l ,  and not at all obvious, choice.80Norton (1983), for example, adopts as the targetrepresentational formalism for his systemstatements in the PROLOG language which can beinterpreted both declaratively and procedurally.Erom a psychological point of view, however, thereare strong reasons for maintaining the distinctionbetween these two kinds of knowledge (Anderson,1976:116-119):- the declarative knowledge seems possessed inall-or-none manner whereas i t  is possible topossess procedural knowledge only partial ly;- the declarative knowledge is acquired suddenlyby being told whereas the procedural knowledge canbe acquired only gradually by performing a skit1;- i t  is possible to communicate verbally thedeclarative but not the procedural knowledge.In ALICE the declarative knowledge isconstituted by the information that the system isable to derive from the texts.
It is representedthrough the BLR propositional language (Fum,Guida, and Tasso, 1984), a formalism derived byaugmenting the representation used inpsychological setting by Kintsch (Kintsch, 1974;Kintsch and van Dijk, 1978) with the featuresnecessary to make i t  computationally tractable.The procedural knowledge represents the knowledgenecessary to the system operation.
It is expressedin form of production systems which operate on thepropositions contained in the knowledge base.There are several motives that make the use ofproductions systems particularly interesting tomodel human cognitive processing.
Productionssystems provide a unifying formalism to deal withthe different kinds of processes that occur inknowledge acquisition through text comprehension.Moreover, they are especially suitable to supportthe strategic approach on which the systemoperation is grounded.2.3 Basic MethodologiesThe strategic approach to text understanding,and reasoning with l inguistic materials, can bef ru i t fu l l y  contrasted with the algorithmic one.Examples of the algorithmic approach in the fieldof natural language processing can be found, forexample, in the use of grammars which producestructural descriptions of sentences by syntacticparsing rules.
In the field of inferentialprocesses this approach is represented by theoremprovers based on resolution mechanisms which,granting that a theorem could be derived from agiven set of axioms, are able to discover itsproof.
These processes can be complex, long andtedious but they guarantee success as long as thealgorithm is correct and i t  is correctly applied.The strategic approach does not guarantee a priorisuccess.
It is based on a set of heuristics,expressed as production rules, which constitutesome working hypotheses about how to discover thecorrect meaning of a fragment of text or the wayby which a certain inference could be drawn.Strategies are rules of thumb which are applied toanalyse, understand, and reason about naturallanguage texts.
Humans differ in their cognitivefunctioning according to the amount and the kindof strategies they have at their disposal, andaccording to the way in which these strategies areapplied.
Experimental evidence for the strategicapproach has been gathered since a long time.Clark and Clark (1977) reviewed some of thestrategies util ized in sentence comprehension; vanDIjk and Kintsch (1983) wrote a whole book toexamine the strategies employed in discourseunderstanding, and Anderson (1976) examined thestrategies his subjects adopted to perform formaldeductions in syllogistic reasoning tasks.The strategic approach is inextricably linkedwith other assumptions concerning textunderstanding and learning.
The goal of the humanunderstanding activity (and of the systems aimedat modelling human cognitive processing) is notthe discovery of the syntactic structure of asentence but of its meaning.
This does not meanthat syntax is of no use in text understanding.Syntactic information, however, constitutes onlyone among the different knowledge sources util izedto capture the meaning of a piece of text, andsyntactic analysis represents neither a separatephase nor a prerequisite for comprehensionactivity.
The construction of the meaningrepresentation takes place more or less at thesame time of the data input.
Humans do not waitunti l  an entire sentence is uttered before theybegin to interpret what has been said.
They mayhave expectations about what sentences look l ike,and these expectations may faci l i tate theunderstanding process.
As words are being receivedpeople try to build a possible semanticinterpretation for them.
Additional words are usedto confirm or disconfirm that interpretation.
Inthe latter case, a new interpretation is build andi t  is checked against the new data.
There is nofixed order between input data and theirinterpretation: interpretations may be data drivenor they may be constructed in absence of externalevidence and only later be matched with data.Language understanding is a multifacetedactivity and several kinds of competence areneeded to perform i t .
ALICE relies on a series ofspecialists which co-operate in performing thevariuos operations ( i .e .
,  parsing, inferencing,memory management) which are required to acquirenew knowledge by text comprehension.812.3 General ArchitectureALICE is composed (see fig.
I) of the followingmodules:= the parser- the inference engine- the memory manager- the monitorwhich can uti l ize, in order to perform theiractivity, two data structures: the knowledge baseand the working memory.The knowledge base can be considered as thelong term memory of the system.
Informationextracted from the texts received in input isrepresented in declarative form in such astructure.
The knowledge base is constituted by ahuge amount of BLR propositions linked to form acohesion graph.
Unlike semantic networks, acohesion graph only indicates the fact that someconcepts and propositions of the knowledge baseare connected; all the information concerning thekind of relationship existing among them is to befound in the BLR propositions.
The knowledge baseis concept indexed; i t  can be accessed through oneor more concepts that become thus activated.
Fromthese concepts activation spreads, through thethe different kinds of arcs - irrespective oftheir direction o to the propositions in whichthey are contained and to other concepts connectedto them.
This mechanism of spreading activation,similar to that described in Quillian (1969),Collins and Loftus (1975) and Anderson (1976),makes i t  possible to selectively access theinformation contained in the knowledge base.The working m~morv represents the short termmemory of the system.
It is a memory of limitedcapacity which represents the portion of theknowledge base which can be accessed and operatedupon by the different productions.
To util ize apiece of knowledge, i t  is necessary to activatei t ,  i.e.
i t  must be present in the working memory.The working memory stores generally only theinformation connected to the sentence that iscurrently being processed plus some informationnecessary to understand the sentence (informationneeded to draw an inference, to establishcoreferential links and coherence, to exactlyquantify an expression etc.
).The system modules do not communicate directlywith each other but they can exchange informationonly through the working memory which serves as a"blackboard" for the whole system.
There are someimportant differences, however, between the use ofIt 'lPARSERWORKING MEMORYl lENGINE MANAGERMONITOR11KNOWLEDGEBASEFig.l: The General Architecture82the working memory in ALICE and otherblackboard-based system like HEARSAY-If (Lesserand Herman, 1977; see also: Cullingford, 1981)).First, in HEARSAY-If each specialist expresses itshypotheses on the blackboard in its ownrepresentation language.
In ALICE, BLR is thecommon language for representing all  theinformation provided by the specialists.
Second,the control of the specialist activity isdecentralized in HEARSAY while in ALICE thecontrol information is expl ic it ly present ratherthan diffused through a large database.
Theactivity of the different modules does not dependonly from the content of the blackboard but isdirectly controlled by the monitor whichdisciplines the operation of the differentmodules.The parser is devoted to translate a naturallanguage expression (a sentence to be processed inlearning mode or a query to be answered in consultmode) into the BLR representation.
This activityis performed through the collaboration of a numberof parsing specialists which are supposed to becompetent in each of the several domains involvedin language understanding, and to cover the widespectrum of different capabilities required tobuild up the text representation.
Parsing isstr ict ly  integrated with the other operationsperformed by the system: inferencing and memorymanagement ( i .e .
,  retrieving old information to beutil ized in text understanding, and integratingnew information in the knowledge base).The inference engine is the module devoted toperform the inferences required to understand apiece of text or to answer a question.
Its task isto go beyond the information given and to discovernew information to be supplied to the system.Different kinds of inferences are performed bythis module: propositional, pragmatic, and formaldeductions.
Propositional inferences are based onlinguistic features of predicates.
They arenecessarily true and can be directly derived fromthe semantic content of the propositions.Pragmatic inferences are derived from knowledgesources beyond the expl ic it ,  l inguistic input.They are not necessarily true but only plausible.Pragmatic inferences, however, are often drawn inprocessing natural language to establish, forexample, the coherence of seemingly separatesegments of texts, to understand referentialexpressions, to build "bridging implicatures",etc.
Formal deductions are often required tounderstand scientific passages.
Humans, however,are different from theorem provers in that theyare neither sound nor complete inferentialengines.
They sometimes reason in contrast withthe dictates of logic; they do not draw everypossible consequence from a set of premises butonly those that appear sensible and interesting;f ina l ly ,  they perform in a reasonably efficientmanner.
The inference engine module is an attemptto simulate human inferential processes in dealingwith scientif ic texts.The memory manager is the only module whichinteracts directly with the knowledge base.
It  isdevoted to retrieve some information necessary tothe system operation, to match the informationextracted from the current text with thatcontained in the knowledge base, to upgrade i t  byintegrating the new knowledge.
The memory managerimplements a multiple-access, parallel searchassumption concerning the way the knowledge basedis searched for information.
This means that thesystem memory can be accessed from all theconcepts contained in the l inguistic input andthat the concepts spread their activation inparallel among the links departing from them.
Whenthe minimum length path between two concepts isdiscovered the propositions standing on i t  arereturned as being relevant to the current input.Through the memory manager i t  is possible tosimulate certain process that are Known to occurin human memory, for example propositional fan andinterference ffects.3.
TOWARDS A MENTAL PARSERIn accordance with the general simulativeapproach of the ALICEproject, the main criterionto follow in designing and evaluating a parser isthat of how well its operation corresponds to theway humans understand language.
Unfortunately, inspite of lots of psycholinguistic studies, we arefar from knowing how the mind works.
Experimentalevidence, at most, can help us to put someconstraints on the specifics of a 'mental parser'.I t  is apparent, for example, that human parsingdoes not occur entirely top-down or bottom-up butuses some combination of these strategies.
It isalmost certain, moreover, that humans do not usebacktracking or looking ahead in order to copewith nondeterminism (Johnson-Laird, 1983).The most important preliminary question to bedealt with in the design of a mental parser,however, is that of what mechanisms people use inunderstanding.
Linguists hold that people rely onformal rules and that they have implicit knowledgeof the grammar they apply in analysing a sentence.Some of the rule systems that linguists use toparse sentences are implausible as psychological~dels~ the resources they demand and thecomputations involved simply exceed the humanprocessing limitations (see, for instanceAnderson's critique of ATN formalisms: Anderson,831976).The parser that has been designed for ALICErelies on the strategic approach (van Dijk andKintsch, 1983) implemented through productionsystems and constitutes a f i r s t  step toward theconstruction of a psychologically viable mentalparser.
The parsing process is organized around aset of parsing specialists.
The monitor is incharge of controlling the overall parsing activityand of directing the operation of the specialiststowards the construction of the BLR.
I t  uti l izes aset of construction rutes which representknowledge about the BLR, about the use of thespecialists, and about the use of the informationsupplied by the specialists for the constructionand validation of the BLR.
The specialists aredevoted to analise the input text and to supplythe information necessary to the monitor.
Thegeneral philosophy of the parser is to exploit anyand at1 available Knowledge whenever helpful.
Thespecialists are therefore supposed to be competentin each of the severals domains which are involvedin the comprehension activity and to cover thewide spectrum of different capabilities requiredto build up the BLR.The following specialists are used:- morpholexical specialist- syntactic specialist- semantic specialist- quantification specialist- reference specialist- time specialist.The morpholexica!
specialist analyzes the wordscontained in the natural language sentences.
It isthe specialist which performs the segmentation ofwords into morphemes and which looks up thedictionary for their definition.
In case theprocessed word is unknown, the specialist providessome hypotheses about its morpholexical features(gender, nu~er, lexical class, etc.)
which wil lbe used for guessing, in collaboration with theother specialists, the meaning of the new word.The syntactic specialist tr ies to discover thesurface structure of each sentence, and torecognize its functional organization.
The rulesi t  uti l izes do not represent a 'granmnar' for thelanguage but only some hypotheses concerning therole of word order in the determination ofmeaning.
The semantic specialist is aimed atproposing a f i r s t  tentative interpretation of thenatural language sentences as a series of BLRpropositions.
It  recognizes the predicates whichwil l  be used in the construction of propositionsand checks that such predicates wil l  beinstantiated with the correct arguments, Thequantification ?PeCialist is used to discover howthe arguments of the propositions could bequantified.
The reference specialist is devoted toexamine i f  each concept conveyed by the input textrepresent a unique token or i f  i t  refers to otherconcepts known by the system.
The time specialistexamines the time specifications contained in thetext which ire implicit in the tense of verbs orexpl ic i t ly  stated through the use of temporaladverbs or time expressions.4.
AN EXAMPLEThis section gives an idea of the parseroperation by following in some detail the analysisof a small sample text.
Let us consider thefollowing sentence:"La materia e' composta da molte sostanzedifferenti .
"(The matter is composed of many differentsubstances.
)As mentioned above, ALICE works under thecontrol of the monitor which directs andcoordinates theact iv i ty  of the specialists.
Themonitor starts by examining the f i r s t  word of thesentence and puts the following information intothe working memory:10 B~UAL ($I, "LA")20 B~ UAL ($PROC-WORD, $I).BLR constitutes in ALICE the conm~n languagethrough which the specialists can exchangeinformation and communicate with each other.
Theonly difference between the standard BLR (asdescribed in Fum, Guida & Tasso, 1984) and theformalism here util ized is the introduction ofl inguistic variables (identified by the $ sign)used exclusively in the parsing act ivity.
The $sign can be followed by an index which indicatesthe word to which the variable refers.
The indexcan be constituted by:- an integer, for example: $I, $2, $3, in whichcase the variable refers to the f i r s t ,  second,third word of the sentence, respectively;- a letter,  for example $x, $y, in which case thevariable refers to a generic word of the sentence;- an expression indicating a fixed displacement inrelation to a given word.
So, for instance, $x-I,$x+I, $y+2, $3+2 refer respectively to the wordthat immediately precedes that indicated by the Sxvariable, to the word that follows i t ,  to the wordthat comes two positions in the sentence afterthat referred to by Sy, and to the f i f th  word ofthe sentence;- an expression indicating a generic displacementin relation to a given word.
$x+n, $5-n thereforeindicate a word that generically follows the xth84word of the sentence, and a word that genericallyprecedes the f i f th  word of the sentence.The main variables uti l ized in the presentexample are:- $.PROC-WORD, which represents the word thesystem is currently processing;- $( index) .CLASS,  $(index).GENDER,$(index).NUMBER, $(index).FUNCTION, whichrepresent the lexical class, the gender, thenu~er, and the syntactic function of the(index)th word of the sentence, respectively;- $(index).CONCEPT, which represents the conceptto which the (index)th word refers and into whichi t  is mapped in the course of the parsingactivity.The predicate ~UAL is used to indicate thatits arguments can be considered as the same thingand can therefore be util ized interchangeably.Proposition 10 then asserts that the variable $Ihas the value "La", that is "La" is the f i r s t  wordof the sentence.
Proposition 20 states that $I( i .e.
"La") is the word that is currentlyprocessed.
This information triggers the activityof the specialist that performs the morpholexicalanalysis.
Looking at its dictionary, thespecialist finds that "La" can be a a definite(feminine, singular) article or a (feminine,singular) pronoun that is used only as object.
Thespecialist returns the following propositions:30 ~UAL ($1.GENDER, FEMININE)40 ~UAL ($1.NUMBER, SINGULAR)50 XOR (60, 70)60 ?B~UAL ($1.CLASS, DEF-ARTICLE)70 ?AND (80, 90)80 ?B~UAL ($1.CLASS, PRONOUN)90 ?B~UAL ($1.FUNCTION, OBJECT)These propositions give the completemorphological analysis of the word "La".Proposition 50 states an alternative and indicatesthat only one of its arguments is true:- either the current word is a definite article,or- both of the following facts hold: ( i) thecurrent word is a pronoun and ( i i )  i t  appears asthe object of the current sentence.Propositions preceded by the ?
sign representexpectations the system has or conditions thatmust be fu l f i l led  by the content of the workingmemory.Since propositions 10 and 20 cannot activateother specialists, the control returns to themonitor which tries to determine the truth valueof propositions 60-90.
There is not enoughinformation in the working memory to allowperforming th is  activity and the monitor,therefore, starts another processing step.
In thenext cycle the activity of the syntactic andreference specialists can be triggered since thecondition part of some of their productions matchthe information contained in the working memory.In particular, the syntactic specialist has in itsrule base the following productions:IF B~UAL ($x.CLASS, DEF-ARTICLE)IHEN XOR (P, Q)P ?B~UAL ($x+I.CLASS, NOUN)Q ?B~UAL ($x+I.CLASS, ADJECTIVE)andIFIHENB~UAL ($x.CLASS, DEF-ARTICLE)I~UAL ($x.GENDER, g)B~UAL ($x.NUMBER, n)B~UAL ($x+I.GENDER, g)B~UAL ($x+I.NUMBER, n)i .e .
,  i f  a word of a sentence is a definitearticle i t  has to be followed by a noun or anadjective which must agree with its gender andnund~er.
The former production is triggered byproposition 60 which represents only a plausiblealternative and states an assertion whose truthvalue must s t i l l  be determined.
This factrepresents a typical case of conditional matchingwhich is taken into account by the monitor whichsubordinates the execution of the action part ofsuch production to the truth of proposition 60.
Asa result, the following propositions aregenerated:100 IMPLY (60, 110)110 ?XOR (120, 130)120 ?B~UAL ($2.CLASS, NOUN)130 ?B~UAL ($2.CLASS, ADJECTIVE)The latter production, after matching(conditionally) the f i r s t  clause with proposition60, and matching the second and third withpropositions 30 and 40, respectively, generates:140 IMPLY (60, 150)150 ?AND (160,170)160 ?B~UAL ($2.GENDER, FEMININE)170 ?B~UAL ($2.NUMBER, SINGULAR).The syntactic specialist Knows also that, i fa pronoun appears as the object of a sentence, thefollowing constituent orders are feasible inItalian: SOV, OVS, VOS, i.e, the pronoun must bepreceded or followed by a verb.
This informationis represented in the following production whichiS triggered in the same cycle:85IF ~UAL ($x.CLASS, PRONOUN)~UAL ($x.FUNCTION, OBJECT)THEN XOR (P, Q)P ?B~UAL ($x-I.CLASS, VERB)Q ?B~UAL ($x+I.CLASS, VERB).This production is triggered by propositions 80and 90 which must be both true in order to allowconsidering proposition 70 - which represents aplausible alternative and whose truth value mustbe s t i l l  determined - also true.
This case ofconditional matching is taken into account by themonitor too and what results is:IBO IMPLY (70, 190)190 ?XOR (200, 210)200 ?B~UAL (SO.CLASS, VERB)210 ?B~UAL ($2.CLASS, VERB).In the same cycle, the reference specialistis triggered Which uses the heuristic:"IF a determiner has been identifiedTHEN look for a noun that specifiesheader of the noun phrase.
"theThis general heuristic is implemented in thisparticular case by the following production:IFTHENB~UAL ($x.CLASS, DEF-ARTICLE)B~UAL ($x+n.CLASS, NOUN)B~UAL ($x+n.CONCEPT, HEADER)and the following information is returned:220 IMPLY (60, 230)230 ?AND (240, 250)240 ?B~UAL ($1+n.CLASS, NOUN)250 ?B~UAL ($1+n.CONCEPT, HEADER)These propositions state that one the of nextwords of the sentence should be syntacticallyclassified as a noun and that the concept to whichthis noun refers shoud be considered the header ofthe noun phrase.Another heuristic uti l ized by the referencespecialist is the following:"IF a pronoun has been identified,I~IEN look for the referent amongwich have the same gender and number.
".the nounsThis heuristic is implemented through thefollowing production:IF UAL ($x.CLASS, PRONOUN)UAL ($x.GENDER, g)ll4ENE~UAL ($x.NUMBER, n)B~UAL ($x.CONCEPT, $y.CONCEPT)B~UAL ($y.CLASS, NOUN)B~UAL ($y.GENDER, g)B~UAL ($y.NU~ER, n)The f i r s t  clause of the condition part of theproduction matches (conditionally) proposition 70while the second and third clause matchpropositions 30 and 40, respectively.
Theproduction gives raise to the followingpropositions:260 IMPLY (70,270 ?AND (280,28O ?B~UAL ($I290 ?B~UAL ($y300 ?B~UAL ($y310 ?B~UAL ($y270)290, 300, 310).CONCEPT, Sy.CONCEPT).CLASS, NOUN).GENDER, FEMININE).NUMBER, SINGULAR).i .e .
,  i f  "La" is a pronoun i t  refers to a conceptrepresented in the text by a word which is afeminine, singular, noun.The information present in the working memoryat the beginning of the cycle (propositions I0-90)cannot activate other specialists.
Af ter  al l  theproductions have fired in a cycle, the results aretaken into account by the monitor which checks theresults obtained through the work of thespecialists.
The monitor tr ies to establish thetruth value of the propositions preceded by thesign, i t  tr ies also to identify the concepts towhich variables indexed by a letter or anexpression refer and, more generally, i t  checksthe compatibility and consistency of thepropositions in the working memory.
In ourexampte, the onty thing that the monitor can do atthis point is to capture the error conditioncontained in proposition 200 which has among itsarguments the variable SO.CLASS, i .e.
the variablewhich refers to the sytactic class of the Oth wordof the sentence.
Proposition 200 is recognized asstating something that cannot be true and, as aconsequence, one of the alternatives stated inproposition 190 is not valid any more.
The monitorsubstitutes the second argument of proposition 180with 210, while propositions 190 and 200 ar~deleted.
At this point we know a tot about thecurrent word.
We know that "La" is an article or apronoun and in both cases we know what shouldhappen next.
If "La" is an article, a noun mustfollow sooner or later, and the concept referredto by this noun wil l  be the header of the nounphrase.
In particular, the next word must be anoun or an adjective, and i t  must be singular andfeminine.
If "La" is a pronoun, on the other hand,i t  must be followed by a verb and its referentmust be looked for among the concepts which are86represented in the sentence by feminine singularnouns.The next word to be processed is "materia".Before the morpholexical specialist could beactivated the monitor performs some housekeepingoperations on the content of the working memory.It  deletes proposition 20 which is not true anymore and adds the following propositions to theworking memory:320 B~UAL ($2, "MATERIA")330 B~UAL ($.PROC-WORD, $2)The morpho lexical specialist analyses the newword and gives as a result the information that i tis a feminine, singular noun.
Moreover, the word"materia" corresponds to a concept known by thesystem, i.e.
i t  is a lexical entry which refers tothe concept MATTER.
The following propositionsresult from this analysis:340 ~UAL ($2.CLASS, NOUN)350 ~UAL ($2.CONCEPT, MATTER)360 ~UAL ($2.GENDER, FEMININE)370 ~UAL ($2.NUI~ER, SINGULAR)In this case we have no problems of semanticambiguity since MATTER represents the only conceptthat the system can connect o the word "materia".Generally speaking, however, each word of thesentence may refer to a number of differentconcepts and i t  is not always possible to decidewhich interpretationisappropriate unti l  more ofthe sentence has been analyzed.
The approach takenin ALICE to solve semantic ambiguity is to usemore information about the context in which thecurrent sentence appears.
Spreading activation isthe mechanism used for this purpose.
Anotherclassic way to deal with cases of polysemy that issometimes used in ALICE is to attach to certaininterpretations a series of requests orexpectations that must be fu l f i l led  by the contentof the working memory.Coming back to our example, the informationreturned by the morpholexical specialist allowsthe monitor to perform a series of checks on thecontent of the working memory concerning thepropositions whose truth value must be determinedand the expectations the system has.
Inparticular: after a series of deductions for whichthe help of the inference engine module isrequested, the following propositions remain inthe working memory:~0 ~UAL ($I, "LA")30 B~UAL ($1.GENDER, FEMININE)40 B~UAL ($1.NUMBER, SINGULAR)60 B~UAL ($1.CLASS, DEF-ARTICLE)120 B~UAL ($2.CLASS, NOUN)160 B~UAL ($2.GENDER, FEMININE)170 B~UAL ($2.NUMBER, SINGULAR)240 B~UAL ($1+n.CLASS, NOUN)250 B~UAL ($1+n.CONCEPT, HEADER)320 B~UAL ($2, "MATERIA")330 B~UAL ($.PROC-WORD, $2)350 B~UAL ($2.CONCEPT, MATTER)This information triggers the activity of thespecialists: the syntactic specialist recognizesthat the definite article and the noun are part ofa noun phrase.
This can be complete or, inItal ian, one or more adjectives can follow thenoun.
Proposition 60, 120 and 250 at the same timetrigger the activity of the reference andquantification specialists.
The referencespecialist looks for another occurrence of thesupposed header of the noun phrase in the workingmemory.The quantification specialist tries to findhow the header of the noun phrase must bequantified.
In this particular case i t  uses thefollowing heuristic:"IF the header concept is an individualconcept,AND i t  has not being previously referred toTHEN quantify i t  individually"and as a result i t  quantifies individually theconcept MATTER'(Fum, Guida, & Tasso, 1984).
Theparsing process goes on by identifying the verb ofthe sentence.
The verb "e' composta" is recognizedas an instance of the concept COMPOSE whichrepresents the constitutive relation of thefollowing predicate:COMPOSE ((composer), (composee>)The task of the parser becomes now that offiguring out the arguments of this predicate.After discovering that the preposition "da"signals that the verb is in the passive form, thati t  is in present tense, and after solving someproblems posed by the second noun phrases whichcontains the fuzzy quantifier "molte", the parserhas all the elements necessary to build up theBLR .
What results in the working memory after theparsing has been completed is the following:3070 COMPOSE (.VVI, MATTER, P)3080 *SUBSTANCE (VVI)3090 MANY (.VVI)3100 DIFFERENT (VVI, P)i .e.
there exist a subset (= more than one) VVI ofentities which are of the type SUBSTANCE ( i .e.each of them ISA SUBSTANCE) that taken together87compose the individual entity MATTER; thecardinality of this subset is MANY, and each ofthe entities have the property to be DIFFERENT.Propositions 3070-3100 are given as output of theparsing process and are stored in the knowledgebase where they can be accessed to answerquestions.5.
CONCLUSIONIn the paper the general design of ALICE hasbeen presented and an ilustration of the parserused by the system has been given.
The main ideason which such an attempt is grounded are:- to exploit all of the possible knowledge to aidthe system in the parsing activity,- to parallelize the morphologic, syntactic, andsemantic analysis, the determination of referents,quantification, etc, and to pursue them as soon asenough information has been gathered;- to provide through the use of the productionsystem formalism, an integrate framework intowhich all the problems posed by the languageunderstanding activity could be dealt with.A prototype reduced version of the system,implemented in FLISP under NOS 2.2 on a controlData Cyber 170, is currently running at theUniversity of Trieste and shows the feasibility ofthis approach.
A full system implementation inCommon LISP is under development.REFERENCESAnderson, J.R. (1976).
LaNguage, Memory, andThought.
HilIsdale: N.J., Erlbaum.Ausubel, D.P.
(1963).
The Psychology o_f_fMeaningfulVerbal Learning.
New York, N.Y.: Grune & Stratton.Clark, H.H.
and Clark, E.V.
(1977).
Psychology andLanguage.
New York,  N.Y. :  Harcourt BraceJovanovich.Collins, A.M. and Loftus, E .F .
(1975).
ASpreading-Activation Thecry of SemanticProcessing.
Psychological Review (82) 407-428.Cullingford, R. (1981).
Integrating KnowledgeSources for Computer "Understanding" Tasks.
IEEETransactions on Systems, Man, and Cybernetics (11)52- 60.Frey, W., Reyle, U., and Rohrer, C. (1983).Automatic Construction of a Knowledge Base byAnalisyng Texts in Natural Language.
Proceedingsof the IJCAI-83, Los Altos, CA: Kaufmann.Fum, D., Guida, G., and Tasso, C. (1984).
APropositional Language for Text Representation,in: B.G.
Bara and G. Guida (Eds.
), ComputationalModels of Natural Language Processing, Amsterdam:North-Holland.Haas, N?
and Hendrix, G.G.
(1983).
Learning byBeing Told: Acquiring ~nowledge for InformationManagement, in: R. Michalski, J.G.
Carbonne11 Jr.,and T.M.
Mitche11, (Eds.
), Machine Learning, PaloAlto,CA: TiogaJohnson-Laird, P .N.
(1983).
Mental Models.Cambridge, U.K.: Cambridge University Press.Kintsch, W. (1974).
The Representation ofin Memory.
Hillsdale, N.J.: Erlbaum.MeaningKintsch, W. and van Dijk, T. (1978).
Toward aModel of Text Comprehension.
Psychological Review(85) 363-394.Lesser, V .R.
and Erman, L.D.
(1977).
ARetrospective View of Hearsay-If Architecture.Proceedings of the IjCAI-77, Los Altos, CA:Kaufmann.Michalski, R., CarbonneiI, J.G.
Jr., and Mitchell,T.M.
(Eds.)
(1983).
Machine Learning, PaloAlto,CA: TiogaNishida, T., Kosaka, A., and Doshita, S. (1983).Towards Knowledge Acquisition f rom NaturalLanguage Documents.
Proceedings of the IJCAI-83,Los Altos, CA: Kaufmann.Norton, L.M.
(1983).
Automated Analysis ofInstructional Texts.
Artif icial Intelligence (20)307-344.Quillian , M.R.
(1969).
The Teachable LanguageComprehender: A simulation program and a theory oflanguage.
Communications ACM (12) 459-476.van Dijk, T. and Kintsch, W. (1983).
Strategies ofDiscourse Comprehension.
New York, N.Y.: AcademicPress.88
