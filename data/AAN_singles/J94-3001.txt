Regular Models of Phonological RuleSystemsRonald M. Kaplan*Xerox Palo Alto Research CenterMartin Kay tXerox Palo Alto Research Centerand Stanford UniversityThis paper presents a set of mathematical nd computational tools for manipulating and rea-soning about regular languages and regular elations and argues that they provide a solid basisfor computational phonology.
It shows in detail how this framework applies to ordered sets ofcontext-sensitive r writing rules and also to grammars in Koskenniemi's two-level formalism.This analysis provides acommon representation f phonological constraints that supports efficientgeneration and recognition by a single simple interpreter.1.
IntroductionOrdered sets of context-sensitive r writing rules have traditionally been used to de-scribe the pronunciation changes that occur when sounds appear in different phono-logical and morphological contexts.
Intuitively, these phenomena ought to be cog-nitively and computationally simpler than the variations and correspondences thatappear in natural language syntax and semantics, yet the formal structure of suchrules seems to require a complicated interpreter and an extraordinarily arge numberof processing steps.
In this paper, we show that any such rule defines a regular elationon strings if its non-contextual part is not allowed to apply to its own output, and thusit can be modeled by a symmetric finite-state transducer.
Furthermore, since regularrelations are closed under serial composition, a finite set of rules applying to eachother's output in an ordered sequence also defines a regular relation.
A single finite-state transducer whose behavior simulates the whole set can therefore be constructedby composing the transducers corresponding to the individual rules.
This transducercan be incorporated into efficient computational procedures that are far more eco-nomical in both recognition and production than any strategies using ordered rulesdirectly.
Since orthographic rules have similar formal properties to phonological rules,our results generalize to problems of word recognition in written text.The mathematical techniques we develop to analyze rewriting rule systems arenot limited just to that particular collection of formal devices.
They can also be ap-plied to other recently proposed phonological or morphological rule systems.
Forexample, we can show that Koskenniemi's (1983) two-level parallel rule systems alsodenote regular relations.
Section 2 below provides an intuitive grounding for the restof our discussion by illustrating the correspondence b tween simple rewriting rulesand transducers.
Section 3 summarizes the mathematical tools that we use to analyzeboth rewriting and two-level systems.
Section 4 describes the properties of the rewrit-ing rule formalisms we are concerned with, and their mathematical characterization* 3333 Coyote Hill Road, Palo Alto CA 94304.
E-mail: kaplan@parc.xerox.comt 3333 Coyote Hill Road, Palo Alto CA 94304.
E-mail: kay@parc.xerox.com(~ 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 3is presented in Sections 5 and 6.
A similar characterization f two-level rule systemsis provided in Section 7.By way of introduction, we consider some of the computational issues presentedby simple morphophonemic rewriting rules such as these:Rule 1N -* m / _ _  \[+labial\]Rule 2N--~nAccording to these rules an underspecified, abstract nasal phoneme N appearing inthe lexical forms iNpractical and iNtractable will be realized as the m in impracticaland as the n in intractable.
To ensure that these and only these results are obtained,the rules must be treated as obligatory and taken in the order given.
As obligatoryrules, they must be applied to every substring meeting their conditions.
Otherwise,the abstract string iNpractical would be realized as inpractical and iNpractical as wellas impractical, and the abstract N would not necessarily be removed from iNtractable.Ordering the rules means that the output of the first is taken as the input to the second.This prevents iNpractical from being converted to inpractical by Rule 2 without firstconsidering Rule 1.These obligatory rules always produce xactly one result from a given input.
Thisis not the case when they are made to operate in the reverse direction.
For example, ifRule 2 is inverted on the string intractable, there will be two results, intractable and iN-tractable.
This is because intractable is derivable by that rule from both of these strings.Of course, only the segments in iNtractable will eventually match against he lexicon,but in general both the N and n results of this inversion can figure in valid interpre-tations.
Compare the words undecipherable and indecipherable.
The n in the prefix un-,unlike the one in in-, does not derive from the abstract N, since it remains unchangedbefore labials (c.f.
unperturbable).
Thus the results of inverting this rule must includeundecipherable for undecipherable ut iNdecipherable for indecipherable sothat each of themcan match properly against he lexicon.While inverting a rule may sometimes produce alternative outputs, there are alsosituations in which no output is produced.
This happens when an obligatory rule isinverted on a string that it could not have generated.
For example, iNput cannot begenerated by Rule 1 because the N precedes a labial and therefore would obligatorilybe converted to m. There is therefore no output when Rule 1 is inverted on iNput.However, when Rule 2 is inverted on input, it does produce iNput as one of its results.The effect of then inverting Rule 1 is to remove the ambiguity produced by invertingRule 2, leaving only the unchanged input to be matched against he lexicon.
Moregenerally, if recognition is carried out by taking the rules of a grammar in reverseorder and inverting each of them in turn, later rules in the new sequence act as filterson ambiguities produced by earlier ones.The existence of a large class of ambiguities that are introduced at one point in therecognition process and eliminated at another has been a major source of difficulty inefficiently reversing the action of linguistically motivated phonological grammars.
In alarge grammar, the effect of these spurious ambiguities i multiplicative, since the in-formation eeded to cut off unproductive paths often does not become available untilafter they have been pursued for some considerable distance.
Indeed, speech under-standing systems that use phonological rules do not typically invert them on stringsbut rather apply them to the lexicon to generate a list of all possible word forms (e.g.Woods et al 1976; Klatt 1980).
Recognition is then accomplished by standard table-332Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemslookup procedures, usually augmented with special devices to handle phonologicalchanges that operate across word boundaries.
Another approach to solving this com-putational problem would be to use the reversed cascade of rules during recognition,but to somehow make the filtering information of particular ules available arlier inthe process.
However, no general and effective techniques have been proposed fordoing this.The more radical approach that we explore in this paper is to eliminate the cascadealtogether, epresenting the information in the grammar as a whole in a single moreunified device, namely, a finite-state transducer.
This device is constructed in twophases.
The first is to create for each rule in the grammar a transducer that exactlymodels its behavior.
The second is to compose these individual rule transducers intoa single machine that models the grammar as a whole.Johnson (1972) was the first to notice that the noncyclic components of standardphonological formalisms, and particularly the formalism of The Sound Pattern of English(Chomsky and Halle 1968), were equivalent in power to finite-state devices despite asuperficial resemblance togeneral rewriting systems.
Phonologists in the SPE tradition,as well as the structuralists hat preceded them, had apparently honored an injunctionagainst rules that rewrite their own output but still allowed the output of a rule toserve as context for a reapplication of that same rule.
Johnson realized that this was thekey to limiting the power of systems of phonological rules.
He also realized that basic?
.
/ .
.
.
.
.
.
rewriting rules were subject o many alternahve modes of apphcahon offering differentexpressive possibilities to the linguist.
He showed that phonological grammars undermost reasonable modes of application remain within the finite-state paradigm.We observed independently the basic connections between rewriting-rule gram-mars and finite-state transducers in the late 1970s and reported them at the 1981meeting of the Linguistic Society of America (Kaplan and Kay 1981).
The mathematicalanalysis in terms of regular elations emerged somewhat later.
Aspects of that analysisand its extension to two-level systems were presented at conferences by Kaplan (1984,1985, 1988), in courses at the 1987 and 1991 Linguistics Institutes, and at colloquia atStanford University, Brown University, the University of Rochester, and the Universityof Helsinki.Our approach differs from Johnson's in two important ways.
First, we abstractaway from the many details of both notation and machine description that are crucialto Johnson's method of argumentation.
Instead, we rely strongly on closure propertiesin the underlying algebra of regular elations to establish the major result that phono-logical rewriting systems denote such sets of string-pairs.
We then use the correspon-dence between regular relations and finite-state transducers to develop a constructiverelationship between rewriting rules and transducers.
This is accomplished by meansof a small set of simple operations, each of which implements a simple mathemat-ical fact about regular languages, regular elations, or both.
Second, our more abstractperspective provides a general framework within which to treat other phonologicalformalisms, existing or yet to be devised.
For example, two-level morphology (Kosken-niemi 1983), which evolved from our early considerations of rewriting rules, relies forits analysis and implementation  the same algebraic techniques.
We are also encour-aged by initial successes in adapting these techniques to the autosegmental formalismdescribed by Kay (1987).2.
Rewriting Rules and TransducersSupposing for the moment hat Rule 2 (N --* n) is optional, Figure 1 shows the tran-sition diagram of a finite-state transducer that models it.
A finite-state transducer has333Computational Linguistics Volume 20, Number 3Figure 1Rule 2 as optional.N:n { { \ [ 0 ~ ~  a:a ... n:n,N:N ... z:zFigure 2Rule 2 as obligatory.N:n ~ other, n:ntwo tapes.
A transition can be taken if the two symbols eparated by the colon in itslabel are found at the current position on the corresponding tapes, and the currentposition advances across those tape symbols.
A pair of tapes is accepted if a sequenceof transitions can be taken starting at the start-state (conventionally labeled 0) and atthe beginning of the tapes and leading to a final state (indicated by double circles) atthe end of both tapes.
In the machine in Figure 1, there is a transition from state 0 tostate 0 that translates every phoneme into itself, reflecting the fact that any phonemecan remain unchanged by the optional rule.
These are shown schematically in thediagram.
This machine will accept a pair of tapes just in case they stand in a certainrelation: they must be identical except for possible replacements of N on the first tapewith n on the second.
In other words, the second tape must be one that could haveresulted from applying the optional rule to the string on the first tape.But the rule is in fact obligatory, and this means that there must be no occurrencesof N on the second tape.
This condition is imposed by the transducer in Figure 2.
Inthis diagram, the transition label "other" abbreviates the set of labels a :a, b:b, .
.
,  z:z,the identity pairs formed from all symbols that belong to the alphabet but are notmentioned explicitly in this particular ule.
This diagram shows no transition overthe pair N:N and the transducer therefore blocks if it sees N on both tapes.
This isanother abbreviatory convention that is typically used in implementations to reducetransducer storage requirements, and we use it here to simplify the state diagrams wedraw.
In formal treatments such as the one we present below, the transition functionis total and provides for transitions from every state over every pair of symbols.
Anytransition we do not show in these diagrams in fact terminates at a single nonfinalstate, the "failure" state, which we also do not show.Figure 3 is the more complicated transducer that models the obligatory behaviorof Rule 1 (N --* m~ .
+\[labial\]).
This machine blocks in state 1 if it sees the pair N:mnot followed by one of the labials p, b, m. It blocks in state 2 if it encounters the pairN:N followed by a labial on both tapes, thus providing for the situation in which therule is not applied even though its conditions are satisfied.
If it does not block and bothtapes are eventually exhausted, it accepts them just in case it is then in one of the finalstates, 0 or 2, shown as double circles.
It rejects the tapes if it ends up in the nonfinalstate 1, indicating that the second tape is not a valid translation of the first one.We have described transducers as acceptors of pairs of tapes that stand in a cer-tain relation.
But they can also be interpreted asymmetrically, as functions either from334Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsother, b:bm:m p:pb:b m:mP:PN:mN:NFigure 3Rule 1 as obligatory.b:b m:mp:pother, n:nb:b m:m p:p N:mN:nFigure 4Composition of obligatory Rules 1 and 2.more abstract to less abstract strings or the other way around.
Either of the tapes cancontain an input string, in which case the output will be written on the other.
In eachtransition the machine matches the symbol specified for the input tape and writes theone for the output.
When the first tape contains the input, the machine models thegenerative application of the rule; when the second tape contains the input, it modelsthe inversion of the rule.
Thus, compared with the rewriting rules from which theyare derived, finite-state transducers have the obvious advantage of formal and compu-tational simplicity.
Whereas the exact procedure for inverting rules themselves i  notobvious, it is clearly different from the procedure required for generating.
The corre-sponding transducers, on the other hand, have the same straightforward interpretationin both directions.While finite-state transducers are attractive for their formal simplicity, they havea much more important advantage for our purposes.
A pair of transducers connectedthrough acommon tape models the composition of the relations that those transducersrepresent.
The pair can be regarded as performing a transduction between the outertapes, and it turns out that a single finite-state transducer can be constructed that per-forms exactly this transduction without incorporating any analog of the intermediatetape.
In short, the relations accepted by finite-state transducers are closed under serialcomposition.
Figure 4 shows the composition of the m-machine in Figure 3 and then-machine in Figure 2.
This transducer models the cascade in which the output ofRule 1 is the input to Rule 2.335Computational Linguistics Volume 20, Number 3Nm0- -  0NFigure 5Generation of intractable.i tiFigure 6Generation of impractical.- -  1 BLOCK: No Labialt r,t o lt rN p rl i f om p rNn2 BLOCK: LabialaaThis machine is constructed so that it encodes all the possible ways in which them-machine and n-machine could interact hrough a common tape.
The only interestinginteractions involve N, and these are summarized in the following table:input m-machine output IL input n-machine output IN labial follows m mN nonlabial follows N nAn N in the input to the m-machine is converted to m before a labial and this m remainsunchanged by the n-machine.
The only instances of N that reach the n-machine musttherefore be followed by nonlabials and these must be converted to n. Accordingly,after converting N to m, the composed machine is in state 1, which it can leave onlyby a transition over labials.
After converting N to n, it enters state 2, from which thereis no labial transition.
Otherwise, state 2 is equivalent to the initial state.Figure 5 illustrates the behavior of this machine as a generator applied to theabstract string iNtractable.
Starting in state 0, the first transition over the "other" arcproduces i on the output tape and returns to state 0.
Two different ransitions are thenpossible for the N on the input tape.
These carry the machine into states 1 and 2 andoutput the symbols m and n respectively.
The next symbol on the input tape is t. Sincethis is not a labial, no transition is possible from state 1, and that branch of the processtherefore blocks.
On the other branch, the t matches the "other" transition back tostate 0 and the machine stays in state 0 for the remainder of the string.
Since state 0336Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsi t 0iF igure 7Recognition of intractable.n t r a  0 0 0-4n t r aN t r aT ToT04n t r a0in p u t, 0q 04~ n p u t0NBLOCK: Labial 2nFigure 8Recognition of input.is a final state, this is a valid derivation of the string intractable.
Figure 6 is a similarrepresentation for the generation of impractical.Figures 7 and 8 illustrate this machine operating as a recognizer.
As we pointedout earlier, there are two results when the cascade of rules that this machine representsis inverted on the string intractable.
As Figure 7 shows, the n can be mapped into n bythe n:n transition at state 0 or into N by the transition to state 2.
The latter transitionis acceptable because the following t is not a labial and thus matches against he"other" transition to state 0.
When the following symbol is a labial, as in Figure 8,the process blocks.
Notice that the string iNput that would have been written on theintermediate ape before the machines were composed is blocked after the secondsymbol by constraints coming from the m-machine.Repeated composition reduces the machines corresponding tothe rules of a com-plete phonological grammar to a single transducer that works with only two tapes,one containing the abstract phonological string and the other containing its phoneticrealization.
General methods for constructing transducers such as these rely on fun-damental mathematical notions that we develop in the next section.3.
Mathemat ica l  Concepts  and  Too lsFormal languages are sets of strings, mathematical objects constructed from a finitealphabet E by the associative operation of concatenation.
Formal anguage theory hasclassified string sets, the subsets of E*, in various ways and has developed corre-337Computational Linguistics Volume 20, Number 3spondences between languages, grammatical notations for describing their memberstrings, and automata for recognizing them.
A similar conceptual framework can beestablished for str ing relations.
These are the collections of ordered tuples of strings,the subsets of ~* x ...  x ~*.We begin by defining an n-way concatenation operation in terms of the familiarconcatenation f simple strings.
If X = (xl ,  x2, .
.
.
x , )  and Y = (Yl, Y2, .
.
.
yn) are n-tuplesof strings, then the concatenation f X and Y, written X. Y or simply XY,  is defined byX.
Y=# IX lY l ,X2Y2 , .
.
.Xnyn)That is, the n-way concatenation f two string-tuples i the tuple of strings formed bystring concatenation of corresponding elements.
The length of a string-tuple IX\] canbe defined in terms of the lengths of its component strings:IXl =ai ~ IxiliThis has the expected property that IX.
Y\] = IX\] + IY\], even if the elements of Xor of Y are of different lengths.
Just as the empty string c is the identity for simplestring concatenation, the n-tuple all of whose elements are e is the identity for n-wayconcatenation, and the length of such a tuple is zero.3.1 Regular Relations and Finite-State TransducersWith these definitions in hand, it is immediately possible to construct families of stringrelations that parallel the usual classes of formal languages.
Recall, for example, theusual recursive definition of a regular language over an alphabet G (superscript idenotes concatenation repeated i times, according to the usual convention, and we letG~ denote G t3 {e}):.2..The empty set and {a} for all a in E ~ are regular languages.If L1, L2, and L are regular languages, then so areL1 ?
L2 -- {xy  I x E Ll~y c L2} (concatenation)L1 U L2 (union)oo Li L* = U (Kleene closure)i=0There are no other regular languages.We can use exactly the same scheme to define regular n-relations in terms of n-wayconcatenation:.2..The empty set and {a} for all a in ~ x ...  x G~ are regular n-relations.If R1, R2, and R are regular n-relations, then so areR1 ?
R2 = {xy  \] x E Rl,y E R2} (n-way concatenation)R1 U R2 (union)O O  .R* = U R' (n-way Kleene closure)i=0There are no other regular n-relations.338Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsOther families of relations can also be defined by analogy to the formal languagecase.
For example, a system of context-free r writing rules can be used to define acontext-free n-relation simply by introducing n-tuples as the terminal symbols of thegrammar.
The standard context-free derivation procedure will produce tree structureswith n-tuple leaves, and the relational yield of such a grammar is taken to be the setof n-way concatenations of these leaves.
Our analysis of phonological rule systemsdoes not depend on expressive power beyond the capacity of the regular elations,however, and we therefore confine our attention to the mathematical and computa-tional properties of these more limited systems.
The relations we refer to as "regular,"to emphasize the connection to formal anguage theory, are often known as "rationalrelations" in the algebraic literature, where they have been extensively studied (e.g.Eilenberg 1974).The descriptive notations and accepting automata for regular languages can alsobe generalized to the n-dimensional case.
An n-way regular expression is simply aregular expression whose terms are n-tuples of alphabetic symbols or c. For ease ofwriting we separate the elements of an n-tuple by colons.
Thus the expression a:b ~:cdescribes the two-relation containing the single pair (a, bc), and a:b:c" q:r:s describesthe three-relation {(anq, bnr~cns) I n >_ 0}.
The regular-expression notation providesfor concatenation, union, and Kleene-closure of these terms.
The accepting automatafor regular n-relations are the n-way finite-state transducers.
As illustrated by thetwo-dimensional examples given in Section 2, these are an obvious extension of thestandard one-tape finite-state machines.The defining properties of the regular languages, regular expressions, and finite-state machines are the basis for proving the well-known Kleene correspondencetheorems howing the equivalence of these three string-set characterizations.
Theseessential properties carry over in the n-way generalizations, and therefore the cor-respondence theorems also generalize.
In particular, simple analogs of the standardinductive proofs show thatEvery n-way regular expression describes a regular n-relation;Every regular n-relation is described by an n-way regular expression;Every n-tape finite-state transducer accepts a regular n-relation; andEvery regular n-relation is accepted by an n-tape finite-state trans-ducer.The strength of our analysis method comes from the equivalence of these differentcharacterizations.
While we reason about the regular relations in algebraic and set-theoretic terms, we conveniently describe the sets under discussion by means of reg-ular expressions, and we prove essential properties by constructive operations on thecorresponding finite-state transducers.
In the end, of course, it is the transducers thatsatisfy our practical, computational goals.A nondeterministic (one-tape) finite-state machine is a quintuple (G, Q,q,F, 5),where G is a finite alphabet, Q is a finite set of states, q c Q is the initial state, andF c Q is the set of final states.
The transition function 6 is a total function that mapsQ x G* to 2 Q, the set of all subsets of Q, and every state s in Q is vacuously a memberof 6(s, ~).
We extend the function 6 to sets of states, so that for any P c_ Q and a E G~,6(P, a) = Upcp 6(p, a).
We also define the usual extension of ~ to a transition function5" on G* as follows: for all r in Q, 6*(r,?)
= 6(r,c) and for all u E G* and a c G*,~*(r~ ua) = 6(~*(r, u), a).
Thus, the machine accepts a string x just in case 6*(q, x) N F isnonempty; that is, if there is a sequence of transitions over x beginning at the initial339Computational Linguistics Volume 20, Number 3state and ending at a set of states at least one of which is final.
We know, of course, thatevery regular language is also accepted by a deterministic, e-free finite-state machine,but assuming vacuous c transitions at every state reduces the number of special casesthat have to be considered in some of the arguments below.A nondeterministic n-way finite-state transducer (fst) is defined by a quintuplesimilar to that of an fsm except for the transition function 6, a total function that mapsQ x E ~ x ... x E ~ to 2 Q.
Partly to simplify the mathematical presentation and partlybecause only the binary relations are needed in the analysis of rewriting rules andKoskenniemi's two-level systems, from here on we frame the discussion in terms ofbinary relations and two-tape transducers.
However, the obvious extensions of theseproperties do hold for the general case, and they may be useful in developing aformal understanding of autosegmental phonological nd morphological theories (foran illustration, see Kay 1987).The transition function 6of a transducer also extends to a function 5" that carries astate and a pair of strings onto a set of states.
Transitions in fsts are labeled with pairsof symbols and we continue to write them with a colon separator.
Thus, u:v labels atransition over a u on the first tape and a v on the second.
A finite-state transducerT defines the regular elation R(T), the set of pairs (x, y) such that 6*(q, x, y) containsa final state.
The pair e:e plays the same role as a label of transducer t ansitions thatthe singleton cplays in one-tape machines, and the e-removal algorithm for one-tapemachines can be generalized to show that every regular relation is accepted by anc:c-free transducer.
However, it will also be convenient for some arguments below toassume the existence of vacuous ?
:e transitions.We write xRy if the pair (x, y) belongs to the relation R. The image of a string xunder a relation R, which we write x/R, is the set of strings y such that (x, y) is inR.
Similarly, R/y is the set of strings that R carries onto y.
We extend this notation tosets of strings in the obvious way: X/R = Uxcx x/R.
This relational notation gives us asuccinct way of describing the use of a corresponding transducer as either a generatoror a recognizer.
For example, if R is the regular elation recognized by the transducerin Figure 4, then R/intractable is the set of strings that R maps to intractable, namely{intractable, iNtractable}, as illustrated in Figure 7.
Similarly, iNtractable/R is the set ofstrings {intractable} that R maps from iNtractable (Figure 5).We rely on the equivalence between regular languages and relations and theircorresponding finite-state automata, and we frequently do not distinguish betweenthem.
When the correspondence b tween a language L and its equivalent machinemust be made explicit, we let M(L) denote a finite-state machine that accepts L. Simi-larly, we let T(R) denote a transducer that accepts the relation R, as provided by thecorrespondence theorem.
We also rely on several of the closure properties of regularlanguages (Hopcroft and Ullman 1979): for regular languages L1 and L2, L1L2 is theregular language containing all strings XlX 2 such that x1 E L1 and x2 C L2.
We usesuperscripts for repeated concatenation: L n contains the concatenation f n membersof L, and L* contains trings with arbitrary repetitions of strings in L, including zero.The operator Opt is used for optionality, so that Opt(L) is L U {~}.
We write E for thecomplement of L, the regular language containing all strings not in L, namely, ~* - L.Finally, Rev(L) denotes the regular language consisting of the reversal of all the stringsin L.3.2 Properties of Regular RelationsThere are a number of basic connections between regular elations and regular lan-guages.
The strings that can occur in the domain and range of a regular elation R340Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systems(Dora(R) = R/G* and Range(R) = G*/R) are the regular languages accepted by thefinite-state machines derived from T(R) by changing all transition labels a:b to a andb respectively, for all a and b in G~.
Given a regular language L, the identity relationId(L) that carries every member of L into itself is regular; it is characterized by the fstobtained from an fsm M(L) by changing all transition labels a to a:a.
Clearly, for alllanguages L, L = Dom(Id(L)) = Range(Id(L)).
The inverse R -1 of a regular elation R isregular, since it is accepted by a transducer formed from T(R) by changing all labelsa:b to b:a.
The reversal Rev(R), consisting of pairs containing the reversal of strings inR's pairs, is also regular; its accepting transducer is derived from T(R) by generalizingthe standard one-tape fsm construction for regular language reversal.Given a pair of regular languages L1 and L2 whose alphabets can, without lossof generality, be assumed equal, the relation L1 x L2 containing their Cartesian prod-uct is regular.
To prove this proposition, we let M1 = (Y\],,Q1~ql~F1,61) and M2 =(G, Q2~ q2~ F2~ 62) be fsms accepting L1 and L2 respectively and define the fstT = (G, Q1 x Q2, (ql, q2), F1 x F2, 6)where for any S 1 C Q1, $2 E Q2 and a, b c G~6((S1, S2),a, b) = 6 l(Sl,a) x 62(s2, b)We can show by induction on the number of transitions that for any strings x and y,6*((q l ,q2) ,x ,y  ) --~ 6~(ql,X ) X 6~(q2,y )This result holds trivially when x and y are both c by the general definition of 6*.
If aand b are in G * and u and v are in G*, then, using the definition of 6* and the definitionjust given for 6 of the Cartesian product machine, we have6*((ql~q2),ua, vb) -- 6(6*((ql~q2),u,v)~a,b)= 6(6~ (ql, u) x 6~ (q2, v), a, b) by induction-- 61(6~(q1,u),a) x 62(6~(q2, v),b)---- 6~(ql, ua) x 6~(q2,vb)Thus, 6*((ql,q2),x,y) contains a final state if and only if both 6~(ql,x) and 6~(q2,y)contain final states, so T accepts exactly the strings in L1 x L2.
\[\]Note that L x L is not the same as Id(L), because only the former can map onemember of L onto a different one.
If L contains the single-character strings a and b,then Id(L) only contains the pairs (a, a / and (b, b) while L x L also contains (a, b) and(b,a).A similar construction is used to prove that regular elations are closed under thecomposition operator discussed in Section 2.
A pair of strings (x, y) belongs to therelation R1 o R2 if and only if for some intermediate string z, (x, z) c R1 and (z, y) c R2.If T(R1) = (~, Q1, ql, Fa, 61) and T(R2) = (G, Q2, q2, F2, 62), the composition R1 o Rz isaccepted by the composite fst(~, Q1 x Q2, (qa, q2), F1 X F2, 6)where6((Sl, $2),a, b) = {(tl, t2) \]for some c E ~,  tl E 6(sl,a, c) and t 2 E 6(52, G b)}341Computational Linguistics Volume 20, Number 3In essence, the 6 for the composite machine is formed by canceling out the interme-diate tape symbols from corresponding transitions in the component machines.
By aninduction on the number of transitions patterned after the one above, it follows thatfor any strings x and y,6*((ql,q2),x,y) = {(h,t2) \[for some z E ~,*, tl 6 8~(ql,x,z) and t2 6 (~(q2~z~y)}The composite transducer enters a final state just in case both component machines dofor some intermediate z.
This establishes that the composite transducer does representthe composition of the relations R1 and R2, and that the composition of two regularrelations is therefore regular.
Composition of regular relations, like composition ofrelations in general, is associative: (al o R2) o R3 = R1 o (R2 o R3) = R1 o R2 o R3.
Forrelations in general we also know that Range(R1 o a2) = Range(R1)/R2.We can use this fact about the range of a composition to prove that the image ofa regular language under a regular relation is a regular language.
(It is well knownthat the images under a regular relation of languages in other classes, for example thecontext-free languages, also remain within those classes (e.g.
Harrison 1978), but theseother results do not concern us here.)
That is, if L is a regular language and R is anarbitrary regular relation, then the languages L/R and R/L are both regular.
If L is aregular language, we know there exists a regular relation Id(L) that takes all and onlymembers of L into themselves.
Since L = Range(Id(L)) it follows thatL/R = (Range(Id(L)))/R= Range(Id(L) o R)Id(L) oR is regular and we have already observed that the range of any regular elationis a regular language.
By symmetry of argument we know that R/L is also regular.Just like the class of regular languages, the class of regular relations is by def-inition closed under the operations of union, concatenation, and repeated concate-nation.
Also, the Pumping Lemma for regular languages immediately generalizes toregular elations, given the definitions of string-tuple length and n-way concatenationand the correspondence to finite-state transducers.
The regular relations differ fromthe regular languages, however, in that they are not closed under intersection andcomplementation.
Suppose that R1 is the relation {(a',bnc *) \[ n > 0} and R2 is therelation {(ant b*c n) I n >_ 0}.
These relations are regular, since they are defined by theregular expressions a:b* ?
:c* and ?
:b* a:c respectively.
The intersection R1 N R2 is{(ant bnc n) \] n >__ 0}.
The range of this relation is the context-free language bnc ~, whichwe have seen is not possible if the intersection is regular.
The class of regular elationsis therefore not closed under intersection, and it immediately follows that it is also notclosed under complementation: by De Morgan's law, closure under complementationand union would imply closure under intersection.
Nonclosure under complementa-tion further implies that some regular elations are accepted by only nondeterministictransducers.
If for every regular relation there is a deterministic acceptor, then thestandard technique (Hopcroft and Ullman 1979) of interchanging its final and nonfi-nal states could be used to produce an fst accepting the complement relation, whichwould therefore be regular.3.3 Same-Length Regular RelationsClosure under intersection and relative difference, however, are crucial for our treat-ment of two-level rule systems in Section 7.
But these properties are required only forthe same-length regular relations, and it turns out that this subclass is closed in thenecessary ways.
The same-length relations contain only string-pairs (x, y) such that342Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsthe length of x is the same as the length of y.
It may seem obvious that the relevantclosure properties do hold for this subclass, but for the sake of completeness we sketchthe technical details of the constructions by which they can be established.We make use of some auxiliary definitions regarding the path-language of a trans-ducer.
A path-string for any finite-state transducer T is a (possibly empty) sequenceof symbol-pairs ul : Vl u2 : v2.. ?
un : vn that label the transitions of an accepting path inT.
The path-language of T, notated as Paths(T), is simply the set of all path-stringsfor T. Paths(T) is obviously regular, since it is accepted by the finite-state machineconstructed simply by interpreting the transition labels of T as elements of an alpha-bet of unanalyzable pair-symbols.
Also, if P is a finite-state machine that accepts apair-symbol language, we define the path-relation ReI(P) to be the relation acceptedby the fst constructed from P by reinterpreting every one of its pair-symbol labelsas the corresponding symbol pair of a transducer label.
It is clear for all fsts T thatRel(M(Paths(T))) = R(T), the relation accepted by T.Now suppose that R1 and R2 are regular elations accepted by the transducers T1and T2, respectively, and note that Paths(T1) A Paths(T2) is in fact a regular languageof pair-symbols accepted by some fsm P. Thus Rel(P) exists as a regular relation.Moreover, it is easy to see that Rel(P) C_ R1 n R2.
This is because very string-pairbelonging to the path-relation is accepted by a transducer with a path-string thatbelongs to the path-languages of both T1 and T2.
Thus that pair also belongs to bothR1 and R2.The opposite containment does not hold of arbitrary regular elations.
Suppose apair (x, y) belongs to both R1 and R2 but that none of its accepting paths in T1 has thesame sequence of transition labels as an accepting path in T2.
Then there is no pathin Paths(T1) N Paths(T2) corresponding to this pair and it is therefore not contained inRel(P).
This situation can arise when the individual transducers have transitions withe-containing labels.
One transducer may then accept a particular string pair througha sequence of transitions that does not literally match the transition sequence takenby the other on that same pair of strings.
For example, the first fst might accept hepair (ab, c) by the transition sequence a:e b:c, while the other accepts that same pairwith the sequence a: c b: e. This string-pair belongs to the intersection of the relations,but unless there is some other accepting path common to both machines, it will notbelong to Rel(P).
Indeed, when We apply this construction tofsts accepting the relationswe used to derive the context-free language above, we find that Rel(P) is the emptyrelation (with no string-pairs at all) instead of the set-theoretic intersection R1 N R2.However, if R1 and R2 are accepted by transducers none of whose accepting pathshave e-containing labels, then a string-pair belonging to both relations will be acceptedby identically labeled paths in both transducers.
The language Paths(T1) A Paths(T2)will contain a path-string corresponding to that pair, that pair will belong to Rel(P),and ReI(P) will be exactly R1 N R2.
Thus, we complete the proof that the same-lengthrelations are closed under intersection by establishing the following proposition:LemmaR is a same-length regular elation if and only if it is accepted by an e-free finite-statetransducer.ProofThe transitions of an e-free transducer T set the symbols of the string-pairs it acceptsin one-to-one correspondence, so trivially, R(T) is same-length.
The proof in the otherdirection is more tedious.
Suppose R is a same-length regular relation accepted bysome transducer T which has transitions of the form u:e or e:v (with u and v not e;343Computational Linguistics Volume 20, Number 3we know all e:e transitions can be eliminated by the obvious generalization of theone-tape -removal algorithm).
We systematically remove all c-containing transitionsin a finite sequence of steps each of which preserves the accepted relation.
A path fromthe start-state to a given nonfinal state will contain some number of u:~ transitionsand some number of c:v transitions, and those two numbers will not necessarily beidentical.
However, for all paths to that state the difference between those numberswill be the same, since the discrepancy must be reversed by each path that leads fromthat state to a final state.
Let us define the imbalance characterizing a state to be thedifference in the number of u: c and c: v transitions on paths leading to that state.
Sincean acyclic path cannot produce an imbalance that differs from zero by more than thenumber of states in the machine, the absolute value of the imbalance is bounded bythe machine size.
On each iteration our procedure has the effect of removing all stateswith the maximum imbalance.
First, we note that transitions of the form u :v alwaysconnect a pair of states with the same imbalance.
Such transitions can be eliminated infavor of an equivalent sequence of transitions c:v and u:c through a new state whoseimbalance is one less than the imbalance of the original two states.
Now supposethat k > 0 is the maximum imbalance for the machine and that all u:v transitionsbetween states of imbalance k have been eliminated.
If q is a k-imbalance state, it willbe entered only by u: c transitions from k - 1 states and left only by c: v transitions alsoto k - 1 states.
For all transitions u:~ from a state p to q and all transitions ?
:v fromq to r, we construct a new transition u:v from p to r. Then we remove state q fromthe machine along with all transitions entering or leaving it.
These manipulations donot change the accepted relation but do reduce by one the number of k-imbalancestates.
We repeat his procedure for all k states and then move on to the k - 1 states,continuing until no states remain with a positive imbalance.
A symmetric procedureis then used to eliminate all the states whose imbalance is negative.
In the end, T willhave been transformed to an c-free transducer that still accepts R. \[\]The same-length regular relations are obviously closed under union, concatena-tion, composition, inverse, and reverse, in addition to intersection, since all of theseoperations preserve both regularity and string length.
An additional path-languageargument shows that they are also closed under relative difference.
Let T1 and T2 bee-free acceptors for R1 and R2 and construct an fsm P that accepts the regular pair-symbol language Paths(T1) -Paths(T2).
A string-pair belongs to the regular relationRel(P) if and only if it has an accepting path in T~ but not in T2.
Thus Rel(P) is R1 - a2.Being a subset of R1, it is also same-length.3.4 Summary of Mathematical ToolsLet us summarize the results to this point.
If L1, L2, and L are regular languages andR1, R2, and R are regular relations, then we know that the following relations areregular:R1 U R2 R1 ?
R2 R* R -1 RIo R2 Id(L) L1 ?
L2 Rev(R)We know also that the following languages are regular (x is a string):Dom(R) Range(R) L/R R/L x/R R/xFurthermore, if R1, R2, and R are in the same-length subclass, then the following alsobelong to that restricted subclass:R1 t3 R2 R1 ?
R2 R* R -1 R1 o R2 Rev(R) R1 N R2 R1 - R2344Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsId(L) is also same-length for all L. Intersections and relative differences of arbitraryregular relations are not necessarily regular, however.
We emphasize that all theseset-theoretic, algebraic operations are also constructive and computational in nature:fsms or fsts that accept he languages and relations that these operations pecify canbe constructed irectly from machines that accept heir operands.Our rule translation procedures makes use of regular relations and languagescreated with five special operators.
The first operator produces a relation that freelyintroduces ymbols from a designated set S. This relation, Intro(S), is defined by theexpression \[Id(~) U \[{e} x S\]\]*.
If the characters a and b are in ~ and S is {$}, forexample, then Intro(S) contains an infinite set of string pairs including (a,a), (a, $a),(a, a$$$), (ab, $$a$b$$), and so on.
Note that Intro(S) -~ removes all elements of S froma string if S is disjoint from G.The second is the Ignore operator.
Given a regular language L and a set of symbolsS, it produces a regular language notated as Ls and read as "L ignoring S." Thestrings of Ls differ from those of L in that occurrences of symbols in S may be freelyinterspersed.
This language is defined by the expression Ls = Range(Id(L) o Intro(S)).It includes only strings that would be in L if some occurrences of symbols in S wereignored.The third and fourth operators enable us to express if-then and if-and-only-if con-ditions on regular languages.
These are the operators If-P-then-S ("if prefix then suffix")and If-S-then-P ("if suffix then prefix").
Suppose L1 and L2 are regular languages andconsider the set of stringsIf-P-then-S(L1, L2) = {x \] for every partition XlX2 of x, if X1 E L1, then X2 E L2}A string is in this set if each of its prefixes in L1 is followed by a suffix in L2.
Thisset is also a regular language: it excludes exactly those strings that have a prefix in L1followed by a suffix not in L2 and can therefore be defined byIf-P-then-S(L1, L2) = ElL2This operator, the regular-language analog of the logical equivalence between P --* Qand -~(P A -~Q), involves only concatenation and complementation, operations underwhich regular languages (though not relations) are closed.
We can also express thesymmetric requirement that a prefix be in L1 if its suffix is in L2 by the expressionhIf-S-then-P (L1, L2) = L1L2Finally, we can combine these two expressions to impose the requirement that a prefixbe in L1 if and only if its suffix is in L2:P-iff-S(L1, L2) = If-P-then-S(L1, L2) N If-S-then-P(L1, L2)These five special operators, being constructive combinations of more primitive ones,can also serve as components of practical computation.The double complementation in the definitions of these conditional operators, andalso in several other expressions to be introduced later, constitutes an idiom for ex-pressing universal quantification.
While a regular expression ~f13` expresses the propo-sition that an instance of fl occurs between some instance of c~ and some instance of 3 ,`the expression c~fl3` claims that an instance of fl intervenes between every instance ofc~ and a following instance of 3'.345Computational Linguistics Volume 20, Number 34.
Rewriting Rule FormalismsPhonological rewriting rules have four parts.
Their general form is-~  ~/,,X pThis says that the string ~ is to be replaced by (rewritten as) the string ~b whenever itis preceded by A and followed by p. If either A or p is empty, it is omitted and, if bothare empty, the rule is reduced toThe contexts, or environments, ,~and p are usually allowed to be regular expressionsover a basic alphabet of segments.
This makes it easy to write, say, a vowel-harmonyrule that replaces a vowel that is not specified for backness as a back or front vowelaccording as the vowel in the immediately preceding syllable is back or front.
This isbecause the Kleene closure operator can be used to state that any number of consonantscan separate the two vowels.
The rule might be formulated as follows:Vi ---+ Bi/BjC *where Bi is the back counterpart of the vowel Vi, and Bj is another (possibly different)back vowel.
There is less agreement on the restrictions that should apply to ~ and~b, the portions that we refer to as the center of the rule.
They are usually simplestrings and some theorists would restrict hem to single segments.
However, theserestrictions are without interesting mathematical consequences and we shall be opento all versions of the theory if we continue to take it that these can also denote arbitraryregular languages.It will be important to provide for multiple applications ofa given rule, and indeed,this will turn out to be the major source of difficulty in reexpressing rewriting rules interms of regular elations and finite-state transducers.
We have already remarked thatour methods work only if the part of the string that is actually rewritten by a rule isexcluded from further ewriting by that same rule.
The following optional rule showsthat this restriction is necessary to guarantee r gularity:c --.
ab/a __  bIf this rule is allowed to rewrite material that it introduced on a previous application,it would map the regular language {ab} into the context-free language {anb n I 1 < n},which we have already seen is beyond the power of regular elations.However, we do not forbid material produced in one application of a rule fromserving as context for a subsequent application of that rule, as would routinely bethe case for a vowel-harmony rule, for example.
It is this restriction on interactionsbetween different applications of a given rule that motivates the notation--.
~/;~ prather thanThe context refers to a part of the string that the current application of the rule does notchange but which, since it may have been changed in a previous application, allowsfor an interaction between successive applications.346Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsThe important outstanding question concerning interactions between applicationsof one and the same rule at different positions in a string has to do with the relativeorder in which they take place.
Consider the obligatory rulea --* b/ab __  baas applied to the stringabababababaAt least three different outcomes are possible, namely:(1) abbbabbbaba(2) ababbbabbba(3) abbbbbbbbbaResult (1) is obtained if the first application is at the leftmost eligible position in thestring; each successive application applies to the output of any preceding one, andfurther to the right in the string.
We call this the left-to-right strategy.
The correspond-ing right-to-left strategy gives rise to (2).
Result (3) comes from identifying all possiblerule applications in the original string and carrying them out simultaneously.
All threestrategies have been advocated by phonologists.
We shall assume that each rule ismarked individually to show which strategy is to be employed for it.
We shall con-centrate on these three strategies, but other less obvious ones can also be treated bysimple rearrangements of our techniques.Optional rules and most obligatory rules will produce at least one output string,perhaps just a copy of the input if the conditions for application are nowhere satisfied.But certain obligatory rules are anomalous in that they may produce no output at all.The following left-to-right rule is a case in point:- .
b /bIf a string containing the symbol b is input to this rule, another b will be insertedimmediately after it, and that one will serve to trigger the rule again.
This process willnever terminate, and no finite-length output is ever produced.
Strange as they mayseem, rules like this are useful as filters to eliminate undesired paths of derivation.In contrast to obligatory rules, optional rules typically produce many outputs.
Forexample, if the rule above (a --* b/ab __  ba) is marked as optional and left-to-right andis also applied to the string abababababa, the following, in addition to (1), would beamong its outputs:(4) abbbabababa(5) ababbbababaThe string (4) is similar to (1) except hat only the leftmost application of the rule hasbeen carried out.
For (5) the application in the middle would not have been possiblefor the obligatory rule and is possible here only because the necessary context was notdestroyed by an application further to the left.Kenstowicz and Kisseberth (1979), who discuss a number of rule application strate-gies in great detail, cite a case in which one rule seems to be required in the grammars347Computational Linguistics Volume 20, Number 3of two languages.
However, it must be applied left to right in one, but right to leftin the other.
In the Australian language Gidabal, the long vowel of certain suffixesbecomes hort if the vowel of the preceding syllable is long.
We find, for example,yagd+ya 'should fix' where we would otherwise xpect yag~+ya.
(We use + to mark thepoint at which the suffix begins and a bar over a vowel to show that it is long.)
Theinteresting question concerns what happens when several of these suffixes are addedto the same stem.
Some examples are:Underlying Surfacebarbar +y~+d~ng barbar +a+dang'straight above'djalum+bF~+d4ng+b~ djalum+b~+dang+b~'is certainly right on the fish'gun~m+b~+daang+b~ gunF~m+ba+d~ng+be'is certainly right on the stump'The rule that Kenstowicz and Kisseberth propose is essentially the following:9 --* V /9  C* __This produces the desired result only if applied left to right and only if obligatory.
Thealternation of long and short vowels results from the fact that each application shortensa long vowel that would otherwise serve as part of the context for a subsequentapplication.The same rule appears as the rhythmic law in Slovak--all suffix vowels are short-ened following a long vowel, as in the following examples:vol+~+me 'we call' chTt+a+me 'we read'vol+~v+a+me 'w  call often' ch~t+av+a+me 'we read often'This time the rule must be applied either simultaneously or from right to left.It might seem that a transducer mimicking the operation of a right-to-left rulewould have to examine its tapes in the opposite order from one that implemented aleft-to-right rule, and it is difficult to see how two transducers operating in differentdirections could then be composed.
However, we shall see that directionality in rewrit-ing rules is not mirrored by directionality in the transducers.
Instead, directionalitydetermines which of the two tapes the left and right contexts must appear on.
In aleft-to-right rule, the left context of the rule is to be verified against he portion of thestring that results from previous applications of that rule, whereas the right context isto be verified against he portion of the string that has not yet been changed but mayeventually be modified by applications further to the right.
In a right-to-left rule, thesituation is reversed.Consider again the left-to-right rule schema9 --, V /9  C* __which applies to the string db~c~d6 to give ~bec~do.
The portions of the tapes that supportthe two applications of the rule are boxed in the diagram on the left below.
The diagramon the right shows how it comes about that there are three applications when the ruleis taken as moving from right to left.\[ fi b c l l  d a' b le l  c I l l a \ [o \ ]348Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsIt is often convenient in phonological rules to introduce a special symbol to markthe beginning and end of the string.
This allows edge-conditioned string transfor-mations to be encoded in rewriting rules.
For example, Kenstowicz and Kisseberthgive the following rule to describe the devoicing of final obstruents in German andRussian:\[+obstruent\] --+ \[-voiced\] / _ _  #We will consider the feature notation exemplified here shortly.
For the moment, it canbe taken as equivalent to a set of rules whose effect is to replace any segment that isclassified as an obstruent by its unvoiced equivalent before the boundary symbol thatmarks the end of a word.
It accounts for the phonological realization of the Russianform xleb 'bread' as xlep.
The boundary symbol # is special in the rule formalism inthat it can only appear in the context parts of a rule, never in the input or outputpatterns, and it never matches an element hat appears explicitly in the string.
Al-though boundary-context rules require distinctive mathematical treatment, we showbelow that they also denote only regular string relations.As we have said, we take it that each rule in a grammar will be annotated to showwhich strategy is to be used in applying it.
We also assume that rules are annotated toshow whether they are to be taken as obligatory or optional.
We have considered onlyobligatory rules up to now, but optional rules are also commonly used to account forcases of free variation.
The mathematical treatment of optional rules will turn out tobe a simpler case of what must be done for obligatory rules and, therefore, a naturalstep in the general development.As well as providing for various strategies for reapplying a single rule, we alsoconsider the possibility of what we call a batch rule.
This is a set of rules that the ap-plication strategies treat as one entity, the individual rules being otherwise unorderedrelative to one another.
This mode of rule application will turn out to be interestingeven if it is not an explicit part of any particular phonological formalism because, as weshall see, it constitutes an essential step in the interpretation of rules that use featuresto refer to underspecified segments.
A good example of this is the vowel-harmonyrule referred to earlier, namelyVi --~ Bi / BjC*In feature notation, this could be written+syllabic \] \[ +back-consonantal ~ \[ +back \ ] /  +syllabic-consonantal\[ +consonantal \]* __meaning that a segment that is specified as a vowel comes also to be specified as backwhen the most recent preceding vowel is back; all other features remain unchanged.The grammar will presumably contain another ule that will apply in circumstanceswhen this one does not, namelyVi --+ Fi / FjC*or+syllabic \] \[ -back-consonantal --+ \[ -back \ ] /  +syllabic-consonantal\[ +consonantal \]* _,349Computational Linguistics Volume 20, Number 3except, of course, that the context can be omitted from whichever of the two is placedsecond in an ordered list of rules.
But this is precisely the question: What is the properorder of this pair of rules?Consider an actual case, namely, vowel harmony in Turkish.
Let A represent anabstract vowel with e and a as its front and back realizations, and I another abstractvowel with i and dotless i as its front and back counterparts.
The first of these occurs,for example, in the abstract plural suffix lAr, and the second occurs in the possessivesuffix Im, meaning 'my.'
Both suffixes can be used together, and the harmony is illus-trated by the different realizations of the abstract vowels in the forms apartmanlArlmand adreslArlm.
These appear as apartmanlamm ' y apartments' and adreslerim 'myaddresses.'
Using only the simple non-feature notation we started out with, we candescribe this variation with the following four rules:A ~ e /eC*A -~ aI --* i /eC*I --+ 1The proper surface forms for these words are produced if these rules are ordered aswe have given them--inserting front vowels first--and if each of them is applied fromleft to right.
However, applying the rules in this way gives the wrong result when wecreate the dative possessive form of adres instead of the possessive plural.
The dativesuffix is spelled simply as the abstract vowel A, and the abstract adreslmA should berealized as adresime if harmony is respected.
But the rules as given will map adreslmAto adresima instead.
This is because the earlier ules apply to the final A at a time beforethe context required for that vowel has been established.
Reordering the rules to fixthis problem will cause the previous correct analyses to fail.
The proper results in allcases come only if we describe Turkish vowel harmony with rules that proceed left toright through the string as a group, applying at each position whichever one matclies.This is the mode of application for a set of rules collected together as a batch.The notion of a batch rule apparently has not arisen as a distinctive formal conceptin phonological theories.
The reason is doubtless that batch rules are unnecessarilyprolix and, in particular, they fail to capture generalizations that can almost alwaysbe made about the individual rules that make up a batch.
Phonologists prefer rulesthat are based on feature matrices.
These rules allow segments to be referred to byspecifying which members of a finite set of properties they do or do not have.
Afeature matrix can specify a segment completely, in which case it is equivalent to theunanalyzable segment names we have been using, or it can leave it underspecified.Feature matrices therefore constitute an abbreviatory convention with the advantagethat what is easy to abbreviate will be motivated to just the extent hat the featuresthemselves are motivated.
An underspecified segment corresponds to a set of fullyspecified segments, and a rule that contains underspecified segments corresponds toa set of rules that are to be applied in batch mode.Feature matrices based on a well-motivated set of features allow the phonologistto capture significant generalizations and thus effectively to reduce the componentsof our batch rules to a single rule in most cases.
A significant addition that has beenmade to the basic machinery of feature-based rules consists of variables written withlowercase Greek letters a, t ,  7, etc.
and ranging over the values + and - .
We canuse them, for example, to collapse our vowel-harmony rules into a single one asfollows:350Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systems+syllabic 1 \[ c~back-consonantal --+ \[ c~back \ ] /  +syllabic-consonantal\[ +consonantal \]* __Both occurrences of the variable ~ must be instantiated to the same value, either + or- ,  at each application of the rule.
What the rule now says is that a vowel takes itsbackness from the vowel in the preceding syllable; that is, the most recent precedingvowel that is separated from it by zero or more consonants.While the explicit use of variables is an important addition to the notation, itwas in fact foreshadowed by a property of the initial feature system, namely thatfeatures not explicitly mentioned in the center of a rule were assumed to be carriedover from the input to the output.
Without this convention, an explicit variable wouldhave been required for each of these.
Explicit feature variables do indeed increase theabbreviatory power of the notation, but, as we show below, they can be translatedsystematically into batch rules over unanalyzable segments.We pay special attention to batch rules, feature matrices, and feature variablesbecause they require some nonobvious extensions to the treatment we provide forordinary rules with unanalyzable symbols.
On the other hand, we have nothing tosay about the many other notational devices that phonologists have proposed forcollapsing rules.
These abbreviatory conventions are either already subsumed by thegeneral regular languages we allow as rule components or can be translated in obviousways to simply ordered rules or batch rules.5.
Rewriting Rules as Regular RelationsWe now come to the central problem of proving that an arbitrary rule in our formalismdenotes a regular string relation and is thus accepted by an equivalent finite-statetransducer.
A rule has the general form-~ ~/~ Pwhere G ~b, A, and p are arbitrary regular expressions.
The mode of application ofthe rule is governed by additional parametric specifications, including for examplewhether the rule applies from left to right or right to left, and whether it is obligatoryor optional.The replacement that such a rule performs is modeled by a relation Replace initiallydefined as follows:Replace = lid(G*) Opt(~ x ~b)\]*The final asterisk allows for repetitions of the basic ~ x ~b mapping, and Id(~*) allowsidentical corresponding substrings to come between successive applications of therule.
The ~ x ~b replacement is optional to allow for the possibilities that the rule itselfmay be optional or that there may be no eligible instances of ~ in the input string.Replace is the set of pairs of strings that are identical except for possible replacementsof substrings belonging to ~ by substrings belonging to ~b.
This set clearly containsall the pairs that satisfy the rule, though perhaps other pairs as well.
The problemnow is to impose restrictions on this mapping so that it occurs in the proper contextsand in accordance with the parameters specified for the rule.
We do this in a series ofapproximations.351Computational Linguistics Volume 20, Number 35.1 Context RequirementsAs a first step, we might be tempted simply to add the context restrictions as necessaryconditions of the ~b x ~p replacement:Replace = lid(P,*) Opt(Id( A ) ~ x ~ Id(p) )\]*This relation includes trings where the q~ x ~p replacement occurs only when imme-diately preceded and followed by identical substrings satisfying A and p, respectively.But this formulation does not allow for the fact, noted above, that the context stringsof one application may overlap either the contexts or the center strings of another.For example, consider the following optional rule, which allows an abstract B to berewritten as b intervocalically:B - - *b /V  VWith the definition of Replace just given, the string pair on the left below would beaccepted but the pair on the right would not:V B V B V V B V B VV b V B V V b V b VBut the second pair also represents a valid application of the rule, one in which thecenter vowel is serving as the right context of one application and the left context ofthe other.The problem is that a given string symbol can simultaneously serve several differ-ent roles in the application of a rule, and all possible interactions must be accountedfor.
As a next approximation, we avoid this confusion by carefully distinguishing andkeeping track of these various roles.
We first consider how to apply a rule to stringsthat have been preprocessed sothat every instance of the left context A is followed bythe auxiliary symbol < and every instance of the right context p is preceded by thesymbol >, where < and > are not in P~.
This means that the replacement operator canbe defined solely in terms of these distinct context-marking brackets, without regardto what A and p actually specify and what they might have in common with eachother or with q~ and ~b.
In essence, we assume that the replacement relation for theabove rule applies to the upper strings shown below, and that all three string pairsare acceptable because ach of the corresponding B-b pairs is bracketed by < and >.>V<B>V<B>V<>V<b>V<b>V<>V<B>V<B>V<>V<b>V<B>V<>V<B>V<B>V<>V<B>V<b>V<To take a somewhat more realistic example, when the rule at the beginning of thepaperN --* m / _ _  \[+labial\]is applied to the string iNprobable, the preprocessed input string would contain thesequence<i<N< >p<r <o< >b<a < >b<l<e<The left context of the rule is empty, so there is a left-context marker < after everycharacter f om the original string.
Every labial is an instance of the right context, andaccordingly there is a > immediately preceding p's and b's.
The rule properly applies torewrite the N because it is bracketed by < and >.
On the other hand, the > is missing352Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsFigure 9The Replace transducer.~x~mand the rule does not apply to the N in the preprocessed version of iNtractable, namely<i<N<t<r<a<c<t<a< >b<l<e<The definition of the Replace operator must be modified in two ways in order to operateon such preprocessed strings.
First it must allow the ~ x ~ mapping only between theappropriate context markers.
Second, some occurrences of the left and right contextstrings do not result in rule applications, either because the rule is optional or becausethe other conditions of the rule are not satisfied.
Thus, the relation must disregard themarkers corresponding to those occurrences inside the identity substrings betweenrule applications.
Relations with this behavior can be obtained through the use ofthe ignoring operator defined in Section 3, which is notated by subscripting.
Let m(for marker) be {<, >}, the set of both markers.
Then our next approximation to thereplacement relation is defined as follows:Replace = \[Id(Gm ) Opt(Id(<) ~m x ~m Id(>))\]*This allows arbitrary strings of matching symbols drawn from ~, U { <, > } between ruleapplications and requires <:< and >:> to key off a ~-~ replacement.
The subscriptm's also indicate that < and > can be ignored in the middle of the replacement, sincethe appearance of left- or right-context s rings is irrelevant in the middle of a givenrule application.
Figure 9 shows the general form of the state-transition diagram fora transducer that accepts a replacement relation.
As before, the start-state is labeled 0and only transitions are shown from which the final-state is reachable.We must now define relations that guarantee that context-markers do in fact ap-pear on the strings that Replace applies to, and only when sanctioned by instances of Aand p. We do this in two stages.
First, we use simple relations to construct a Prologueoperator that freely introduces the context markers in m:Prologue = Intro(m )An output string of Prologue is just like the corresponding input except hat bracketsappear in arbitrary positions.
The relation Prologue -1 removes all brackets that appearon its input.Second, we define more complex identity relations that pair a string with itselfif and only if those markers appear in the appropriate contexts.
The P-iff-S operatoris the key component of these context-identifying predicates.
The condition we mustimpose for the left context is that the left-context bracket < appears if and only if it isimmediately preceded by an instance of A.
This basic requirement is satisfied by stringsin the regular language P-iff-S(G*A, <G*).
The situation is slightly more complicated,however, because of two special circumstances.An instance of A may have prefixes that are also A instances.
If A is the expressionab*, then a<b< is an acceptable marking but ab< and a<b are not because the two353Computational Linguistics Volume 20, Number 3)~-instances are not both followed by <.
The brackets that necessarily follow suchprefixes must not prevent he longer instances from also being identified and marked,and right-context brackets also must not interfere with left-context identification.
Theignore operators in the expression P-iff-S (~*<,~<, ~*< )> allow for these possibilities.This disregards slightly too many brackets, however: since an instance of &< followedby an < is also an instance of ~<, it must be followed by another bracket, and soon.
The only (finite) strings that belong to this language are those that contain noinstances of A at all!
To correctly identify and mark left-contexts, the bracket followinga &< instance must not be ignored.
Thus, the requisite set of strings is the regularlanguage Leftcontext(&, <, >), where the Leflcontext operator is defined as follows:Leflcontext( &, l, r) = P-iff-S(C?
At - ~?
l, lYe, T) rWe parameterize this operator for the left-context pattern and the actual brackets othat it can be used in other definitions below.The other complication arises in rules intended to insert or delete material in thestring, so that either ~ or ~b includes the empty string e. Consider the left-to-right rulea--*e / bIterated applications of this rule can delete an arbitrary sequence of a's, convertingstrings of the form baaaa.., a into simply b.
The single b at the beginning serves asleft-context for applications of the rule to each of the subsequent a's.
This presents aproblem for the constructions we have developed so far: The Replace relation requiresa distinct < marker for each application of the rule.
The < that sanctions the deletionof the leftmost a in the string is therefore not available to delete the next one.
How-ever, the Leflcontext operator as defined disallows two left-context brackets in a row.Our solution is to insert an explicit character 0 to represent the deleted material.
IfLeflcontext ignores this character in &, 0 will always be followed by another left bracketand thus another ule application is possible.The auxiliary symbol 0 is not in ~.
or in the set of context brackets.
It will substitutefor the empty strings that might appear in the center of rules (in ~ or ~b), but it is agenuine symbol in an expanded alphabet which, unlike the normal e, actually appearsas a distinct element in character strings.
The Prologue relation is extended to freelyintroduce 0 as well as the brackets in m:Prologue = Intro(m U {0})We then construct alternative versions of q~ and ~b in which this special symbol replacesthe true empty strings.
We define~0 ~ q~ i fe?~= I.
\ [~-e \ ]U0  otherwisewhich contains exactly the same strings as ~ except that the singleton string 0 isincluded instead of the empty string that otherwise might be in the language.
~b ?
isdefined similarly, and then the replacement operator is expressed in terms of thesenew regular languages:Replace = \[Id(C m o) Opt(Id( <) ~o x~bO Id(>))\]*Now we can complete our definition of the left-context identifier:Leftcontext( &,l, r) = P-iff-S(C~o .kl o - ~?o l, 1 ~,~o)r354Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systems0r ~, >Figure 10Left-context identifiers.As desired, the regular language denoted by this operator includes strings if andonly if every substring belonging to & (ignoring 1, r, and 0) is immediately followedby a bracket 1.
This effect is illustrated by the state-transition diagrams in Figure 10.The machine on the left is a minimal-state acceptor for the empty-context languageLeflcontext(c, <, >).
It accepts trings that have at least one <, and every 0 or ~ symbolmust be followed by a <.
The >-labeled transitions represent the fact that > is beingignored.
The machine on the right accepts the language Leflcontext(a, <, >); it requires< to appear after every a or after any 0 that follows an a.
This particular machine isnondeterministic so that its organization is easier to understand.An operator for identifying and marking right-context s rings can be defined sym-metrically:aightcontext(p~l~r) = P-iff-S(~rO r, Pro ~rO -- r ~rO)lThus Rightcontext(p~ <~ >) includes strings if and only if every substring belonging top (with appropriate ignoring) is immediately preceded by a right-context bracket >.Alternatively, taking advantage of the fact that the reversal of a regular language isalso a regular language, we can define Rightcontext in terms of Leftcontext:Rightcontext(p, I, r) = Rev( Leftcontext( Rev(p), r~ l))These context identifiers denote appropriate string-sets even for rules with unspecifiedcontexts, if the vacuous contexts are interpreted as if the empty string had been spec-ified.
The empty string indicates that adjacent symbols have no influence on the ruleapplication.
If an omitted & is interpreted as c, for example, every Leficontext stringwill have one and only one left-context bracket at its beginning, its end, and betweenany two G symbols, thus permitting a rule application at every position.5.2 Directional and Simultaneous ApplicationWe now have components for freely introducing and removing context brackets, forrejecting strings with mislocated brackets, and for representing the rewrite action ofa rule between appropriate context markers.
The regular relation that models theoptional application of a rule is formed by composition of these pieces.
The order ofcomposition depends on whether the rule is specified as applying iteratively from leftto right or from right to left.As noted in Section 4, the difference is that for left-to-right rules, the left-contextexpression &can match against he output of a previous (that is, leftward) applicationof the same rule, but the right-context expression p must match against the as yetunchanged input string.
These observations are directly modeled by the order in whichthe various rule components are combined.
For a left-to-right rule, the right contextis checked on the input (4) side of the replacement, while the left context is checkedon the output (~;) side.
The regular relation and corresponding transducer for a left-355Computational Linguistics Volume 20, Number 3to-right optional rule is therefore defined by the following sequence of compositions:Prologue oId(Rightcontext(p, < >)) oReplace oId(Leflcontext(A, <, >)) oPrologue -1Both left- and right-context brackets are freely introduced on input strings, strings inwhich the right-context bracket is mislocated are rejected, and the replacement takesplace only between the now-constrained right-context brackets and the still free left-context markers.
This imposes the restriction on left-context markers that they at leastappear before replacements, although they may or may not freely appear elsewhere.The left-context checker ensures that left-context markers do in fact appear only in theproper locations on the output.
Finally, all brackets are eliminated, yielding strings inthe output language.The context-checking situation is exactly reversed for right-to-left rules: the left-context matches against he unchanged input string while the right-context matchesagainst he output.
Right-to-left optional application can therefore be modeled simplyby interchanging the context-checking relations in the cascade above, to yieldPrologue oId(Leftcontext(A, <, >)) oReplace oId(Rightcontext(p, < >)) oPrologue -1The transducer corresponding tothis regular elation, somewhat paradoxically, modelsa right-to-left rule application while moving from left to right across its tapes.Simultaneous optional rule application, in which the sites of all potential stringmodifications are located before any rewriting takes place, is modeled by a cascadethat identifies both left and right contexts on the input side of the replacement:Prologue oId(Leftcontext(A, <, >) A Rightcontext(p, <, >)) oReplace oPrologue -15.3 Obligatory ApplicationThese compositions model the optional application of a rule.
Although all potentialapplication sites are located and marked by the context checkers, these compositionsdo not force a q~-~ replacement to take place for every instance of ~ appearing inthe proper contexts.
To model obligatory rules, we require an additional constraintthat rejects string pairs containing sites where the conditions of application are metbut the replacement is not carried out.
That is, we must restrict he relation so that,disregarding for the moment he effect of overlapping applications, every substring ofthe form A~p in the first element of a pair corresponds to a A~pp in the second elementof that pair.
We can refine this restriction by framing it in terms of our context-markingbrackets: the Replace relation must not contain a pair with the substring <~> in oneelement corresponding to something distinct from <~b> in the other.We might try to formulate this requirement by taking the complement of a relationthat includes the undesired correspondences, a  suggested by the expressionXd( ;n 0) Ia(<) Id(>) Id(r 4 0)356Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsThis expression might be taken as the starting point for various augmentations thatwould correctly account for overlapping applications.
However, pursuing this line ofattack will not permit us to establish the fact that obligatory rules also define regularmappings.
First, it involves the complement of a regular relation, and we observedabove that the complement of a regular relation (as opposed to the complement of aregular language) is not necessarily regular.
Second, even if the resulting relation itselfturned out to be regular, the obvious way of entering it into our rule composition isto intersect it with the replacement relation, and we also know that intersection ofrelations leads to possibly nonregular results.Proving that obligatory rules do indeed define regular mappings requires an evenmore careful analysis of the roles that context-brackets can play on the various interme-diate strings involved in the rule composition.
A given left-context bracket can servein the Replace relation in one of three ways.
First, it can be the start of a rule application,provided it appears in front of an appropriate configuration of G ~, and right-contextbrackets.
Second, it can be ignored during the identity portions of the strings, theregions between the changes sanctioned by the replacement relation.
Third, it canbe ignored because it comes in the middle or center of another ule application thatstarted to the left of the bracket in question and extends further to the right.
Supposewe encode these three different roles in three distinct left-bracket symbols <, <, anda i< and also provide for a similar set of distinct right-context brackets >, >, and >.c a i cWherever a rule is properly applied, the input side of the replacement relation willcontain a substring of the formc cThe crucial difference in the case where an obligatory left-to-right rule incorrectlyfails to apply is that the left-context preceding the ~0 is marked with < instead ofi<, since it is part of an identity sequence.
This situation is undesirable no matterawhat types of brackets are ignored in the ~0 pattern or mark the right-context of thispotential application.
Whether those brackets are in the center or at the boundary ofreplacements hat are carried out further to the right of the offending situation, theleftward application marked by the < should have taken precedence.iThe symbols < and > were previously used as auxiliary characters appearing inintermediate strings.
With a slight abuse of notation, we now let them act as coversymbols standing for the sets of left and right brackets {<~ a<~ c <} and {>, a>~ c>} re-spectively, and we let m be the combined set < u >.
A substring on the input sideof the replacement is then a missed left-to-right application if it matches the simplepattern coo>.
Thus, we can force obligatory application of a left-to-right rule by re-quiring that the strings on the input side of its replacement contain no such substrings,or, to put it in formal terms, that the input strings belong to the regular languageObligatory( O, < >), where Obligatory is defined by the following operator:1Obligatory(G l~ r) = Y'm 0 1 ~0 r Gm 0By symmetry, a missed application of a right-to-left rule matches the pattern <~o>.,and Obligatory(~ <~ >) is the appropriate input filter to disallow all such substrings.1Note that the obligatory operator involves only regular languages and not relationsso that the result is still regular despite the complementation peration.We must now arrange for the different ypes of brackets to appear on the input toReplace only in the appropriate circumstances.
As before, the context identifiers must357Computational Linguistics Volume 20, Number 3ensure that none of the brackets can appear unless preceded (or followed) by the ap-propriate context, and that every occurrence of a context is marked by a bracket freelychosen from the appropriate set of three.
The Leflcontext and Rightcontext operatorsgiven above will have exactly this effect when they are applied with the new mean-ings given to <, >, and m. The Replace operator must again be modified, however,because it alone distinguishes the different roles of the context brackets.
The followingfinal definition chooses the correct brackets for all parameters of rule application:= 4<>?
?<> Replace \[Id(E~> 0) Opt(Id(<) o oi i  cc  ccThe behavior of obligatory rules is modeled by inserting the appropriate filter in thesequence of compositions.
Left-to-right obligatory rules are modeled by the cascadePrologue oId(Obligatory(~, <., >)) olId(Rightcontext(p, <, >)) oReplace oId(Leftcontext(A, <, >)) oPrologue - 1and right-to-left obligatory rules are modeled by:Prologue oId(Obligatory(G <, >.))
o1Id(Leftcontext(A, <, >)) oReplace oId(Rightcontext(p, <, >)) oPrologue -1We remark that even obligatory rules do not necessarily provide a singleton outputstring.
If the language ~b contains more than one string, then outputs will be producedfor each of these at each application site.
Moreover, if ~ contains strings that aresuffixes or prefixes (depending on the direction of application) of other strings in 0,then alternatives will be produced for each length of match.
A particular formalismmay specify how such ambiguities are to be resolved, and these stipulations would bemodeled by additional restrictions in our formulation.
For example, the requirementthat only shortest ~ matches are rewritten could be imposed by ignoring only one of< or > in the mapping part of Replace, depending on the direction of application.c Tl~ere are different formulations for the obligatory application of simultaneousrules, also depending on how competition between overlapping application sites is tobe resolved.
Intersecting the two obligatory filters, as in the following cascade, modelsthe case where the longest substring matching ~ is preferred over shorter overlappingmatches:Prologue oId(Obligatory(G <, >) N Obligatory(c~, <, > ) ) ol 1Id(Rightcontext(p, <, >) n Leflcontext(A, <, >)) oReplace oPrologue -1The operators can be redefined and combined in different ways to model other regimesfor overlap resolution.358Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systems5.4 Boundary ContextsA rule contains the special boundary marker # when the rewriting it describes isconditioned by the beginning or end of the string.
The boundary marker only makessense when it appears in the context parts of the rule; specifically, when it occursat the left end of a left-context string or the right end of a right-context s ring.
Nospecial treatment for the boundary marker would be required if # appeared as thefirst and last character of every input and output string and nowhere else.
If thiswere the case, the compositional cascades above would model exactly the intendedinterpretation wherein the application of the rule is edge-sensitive.
Ordinary input andoutput strings do not have this characteristic, but a simple modification of the Prologuerelation can simulate this situation.
We defined Prologue above as Intro(m U {0}).
Wenow augment that definition:Prologue = Intro(m U {0}) o \[?
:# Id(G m o # ~'m o) c:#\]We have composed an additional relation that introduces the boundary marker at thebeginning and end of the already freely bracketed string, and also rejects trings con-taining the boundary marker somewhere in the middle.
The net effect is that stringsin the cascade below the Prologue are boundary-marked; bracketed images of the orig-inal input strings and the context identifiers can thus properly detect he edges ofthose strings.
The inverse Prologue at the bottom of the cascade removes the boundarymarker along with the other auxiliary symbols.5.5 Batch RulesIt remains to model the application of a set of rules collected together in a singlebatch.
Recall that for each position in the input string each rule in a batch set isconsidered for application independently.
As we have seen several times before, thereis a straightforward approach that approximates this behavior.
Let {R1,..., Rn} be theset of regular elations for rules that are to be applied as a batch and construct therelation \[UkRk\]*.
Because of closure under union, this relation is regular and includesall pairs of strings that are identical except for substrings that differ according tothe rewriting specified by at least one of the rules.
But also as we have seen severaltimes before, this relation does not completely simulate the batch application of therules.
In particular, it does not allow for overlap between the material that satisfiesthe application requirements of one rule in the set with the elements that sanctiona previous application of another ule.
As usual, we account for this new array ofoverlapping dependencies by introducing a larger set of special marking symbols andcarefully managing their occurrences and interactions.A batch rule is a set of subrules {01 --+ ~1/A1 pl,..., on ~ ~;n / /~n ion}together with a specification of the standard parameters of application (left-to-right,obligatory, etc.).
We use superscripts to distinguish the components of the differentsubrules to avoid (as much as possible) confusion with our other notational conven-tions.
A crucial part of our treatment ofan ordinary rule is to introduce special bracketsymbols to mark the appearance of its left and right contexts o that its replacementsare carried out only in the proper (possibly overlapping) environments.
We do thesame thing for each of the subrules of a batch, but we use a different set of brack-ets for each of them.
These brackets permit us to code in a single string the contextoccurrences for all the different subrules with each subrule's contexts distinctivelymarked.<k <k <k~ of left-context brackets for the k th subrule O k --* Let (k be the set ( i  'a ' c j~k//~k tO k of the batch, let >k be the corresponding set of right-context brackets,359Computational Linguistics Volume 20, Number 3and let m k be the set <k U >k.
We also redefine the generic cover symbols <, >, and mto stand for the respective collections of all brackets: K = Uk K k, > = LJk > k, m = K LJ >.Note that with this redefinition of m, the Prologue relation as defined above will nowfreely introduce all the brackets for all of the subrules.
It will also be helpful to notatethe set of brackets not containing those for the k th subrule: m -k = m - m k.Now consider the regular language Leftcontext(A k, <k, >k)m_k" This contains tringsin which all instances of the k th subrule's left-context expression are followed by oneof the k th left-context brackets, and those brackets appear only after instances of Ak.The k th right-context brackets are freely distributed, as are all brackets for all theother subrules.
Occurrences of all other left-context brackets are restricted in similarlydefined regular languages.
Putting all these bracket-restrictions together, the languageNLeftcontext( Ak, <k, >k)m_kkhas each subrule's left-context duly marked by one of that subrule's left-context brack-ets.
This leaves all right-context brackets unconstrained; they are restricted to theirproper positions by the corresponding right-context languageNRightcontext(pk, <k, > k)m_kkThese intersection languages, which are both regular, will take the place of the simplecontext identifiers when we form the composition cascades to model batch-rule appli-cation.
These generalized context identifiers are also appropriate for ordinary rules ifwe regard each of them as a batch containing only one subrule.A replacement operator for batch rules must also be constructed.
This must mapbetween input and output strings with context-brackets properly located, ensuringthat any of the subrule rewrites are possible at each properly marked position butthat the rewrite of the k th subrule occurs only between <k and >k.
The complete seta aof possible rewrites is encoded in the relation\[id(a<k ) ok xW > Id( k)\]c c ?Cwhere the generic symbol <c now stands for {<1 ... c<k}, the set of all left-center brack-ets, and the generic > is assigned a corresponding meaning.
We incorporate this rela-Ction as the rewrite part of a new definition of the Replace operator, with the generic <iand > now representing the sets of all left and right identity brackets:iReplace= \[Id(E~>0) Opt(Uk \[Id(<k ) ~Ok X @Okc ~ Id(>k)\])\]*This relation allows for any of the appropriate replacements separated by identity sub-strings.
It is regular because of the union-closure property; this would not be the case,of course, if intersection or complementation had been required for its construction.A model of the left-to-right application optional application of a batch rule isobtained by substituting the new, more complex definitions in the composition cascadefor ordinary rules with these application parameters:Prologue ok k Id(nkRightcontext(p , < , >k)m_ Q oReplace oid ( nk Leftcontext ( A k ' <k, > k )m_k ) 0Prologue -1360Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsOptional right-to-left and simultaneous batch rules are modeled by similar substitu-tions in the corresponding ordinary-rule cascades.
Obligatory applications are handledby combining instances of the Obligatory operator constructed independently for eachsubrule.
Obligatory(~ k, (k  >k) excludes all strings in which the k th subrule failed toiapply, moving from left to right, when its conditions of application were satisfied.The intersection of the obligatory filters for all subrules in the batch ensures that atleast one subrule is applied at each position where application is allowed?
Thus thebehavior of a left-to-right obligatory batch rule is represented by the compositionPrologue oid(NkObligatory(~bk ' <ki >k)) oid(nkRightcontext(pk ' <k >k)m_k ) 0Replace oid(nkLeflcontext(,~k ' <k >k)m_k ) 0Prologue -1Again, similar substitutions in the cascades for ordinary obligatory rules will modelthe behavior of right-to-left and simultaneous application?5.6 Feature Matrices and Finite Feature VariablesUsing only operations that preserve the regularity of string sets and relations, we havemodeled the properties of rewriting rules whose components are regular languagesover an alphabet of unanalyzable symbols.
We have thus established that every suchrule denotes a regular elation.
We now extend our analysis to rules involving regularexpressions with feature matrices and finite feature variables, as in the Turkish vowelharmony rule discussed in Section 4:+syllabic \] I c~back-consonantal ---, \[ c~back \ ] /  +syllabic-consonantal\[ +consonantal\]* __We first translate this compact feature notation, well suited for expressing linguisticgeneralizations, into an equivalent but verbose notation that is mathematically moretractable.
The first step is to represent explicitly the convention that features not men-tioned in the input or output matrices are left unchanged in the segment that therule applies to.
We expand the input and output matrices with as many variables andfeatures as necessary so that the value of every output feature is completely specifiedin the rule.
The center-expanded version of this example is+syllabic-consonantalflbackfllround&highflnfn+syllabic-consonantalc~back--* fllround&highflnfn\ [aback  \]/ +syllabic \[ +consonantal \]* __-consonantalThe input and output feature matrices are now fully specified, and in the contexts thevalue of any unmentioned feature can be freely chosen.A feature matrix in a regular expression is quite simple to interpret when it doesnot contain any feature variables.
Such a matrix merely abbreviates the union of all361Computational Linguistics Volume 20, Number 3segment symbols that share the specified features, and the matrix can be replaced bythat set of unanalyzable symbols without changing the meaning of the rule.
Thus,the matrix \[+consonantal\] canbe translated to the regular language {p, t, k, b, d.. .
}and treated with standard techniques.
Of course, if the features are incompatible, thefeature matrix will be replaced by the empty set of segments.A simple translation is also available for feature variables all of whose occurrencesare located in just one part of the rule, as in the following fictitious left context:\[ ~high \ ] \ [  +consonantal \ ]*\[  -around \]If ~ takes on the value +, then the first matrix is instantiated to \[+high\] and denotesthe set of unanalyzable symbols, say {e, i .
.
.
.
}, that satisfy that description.
Thelast matrix reduces to \[-round\] and denotes another set of unanalyzable symbols(e.g.
{a, e, i .
.
.
.
}).
The whole expression is then equivalent to{e, i , .
.
.}
{p , t ,k ,b ,d .
.
.
}*{a ,e , i , .
.
.
}On the other hand, if ~ takes on the value - ,  then the first matrix is instantiated to\[-high\] and denotes a different set of symbols, say {a, o... }, and the last one reducesto \[+ round\].
The whole expression on this instantiation of ~ is equivalent to{a ,o  .
.
.
.  }
{p , t ,k ,b ,d .
.
.
}*{o ,u , .
.
.
}On the conventional interpretation, the original expression matches trings that belongto either of these instantiated regular languages.
In effect, the variable is used to encodea correlation between choices from different sets of unanalyzable symbols.We can formalize this interpretation i the following way.
Suppose 0 is a regularexpression over feature matrices containing a single variable ~ for a feature whosevalues are drawn from a finite set V, commonly the set {+~-}.
Let 0\[o~ -~ v\] be theresult of substituting v E V for ~ wherever it occurs in 0, and then replacing eachvariable-free feature matrix in that result by the set of unanalyzable symbols thatsatisfy its feature description.
Then the interpretation of ~ is given by the formulavEVThis translation produces a regular expression that properly models the choice-correla-tion defined by ~ in the original expression.
Rule expressions containing several locallyoccurring variables can be handled by an obvious generalization of this substitutionscheme.
If Oz I .
.
.
O~ n are the local variables in 0 whose values come from the finite setsV1... Vn, the set of n-tuplesI = {<OZ 1 ---> V l~.
.
.
~Oz n --+ Vn> Iv1 E Wl.. .Vn E Vn}represents the collection of all possible value instantiations of those variables.
If we letO\[i\] be the result of carrying out the substitutions indicated for all variables by some iin/, the interpretation of the entire expression is given by the formulauO\[i\]iElWhen all local variables are translated, the resulting expression may still contain fea-ture matrices with nonlocal variables, those that also occur in other parts of the rule.362Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsIndeed, the input and output expressions will almost always have variables in com-mon, because of the feature variables introduced in the initial center-expansion step.Variables that appear in more than one rule part clearly cannot be eliminated fromeach part independently, because the correlation between feature instantiations wouldbe lost.
A feature-matrix rule is to be interpreted as scanning in the appropriate di-rection along the input string until a configuration of symbols is encountered thatsatisfies the application conditions of the rule instantiated to one selection of valuesfor all of its variables.
The segments matching the input are then replaced by the out-put segments determined by that same selection, and scanning resumes until anotherconfiguration is located that matches under possibly a different selection of variablesvalues.
This behavior is modeled as the batch-mode application of a set of rules eachof which corresponds to one variable instantiation of the original rule.Consider a center-expanded rule of the general form ~ --* ~b/~ __  p, and let I bethe set of possible value instantiations for the feature-variables it contains.
Then thecollection of instantiated rules is simply(q~\[i\] ~ ~b\[i\]/),\[i\] p\[i\] \] i c I}The components of the rules in this set are regular languages over unanalyzable seg-ment symbols, all feature matrices and variables having been resolved.
Since eachinstantiated rule is formed by applying the same substitution to each of the origi-nal rule components, the cross-component correlation of symbol choices is properlyrepresented.
The behavior of the original rule is thus modeled by the relation thatcorresponds to the batch application of rules in this set, and we have already shownthat such a relation is regular.5.7 SummaryThis completes our examination of individual context-sensitive r writing rules.
Wehave modeled the input-output behavior of these rules according to a variety of dif-ferent application parameters.
We have expressed the conditions and actions pecifiedby a rule in terms of carefully constructed formal languages and string relations.
Ourconstructions make judicious use of distinguished auxiliary symbols so that crucialinformational dependencies can be string-encoded in unambiguous ways.
We havealso shown how these languages and relations can be combined by set-theoretic oper-ations to produce a single string relation that simulates the rule's overall effect.
Sinceour constructions and operations are all regularity-preserving, we have established thefollowing theorem:TheoremFor all the application parameters we have considered, every rewriting rule whosecomponents describe regular languages denotes a regular string relation.This theorem has an immediate corollary:CorollaryThe input-output string pairs of every such rewriting rule are accepted by some finite-state transducer.This theoretical result has important practical consequences.
The mathematical nalysisthat establishes the theorem and its corollary is constructive in nature.
Not only dowe know that an appropriate relation and its corresponding transducer exist, we also363Computational Linguistics Volume 20, Number 3know all the operations to perform to construct such a transducer f om a particularrule.
Thus, given a careful implementation f the calculus of regular languages andregular elations, our analysis provides a general method for compiling complicatedrule conditions and actions into very simple computational devices.6.
Grammars of Rewriting RulesThe individual rules of a grammar are meant o capture independent phonologicalgeneralizations.
The grammar formalism also specifies how the effects of the differentrules are to be combined together to account for any interactions between the gen-eralizations.
The simplest method of combination for rewriting rule grammars i forthe rules to be arranged in an ordered sequence with the interpretation that the firstrule applies to the input lexical string, the second rule applies to the output of thefirst rule, and so on.
As we observed earlier, the typical practice is to place specializedrules with more elaborate context requirements earlier in the sequence so that theywill override more general rules appearing later.The combined effect of having one rule operate on the output of another can bemodeled by composing the string relations corresponding to each rule.
If the stringrelations for two rules are regular, we know that their composition is also regular.The following result is then established by induction on the number of rules in thegrammar:TheoremIf G = (R1,..., Rn) is a grammar defined as a finite ordered sequence of rewriting ruleseach of which denotes a regular elation, then the set of input-output s ring-pairs forthe grammar as a whole is the regular elation given by R1 o. .
.
o Rn.This theorem also has an immediate corollary:CorollaryThe input-output string pairs of every such rewriting grammar are accepted by asingle finite-state transducer.Again, given an implementation f the regular calculus, a grammar transducer can beconstructed algorithmically from its rules.We can also show that certain more complex methods of combination also denoteregular elations.
Suppose a grammar is specified as a finite sequence of rules but witha further specification that rules in some subsequences are to be treated as a blockof mutually exclusive alternatives.
That is, only one rule in each such subsequencecan be applied in any derivation, but the choice of which one varies freely betweenderivations.
The alternative choices among the rules in a block can be modeled as theunion of the regular elations they denote individually, and regular elations are closedunder this operation.
Thus this kind of grammar also reduces to a finite compositionof regular elations.In a more intricate arrangement, the grammar might specify a block of alterna-tives made up of rules that are not adjacent in the ordering sequence.
For example,suppose the grammar consists of the sequence (R1,R2,R3,R4,R5), where R2 and R4constitute a block of exclusive alternatives.
This cannot be handled by simple union ofthe block rules, because that would not incorporate the effect of the intervening ruleR3.
However, this grammar can be interpreted as abbreviating a choice between two364Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsdifferent sequences, (R1, R2, R3, Rs) and (R1, R3, R4, Rs), and thus denotes the regularrelationa I o \[(a 2 oa3)  U (a 3 oR4) \] oR 5The union and composition operators can be interleaved in different ways to showthat a wide variety of rule combination regimes are encompassed by the regular rela-tions.
There may be grammars pecifying even more complex rule interactions, and,depending on the formal details, it may be possible to establish their regularity byother techniques; for example, by carefully managing a set of distinguished auxiliarysymbols that code inter-rule constraints.We know, of course, that certain methods for combining regular ules give rise tononregular mappings.
This is true, for example, of unrestricted cyclic application ofthe rules in a finite ordered sequence.
According to a cyclic grammar specification,a given input string is mapped through all the rules in the sequence to produce anoutput string, and that output string then becomes a new input for a reapplicationof all the rules, and the process can be repeated without bound.
We can demonstratethat such a grammar is nonregular by considering again the simple optional rule~- - *ab /abWe showed before that this rule does not denote a regular relation if it is allowedto rewrite material that was introduced on a previous application.
Under those cir-cumstances it would map the regular language {ab} into the context-free language{ anbn I 1 _< n}.
But we would get exactly the same result from an unrestricted cyclicgrammar whose ordered sequence consists only of this single rule.
In effect, cyclicreapplication of the rule also permits it to operate arbitrarily, often on its own output.In the worst case, in fact, we know that the computations of an arbitrary Turing ma-chine can be simulated by a rewriting grammar with unrestricted rule reapplication.These results seem to create a dilemma for our regularity analysis.
Many phono-logical formalisms based on ordered sets of rewriting rules provide for cyclic ruleapplications.
The underlying notion is that words have a bracketed structure re-flecting their morphological composition.
For example, unenforceable has the structure\[un\[\[en\[force\]\]able\]\].
Th  idea of the cycle is that the ordered sequence of rules is ap-plied to the innermost bracketed portion of a word first.
Then the innermost set ofbrackets is removed and the procedure is repeated.
The cycle continues in this wayuntil no brackets remain.The cycle has been a major source of controversy ever since it was first proposed byChomsky and Halle (1968), and many of the phenomena that motivated it can also begiven noncyclic descriptions.
Even for cases where a nonrecursive, iterative accounthas not yet emerged, there may be restrictions on the mode of reapplication thatlimit the formal power of the grammar without reducing its empirical or explanatorycoverage.
For example, the bracket erasure convention means that new string materialbecomes accessible to the rules on each cycle.
If, either implicitly or explicitly, thereis also a finite bound on the amount of old material to which rules in the new cyclecan be sensitive, it may be possible to transform the recursive specification to anequivalent i erative one.
This is analogous to the contrast between center-embeddingcontext-free grammars and grammars with only right- or left-linear ules; the latter areknown to generate only regular languages.
Unfortunately, phonological theories areusually not presented in enough formal detail for us to carry out such a mathematicalanalysis.
The regularity of cyclic phonological formalisms will have to be examinedon a case-by-case basis, taking their more precise specifications into account.365Computational Linguistics Volume 20, Number 3We have shown that every noncyclical rewriting grammar does denote a regularrelation.
We now consider the opposite question: Is every regular elation denoted bysome noncyclic rewriting rammar?
We can answer this question in the affirmative:TheoremEvery regular elation is the set of input/output s rings of some noncyclic rewritinggrammar with boundary-context rules.ProofLet R be an arbitrary regular elation and let T = (G, Q, q0, F, 6) be a finite-state trans-ducer that accepts it.
Without loss of generality we assume that G and Q are disjoint.We construct a rewriting rammar that simulates the operation of T, deriving a stringy from a string x if and only if the pair Ix, Y/is accepted by T. There will be four rulesin the grammar that together implement the provisions that T starts in state q0, makestransitions from state to state only as allowed by 6, and accepts a string only if thestate it reaches at the end of the string is in F. Let ~, U Q u {#,$} be the alphabet ofthe grammar, where # is a boundary symbol not in either G or Q and $ is anotherdistinct symbol that will be used in representing the finality of a state.
Our rules willintroduce states into the string between ordinary tape symbols and remove them tosimulate the state-to-state advance of the transducer.
The first rule in the grammarsequence is the simple start rule:--* qo/# - -  (obligatory, left-to-right)The effect of this rule is to introduce the start-state as a symbol only at the beginningof the input string, as specified in the rule by the boundary symbol #.
The string abc isthus rewritten by this rule to qoabc.
The following sets of rules are defined to representthe state-to-state transitions and the final states of the transducer:Transitions = {u ~ vqj/qi  _ _  I qi~qj E Q;u~v E G*; and qj E 6(qi~u,v)}Final = {~ --* $/qi # I qi C F}The second rule of the grammar is an obligatory, left-to-right batch rule consistingof all the rules in Transitions U Final.
If the transition function carries the transducerfrom qi to qj over the pair /u, v/, there will be a rule in Transitions that applies to thestring ... q iu .
.
,  at the position just after the substring beginning with qi and produces?
.. q ivq j .
.
,  as its output.
Because 6is a total function on Q x G* x G~, some subrule willapply at every string position in the left-to-right batch scan.
The state-context for theleft-most application of this rule is the start-state q0, and subrules corresponding tostart-state ransitions are selected.
This introduces a state-symbol that makes availableat the next position only subrules corresponding to transitions at one of the start-state'ssuccessors.
The batch rule eventually writes a state at the very end of the string.
If thatstate is in F, the corresponding Final subrule will apply to insert $ at the end of thestring.
If the last state is not in F, $ will not be inserted and the state will remain as thelast symbol in the string.
Thus, after the batch rule has completed its application, aninput string x will have been translated to an output string consisting of intermixedsymbols from Q and ~.
We can prove by a simple induction that the string of statesobtained by ignoring symbols in G U {#, $} corresponds toa sequence of state-to-statemoves that the transducer can make on the pair Ix, Y/, where y comes from ignoring$ and all state-symbols in the output string.366Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsTwo tasks remain: we must filter the output o eliminate any strings whose deriva-tion does not include a Final subrule application, and we must remove all state-symbolsand $ to obtain the ultimate output string.
If a Final rule did not apply, then the lastelement in the batch output string is a state, not the special character $.
We must for-mulate a rule that will "bleed" the derivation, producing no output at all if its inputends in a state-symbol instead of $.
We can achieve this with an anomalous obligatoryrule whose output would be infinitely long if its input ever satisfies the conditions forits application.
The following rule behaves in this way:e --* $ /Q  # (obligatory, left-to-right)It has the effect of filtering strings that do not represent transitions to a final state byforcing indefinitely many insertions of $ when no single $ is present.
The output ofthis rule will be all and only the strings that came from a previous application of aFinal rule.
The last rule of the grammar is a trivial clean-up rule that produces thegrammar's final output strings:Q u $ ~ c (obligatory, left-to-right)This completes the proof of the theorem.
We have constructed for any regular elationan ordered sequence of four rules (including a batch rule with finitely many subrules)that rewrites a string x to y just in case the pair (x, y) belongs to the relation.
\[\]We remark that there are alternative but perhaps less intuitive proofs of this the-orem framed only in terms of simple nonbatch rules.
But this result cannot be estab-lished without making use of boundary-context rules.
Without such rules we can onlysimulate a proper subclass of the regular elations, those that permit identity prefixesand suffixes of unbounded length to surround any nonidentity correspondences.
It isinteresting to note that for much the same reason, Ritchie (1992) also made crucial useof two-level boundary-context rules to prove that the relations denoted by Kosken-niemi's (1985) two-level grammars are also coextensive with the regular relations.Moreover, putting Ritchie's result together with ours gives the following:TheoremOrdered rewriting rammars with boundaries and two-level constraint grammars withboundaries are equivalent in their expressive power.Although there may be aesthetic or explanatory differences between the two formalsystems, empirical coverage by itself cannot be used to choose between them.7.
Two-Level Rule SystemsInspired in part by our early report of the material presented in this paper (Kaplanand Kay 1981), Koskenniemi (1983) proposed an alternative system for recognizing andproducing morphological nd phonological word-form variants.
Under his proposal,individual generalizations are expressed irectly in the state-transition diagrams offinite-state transducers, and their mutual interactions emerge from the fact that everyinput-output string pair must be accepted simultaneously b  all these transducers.Thus, he replaced the serial feeding arrangement of the independent generalizationsin a rewriting grammar with a parallel method of combination.
In eliminating theintermediate strings that pass from one rewriting rule to another, he also reduced to367Computational Linguistics Volume 20, Number 3just two the number of linguistically meaningful levels of representation.
I  two-levelparlance, these are usually referred to as the lexical and surface strings.7.1 The Analysis of Parallel AutomataThe lexical-surface string sets of the individual generalizations in Koskenniemi's sys-tem are clearly regular, since they are defined outright as finite-state transducers.
Butit is not immediately obvious that the string relation defined by a whole two-levelgrammar is regular.
Koskenniemi gave an operational specification, not an algebraicone, of how the separate transducers are to interact.
A pair of strings is generated bya two-level grammar if the pair is accepted separately by each of the transducers, andfurthermore, the label on the transition taken by one fst at a particular string positionis identical to the label of the transition that every other fst takes at that string posi-tion.
In essence, he prescribed a transition function 6 for a whole-grammar transducerthat allows transitions between states in cross-product s ate sets just in case they arepermitted by literal-matching transitions in the individual machines.This transition function generalizes to a two-tape transducer the construction of aone-tape finite-state machine for the intersection of two regular languages.
We mighttherefore suspect hat the lexical-surface r lation for a two-level grammar consistingof transducers TI~... Tn is the relation niR(Ti).
However, what is actually computedunder this interpretation is the relation Rel(Paths(T1) n Paths(T2)...
Paths(Tn)) of theform discussed in Section 3.
As we observed, this may be only a proper subset of therelation niR(Ti) when the component relations contain string pairs of unequal ength.In this case, the literal-matching transducer may not accept he intersection, a relationthat in fact may not even be regular.The individual transducers allowed in two-level specifications do permit the ex-pansion and contraction of strings by virtue of a null symbol 0.
If this were treated justlike c, we would be able to say very little about the combined relation.
However, theeffect of Koskenniemi's literal-matching transition function is achieved by treating 0 asan ordinary tape symbol, so that the individual transducers are C-free.
The intersectionof their same-length relations is therefore regular.
The length-changing effect of thewhole-grammar t ansducer is then provided by mapping 0 onto ~.
Thus we embedthe same-length intersection iR(Ti) as a regular inner component of a larger regularrelation that characterizes the complete lexical-to-surface mapping:Intro(O) o \[OR(Ti)\] oIntro(O) -11This relation expands its lexical string by freely introducing 0 symbols.
These are con-strained along with all other symbols by the inner intersection, and then the surfaceside of the inner relation is contracted by the removal of all 0's.
The entire outer re-lation gives an algebraic model of Koskenniemi's operational method for combiningindividual transducers and for interpreting the null symbol.
With this analysis of thetwo-level system in terms of regularly-closed operations and same-length relations,we have shown that the string relations accepted by parallel two-level automata rein fact regular.
We have also shown, by the way, that the two-level system is techni-cally a four-level one, since the inner relation defines two intermediate, 0-containinglevels of representation.
Still, only the two outer levels are linguistically significant.In typical two-level implementations the Intro relations are implicitly encoded in theinterpretation algorithms and do not appear as separate transducers.368Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systems7.2 Two-Level Rule NotationKoskenniemi (1983) offered an informal grammatical notation to help explicate theintended effect of the individual transducers and make the generalizations encodedin their state-transition diagrams easier to understand and reason about.
However,he proposed no method of interpreting or compiling that notation.
In later work (e.g.Karttunen, Koskennienni, and Kaplan 1987; Karttunen and Beesley 1992) the math-ematical techniques we presented above for the analysis of rewriting systems wereused to translate this notation into the equivalent regular elations and correspond-ing transducers, and thus to create a compiler for a more intuitive and more tractabletwo-level rule notation.
Ritchie (1992) summarizes aspects of this analysis as presentedby Kaplan (1988).
Ritchie et al (1992) describe a program that interprets this notationby introducing and manipulating labels assigned to the states of component finite-state machines.
Since these labels have no simple set-theoretic significance, such anapproach does not illuminate the formal properties of the system and does not makeit easy to combine two-level systems with other formal devices.Ignoring some notational details, agrammar of two-level rules (as opposed to fsts)includes a specification of a set of "feasible pairs" of symbols that we denote by 7r.
Thepairs in 7r contain all the alphabet symbols and 0, but do not contain e except possiblywhen it is paired with itself in e: ~.
The relations corresponding to all the individualrules are all subsets of ~r*, and thus are all of the restricted same-length class (since~r does not contain e paired with an alphabetic symbol).
For this class of relations,it makes sense to talk about a correspondence b tween a symbol in one string in astring-pair and a symbol in the other: in the pair (abc, lmn) for example, we can saythat a corresponds tol, b to m, and c to n, by virtue of the positions they occupy relativeto the start of their respective same-length strings.
Symbol pairs that correspond inthis way must be members of 7r.
It also makes sense to talk about correspondingsubstrings, equences of string pairs whose symbols correspond to each other in somelarger string pair.
Corresponding substrings belong to 7r*.The grammar contains a set of rules whose parts are also same-length regular-relation subsets of 7r*.
There are two basic kinds of rules, context restriction rules andsurface coercion rules.
A simple context restriction rule is an expression of the form~-~A__pwhere ~-, ~, and p denote subsets of 7r*.
Usually ~- is just a single feasible pair, asingleton element of 7r, but this limitation has no mathematical significance.
Eitherof the contexts )~ or p can be omitted, in which case it is taken to be e: e. Such arule is interpreted as denoting a string relation whose members atisfy the followingconditions: Every corresponding substring of a string pair that belongs to the relation~- must be immediately preceded by a corresponding substring belonging to the left-context ~ and followed by one belonging to the right-context p. In other words, anyappearance of T outside the specified contexts is illegal.
Under this interpretation, therelation denoted by the rulea:b =~ c:d e:fwould include the string pairs Icae, dbf) and (cae, cge), assuming that a :g is in 7r alongwith the symbol pairs mentioned in the rule.
The first string pair is included becausethe pair a:b is properly surrounded by c:d and e:f. The second belongs because itcontains an instance of a:g instead of a:b and thus imposes no requirements on thesurrounding context.
The string pair (cae, cbe) is not included, however, because a:bappears in a context not sanctioned by the rule.369Computational Linguistics Volume 20, Number 3A simple surface coercion rule is written with the arrow going in the other direc-tion:T~,kpFor strings to satisfy a constraint of this form, they must meet a more complicated setof conditions.
Suppose that a corresponding substring belonging to ,k comes before acorresponding substring belonging to p, and that the lexical side of the paired substringthat comes between them belongs to the domain of T. Then that intervening pairedsubstring must itself belong to T. To illustrate, consider the surface coercion versionof the context restriction example above:a:b 4= c :d__e : fThe string pair (caG dbf} satisfies this constraint because a:b comes between the con-text substrings c:d and e:f. The pair (cbe, dbf} is also acceptable, because the stringintervening between c:d and e :f does not have a on its lexical side.
However, the pairIcae, dgf} does not meet the conditions because a:g comes between c:d and e:f. Thelexical side of this is the same as the lexical side of the 7 relation a:b, but the pair a :gitself is not in T. Informally, this rule forces the a to be realized as a surface b when itappears between the specified contexts.Karttunen et al (1987) introduced a variant of a surface coercion rule called asurface prohibition.
This is a rule of the formand indicates that a paired substring that comes between instances of )~ and p andwhose lexical side is in the domain of T must not itself belong to ~-.
We shall see thatthe mathematical properties of surface prohibitions follow as immediate corollaries ofour surface coercion analysis.The notation also permits compound rules of each type.
These are rules in whichmultiple context pairs are specified.
A compound context restriction rule is of the formT ~ /~1 __  pl; ~2 __  p2;.../~n __  finand is satisfied if each instance of ~- is surrounded by an instance of some Ak_pk pair.A compound surface coercion rule requires the 7 surface realization in each of thespecified contexts.For convenience, surface coercions and context restrictions can be specified in asingle rule, by using 4=~ as the main connective instead of ~ or o .
A bidirectionalrule is merely an abbreviation that can be included in a grammar in place of the twosubrules formed by replacing the 4~ first by ~ and then o .
Such rules need no furtherdiscussion.7.3 Context Restriction Rules (3 )To model the conditions imposed by context restriction rules, we recall the If-P-then-Sand If-S-then-P operators we defined for regular languages L1 and L2:If-P-then-S(L1, L2) = L1L2 = ~* - L1L2If-S-then-P(L1, C2) = ElL2 = ~* - LIL2370Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule SystemsThese operators can be extended to apply to string relations as well, and the resultswill be regular if the operands are in a regular subclass that is closed under comple-mentation.
For notational convenience, we let the overbar in these extensions and inthe other expressions below stand for the complement relative to 7r* as opposed to themore usual ~* x ~*:_ _  mIf-P-then-S(R1,R2) = ~* - R1R2 = RIR2mIf-S-then-P(R1, R2) = 7r* - R1R2 = RIR2The conditions for a simple context restriction rule are then modeled by the followingrelation:Restrict(% A, p) = If- S-then-P (Tr* A, T ~r* ) n If-P-then- S ( Tr*T , p~r* )The first component ensures that ~- is always preceded by A, and the second guaranteesthat it is always followed by p.A compound context restriction rule of the form3- :=> /~1 __  p l ;  /~2 __  p2 ;  .
.
.
; .,~n __  pnis satisfied if all instances of ~- are surrounded by substrings meeting the conditions ofat least one of the context pairs independently.
A candidate model for this disjunctiveinterpretation is the relationURestrict (% )~ k, pk)kThis is incorrect, however, because the scope of the union is too wide.
It specifies thatthere must be some k such that every occurrence of T will be surrounded by Ak-p k,whereas the desired interpretation is that each 7- must be surrounded by )~k_pk, but adifferent kmight be chosen for each occurrence.
A better approximation is the relation\[UkRestrict(T, )~k pk)\],Because of the outer Kleene * iteration, different instances of the rule can apply atdifferent string-pair positions.
But this also has a problem, one that should be familiarfrom our study of rewriting rules: the iteration causes the different rule instances tomatch on separate, successive substrings.
It does not allow for the possibility thatthe context substring of one application might overlap with the center and contextportions of a preceding one.This problem can be solved with the auxiliary-symbol techniques we developedfor rewriting rule overlaps.
We introduce left and right context brackets <k and >kfor each context pair Ak-p k, These are distinct from all other symbols, and since theiridentity pairs are now feasible pairs, they are added to ~r.
These pairs take the placeof the actual context relations in the iterative union\[UkRestrict(T, Id( <k), Id(> k) )\]*This eliminates the overlap problem.
We then must ensure that these bracket pairsappear only if appropriately followed or preceded by the proper context relation.With m being the set of all bracket pairs and subscripting now indicating that identitypairs of the specified symbols are ignored, we define a two-level left-context operatorLeftcontext( A, 1) = If-S-then-P( Tr* Am, Id ( l)Tc* )371Computational Linguistics Volume 20, Number 3so that Leflcontext(& k,<k) enforces the requirement that every <k pair be preceded byan instance of I k. This is simpler than the rewriting left-context operator because notevery instance of A must be marked---only the ones that precede ~-, and those arepicked out independently b  the iterative union.
That is why this uses a one-wayimplication instead of a biconditional.
As in the rewriting case, the ignoring providesfor overlapping instances of ,~.
The right-context operator can be defined symmetricallyusing If-P-then-S or by reversing the left-context operator:Rightcontext(p, r) = Rev(Leftcontext( Rev(p), r) )Putting the pieces together, the following relation correctly models the interpretationof a compound context restriction rule:Intro(m) o\[URestrict(r, ld( Kk), Id( >k) )\] * N \[Ak \[Leftcontext( Ak, <k) A Rightcontext(p k, >k)\]\]k o Intro(m) -1Auxiliary marks are freely introduced on the lexical string.
Those marks are appropri-ately constrained so that matching brackets enclose very occurrence of T, and eachbracket marks an occurrence of the associated context relation.
The marks are removedat the end.
Note that there are only same-length relations in the intermediate expres-sion, and that all brackets introduced at the top are removed at the bottom.
Thus thecomposite relation is regular and also belongs to the same-length subclass, so that theresult of intersecting it with the same-length regular elations for other rules will beregular.7.4 Surface Coercion Rules (~)A surface coercion rule of the form~-~l__pimposes a requirement on the paired substrings that come between all members of theA and p relations.
If the lexical side of such a paired substring belongs to the domainof -r, then the surface side must be such that the intervening pair belongs to T.To formalize this interpretation, we first describe the set of string pairs that failto meet the conditions.
The complement of this set is then the appropriate relation.The relation Y = ~r* - 7- is the set of string pairs in Tr* that are not in T, because ithertheir lexical string is not in the domain of ~- or 7- associates that lexical string withdifferent surface strings, ld(Dom(7)) o ~ is the subset of these whose lexical stringsare in the domain of ~- and whose surface strings must therefore be different han ~-provides for.
The unacceptable string pairs thus belong to the same-length relationzc*A\[Id(Dom(T)) o ~\]p~r*, and its regular complement in the Coerce operatorCoerce(T, A, p) = 7r*l\[Id(Dom(,-)) o Y\]pTr*contains all the string pairs that satisfy the rule.For most surface coercions it is also the case that this contains only the pairs thatsatisfy the rule.
But for one special class of coercions, the epenthesis rules, this relationincludes more string pairs than we desire.
These are rules in which the domain of ~-includes trings consisting entirely of O's, and the difficulty arises because of the dualnature of two-level O's.
They behave formally as actual string symbols in same-length372Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsrelations, but they are also intended to act as the empty string.
In this way they aresimilar to the 4% in the centers of rewriting rules, and they must also be modeled byspecial techniques.
The epenthesis ruleO:b4=c:c d:dcan be used to illustrate the important issues.If this is the only rule in a grammar, then clearly that grammar should allow thestring pair (cd, cbd) but disallow the pair (cd, ced), in which e appears instead of bbetween the surface c and d. It should also disallow the pair (cd, cd), in which c and dare adjacent on both sides and no epenthesis has occurred.
This is consistent with theintuition that the 0 in the rule stands for the absence of explicit lexical string material,and that therefore the rule must force a surface b when lexical c and d are adjacent.In our analysis this interpretation f 0 is expressed by having the Intro relation freelyintroduce 0's between any other symbols, mimicking the fact that e can be regarded asfreely appearing everywhere.
The pair (cd, cbd) is allowed as the composition of pairs(cd, cOd) and (cOd, cbd); the first pair belongs to the Intro relation and the second issanctioned by the rule.
But because O's are introduced freely, the Intro relation includesthe identity pair (cd, cd) as well.
The Coerce relation as defined above also contains thepair (cd, cd} (= (ccd, c4d)), since 4:4 is not in \[0:0 o 0:b\].
The grammar as a whole thusallows (cd, cd} as an undesired composition.We can eliminate pairs of this type by formulating a slightly different relation forepenthesis rules such as these.
We must still disallow pairs when O's in the domain of7 are paired with strings not in the range.
But we also want to disallow pairs whoselexical strings do not have the appropriate O's to trigger the grammar's epenthesiscoercions.
This can be accomplished by a modified version of the Coerce relation thatalso excludes realizations of the empty string by something not in 7.
We replace theDom(T) expression i  the definition above with the relation Dom(T U {4: 4}).
The two-level literature is silent about whether or not an epenthesis rule should also rejectstrings with certain other insertion patterns.
On one view, the rule only restricts theinsertion of singleton strings and thus pairs such as (cd, cbbd) and (cd, ceed) would beincluded in the relation.
This view is modeled by using the Dom(T t3 {4:4}) expression.On another view, the rule requires that lexically adjacent c and d must be separatedby exactly one b on the surface, so that (cd, cbbd) and (cd, ceed) would be excludedin addition to (cd, ced) and (cd, cd).
We can model this second interpretation by using0* instead of Dom(7 U {c:4}).
The relation then restricts the surface realization of anynumber of introduced 0%.
It is not clear which of these interpretations leads to a moreconvenient formalism, but each of them can be modeled with regular devices.Karttunen and Beesley (1992, p. 22) discuss a somewhat different peculiarity thatshows up in the analysis of epenthesis rules where one context is omitted (or equiva-lently, one context includes the pair 4:~).
The rule0 : b 4= c:c d:drequires that a b corresponding to nothing in the lexical string must appear in thesurface string after every c:c pair.
If we use either the Dom (r U {c : ~}) or 0* expressionsin defining the coercion relation for this rule, the effect is not what we intend.
Theresulting relation does not allow strings in which a ?
: ?
follows c: c, because ?is includedin the restrictive domain expression.
But 4:e follows and precedes every symbol pair,of course, so the result is a relation that simply prohibits all occurrences of c:c. If,however, we revert o using the domain expression without the {~:~} union, we fall373Computational Linguistics Volume 20, Number 3back into the difficulty we saw with two-context epenthesis rules: the resulting relationproperly ensures that nothing other than b can be inserted after c:c, but it leaves openthe possibility of c:c followed by no insertion at all.A third formulation is necessary to model the intended interpretation of one-context epenthesis rules.
This is given by the relation 7r*)xyTc* if only the left-contextis specified, or 7c*yp~r* if only p appears.
These exclude all strings where an instanceof the relevant context is followed by paired substrings not in 7, either because theappropriate number of lexical O's were not (freely) introduced or because those 0'scorrespond to unacceptable surface material.
These two prescriptions can be broughttogether into the single formula ~r*)~pTc* for all one-context rules, since whichevercontext is missing is treated as the identity pair c:?.
We can bring out the similaritybetween this formula and the original Coerce relation by observing that this one isequivalent o 7c*,~\[Id(Dom(Tc*))o ~\]p~r* because Id(DomOr*)) o-?
and ~ are the samerelation.We now give a general statement of the Coerce relation that models surface coer-cions whether they are epenthetic or non-epenthetic:Coerce(T, ~, p) = 7r*A\[Id(Dom(X) ) oY\]pTr*, whereX = T if r has no epenthetic pairs;X = ~-U {c:e} (or perhaps \[0:0\]*) if T has only epenthetic pairsand neither )~ nor p contains e:e;X = ~-* if T has only epenthetic pairs and one of ~ or p doescontain e: c.This definition assumes that T is homogeneous in that either all its string-pairs areepenthetic or none of them are, but we must do further analysis to guarantee that thisis the case.
In the formalism we are considering, ~- is permitted to be an arbitrary same-length relation, not just the single unit-length pair that two-level systems typicallyprovide for.
If ~- contains more than one string-pair, the single rule is interpreted asimposing the constraints that would be imposed by a conjunction of rules formed bysubstituting for T each of its member string-pairs in turn.
Without further specificationand even if ~- contains infinitely many pairs, this is the interpretation modeled bythe Coerce relation, provided that T is homogeneous.
To deal with heterogeneous Trelations, we separate the epenthetic and nonepenthetic pairs into two distinct andhomogeneous subrelations.
We partition an arbitrary 7- into the subrelations T ?
and ~-?defined as~-0 = Ia (0* )  o ~-T ~ ~ T - -  T OWe then recast a rule of the form r ~ )x __  p as the conjunction of the two rulesT o ~ A __  p~-o ~ ~ __  pThese rules taken together epresent the desired interpretation of the original, andeach of them is properly modeled by exactly one variant of the Coerce relation.We have now dealt with the major complexities that surface coercion rules present.The compound forms of these rules are quite easy to model.
A rule of the formT ?= ,,~1 __  p l ;  ,~2 __  p2 ; .
.
.
;/~n __  pn374Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsis interpreted as coercing to the surface side of ~- if any of the context conditions aremet.
Auxiliary symbols are not needed to model this interpretation, since there is noiteration to introduce overlap difficulties.
The relation for this rule is given simply bythe intersection of the individual relations:NCoerce( T, A k, pk)kWe conclude our discussion of two-level rules with a brief mention of surface prohi-bitions.
Recall that a prohibition ruleindicates that a paired substring must not belong to "r if it comes between instancesof ,~ and p and its lexical side is in the domain of T. We can construct a standardsurface coercion rule that has exactly this interpretation by using the complement of7- restricted to ~-'s domain:\[Id(Dom@)) o ~\] ~ A __  pAs desired, the left side is the relation that maps each string in the domain of ~- to allstrings other than those to which T maps it.
Surface prohibitions are thus reduced toordinary surface coercions.7.5 Grammars of Two-Level  RulesThe relation for a grammar of rules is formed just as for a grammar of parallel au-tomata.
The intersection of the relations for all the individual rules is constructedas a same-length inner relation.
This is then composed with the 0 introduction andremoval relations to form the outer lexical-to-surface map.
Rule-based two-level gram-mars thus denote regular elations, just as the original transducer-based grammars do.Some grammars may make use of boundary-context rules, in which case a special sym-bol # can appear in contexts to mark the beginning and end of the strings.
These canbe modeled with exactly the same technique we outlined for rewriting rules: we com-pose the additional relation \[~:#Id (Era0 # E~0 ) ~:#\] at the beginning of the four-levelcascade and compose its inverse at the end.
As we mentioned before, the two-levelgrammars with boundary-context rules are the ones that Ritchie (1992) showed werecomplete for the regular elations.In reasoning about these systems, it is important o keep clearly in mind thedistinction between the outer and inner relations.
Ritchie (1992), for example, alsoproved that the "languages" generated by two-level grammars with regular contextsare closed under intersection, but this result does not hold if a grammar's languageis taken to be its outer relation.
Suppose that G1 has the set {a:b,O:c} as its feasiblepairs and the vacuous a:b ~ __  as its only rule, and that G2 has the pairs {a:c, 0:b}and rule a:c =~ __ .
The domain of both outer (0-free) relations is a*.
A string a n ismapped by G1 into strings containing n b's with c's freely intermixed and by G2 intostrings containing n c's with b's freely intermixed.
The range of the intersection of theouter relations for G1 and G2 thus contains trings with the same number of b's andc's but occurring in any order.
This set is not regular, since intersecting it with theregular language b'c* produces the context-free language bnc n. The intersection of thetwo outer relations is therefore also not regular and so cannot be the outer relation ofany regular two-level grammar.375Computational Linguistics Volume 20, Number 3We have shown how our regular analysis techniques can be applied to two-levelsystems as well as rewriting grammars, and that grammars in both frameworks de-note only regular elations.
These results open up many new ways of partitioning theaccount of linguistic phenomena in order to achieve descriptions that are intuitivelymore satisfying but without introducing new formal power or computational machin-ery.
Karttunen, Kaplan, and Zaenen (1992), for example, argued that certain Frenchmorphological patterns can be better described as the composition of two separatetwo-level grammars rather than as a single one.
As another option, an entire two-levelgrammar can be embedded in place of a single rule in an ordered rewriting system.
Aslong as care is taken to avoid inappropriate complementations and intersections, allsuch arrangements will denote regular elations and can be implemented by a uniformfinite-state transducer mechanism.8.
ConclusionOur aim in this paper has been to provide the core of a mathematical frameworkfor phonology.
We used systems of rewriting rules, particularly as formulated in SPE,to give concreteness to our work and to the paper.
However, we continually soughtsolutions in terms of algebraic abstractions of sufficiently high level to free them fromany necessary attachment to that or any other specific theory.
If our approach provesuseful, it will only be because it is broad enough to encompass new theories andnew variations on old ones.
If we have chosen our abstractions well, our techniqueswill extend smoothly and incrementally to new formal systems.
Our discussion oftwo-level rule systems illustrates how we expect such extensions to unfold.
Thesetechniques may even extend to phonological systems that make use of matched pairsof brackets.
Clearly, context-free mechanisms are sufficient o enforce dependenciesbetween corresponding brackets, but further esearch may show that accurate phono-logical description does not exploit he power needed to maintain the balance betweenparticular pairs, and thus that only regular devices are required for the analysis andinterpretation f such systems.An important goal for us was to establish a solid basis for computation i thedomain of phonological nd orthographic systems.
With that in mind, we developeda well-engineered computer implementation f the calculus of regular languages andrelations, and this has made possible the construction ofpractical language processingsystems.
The common data structures that our programs manipulate are clearly states,transitions, labels, and label pairs--the building blocks of finite automata nd trans-ducers.
But many of our initial mistakes and failures arose from attempting also tothink in terms of these objects.
The automata required to implement even the simplestexamples are large and involve considerable subtlety for their construction.
To viewthem from the perspective ofstates and transitions i much like predicting weather pat-terns by studying the movements of atoms and molecules or inverting a matrix with aTuring machine.
The only hope of success in this domain lies in developing an appro-priate set of high-level algebraic operators for reasoning about languages and relationsand for justifying a corresponding set of operators and automata for computation.From a practical point of view, the result of the work reported here has been a setof powerful and sometimes quite complex tools for compiling phonological grammarsin a variety of formalisms into a single representation, namely a finite-state transducer.This representation has a number of remarkable advantages: (1) The program requiredto interpret his representation is simple almost to the point of triviality, no matterhow intricate the original grammars might have been.
(2) That same program can beused to generate surface or textual forms from underlying lexical representations or376Ronald M. Kaplan and Martin Kay Regular Models of Phonological Rule Systemsto analyze text into a lexical string; the only difference is in which of the two symbolson a transition is regarded as the input and which the output.
(3) The interpreter isconstant even under radical changes in the theory and the formalism that informedthe compiler.
(4) The compiler consists almost entirely of an implementation f thebasic calculus.
Given the operators and data types that this makes available, only avery few lines of code make up the compiler for a particular theory.Reflecting on the way the relation for a rewriting rule is constructed from simplerrelations, and on how these are composed to create a single relation for a completegrammar, we come naturally to a consideration of how that relation should comportwith the other parts of a larger language-processing system.
We can show, for example,that the result of combining together a list of items that have exceptional phonologicalbehavior with a grammar-derived relation for general patterns is still a regular re-lation with an associated transducer.
If E is a relation for a finite list of exceptionalinput-output pairs and P is the general phonological relation, then the combination isgiven byE m \[Id(Dom(E)) o P\]This relation is regular because E is regular (as is any finite list of pairs); it suppressesthe general mapping provided by P for the exceptional items, allowing outputs forthem to come from E only.
As another example, the finite list of formatives in a lex-icon L can be combined with a regular phonology (perhaps with exceptions alreadyfolded in) by means of the composition Id(L) o P. This relation enshrines not only thephonological regularities of the language but its lexical inventory as well, and its cor-responding transducer would perform phonological recognition and lexical ookup ina single sequence of transitions.
This is the sort of arrangement that Karttunen et al(1992) discuss.
Finally, we know that many language classes are closed under finite-state transductions or composition with regular elations--the images of context-freelanguages, for example, are context-free.
It might herefore prove advantageous to seekways of composing phonology and syntax to produce a new system with the sameformal properties as syntax alone.AcknowledgmentsWe are particularly indebted to DannyBobrow for helpful discussions in the earlystages of the research on rewriting systems.Our understanding and analysis oftwo-level systems i  based on veryproductive discussions with LauriKarttunen and Kimmo Koskenniemi.
Wewould like to thank John Maxwell, MaryDalrymple, Andy Daniels, Chris Manning,and especially Kenneth Beesley for detailedcomments on earlier versions of this paper.Finally, we are also indebted to theanonymous referees for identifying anumber of technical and rhetoricalweaknesses.
We, of course, are responsiblefor any remaining errors.ReferencesChomsky, Noam, and Halle, Morris (1968).The Sound Pattern of English.
Harper andRow.Eilenberg, Samuel (1974).
Automata,Languages, and Machines.
Academic Press.Harrison, Michael A.
(1978).
Introduction toFormal Language Theory.
Addison-Wesley.Hopcroft, John E., and Ullman, Jeffrey D.(1979).
Introduction to Automata Theory,Languages and Computation.Addison-Wesley.Johnson, C. Douglas (1972).
Formal Aspects ofPhonological Description.
Mouton.Kaplan, Ronald M. (1984).
"Finite-statemodels of phonological rule systems.
"Paper presented to the First Mathematics ofLanguage Conference, University ofMichigan.Kaplan, Ronald M. (1985).
"Finite-statemodels of phonological rule systems.
"Paper presented to the Workshop on FiniteState Morphology, Center for the Study ofLanguage and Information, StanfordUniversity.Kaplan, Ronald M. (1988).
"Regular modelsof phonological rule systems."
Paperpresented to the Alvey Workshop on Parsingand Pattern Recognition, Oxford University.377Computational Linguistics Volume 20, Number 3Kaplan, Ronald M., and Kay, Martin (1981).
"Phonological rules and finite-statetransducers."
Paper presented to theWinter Meeting of the Linguistic Society ofAmerica, New York.Karttunen, Lauri, and Beesley, Kenneth(1992).
"Two-level rule compiler.
"Technical report, Xerox Palo AltoResearch Center, Palo Alto, California.Karttunen, Lauri; Kaplan, Ronald M.; andZaenen, Annie (1992).
"Two-levelmorphology with composition.
"COLING-92, 141-148.
Nantes.Karttunen, Lauri; Koskenniemi, Kimmo;and Kaplan, Ronald M. (1987).
"Acompiler for two-level phonologicalrules."
In Report No.
CSLI-87-108, Centerfor the Study of Language andInformation, Stanford University.Kay, Martin (1987).
"Nonconcatenativefinite-state morphology."
In Proceedings,Third European Conference ofthe Associationfor Computational Linguistics, 2-10.Copenhagen.Kenstowicz, Michael, and Kisseberth,Charles (1979).
Generative Phonology:Description and Theory.
Academic Press.Klatt, Dennis H. (1980).
"Scriber and Lafs:Two new approaches tospeech analysis.
"In Trends in Speech Recognition, edited byWayne Lea, 529-555.
Prentice-Hall.Koskenniemi, Kimmo (1983).
"Twoqevelmorphology: A general computationalmodel for word-form recognition andproduction."
Publication No.
11,Department of General Linguistics,University of Helsinki.Koskenniemi, Kimmo (1985).
"Compilationof automata from morphologicaltwo-level rules."
In Papers from the FifthScandinavian Conference ofComputationalLinguistics, 143-149.
Helsinki, Finland.Ritchie, Graeme D. (1992).
"Languagesgenerated by two-level morphologicalrules."
Computational Linguistics, 18 (1),41-59.Ritchie, Graeme D.; Russell, Graham J.;Black, Alan W.; and Pulman, Stephen G.(1992).
Computational Morphology.
MITPress.Woods, William A.; Bates, Madeleine;Brown, Geoffrey; Bruce, Bertram C.;Cook, Craig C.; Klovstad, John W.;Makhoul, John; Nash-Webber, Bonnie;Schwartz, Richard; Wolf, Jared; and Zue,Victor (1976).
"Speech understandingsystems: Final report."
Report No.
3438,Bolt Beranek and Newman, Inc.,Cambridge, Mass.378
