Proceedings of ACL-08: HLT, pages 771?779,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsLearning Bilingual Lexicons from Monolingual CorporaAria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick and Dan KleinComputer Science Division, University of California at Berkeley{ aria42,pliang,tberg,klein }@cs.berkeley.eduAbstractWe present a method for learning bilingualtranslation lexicons from monolingual cor-pora.
Word types in each language are charac-terized by purely monolingual features, suchas context counts and orthographic substrings.Translations are induced using a generativemodel based on canonical correlation analy-sis, which explains the monolingual lexiconsin terms of latent matchings.
We show thathigh-precision lexicons can be learned in a va-riety of language pairs and from a range ofcorpus types.1 IntroductionCurrent statistical machine translation systems useparallel corpora to induce translation correspon-dences, whether those correspondences be at thelevel of phrases (Koehn, 2004), treelets (Galley etal., 2006), or simply single words (Brown et al,1994).
Although parallel text is plentiful for somelanguage pairs such as English-Chinese or English-Arabic, it is scarce or even non-existent for mostothers, such as English-Hindi or French-Japanese.Moreover, parallel text could be scarce for a lan-guage pair even if monolingual data is readily avail-able for both languages.In this paper, we consider the problem of learningtranslations from monolingual sources alone.
Thistask, though clearly more difficult than the standardparallel text approach, can operate on language pairsand in domains where standard approaches cannot.We take as input two monolingual corpora and per-haps some seed translations, and we produce as out-put a bilingual lexicon, defined as a list of wordpairs deemed to be word-level translations.
Preci-sion and recall are then measured over these bilin-gual lexicons.
This setting has been considered be-fore, most notably in Koehn and Knight (2002) andFung (1995), but the current paper is the first to usea probabilistic model and present results across a va-riety of language pairs and data conditions.In our method, we represent each language as amonolingual lexicon (see figure 2): a list of wordtypes characterized by monolingual feature vectors,such as context counts, orthographic substrings, andso on (section 5).
We define a generative model over(1) a source lexicon, (2) a target lexicon, and (3) amatching between them (section 2).
Our model isbased on canonical correlation analysis (CCA)1 andexplains matched word pairs via vectors in a com-mon latent space.
Inference in the model is doneusing an EM-style algorithm (section 3).Somewhat surprisingly, we show that it is pos-sible to learn or extend a translation lexicon us-ing monolingual corpora alone, in a variety of lan-guages and using a variety of corpora, even in theabsence of orthographic features.
As might be ex-pected, the task is harder when no seed lexicon isprovided, when the languages are strongly diver-gent, or when the monolingual corpora are from dif-ferent domains.
Nonetheless, even in the more diffi-cult cases, a sizable set of high-precision translationscan be extracted.
As an example of the performanceof the system, in English-Spanish induction with ourbest feature set, using corpora derived from topicallysimilar but non-parallel sources, the system obtains89.0% precision at 33% recall.1See Hardoon et al (2003) for an overview.771statesocietyenlarge-mentcontrolimport-ancesociedadestadoamplifi-caci?nimport-anciacontrol......stmFigure 1: Bilingual lexicon induction: source word typess are listed on the left and target word types t on theright.
Dashed lines between nodes indicate translationpairs which are in the matching m.2 Bilingual Lexicon InductionAs input, we are given a monolingual corpus S (asequence of word tokens) in a source language anda monolingual corpus T in a target language.
Lets = (s1, .
.
.
, snS ) denote nS word types appearingin the source language, and t = (t1, .
.
.
, tnT ) denoteword types in the target language.
Based on S andT , our goal is to output a matching m between sand t. We represent m as a set of integer pairs sothat (i, j) ?m if and only if si is matched with tj .2.1 Generative ModelWe propose the following generative model overmatchings m and word types (s, t), which we callmatching canonical correlation analysis (MCCA).MCCA modelm ?
MATCHING-PRIOR [matching m]For each matched edge (i, j) ?m:?zi,j?
N (0, Id) [latent concept]?fS(si) ?
N (WSzi,j,?S) [source features]?fT(ti) ?
N (WTzi,j,?T) [target features]For each unmatched source word type i:?fS(si) ?
N (0, ?2IdS) [source features]For each unmatched target word type j:?fT(tj) ?
N (0, ?2IdT) [target features]First, we generate a matching m ?M, whereMis the set of matchings in which each word type ismatched to at most one other word type.2 We takeMATCHING-PRIOR to be uniform overM.3Then, for each matched pair of word types (i, j) ?m, we need to generate the observed feature vectorsof the source and target word types, fS(si) ?
RdSand fT (tj) ?
RdT .
The feature vector of each wordtype is computed from the appropriate monolin-gual corpus and summarizes the word?s monolingualcharacteristics; see section 5 for details and figure 2for an illustration.
Since si and tj are translations ofeach other, we expect fS(si) and fT (tj) to be con-nected somehow by the generative process.
In ourmodel, they are related through a vector zi,j ?
Rdrepresenting the shared, language-independent con-cept.Specifically, to generate the feature vectors, wefirst generate a random concept zi,j ?
N (0, Id),where Id is the d ?
d identity matrix.
The sourcefeature vector fS(si) is drawn from a multivari-ate Gaussian with mean WSzi,j and covariance ?S ,where WS is a dS ?
d matrix which transforms thelanguage-independent concept zi,j into a language-dependent vector in the source space.
The arbitrarycovariance parameter ?S  0 explains the source-specific variations which are not captured by WS ; itdoes not play an explicit role in inference.
The targetfT (tj) is generated analogously using WT and ?T ,conditionally independent of the source given zi,j(see figure 2).
For each of the remaining unmatchedsource word types si which have not yet been gen-erated, we draw the word type features from a base-line normal distribution with variance ?2IdS , withhyperparameter ?2  0; unmatched target wordsare similarly generated.If two word types are truly translations, it will bebetter to relate their feature vectors through the la-tent space than to explain them independently viathe baseline distribution.
However, if a source wordtype is not a translation of any of the target wordtypes, we can just generate it independently withoutrequiring it to participate in the matching.2Our choice ofM permits unmatched word types, but doesnot allow words to have multiple translations.
This setting facil-itates comparison to previous work and admits simpler models.3However, non-uniform priors could encode useful informa-tion, such as rank similarities.7721.01.020.05.0100.050.0...SourceSpaceCanonicalSpaceRdsRdt1.01.0...1.0TargetSpaceRd1.0{{OrthographicFeaturesContextualFeaturestimetiempo#ti#tiimempome#pe#changedawnperiodnecessary40.065.0120.045.0suficienteper?odomismoadicionalsitjzfS(si)fT(tj)Figure 2: Illustration of our MCCA model.
Each latent concept zi,joriginates in the canonical space.
The observedword vectors in the source and target spaces are generated independently given this concept.3 InferenceGiven our probabilistic model, we would like tomaximize the log-likelihood of the observed data(s, t):`(?)
= log p(s, t; ?)
= log?mp(m, s, t; ?
)with respect to the model parameters ?
=(WS ,WT ,?S ,?T ).We use the hard (Viterbi) EM algorithm as a start-ing point, but due to modeling and computationalconsiderations, we make several important modifi-cations, which we describe later.
The general formof our algorithm is as follows:Summary of learning algorithmE-step: Find the maximum weighted (partial) bi-partite matching m ?MM-step: Find the best parameters ?
by performingcanonical correlation analysis (CCA)M-step Given a matching m, the M-step opti-mizes log p(m, s, t; ?)
with respect to ?, which canbe rewritten asmax??
(i,j)?mlog p(si, tj ; ?).
(1)This objective corresponds exactly to maximizingthe likelihood of the probabilistic CCA model pre-sented in Bach and Jordan (2006), which provedthat the maximum likelihood estimate can be com-puted by canonical correlation analysis (CCA).
In-tuitively, CCA finds d-dimensional subspaces US ?RdS?d of the source and UT ?
RdT?d of the tar-get such that the components of the projectionsU>S fS(si) and U>T fT (tj) are maximally correlated.4US and UT can be found by solving an eigenvalueproblem (see Hardoon et al (2003) for details).Then the maximum likelihood estimates are as fol-lows: WS = CSSUSP 1/2, WT = CTTUTP 1/2,?S = CSS ?WSW>S , and ?T = CTT ?WTW>T ,where P is a d?
d diagonal matrix of the canonicalcorrelations, CSS = 1|m|?
(i,j)?m fS(si)fS(si)> isthe empirical covariance matrix in the source do-main, and CTT is defined analogously.E-step To perform a conventional E-step, wewould need to compute the posterior over all match-ings, which is #P-complete (Valiant, 1979).
On theother hand, hard EM only requires us to compute thebest matching under the current model:5m = argmaxm?log p(m?, s, t; ?).
(2)We cast this optimization as a maximum weightedbipartite matching problem as follows.
Define theedge weight between source word type i and targetword type j to bewi,j = log p(si, tj ; ?)
(3)?
log p(si; ?)?
log p(tj ; ?
),4Since dS and dT can be quite large in practice and of-ten greater than |m|, we use Cholesky decomposition to re-represent the feature vectors as |m|-dimensional vectors withthe same dot products, which is all that CCA depends on.5If we wanted softer estimates, we could use the agreement-based learning framework of Liang et al (2008) to combine twotractable models.773which can be loosely viewed as a pointwise mutualinformation quantity.
We can check that the ob-jective log p(m, s, t; ?)
is equal to the weight of amatching plus some constant C:log p(m, s, t; ?)
=?
(i,j)?mwi,j + C. (4)To find the optimal partial matching, edges withweight wi,j < 0 are set to zero in the graph and theoptimal full matching is computed inO((nS+nT )3)time using the Hungarian algorithm (Kuhn, 1955).
Ifa zero edge is present in the solution, we remove theinvolved word types from the matching.6Bootstrapping Recall that the E-step produces apartial matching of the word types.
If too fewword types are matched, learning will not progressquickly; if too many are matched, the model will beswamped with noise.
We found that it was helpfulto explicitly control the number of edges.
Thus, weadopt a bootstrapping-style approach that only per-mits high confidence edges at first, and then slowlypermits more over time.
In particular, we computethe optimal full matching, but only retain the high-est weighted edges.
As we run EM, we graduallyincrease the number of edges to retain.In our context, bootstrapping has a similar moti-vation to the annealing approach of Smith and Eisner(2006), which also tries to alter the space of hiddenoutputs in the E-step over time to facilitate learn-ing in the M-step, though of course the use of boot-strapping in general is quite widespread (Yarowsky,1995).4 Experimental SetupIn section 5, we present developmental experimentsin English-Spanish lexicon induction; experiments6Empirically, we obtained much better efficiency and evenincreased accuracy by replacing these marginal likelihoodweights with a simple proxy, the distances between the words?mean latent concepts:wi,j = A?
||z?i ?
z?j ||2, (5)where A is a thresholding constant, z?i = E(zi,j | fS(si)) =P 1/2U>S fS(si), and z?j is defined analogously.
The increasedaccuracy may not be an accident: whether two words are trans-lations is perhaps better characterized directly by how closetheir latent concepts are, whereas log-probability is more sensi-tive to perturbations in the source and target spaces.are presented for other languages in section 6.
Inthis section, we describe the data and experimentalmethodology used throughout this work.4.1 DataEach experiment requires a source and target mono-lingual corpus.
We use the following corpora:?
EN-ES-W: 3,851 Wikipedia articles with bothEnglish and Spanish bodies (generally not di-rect translations).?
EN-ES-P: 1st 100k sentences of text from theparallel English and Spanish Europarl corpus(Koehn, 2005).?
EN-ES(FR)-D: English: 1st 50k sentences ofEuroparl; Spanish (French): 2nd 50k sentencesof Europarl.7?
EN-CH-D: English: 1st 50k sentences of Xin-hua parallel news corpora;8 Chinese: 2nd 50ksentences.?
EN-AR-D: English: 1st 50k sentences of 1994proceedings of UN parallel corpora;9 Ara-bic: 2nd 50k sentences.?
EN-ES-G: English: 100k sentences of EnglishGigaword; Spanish: 100k sentences of SpanishGigaword.10Note that even when corpora are derived from par-allel sources, no explicit use is ever made of docu-ment or sentence-level alignments.
In particular, ourmethod is robust to permutations of the sentences inthe corpora.4.2 LexiconEach experiment requires a lexicon for evaluation.Following Koehn and Knight (2002), we considerlexicons over only noun word types, although thisis not a fundamental limitation of our model.
Weconsider a word type to be a noun if its most com-mon tag is a noun in our monolingual corpus.11 For7Note that the although the corpora here are derived from aparallel corpus, there are no parallel sentences.8LDC catalog # 2002E18.9LDC catalog # 2004E13.10These corpora contain no parallel sentences.11We use the Tree Tagger (Schmid, 1994) for all POS taggingexcept for Arabic, where we use the tagger described in Diab etal.
(2004).7740.6 0.65 0.7 0.75 0.8 0.850.9 0.95 10  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8Precision Recall EN-ES-PEN-ES-WFigure 3: Example precision/recall curve of our systemon EN-ES-P and EN-ES-W settings.
See section 6.1.all languages pairs except English-Arabic, we ex-tract evaluation lexicons from the Wiktionary on-line dictionary.
As we discuss in section 7, our ex-tracted lexicons have low coverage, particularly forproper nouns, and thus all performance measures are(sometimes substantially) pessimistic.
For English-Arabic, we extract a lexicon from 100k parallel sen-tences of UN parallel corpora by running the HMMintersected alignment model (Liang et al, 2008),adding (s, t) to the lexicon if s was aligned to t atleast three times and more than any other word.Also, as in Koehn and Knight (2002), we makeuse of a seed lexicon, which consists of a small, andperhaps incorrect, set of initial translation pairs.
Weused two methods to derive a seed lexicon.
Thefirst is to use the evaluation lexicon Le and selectthe hundred most common noun word types in thesource corpus which have translations in Le.
Thesecond method is to heuristically induce, where ap-plicable, a seed lexicon using edit distance, as isdone in Koehn and Knight (2002).
Section 6.2 com-pares the performance of these two methods.4.3 EvaluationWe evaluate a proposed lexicon Lp against the eval-uation lexicon Le using the F1 measure in the stan-dard fashion; precision is given by the number ofproposed translations contained in the evaluationlexicon, and recall is given by the fraction of pos-sible translation pairs proposed.12 Since our model12We should note that precision is not penalized for (s, t) ifs does not have a translation in Le, and recall is not penalizedfor failing to recover multiple translations of s.Setting p0.1 p0.25 p0.33 p0.50 Best-F1EDITDIST 58.6 62.6 61.1 ?- 47.4ORTHO 76.0 81.3 80.1 52.3 55.0CONTEXT 91.1 81.3 80.2 65.3 58.0MCCA 87.2 89.7 89.0 89.7 72.0Table 1: Performance of EDITDIST and our model withvarious features sets on EN-ES-W. See section 5.naturally produces lexicons in which each entry isassociated with a weight based on the model, we cangive a full precision/recall curve (see figure 3).
Wesummarize these curves with both the best F1 overall possible thresholds and various precisions px atrecalls x.
All reported numbers exclude evaluationon the seed lexicon entries, regardless of how thoseseeds are derived or whether they are correct.In all experiments, unless noted otherwise, weused a seed of size 100 obtained from Le andconsidered lexicons between the top n = 2, 000most frequent source and target noun word typeswhich were not in the seed lexicon; each systemproposed an already-ranked one-to-one translationlexicon amongst these n words.
Where applica-ble, we compare against the EDITDIST baseline,which solves a maximum bipartite matching prob-lem where edge weights are normalized edit dis-tances.
We will use MCCA (for matching CCA) todenote our model using the optimal feature set (seesection 5.3).5 FeaturesIn this section, we explore feature representations ofword types in our model.
Recall that fS(?)
and fT (?
)map source and target word types to vectors in RdSand RdT , respectively (see section 2).
The featuresused in each representation are defined identicallyand derived only from the appropriate monolingualcorpora.
For a concrete example of a word type tofeature vector mapping, see figure 2.5.1 Orthographic FeaturesFor closely related languages, such as English andSpanish, translation pairs often share many ortho-graphic features.
One direct way to capture ortho-graphic similarity between word pairs is edit dis-tance.
Running EDITDIST (see section 4.3) on EN-775ES-W yielded 61.1 p0.33, but precision quickly de-grades for higher recall levels (see EDITDIST in ta-ble 1).
Nevertheless, when available, orthographicclues are strong indicators of translation pairs.We can represent orthographic features of a wordtype w by assigning a feature to each substring oflength ?
3.
Note that MCCA can learn regular or-thographic correspondences between source and tar-get words, which is something edit distance cannotcapture (see table 5).
Indeed, running our MCCAmodel with only orthographic features on EN-ES-W, labeled ORTHO in table 1, yielded 80.1 p0.33, a31% error-reduction over EDITDIST in p0.33.5.2 Context FeaturesWhile orthographic features are clearly effective forhistorically related language pairs, they are morelimited for other language pairs, where we need toappeal to other clues.
One non-orthographic cluethat word types s and t form a translation pair isthat there is a strong correlation between the sourcewords used with s and the target words used with t.To capture this information, we define context fea-tures for each word type w, consisting of counts ofnouns which occur within a window of size 4 aroundw.
Consider the translation pair (time, tiempo)illustrated in figure 2.
As we become more con-fident about other translation pairs which have ac-tive period and periodico context features, welearn that translation pairs tend to jointly generatethese features, which leads us to believe that timeand tiempo might be generated by a common un-derlying concept vector (see section 2).13Using context features alone on EN-ES-W, ourMCCA model (labeled CONTEXT in table 1) yieldeda 80.2 p0.33.
It is perhaps surprising that context fea-tures alone, without orthographic information, canyield a best-F1comparable to EDITDIST.5.3 Combining FeaturesWe can of course combine context and orthographicfeatures.
Doing so yielded 89.03 p0.33 (labeledMCCA in table 1); this represents a 46.4% error re-duction in p0.33 over the EDITDIST baseline.
For theremainder of this work, we will use MCCA to refer13It is important to emphasize, however, that our currentmodel does not directly relate a word type?s role as a partici-pant in the matching to that word?s role as a context feature.
(a) Corpus VariationSetting p0.1 p0.25 p0.33 p0.50 Best-F1EN-ES-G 75.0 71.2 68.3 ?- 49.0EN-ES-W 87.2 89.7 89.0 89.7 72.0EN-ES-D 91.4 94.3 92.3 89.7 63.7EN-ES-P 97.3 94.8 93.8 92.9 77.0(b) Seed Lexicon VariationCorpus p0.1 p0.25 p0.33 p0.50 Best-F1EDITDIST 58.6 62.6 61.1 ?
47.4MCCA 91.4 94.3 92.3 89.7 63.7MCCA-AUTO 91.2 90.5 91.8 77.5 61.7(c) Language VariationLanguages p0.1 p0.25 p0.33 p0.50 Best-F1EN-ES 91.4 94.3 92.3 89.7 63.7EN-FR 94.5 89.1 88.3 78.6 61.9EN-CH 60.1 39.3 26.8 ?- 30.8EN-AR 70.0 50.0 31.1 ?- 33.1Table 2: (a) varying type of corpora used on system per-formance (section 6.1), (b) using a heuristically chosenseed compared to one taken from the evaluation lexicon(section 6.2), (c) a variety of language pairs (see sec-tion 6.3).to our model using both orthographic and contextfeatures.6 ExperimentsIn this section we examine how system performancevaries when crucial elements are altered.6.1 Corpus VariationThere are many sources from which we can derivemonolingual corpora, and MCCA performance de-pends on the degree of similarity between corpora.We explored the following levels of relationships be-tween corpora, roughly in order of closest to mostdistant:?
Same Sentences: EN-ES-P?
Non-Parallel Similar Content: EN-ES-W?
Distinct Sentences, Same Domain: EN-ES-D?
Unrelated Corpora: EN-ES-GOur results for all conditions are presented in ta-ble 2(a).
The predominant trend is that system per-formance degraded when the corpora diverged in776content, presumably due to context features becom-ing less informative.
However, it is notable that evenin the most extreme case of disjoint corpora fromdifferent time periods and topics (e.g.
EN-ES-G),we are still able to recover lexicons of reasonableaccuracy.6.2 Seed Lexicon VariationAll of our experiments so far have exploited a smallseed lexicon which has been derived from the eval-uation lexicon (see section 4.3).
In order to exploresystem robustness to heuristically chosen seed lexi-cons, we automatically extracted a seed lexicon sim-ilarly to Koehn and Knight (2002): we ran EDIT-DIST on EN-ES-D and took the top 100 most con-fident translation pairs.
Using this automatically de-rived seed lexicon, we ran our system on EN-ES-D as before, evaluating on the top 2,000 noun wordtypes not included in the automatic lexicon.14 Us-ing the automated seed lexicon, and still evaluat-ing against our Wiktionary lexicon, MCCA-AUTOyielded 91.8 p0.33 (see table 2(b)), indicating thatour system can produce lexicons of comparable ac-curacy with a heuristically chosen seed.
We shouldnote that this performance represents no knowledgegiven to the system in the form of gold seed lexiconentries.6.3 Language VariationWe also explored how system performance variesfor language pairs other than English-Spanish.
OnEnglish-French, for the disjoint EN-FR-D corpus(described in section 4.1), MCCA yielded 88.3 p0.33(see table 2(c) for more performance measures).This verified that our model can work for anotherclosely related language-pair on which no model de-velopment was performed.One concern is how our system performs on lan-guage pairs where orthographic features are less ap-plicable.
Results on disjoint English-Chinese andEnglish-Arabic are given as EN-CH-D and EN-ARin table 2(c), both using only context features.
Inthese cases, MCCA yielded much lower precisionsof 26.8 and 31.0 p0.33, respectively.
For both lan-guages, performance degraded compared to EN-ES-14Note that the 2,000 words evaluated here were not identicalto the words tested on when the seed lexicon is derived from theevaluation lexicon.
(a) English-SpanishRank Source Target Correct1.
education educaci?n Y2.
pacto pact Y3.
stability estabilidad Y6.
corruption corrupci?n Y7.
tourism turismo Y9.
organisation organizaci?n Y10.
convenience conveniencia Y11.
syria siria Y12.
cooperation cooperaci?n Y14.
culture cultura Y21.
protocol protocolo Y23.
north norte Y24.
health salud Y25.
action reacci?n N(b) English-FrenchRank Source Target Correct3.
xenophobia x?nophobie Y4.
corruption corruption Y5.
subsidiarity subsidiarit?
Y6.
programme programme-cadre N8.
traceability tra?abilit?
Y(c) English-ChineseRank Source Target Correct1.
prices ?
Y2.
network ?
Y3.
population ?
Y4.
reporter ?
N5.
oil ?
YTable 3: Sample output from our (a) Spanish, (b) French,and (c) Chinese systems.
We present the highest con-fidence system predictions, where the only editing doneis to ignore predictions which consist of identical sourceand target words.D and EN-FR-D, presumably due in part to thelack of orthographic features.
However, MCCA stillachieved surprising precision at lower recall levels.For instance, at p0.1, MCCA yielded 60.1 and 70.0on Chinese and Arabic, respectively.
Figure 3 showsthe highest-confidence outputs in several languages.6.4 Comparison To Previous WorkThere has been previous work in extracting trans-lation pairs from non-parallel corpora (Rapp, 1995;Fung, 1995; Koehn and Knight, 2002), but gener-ally not in as extreme a setting as the one consid-ered here.
Due to unavailability of data and speci-ficity in experimental conditions and evaluations, itis not possible to perform exact comparisons.
How-777(a) Example Non-Cognate Pairshealth saludtraceability rastreabilidadyouth juventudreport informeadvantages ventajas(b) Interesting Incorrect Pairsliberal partidoKirkhope Gorselaction reaccio?nAlbanians Bosniaa.m.
horasNetherlands Bretan?aTable 4: System analysis on EN-ES-W: (a) non-cognatepairs proposed by our system, (b) hand-selected represen-tative errors.
(a) Orthographic FeatureSource Feat.
Closest Target Feats.
Example Translation#st #es, est (statue, estatua)ty# ad#, d# (felicity, felicidad)ogy g?
?a, g??
(geology, geolog?
?a)(b) Context FeatureSource Feat.
Closest Context Featuresparty partido, izquierdademocrat socialistas, demo?cratasbeijing pek?
?n, kiotoTable 5: Hand selected examples of source and target fea-tures which are close in canonical space: (a) orthographicfeature correspondences, (b) context features.ever, we attempted to run an experiment as similaras possible in setup to Koehn and Knight (2002), us-ing English Gigaword and German Europarl.
In thissetting, our MCCA system yielded 61.7% accuracyon the 186 most confident predictions compared to39% reported in Koehn and Knight (2002).7 AnalysisWe have presented a novel generative model forbilingual lexicon induction and presented results un-der a variety of data conditions (section 6.1) and lan-guages (section 6.3) showing that our system canproduce accurate lexicons even in highly adverseconditions.
In this section, we broadly characterizeand analyze the behavior of our system.We manually examined the top 100 errors in theEnglish-Spanish lexicon produced by our systemon EN-ES-W. Of the top 100 errors: 21 were cor-rect translations not contained in the Wiktionarylexicon (e.g.
pintura to painting), 4 werepurely morphological errors (e.g.
airport toaeropuertos), 30 were semantically related (e.g.basketball to be?isbol), 15 were words withstrong orthographic similarities (e.g.
coast tocostas), and 30 were difficult to categorize andfell into none of these categories.
Since many ofour ?errors?
actually represent valid translation pairsnot contained in our extracted dictionary, we sup-plemented our evaluation lexicon with one automat-ically derived from 100k sentences of parallel Eu-roparl data.
We ran the intersected HMM word-alignment model (Liang et al, 2008) and added(s, t) to the lexicon if s was aligned to t at leastthree times and more than any other word.
Evaluat-ing against the union of these lexicons yielded 98.0p0.33, a significant improvement over the 92.3 us-ing only the Wiktionary lexicon.
Of the true errors,the most common arose from semantically relatedwords which had strong context feature correlations(see table 4(b)).We also explored the relationships our modellearns between features of different languages.
Weprojected each source and target feature into theshared canonical space, and for each projectedsource feature we examined the closest projectedtarget features.
In table 5(a), we present some ofthe orthographic feature relationships learned by oursystem.
Many of these relationships correspond tophonological and morphological regularities such asthe English suffix ing mapping to the Spanish suf-fix g??a.
In table 5(b), we present context featurecorrespondences.
Here, the broad trend is for wordswhich are either translations or semantically relatedacross languages to be close in canonical space.8 ConclusionWe have presented a generative model for bilinguallexicon induction based on probabilistic CCA.
Ourexperiments show that high-precision translationscan be mined without any access to parallel corpora.It remains to be seen how such lexicons can be bestutilized, but they invite new approaches to the statis-tical translation of resource-poor languages.778ReferencesFrancis R. Bach and Michael I. Jordan.
2006.
A proba-bilistic interpretation of canonical correlation analysis.Technical report, University of California, Berkeley.Peter F. Brown, Stephen Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1994.
The mathematicof statistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004.Automatic tagging of arabic text: From raw text tobase phrase chunks.
In HLT-NAACL.Pascale Fung.
1995.
Compiling bilingual lexicon entriesfrom a non-parallel english-chinese corpus.
In ThirdAnnual Workshop on Very Large Corpora.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inference and trainingof context-rich syntactic translation models.
InCOLING-ACL.David R. Hardoon, Sandor Szedmak, and John Shawe-Taylor.
2003.
Canonical correlation analysis anoverview with application to learning methods.
Tech-nical Report CSD-TR-03-02, Royal Holloway Univer-sity of London.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In Pro-ceedings of ACL Workshop on Unsupervised LexicalAcquisition.P.
Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In Proceedings of AMTA 2004.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In MT Summit.H.
W. Kuhn.
1955.
The Hungarian method for the as-signment problem.
Naval Research Logistic Quar-terly.P.
Liang, D. Klein, and M. I. Jordan.
2008.
Agreement-based learning.
In NIPS.Reinhard Rapp.
1995.
Identifying word translation innon-parallel texts.
In ACL.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In International Conferenceon New Methods in Language Processing.N.
Smith and J. Eisner.
2006.
Annealing structural biasin multilingual weighted grammar induction.
In ACL.L.
G. Valiant.
1979.
The complexity of computingthe permanent.
Theoretical Computer Science, 8:189?201.D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In ACL.779
