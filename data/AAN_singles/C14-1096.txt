Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1015?1024, Dublin, Ireland, August 23-29 2014.Collecting Bilingual Audio in Remote Indigenous CommunitiesSteven BirdDept of Computing andInformation Systems,University of Melbourne;Linguistic Data Consortium,University of PennsylvaniaLauren GawneDepartment of Linguisticsand Multilingual Studies,Nanyang TechnologicalUniversity, SingaporeKatie GelbartSchool of Orientaland African Studies,University of LondonIsaac McAlisterDepartment of Languages,Literatures, and Cultures,University of Massachusetts,AmherstAbstractMost of the world?s languages are under-resourced, and most under-resourced languages lacka writing system and literary tradition.
As these languages fall out of use, we lose importantsources of data that contribute to our understanding of human language.
The first, urgent step isto collect and orally translate a large quantity of spoken language.
This can be digitally archivedand later transcribed, annotated, and subjected to the full range of speech and language process-ing tasks, at any time in future.
We have been investigating a mobile application for recordingand translating unwritten languages.
We visited indigenous communities in Brazil and Nepal andtaught people to use smartphones for recording spoken language and for orally interpreting it intothe national language, and collected bilingual phrase-aligned speech recordings.
In spite of sev-eral technical and social issues, we found that the technology enabled an effective workflow forspeech data collection.
Based on this experience, we argue that the use of special-purpose soft-ware on smartphones is an effective and scalable method for large-scale collection of bilingualaudio, and ultimately bilingual text, for languages spoken in remote indigenous communities.1 IntroductionPast the top one to three hundred economically significant languages, there are few prospects for re-sourcing the production of annotated corpora.
Advances in natural language processing have relied onsuch corpora ?
including treebanks and wordnets ?
though they are expensive to produce and depend onsubstantial prior scholarship on the language.
An alternative is to collect bilingual aligned text, relatinga low-resource language to a high-resource language, and then infer lexical and syntactic informationfrom the high-resource language via alignments (Abney and Bird, 2010; Baldwin et al., 2010; Palmer etal., 2010; Das and Petrov, 2011).This approach only works for written languages.
Over half the world?s languages lack a literarytradition.
In some cases they have a writing system, but it is not in regular use and so these languagesremain effectively unwritten.
Collecting data for unwritten languages necessarily involves speech.w1w2w3w4w5w6w7w8w9w10w11w12f1f2f3f4f5f6f7f8f9f10f11f12f13f14f15f16f17f18f19f20f21f22f23f24f25f26f27f1f2f5f6f7f8w3w2f9f10f11f15f16f22f23f12f13f14w1w6w5f17f18f19f20f21w8w7w9w10f24f25w12w11w'1w'2w'3w'4w'5w'6w'7w'8w'8w'10w'11w'12f26f27f3f4w4Figure 1: The Vision: phrase-aligned bilingual audio from an unwritten language to a language of widercommunication, along with extracted acoustic features and crowdsourced transcription (left); interlinearglossed text with word segmentation, word-level glosses, and sentence-level translations (right).This work is licensed under a Creative Commons Attribution 4.0 International Licence.1015While the physical isolation of these languages presents a logistical challenge, it is still possible tocollect hundreds of hours of speech using mobile devices (de Vries et al., 2014).
Furthermore, thereare promising signs that natural language processing methods and speech processing methods can beintegrated (Zhang et al., 2004; Dredze et al., 2010; Vu et al., 2011; Siniscalchi et al., 2012; Lee andGlass, 2012).
Thus, the challenge is to collect substantial quantities of bilingual aligned audio, transcribethe translations, extract phonetic features from the source language and, ultimately, produce bilingualaligned text (see Figure 1).We have chosen to focus on endangered languages because of the interesting and difficult challengesthat are faced in collecting data.
However, the resource problem exists even for vital languages havinglarge speaker populations.
For example, Shanghainese (Wu) is spoken by 77 million people in China,but is almost never written down because written Chinese is based on Mandarin; Oromo is spoken by17 million people in Ethiopia, but few of its speakers know how to write it.
Such languages are collec-tively spoken by billions, yet remain seriously under-resourced.
Thus, while our focus is on endangeredlanguages, the approach applies to under-resourced languages in general.Several other promising approaches to the problems raised by endangered languages are being activelypursued in computational linguistics, however they typically focus on written language with annotations,often with the goal of making optimal use of human expertise (Probst et al., 2002; Levin et al., 2006;Clark et al., 2008; Palmer et al., 2010; Bender et al., 2012; Beale, 2012; Bender et al., 2013).
Theresearch reported here is unique in its focus on securing spoken language data in a form and on a scalethat will be usable even once the languages in question are no longer spoken.This paper explores ways that networked smartphones can be used for collecting bilingual alignedaudio.
We have used a prototype Android application for collecting audio and phrase-aligned translations(or consecutive interpretations).
We took a set of phones to villages in Brazil and Nepal, and workedwith languages Temb?e, Nhengatu and Kagate.
We visited at the invitation of the local communities andcollaborated closely with them in each stage of the process, including setting the goals and agreeingon the form of dissemination, cf.
(Rice, 2011).
We compiled small collections of recorded texts andtranslations in each language.We describe and evaluate this novel resource-creation activity, and argue that it can be used effectivelyfor large-scale collection of bilingual aligned audio.
This paper is organised as follows.
In section 2,we give an overview of the mobile software.
The next three sections report the activities in the threecommunities.
We reflect on the work in section 6.2 Mobile applications for recording and translating endangered languagesSmartphones are proliferating: they are part of the vanguard of technologies that make it into manyisolated communities.
Even in the most remote villages, many people own a mobile phone, keep it ontheir person, and are able to get it charged when mains electricity is unreliable or non-existent.
Thesephones can be inexpensive (US$100-200) and some models have sufficient audio quality to be useful forspeech data collection.
With suitable software it is possible to collect metadata along with recordings,including location, date, the identity of the speaker, and possibly some information about the contentsuch as the title and genre.
The networking capability of a smartphone facilitates wireless sharing andbackup.The speech collection task calls for a variety of individual contributions.
The best speakers of thelanguage are not necessarily the best translators; they may be monolingual.
Similarly, the best translatorsmay not be the best transcribers; they may be illiterate.
Thus, for reasons of skill, not just scale, we needto involve a whole team of people in the data collection activity.
In the medium term, we assume that thiswork would take place under the supervision of a linguist who provides hardware and training, and whomonitors the balance of the collection, including coverage of various discourse types, getting everythingtranslated, and so forth).Aikuma is open source software that supports recording of speech directly to phone storage (Hankeand Bird, 2013; Bird et al., 2014).
Recordings are synchronized with other phones that are connectedto the same WiFi LAN, so that any user can listen to recordings made on any phone in the same local1016network.
A user can ?like?
a recording to improve its overall ranking.
A user can also provide a phrase-by-phrase spoken translation of the recording, using the interface shown in Figure 2.
This functionalityis based on the protocol of ?Basic Oral Language Documentation?
(Reiman, 2010; Bird, 2010).
(a) Recording a Temb?e narrative (b) Translating Temb?e into PortugueseFigure 2: Recording and translating using the Aikuma Android appUsers press and hold the left play button to hear the next segment of audio source.
They can pressit multiple times to hear the same segment over again.
Once ready, they press the right record buttonand speak a translation of the source.
This process continues until the source has been fully translated.It generates a second audio file that is time-aligned with the source (cf Figure 1).
The app supportsplayback of the source, the translation, and the source with interleaved translation.Aikuma maintains a database of speakers and synchronizes this to the other phones along with therecordings and titles, and keeps track of which speaker provided which recording.
In this way, basicmetadata resides with the recordings, and recordings are effectively backed up several times over.
If thecontents of one phone are periodically archived, then we have a permanent copy of all the recordings andmetadata from all of the phones.We used HTC Desire C and HTC Desire 200 phones which cost US$160 each.
We chose these phonesfor their support of Android 4 and their recording quality.
Unlike a professional audio set-up, mobilephone audio recording includes built-in noise suppression that is optimised for near-field voice sourcesand attenuates background noise.
The software stores audio in uncompressed 16kHz 16-bit mono.
Thequality of the audio from these phones is more than sufficient to support phonetic analysis (Bettinson,2013).
We expect these materials to be considered of archival quality in those cases where the originalrecording environment was quiet and where the content itself has linguistic and cultural value.Another advantage of smartphones compared with professional recording equipment is ease ofrecharging.
Many remote indigenous communities without mains electricity are still able to keep phonescharged with the help of generators and car batteries.
By choosing to use mobile phones, we can piggy-back on the existing infrastructure.The cost and usability of smartphones relative to professional recording equipment makes it easyto consider giving them out to people to make recordings in their own time.
Apart from significantlyincreasing the amount of recorded and translated material that a linguist can collect, this gives speakersdirect control over the content and context of the recordings, and it may lead to the collection of morenaturalistic materials.
In some cases, speakers already own an Android phone and can simply install thesoftware and get started.In the following three sections we report on our experience of using these phones with indigenouscommunities in the Amazon and the Himalayas.3 Temb?e, Par?a State, BrazilThe Temb?e language is spoken by approximately 150 people amongst a larger community numberingabout 1,500, in a group of villages in the Reserva Alto Rio Guam in the vicinity of Paragominas in thePar?a state of Brazil.
Bird, Gelbart, and McAlister spent five days in the village of Cajueiro (Akazu?yw),1017the gateway to several other Temb?e villages that can only be accessed by river.
Like many Indian villages,Cajueiro is laid out around a soccer field.
The village was connected to the electricity grid ten years ago.We recorded 14 texts from 8 speakers, mostly personal narratives but also a song and a dialogue.
Mosttexts were orally translated; some were translated twice.
Of two hours of source audio, 35 minutes wereorally translated, producing an extra 25 minutes of audio.Our visit to Cajueiro is mostly interesting for the great variety of unanticipated challenges, and howwe were still able to use the platform to collect data.Previous contact with the Temb?e community was mediated by staff at the Goeldi Museum in Bel?em.The Temb?e community had been discussing prospects for installing an antenna in Cajueiro to enablean Internet connection.
On arrival, the chief asked about our plans to set up Internet access, and weexplained that we were not able to do this because there was no signal for 100km.
After this, the chieflost interest in our activities and we were not able to hold a village meeting as we had hoped, in orderto discuss our work, invite participation, and demonstrate the use of the technology for recording andtranslation.
Instead, we could only work one-on-one.Our first 24 hours in the village was spent on video documentation of a coming-of-age ceremony.
Moreelaborate versions of this ceremony had been filmed in the past, so there was minimal documentary valuein recording this event.
However, it was the basis for our invitation to the village, cf.
(Crowley, 2007,80), and it enabled us to meet the whole community and to observe the limited social interaction, almostexclusively conducted in Portuguese.In the following days, we went around the village showing the app to people, explaining our work,playing existing recordings in Temb?e and other languages, and trying to find fluent speakers who weremotivated to preserve Temb?e linguistic heritage.
Few people claimed to be fluent and we only found sixwho were willing to be recorded, all men.
No women would consent to being recorded until a Temb?eman, trained as a computer technician, learnt how to use the app and took a handset and found two femalespeakers and recorded them.
They were in their thirties, less confident with the language, and could onlyread haltingly from a small storybook.
For the fluent speakers we were able to find, the documentaryactivity proceeded naturally; they easily recounted histories and gave phrase-by-phrase translations.
Weprepared a selection from our recordings and made audio CDs to give away for people to play on theirpersonal stereos.We experienced a variety of technical difficulties with the smartphones, none of which had been appar-ent during lab testing.
The most obvious were due to people?s unfamiliarity with smartphones.
Signingin required entering the participant?s name using a touchscreen keyboard, then selecting an ISO 639 lan-guage code via a search interface, then taking a photo using the phone.
The photo could not be takeneasily by the participant as the phones lacked a front-facing camera.
Consequently, we generally tookcare of these tasks on behalf of speakers.
Similarly, upon completion of a recording, the participant wasprompted to enter a name for the recording, and we would reclaim the phone and enter a title after a briefdiscussion with the participant about a suitable choice.Further problems concerned the translation task.
A couple of participants began to give a Portugueseparaphrase immediately on finishing a story.
Despite the obvious value of capturing an immediate para-phrase from the same speaker, the software was not designed for this and we had no way to capturethe paraphrase as a separate audio file and link it back to the original.
The thumb-controlled interface(Figure 2b) was also slightly problematic.
Often a speaker would still be holding down the play buttonwith his left thumb at the moment he went to press the record button with his right thumb.
Sometimes,speakers would begin to speak and then notice that playback was still continuing, and only then releasethe play button.
By the time they had pressed the record button again, they had already spoken a word ortwo, and this speech was not captured by the app.
This problem happened often enough to interfere withthe flow of the translation task.
Possible solutions are to have the controls operated by a single thumb,or else to change the behavior of the app so that the most recent thumb gesture overrides a existing but-ton press.
Several other interactional issues with the software were identified and resolved with similarminor changes to behavior.A final set of issues concerned dissemination.
Many Indian villages are now equipped with computer1018rooms and have desktop machines with CD burners, though mains electricity may be intermittent, or elsedepend on a generator.
We were able to transfer files from the phones to a local machine using a USBconnection, though it was a slow process to identify the recordings of interest to the participants and tocompile an audio CD.
Instead, we realised that any user of a phone should be able to export selectedrecordings to a local folder that could be burnt to CD.The key problem for us, however, was lack of participation.
The main reason for this, we believe, wasthe limited local interest in the Temb?e language.
A secondary factor was the misunderstanding about ourcontribution (?bringing the Internet?)
and the fact that the product, a CD of stories, was not necessarilysomething that the community wanted.4 Nhengatu, Amazonas State, BrazilThe Nhengatu language is a creole spoken by 10,000 people across a wide area, including the village ofTerra Preta, 50km NW of Manaus.
Nhengatu used to be the language of communication amongst Indiansfrom different tribes along the Rio Negro, and between Indians and non-Indians in the Brazilian Amazon.Although most of the inhabitants of Terra Preta are ethnically Bar?e, the only indigenous language spokenin the village is Nhengatu.
Younger generations are monolingual in Portuguese.
Unusually, there arealso some non-Indians living in the village.
The villagers were open to receiving us, partly due to theirproximity to Manaus and the fact they were accustomed to meeting tourists and showing white peoplearound and selling handcrafts.
Compared with Cajueiro, there was a stronger sense of community inTerra Preta: on weekends they would have breakfast together in a communal meeting place, and agreeon community service tasks for the weekend.We made a preliminary visit and presented our work at a public meeting.
We called for a volunteer totell a story to the group and then invited another volunteer to provide an oral translation.
Both individualsdid a perfect job even though neither one had used the software before.
One of them, a former villagechief, addressed the group and explained the significance of our work.
He then asked if we would helpin the preparation of a DVD.
Since we did not have the necessary equipment, we offered to create abilingual storybook instead.
They agreed, and said this could be used in their local school.
We hadalready intended to propose this as our contribution to the community after our experience with Temb?e,where most people did not grasp the value of us only leaving audio recordings.
A booklet would be anatural extension to our documentary goals, and it offered to draw in the whole community including thechildren who could provide illustrations.Three weeks later, once the necessary approvals had been obtained, we arrived in Terra Preta andlaunched our activities with another public meeting.
At this meeting, and again at public meetings onthe following two mornings, we invited anyone who was interested to take a phone and record a story.Sometimes a storyteller held a phone while addressing a small group (often involving children), andrecounted a folktale.After three days, we recorded 35 texts from nine speakers (including two children), mostly folkloreand personal narratives.
Most texts were orally translated.
Of 2.5 hours of source audio, approximatelyone hour of recordings were orally translated (some two or more times), producing an extra two hours ofaudio.
Seven short texts by children or directed at children were delivered in Portuguese, and we did nottranslate these back into Nhengatu.During the second half of the visit, four men who were literate in Nhengatu joined us in the task oftranscribing the stories, focussing on those that would be most interesting for inclusion in the storybook.They worked in parallel, playing back the recordings on the phones, transcribing them on paper, thenbringing the sheets back to be typed and proof-read.
This work was arduous, continuing through the heatof the day, but they were keen to process as many stories as possible.Two weeks after our visit, we published a small booklet of stories and translations and sent copiesback to the village, and posted a digital copy in the Internet Archive (Bird et al., 2013).We encountered some additional technical difficulties that we had not experienced in Cajueiro.
First,a bug in the recording app which appeared on the last day caused one recording to overrun and produceda three hour (350MB) file.
After this, WiFi synchronisation was too slow to be effective, and it was1019necessary to perform synchronisation manually, copying the files from all phones onto a laptop, thencopying the collection back onto each phone.
Second, the presence of an audience for some storiesencouraged the storyteller to speak loudly.
Since speakers were holding the phone close to their mouths,this resulted in clipped audio.
Third, at the height of our intensive transcription and translation process,we needed to keep track of the activities of several participants, and created a checklist.
Finally, therewas an issue with the power supply.
Unlike Cajueiro, Terra Preta is not attached to the electricity grid, butit has a generator which is turned on for four hours every evening, and sometimes during the morningsfor brief periods.
We could use this to keep the phones charged and to power the router for long enoughto synchronise the phones a couple of times each day.
But the village became very noisy when powerwas available, thanks to an abundance of stereo systems and power tools, and this made it difficult to getgood quality recordings during these times.Figure 3: Transcribing a spoken translationIn spite of these problems, there were some suc-cesses.
The most notable was that participants tookno more than a minute to become adept with therecording functionality and the thumb-controlled oraltranslation functionality (Figure 2b).
Second, theavailability of multiple networked recording devicesmeant that we could collect materials in parallel.
Forexample, we could discuss a story we wanted torecord and then send several people off at the sametime to record their own versions.
Then they couldsynchronise their recordings and hear what each othersaid.
Finally, automatic synchronisation greatly facil-itated concurrent transcription activities.
We couldassign people to transcribe or translate a particularsource recording without having to keep track of device it had been recorded with: it was already avail-able on all of the phones.5 Kagate, Ramechhap district, NepalA third field test with a later version of the app was undertaken in Nepal.
Kagate, known to its speakersas Syuba, is a Tibeto-Burman language spoken by around 1,500 people in the Ramechhap district, eastof Kathmandu.
Handsets with the Aikuma app were taken by Gawne and were deployed in parallel, inthe context of a project to video record traditional folk narratives and history.
Twelve original recordingswere made, totalling 80 minutes.
Four of these recordings were translated into Nepali, and two record-ings were also carefully ?respoken?
to aid later written transcription (Woodbury, 2003).
Although therecordings represent a more modest total than at other fieldsites, this field test demonstrates that Aikumacan operate in conjunction with, and to the benefit of, more traditional field methods.
A number ofchallenges were addressed.The first challenge was the lack of mains electricity, with the village only having a number of smallsolar panels for charging mobile phones and running small lights.
Much like at the Nhengatu site, mobilephones enabled work to proceed in the absence of mains electricity.
Indeed, this was greatly beneficialbecause it meant that more recordings could be made without rapidly depleting the video camera battery,which required charging at a village a one hour walk away.
The lack of proximal mains electricity meantthat it was not possible to run the router and synchronise the data on each phone.
As a result of this (andparticipation issues discussed below) the researcher only kept two devices in use at a time, making iteasier to keep track of what was on each device.
This field trip demonstrated that even without the datasynchronization feature Aikuma is still a useful fieldwork tool.The second challenge was fostering participation.
As a number of anthropologists working in re-lated communities have observed, the centre of village life for Kagate people is the household (F?urer-Haimendorf, 1964; Desjarlais, 1992).
Relationships beyond this are negotiated through extended famil-ial relations of reciprocity.
Therefore, there were no opportunities to arrange community meetings as in1020Terra Preta, or even to find an individual who was an officially designated leader.
As a result, much timewas spent engaging a small number of enthusiastic participants and working with them to engage othermembers of the community through existing social networks.
The benefit of the mobile devices was thatthey could be carried about and then demonstrated to people during a lull in other activities.
Becauseof this portability and ease of demonstration, the mobile phones became a key part of negotiations withall participants, even those who the community members wanted to video record.
Having the handsetsmeant that we could immediately show people the outcome of a recording session.
Sometimes, evenafter this demonstration, people were reluctant to participate in recording with video cameras or phones.We took this as a positive sign that participants had a better level of informed consent with which tomake this choice than they otherwise would have.
Many community members were reluctant to takethe phones, as even basic smartphones that we chose for their affordability are an expensive commodityand out of the price bracket of many.
A small number of people became comfortable enough to take thephones away to work with, but would return them immediately after a specific task had been completed.With a longer period of presence in the village it is likely more people would become more comfortablewith the process.The final issue, like at other sites, concerned the process of saving recordings once they had beenmade.
Processes that are taken for granted with some audiences, like naming a recording, presume agreat deal of cultural knowledge about iconography, the layout of keyboards, and spelling conventions.It was only on the final day that one of the more frequent participants saved a file without assistance.Fortunately, an import feature had been built into the app, which meant that when participants returnedwith files that they had not managed to save they could still be loaded into the list.
While some of theissues faced can be overcome through further refining the design, others are useful educational tools tohelp familiarize participants with key features of digital literacy.Throughout the above discussion we have touched on some benefits to using Aikuma at this fieldsite.
There are some other advantages that are also worth noting.
The first is that the portability of thehandsets meant that there was a wider range of participants recorded.
The limited electricity availablefor the parallel video documentation, and community attitudes about who was a suitable participant inthat work, meant that only a small section of the community (mostly older males) would have beendocumented.
The lower formality of using the phones, compared with a bulky video camera, meant thatpeople also felt quite relaxed, often telling stories with an audience present.The use of phones also meant that there were fewer missed opportunities for recording.
One eveningwe used the phones when the light was too poor for video.
Another morning when the researcher wasunwell, she gave one of the handsets to a member of the community who recorded some traditional storieswith an older man who had not been able to remember them the day before.
On yet another occasion, aman took one of the handsets away and recorded a translation while the researcher was filming a videowith another participant.
Although the linguist was still needed for the saving of recordings, peoplebecame less dependent on her presence to do their own documentation work.6 DiscussionReflecting on our experience in the Temb?e, Nhengatu, and Kagate communities, further issues warrantdiscussion.The mobile device was a major attraction.
People gathered round to see how it was used, then ex-plained it to others in their native language.
They brought elders to see the work, and encouraged themto tell stories.
This impact convinced us that the mobile phone is an effective platform for engagingwith participants and helping them quickly grasp the collection and dissemination aspects of languagedocumentation work, cf.
(Rice, 2011).
Note that the phones were not equipped with SIM cards, and sothere was no distraction of them being used for voice calls or for downloading extraneous software.However, the device was also an obstacle.
Although some people had used smartphones, few had ex-perienced touchscreens.
Creating a user profile required entering a name using the touchscreen keyboard.It seemed like overkill to train individuals to use a keyboard and to go through a process they would onlyperform once.
Moreover, the language selection process displayed a searchable list of 7,000 languages,1021and it would have been easier to have a small selection of local languages to choose from.
In Temb?e,the man who was trained as a computer technician learned to create user profiles for other people.
Bythe time of the Kagate experiment, we added support for default languages, and set these as Kagate andNepali.
This simplified the task, though it also meant that we did not capture information about people?scompetencies in other languages.
These issues with the device only occurred at the outset, and highlightthe need to simplify the metadata collection process.
The impact of the problem would be reduced withimproved software design.The device helped with the process of obtaining informed consent.
We played an existing recording,either one collected during an earlier phase of documenting the language, or one from another endangeredor extinct language.
In this way we communicated the idea that language recordings can be preservedand transmitted over distance and time, even once the language is no longer spoken.
We also asked whatpeople thought about the idea of others hearing their language, and they were generally enthusiastic.In the case of a further Brazilian language, one community leader asked for substantial donations ofhardware and another cited intellectual property concerns, and so we did not record this language.
Arelated open issue concerns the process for documenting informed consent, particularly when workingwith monolingual speakers.Most of the collected material consisted of personal narratives, folklore, and a limited amount ofsinging.
Other discourse types that we did not collect include dialogue, oratory, and procedural discourse,cf.
(Johnson and Aristar Dry, 2002).
On many occasions, people listened to a traditional narrative andthen asked to recount their own version.
Consequently, we see the possibility for achieving substantiallexical overlap in recordings by different speakers, which could help with speech modelling, dialectidentification, and lexicon production.7 ConclusionsWe have investigated the use of Aikuma, an Android app designed for recording and translating unwrittenlanguages.
We taught members of indigenous communities in Brazil and Nepal to use smartphones forrecording spoken language and for orally interpreting it into the national language, and we collecteda sample of bilingual phrase-aligned speech in the languages.
We collected approximately 8.5 hours ofaudio, approximately 100,000 words, and in the process, we demonstrated that the platform is an effectiveway to engage indigenous communities in the task of building phrase-aligned bilingual speech corpora.The built-in networking capability of the phone was used to good effect in Nhengatu for leveraging thecontribution of multiple members of the community who have differing linguistic aptitudes.We identified several areas for additional functionality: support for adding a paraphrase as soon as astory has been told; support for exporting playlists to CD; a checklist that shows which recordings havebeen translated; permitting handwritten transcriptions to be photographed and linked back to the originalaudio; and redesigning the interface to remove some remaining English prompts and confusing icons.These and other enhancements are being developed in our open source project.1Above all, we have found that this approach to linguistic data collection greatly facilitates work onindigenous languages that are falling out of use.
It bypasses the need for expensive equipment by pig-gybacking on the burgeoning adoption of mobile phones and wireless broadband networks.
We areoptimistic about the prospects of using this approach to collect substantial new corpora for supportinglinguistic research and language technology development, even for some of the most isolated linguisticcommunities in the world.AcknowledgmentsThis research was supported by NSF Award 1160639 Language Preservation 2.0: Crowdsourcing OralLanguage Documentation using Mobile Devices (Bird and Liberman), ARC Award 120101712 Lan-guage Engineering in the Field (Bird), and Firebird Foundation project Documenting the TraditionalSongs and Stories in Kagate, a language of Nepal (Gawne).
Bird, Gelbart, and McAlister are grateful toDr Denny Moore and the Goeldi Museum (Bel?em) for facilitating their work in Brazil.1https://github.com/aikuma1022ReferencesSteven Abney and Steven Bird.
2010.
The Human Language Project: building a universal corpus of the world?slanguages.
In Proceedings of the 48th Meeting of the Association for Computational Linguistics, pages 88?97.Association for Computational Linguistics.Timothy Baldwin, Jonathan Pool, and Susan Colowick.
2010.
PanLex and LEXTRACT: Translating all words ofall languages of the world.
In Proceedings of the 23rd International Conference on Computational Linguistics,pages 37?40, Beijing, China.Stephen Beale.
2012.
Documenting endangered languages with Linguist?s Assistant.
Language Documentationand Conservation, 6:104?134.Emily Bender, Robert Schikowski, and Balthasar Bickel.
2012.
Deriving a lexicon for a precision grammarfrom language documentation resources: A case study of Chintang.
In Proceedings of the 25th InternationalConference on Computational Linguistics, pages 247?262.Emily Bender, Michael Wayne Goodman, Joshua Crowgey, and Fei Xia.
2013.
Towards creating precisiongrammars from interlinear glossed text: Inferring large-scale typological properties.
In Proceedings of the7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 74?83.Association for Computational Linguistics.Mat Bettinson.
2013.
The effect of respeaking on transcription accuracy.
Honours Thesis, Dept of Linguistics,University of Melbourne.Steven Bird, Katie Gelbart, and Isaac McAlister, editors.
2013.
F?abulas de Terra Preta.
Internet Archive.Steven Bird, Florian R. Hanke, Oliver Adams, and Haejoong Lee.
2014.
Aikuma: A mobile app for collaborativelanguage documentation.
In Proceedings of the Workshop on the Use of Computational Methods in the Study ofEndangered Languages.
Association for Computational Linguistics.Steven Bird.
2010.
A scalable method for preserving oral literature from small languages.
In Proceedings of the12th International Conference on Asia-Pacific Digital Libraries, pages 5?14.Jonathan Clark, Robert Frederking, and Lori Levin.
2008.
Toward active learning in data selection: Automaticdiscovery of language features during elicitation.
In Proceedings of the Sixth International Conference onLanguage Resources and Evaluation.Terry Crowley.
2007.
Field Linguistics: A Beginner?s Guide.
Oxford University Press.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projections.In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human LanguageTechnologies, pages 600?609.
Association for Computational Linguistics.Nic de Vries, Marelie Davel, Jaco Badenhorst, Willem Basson, Febe de Wet, Etienne Barnard, and Alta de Waal.2014.
A smartphone-based ASR data collection tool for under-resourced languages.
Speech Communication,56:119?131.Robert R. Desjarlais.
1992.
Body and emotion: the aesthetics of illness and healing in the Nepal Himalayas.Philadelphia: University of Pennsylvania Press.Mark Dredze, Aren Jansen, Glen Coppersmith, and Ken Church.
2010.
NLP on spoken documents without ASR.In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 460?470.Association for Computational Linguistics.Christoph von F?urer-Haimendorf.
1964.
The Sherpas of Nepal: Buddhist highlanders.
London: John Murray.Florian R. Hanke and Steven Bird.
2013.
Large-scale text collection for unwritten languages.
In Proceedings ofthe 6th International Joint Conference on Natural Language Processing, pages 1134?1138.
Asian Federationof Natural Language Processing.Heidi Johnson and Helen Aristar Dry.
2002.
OLAC discourse type vocabulary.
http://www.language-archives.org/REC/discourse.html.Chia-ying Lee and James Glass.
2012.
A nonparametric bayesian approach to acoustic model discovery.
In Pro-ceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 40?49.
Associationfor Computational Linguistics.Lori Levin, Jeff Good, Alison Alvarez, and Robert Frederking.
2006.
Parallel reverse treebanks for the discoveryof morpho-syntactic markings.
In Jan Haji?c and Joakim Nivre, editors, Proceedings of the Fifth Workshop onTreebanks and Linguistic Theories, pages 103?114.Alexis Palmer, Taesun Moon, Jason Baldridge, Katrin Erk, Eric Campbell, and Telma Can.
2010.
Computationalstrategies for reducing annotation effort in language documentation.
Linguistic Issues in Language Technology,3:1?42.1023Katharina Probst, Lori Levin, Erik Peterson, Alon Lavie, and Jaime Carbonell.
2002.
MT for resource-poorlanguages using elicitation-based learning of syntactic transfer rules.
Machine Translation, 17(4):225?270.Will Reiman.
2010.
Basic oral language documentation.
Language Documentation and Conservation, 4:254?268.Keren Rice.
2011.
Documentary linguistics and community relations.
Language Documentation and Conserva-tion, 5:187?207.S.M.
Siniscalchi, Dau-Cheng Lyu, T. Svendsen, and Chin-Hui Lee.
2012.
Experiments on cross-language at-tribute detection and phone recognition with minimal target-specific training data.
IEEE Transactions on Audio,Speech, and Language Processing, 20:875?887.Ngoc Thang Vu, Franziska Kraus, and Tanja Schultz.
2011.
Rapid building of an ASR system for under-resourcedlanguages based on multilingual unsupervised training.
In Interspeech, pages 3145?3148.Anthony C. Woodbury.
2003.
Defining documentary linguistics.
In Peter Austin, editor, Language Documentationand Description, volume 1, pages 35?51.
London: SOAS.Ruiqiang Zhang, Genichiro Kikui, Hirofumi Yamamoto, Taro Watanabe, Frank Soong, and Wai Kit Lo.
2004.A unified approach in speech-to-speech translation: integrating features of speech recognition and machinetranslation.
In Proceedings of the 20th International Conference on Computational Linguistics, pages 1168?1174.1024
