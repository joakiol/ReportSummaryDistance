Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 155?159,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsMorphoLogic?s submission for the WMT 2009 Shared TaskAttila Nov?kMorphoLogicKardhegy utca 5, Budapest 1116, Hungarynovak@morphologic.huAbstractIn this article, we describe the machinetranslation systems we used to createMorphoLogic?s submissions to theWMT09 shared Hungarian to Englishand English to Hungarian shared transla-tion tasks.
We used our rule basedMetaMorpho system to generate our pri-mary submission.
In addition, we createda hybrid system where the Moses de-coder is used to rank translations or as-semble partial translations created byMetaMorpho.
Our third system was apurely statistical morpheme based systemfor the Hungarian to English task.1 IntroductionThis year, MorphoLogic submitted translationsfor the WMT09 shared Hungarian to English andEnglish to Hungarian translation tasks.
Our pri-mary submissions were translated by MetaMor-pho, a purely rule based machine translation sys-tem (Pr?sz?ky and Tihanyi, 2002).
Since lastyear?s workshop we improved the Hungarian toEnglish grammar of MetaMorpho by makingmore efficient the handling of certain structuralambiguities and making the way the system han-dles long sentences more robust.The way Metamorpho selects the translation tooutput is not optimal whether or not a full parsefor the source sentence could be obtained by itsparser.1 Thus we decided to experiment with ahybrid system where translations and partialtranslations produced by MetaMorpho are rankedor assembled by the Moses decoder (Koehn etal., 2007) using a target language model.1 In the first case, simply the first translation is outputinstead of considering all possible translations andselecting the best, while in the second case, the algo-rithm that combines the partial translations does notcheck how well the target language side of the piecesfit together.In addition, we created a purely statisticalmorpheme based system (also using Moses) forthe Hungarian to English task.
However, resultsobtained with the latter setup have been clearlyinferior in quality to those produced by the rulebased system both in terms of BLEU score andsubjective human judgment.2 The MetaMorpho translation systemMetaMorpho is a rule based system the architec-ture of which differs from that of most well-known rule based systems: it does not contain aseparate transfer component.
Its grammar oper-ates with pairs of patterns (context-free rules en-riched with features) that consist of one sourcepattern used during bottom-up parsing and one ormore target patterns that are applied during top-down generation of the translation.
The architec-ture of the grammar is completely homogeneous:the same formalism is used to represent generalrules of grammar, more-or-less idiomatic phrasesand fully lexicalized items, these differ only inthe degree of underspecification.The translation of the parsed structures is al-ready determined during parsing the source lan-guage input.
The actual generation of the targetlanguage representations does not involve anyadditional transfer operations: target languagestructures corresponding to substructures of thesource language parse tree are combined and theleaves of the resulting tree are interpreted by amorphological generator.MetaMorpho processes input by first segmentingit into sentences, then tokenizing them and per-forming morphological analysis on tokens, as-signing morphosyntactic attribute vectors tothem.
This is followed by parsing the network ofambiguous token sequences using the source sideof the grammar.
Features are used in the gram-mar to express constraints on the applicability ofrules and to store morphosyntactic, valence andlexical information concerning the parsed input.When no applicable rules remain, translationis generated in a top-down fashion by combiningthe target structures corresponding to the source155patterns constituting the source language parsetree.
A source language rule may have more thanone associated target rule.
The selection of thetarget structure to apply relies on constraints onthe actual values of features in the source rule.Unlike in classical transfer-based systems,word order rearrangement is already determinedduring parsing the source language input by theapplied rules and the values of the features.
Dur-ing generation, the already determined rear-ranged structures are simply spelled out.
Themorphosyntactic feature vectors on the terminallevel of the generated tree are interpreted by amorphological generator that synthesizes the cor-responding target language word forms.Handling ambiguity is always a difficultproblem in a rule based system.
MetaMorphogets rid of alternatives either by using high levelheuristics or by specific rules explicitly overrid-ing some more general alternatives.
GenerallyMetaMorpho only generates the first possibletranslation corresponding to the first parse it pro-duces.
In the case of long sentences however,MetaMorpho still may run into the problem ofgenerating too many hypotheses.
The solution tothis problem originally was simply to abort theparser when it had spent too much time on ana-lyzing a sentence.
This resulted in a sequence ofwords at the end of the sentence remaining un-translated.
We managed to alleviate this problemby introducing subsentential segmentation thatpartitions the input sentence into chunks at pre-sumably safe places (usually clause boundaries).3 Using a target language model to com-bine partial parsesDuring parsing, a hierarchy of partial structuresis built by the parser.
If the parser fails to pro-duce full parse of the sentence, MetaMorpho re-verts to using a heuristic process that constructsan output by combining the output of a selectedset of these partial structures covering the wholesentence.
These assembled translations are usu-ally suboptimal, because in the absence of a fullparse some structural information such as agree-ment is often lost.3.1 Pronoun droppingIn the case of Hungarian to English translation,pronoun dropping in Hungarian is a further prob-lem when trying to assemble a translation frompartial structures.
Since the number and personof the subject and the definiteness of the object(in the case of transitive verbs) is exactly ex-pressed by Hungarian verbal agreement suffixes,explicit subject and object pronouns may be (andusually are) dropped (unless they are focused orotherwise stressed).
The problem is that the sameverb forms are used when the subject or object isa full NP.
In these cases, however no pronoun isincorporated in the verbal suffix:Hallja.
He/she/it hears him/her/it.Fred hallja a doktort.
Fred hears the doctor.For single verb forms the MetaMorpho parseronly generates English phrases that contain sub-ject pronouns (and in the case of a transitivedefinite verb like hallja also an object pronoun:he hears it), because the verb is only representedin the grammar by structures that inherently con-tain its possible argument structures.
This resultsin extra pronouns appearing in the assembledoutput translation if there is in fact an overt sub-ject and/or object in the sentence.
The same thingapplies to 3rd person singular possessive con-structions:h?za his houseFred h?za.
Fred?s house.3.2 Utilizing the Moses decoderThe original partial structure combination algo-rithm in MetaMorpho does not utilize a statisticalmodel of the target language.
In our experiments,we replaced the original phrase combination al-gorithm with a statistical model using the Mosesdecoder hoping that this would improve thetranslations produced in these cases.
We createdan interface to the parser that can output all par-tial parses generated during parsing the inputsentence along with their translations.We directly constructed a phrase table fromthe partial translations and used the Moses de-coder to select the best translation using a surfacetarget language model.
We assumed a uniformdistribution on the translations in the phrase table(for lack of a better estimation of the translationprobabilities) and assigned a zero weight to thephrase model in the Moses configuration.
Nei-ther did we use a lexicalized distortion table.
Thedecoder thus selects the best translation based onthe language model score assigned to it.
In ourexperiments we used 5-gram language modelscreated from the WMT09 bilingual training data.We could not use language models created fromthe larger monolingual corpora: the RAM in-156stalled in our test machine was not enough forthat.2We experimented with various parameter set-tings and ways of building the phrase table.While including partial translations in the phrasetable for sentences that had a full parse definitelyhurt performance, adding all alternative fulltranslations (if the parser managed to parse thewhole sentence) to the phrase table and lettingthe language model select the best one (insteadof MetaMorpho defaulting to the first successfulparse) improved performance as could be ex-pected.
We needed to increase the maximum al-lowed phrase length parameter from the defaultto allow the decoder to use the full sentencetranslations (failing to do so resulted in a seriousdegradation of performance).Adding alternative versions of phrases con-taining possibly spurious pronouns to the phrasetable with the pronouns removed or properlymodified also had a beneficial effect as this re-duced the frequency of extra inserted pronounsin the translations.While our original phrase assembly algorithmnever attempts to reorder the chunks it selects,we did experiment with different distortion pa-rameter settings in the statistical approach sincereordering comes for free with the Moses de-coder.
(Well, there is in fact a price to pay fordistortion: a sharp fall in decoding speed.)
Wefound that not penalizing word order changes bythe decoder clearly had a detrimental effect onthe accuracy of translations.
The default distor-tion limit and penalty (distortion limit was of sixwords (d=6) in this setting; distortion penaltyweight was identical with the language modelweight) often resulted in translations with com-pletely out-of-place chunks at the end of the sen-tence.
We got the best results (also in terms ofBLEU score) when disallowing distortion alto-gether even though this results in somewhat dis-fluent output, especially if the target language isEnglish and the original Hungarian sentence wasverb final.
Disallowing distortion also made de-coding more than ten times faster.2 Building lower-order LMs, cutting off singletons,and/or limiting the LM's vocabulary to the most fre-quent phrases could be possible solutions to that prob-lem as the reviewer of the paper pointed out.
We aregoing to try to solve the memory problem using acombination these techniques in our follow-up ex-periments.3.3 ResultsUnfortunately, even with the best parameter set-tings that we have found, we managed to achieveonly a slight improvement in BLEU scores com-pared to the original heuristics used in MetaMor-pho.
The following table lists the (case insensi-tive) BLEU scores achieved by the originalpurely rule based system and various versions ofthe hybrid system on the WMT09 test set.3Hungarian to EnglishMetaMorpho 9.96d=6, no distortion penalty, reassem-bling full parses9.62d=6, distortion penalty, no partialanalyses for full parse sentences9.70d=0, no distortion, no partial analysesfor full parse sentences, pronoun drop-ping10.10English to HungarianMetaMorpho 8.13d=6, distortion penalty, no partialanalyses for full parse sentences8.22d=0, no distortion, no partial analysesfor full parse sentences8.44Although we got slightly better results usingthe hybrid system, we submitted the output of theoriginal fully rule based MetaMorpho system asour primary submission.4 A morpheme based Hungarian toEnglish statistical translation systemIn addition to the hybrid system above, we alsoexperimented with a statistical system using theMoses toolkit that we used to build a Hungarianto English translation system.
The model that weimplemented is based on a morpheme based rep-resentation of both languages instead of a wordform based or factored representation.4.1 The architecture of the systemThe Hungarian side of the WMT09 paralleltraining corpus was analyzed and stemmed usingthe Humor morphological analyzer (Pr?sz?kyand Kis, 1999; Pr?sz?ky and Nov?k, 2005) andwe used the Hunpos tagger (Hal?csy, Kornai andOravecz, 2007) for disambiguating the morpho-3 We first used a cleaned-up version of the WMT08test set (with typos and badly converted charactersfixed) in our experiments.
Then we rerun some of thetest configurations on the WMT09 test set and gotsimilarly improving results, which we report here.157logical tagging.
For English tagging, we usedCRFTagger (Phan, 2006), a Java-based condi-tional random fields POS tagger, while stemmingwas performed by morpha (Minnen, Carroll andPearce, 2001).
We used the correspondingmorphg word form generator to generate the out-put surface word forms.
Unfortunately, morphaneutralizes some present and past forms of thecopula, we needed to fix this to get the properforms in the output.We segmented both sides of the corpus intomorphemes based on the analyses, so the tokensin our system were morphemes instead of wordforms.
The following is a lowercased examplesentence pair from the training corpus:a[det] 137[szn] apr?
[mn] csillag[fn] [ela] ?ll?
[mn]spir?l[fn] meg+[ik] dupl?z?dik[ige] [me3] .
[punct]the_dt spiral_nn of_in 137_cd tiny_jj star_nn s_nnsdouble_vb ed_vbd itself_prp ._.The motivation for this approach was thatHungarian has a very rich morphology withthousands of possible inflected forms for eachword in the open word classes.
In addition, manyEnglish function words, such as prepositions,possessive and other pronouns etc.
correspond tobound morphemes in Hungarian, which makesalready the word alignment part of the Mosestraining procedure a difficult task.
It is difficultcapture generalizations like the ones above usinga word form based representation.
There are alsosystematic morpheme order differences betweenthese corresponding morphemes: the inflectionalsuffixes (or postpositions) corresponding to Eng-lish prepositions follow noun phrases rather thanpreceding them and the same applies to posses-sive pronouns and subject pronouns (the lattercorresponding to verb agreement suffixes).
Wehoped that these difficulties could be addressedby a morpheme based solution adequately.The phrase table was built using the defaultgrow-diag-final heuristic from Giza++ align-ments that we acquired from the morphemebased representation of the corpus.
We used thedefault settings for Giza++.
We also used a lexi-calized reordering table.
The distortion parameterwas left at the default value.
We also analyzedand tried to use a 5-gram language model builtfrom the monolingual English corpus that waspublished as part of the WMT09 shared transla-tion task training material but the resulting modelwas too big to be loaded into the 3GB RAM ofthe machine that we used in our experiments.
Wetried to use IRSTLM instead of SRILM but wedid not manage to solve the memory overloadproblem.
So in the end we used a 5-gram mor-pheme based language model that was built fromthe English side of the bilingual training corpusonly.We run the MERT parameter optimizationprocedure using a morpheme based BLEU scorecomputed on the morpheme segmented versionof the WMT09 Hungarian to English tuning set.MERT took several days to run.4.2 ResultsWe used the parameter settings suggested bythe (morpheme BLEU score based) MERT opti-mization and generated English surface wordforms using morphg.
We expected that the mor-pheme based solution would pose a new prob-lem: that of misplaced morphemes in the outputthat do not correspond to any valid surface wordform.
In such cases we resorted to skipping themisplaced morpheme, although this is obviouslynot an optimal solution.The BLEU score we obtained on the detoken-ized output was not very encouraging, to put itmildly: 7.82.
When we rerun the decoder withthe parameter settings obtained from a previousbroken down MERT session, we obtainedsomewhat better results: 7.95.
But this is stillvery far from the 9.96/10.10 points achieved byMetaMorpho and the hybrid solution.
Inspectionof the translation results confirmed that the trans-lations generated by the morpheme based setupare far inferior to those generated by our rulebased system.Inspecting Giza++ alignments revealed that,contrary to our hopes, segmenting the trainingcorpus into morphemes did not in itself solve theword alignment quality problem: the alignmentslook even worse than those achieved on the plaintext version of the corpus.
On the other hand, allthe drawbacks of the approach that we predicted:reduced span of local dependencies in the lan-guage models and the phase table due to the in-creased number of tokens spanning the samespan of input, misplaced morphemes, etc.
seemto have hit us.5 ConclusionIn this article, we described the rule based, hy-brid and statistical systems that we implementedand used in the WMT09 shared translation task.Although we only managed to slightly im-prove the performance of our rule based machinetranslation system in our hybrid experiment and158with our first attempt at a morpheme based statis-tical system we obtained more modest resultsthan we hoped, we think that it is still worth tomake further attempts to build better translationsystems for the Hungarian English language pairalong these lines.AcknowledgmentsThis research has been supported by the Euro-pean Commission in the FP6-IST project Euro-Matrix.
We also would like to thank L?szl?
Lakiand Borb?la Sikl?si for the work they have putinto the statistical system that we built.ReferencesP?ter Hal?csy, Andr?s Kornai, and Csaba Oravecz.2007.
HunPos ?
an open source trigram tagger In:Proceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics Compan-ion Volume Proceedings of the Demo and PosterSessions, Association for Computational Linguis-tics, Prague, Czech Republic, 209?212.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Ber-toldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, Evan Herbst.
2007.
Moses:Open Source Toolkit for Statistical Machine Trans-lation In: Proceedings of the 45th Annual Meetingof the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, Association for ComputationalLinguistics, Prague, Czech Republic, 177?180.Guido Minnen, John Carroll and Darren Pearce.
2001.Applied morphological processing of English,Natural Language Engineering, 7(3).
207?223.Xuan-Hieu Phan.
2006.
CRFTagger: CRF EnglishPOS Tagger, http://crftagger.sourceforge.net/G?bor Pr?sz?ky and Attila Nov?k.
2005.
Computa-tional Morphologies for Small Uralic Languages.In: A. Arppe, L. Carlson, K. Lind?n, J. Piitulainen,M.
Suominen, M. Vainio, H. Westerlund, A. Yli-Jyr?
(eds.
): Inquiries into Words, Constraints andContexts Festschrift in the Honour of KimmoKoskenniemi on his 60th Birthday, 116?125.Gummerus Printing, Saarij?rvi/CSLI Publications,Stanford.G?bor Pr?sz?ky and L?szl?
Tihanyi.
2002.
MetaMor-pho: A Pattern-Based Machine Translation System.In: Proceedings of the 24th 'Translating and theComputer' Conference, 19?24.
ASLIB, London,United Kingdom.159
