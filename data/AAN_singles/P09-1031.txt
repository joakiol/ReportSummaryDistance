Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 271?279,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPA Metric-based Framework for Automatic Taxonomy InductionHui YangLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon Universityhuiyang@cs.cmu.eduJamie CallanLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon Universitycallan@cs.cmu.eduAbstractThis paper presents a novel metric-basedframework for the task of automatic taxonomyinduction.
The framework incrementally clus-ters terms based on ontology metric, a scoreindicating semantic distance; and transformsthe task into a multi-criteria optimizationbased on minimization of taxonomy structuresand modeling of term abstractness.
It com-bines the strengths of both lexico-syntacticpatterns and clustering through incorporatingheterogeneous features.
The flexible design ofthe framework allows a further study on whichfeatures are the best for the task under variousconditions.
The experiments not only showthat our system achieves higher F1-measurethan other state-of-the-art systems, but also re-veal the interaction between features and vari-ous types of relations, as well as the interac-tion between features and term abstractness.1 IntroductionAutomatic taxonomy induction is an importanttask in the fields of Natural LanguageProcessing, Knowledge Management, and Se-mantic Web.
It has been receiving increasingattention because semantic taxonomies, such asWordNet (Fellbaum, 1998), play an importantrole in solving knowledge-rich problems, includ-ing question answering (Harabagiu et al, 2003)and textual entailment (Geffet and Dagan, 2005).Nevertheless, most existing taxonomies are ma-nually created at great cost.
These taxonomiesare rarely complete; it is difficult to include newterms in them from emerging or rapidly changingdomains.
Moreover, manual taxonomy construc-tion is time-consuming, which may make it un-feasible for specialized domains and personalizedtasks.
Automatic taxonomy induction is a solu-tion to augment existing resources and to pro-duce new taxonomies for such domains andtasks.Automatic taxonomy induction can be decom-posed into two subtasks: term extraction and re-lation formation.
Since term extraction is rela-tively easy, relation formation becomes the focusof most research on automatic taxonomy induc-tion.
In this paper, we also assume that terms in ataxonomy are given and concentrate on the sub-task of relation formation.Existing work on automatic taxonomy induc-tion has been conducted under a variety ofnames, such as ontology learning, semantic classlearning, semantic relation classification, andrelation extraction.
The approaches fall into twomain categories: pattern-based and clustering-based.
Pattern-based approaches define lexical-syntactic patterns for relations, and use these pat-terns to discover instances of relations.
Cluster-ing-based approaches hierarchically cluster termsbased on similarities of their meanings usuallyrepresented by a vector of quantifiable features.Pattern-based approaches are known for theirhigh accuracy in recognizing instances of rela-tions if the patterns are carefully chosen, eithermanually (Berland and Charniak, 1999; Kozare-va et al, 2008) or via automatic bootstrapping(Hearst, 1992; Widdows and Dorow, 2002; Girjuet al, 2003).
The approaches, however, sufferfrom sparse coverage of patterns in a given cor-pus.
Recent studies (Etzioni et al, 2005; Kozare-va et al, 2008) show that if the size of a corpus,such as the Web, is nearly unlimited, a patternhas a higher chance to explicitly appear in thecorpus.
However, corpus size is often not thatlarge; hence the problem still exists.
Moreover,since patterns usually extract instances in pairs,the approaches suffer from the problem of incon-sistent concept chains after connecting pairs ofinstances to form taxonomy hierarchies.Clustering-based approaches have a main ad-vantage that they are able to discover relations271which do not explicitly appear in text.
They alsoavoid the problem of inconsistent chains by ad-dressing the structure of a taxonomy globallyfrom the outset.
Nevertheless, it is generally be-lieved that clustering-based approaches cannotgenerate relations as accurate as pattern-basedapproaches.
Moreover, their performance islargely influenced by the types of features used.The common types of features include contextual(Lin, 1998), co-occurrence (Yang and Callan,2008), and syntactic dependency (Pantel and Lin,2002; Pantel and Ravichandran, 2004).
So farthere is no systematic study on which featuresare the best for automatic taxonomy inductionunder various conditions.This paper presents a metric-based taxonomyinduction framework.
It combines the strengthsof both pattern-based and clustering-based ap-proaches by incorporating lexico-syntactic pat-terns as one type of features in a clusteringframework.
The framework integrates contex-tual, co-occurrence, syntactic dependency, lexi-cal-syntactic patterns, and other features to learnan ontology metric, a score indicating semanticdistance, for each pair of terms in a taxonomy; itthen incrementally clusters terms based on theirontology metric scores.
The incremental cluster-ing is transformed into an optimization problembased on two assumptions: minimum evolutionand abstractness.
The flexible design of theframework allows a further study of the interac-tion between features and relations, as well asthat between features and term abstractness.2 Related WorkThere has been a substantial amount of researchon automatic taxonomy induction.
As we men-tioned earlier, two main approaches are pattern-based and clustering-based.Pattern-based approaches are the main trendfor automatic taxonomy induction.
Though suf-fering from the problems of sparse coverage andinconsistent chains, they are still popular due totheir simplicity and high accuracy.
They havebeen applied to extract various types of lexicaland semantic relations, including is-a, part-of,sibling, synonym, causal, and many others.Pattern-based approaches started from and stillpay a great deal of attention to the most commonis-a relations.
Hearst (1992) pioneered using ahand crafted list of hyponym patterns as seedsand employing bootstrapping to discover is-arelations.
Since then, many approaches (Mann,2002; Etzioni et al, 2005; Snow et al, 2005)have used Hearst-style patterns in their work onis-a relations.
For instance, Mann (2002) ex-tracted is-a relations for proper nouns by Hearst-style patterns.
Pantel et al (2004) extended is-arelation acquisition towards terascale, and auto-matically identified hypernym patterns by mi-nimal edit distance.Another common relation is sibling, which de-scribes the relation of sharing similar meaningsand being members of the same class.
Terms insibling relations are also known as class mem-bers or similar terms.
Inspired by the conjunctionand appositive structures, Riloff and Shepherd(1997), Roark and Charniak (1998) used co-occurrence statistics in local context to discoversibling relations.
The KnowItAll system (Etzioniet al, 2005) extended the work in (Hearst, 1992)and bootstrapped patterns on the Web to discoversiblings; it also ranked and selected the patternsby statistical measures.
Widdows and Dorow(2002) combined symmetric patterns and graphlink analysis to discover sibling relations.
Davi-dov and Rappoport (2006) also used symmetricpatterns for this task.
Recently, Kozareva et al(2008) combined a double-anchored hyponympattern with graph structure to extract siblings.The third common relation is part-of.
Berlandand Charniak (1999) used two meronym patternsto discover part-of relations, and also used statis-tical measures to rank and select the matchinginstances.
Girju et al (2003) took a similar ap-proach to Hearst (1992) for part-of relations.Other types of relations that have been studiedby pattern-based approaches include question-answer relations (such as birthdates and inven-tor) (Ravichandran and Hovy, 2002), synonymsand antonyms (Lin et al, 2003), general purposeanalogy (Turney et al, 2003), verb relations (in-cluding similarity, strength, antonym, enable-ment and temporal) (Chklovski and Pantel,2004), entailment (Szpektor et al, 2004), andmore specific relations, such as purpose, creation(Cimiano and Wenderoth, 2007), LivesIn, andEmployedBy (Bunescu and Mooney , 2007).The most commonly used technique in pat-tern-based approaches is bootstrapping (Hearst,1992; Etzioni et al, 2005; Girju et al, 2003; Ra-vichandran and Hovy, 2002; Pantel and Pennac-chiotti, 2006).
It utilizes a few man-crafted seedpatterns to extract instances from corpora, thenextracts new patterns using these instances, andcontinues the cycle to find new instances andnew patterns.
It is effective and scalable to largedatasets; however, uncontrolled bootstrapping272soon generates undesired instances once a noisypattern brought into the cycle.To aid bootstrapping, methods of patternquality control are widely applied.
Statisticalmeasures, such as point-wise mutual information(Etzioni et al, 2005; Pantel and Pennacchiotti,2006) and conditional probability (Cimiano andWenderoth, 2007),   have been shown to be ef-fective to rank and select patterns and instances.Pattern quality control is also investigated byusing WordNet (Girju et al, 2006), graph struc-tures built among terms (Widdows and Dorow,2002; Kozareva et al, 2008), and pattern clusters(Davidov and Rappoport, 2008).Clustering-based approaches usually representword contexts as vectors and cluster words basedon similarities of the vectors (Brown et al, 1992;Lin, 1998).
Besides contextual features, the vec-tors can also be represented by verb-noun rela-tions (Pereira et al, 1993), syntactic dependency(Pantel and Ravichandran, 2004; Snow et al,2005), co-occurrence (Yang and Callan, 2008),conjunction and appositive features (Caraballo,1999).
More work is described in (Buitelaar etal., 2005; Cimiano and Volker, 2005).
Cluster-ing-based approaches allow discovery of rela-tions which do not explicitly appear in text.
Pan-tel and Pennacchiotti (2006), however, pointedout that clustering-based approaches generallyfail to produce coherent cluster for small corpora.In addition, clustering-based approaches had on-ly applied to solve is-a and sibling relations.Many clustering-based approaches face thechallenge of appropriately labeling non-leaf clus-ters.
The labeling amplifies the difficulty in crea-tion and evaluation of taxonomies.
Agglomera-tive clustering (Brown et al, 1992; Caraballo,1999; Rosenfeld and Feldman, 2007; Yang andCallan, 2008) iteratively merges the most similarclusters into bigger clusters, which need to belabeled.
Divisive clustering, such as CBC (Clus-tering By Committee) which constructs clustercentroids by averaging the feature vectors of asubset of carefully chosen cluster members (Pan-tel and Lin, 2002; Pantel and Ravichandran,2004), also need to label the parents of split clus-ters.
In this paper, we take an incremental clus-tering approach, in which terms and relations areadded into a taxonomy one at a time, and theirparents are from the existing taxonomy.
The ad-vantage of the incremental approach is that iteliminates the trouble of inventing cluster labelsand concentrates on placing terms in the correctpositions in a taxonomy hierarchy.The work by Snow et al (2006) is the mostsimilar to ours because they also took an incre-mental approach to construct taxonomies.
In theirwork, a taxonomy grows based on maximizationof conditional probability of relations given evi-dence; while in our work based on optimizationof taxonomy structures and modeling of termabstractness.
Moreover, our approach employsheterogeneous features from a wide range; whiletheir approach only used syntactic dependency.We compare system performance between (Snowet al, 2006) and our framework in Section 5.3 The FeaturesThe features used in this work are indicators ofsemantic relations between terms.
Given two in-put terms yx cc , , a feature is defined as a func-tion generating a single numeric score?
),( yx cch ?
or a vector of numeric scores?
),( yx cch ?n.
The features include contextual,co-occurrence, syntactic dependency, lexical-syntactic patterns, and miscellaneous.The first set of features captures contextual in-formation of terms.
According to DistributionalHypothesis (Harris, 1954), words appearing insimilar contexts tend to be similar.
Therefore,word meanings can be inferred from andrepresented by contexts.
Based on the hypothe-sis, we develop the following features: (1) Glob-al Context KL-Divergence: The global context ofeach input term is the search results collectedthrough querying search engines against severalcorpora (Details in Section 5.1).
It is built into aunigram language model without smoothing foreach term.
This feature function measures theKullback-Leibler divergence (KL divergence)between the language models associated with thetwo inputs.
(2) Local Context KL-Divergence:The local context is the collection of all the lefttwo and the right two words surrounding an inputterm.
Similarly, the local context is built into aunigram language model without smoothing foreach term; the feature function outputs KL diver-gence between the models.The second set of features is co-occurrence.
Inour work, co-occurrence is measured by point-wise mutual information between two terms:)()(),(log),(yxyxyxcCountcCountccCountccpmi =where Count(.)
is defined as the number of doc-uments or sentences containing the term(s); or nas in ?Results 1-10 of about n for term?
appear-ing on the first page of Google search results fora term or the concatenation of a term pair.
Based273on different definitions of Count(.
), we have (3)Document PMI, (4) Sentence PMI, and (5)Google PMI as the co-occurrence features.The third set of features employs syntactic de-pendency analysis.
We have (6) Minipar Syntac-tic Distance to measure the average length of theshortest syntactic paths (in the first syntacticparse tree returned by Minipar1) between twoterms in sentences containing them, (7) ModifierOverlap, (8) Object Overlap, (9) Subject Over-lap, and (10) Verb Overlap to measure the num-ber of overlaps between modifiers, objects, sub-jects, and verbs, respectively, for the two termsin sentences containing them.
We use Assert2 tolabel the semantic roles.The fourth set of features is lexical-syntacticpatterns.
We have (11) Hypernym Patterns basedon patterns proposed by (Hearst, 1992) and(Snow et al, 2005), (12) Sibling Patterns whichare basically conjunctions, and (13) Part-of Pat-terns based on patterns proposed by (Girju et al,2003) and (Cimiano and Wenderoth, 2007).
Ta-ble 1 lists all patterns.
Each feature function re-turns a vector of scores for two input terms, onescore per pattern.
A score is 1 if two terms matcha pattern in text, 0 otherwise.The last set of features is miscellaneous.
Wehave (14) Word Length Difference to measure thelength difference between two terms, and (15)Definition Overlap to measure the number ofword overlaps between the term definitions ob-tained by querying Google with ?define:term?.These heterogeneous features vary from sim-ple statistics to complicated syntactic dependen-cy features, basic word length to comprehensiveWeb-based contextual features.
The flexible de-sign of our learning framework allows us to useall of them, and even allows us to use differentsets of them under different conditions, for in-stance, different types of relations and differentabstraction levels.
We study the interaction be-1http://www.cs.ualberta.ca/lindek/minipar.htm.2http://cemantix.org/assert.tween features and relations and that betweenfeatures and abstractness in Section 5.4 The Metric-based FrameworkThis section presents the metric-based frame-work which incrementally clusters terms to formtaxonomies.
By minimizing the changes of tax-onomy structures and modeling term abstractnessat each step, it finds the optimal position for eachterm in a taxonomy.
We first introduce defini-tions, terminologies and assumptions about tax-onomies; then, we formulate automatic taxono-my induction as a multi-criterion optimizationand solve it by a greedy algorithm; lastly, weshow how to estimate ontology metrics.4.1 Taxonomies, Ontology Metric, Assump-tions, and Information FunctionsWe define a taxonomy T as a data model thatrepresents a set of terms C and a set of relationsR between these terms.
T can be written asT(C,R).
Note that for the subtask of relation for-mation, we assume that the term set C is given.
Afull taxonomy is a tree containing all the terms inC. A partial taxonomy is a tree containing only asubset of terms in C.In our framework, automatic taxonomy induc-tion is the process to construct a full taxonomy T?given a set of terms C and an initial partial tax-onomy ),( 000 RST , where CS ?0 .
Note that T0 ispossibly empty.
The process starts from the ini-tial partial taxonomy T0 and randomly adds termsfrom C to T0 one by one, until a full taxonomy isformed, i.e., all terms in C are added.Ontology MetricWe define an ontology metric as a distancemeasure between two terms (cx,cy) in a taxonomyT(C,R).
Formally, it is a function ??
CCd : ?+,where C is the set of terms in T.  An ontologymetric d on a taxonomy T with edge weights wfor any term pair (cx,cy)?C is the sum of all edgeweights along the shortest path between the pair:?
?=),(,),(,)(),(yxPeyxyxwTyxewccdHypernym Patterns Sibling PatternsNPx (,)?and/or other NPy NPx and/or NPysuch NPy as NPx Part-of PatternsNPy (,)?
such as NPx NPx of NPyNPy (,)?
including NPx NPy?s NPxNPy (,)?
especially NPx NPy has/had/have NPxNPy like NPx NPy is made (up)?
of NPxNPy called NPx NPy comprises NPxNPx is a/an NPy NPy consists of NPxNPx , a/an NPyTable 1.
Lexico-Syntactic Patterns.Figure 1.
Illustration of Ontology Metric.274where ),( yxP  is the set of edges defining theshortest path from term cx to cy .
Figure 1 illu-strates ontology metrics for a 5-node taxonomy.Section 4.3 presents the details of learning ontol-ogy metrics.Information FunctionsThe amount of information in a taxonomy T ismeasured and represented by an informationfunction Info(T).
An information function is de-fined as the sum of the ontology metrics among aset of term pairs.
The function can be definedover a taxonomy, or on a single level of a tax-onomy.
For a taxonomy T(C,R), we define itsinformation function as:?
?<=Cycxcyxyx ccdTInfo,,),()(   (1)Similarly, we define the information functionfor an abstraction level Li as:?
?<=iLycxcyxyxii ccdLInfo,,),()(   (2)where Li is the subset of terms lying at the ith lev-el of a taxonomy T. For example, in Figure 1,node 1 is at level L1, node 2 and node 5 level L2.AssumptionsGiven the above definitions about taxonomies,we make the following assumptions:Minimum Evolution Assumption.
Inspired bythe minimum evolution tree selection criterionwidely used in phylogeny (Hendy and Penny,1985), we assume that a good taxonomy not onlyminimizes the overall semantic distance amongthe terms but also avoid dramatic changes.
Con-struction of a full taxonomy is proceeded by add-ing terms one at a time, which yields a series ofpartial taxonomies.
After adding each term, thecurrent taxonomy Tn+1 from the previous tax-onomy Tn is one that introduces the least changesbetween the information in the two taxonomies:),(minarg ''1 TTInfoT nTn ?=+where the information change function is|)()(| ),( baba TInfoTInfoTTInfo ?=?
.Abstractness Assumption.
In a taxonomy, con-crete concepts usually lay at the bottom of thehierarchy while abstract concepts often occupythe intermediate and top levels.
Concrete con-cepts often represent physical entities, such as?basketball?
and ?mercury pollution?.
While ab-stract concepts, such as ?science?
and ?econo-my?, do not have a physical form thus we mustimagine their existence.
This obvious differencesuggests that there is a need to treat them diffe-rently in taxonomy induction.
Hence we assumethat terms at the same abstraction level havecommon characteristics and share the same Info(.)function.
We also assume that terms at differentabstraction levels have different characteristics;hence they do not necessarily share the sameInfo(.)
function.
That is to say, ,concept  Tc ?
?, leveln abstractio TLi ?
(.).
uses ii InfocLc ?
?4.2 Problem FormulationThe Minimum Evolution ObjectiveBased on the minimum evolution assumption, wedefine the goal of taxonomy induction is to findthe optimal full taxonomy T?
such that the infor-mation changes are the least since the initial par-tial taxonomy T0, i.e., to find:),(minarg?
'0'TTInfoTT?=   (3)where 'T  is a full taxonomy, i.e., the set of termsin 'T  equals C.To find the optimal solution for Equation (3),T?
, we need to find the optimal term set C?
andthe optimal relation set R?
.
Since the optimal termset for a full taxonomy is always C, the only un-known part left is R?
.
Thus, Equation (3) can betransformed equivalently into:)),(),,((minarg?
000'''RSTRCTInfoRR?=Note that in the framework, terms are addedincrementally into a taxonomy.
Each term inser-tion yields a new partial taxonomy T. By theminimum evolution assumption, the optimal nextpartial taxonomy is one gives the least informa-tion change.
Therefore, the updating function forthe set of relations 1+nR after a new term z is in-serted can be calculated as:)),(),},{((minarg?
''nnnRRSTRzSTInfoR ?
?=By plugging in the definition of the informationchange function (.,.)Info?
in Section 4.1 and Equ-ation (1), the updating function becomes:|),(),(|minarg?,}{,'?????
?=nSycxcyxznSycxcyxRccdccdRThe above updating function can be transformedinto a minimization problem:yxccdccduccdccduuznSycxcyxnSycxcyxnSycxcyxznSycxcyx<??????????????
}{,,,}{,),(),(),(),(    subject tominThe minimization follows the minimum evolu-tion assumption; hence we call it the minimumevolution objective.275The Abstractness ObjectiveThe abstractness assumption suggests that termabstractness should be modeled explicitly bylearning separate information functions for termsat different abstraction levels.
We approximatean information function by a linear interpolationof some underlying feature functions.
Each ab-straction level Li is characterized by its own in-formation function Infoi(.).
The least square fit ofInfoi(.)
is: .|)(|min 2iTiii HWLInfo ?By plugging Equation (2) and minimizing overevery abstraction level, we have:2,,,)),(),((min yxjijjii iLycxcyx cchwccd ??
?
?
?where jih , (.,.)
is the jth underlying feature func-tion for term pairs at level Li, jiw , is the weightfor jih , (.,.).
This minimization follows the ab-stractness assumption; hence we call it the ab-stractness objective.The Multi-Criterion Optimization AlgorithmWe propose that both minimum evolution andabstractness objectives need to be satisfied.
Tooptimize multiple criteria, the Pareto optimalityneeds to be satisfied (Boyd and Vandenberghe,2004).
We handle this by introducing   0,1 tocontrol the contribution of each objective.
Themulti-criterion optimization function is:yxcchwccdvccdccduccdccduvuyxjijjii LccyxzSccyxSccyxSccyxzSccyxiyxnyxnyxnyxnyx<?=?????+??
???????????
?2)),(),((),(),(),(),(      subject to)1(min,,,}{,,,}{,?
?The above optimization can be solved by a gree-dy optimization algorithm.
At each term insertionstep, it produces a new partial taxonomy by add-ing to the existing partial taxonomy a new term z,and a new set of relations R(z,.).
z is attached toevery nodes in the existing partial taxonomy; andthe algorithm selects the optimal position indi-cated by R(z,.
), which minimizes the multi-criterion objective function.
The algorithm is:);,()};)1((min{arg;\RSTvuRR{z}SSSCz(z,.)ROutputforeach??
?+????
?The above algorithm presents a general incre-mental clustering procedure to construct taxono-mies.
By minimizing the taxonomy structurechanges and modeling term abstractness at eachstep, it finds the optimal position of each term inthe taxonomy hierarchy.4.3 Estimating Ontology MetricLearning a good ontology metric is important forthe multi-criterion optimization algorithm.
In thiswork, the estimation and prediction of ontologymetric are achieved by ridge regression (Hastie etal., 2001).
In the training data, an ontology me-tric d(cx,cy) for a term pair (cx,cy) is generated byassuming every edge weight as 1 and summingup all the edge weights along the shortest pathfrom cx to cy.
We assume that there are some un-derlying feature functions which measure thesemantic distance from term cx to cy.
A weightedcombination of these functions approximates theontology metric for (cx,cy):?= ),(),( yxjjj cchwyxdwhere jw  is the jth weight for ),( yxj cch , the jthfeature function.
The feature functions are gener-ated as mentioned in Section 3.5 Experiments5.1 DataThe gold standards used in the evaluation arehypernym taxonomies extracted from WordNetand ODP (Open Directory Project), and me-ronym taxonomies extracted from WordNet.
InWordNet taxonomy extraction, we only use theword senses within a particular taxonomy to en-sure no ambiguity.
In ODP taxonomy extraction,we parse the topic lines, such as ?Topicr:id=`Top/Arts/Movies?
?, in the XML databasesto obtain relations, such as is_a(movies, arts).
Intotal, there are 100 hypernym taxonomies, 50each extracted from WordNet3 and ODP4, and 50meronym taxonomies from WordNet5.
Table 23WordNet hypernym taxonomies are from 12 topics: ga-thering, professional, people, building, place, milk, meal,water, beverage, alcohol, dish, and herb.4ODP hypernym taxonomies are from 16 topics: computers,robotics, intranet, mobile computing, database, operatingsystem, linux, tex, software, computer science, data commu-nication, algorithms, data formats, security multimedia, andartificial intelligence.5WordNet meronym taxonomies are from 15 topics: bed,car, building, lamp, earth, television, body, drama, theatre,water, airplane, piano, book, computer, and watch.Statistics WN/is-a ODP/is-a WN/part-of#taxonomies 50 50 50#terms 1,964 2,210 1,812Avg #terms 39 44 37Avg depth 6 6 5Table 2.
Data Statistics.276summarizes the data statistics.We also use two Web-based auxiliary datasetsto generate features mentioned in Section 3:?
Wikipedia corpus.
The entire Wikipedia corpusis downloaded and indexed by Indri6.
The top100 documents returned by Indri are the globalcontext of a term when querying with the term.?
Google corpus.
A collection of the top 1000documents by querying Google using eachterm, and each term pair.
Each top 1000 docu-ments are the global context of a query term.Both corpora are split into sentences and are usedto generate contextual, co-occurrence, syntacticdependency and lexico-syntactic pattern features.5.2 MethodologyWe evaluate the quality of automatic generatedtaxonomies by comparing them with the goldstandards in terms of precision, recall and F1-measure.
F1-measure is calculated as 2*P*R/(P+R), where P is precision, the percentage ofcorrectly returned relations out of the total re-turned relations, R is recall, the percentage ofcorrectly returned relations out of the total rela-tions in the gold standard.Leave-one-out cross validation is used to aver-age the system performance across differenttraining and test datasets.
For each 50 datasetsfrom WordNet hypernyms, WordNet meronymsor ODP hypernyms, we randomly pick 49 ofthem to generate training data, and test on theremaining dataset.
We repeat the process for 50times, with different training and test sets at each6http://www.lemurproject.org/indri/.time, and report the averaged precision, recalland F1-measure across all 50 runs.We also group the fifteen features in Section 3into six sets: contextual, co-concurrence, pat-terns, syntactic dependency, word length differ-ence and definition.
Each set is turned on one byone for experiments in Section 5.4 and 5.5.5.3 Performance of Taxonomy InductionIn this section, we compare the following auto-matic taxonomy induction systems: HE, the sys-tem by Hearst (1992) with 6 hypernym patterns;GI, the system by Girju et al (2003) with 3 me-ronym patterns; PR, the probabilistic frameworkby Snow et al (2006); and ME, the metric-basedframework proposed in this paper.
To have a faircomparison, for PR, we estimate the conditionalprobability of a relation given the evidenceP(Rij|Eij), as in (Snow et al 2006), by using thesame set of features as in ME.Table 3 shows precision, recall, and F1-measure of each system for WordNet hypernyms(is-a), WordNet meronyms (part-of) and ODPhypernyms (is-a).
Bold font indicates the bestperformance in a column.
Note that HE is notapplicable to part-of, so is GI to is-a.Table 3 shows that systems using heterogene-ous features (PR and ME) achieve higher F1-measure than systems only using patterns (HEand GI) with a significant absolute gain of >30%.Generally speaking, pattern-based systems showhigher precision and lower recall, while systemsusing heterogeneous features show lower preci-sion and higher recall.
However, when consider-ing both precision and recall, using heterogene-ous features is more effective than just using pat-terns.
The proposed system ME consistently pro-duces the best F1-measure for all three tasks.The performance of the systems for ODP/is-ais worse than that for WordNet/is-a.
This may bebecause there is more noise in ODP than inWordNet/is-aSystem Precision Recall F1-measureHE 0.85 0.32 0.46GI n/a n/a n/aPR 0.75 0.73 0.74ME 0.82 0.79 0.82ODP/is-aSystem Precision Recall F1-measureHE 0.31 0.29 0.30GI n/a n/a n/aPR 0.60 0.72 0.65ME 0.64 0.70 0.67WordNet/part-ofSystem Precision Recall F1-measureHE n/a n/a n/aGI 0.75 0.25 0.38PR 0.68 0.52 0.59ME 0.69 0.55 0.61Table 3.
System Performance.Feature  is-a sibling part-ofBenefitedRelationsContextual 0.21 0.42 0.12 siblingCo-occur.
0.48 0.41 0.28 AllPatterns 0.46 0.41 0.30 AllSyntactic 0.22 0.36 0.12 siblingWord Leng.
0.16 0.16 0.15 All butlimitedDefinition 0.12 0.18 0.10 Sibling butlimitedBest Features Co-occur.,patternsContextual,co-occur.,patternsCo-occur.,patternsTable 4.
F1-measure for Features vs. Relations: WordNet.277WordNet.
For example, under artificial intelli-gence, ODP has neural networks, natural lan-guage and academic departments.
Clearly, aca-demic departments is not a hyponym of artificialintelligence.
The noise in ODP interferes withthe learning process, thus hurts the performance.5.4 Features vs. RelationsThis section studies the impact of different setsof features on different types of relations.
Table 4shows F1-measure of using each set of featuresalone on taxonomy induction for WordNet is-a,sibling, and part-of relations.
Bold font means afeature set gives a major contribution to the taskof automatic taxonomy induction for a particulartype of relation.Table 4 shows that different relations favordifferent sets of features.
Both co-occurrenceand lexico-syntactic patterns work well for allthree types of relations.
It is interesting to seethat simple co-occurrence statistics work as goodas lexico-syntactic patterns.
Contextual featureswork well for sibling relations, but not for is-aand part-of.
Syntactic features also work well forsibling, but not for is-a and part-of.
The similarbehavior of contextual and syntactic featuresmay be because that four out of five syntacticfeatures (Modifier, Subject, Object, and Verboverlaps) are just surrounding context for a term.Comparing the is-a and part-of columns inTable 4 and the ME rows in Table 3, we notice asignificant difference in F1-measure.
It indicatesthat combination of heterogeneous features givesmore rise to the system performance than a sin-gle set of features does.5.5 Features vs. AbstractnessThis section studies the impact of different setsof features on terms at different abstraction le-vels.
In the experiments, F1-measure is evaluatedfor terms at each level of a taxonomy, not thewhole taxonomy.
Table 5 and 6 demonstrate F1-measure of using each set of features alone oneach abstraction levels.
Columns 2-6 are indicesof the levels in a taxonomy.
The larger the indic-es are, the lower the levels.
Higher levels containabstract terms, while lower levels contain con-crete terms.
L1 is ignored here since it only con-tains a single term, the root.
Bold font indicatesgood performance in a column.Both tables show that abstract terms and con-crete terms favor different sets of features.
Inparticular, contextual, co-occurrence, pattern,and syntactic features work well for terms at L4-L6, i.e., concrete terms; co-occurrence works wellfor terms at L2-L3, i.e., abstract terms.
This differ-ence indicates that terms at different abstractionlevels have different characteristics; it confirmsour abstractness assumption in Section 4.1.We also observe that for abstract terms inWordNet, patterns work better than contextualfeatures; while for abstract terms in ODP, theconclusion is the opposite.
This may be becausethat WordNet has a richer vocabulary and a morerigid definition of hypernyms, and hence is-arelations in WordNet are recognized more effec-tively by using lexico-syntactic patterns; whileODP contains more noise, and hence it favorsfeatures requiring less rigidity, such as the con-textual features generated from the Web.6 ConclusionsThis paper presents a novel metric-based tax-onomy induction framework combining thestrengths of lexico-syntactic patterns and cluster-ing.
The framework incrementally clusters termsand transforms automatic taxonomy inductioninto a multi-criteria optimization based on mini-mization of taxonomy structures and modeling ofterm abstractness.
The experiments show that ourframework is effective; it achieves higher F1-measure than three state-of-the-art systems.
Thepaper also studies which features are the best fordifferent types of relations and for terms at dif-ferent abstraction levels.Most prior work uses a single rule or featurefunction for automatic taxonomy induction at alllevels of abstraction.
Our work is a more generalframework which allows a wider range of fea-tures and different metric functions at differentabstraction levels.
This more general frameworkhas the potential to learn more complex taxono-mies than previous approaches.AcknowledgementsThis research was supported by NSF grant IIS-0704210.
Any opinions, findings, conclusions, orrecommendations expressed in this paper are ofthe authors, and do not necessarily reflect thoseof the sponsor.Feature  L2 L3 L4 L5 L6Contextual 0.29 0.31 0.35 0.36 0.36Co-occurrence 0.47 0.56 0.45 0.41 0.41Patterns 0.47 0.44 0.42 0.39 0.40Syntactic 0.31 0.28 0.36 0.38 0.39Word Length 0.16 0.16 0.16 0.16 0.16Definition 0.12 0.12 0.12 0.12 0.12Table 5.
F1-measure for Features vs. Abstractness:WordNet/is-a.Feature  L2 L3 L4 L5 L6Contextual 0.30 0.30 0.33 0.29 0.29Co-occurrence 0.34 0.36 0.34 0.31 0.31Patterns 0.23 0.25 0.30 0.28 0.28Syntactic 0.18 0.18 0.23 0.27 0.27Word Length 0.15 0.15 0.15 0.14 0.14Definition 0.13 0.13 0.13 0.12 0.12Table 6.
F1-measure for Features vs. Abstractness:ODP/is-a.278ReferencesM.
Berland and E. Charniak.
1999.
Finding parts in verylarge corpora.
ACL?99.S.
Boyd and L. Vandenberghe.
2004.
Convex optimization.In Cambridge University Press, 2004.P.
Brown, V. D. Pietra, P. deSouza, J. Lai, and R. Mercer.1992.
Class-based ngram models for natural language.Computational Linguistics, 18(4):468?479.P.
Buitelaar, P. Cimiano, and B. Magnini.
2005.
OntologyLearning from Text: Methods, Evaluation and Applica-tions.
Volume 123 Frontiers in Artificial Intelligence andApplications.R.
Bunescu and R. Mooney.
2007.
Learning to ExtractRelations from the Web using Minimal Supervision.ACL?07.S.
Caraballo.
1999.
Automatic construction of a hypernym-labeled noun hierarchy from text.
ACL?99.T.
Chklovski and P. Pantel.
2004.
VerbOcean: mining theweb for fine-grained semantic verb relations.
EMNLP?04.P.
Cimiano and J. Volker.
2005.
Towards large-scale, open-domain and ontology-based named entity classification.RANLP?07.P.
Cimiano and J. Wenderoth.
2007.
Automatic Acquisitionof Ranked Qualia Structures from the Web.
ACL?07.D.
Davidov and A. Rappoport.
2006.
Efficient Unsuper-vised Discovery of Word Categories Using SymmetricPatterns and High Frequency Words.
ACL?06.D.
Davidov and A. Rappoport.
2008.
Classification of Se-mantic Relationships between Nominals Using PatternClusters.
ACL?08.D.
Downey, O. Etzioni, and S. Soderland.
2005.
A Probabil-istic model of redundancy in information extraction.
IJ-CAI?05.O.
Etzioni, M. Cafarella, D. Downey, A. Popescu, T.Shaked, S. Soderland, D. Weld, and A. Yates.
2005.
Un-supervised named-entity extraction from the web: an ex-perimental study.
Artificial Intelligence, 165(1):91?134.C.
Fellbuam.
1998.
WordNet: An Electronic Lexical Data-base.
MIT Press.
1998.M.
Geffet and I. Dagan.
2005.
The Distributional InclusionHypotheses and Lexical Entailment.
ACL?05.R.
Girju, A. Badulescu, and D. Moldovan.
2003.
LearningSemantic Constraints for the Automatic Discovery ofPart-Whole Relations.
HLT?03.R.
Girju, A. Badulescu, and D. Moldovan.
2006.
AutomaticDiscovery of Part-Whole Relations.
Computational Lin-guistics, 32(1): 83-135.Z.
Harris.
1985.
Distributional structure.
In Word, 10(23):146-162s, 1954.T.
Hastie, R. Tibshirani and J. Friedman.
2001.
The Ele-ments of Statistical Learning: Data Mining, Inference,and Prediction.
Springer-Verlag, 2001.M.
Hearst.
1992.
Automatic acquisition of hyponyms fromlarge text corpora.
COLING?92.M.
D. Hendy and D. Penny.
1982.
Branch and bound algo-rithms to determine minimal evolutionary trees.
Mathe-matical Biosciences 59: 277-290.Z.
Kozareva, E. Riloff, and E. Hovy.
2008.
Semantic ClassLearning from the Web with Hyponym Pattern LinkageGraphs.
ACL?08.D.
Lin, 1998.
Automatic retrieval and clustering of similarwords.
COLING?98.D.
Lin, S. Zhao, L. Qin, and M. Zhou.
2003.
IdentifyingSynonyms among Distributionally Similar Words.
IJ-CAI?03.G.
S. Mann.
2002.
Fine-Grained Proper Noun Ontologiesfor Question Answering.
In Proceedings of SemaNet?
02:Building and Using Semantic Networks, Taipei.P.
Pantel and D Lin.
2002.
Discovering word senses fromtext.
SIGKDD?02.P.
Pantel and D. Ravichandran.
2004.
Automatically labe-ling semantic classes.
HLT/NAACL?04.P.
Pantel, D. Ravichandran, and E. Hovy.
2004.
Towardsterascale knowledge acquisition.
COLING?04.P.
Pantel and M. Pennacchiotti.
2006.
Espresso: LeveragingGeneric Patterns for Automatically Harvesting SemanticRelations.
ACL?06.F.
Pereira, N. Tishby, and L. Lee.
1993.
Distributional clus-tering of English words.
ACL?93.D.
Ravichandran and E. Hovy.
2002.
Learning surface textpatterns for a question answering system.
ACL?02.E.
Riloff and J. Shepherd.
1997.
A corpus-based approachfor building semantic lexicons.
EMNLP?97.B.
Roark and E. Charniak.
1998.
Noun-phrase co-occurrence statistics for semi-automatic semantic lexiconconstruction.
ACL/COLING?98.R.
Snow, D. Jurafsky, and A. Y. Ng.
2005.
Learning syntac-tic patterns for automatic hypernym discovery.
NIPS?05.R.
Snow, D. Jurafsky, and A. Y. Ng.
2006.
Semantic Tax-onomy Induction from Heterogeneous Evidence.ACL?06.B.
Rosenfeld and R. Feldman.
2007.
Clustering for unsu-pervised relation identification.
CIKM?07.P.
Turney, M. Littman, J. Bigham, and V. Shnayder.
2003.Combining independent modules to solve multiple-choice synonym and analogy problems.
RANLP?03.S.
M. Harabagiu, S. J. Maiorano and M. A. Pasca.
2003.Open-Domain Textual Question Answering Techniques.Natural Language Engineering 9 (3): 1-38, 2003.I.
Szpektor, H. Tanev, I. Dagan, and B. Coppola.
2004.Scaling web-based acquisition of entailment relations.EMNLP?04.D.
Widdows and B. Dorow.
2002.
A graph model for unsu-pervised Lexical acquisition.
COLING ?02.H.
Yang and J. Callan.
2008.
Learning the Distance Metricin a Personal Ontology.
Workshop on Ontologies and In-formation Systems for the Semantic Web of CIKM?08.279
