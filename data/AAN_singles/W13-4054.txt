Proceedings of the SIGDIAL 2013 Conference, pages 349?353,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsCounseling Dialog System with 5W1H ExtractionSangdo Han, Kyusong Lee, Donghyeon Lee, Gary Geunbae LeeDepartment of Computer Science and Engineering, POSTECH, South Korea{hansd,kyusonglee,semko,gblee}@postech.ac.krAbstractIn this paper, we introduce our counseling dia-log system.
Our system interacts with users byrecognizing what the users say, predicting thecontext, and following the users?
feelings.
Forthis interaction, our system follows three basiccounseling techniques: paraphrasing, askingopen questions, and reflecting feelings.
To fol-low counseling techniques, we extracted5W1H information and user emotions fromuser utterances, and we generated system ut-terances while using the counseling techniques.We used the conditional random field algo-rithm to extract 5W1H information, and con-structed our counseling algorithm using a dia-log strategy that was based on counselingtechniques.
A total of 16 adults tested our sys-tem and rated it with a higher score as an in-teractive communicator compared with thebaseline system.1 IntroductionOver the past 45 years, suicide rates have in-creased by 60% worldwide.1 To prevent suicide,suicide people need to counsel with counselors.However, counseling with a human counselorrequires a substantial cost, and in addition, thereis a location restriction.
Developing a counselingdialog system could be an effective solution toaddress this problem because the system has nolimitations with respect to time and location.In this study, we present a counseling dialogsystem.
The system interacts with users by rec-ognizing what the users say, predicting the con-text, and following the users?
feelings.
We usedthree counseling techniques for our system, tointeract with the users.
The system performs par-aphrasing, asks open questions, and reflects feel-ings.1http://www.who.int/mental_health/prevention/suicide/suicideprevent/en/Paraphrasing is a technique that paraphrasesuser utterances.
For example, when a user utter-ance is ?My dog picked up the ball?, then itcould be paraphrased by ?Oh, your dog pickedup the ball?.
The technique of asking open ques-tions is to ask some questions to the user, to ob-tain more information.
For example, when a usersays ?I played computer games?, then the coun-selor could say ?When did you play??
or ?Wheredid you play??.
Finally, reflecting a feeling is asimilar technique to paraphrasing, but it includesemotional comments.
For example, when a usersays ?My dog died.
I?m so sad?, then the counse-lor could say, ?Oh, your dog died.
You look de-pressed.?
or ?You look so sad?.In our approach, we extract 5W1H (who, what,when, where, why, how) information and fourbasic emotions (happy, afraid, sad, and angry)from user utterances.
We generate system utter-ances using 5W1H information and basic emo-tions.2 Counseling TechniquesCounselors show empathy with clients by listen-ing and understanding them.
Clients feel com-fortable by a counselor?s attention.
Counselorslisten, ask questions, answer questions, and con-centrate on clients.
Attention and empathy is im-portant for counseling.
Counselors show interestand care about the clients?
emotions.
Our coun-seling dialog system also focused on attendingand empathy.Many counseling techniques are used in coun-seling.
Basic attending, self-expression, and mi-cro-training skills are introduced in Theron et al(2008).
Basic attending and self-expression skillsare about non-verbal behavior, such as tone ofvoice and eye contact.
Micro-training skills arethe basic verbal counseling techniques that arelearned for counseling beginners: open andclosed questions, minimal encouragement, para-phrasing, reflection of feelings and summariza-tion.349We chose three micro-training skills to attendand show empathy with clients.
These skills areopen questions, paraphrasing, and reflection offeelings because they are basic techniques toshow emphasize effectively.3 Related WorkThe SEMAINE project aims to build a SensitiveArtificial Listeners (SAL) ?
conversationalagents that are designed to interact with a humanuser through robust recognition and the genera-tion of non-verbal behavior (Schr?der et al2008).
This system detects user emotions bymultimodal sensors (camera, microphone).
Avirtual face in this system shows facial expres-sions based on user emotions, and it encouragesthe user to speak by reacting and asking ques-tions.
These techniques could show empathywith users.
However, it has limited verbal skillsbecause SEMAINE does not have language un-derstanding module.
In our research, our systemfollows user utterances and generates system ut-terances based on user?s 5W1H.4 Data CollectionWe generated 4,284 utterances by using fifty-three 5W1H information sets and four basicemotions (Figure 1).
Each utterance could begenerated by using part of the 5W1H informationand four emotions.Wh When Where What How WhyMyomYesterday Park Key LostHer pocketwas puncturedEmotionSadMy mom lost key yesterday.Yesterday, my mom lost key at the park.Sadly, my mom lost key yesterday.My mom lost key because her pocket was punctured.Given SituationCollected CorpusFigure 1.
Counseling Corpus Collecting ProcessWe tagged each 5W1H element in each utter-ance and the user intention for each utterance(Table 1).
The system?s actions were labeled byfollowing counseling strategies which will bediscussed in section 5.3.Tagged Corpus User Intention System Action<who>My mom</who> <how>lost</how> <what>akey</what> <when>yesterday</when>.Inform_5W1H Ask_Open_Question<when>Yesterday</when>, <who>my mom</who><how>lost</how> <what>a key</what> at the<where>park</where>.Inform_5W1H Paraphrase<who>My mom</who> <how>lost</how> <what>akey</what> <when>yesterday</when>.
I?m so sad.Inform_5W1H_EmotionReflect_FeelingI?m so sad.
Inform_Emotion Reflect_FeelingThank you.
Thank WelcomeGood bye.
Bye ByeTable 1.
Corpus Tagging ExamplesUser intentions we defined can be separated intwo groups: ?counseling?
and ?others?.
Utterancesin ?counseling?
group include 5W1H informationor emotional information.
Utterances which donot including them are in ?others?
group.
Greet-ings, thanks, and farewells are included (Table 2).Couns ing group Others groupInform_5W1H,Inform_emotion,Inform_5W1H_emotion, ?Thank, Bye, Greeting, Agree,Disagree,?Table 2.
Two Separated Groups of User Intentions5 Method5.1 ArchitectureOur system architecture is given in graph 2.When a user inputs a sentence, a natural lan-guage understanding (NLU) module understandsthe main action (the user?s intention) and extractsthe 5W1H entities from the user?s utterance.
Theemotion detection module detects the user?semotions using the emotional keyword diction-ary.
The dialog management module decides thesystem?s action from the main action and the5W1H information from the trained module fromthe example dialog corpus.
The natural languagegeneration (NLG) module generates the systemutterance using a system utterance template.
Wecan generate the system utterance by replacing5W1H slots with entities.UserNaturalLanguageUnderstandingDialogManagerNaturalLanguageGenerationDialogTemplateEmotionDetectorOutputEmotionalKeywordFigure 2.
Counseling Dialog System Hierarchy3505.2 Natural Language UnderstandingIn our approach, the NLU module understandsthe user utterance by classifying the main actionand the 5W1H entities from the user utterance.To classify user intention, we used maximumentropy model (Ratnaparkhi, 1998) trained on alinguistically motivated features.
We used a lexi-cal word features for the utterance model.
Thelexical word features are lexical trigrams usingprevious, current, and next lexical words.
To ex-tract 5W1H entities, we used a conditional ran-dom field (CRF) model (Laffery et al 2001).We also used lexical word features (lexical tri-grams) to train model.5.3 Dialog Management with CounselingStrategyWhen we extract 5W1H information or useremotions, the dialog management module keepsthem in the emotion slot or in the six 5W1H slots.This slot information is discussed in a dialog.The dialog management module decides thesystem?s action by the main action, the 5W1Hentities, and the user?s emotions.
Dialog man-agement follows the rules in figure 3, which isour dialog strategy for the counseling system.
Infigure 3, ?Counseling group??
node finds usersintentions included in ?others group?
(rejection orthanks could be included).
The ?User EmotionDetection?
node figures out whether the user ut-terance is to include emotional keywords orwhether the user emotion is already known bythe discourse.
The ?6 slot empty?
node checkswhether the user utterance includes at least oneof the 5W1H elements or whether the 5W1H en-tity is already known.
The ?6 slot full?
node de-cides whether the user utterance with a discoursehas all six 5W1H entries.
From this strategy, wecan notice that we cannot reflect a user?s feelingwithout the user?s emotion.
We cannot ask openquestions when all of the 5W1H slots are filled.YesNoNoNoNoNoYesNoYesYesYesYes6 slotempty6 slotfull6 slotempty6 slotfullCounselinggroup?UserUtteranceUserEmotionDetectionParticularSystem ActionsAsk OpenQuestionReflectFeelingAsk OpenQuestionReflectFeelingParaphraseAsk OpenQuestionParaphraseReflectFeelingParaphraseAsk OpenQuestionParaphraseFigure 3.
Dialog Strategy Architecture5.4 Emotion DetectionThe emotion detection module decides the user?semotion with respect to the four basic emotions.To detect the user?s emotions, we find emotionalkeywords in the user?s utterances.
If any emo-tional keyword appears in a user utterance, wedecide that the user?s emotion which includesthat keyword.
For this approach, we made a dic-tionary of emotional keywords for each basicemotion.
The dictionary has approximately 15emotional keywords for each basic emotion (Ta-ble 3).E otion KeywordsHappy happy, joy, glad, pleasure, ?Sad sad, depress, grief, sorrow,?Angry anger, rage, indignation, wrath, ?Afraid afraid, fear, terror, dread, ?Table 3.
Emotional Keywords for Emotions5.5 Natural Language GenerationThe NLG module generates the system?s utter-ances by selecting an utterance template from thetemplate database.
There are various systemtemplates for each system action, for the 5W1Hslot entities, and for the user?s emotions (Figure4).
When the system template is chosen, we cangenerate system utterances by replacing the5W1H slot with a 5W1H discourse.
?O?
meanswe should have the entity, ?X?
means we do nothave the entity, and ?*?
means we do not carewhether we have the entity or not.Who When Where What How Why Emotion System ActionO X O O O X O Reflect EmotionO X O O O X * ParaphraseSystem Action System TemplateReflect Emotion Oh, <who> <how> <what>.
You look so sad.Paraphrase Oh, did <who> <how> <what>?System UtteranceOh, your mom lost a key.
You look so sad.Oh, did your mom lost a key?Who When Where What How WhyMymomYesterday Park Key LostHer pocketwas puncturedEmotionSadFigure 4.
System Utterance GenerationOur overall counseling dialog example is shownin (Table 4).351User My mom lost a key yesterday.System Oh, where did you mom lost a key?User At the park.System Your mom lost a key at the park, right?User Yes, that?s right.
I?m so sad.System You look so sad.
Cheer up.User Thank you.System My pleasure.Table 4.
Counseling Dialog Example6 ExperimentWe measured how systems show empathy withusers.
Our baseline system is a Korean chat-oriented dialog system (Kim et al 2012).
Thechat-oriented dialog system shows empathy byunderstanding user utterances and making a con-versation.
In our experiment, 7 basic situationsare given for each person.
Situations are ex-plained by 5W1H, and users generated variousutterances using that information.
Each persongenerated approximately 100 utterances during30 minutes and made estimates for each system.We recruited 16 volunteers to use our system andto estimate its effectiveness.
Each user checked17 questions from 1 to 10.
The questions ask us-ers how does each system understand the userutterance, is it appropriate for counseling, anddoes it satisfy the users (Table 5).QuestionChat-OrientedCounseling1-1.
The system used counseling techniques:paraphrasing, open question, reflect feeling.3.50 7.061-2.
The system knows my emotion.
3.44 6.881-3.
There was no break in the conversation.
2.63 6.881-4.
The system acts like a counselor.
2.88 6.691-5.
The system shows empathy with me.
4.69 7.311-6.
I feel the system understands me.
2.56 6.502-1.
The system understands what I said.
2.88 6.812-2.
The system understands 5W1H information.
4.13 7.442-3.
System utterances are appropriate.
2.75 6.942-4.
System utterances have no problem.
3.50 5.503-1.
I could speak about various situations.
4.31 6.383-2.
I had a casual conversation.
4.75 6.883-3.
Scenarios look expandable.
5.50 7.634-1.
I satisfied overall conversation.
3.10 6.564-2.
I satisfied overall counseling.
2.38 6.564-3.
The system looks appropriate as a counselor.
2.50 6.384-4.
I?ll recommend the system as a counselor to myfriends.2.31 5.38Mean 3.40 6.69Standard Deviation 0.96 0.59Table 5.
Experiment ResultsQuestions 1-1 to 1-6 ask users how each sys-tem is appropriate as a counselor.
Counselingsystem rated 6.89 for mean.
Questions 2-1 to 2-4are about users?
tterances understandability.
Inthese questions, counseling system rated 6.67 onthe average.
Questions 3-1 to 3-3 show how var-ious dialogs covered.
Our system got 6.96 formean.
Finally, questions 4-1 to 4-4 are aboutoverall satisfaction.
These questions rated 6.22for mean.
Our p-value through t-test was3.77*10-11.Counseling system got higher score than chat-oriented system because users felt empathy betterwith our system than baseline system.
As a coun-selor, counseling system is much better thanchat-oriented system.
Our baseline system wasnot appropriate as a counselor because it rated3.39 for average.
However, our system scoredover 6.5 overall.
It means our system is valuableas a counselor.7 ConclusionIn this study, we introduced counseling tech-niques that we used to implement counselingdialog system.
The experimental results showedthat our system shows empathy with users.
Alt-hough the results of this study bring us a stepcloser to implementing counseling dialog system,the results are only valid with 5W1H informationin Korean.
Our future works are to improve ourcounseling dialog system using new NLU mod-ule which extracts 5W1H information from moregeneral utterances, with new emotion detectionmethod, and with more counseling techniques.AcknowledgmentsThis research was supported by the Basic Sci-ence Research Program through the National Re-search Foundation of Korea(NRF) funded by theMinistry of Education, Science and Technolo-gy(2012-0008835).This research was supported by theMSIP(Ministry of Science, ICT&Future Plan-ning), Korea, under the ITRC(Information Tech-nology Research Center) support program super-vised by the NIPA(National IT Industry Promo-tion Agency) (NIPA-2013-H0301-13-3002)ReferencesKim, Y., Noh, H., & Lee, G. G. (2012).
Dialog man-agement on chatting system based on lexico-syntactic patterns and named entity types.
Proceed-ings of Spring Conference of Korean Society ofSpeech Sciences, 41-42,  Seoul, Korea.352Lafferty, J., McCallum, A., & Pereira, F. (2001).Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.Proceedings of the 18th International Confer-ence on Machine Learning, 282-289.Ratnaparkhi, A.
(1998).
Maximum entropy modelsfor natural language ambiguity resolution.Computer and Information Science, Universityof Pennsylvania, Philadelphia, USA.Schr?der, M., Cowie, R., Heylen, D., Pantic, M., Pe-lachaud, C., & Shuller, B.
(2008).
Towards re-sponsive sensitive artificial listeners.
Workshopon Human-Computer Conversation, Bellagio, Italy.Theron, M. J.
(2008).
A manual for basic relationalskills training in psychotherapy.
Masters of Artsin Clinical Psychology, University of South Africa,South Africa.353
