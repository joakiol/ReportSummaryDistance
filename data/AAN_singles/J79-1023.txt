b r i c t m  Journal of C~mputat~~nal  l$ingui~tio Microfiche 23C o p y r i g h t  1 9 7 5  by t h e  A s s o c i a t i o n  for.
~ompufational L i n g u i s t i a sA U T 0 N 0 T E 2 : NETWORK MEDIATEDNATURAL LANGUAGE COMMUNICATIONIN A PERSONALINFORMATION RETRIEVAL SYSTEMWilliam E. Linn, Jr .
2andWalter ReitmanUpiversity of MichiganAnn Arbor1 T h i s  paper is based on a doctoral disserfiation by the first author.
Supportfrom the iUationai Science Foundation under ~ r m t  'No.
DCR71-02038 is gratefullyacknowle8ged.
Those wishing more mmplete details about sys tem c a d s  andimp.tomentatioa should,write the s-d author for a User's Manual.2 lVow a t t  southern Railway System, 125 Spring Street,  S .
W., Atlanta, Georgia 30.303ABSTRACTNatural language combinesnOuns and adjectives into noun phrases,, andlinks phrases by means of.p,repositions to form complex descriptiops ofobjects and topics.
AUTONOTEZ, a file-orsented retrieval systeq, allowsthe user to employ such descriptions to characterize the items of informa-tion he wishes to store and retrieve.
Tn addition.
the system also cm-structs a network qpresentation of the user's sub3ect matter, using syntac-tic analysis to  derive dependency structures fxhn h h  descriptions.
Thedepe~dency information, expressed as subordinate and coordinate linkagesamong the phrases, is representea by a tree of nodes, with simple phrasesa t  the terminalbranches.
The PARSER uses the network to digambiguate dewcriptions, querying the user only a b h t  regidual ambiguities.Associated with the PARSER is a network LOCATOR, which determineswhether a ckrent user description refers to an existing topic at some levelin  the network.
The LOCATOR also builds a table specifying t;he changes, ifanp, to be mede in a network in order to represent the topicdnferred fromthe current input description.
For example, if the user's description con-tains one or more simple phrases (thereafter referred to  as active) directlydescribing at least one existing node in  the network, the description as awhole quite likely references an exssting network topic.
To locate 1t, thePARSER fgrs't deterdaes tlie - focus phrase, the active phrase at the highestdependency level.
The nodes directly described by the focus phrase arew e d  to generate candidate topice.
These then are matched against theremaining active phrases obtained from the description to determine themost l ike ly  referent.Manp gf the procedures employed in dsScription and representation alsoare wed in network-mediated' retrieval.
The user may* in i t iate  retrievalwith a FIND comm~nd, supplying a descripti~n as afgument.
The resultantphrase table is passed along to the network LOCATOR, which returns a nodentllhber to the FIND processor.
The FIND processor constructs a set of i t e mnumbers by extracting the tkxttral  refereaces from the node.
The systemthen checks for upward pointers from the node.
If there ars.tm.-uctura~lyxelsted topics, the FIND processor so informs the user.
Note that by virtueof netwprk midiation of retrieval, i f  a user descr ipt ion  Ys imprecise orincorrect, the systemmay be able t o  direct the user to relevant relatedtopics.meri the system queries the user about a topic, f o r  example to deter-mine the intent-of a descriptPon, the eapic node number is passed to aSPEAKER component.
A phraeal description of the node is returned.
Tominimize redundant c m i c a t i o n ,  a level indicator  may Qe set according tothe level of &tail in the user's description.
For example, if the userdescribes an item as RESULTS OF TBE WPERIMWT and the systemamst ask it hei n  rezerring t o  SMITH'S EXPERIMENT ON SHORT TERM MEMIRY OF WHITE RATS,the resulting query would be: ARE YOU W R R I N G  TO SMITH'S EXPERIMENT ONW O R P ?Cmetruct5on of a desclr;iption from the network takes place in mobstages.
The fitst stage steps thorugh the network recurs&vely, collectingthe e i q l e  phrases that directly or indirectly describe fhe speoif ied node.The l e v e l  indicator blocks collection of simple phrasee below the specifiedlevel.
The second stage is carried out by a recursive algorithm thatoperaqes on the tabled simple phraygs and their interrelations to constructthe phrasal description.The last major component of the system handle6 network modificationand reorganization.
This enables the user t o  add or remove references andphrases, and t o  modify,, delete, or reorganize h i s  t o p i c  structure.A de ta i l ed  ease study comparing AUTONOTE2 with a good keyword-basedretrieval aystxm showed that fol: a coherent body of material, the comuni-cati,ve efficiency 0% AUTONOTEL, as measuredfbp the ratio of the number o fpords conveyed to the number of words entered, was more than double that ofthe kyword-based system.
Retrieval capability was enhanced considerably,and the tepresentati~n dewqrk effectxvely distinguished among the manytopics partially indexed by the same words.
Furthermore, SPEAKER output oftopics from the rep~esentatiorral network proved a useful retrieval inter-mediary, greatly reducing the need fo,r perusal of i t e m  texts.TABLE OF CONTENTSPageI .
AUTONOTI?
SYSTEM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Basic~~ONOTECommands~  10. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
AUTONOTE System Organization 14. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
111 .
QVER~IEWOFAUTONOTEZ 16. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
The Descripaoh Languagk 1 7. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Representational Framework 19. .
.
.
.
.
.
.
.
.
.
.
.
.
Criteria for the Representation 19. .
.
.
.
.
.
.
.
.
Overview o f  the AUTONOTE2 Implementation 24Design of the Network Data Structures .
.
.
.
.
.
.
.
.
32. .
.
.
.
.
.
.
.
.
.
Storqge Implementation of the Network 37The Repfesentational Network: An Example .
.
.
.
.
.
.
.
40. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Parsing OF Descriptions 40VI .
N E T W O R K ~ I A T E D B E T R I W A I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68Retrieval via Descriptions, .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68Interrogating the Wetwork .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
71. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
!be S P U R  Component 73Page.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
VXT .
I ' T E ~ ~ O R K  MODIFICATION 78. .
.
.
.
.
.
Adding Refetences and Phrases to the Network 79. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Moving through the Network 81. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
The Caching F a c i l i t y  81. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
RetrievalCommands 82Removing References and Phrases from the Network .
.
.
82Topic Deletion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82. .
.
.
.
.
.
.
.
.
.
.
Creating New Topic Representations 86. .
.
.
.
.
.
.
.
.
.
.
.
.
.
VIII .
A CASE STUDY OF SYSTEM PlERFORMANCE 87. .
.
.
.
.
.
.
The Inapplicability of Recall and precision 87. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
The Sauvain Data Base .
.
.
88. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Results 88. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Conclusion 9 4. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
REFERENCES 97I.
INTRODUCTIONWhen two humans communicate, each party builds  up a conceptual represen-t a t i on  of the  topics  of discussion.
Such repreqentations are fundamental t ohuman cormrmnicat%~e fficiency.
The l i s t e n e r '  s representat ion of the  topicsalteacly discussed f a c i l i t a t e s  communication i n  t h a t  t he  speaker i s  sparedthe trouble of describing i n  complete detai l  those t h b g s  t o  which he re fe r s .Furthermore, the speaker can proceed to related top ics  without having t odescribe them in full.
For example, a speaker who has been ta lking about thedesign of a particular experiment can safely move on t o  discuss the  resultsof the experiment without specifying anew the experiment he has i n  mind.We use the term r e f e r e n t i a l  communication t o  indicate  the process bywhich a speaker communicates a reference t o  some subject  or top ic  t o  al i s t ene r .
ff within the envirbnment of a personal information system, wev i e w  t h e  information universe as a collection of textual materials  eachII per t inent  to one o r  more topics," then one can readi ly  construct an analogy,The user  and system take on the  r o l ~ ~ s  of speaker and l i s t e n e r ,  respectively.The domain of discourse is a set of topic descript ions characterizing thet he r ' s  t ~ t u a l m a t e r i a l s ,  The user en te r s  his materials and describes t othe system the topic or topics t o  which they pertain.
Durlng t h i s  process,the system constructs its - represiintation for the subjec ts  the user  hasdescribed, and associatgs each piece of text with its, corresbonding top icrepresentations.This paper describes the design and implementation of a personal infor-mation storage and retrieval system based on the  foregoing analogy w i t hhuman referential communication.
It presents a hierarchical network datastrqcture foe representing topic descriptions formulated within a phrasaldescription language.
~alied the representational network, this structureenables the system to move easily from one Bubject to other  elated ones.It provides a means for representing the user's working context, therebyenabling the user to describe his materials much more tersely than is possi-ble in keyword-based systems.
The system makes use of the syntactic depen-dencies among the words and phrases of descriptiops in or'der to representstructural relationsh'ips among the user's topics.
Consequently, the userimpaats structure to the data base in a particularly natural way, eliminatingmuch of the organization activity normalb associated with keyword-basedsystems.
Our central thesis is that the network mediated techniques providefor m z e  effective mawmachine communication during the processes of des-cription, organization, and retrieval within a personally generated informa-tion universeThe procedures used here differ substantially from the typical keywordindexing and retrieval mechanisms of other personal retrieval systems.
Thecentrab objective is to provide the user with framework for defining theimportant topics or informational objects he deals with, and to enable him toeasily associate items in his data base with these entities.
Rather thanviewing the data base as a collection of items and associated index terms,the user deals with "objects" thet are in some sense meaningful to him.Whether retrieving information or indexing new material the user conveysreferences to the appropriate topics.
This shift in the user's view of hisinformation universe, coupled with the mechanisms we have developed forbuilding up and re fe r r ing  t o  the  top ic  framework, oons t i tu t e  the substanceof our approach t o  personal information s torage and r e t r i e v a l .11.
THE AWONOTE SYSTEMThe system described here uses the  AUTONOTE information storage andr e t r i e v a l  system (Reibnan - e t  -.
al 9 1969) as a base.
AUTONOTE is an on-liner e t r i e v a l  system t h a t  runs a& a user program under the  Michigan TerminalSystem (MTS) , a time-oharing system implemented on t h e  IBM 370/168.
Thebas ic  u n i t s  o f  information s tored i n  AUTONOTE a're ca l l ed  items.
The usermay en te r  a r b i t r a r y  t e x t u a l  mater ia ls  i n t o  an item and may assign d e s c r i p m r sby whfch these mater ia ls  can be re t r ieved.
Ret r ieva l  requests  take t h e  farm~f s ing le  descr iptors  or combinations o f  descr ip tors  connected by AND, OR, 9sNOT l o g i c a l  operators.
F a c i l i t i e s  a r e  provided f o r  de le t ing ,  replacing,l inking,  and h ie rarch ica l ly  organizing text i t e m & .AUTONOTE makes extensive use of the WS d i sk  f i l e  sys tem EiflIS diskf i l e s  ( l ine  f i l e s )  may be read o r  wr i t t en  either sequent ia l ly  o r  i n  an indexedfashion by specifying a l i n e  f i l e  number.
AUTONOTE maintdins two l i n e  f i l e sfo r  each user's data base; one f o r  storing t ex tua l  mater ia l s  and bookkeepinginformation, the  o ther  f o r  s t o r i n g  a descr ip tor  index.
Each t e x t  i t e moccupies a s p e c i f i c  region of the  l i n e  number range of the  t ex t  f i l e .
Thedescripfor index, on the  other hand, is accessed through an e f f i c i e n t  hashcoding algorithm t h a t  mdps each descr ip tor  i n t o  an index f i l e  l i n e  number.The descr ip tor  index i s  organized a s  an inverted f i l e ,  t h a t  is ,  each l i ne  i nthe index contains poin te rs  t o  each of the  t e x t  items assigned the  descr ip torf o r  t h a t  line.Basic AUTONOTE CommandsText entry ,  To e n t e r  a new text i t e m ,  the  user  f i r s t  types the  commandENTER and the  eystem responds with a numerical t ag  f o r  the new i t e m .
Thesystem then e n t e r s  a "lext i n s e r t i a n  mode" and i n d i c a t e s  its readiness t oaccept successive text lines with a quest ion mark.
Aftex enter ing  text,, theuser may re tu rn  t o  "command mode" by enter ing a n u l l  l i n e  o r  an end-of-fileindicat ion,  Should the  user  a t  any t i m e  wish t o  continue i n s e r t i n g  t e x t  i n t othe current i t e m ,  he may re-enter t e x t  i n s e r t i o n  mode via the INSERT cormnand.Subsequent l i n e s  are placed below the most recent  l i n e  f o r  the  current  i t e mi n  the text  file.In command mode, the  system prompts the  user  for  input  with a minus sign.The user may give each command i n  f u l l  o r  he may abbreviate by giving anyi n i t i a l  subs t r ing  of the command name.Descriptor entry.
To as soc ia t e  one o r  more desc r ip to r s  with the  currenttext i t e m ,  the user  en te r s  a list of words, beginning the  input  l i n e  with ana t  sign (@).
Any character  s t r i ng  up t o  16 characters  i n  length may be usedas a descr iptor .
kn addi t ion  t o  updating the descr ip tor  index, t h e  systema l s o  places the  actual "@-linet' i n  the t e x t  file i n  a subregion beneath t h etext a?
che current  item.Retrieval, To display a p a r t c i u l a r  t e x t  i t e m  the  user  may en te r  thecommand PRINT followed by the  appropriate item number.
Sequential blocks ofitems can a l s o  be specif ied i n  the PRINT commapd, & g o ,  PRINT 77...85.In most cases, however, the spec i f i c  i t e m  number(s) w i l l  not be known.The LIST command accepts a descr ip tor  o r  log ica l  combination of descr ip torsas its argument and ~esponds  with a  list of the i t e m  numbere t h a t  satisfythe.
query.
The functions of the  PRINT and LIST commands are combined i n  theRETRIEVE7command.
It a l s o  takes a descriptor spec i f i ca t ion  Be argument andcauses each i t e m  .
i ~  the resu l t ing  list t o  be PRIWed.Defini t ional  f a c i l i t y .
AUTONOTE a l s o  provides a de f in i t i ona l  f a c i l i t yt ha t  allows the user t o  create sets of items referenced by a r b i t r a r y  com-binations of descriptors.
For example, the c o m n d  CREATE SIRS= INFORMATIONAND RETRIJ3VA.L AND SYSTEMS adds a new descr ip tor ,  SIRS, t o  the  index t h a treferences each i t e m  having the words INFORMATION, RETRI~vAL, and SYSTEMS asdescriptors.
Any defined term may be used just as any other  descr iptor  i nr e t r i e v a l  requests;  they m y  also be used to def other  new terms (e,g.,CREATE $OTHERSYSTEMS= SIRS NOT AUTONOTE) .The definitYona1 f a c i l i t y  is also invoked impl ic i t ly  each time the useri ssues  a r e t r i e v a l  query.
The set of items referenced by the most recentLIST or RETRIEVE command, cal led the ac t ive  s e t ,  i s  assigned the name $,Should the user wish t o  r e f i n e  the r e s u l t s  of the  previous query, he hasaccess to the active set.
To f a c i l i t a t e  t h i s  process, each t i m e  a missingdescr ip tor  is noted i n  a r e t r i e v a l  request  the descriptor $ is inserteda u t o ~ & L c a l l y  by the  system.
For example, the  command LIST NOT FPRT i sInterpreted as LIST $ NOT FROTRAN, i.e., the  old ac t i ve  set of items isrestricted t o  include only those not referenced by the  descr ip tor  FQRTThis operation, of course, redefines the active set.Item-iteq l i n k a e .
The a b i l i t y  to define a s s o ~ i a t i v e  l i n k s  betweenany two t e x t  items is provided by t h e  APPEND command.
When an i t e m  is  dis-played, its assoc ia t ive  l i n k s  t o  o the r  items may opt iona l ly  be pr in ted  alongwith a user-lspecified comment ind ica t ing  the na tu re  of the  assocLation.Tu to r i a l  feature.
Throughout the course of i t s  development, AUTONOTEhas been employed t o  c o l l e c t ,  organize, and maintain up-to-date documentationaf i ts  c a p a b i l i t i e s ,  usage s t r a t e g i e s ,  and s o  ono This information is storedi n  a pub l i ca l ly  ava i l ab le  da ta  base.
It includes b r i e f  desc r ip t ions  of ea&of t h e  commands, announcements of recent  developments and system changes, ando t h e r  i n s t r u c t i v e  information.
The AUTONOTE u s e r  may ca l l  upon t h i s  s t o r e  ofw t e r i a l  by enter ing  a HELP command.
The user  s d a t a  base is  temporarily seta s ide  and the publ ic  data  base i s  attsebed t o  t h e  system.
The use r  may thenr e t r i e v e  i n s t r u c t i v e  informakion i n  the same way t h a t  he operates  wi th  h i sown da ta  base.
To a s s i s t  novice users ,  t he  system will opt iona l ly  p r i n ti n s t r u c t i o n s  f o r  accessing t h e  HELP da ta  base.Grouping.
AllTONOTE provides a grouping f a c i l i t y  which permits  the  usert o  organize t e x t  items i n  severa l  use fu l  ways.
It enables the  user t o  def inea "grouping item" which references  an a r b i t r a r i l y  ordered list of o ther  itemsThis is done by entering i n t o  an item an @-line o f  the form:Since apy item can represent  a g+oup, *it i s  poss ib le  t o  form a complex hier-a r c h i c a l  s t r u c t u r e  in t h i s  way.A grouping item can be viewed as a node of an inver ted tree s t r u c t u r ew;ith downward b ranJ le s  t o  those items l i s t e d  i n  i t s  "@GROW" l i n e .
A requestto  display a grouping i t e m  i n i t i a t e s  recurs ive  processing of t h e  t r e estructure to identify the terminal ad& nonterminal f terns of the hierarchy.The user may request tha t  only terminal or',nonterminal items,be displayed,or t e entire list of materials be printed,The organization of the HELP data base described above provides anexcellent example of the pmer and flexibility of the grouping f a c i l i t y .The HErJe text filelcontains a t  this wri t ing approxinrstely 150 %terns ofdocumentation.
Using the grouping conventton, these are orgaritzed i n tofive subgroups: (1) general #nf ormation; (2) input and editing facilities ;(3) output (retrieval) facilities; (4) organizational facilities; and (5)utflity compands.
Thme-is; one major item which groups all of these aub-grottps into a single tree structure.
The top node of the strusture isindexed by the descriptor USERS-MANUAL.
As new facil it ies  are incorporatedinto the system, their descriptions are entered .Into the manual structure,thus assuring that complete and up-to-date documentat$..on is always avail-able.
A t  any time, the single command: RETRIEVE U S E R S - W A L  causes theentire updated data base to be displayed in  organieed fom:Command modifiers.
AUTONOTE lacJudes a set of modifiers or optioneettings that control the execution of many c ds.
These include optionsthat affect the format o f  displayed items, the etlrpanslon of grouping atruc-tures, the nature and extent of system feedback, etc.
E&ch 0-f the modifiershas a default.
value that i s  chosen to  simplify use of the system by anovice.
The more experienced user may alter the modifiers via the SET cmand to.
tailor the system to hie awn needs, usage patterns and h v e l  ofcompetence.AUTONOTE also provides a large number of auxillary commands and f a c i l i -ties.
A list of the major AUTONOTE commands, each accompanied by a briefdescription, is incldded in Linn (1972, Appendix A).AaTONOTE S m OtganizationAUTONOTE l-@s been des gned as a modular system SQ that as new faci l i -ties become a~ailable~they may be tested and later added with' little or noreprogramming of the exjgting system.
The majority of AUTOMOTE coare fmplemented as subroutines, each of which resides permanently in an MTSdisk f i le .
The basic system $s organized around a central monitor thataccepts user input and calls upon appropriate modules to service the user'srequests.
In addition to the monitor, the core resident system includes adynamic loader, a disk file interface and a set of frequently used utilityroutines.
A number of pridtive commands, text entry, and descriptor assign-ment are qlso handled by the resident system.
As the user =quests morecbmplex sentices (LIST, RETRIEVE, or PRINT, Ear example), the monitor callsupon the* dynamic loader to bring the appropriate modules into core storage.These routines then becoke a part of the resident system, remining in wreetorage until the user explZcitly requests their removd.
An organizationaldiagram of the AUTONOTE system appears i n  Fig.
1.The modular design of AUTONOTE coupled wtth the dynamic loading facilityoffers two important benefits.
From the user s viewpoint, he has access tothe complete repertory of AUTONOTE seMces, yet he pays core storagecharges only fm those routines he actually uses during a given session.To the developers of the system, the modular framework f a c i l i t a t e s  theSTORAGEmUT/otrrPUTROUTIWSJAdMONITORLYIMMIC LOADER I(COMMANDINTERPRErnR)sPROCESSORFig, 1 - AUTONOTE System Organizationaddition of new system components.
The latter has been an important factorin the implementation of the AUTONOTE2 system.111, OVERVIEW OF AUTONOTE2The AUTONOTE2 system uses ideas (Reitman, 2965; Reitman - et -* a1 9 1969)concerning the use of our "knowledge of the world" to clisambiguate and fillin implied facts when conversing with one anathear.
Zn parti~ular, the systemdesign is based upon the assumption that efficient human communication..."depends upon the listener's ability to make inferences from prior informa-tion, from context, and from a knowledge of the speaker and the world.
Com-municating in this way, we risk occasional misunderstanding as the price foravoiding verbose, redundant messages largely consisting of material thelistener already knows" [Reitman - et -* a1 9 19691.In b u ~  mare restricted domain of discourse, we view the process of humanreferential c~unication as onq >pided by some f o m  of internal rapresenta-tion of the various topfqs or referents discussed earlier.
When a listenercan be assumed to have such a representation, the speaker is spared the dif-ficulty of describing in complete detail the things to which he refers.
He;need only give enough information to allow the referent to be discerned infull.
Our goal then is to develop a represenratlonal scheme for our retrievalsystem that allows the user analogous conrmunicative efficiencies.The Description LanguageThe first step in devising a representational framework wa8 the f o m -lation of a language for expressing topic dedcriptions to the system.Although an underlying factor in the design of AUTONOTEL was to make com-It municatloh with the system more natural," it should be noted that theemphasis of this research is not upon parsing or "understanding" naturallanguage.
Rather, our goal is to investigate the notions of topic repre-sentation and referential camunication as a means f o r  improving the user'sability to describe, organize, and retrieve his materials.
Consequently,a minimal subset of noun phrases waa chosen-minimal in the sense that itexcludes most of the complexity of natural English, yet still retains adegree of descriptive richness sufficient to explore the underlying ideas ofthis study.Natural language enables us to combine nouns and adjectives i n t ~  nounphrases and to interlink noun phrases via prepositions to form complex des-criptions of objects in the real world.
The AUTONOTE2 description languageprovldes such a framework for composing topic references.
A form~l grammarfor the language is given in Fig.
2 along with a few sample descriptions thatillustrate the flexibility of expression achievable with the language.
Thesegrammatical rules are not in fact used explicitly by the system in actuallyparsing topic descriptions.
The grammar is presented here only to specifyprecisely the set of descriptions acceptable to the system.
The actualAUTONOTE2 parser i s  heuristic-based, making use of previously analyzedphrases, noun-preposition co-occurrences, and a set  of heuristics to guideqdeacrip tion> : : = (noun-group, Iknoun-group> <preposition> <description><noun-group 3 : := (<article>) (<modif ier-group) <noun>a/ <preposition> : about 1 to I from 1 in I on etc.
: := a I an I the(a) Grammar for the description language.The paper about microprogramming in the proceedings of the fall joint computerconferenceNotes on the organization of AUTONOTE2 for use in the presentation of the ACMPaperThe use of recall precision measures in the evaluation of the SMART informationretrieval systemQuotes from Peldman's 1969 paper for use in the introduction of the secondchapterb(b) Sample descriptions.Fig.
2 - The AUTONOTE2 Description Language%odif iers and nouns are arbitrary character strings not recognized asarticles or prepositions.
When a number of consecutive "words" are encountered,the last is parsed as a noun and the preceding words as modifiers.b Possessive adjectives are treated as a special case of adjectival modifi-cation.the  parsing process.
In  some ins tances ,  the  user  may even be asked f o rparsing ass is tance.Representational FrameworkCentral t o  the design of AUTONOTEZ is the  idea  of viewing the user ' sinformation universe a s  a co l lec t ion  of "informational objects" o r  top ics ,each having associated with i t  a number of t e x t  i t e m s .
When the user wishest o  describe a t e x t  item, we assume he has such a topic  i n  mind.
Using t h ephrasal  language specif ied above, he composes a descr ip t ion  of t h a t  top icand presents  i t  t o  the  system.
AUTONOTE2 then constructs  an i n t e r n a l  repre-senta t ion of t h a t  topic.
When a text  i t e m  i s  described, the system mustconsult  the representat ion t o  determine i f  t he  descr ip t ion  (1) references anex is t ing  topic, (2) is r e l a t e d  t o  an e x i s t i n g  topic ,  o r  (3) def ines  a newtopic.
In any case, the ul t imate  goal  i s  t o  assoc ia te  the text i t e m  with atopic representation, possibly augmenting the  representat ion i n  the process.Criteria for the RepresentationEfficiency of comunication, E f f i c i e n t  man-machine communication im-p l i e s  t h a t  the user  should not i n  general  have t o  formulate a complete des-c r ip t ion  of a p a r t i c u l a r  top ic  i n  order t o  convey a reference t o  i t .
Thesystem should be capable of accepting and co r rec t ly  i n t e r p r e t i n g  incompletereferefices bp f i l l i n g  i n  missing information.
A s  an example, a top ic  f u l l ydescribed as THE PAPER BY SALTON ABOUT THE SMART SYSTEM might be re fer red  t oas THE PAPER, THE PAPER BY SALTON, THE PAPER ABOUT THE SMART SYSTEM and so on.A descr ipt ion i n  the AUTONOTE2 language consists of a noun modified byadject ives  and preposi t ional  phrases.
The words t h a t  modify any given termmay themselves be modified in exactly the same way.
In effect ,  each adjec-tive and prepositional phrase functions as a phrase component that impartsgreater detail to the overall description.
In the example above, BY SALTONand ABOUT THE SYSTEM provide information about the paper; SMART specifieswhich system is meant.To facilitate efficient communication we require a representationalframework that makes explicit the component phrases of each topic description.Given such a framework, we have a basis for comparing incomplete descriptionswith the representation to determine possible topic referents.-.A system that makes use of syntax in the user'sdescriptor entries increases descriptive power in that it permits distinctionsthat, in geberal, will not be made in keyword-based retrieval systems.
A des-cription such as THE ORGANIZATION OF THE PAPER ABOUT MTS is semanticallyquite different from THE PAPER ABOUT THE ORGANIZATION OF MTS, despite the factthat both contain the same words, A system that takes into considerationthe syntactic relationships that hold among the words ORGANIZATION, PAPER,and MTS can discriminate between the two.The considerations outlined thus far lead quite naturally to some formof dependency representation for the user's topics.
Essentially, a depen-dency representation for the AUTONOTE2 language would reflect the syntacticdependence of each adjective and prepositional phrase upon an appropriatenoun.
Such a framework provides the essential information for enhancingdescriptive power and communicative efficiency as defined above.Hierarchical representations.
We view a topic as a group of intercon-nected subtopics, each bearing on a central theme yet with varying levels ofgenerality.
To make this notion more concrete, consider a user of AUTONOTE2putting down his thoughts and ideas for a book he is writing.
He begins byentering some general material which he describes simply as "THE BOOKABOUT.. .
."
At some later time he may enter an outline for the book, a listof reference materials he will use, publishing arrangements, etc.
Stilllater, he wi.11 enter materials for the chapters of his book and perhaps out-lines for each chapter, In time he will have defined a host of related des-criptions.
Fig.
3 gives a pictorla1 representation of the resultant complex"topic. "
The representational spl~eme of AUTONOTE2 was designed with complexhierarchies such as this one in mind.
In other words, we want to representrelated topic descriptions via interconnections in a network,The essential idea is that such a network corresponds to a map of theorganization of the associated textual materials--a map that should reflectimportant structural relationships among the materials from the user' s view-point.
A hierarchical representation of this kind is especially effectiveduring retrieval.
If the user requests materials dealing with h i s  book, forexample, the system can also inform him that he bas more specific items deal-ing with the publishing arrangements, the component chapters, and so on.The notion of a representational network fits well with the dependencyframework we require.
The syntactic dependencies among the words and phrasesof a description may be used to represent structural relationships among theuser's topics.
In the example above, the network connection between theOF CHAPTER 1W E  BOOKFig.
3 - A Topic Hierarchy"out line" and the "book1' corresponds to the syntactic dependency of "book"upon "outline1' in the descrip tionL THE OUTLINE OF THE BOUK ABOUT.
.
.
.Au~plentation of the repre-sentation.
In the previous discussion ofcommunicative efficiency we were concerned with associating an incompletedescription with its corresponding topic.
In designing the representationalframedork we also had to consider the cqse in which a reference provides amore detailed d'escription of an existing topic.
In such instances we want toenrich the topic represbntation to include the additional information.Whether additional descriptive information is encountered in a subsequentitem description or in a retrieval request, we want the system to incorporateit into its existing knowledge of the user's topics.
This requires that therepresentation be stmctured in such a way that dynamic augmentation is easilyaccomplished.The representation of context.
In providing a framework for interpre-ting terse, incomplete references we naturally are confronted with the problemof ambiguity.
A description such as THE PAPER, or TRE PAPER ABOUT MICROPRO-GRAMMING may in fact satisfy a large number of distinctly described topics.To deal with this problem we require some kind of contextual framework thatenables the system to infer, where possible, the intent of a vague or ambigu-ous reference.
A user who has been entering material for a paper he iswriting should be able to describe a subsequent item as,say, THE OUTLINE OFTHE PAPER, and have the system infer which paper he means.
In general then,we want the representatfonal framework to include information that identifiesthe "working- context ," i. e. , those topics the user has ref erred to recently.System interrogation of the user.
Presented with an ambiguous descrip-tion "out of context," the system is faced with much the same dilemma a humanlistener would face.
In such instances, we want the system to be capable ofasking pertinent questions to resolve the ambiguous reference.
This implies,of course, that the representation preserve sufficient information to enableit to reconstruct descriptions of the user's topics.werview of the AUTONOTE2 IrpplementationData structures.
We have now presented the major design requirementsfor the representational framework.
These preliminary criteria suggest arepresentation organized as a network of (possibly interconnected) dependencystructures obtained from syntactic analysis of topic descriptions.
The net-work data structures are- discussed in section IVin terms of the representa-tional criteria and also the computational requirements--how they are to beaccessed, modified, and so on.The parser.
The parsing of descriptions is guided by the state of therepresentation at the point they are entered.
For this reason, the parsingalgorithm is treated in section IV in conjunction with the representationaldata structures.
The&presentation includes detailed dlscussion of the parsingproblems encountered and the heuristics employed in dealing with them.Network,,locati,on.
The function of the network locator is to analyze theparse tree to decide whether the description references an existing topic ordefines a new one.
Once this decision is made, it constructs a list of anynetwork madifications required to represent the topic and its associated itemreference.
The network location algorithm is described in section V.Retrieval.
The AUTONOTE2 retrieval component is invoked via a FINDcommand.
The command takes a topic description as its argument.
The FINDprocessor in turn calls upon both the parser and network locator, regainingcontrol after the appropriate network topic has been identified.
Text itemsdirectly associated with the topic then may be retrieved from the data base.Alternately, the retrieval component will move to structurally related topicsin the representational network to collect additional item references forsubsequent display.To reconstruct topiq descriptions from the network, AUTONOTE2 includesa SPEAKER module.
If the user's description is ambiguous, for exmple, thenetwork locator may call for a display of the alternative topics.
The FINDprocessor employs the SPEAKER to present descriptions of topics structurallyrelated to the user's original query.
The user also may invoke the SPEAKERexplicitly, via a DESCRIBE comnd, to obtain descriptions of some subset ofthe topics in the representational network.
The retrieval component, theSPEAKER, and the DESCRIBE command are treated in section VI.Network modification.
The last major component obf AUTONOTEP, the net-work modification processor, is described in section VIZ.
It allows theuser to delete topic representations, create new ones, and merge multipletopics into a single representation.
It also enables the user to movethrough clusters of related topics in order to explore associations in thenetwork.Auxiliary commands.
Various auxillary conrmands and facilities are givenin Linn (1972, Appendix By.
This appendix also includes some discussion ofusage strategies for achieving the most effective use of AUTONOTE2.Fig.
4 depicts  the  organization of the  AUTONOTE2 components wi thin  theAUTONOTE system framework,IV.
THE PARSER AND THE REPRESENTATIONAL NETWORKOverviewWhen the  user  wise$ t o  descr ibe  a t e x t  i t e m ,  w e  assume he has i n  mindsome subjec t ,  topic ,  o r  informational object t h a t  can be characterized by aphrasa l  descript ion.
A descr ip t ion  may convey a r e f e e n c e  t o  a t o p i c  the  userhas d e a l t  with earlier; o r  i t  may def ine  a new one.
The descr ip t ion  is ana-lyzed t o  determine a dependency tree--a s t r u c t u r e  that preserves the  o r i g i n a lwords and phrases of the  descr ip t ion  and the  s y n t a c t i c  dependencies amongthem.In  constructing t h i s  tree, the parser  incorporates primary u n i t s  ca l ledsimple phrases.
A simple phrase may cons is t  of a modifier and a noun (e .g.,ACM CONFEFUNCE), o r  of a noun followed by a preposi t ion and modifier (e.g.,OUTLINE OF PAPER).
The parser  e x t r a c t s  these b a s i c  phrases from t h e  o r i g i n a ldescr ip t ion  and records t h e  s y n t a c t i c  dependencies among them.
A descr ip t ionsuch as THE OUTLINE: OF THE PAPER ABOUT AUTONOTE2 FOR THE ACM CONFERENCE willbe analyzed i n t o  four  simple phrases: (1) THE OUTLINE OF THE PAPER, (2) THEPAPER ABOUT AUTONOTE2, (3) THE PAPER FOR THE CONFERENCE, and (4) THE ACM CON-FERENCE.
Each simple phrase cons i s t s  of a subjec t  noun and a modifier word.When two simple phrases have a common subject  noun, w e  say they a re  coordin-ate simple phrases.
When a modifier word of one simple phrase subsequently-becomes the subjec t  noun of another,  we say the latter phrase is  subordinateDESCRIPTIONPROCESSORFig.
4 - The Organization of AUTONOTE2 @thin the AUTONOTE Systemt o  the former.
In  the above example, THE PAPER ABOUT AUTONOTE2 and THE PAPERFOR THE CONFERENCE are coordinate simple phrases--both have PAPER a s  the i rsubjec t  noun.
Both of these  a r e  subordinate t o  the phrase OUTLINE OF THEPAPER, i n  which PAPER appears a s  a modifier word.
Additioaally, the  simplephrase THE ACM CONFERENCE i s  subordinate TO THE PAPER FOR TWE CONFERENCE.Subordinate phrases simply qual i fy  t h e  use of t h e i r  subject  words.
For ex-ample, phrases subordinate t o  THE OUTLINE OF THE PAPER provide a more de ta i leddescr ipt ion of t h e  paper ("ABOUT AUTONOTE2 , " and "FOR THE CONFERENCE") ; thephrase subordinate t o  THE PAPER FOR THE CONFERENCE fu r the r  q u a l i f i e s  the con-f erence.In  e f f e c t ,  two kinds of dependency information are extracted by theparser .
The f i r s t  is the  dependency of ad jec t ives  and preposi t ional  phrasesupon a noun.
This information is  ref lec ted  i n  the  se l ec t ion  of the  simplephrases themselves.
Second, there  are the  dependency re la t ionships  amongt h e  simple phrases of the descript ion,  This information, expressed i n  ttrmsof subordinate and coordinate linkages, may be represented by a tree s t ruc tu reconsis t ing of nodes with simple phrases a t  the  terminal branches.
Fig.
5 *gives the  tree s t r u c t u r e  f o r  the  example.
Simple phrases wlth an immediatelknkage t o  a node are said t o  d i r e c t l y  describe t h a t  node.
Note t h a t  the twocoordinate phrases from the  example d i r e c t l y  describe a common node, node B.The subordinate relationship of the node B phrases t o  the  node A phrase, andi n  turn, t h a t  of t h e  node C phrase t o  the node B phrases i s  re f l ec ted  by down-ward branches connecting those nodes.The re su l t an t  t r e e  s t ruc tu re  degines the r e p r e s e n t a t f ~ n  of i t s  correspon-ding topic.
Representations of each of the  use r ' s  topics  are organized into aFig.
5 - Siaiple Phraqe Dependency Structurehierarchica l  data structure cal led the  representat ional  network.
The repre-sentational fietwork is composed of interconnected nodes, s imple  phrases, andwords.
When descript ion i s  mapped ohto the network, the  number of t he  asso-cia ted  text item i s  s tored with the  highest  order node i n  the correspondingtopic  representation.Each node i n  the network may b&ve up to four types of linkages: (I)pointers  down t o  simple phrases that d i r e c t l y  describe the node; (2) pointersd m  t o  subordinate nodes; (3) pointers  up t o  superior nodes; and (4) poin-t e r s  to textual materials  associated with the  node.
Each simple phrase orsingle word is d i r ec t l y  accessible  3s a un i t  i n  the network.
through hash cod-ing procedures similar t o  those used in maintaining the  AUTONOTE keyword in-dex.
I ~ s o c i a t e d  with each simple phrase are the l inkages t o  the node(s) thephrase directly describes.
In  turn,  each sdngle word has associated pointersthat lead the  system t o  the s imple  phrases  containing the  word.
Fig.
6 il-l u s t r a t e s  the network representation of the eftample.Once a topic  is defined i n  t h e  network, t h e  user can r e f e r  t o  i t  usinga word, a simple phrase or composition of simple phrases, For example,should the user  later describe a new text item as say, OUTLINE OF THE PAPERor OUTLINE OF THE PAPER ABOUT AUTONOTF2, the system will note that: i t  al-ready has a representation for the topic.
The only change t o  the  network i nsuch cases i s  the addtkion of new item reference linkage t o  the i d e n t i f f e dnode (node 1).
In  general, the system attempts to relate each new item des-cription t o  those it a l ready  "knows" about.
For new t o p i c s ,  new nodes areal located i n  the network.
Should some subset of the simple phrases of a newdescr ipt ion r e f e r  t o  an exis t ing  topic, the additional simple phrases arePointer  to tex tPAPER aboutF i g  6 - Corresponding Representational Network Structurelinked to that existing representation.
For example, if in reference to thesame paper the user describes another item as THE ABSTRACT OF THE PAPER ABOUTAUTONOTE2, the system would modify the network to that shown in Fig.
7.Design of the Network Data StructuresL i s t  structures.
As noted above, the representational criteria dictatea hierarchical ne4Qork-type organization, based upon dependency analyses oftopic descriptions.
List structures are particularly well suited for thiskind of application.
They provide a convenient representahon for depen-dency trees and are especially appropriate for dealing with complex, evol-ving structures.In designing special purpose list structures for the representationalnet~~ork,  we first specified the logical components of the structure and de-fined the interconnections among these primitives.
Three logical componentswere forumlated--simple phrases, nodes, and words.
The following subsectionspresent the major design considerations for each structural component.Simple phrases,.
Given our goal of communicative efficiency, we chosethe simple phrase as a primary udit for the network.
By analyzing a toplct ?
description into simple phrases we are in effect isolating possible short-hand" references to the given topic.
The representational data structureshave been designed to allow a topic to be referenced through any of its com-ponent simple phrases.Simple phrases are formed from either adjectival or prepositional modi-fication of a noun.
Very often, an adjectival modification can be equiva-lently expressed by a prepositional phrase dependent upon the same nounPointer  toPointer to textFig.
7 - Network Representation of a Topic Hierarchy(example: THE PAPER ABOUT AUTONOm and THE AUTONOTE PAPER).
In  o the r  in-stances the  a d j e c t i v a l  form may have m u l t i p l e  i n t e r p r e t a t i o n s ;  THE SMITHARTICLE could r e f e r  t o  an a r t i c l e  by Smith o r  possibly an a r t i c l e  aboutSmith.
Some preposi t ions  may be used synonymousLy i n  a p a r t i c u l a r  context(THE PAPER ABOUT (ON) SHORT TERM MEMORY); others  convey d i s t i n c t l y  d i f f e r e n tmeanings (THE MEMO TO THE COMMITTEE versus THE MEMO FROM THE COMMITTEE).
Wedo not dea l  with these  problems t o  the  extent  of providing a semantics f o r"understanding" n a t u r a l  language.
Hmwer, the  representational s t r u c t u r emakes e x p l i c i t  the  var ious  p o s s i b i l i t i e s ,  s o  tha t  the  sys t em i s  able t o  gen-e r a t e  p laus ib le  alternatives.W e  treat a d j e c t i v a l  modification as a s p e c i a l  case, a s  i f  the modifierand subjec t  noun were r e l a t e d  by an unspecif ied preposi t ion.
In  terms ofthe  d a t a  s t r u c t u r e  design, a l l  simple phrases composed of the  same two wordsare mapped i n t o  a l a r g e r  u n i t ,  each subunit of which represents  a p a r t i c u l a rins tance of a simple phrase i n  a t o p i c  descr ipt ion.
This arrangement assuresthat all information on simple phrases involving any two words i s  accessibleco l l ec t ive ly .
Th i s  information w i l l  then be a t  hand t o  provide a b a s l s  f o ri n t e r p r e t i n g  the  a l t e r n a t i v e  r e f e r e n t s  of each incoming simple phrase.
Forexample, should t he  user  make reference t o  THE SMITH PAPER and the systemf i n d s  only PAPER ABOUT SMITH i n  the  network, then that s ing le  a l t e r n a t i v eis chosen.
On the  o the r  hand, i f  PAPER BY SMITH also is present ,  the  systemconsiders both p o s s i b i l i t i e s .Network nodes.
The next structural component of the representa t iona lnetwork is  the node, A node groups together a s e t  of simple phrases t h a tcomprise the descr ip t ion  of the node, m e  node a l s o  functions a s  a  co l l ec to rof i t e m  references ,  Each node i n  the representa t iona l  network correspondst o  a top ic  o r  concept pe r t inen t  t o  the items of t e x t u a l  ma te r i a l  associa tedwith i t .
The simple phrases that d i r e c t l y  descr ibe  a node def ine  the  cor-responding concept.
Any given node may be l inked t o  more general  (lower)nodes, o r  t o  more s p e c i f i c  (higher) nodes.
For example, a node t h a t  repre-sen t s  a p a r t i c u l a r  paper may be linked downward t o  another tha t  describesa conference a t  which t h e  paper was presented; i t  may a l s o  be l inked t osevera l  higher order nodes corresponding t o ,  say, a summary, an ou t l ine ,  anda review of the paper.
As more and more i t e m s  are described,  addi t iona ltopics  may be t i e d  i n t o  t h e  same conference node.
The u l t imate  r e s u l t  w i l lbe a highly interconnected set  of concept nodes, each with its own s e t  ofassociated t e x t u a l  materials.To achieve th i s  kind of s t r u c t u r a l  organization f o r  the network, wemake use of the dependency re l a t ionsh ips  i n  the  use r ' s  descr ip t ions :  eachnode l e v e l  corresponds t o  a s y n t a c t i c  dependency leve l .
I n  terms of theexample above, t h e  ad jec t ives  and prepos i t iona l  phrases modifying the  noun"paper" a r e  formed i n t o  simple phrases t h a t  w i l l  d i r e c t l y  describe a commonnode.
Simple phrases iden t i fy ing  t h e  c o n f e r ~ n c e  w i l l  descr ibe  a subordinatenode due t o  the syn tac t i c  dependency of "conference" upon "paper" i n  a phraseof the  form, PAPER AT THE...CONFERENCE.
Superior nodes are assigned t o  theout l ine ,  t h e  summary, and the review, r e f l e c t i n g  the  dependence of "paper''upon those nouns i n  appropr ia te  descr ipt ions .A node may be viewed as a co l l ec t ion  of po in te r s  t o  simple phrases,other nodes, and t e x t  i t e m s .
A l l  node l inkages a r e  two-way.
Pointers  d mfrom a node to i t s  simple phrases a r e  required i n  order t o  reconstruct  adescr ip t ion  of t h e  node, Po in te r s  down t o  subordinate nodes a r e  necessary f o rthe  same reason.
Both upward and downwa~d po in te r s  t o  o ther  nodes provide ameans f o r  moving from any top i c  t o  s t r u c t u r a l l y  r e l a t e d  ones.
Associated witheach instance of a simple phrase i s  a po9nter t o  the  node where item re fe r -ences are s to red ,  F ina l ly ,  bookkeeping information s to red  with each t e x t  i temincludes po in t e r s  t o  each t o p i c  node wi th  which the i t e m  i s  associated.
Item-node l inkages enable t h e  system t o  provide the  user  wi th  t op i c  descr ip t ions  ofany t e x t  i t e m .Words.
The represen ta t iona l  s t r u c t u r e s  considered thus  far  provide s i m -p l e  phrases as the  s o l e  means f o r  accessing the  nodes i n  the  network.
A l e s sres t rAct ive  access mechanism a l s o  i s  required,  f o r  s e v e r a l  important reasons.First, i t  would be u n r e a l i s t i c  t o  assume t h a t  t h e  use r  will always phrase ref-erences t o  a p a r t i c u l a r  t o p i c  i n  exac t ly  the  stme way, Second, s i n g l e  worddescr ip t ions  play an important r o l e  i n  achieving our goal  of communicativeefficiency.
Since we a n t i c i p a t e  t ha t  users w i l l  make frequent use of s i n g l eword references when working i n  the  context of a p ~ r t i c u l a r  t o p i c ,  we  want t oprovide a n a t u r a l  and convenient treatment of such descr ip t ions .
F ina l ly ,  aphrasa l  desc r ip t ion  can convey a higher  order  c a t e g ~ r i z a t i o n  of an e x i s t i n gtop i c  without containing a simple phrase f o r  t h a t  topic .
For example, THEREVIEMER'S COMMENTS ON THE PAPER may reference a paper mentioned e a r l i e r ;  ye ti t  conta ins  no simple phrases descr ib ing t h a t  paper.These considerat ions lead us t o  the t h i r d  l o g i c a l  component of the  networkda ta  s tmctu\ res ,  the s i n g l e  word.
Es sen t i a l l y ,  each component word provldes ac-cess t o  a series of po in t e r s  t o  simple phrases i n  which the  word occurs.Word-to-phrase po in te r s  a r e  of two types: those ind ica t ing  usageas subject noun; and those indicating modifier usage in a particular simplephrase.
As we shall see later, this distinction is required in order torelate new simple phrases to existing topics at an appropriate node level.Hadng specified the three logical components and the linkages in therepresentational network, we now turn our attent&on to the storage implemen-tation of these structures.Storage Implementation of the Network StructureThere are three directories needed to maintain the representational net-work, one for each of the components of the structure.
All directory infor-matlon must, of course, be saved in permanent storage between AUTONOTE2 ses-sions.
Two design alternatives were considered for maintaining the networkduring execution of the program.
Thedirectories could be accessed and up-dated on disk, or they could be brought into core storage for the duratlonof the session.
We adopted the former strategy for a number of reasons.First, AUTONOTE is highly oriented toward the use of disk file storage.Several file interface routines were available at the outset for convenientlystoring and accessing information through the MTS file system.
Second, asthe network grows in complexity, it becomes increasingly unlikely that theuser will reference the major portion of the network during any given ses-sion.
By maintaining the network in disk files, the amount of core storagerequired is substantially reduced.
Finally, the file approach greatlysimplified the programming effort, especially in those system componentsthat operate recursively on the list structured network.
We will elaborateon this point further in section VI, which i l lu s t ra te s  the simplification ofrecursive processes in AUTONOTE2.Rather than s t o r e  a l l  the d i r e c t o r i e s  i n  a s i n g l e  d fsk  f i l e ,  we  choset o  maintain each d i r e c t o r y  s epa ra t e ly .
This  s t r a t e g y  prese rves  t he  l o g i c a ld i s t i n c t i o n  among t h e  t h r e e  types  of d i r e c t o r y  information,  and has  a l s os imp l i f i ed  t he  p rograming  of t he  system.
We now desc r ibe  the  o rgan iza t ionof each of t he  d i r e c t o r y  f i l e s .The node d i r ec to ry .
Each node i n  t h e  r e p r e s e n t a t i o n a l  network has  acorresponding i n t e g r a l  node number which is a l s o  the  l i n e  number i n  t he  noded i r e c t o r y  f i l e .
As new node numbers are needed t o  r ep re sen t  new t o p i c s ,  thenext s e q u e n t i a l l y  numbered l i n e  i n  t h e  node d i r e c t o r y  i s  assigned as the  nodenumber.
Each node d i r e c t o r y  l i n e  contarns  four  fields--one f o r  bookkeepinginformation and t h r e e  f i e l d s  f o r  t h e  upward, downward, and i tem re fe rencep o i n t e r s  f o r  t h e  node.
The i t e m  r e f e r ence  region con ta ins  a l i s t  o f  I n t e g e ri t e m  numbers.
The upward p o i n t e r  reg ion  a l s o  con ta ins  a l i s t  of rn t ege r st h a t  r ep re sen t  immediate l inkages  t o  supe r io r  nodes.
The two types of down-ward p o i n t e r s  ( t o  mdes and t o  phrases)  a r e  s to red  i n  a common reglon.
Eachnode, simple phrase,  and s i n g l e  word has  a corresponding f i l e  l l n e  number I ni ts  r e spec t ive  d i r e c t o r y  f i l e .
I n  t he , ca se  of nodes, the  l i n e  number i ssimply t h e  node number.
I n  the case  of words and simple phrases ,  the  l i n enuntiber is the  r e s u l t  of a, hash codPng process  on a compact charac te r represen-t a t i o n  of t he  word o r  phrase.
Thus a "pointer" 1s  a c t u a l l y  a f i l e  l i n e  num-ber.
Downward p o i n t e r s  t o  nodes and phrases  a r e  d i s t i ngu i shab le  i n  t he  noded i r e c t o r y  on the  b a s i s  of t h e  magnitude of t he  l i n e  number.Since each of t he  t h r e e  p o i n t e r  f i e l d s  is of f i xed  length ,  t h e r e  is amaximum number of each type of p o i n t e r  f o r  a given node d i r e c t o r y  l i n e .Each f i e l d  consequently has an  associa ted cont inuat ion p o i n t e r  t o  a l i n ewhere add i t iona l  po in te rs  a r e  stored i f  necessary.The phrase di rectory.
To loca te  the  phrase d i r ec to ry  l i n e  f o r  a  par-t i c u l a r  simple phrase, a hash coding funct ion i s  appl ied t o  the  characters t r i n g  formed by concatenating the  modifier word, a s l a sh ,  and the subjec tword.
For example, the d i r ec to ry  l i n e  f o r  the  simple phrase PAPER ABOUTAUTONOTE i s  the hashcode f o r  the  s t r i n g  "AUTONOTE/PAPER."
Since the  hashingfunction operates  only on t h e  modifier and sub jec t  word, simple phrasesformed from the same two words, but with d i f f e r i n g  (or  no) preposi t ions ,  aremapped i n t o  the same d i rec to ry  l i n e  number.To d i s t ingu i sh  among the  var ious  ins tances  of the  same two-word combin-a t ion ,  the d i rec to ry  line f o r  simple phrases c o n s i s t s  of a s e r i e s  of p o i n t e rblocks.
Each poin ter  block contains a code f o r  the  p a r t i c u l a r  prepos i t ionused, some additional bookkeeping information, and a  po in te r  t o  the  noded i r e c t l y  descrsbed by t h a t  occurrence of the simple phrase.The word directory.
The word d i rec to ry  incorporates  the  same poin te rblock p r i n c i p l e  as the  phrase d i rec tory .
The po in te r  f i e l d  of the  block i nthis case i s  a poin te r  i n t o  the phrase d i r ec to ry .
The prepos i t ion  code f i e l dcontains a  binary f l a g  ind ica t ing  whether the p a r t i c u l a r  wdrd occurs as t h esubjec t  noun o r  modifier word i n  the simple phrase spec i f i ed  by the  poin te r .Like phrases, each word d i r ec to ry  l i n e  is  accessed through an e f f i c i e n t  hashcoding algorithm.The word d i rec tory  a l s o  maintains prepos i t ion  usage information f o r e a c hword.
For example, the entry f o r  MEMO may indicate that the word hasoccurred with the  prepos i t ions  ON, ABOUT, TO, FROM, e t c .
T h i s  informationis used t o  guide the  pars ing of descr ip t ions .The organization of the  th ree  network d i r e c t o r i e s  is depicted i n  Fig.
8.$he Representational.
Network: An ExampleTo help  f i x  iderfs, Qe now present  a more d e t a i l e d  example t h a t  i l l u s -t r a t e s  the  s t r u c t u r e  of t h e  r ep resen ta t iona l  netwo2k.
Suppose the userdescr ibes  Items 157, 158, and 159 as THE PAPER ABOUT AUTONOTE FOR THE ACMCONFERENCE: he e n t e r s  ma te r i a l s  on t h e  organizat ion of t h a t  paper i n t oI t e m s  201 and 202.
A summary of the  paper i s  placed i n  Item 230.
The usera l s o  descr ibes  I t e m  270 as SMITH'S PAPER, and e n t e r s  a summary of t h a t  paperi n t o  Item 312.
A p i c t o r i a l  representa t ion  of the r e s u l t a n t  por t ion  of thenetwork is given i n  Fig.
9, whi le  t h e  corresponding d i rec to ry  contents  appeari b  Fig.
10.
For s impl ic i ty ,  t he  simple phrase hash codes a r e  represented bythe  a lphabet ic  charac te rs  U through 2.
( In  subsequent diagrams, w e  a l soomi tword-to-phrase l inkages  f o r  s impl ic i ty .
)Pars ing of Descript ionsThis s e c t i o n  o u t l i n e s  our genera l  approach t o  pars ing t o p i c  descrip-t ions .
The parsing of prepos i t iona l  phrases,  consecutive modifiers ,  andpossessive modifiers  i s  considered.Prepos i t iona l  phrases.
Despite the  apparent s impl i c i ty  of t h e  descrip-t i o n  language the re  are seve ra l  n o n t r i v i a l  pars ing problems.
One of thesei s  t h e  d i f f i c u l t y  in,dletermining the  noun r e f e r e n t  of p repos i t iona l  phrases.The determination of noun r e f e r e n t s  is  p a r t i a l l y  a semantic problem r a t h e rthan a purely s y n t a c t i c  one.
Consider the  following two d e s c r i p t ~ o n s :(a) Format f o r  the word and phrase d i r ec to r i e s .Se r i e s  of FixedLength  locks^(Format Given i n(b) Below)(b) Pointer  block format i n  the  word and phrase d i r ec to r i e s .In te rna l  Formof the  Wordo r  PhrasePreposi-t i o nUsageCUpwardLinkFig.
8 - Representational Network Directory FormatsPointer  t oContinua-t i onLinesNumberofUpwardLinksAccessRecencyPrepositioncodeCNumberofUpwardLinks%sed i n  conjunction with the hash codihg mechanism.Col l is ibnpointerab For single words, there  is  one block f o r  each phrase containing theword.
For phrases, there  i s  one block f o r  each - node that the phrase d i r e c t l ydescribes.Ar t i c l eCodes( c )  Format f o r  the node directory.NumberofDownwardLinks%or s ing le  words, the preposit ion code is  used t o  d i s t inguish  betweenwords used as subjects or  modifiers.For FutureExpansion' NumberofItemsPreposi-t i o nCode f o rEachDownwardPointerAccessRecencyIL i s t  ofUpwardPoin-tersL i s tofI t e mRef=ences-Continu-a t ionLinePointersL i s t  ofDownwardPointersFAg.
9 - A Complex Representation(a) Word directory.J(b) Phrase directbry.CWord10rganizationPaperI Z Z E z c eS VACHM t h  (poss)1rNoBlocks1512111BlocksLineI No.UVWXYZv(c) Node directory.1BlocksLineNo123456Fig.
10 - Corresponding Directory contentsaU (sub)W (sub)X (mod)W (mod)Z (sub)Y (mod)V (mod)Phrasepaper/organizationsmikhlpaper (poss)con?
erence/paperautonote/paperacm/conferencepaper /summaryNode 3 (of)Node 5 (adj)Node 1 (for)Node 1 (about)Node 2 (adj)Node 4 (of)a See Fig.
9 .U (mod) X (sub)Y (sub)No.Blocks111112 Node 6 (of)PointersUP394I* * ** a *6m e .V (sub)!PointersDown2,W,XY19u2 9 1V295Z (mod)-I t e mReferences8157, 11158, 1,159* a *#201, #202$203#27011312I) I 1THE MEMO (FROM THE COMMITTEE) (TO THE CHAIRMAN).In the f i r s t  example, both prepos i t ional  phrases r e f e r  t o  the immedi-a t e ly  preceding noun.
I n  the  second case, both refer back t o  the noun MEMOa t  the beginning of t he  s t r i ng ,  Although nei ther  of these examples i s  in-t u i t i v e l y  ambiguous, the parsing algorithm must consider each preceding nounas  a possible  re fe ren t  of any given prepos i t ional  phrase,?he AUTONOTE2 parser  dea ls  with t h i s  problem t o  a l imited extent, byu t i l i z i n g  preposi t ional  clues,  For example, i f  the system f inds  t h a t  thenoun MEMO can form a simple phrase with the  preposi t ions ON, ABOUT, TO, andFRW, then phrases introduced by these preposit ions w i l l  be associated withthat noun.
Such clues w i l l  not  always y ie ld  a unique parsing, of course, asi n  the caee of inherent ly ambiguous descriptions.
THE PAPER FOR THE CON-FERENCE ON GENETICS, for example, could r e f e r  t o  a paper on genetics t o  bedelivered at a conference, or  t o  a paper which i s  t o  be delivered a t  a con-fyence on genetics.In  sucfi instances w e  r e ly  upon the  user  t o  supply t he  referent  nounupon request.
In t he  example above, t he  system may prompt: DOES "ABOUTGENETICS" REFER TO PAPER OR CONFERENCE?
Should the user  reply CONFERENCE,the simple phrase CONFERENCE ON GmETICS w i l l  be added t o  the  network.
Ifat  some later t i m e ,  the parser i s  attempting t o  find a referent  f o r  the  pre-positional phrase ON GENETICS where CONFERENCE i s  one of the  a l t e rna t ives ,ft forms t h a t  simple phrase di rec t ly .Consecutive modifiers.
A p a r a l l e l  problem arises i n  determining thenoun referents for a s t r i n g  of consecutive modifiers.
Descriptionscontaining at 111ust a single adjective for any particular noun are parsed inthe obvious manner.
A simple phrase is formed from each modifier and thenoun following it.
In the event a noun i s  preceded by two or more modifiers,the parser is confronted with a task similar to that of determining thereferent of a prepositional phrase.
The modifier occurring immediately be-fore the noun is  first processed as above.
Each of the remaining modifiers,however, can modify any one of several words depending upon their "distance"f r o m  the head noun.
Specifically,  any such modifier can refer to either thehead noun or any of the other modifiers following it.
Consider the descrip-tions :A summary of pIA summary of personal informIn both of the cases above, INFORMATION modifies the modifier RETRIEVAL whichin turn modifies the head noun SYSTEMS.
~epending upon the user's intent,PERSONAL can modify either INFORMATION or SYSTEMS.
The choice of modifierreferents is an especially important problem when there are multiple parslngs,each resulting in a different semantic interpretation.
For example, LARGECOMPUTER CONFEREXCE could refer t o  a conference on large computers, or alarge conference on computers.
Another important reason for our emphasisupon correctly identifying modifier referents concerns the use of para-phrasing.
In the example, PERSONAL INFORMATION RETRIEVAL SYSTEMS, if wedetermine that INFORMATION modifies RETRIEVAL and PERSONAL modifies SYSTEMS,then the resultant topic can be paraphrased as (1) PERSONAL SYSTEMS FORINFORMATION RETRIEVAL, or (2) PERSONAL SYSTEMS FOR THE RETRIEVAL OF INFORMA-TION.
Depending upon context and the nature of other topics in the network,the following incomplete descriptions will in most cases identify the topic:1.
SYSTEMS2.
SYSTEMS FOR RETRIEVAL (or RETRIEVAL SYSTEMS)3.
PERSO~AL SYSTEMS4.
PERSONAL SYSTEMS FOR RETRIEVAL (or PERSONAL RETRIEVAL SYSTEMS)5.
SYSTENS FOR INFORMATION MTRIEVAL6, SYSTEMS FOR RETRIEVAL OF INFORMATIONA different choice of modif~er referents determines a correspondingly chi-ferent set of paraphrases, If PERSONAL was intended to modify INFORMATION,we would have the paraphrase SYSTEMS FOR THE ~ T R I E v A L  OF PERSONAL INFORMATION,with a corresponding list of incomplete references to the topic.As in the prepositional case, the choice of modifier referents is guidedby the current state of the representational network.
After processing thelast modifier in the string, the parser pos i t i ons  itself a t  t he  precedingmodifier and moves left in the input string untll the first word in the modi-fier string is processed.
In the above example, after associating RETRIEVALwith SYSTEMS, the parser next examines the modifier INFORMATION.
A list ofsimple phrase candidates is formed.
In this case, the list contains INFORMA-TION RETRIEVAL and LNFORlUTLON SYSTEMS.
If neither of the candidate phraseshas been previously used, the system queries-: WHAT DOES INFORMATION MODIFY?The user's reply is matched against the oandidate referents and the appropriatesimple phrase is formed.Possessive adjectives, Possessives are processed in much the same way asnormal modifiers.
The system recognizes the ' s  word stem and marks the rootword as a possessive.
The root word is later stored in the network directoriesalong with a possessive flag.
Thus the phrase SMITH'S PAPER is stored intern-ally as SMITH~PAPER (possessive).
The removal of the stem insures that a sub-sequent simple phrase incorporating a preposition (PAPER BY SMITH) will hash tothe same directory lifie thus allowing the use of either prepositional or pos-sessive forms in referencing topics.A p a r t i c u l a r l y  interesting case arises when a possessive occurs in a stringof consecutive modifiers as in SMITH'S LATEST MEMORY EXPERIMENT.
The string isfirst processed as described above; that is, a check is made to see if SMITHhas been used in a simple phrase with LATEST, MEMORY, or EXPERIMENT.
In theevent that this yields no clues, the system then checks to see if SMITH wasrendered as a pbssessive.
Upon noting that it was, the parser carries out aheuristic that assumes that the possessive modifies the head noun, EXPERIMENT.The possessive heuristic can be fully stated as follows.
A possessiveoccurring in a stfing of modifiers will be assumed to modify the head noun un-less another possessive occurs between it and the head noun.
In the lattercase, the first possessive will be assumed to modify the second.
This is simi-lar to the possessive feature employed by the REL parser (Dosert & Thompson,1971).
Thus in SMITH'S RESEARCH GROUP'S MEMORY EXPERIMENT, SMITH'S is assumedto modify GROUP, and GROUP'S is assumed to modify the head noun EXPERIMENT.The question now arises, why check the phrase directory first instead ofapplying the possessive heuristic immediately?
To answer this, suppose a topicwas or ig ina l ly  described as THE WSULTS OF THE MEMORY EXPERIMENT BY SMXJTH andt he  user  now at tempts  t o  r e f e r  t o  i t  as SMITH'S MEMORY EXPERIMENT RESULTS.
I ft he  possess ive  h e u r i s t i c  were applied immediately, the  system would i n c o r r e c t l yform the  simple phrase SMITH'S RESULTS, n o t  SMITH'S EXPERIMENT.
By checkingthe  network f i r s t ,  t he  simple phrase EXPERImNT BY SMITH w i l l  be detec ted  andthe  system w i l l  pa r se  the  desc r ip t i on  appropr ia te ly .Implementation of the  Parse rThe u l t ima te  goal of t he  pa r se r  i s  t o  determine t h e  simple phrases of at o p i c  descr ip t ion .
The pars ing algori thm is implemented as a two s tage  pro-cess .
The f i r s t  s t age  is a prel iminary scan t o  a s c e r t a i n  t h a t  the  s t r i n g  i si n  a form acceptable  f o r  ana lys i s .
The desc r ip t i on  i s  segmented i n t o  anordered list of words, each of which i s  marked as e i t h e r  WORD, POSSESSIVE,ARTICLE, o r  PEPOSITION.
The parse r  makes no d i s t i n c t i o n  between nouns andmodif iers  u n t i l  completing the  scan.
A t  t h i s  po in t ,  the  l a s t  i n  a series ofconsecutive WORDS i s  marked as a NOUN; t h e  preceding words a r e  marked a s  MOD-IFIERS.
Possessive modif iers  a r e  an exception as they can be recognized ex-p l i c i t l y  during t h e  scan.
A record of a r t i c l e  usage i s  a l s o  kept ,  but  t hea r t i c l e s  themselves a r e  n o t  placed on the  word l i s t .The prel iminary scan of the  desc r ip t i on  can be viewed as a simple f i n i t estate process.
Of course,  t o  be completely formal, t he  recognizer  would havet o  examine each input  charac te r .
For convenience w e  w i l l  assume a f i v e  s t a t eautomaton wi th  inputs :  WORD, POSSESSIVE, PREPOSITION, and ARTICLE.
The statet r a n s i t i o n  graph f o r  the  machine i s  given i n  Fig.
11.
The machine s t a r t s  i nstate So, examines t he  next  input  and moves t o  a new s t a t e .
I f  a t  the  end oft h e  input  s t r i n g ,  the  machine is i n  state S ca l l ed  the  f i n a l  s t a t e ,  the  in- 1'put  is accepted; otherwise,  the  u se r  i s  asked t o  rephrase.
Note t h a t  i n  s t a t eS2' the machine has just encountered an article and is anticipating a "word.
"If the machine is in state S upon completion, it has juat recognized a pre- 0position and is expecting an object; thus, the string is rejected.
The stateS is reached whenever a possessive is encountered.
Since a possessive must 4have an object noun, a "word" input is required to reach state  S1.
State S 3is a trapping state; once entered, the machine remains in that state regard-less of the remaining input and the description is consequently rejected.State S corresponds to various error conditions--two consecutive prepositions 3or articles, an article between two words, a phrase beginning wlth a preposi-tion, etc.The state transitions for the description BRUNER'S FIRST EXPERIMENT ON THECONSERVATION OF LIQUIDS are given below along with the resultant word list.INPUTBruner' sFirstExperimentOnTheConservationOfLiquidsTYPEPossessiveWordWordPrepositionArticleWordPrepositionWordWORD-Bruner ' sFirstExperimentOnConservationOfLiquidsRESULTANT STATEs4S1S1SoS2S1$0S Accept 1TYPE-ModifierModifierNounPrepositionNoun (the)PrepositionNounDescript ions found acceptable by the scanner next undergo ana lys i s  by thesecond stage procedure.
This algorithm steps through the  word l i s t  and bu i ld sa t a b l e  of simple phrases ca l l ed  the phrase t a b l e .
Each en t ry  i n  the phraset a b l e  Includes (1) the  i n t e r n a l  character  represen ta t ion  of t he  phrase f o r  usei n  hash coding, (2) a numerical code f o r  the prepos i t ion  used, (3) the  hashcode (d i rec to ry  line number) f o r  t h e  phrase, (4) a list of nodes d i r e c t l y  des-cr ibed by the  phrase,  and (5) a coordinate o r  subordinate l i n k  t o  anotherphrase t a b l e  ent ry .We now i l l u s t r a t e  the  const ruct ion  of the  phrase t a b l e  by followingthrough severa l  examples.The parser i n  operation.
Let  u s  assume t h a t  a u se r  is running the systemf o r  t he  f i r s t  t i m e ;  consequently, t he  t h r ee  network d i r e c t o r i e s  a r e  i n i t i a l l yempty.
I t e m  No.
1 is  opened, some text is i n s e r t e d ,  and the  u se r  descr ibes  i tas THE PLANNED PAPER ABOUT AUTONOTE FOR THE CONFERENCE.
The descr ip t ion  suc-ce s s fu l ly  passes the prel iminary scan aqd t h e  word l ist  is  constructed.
Theparse r  then moves on t o  determine the  simple phrases.The modifier PLANNED i s  f i r s t  noted.
Since i t  i s  followed immediately bya noun, the  simple phrase PLANNED PAPER becomes the  f i r s t  e n t r y  i n  the  phraset ab le .
Next the prepos i t iona l  phrase ABOUT AUTONOTE i s  encountered.
Againt he re  i s  only one poss ib le  noun r e f e ren t .
The phrase PAPER ABOUT AUTONOTE isentered  i n t o  t he  t a b l e  and marked as coordinate w i t h  t he  first entry .
Todetermine the  r e f e r e n t  of FOR CONFERENCE, the  system must consider  two alter-nat ives :  AlfTONOTE FOR CONFERENCE and PAPER FOR CONFERENCE.
The network i s  in-terrogated t o  determine i f  e i t h e r  of t h e  candidate phrases has been previouslyused.
This tes t  f a i l s  since the network is empty a t  c h i s  point .
A check isthen made i n  the  word d i r ec to ry  t o  determine i f  e i t h e r  AUTONOTE o r  PAPER hasheaded a s imple  phrase wi th  the prepos i t ion  FOR* This a l s o  f a i l s  so the  sys-t e m  asks t h e  user :  DOES "FOR CONFERENCE" REFER TO PAPER?
A yes responser e s u l t s  i n  t he  add i t ion  of PAPER FOR CONFERENCE t o  the  phrase t ab le .
Sincet he  noun r e f e r e n t ,  PAPER, is  the  same a s  the previous phrase,  the new e n t r yis  marked as coordinate wi th  PAPER ABOUT AUTONOTEw The completed phrase t a b l ei s  given i n  Fig.
12.
(1) autono te/paper(2) planned/paper(3) conferenee/paperFig.
12 - Sample Phrase TableThe phrase t a b l e  fs next  passed t o  t h e  network loca tor .
We w i l l  assume i tdetermines that t he  user is  def in ing a new topic .
Using the  s y n t a c t i c  depen-dencies i n  t he  phrase t a b l e ,  the  network loca to r  ass igns  new node numbers t ot he  phrases i n  the  descr ip t ion .
I n  t h i s  case,  a l l  t h r ee  phrases are coordin-ate; each will directly descr ibe  node No.
1 i n  the  network.
I n  add i t ion ,  areference  t o  Item NO* 1 is  s tored with t h e  t o p i c  node ( see  Fig.
13).The user next e n t e r s  Text Item Noo 2 describing i t  as THE ORGANIZATION OFTHE PAPER FOR THE ACM CONFERENCE.
The system proceeds as before  untll i t  en-counters t h e  p repos i t i ona l  phrase FOR THE CONFERENCE.
It forms the  two a l t e r -na t ives  PAPER FOR CONFERENCE and ORGANIZATION FOR CONFERENCE0 Upon in t e r ro -gating the network, it  finds t h a t  PAPER FOR CONFERENCE has been definedpreviously and accepts that candidate.
ACM CONFERENCE is added to the phrasetable and the parsing is complete (Fig.
14).PAPER aboutAutonote(I) paper/organization(2) con?
erence/paper(3) acm/ con?
erenceFig.
14 - Sample Phrase TableThe network locator must then determine ff the user is referring to thesame paper or a new one.
The operation of the network locator will be dis-cussed in detail in the next chapter.
Let us assume for now that the currentdescription is indeed a reference to the same paper.
The simple phrase PAPERFOR CONFERENCE is already in the network.
The system must then decide what todo with THE ORGANIZATION OF PAPER, and with ACM CONFERENCE.
Since the  formeris  super ior  t o  the  node 1 phrase, i t  is assigned t o  node 2 and a downwardpoin te r  from node 2 t o  node 1 i s  added.
The phrase ACM CONFERENCE, on theother hand, is subordinate t o  a node 1 phrase.
Thus i t  is  assigned a new nodenumber (node 3) and a po in te r  up from node 3 t o  node 1 is  added.
Phrase-to-node and node-to-node poin te rs  a r e  two way, thus corresponding poin te rs  downfrom node 1 t o  node 3, and up from node 1 t o  node 2 a r e  a l s o  added.
The r e s u ltant  network i s  i l l u s t r a t e d  i n  Fig, 15.
This example poin ts  out an i n t e r e s t -ing f e a t u r e  of the  AUTONOTE2 system.
Although I t e m  No, 1 was o r i g i n a l l y  des-cribed as alpaper f o r  some unspecified conference, a subsequent reference t ot h a t  paper has enriched i t s  descr ipt ion.V, THE NETWORK LOCATORThe purpose of t h e  network loca to r  i s  t o  determine whether the  use r ' s  desc r i p t i o n  makes reference t o  an e x i s t i n g  top ic  i n  the  representat ional  network.Its decis ion is  based on the  information i n  the  phrase t ab le  and the currents t a t e  of the network.
Once the  decis ion i s  made, the  loca tor  bu i lds  a tab le ,ca l led  the  l i n k s  tab le ,  t h a t  s p e c i f i e s  the  changes t o  be made i n  the  networkt o  represent  the descr ipt ion.In cases where the  input  descriptiori  matches exac t ly  some s t r u c t u r e  i nthe  network, the  l i n k s  t a b l e  w i l l  specify  only the addi t ion of an i t e m  re fe r -ence.
When the description def ines  a new topic ,  every phrase i n  the phraset ab le  w i l l  be assigned a new node and l i n k s  e n t r i e s  w i l l  be made f o r  the pro-per node-node linkages.F i g .
15 - Network after AugmentationI n  order  t o  descr ibe  more p rec i se ly  t he  operat ion of the  network loca to r ,l e t  us assume the  network has  evolved t o  t he  s t a t e  depicted i n  F ig .
16.
Notet h a t  by s t a r t i n g  a t  any node and t r ac ing  downward through the  network, i t  i sposs ib le  t o  reconst ruct  the  descr ip t ion  of the  t o p i c  the  node represents .
Thenodes i n  t he  network represent  the  fo'llowing topics .Node 1.
THE PLANNED PAPER ABOUT $WONOTE FOR THE ACM CONFEIIENCE.Node 2.
ORGANIZATION OF THE PLANNBD PAPER ABOUT AUTONOTE FOR THEACM CONFERENCE.Node 3.
THE ACM CONFERENCE.Node 4.
AN ABSTRACT OF THE FIRST PAPER ABOUT AUTONOTE.Node 5.
THIE FIRST PAPER ABOUT AUTQNOTE.Node 6.
THE REVIEWER'S COMMENTS O@ THE PLANNED PAPER..ooNode 7.
THE PROCEEDINGS OF THE Am CONFERENCE.Node 8.
TRAVEL ARRANGEMI3W.S FOR THE ACM CONFERENCE.To i l l u s t r a t e  the network loca t ion  procedures, we w i l l  now ga "through seve ra lsubsequent references  t o  top ics  a l ready defined i n  the r q r m e n t a t i o n .Before passing t h e  phrase t a b l e  t o  the l oca to r ,  t he  parse r  f i r s t  checks t osee i f  t h e  descr ip t ion  contains any a c t i v e  phrases,  simple phrases t h a t  direc-tly descr ibe  one o r  more nodes i n  the  network.
When t h e  l oca to r  ge t s  con t ro l ,it checks an i n t e r n a l  flag t h a t  i nd i ca t e s  one of t h r ee  condit ions:  the  des-c r i p t i o n  contains one o r  more a c t i v e  phrases;  the  descr ip t ion  contains noa c t i v e  phrases; o r  the desc r ip t i on  contains only a s ing le  word.A s  our  f i r s t  example, consider t h e  subseqaent i t e m  descr ip t ion:  THE PAPERABOUT AUTONOTE FOR THE CONFERENCE.
The phrase t ab l e  is  given i n  Fig.
1 7 .
Theloca to r  notes tliat t h e r e  are two a c t i v e  phrases and focuses i t s  a t t e n t i o n  onARRANGEMENTSORCZANI ZATIONPROCEEDINGSPAPER aboutCONFERENCE uFig.
16 - A Cluster o f  Related TopicsFig.
1 7  - Sample Phrase Tablethe first of these, PAPER ABOUT AUTONOTE.
From information i n  the phrase tab le ,it sees t h a t  PAPER ABOUT AUTONOTE plays a r o l e  i n  two d-istinct topics  repre-sented by nodes 1 and 5.
It then considers bath of these a l t e rna t ives ,  check-ing t o  see if t he  remaining phrases i n  the  phrase t ab le  e i t h e r  d i r e c t l y  o r  in-d i r e c t l y  descxibe e i t h e r  of the  two nodes.
Since both phrases d i r e c t l y  des-c r ibe  node 1, the locator  assumes t h a t  i t  is the top ic  node of user  reference.As an option, the  user may request the loca tor  t o  display i t s  assumptions, i nwhich case the system rep l i e s :  I ASSUME YOU MEAN THE PLANNED PAPER ABOUTAUTO-NOTE FOR THE ACM CONFERENCE.
Other than t he  addi t ion of an i t e m  reference t onode 1, no network changes are made i n  this example.
Note t h a t  the user  hase f f i c i e n t l y  made reference t o  tbe desired topic ,  re lying on the  system t o  f i l lia the gaps in h i &  descript ion.
The system would proceed i n  much the same wayi n  processing shorthand descr ipt ions  such as SUMMARY OF THE PAPER or  REVIEWER'SCOMMENTS ON THE FAPER, i n  each-caae assumtng t h a t  the user  is  re fe r r ing  t o  thesame paper about AUTONOTEIn previous discussion we have alluded t o  the  use of contextual clues i ndeciding among the a l t e r n a t i v e  r e fe ren t s  of a vague o r  ambiguous descript ion.Context i n  the AUTONOTE2 system takes t h e  form of an access recency nwlber(context number).
Each t i m e  the  user  r e f e r s  to  some top ic  in  the  network,kPhrase-(1) autonote/paper(2) Conferenae/papere1LinksPode I.Node 1mArticlethethe-Preposit ionaboutf o ri-Dependencyrootco-ord 1each of the component nodes is  assigned the  current  context number.
The cur-r e n t  context number is incremented a t  the beginning of each AUTONOTE2 sessionand each t i m e  the  user defines a new topic.
Thus when deciding among al terna-t i v e  topic  nodes, the system can readi ly  determine which was re fer red  t o  mostrecently,Another c l a s s  of in t e res t ing  cases a r e  those i~ which the  descript ionconsis ts  of a s ing le  noun.
I?
t he  current descr ipt ion is THE PAPER, f o r  ex-ample, the system would use the  word directory t o  loca te  those simple phraseswhere PAPER is  the subject  noun.
Using the r e su l t an t  l is t  of simple phrases,a list of nodes d i r e c t l y  described by these phrases i s  generated, I n  t h i scase, t h i s  process generates two a l t e rna t ives  (node 5 and node 1).
The systemthen functions as before, e i t h e r  choosing a node i n  context, o r  in terrogat idgthe user,The foregoing discussion has described our approach t o  network location.We now give a more deta i led presentat ion of the algorithm.Case I: Active phrases i n  the  description.
Should t h e  use r ' s  descr ipt ioncontain one or more ac t ive  phrases, there  is a good p o s s i b i l i t y  t h a t  i t  refer-ences an existing network topic.
The first s t e p  i n  processing such a descrip-tion is to determine the  focus phrase, the a c t i v e  phrase a t  the  highest  depen-dency level.
Note that the focus phrase may be subordinate to other (non-active) phrases i n  the desctipt ion.
The bas ic  idea is  t o  use the  nodes direc-t l y  described by the focus phrase to get a set of candidate topics.
Once thesecandidates are determined, they are matched against  the remaining act ivephrasesi n  the phrase table t o  determine the most l i k e l y  referent .Before describing the matching process, let us first consider a fewspecial cases.
Suppose, for instance, that the focus phrasq directly des-cribes only one topic node and that any additional active phrases are alsopresent ih that toflic representation.
The presence (or absence) of non-active phrases in the description is, in this case, an important parameter.Any non-active phkases may serve to distinguish the description from the exis-ting topic.
On the other hand, they could very well represent additional des-cription of the topic at hand.
If the topic under consideration is recent, wefirst assume the latter case.
In addition, when processing descriptions ren-dered for retrieval, the netwofk locator naturally rules out the possibilitythat a new topic is being described and accepts the one at hand.The_matching process.
When the focus phrase directly describes two ormore nodes, a network matching procedure is used to determine which of theassociated topics the description references.
The matching routine uses alist of the candidate nodes, a list of the active phrases in the description,and the current contents of the representational network.
For each candidatenode, the routine determines how many of the descripti~n's active phrasesdirectly or indirectly describe that node.
The matching routine returns atable of t h i s  information along with the number of the node, if any, that bestmatches the input- description.
The "best" node is the one that has the high-est number of matching phrases.
If two or more nodes have an equal number ofmatching phrases, an attempt is made to choose one of them on the basis a?
con-text.The simplified flow diagram appearing in Fig.
18 summarizes the decisionprocedure for the case in whikh the description contains one or more active#up--the number of upwardpointers  t o  nodes fromthe focus phraseilevel--a user-specifiedi n t e rac t ion  level#nonac t--number of nonac t ivephrases i n  the des-c r ip t ionf indmode--a binary flag, "on"fo r  r e t r i e v a l  descrip-iionsPig.
18 - Network Location Procedure for Descriptions Containing Active Phrasesphrases.
Note i n  p a r t i c u l a r  t h a t  i n  case the descr ip t ion  cons i s t s  of only as i n g l e  active phrase tha t  d i r e c t l y  descr ibes  a s i n g l e  node, t he  network l ~ c a -t o r  assumes the  node immediately.
The r a t i o n a l e  is t h a t  we  a n t i c i p a t e  theuser  w i l l  f requently make use of such terse descr ip t ions  i n  reference t o  pre-viously define topics .
Recal l ing our earlier d iscuss ion of human referent ia lcommunication, a speaker makes incomplete references wi th  the  assumption t h a tthe t o p i c  can be i n fe r r ed  by t h e  l i s t e n e r ;  otherwise, he descr ibes  h i s  sub jec tmore p rec i se ly  t o  avoid being misunderstood.
The network loca tor  was designedwith t h i s  i n  mind.
That is, whenever a terse descr ip t ion  references  a s i n g l enode directly, or i n  context ,  t h a t  node i s  taken as the r e f e r e n t ,Case 11: No.
a c t i v e  phrases.
The f i r s t  s t e p  i n  processing a desc r ip t i onwith no a c t i v e  phrases is  t o  examine i t s  component words, attempting t o  iden-t i f y  poss ib le  r e f e r e n t s  by u t i l i z i n g  the  word and phrase d i r e c t o r i e s .
If nocandidate nodes a r e  generated by the  procedure, the  network loca tor  assumesa new t op ic  is being defined and allocates new nodes i n  the  network,Non-acttve descr ip t ions  t h a t  reference  e x i s t i n g  top i c s  f a l l  i n t o  two cate-gories .
F i r s t ,  t he re  are those t h a t  paraphrase some e x i s t i n g  top i c  descrip-t t on ,  For example, a t o p i c  o r i g i n a l l y  described a s  THE USE OF THESAURI IN THESMART S'ISTEMmay subsequently be referred t o  as THESAURI TECHNIQUES I N  SALTON'SSYSTEN.
Second, the description may c o n s t i t u t e  a more s p e c i f i c  c l a s s i f i c a t i o nof some topic.
While working i n  t he  context  of a p a r t i c u l a r  paper, f o r  ex-ample, the  user  may describe a new i t e m  as THE ORGANIZATION OF THE PAPER, whereORGANIZATION OF PAPER is a non-active phrase.The word search procedure involves the use of s e l ec t ed  words from the  des-c r i p t i o n  and the wofd d i r e c t o q  t o  ob t a in  a set of a c t i v e  phrases containingrhose words.
From there ,  a s e t  of nodes i s  obtained by co l l ec t i ng  the  upwardpo in te r s  from those phrases i n  t he  phrase d i rec to ry .
The r e s u l t a n t  set ofnodes then is  processed as a list of candidate t op i c s  just a s  i f  they had beenobtained immediately from a descr ip t ion  containing a c t i v e  phrases.An important considerat ion here  is which of the  words i n  the  descr ip t iont o  use i n  the  search f o r  candidate topics .
In  an e a r l y  vers ion of the system,w e  t r i e d  using each noun and modifier i n  turn.
Although this approach w a s  suc-ce s s fu l  i n  many cases, i t  of ten  r e su l t ed  i n  an extremely lengthy list of a l t e r -na t ives .
We a l s o  noted t h a t  words a t  the highes t  dependency l e v e l  more o f tenl ed  t o  i d e n t i f i c a t i o n  of the  t o p i c  node than those words occurr ing a t  subordin-ate levels .
For t h i s  reason, it w a s  decided t o  c u r t a i l  the  word search, using1 I only t h e  words i n  t he  roo t  phrase" of t h e  descr ip t ion .
Fop the  non-activedescr ip t ion  PAPER ON CLUSTERING I N  THE SMART SYSTEM, the  words PAPSR and CLUS-TERING would be used in the  search f o r  candidate nodes.
A s  a user option,  thesystem w i l l  expand t h e  search t o  inc lude  the  remaining words i n  the  descr ip t ion .There a r e  four  stages i n  the search f o r  candidate top ics  (see below).Stages 1 and 2 deal with the sub jec t  word of t h e  roo t  phrase; Stages 3 and 4with the modifier word.
In  Stages 1 and%3, only those nodes d i r e c t l y  describedby phrases having the p a r t i c u l a r  word i n  sub jec t  pos i t i on  a r e  considered.
InStages 2 and 4, t op i c  nodes with t he  word i n  modifier pos i t i on  are considered.Stage 1Stage 2S,tage 3Stage 4Role of wordtinthe  descr ip t ionSubjectSubjectModifierModifierRole of word i nt h e  networkSubjectModifierSubjectModifierAfter completion of each stage, i f  there  were any nodes generated theyare passed through the recency check.
I f  no node is  dist inguished,  the  useri s  presented with a l i s t  of the  a l t e rna t ives .
The user  may then choose one ofthe topics  o r  reply t h a t  none i s  the  intended re feren t ,  i n  which case the  nexts tage is  t r i e d .I f  a node eventually is iden t i f i ed  by t h i s  process, the  locator  must notethe  s tage i t  i s  i n ,  s ince each case implies a d i s t i n c t  links table .
Fig.
19gives an example of each case.
The s t a t e  of the  network before processing thedescr ipt ion i s  i l l u s t r a t e d  $y s o l i d  l i n e s ;  the network addi t ions  by dashedl ines .
Note tha t  is the Stage 2 example, the  user  o r ig ina l ly  described a newtopic  simply a s  ORGANIZATION OF THE PAPER and then gave a more complete des-c r ip t ion  of the  paper.
The descr ipt ion of the paper was a l so  l e f t  pending inthe  Stage 4 example.
In f a c t ,  Case 2 and 4 can only occur i n  t h i s  s i t u a t i o ns ince the  presence of a simple phrase with paper a s  the subject  noun would havebeen picked up earlier i n  e i t h e r  Stage 1 or 3.The s tage i n  which top ic  iden t i f i ca t ion  i s  made a l s o  is  important whenprocessing r e t r i e v a l  descript ions,  Recall  t h a t  a p r i ac ipa l  advantage of ther e f e r e n t i a l  system i s  t h a t  i t  enriches i t s  representat ion of the  user 's  topicsduring r e t r i e v a l .
Whenever a r e t r i e v a l  descr ipt ion contains s i m p l e  phrases notasready present  i n  the  representat ion of the  iden t i f i ed  topic ,  they a re  addedt o  the representation.
However, i f  top ic  iden t i f i ca t ion  occurs i n  Stage 2 ,note t h a t  a simple phrase w i l l  be added a t  one l eve l  higher than the decidedtopic.
I f  processing a r e t r i e v a l  descr ipt ion,  the addit ion would be meaning-less a s  i t  w i l l  not enrich the  descr ipt ion of the iden t i f i ed  node.
For example,i f  the user  has previously described a paper and l a t e r  c a l l s  f o r  the r e t r i e v a lI 1i Acm II CONFERENCE I\--Z'4'CI-2.-\'.
'.\(a) Stage 1.
User input: The paper for the Acm conference.I PAPER about I PAPER f o r  I1I PAPER for I i , conference IL,,, _IplannedPAPERI Autonote I I conference 1I I I IL -  - -, L - - - - - -  JPAPER aboutAutonote(b) Stage 2.
User input: The paper about Autonote for the conference.Fig.
19 - Network Alterations Arising from a Successful Word Search in Eachof the Four Stages1 of paper\\PAPER about( c )  Stage 3.
User inpu t :  The organizat ion  of t h e  paper .// - \I \\ I/4- - * \\\ \ / \\ / \\ / \\ /4, - % b r - - -  --1 Y/ \ IORGANIZATION I \ ' I SUMMARYI 1 of paper , \N' - 0 v L - - - - -  / \ AI I IPAPER about 1 I PAPER f o r  ,I Autonote i 1 conference1 I(d) Stage 4 ,  User input: Summary of the pape r  about Autdnote f o r  the  confer-ence.Fig, 19 - Continuedof MATERIAL FOR THE PAPER, the  add i t ion  of a higher  order  node po in t ing  downt o  the "paper" node i s  of no value  i n  l a t e r  referencing the  top ic .
In  suchcases,  the  network loca to r  r e tu rns  the  located  node t o  the  r e t r i e v a l  processorand suppresses the  network addi t ion .
To s t a t e  t h i s  more genera l ly ,  r e t r i e v a ldesc r ip t ions  are employed t o  augment t he  represen ta t ion  only when the  addi-t i o n a l  phrases c o n s t i t u t e  co-ordinate o r  subordinate descr ip t ion  of the  loca tedtopic .Although w e  have found the  word searching procedure q u i t e  e f f e c t i v e ,  i t ssuccess u l t imate ly  depends upon a co-occurrance of some word i n  both the  des-c r i p t i o n  and the  Yepresentational network.
A proposed extension t o  AUTONOTE2,as described in  Linn (1972), would augment t h i s  procedure t o  inc lude  word s t e mand synonym processing.The major objec t ion  t o  t h i s  procedure is  t h a t  as t h e  network grows largeri t  generates  too many candidate nodes and consequently more quer ies  t o  t heuse r .To alleviate t h i s  problem, we al low the  use r  t o  cancel  processing of the des-c r i p t i o n  any t i m e  he decides t he  system is  having d i f f i c u l t y  r e l a t i n g  h i s  des-c r i p t i o n  t o  t h e  cur ren t  representa t ion ,  I n  add i t i on ,  i f  the  u se r  i s  unsurehow he previously described a p a r t i c u l a r  topic, a facility is  provided t h a tallows him t o  obtain t o p i c  descr ip t ions  from a spec i f i ed  region of the  network.Upon not ing t h e  t o p i c  he o r i g i n a l l y  intended, he  may then give a more p rec i sedescr ip t ion .Case 111: One word descr ip t ions .
Descript ions cons i s t ing  of a s i n g l enoun are processed i n  much the  same manner as non-active d e s c r i p t i ~ n s ,  Thenoun i s  treated as i f  i t  r e su l t ed  from a d e l e t i o n  on a simple phrase.
The w r dd i r ec to ry  is f i r s t  searched f o r  simple phrases i n  which the  word appears as thesubject and, if necessary, the modifier.
The nodes obtained from the phrasedirectory then are processed as described earlier.VI.
NETWORK MEDIATED RETRIEVALThe previous sections dealt primarily with the process of item descrip-tion, that is, the process of constructing a representation from descriptionsof the user's textual materials.
This section discusses the AUTONOTE2 proced-ures that retrieve information through the representational network.Retrieval via DescriptionsMany of the procedures described earlier for item description and repre-sentation are used in retrieval.
The user initiates retrieval by giving a FINDcommand, supplying a description as argument.
Retrieval descriptions are firstpassed to the parser, and are therefore subject to exactly the same constraintsas item descriptions.
If the description is acceptable, the resultant phrasetable is passed along to the netw~rn locator which ultimately returns a nodenumber to the FIND processor.The FIND processor constructs a set of item numbers by extracting thetextual references from the node returned by the network locator.
The systemthen checks for upward poipters from the node, to more specifically describedmaterials, If there are ~tructurally related topics, the FIND processor soinforms the user and asks if he would like to explore further.
If so, theuser is presented with descriptions of the higher order alternatives.
Usingthe network depicted in Fig.
16, for example, consider the retrieval requestFIND THE PLANNED PAPER ABOUT AUTONOTE.
The network locator would determinet h a t  node 1 i s  the desired referent  and re turn  t h a t  fact t o  the  FIND processor.After s tor ing  away the  item references of node 1 the system would ask:DO YOU WANT:A.
THE ORGANIZATION OF THE PAPERB w  THE REVIEWER'S COMMENTS ON THE PAPERThe user m y  respond with an appropriate letter indicating which topic hedesires.
If the top ic  selected a l s o  has higher order nodes, the  process isrepeated u n t i l  the user  terminates the  search.I f  the  node returned by the  network locator  has no associated item refer-ences, the system searches upward i n  the  network f o r  a node with t e x t  i t e mpointers.
I f  a node is reached with multiple upward paths, the  system stopsand queries the user.
For example, i f  a user has entered only an out l ine  andsome bibliographic references f o r  a paper he is wri t ing,  then a r e t r i e v a l  des-c r ip t ion  tha t  maps onto the "paper" node would e l i c i t  a query such as:DO YOU WANT:A.
THE OUTLINE OF THE PAPERB.
BIBLIOGRAPHIC WFERENCES FOR THP, PAPERThis example i l l u s t r a t e s  a d i s t i n c t  advantage of the  r e f e r e n t i a l  systemover sfmple keyword indexing.
When the  user ' s  descript ion i s  imprecise, AUTO-NOTE2 d i r e c t s  the  user  t o  re la ted  top ic  nodes with associated tex tua l  materials ,Upon termination of the search, the r e su l t an t  set of t ex tua l  references isstored internal ly .
Depending upon the  user' s option se t t ings  , a referencecount and the  set of ftem numbers then may be displayed on the  user ' s  consoh.The user may PRINT those pa r t i cu la r  items he wishes ta see,  o r  he may simplyRETRIEVE the  e n t i r e  s e t ,I n  dea l ing  wi th  groups of r e l a t e d  i t e m s ,  network mediated r e t r i e v a l  hasthree major advantages over simple keyword-based technfques.
F i r s t ,  the  u s e rI I need only make his desc r ip t i ons  more specific in order  t o  zero in" upon cor-respondingly specific t e x t u a l  materials.
Second, the  r ep re sen ta t i ona l  networkenables  the system t o  use the use r ' s  o r i g i n a l  de sc r ip t i on  as a s t a r t i n g  p o i n ti n  guiding h i m  t o  s t r u c t u r a l l y  r e l a t e d  t o p i c  nodes.
F i n a l l y ,  the p o s s i b i l i t yof network exp lora t ion  can help the  use r  recal l  the s t r u c t u r e  of t he  materialsrepresented i n  some por t ion  of t he  network.
This can be quite valuable afterthe user has spent an extended period working with  o ther  t o p i c s ,  or  as t henumber of t o p i c s  and t h e i r  in te rconnec t ions  become large.After processing a r e t r i e v a l  reques t ,  t h e  system determines i f  the u s e r ' sde sc r ip t i on  contained any p repos i t i ona l  phrases  o r  ad j ec t ives  n o t  alreadypresen t  i n  the i d e n t i f i e d  t o p i c ' s  r epresen ta t ion .
I f  so ,  t h e  t o p i c  descr ipt i o n  is enriched accordingly.
For example, if the  represen ta t ion  of thelocated node is THE PAPER FOR TNEl ACM CONFERENCE, and the user  referred to itby the retrieval desc r ip t i on  TKE PAPFR FOR THE FALL CONFERENCE, the systemwill augment i ts  represen ta t ion  t o  inc lude  the simple phrase FALL CONFERENCE.This  is an important  aspect of AUTONOTEZ.
Whether desc r ip t i ons  are employedfor t h e  purpose of charac te r iz ing  text  i t e m s  o r  retrieviag them, the  systemcontinually updates i ts  represen ta t ion  of t he  user ' s  topics ,  I n  add i t ion ,t h i s  example i l l u s t r a t e s  how the  system i s  a b l e  t o  establish a limited form ofphrase synonomy.
There will subsequently be a node i n  the network directlydescribed by both  ACM CONFERENCE and FALL CONFERENCE, and any t o p i c  assoc ia tedw i t h  that node may l a t e r  be referenced using e i t h e r  o r  both of t he  two simplephrases.Interrogating .the NetworkAs the network grows complex, the user must be able  t o  question the sys-tem about the current  representation.
This capability may help him recall  thestructure of some set of related topics.
O r ,  p r i o r  t o  formulating a new topicdescription, the user may wish to examine the representat ional  network f o rpossible re la ted topics.
Finally,  per iodic  perusal  of the network maystrengthen the user ' s  own conceptual representat ion of the various topics andtheir interrelationships.The DESCRIBE command r e t r i eves  top ic  descr ipt ions  ?tom the representa-tional network.
It accepts 9 variety of arguments and first generates a setof topic nodes.
Then, using the SPEAKER routine, it outputs a description ofesch n ~ d e  in the set.
The various input forms include t h e  following.DESCRIBE ITEM <list).
Each time the description processor adds a t ex tua lreference t o  a node, the node number is  placed in a predetermined location inthe text f i l e  region of the,item.
The DESCRIBE processor consequently hasaccess t o  the desired set of associated node numbers.
For any par t i cu la r  t ex ti tem,  the user may wish to know which topics  it currently is associated with.Initially, when an i t e m  is first described by t h e  user, t h e  actual descript ionline i s  placed in the data base beneath the text.
To recall how he describedan item origfnally, the user need only request that the item be printed (omit-ting the text  i.f he chooses).
But the o r ig ina l  descript ion may have been onlya terse reference, i n  contex t , to  amore fully described node.
Furthermore, thedescription of that node may have been enriched o r  altered subsequent t o  theentry of the item.
To obtain a full description of each topic presentlyassocia ted  wi th  the  i t e m ,  r egard less  of how t h e  i tem o r i g i n a l l y  was described,the user  employs DESCRIBE ITEM.DESCRIBE CURRENT [TOPICL.
A po in te r  t o  t he  node most recen t ly  referencedi n  t h e  repxesentat ion i s  maintained i n  t he  node d i rec to ry .
I n  response t ot h i s  command, the  DESCRIBE rou t ine  simply determines the node number and dis-p lays  i ts  descr ip t ion .
The cur ren t  node number is saved between AUTONOTE2sess ions ;  t h i s  command i s  o f t e n  employed a t  the  beginning of a sess ion t oremind the  u se r  of the  previotis working context .DESCRIBE TOPICS.
This command causes every node i n  t h e  network havingassocia ted  i t e m  references  t o  be described.
Because of the  voEuminous output ,i t  i s  most f requent ly  employed i r i  batch mode.DESCRIBE <descript ion>.
When the  DESCRIBE rou t ine  encounters an argumentt h a t  is no t  i n  one of the s p e c i a l  forms discussed above, i t  t r e a t s  the inpu t  asa phrasa l  descr ip t ion .
Using the  parse r  and network loca to r ,  an attempt i smade t o  map the input  i n t o  a unique t o p i c  node.
T f  successful ,  a complete des-c r i p t i o n  of t h e  node i s  presented t o  the  user .
Thus, i f  the  user  cannot re-call prec i se ly  how he described some top ic ,  he may supply an incomplete rder-ence t o  ob ta in  t h e  t op i c  descr ip t ion  i n  f u l l .The network loca tor  funct ions  somewhat d i f f e r e n t l y  when processing a des.c r i p t i o n  f o r  t he  DESCRIBE command.
I f  i t  is  unable t o  d i sce rn  a unique nodeusing the  matching procedure and context,  a list of the  a l t e r n a t i v e s  i s  re-turned f o r  subsequent display.The FULLY modifier.
The user  may reques t  t h e  d isplay  of a  hos t  of r e l a t e dtopics by employing the.
JXJLLY modifier.
Spec i f i ca l l y ,  t he  user  types DESCRIBEFULLY, followed by any of t he  argument forms discussed above.
As before,  t h i sgenerates a node or  set of nodes.
When describing FULLY, each node i s  i n  turnexpanded i n t o  a set of s t r u c t u r a l l y  re la ted  nodes a l so  having associated text-ua l  references.A s  an example, consider again the network i n  Fig.
16.
The user  types DES-CRIBE 'FULLY, THE PAPER ABOUT AUTONOTE.
Assuming no choice i s  possible  i n  con-text, the  descr ipt ion i s  ambiguous, and the  network loca tor  r e tu rns  nodes 1and 5 .The two nodes themare  passed t o  a rout ine  that displays  an indented out-l ine representing the s t r u c t u r a l l y  r e l a t ed  top ics  reached by moving upward i nthe network.
Each l e v e l  of indentat ion represents  a node l e v e l  traversed i nthe network.
In th i s  example the  following o u t l i n e  would be pr inted:A.
THE PLANNED PAPER FOR THE ACM CONFE3ENCETHE: ORGANIZATION OF THE PAPERTHE REVIEWER'S COMMENTS ON THE PAPERB.
THE FIRST PAPER ABOUT AUTONOTETHE ABSTRACT OF THE PAPERDESCRIBE STRUCTURES.
This  command functions as if FULLY was specif ied,diaplaying ou t l ines  of each top ic  c l u s t e r  i n  t h e  representat ional  network.
Toaccomplish t h i s ,  the network is  searched f o r  nodes having nowdownward pointerst o  other nodes.
Each such node corresponds t o  the lowest order node level i na pa r t i cu la r  c l u s t e r  of related topics.
When described FULLY, t he  e f f e c t  ist o  reveal t he  s t r u c t u r a l  ou t l ine  of i ts  associa ted c lus te r .The SPEAKER ConrpanentA s  we have seen, SPEAKER i s  invoked during many phases of AUTONOTE2'soperation.
The calling rout ine  passes the SPEAKER a node number.
A buffercontaining a phrasal descr ipt ion of the node i s  returned.
A second, opt ionalinput  parameter spec i f i e s  the  level of d e t a i l  desired i n  the r e su l t an t  des-c r ip t ion ,  The level ind ica tor  corresponds t o  the  number of node l eve l s  i nthe representat ion t o  be employed i n  formulating t h e  descr ipt ion.The l e v e l  ind ica tor  is p a r t i c u l a r l y  use fu l  when the  system must questionthe  i n t e n t  of a descript ion.
When querying the user  during the network loca-t i o n  process,  f o r  example, the system requests  top ic  descr ip t ions  from theSPEAKER with  the  l e v e l  ind ica to r  set according t o  the use r ' s  current preferredl e v e l o f d e t a i l , a s  in fer red  from h i s  most recent  descr ipt ion.
For example, i fthe user describes an i t e m  as RESULTS OF THE EXPERIMENT and the system mustask i f  he is re fe r r ing  t o  SMITH'S EXPERIMENT ON THE SHORT TERM MENORY OF WHITERATS, the  r e s u l t i n g  query would be ARE YOU REFlERRING TO SMITH'S EXPERIMENT ONMEMORY?The p rocess  of constructing a descr ip t ion  from the  network takes place i ntwo stages.
The f i r s t  s tage  s t e p s  through t h e  network recurs ively ,  co l l ec t ingthe  simple phrases that d i r e c t l y  o r  i n d i r e c t l y  describe the specif ied node.The level ind ica tor ,  i f  appl icable ,  blocks the  co l lec t ion  of simple phrasesbelow the  spec i f ied  level .
During t h i s  s tage ,  the  SPEAKER constructs  twot ab les  of words, one f o r  subjec t  nouns and another f o r  modifiers.
Each en t ryi n  the  sub jec t s  t ab le  is  l inked t o  a l ist  of ad jec t ives  f o r  t h a t  subject ,  anda l ist  (ca l led  the modification chain) of preposi t ional  modifications of thesubjec.t noun.
For example, t h e  subjects  t a b l e s  en t ry  f o r  PAPER may have anadject ive  list containing PLANNED, and a modification chain consis t ing of(ABOUT) AUTONOTE and (FOR) CONEI3RENCE.
Both of the  lists are chained throughthe  t a b l e  oE modifiers.
Note t h a t  some words w i l l  appear i n  both the subjec tand modifier tables .
For example, PAPER may be i n  the modifler t ab le  a s  p a r tof the  modification chain of the word ORGANTZATION, and also is the subjectstable with a modification chain of i t s  own,The subjects  t ab le  also maintains ar t ic le  usage information f o r  each ofi ts  en t r ies .
Fig.
20 i l l u s t r a t e s  the subject  and modi f i e r  tables constructedfrom a typ ica l  top ic  node,(a) Subjects tab leA(b) Modifier tab letSubjectNounorganizationPaperconferencesFig.
20 - SPEAKER tab les  generated from the  network representat ion ofORGANIZATION OF TTB PLANNED PAPER ABOUT AUTONOTE FOR THEACM C O m R E N C E  .Art ic lethethetheAChainLink.... * a(5)......- iC -ModifierWord(13 planned(2) paper(3) autonote(4) acm(5) conf erenceThe second stage i s  carried out by a recursive algorithm that  operates on- YModificationChain(2)(3)...Level133Prepositionadjofaboutadjf o rthe two tables  t o  construct the phrasal  descript ion.
The process begins withthe f i r s t  word i n  the subjects  table, i n  t h i s  case ORGANIZATION.
If an a r t i c l eapplies, i t  is added t o  the descr ipt ion buffer.
Next, the adject ive  chain i s-.
,._LAdjectiveChain.
.
.
(1)( 4 )t raversed adding each a d j e c t i v e  i n  tu rn  t o  t h e  buf fe r .
I n  t h i s  case t h e r e  a r eno ad jec t ive8  so  the cur ren t  sub jec t  word (ORGANIZATION) i s  added t o  t h e  buf-f e r  and t h e  systetn continues wi th  the modificat ion chain.
This l eads  t o  thesecond e n t r y  i n  t h e  modif ier  t a b l e ,  (OF) PAPER.
The prepos i t ion  i s  then addedt o  the buffer  y i e ld ing  THE ORGANIZATION OF.
Next, a check i s  made i n  the  sub-j e c t s  t a b l e  t o  determine if the cur ren t  modif ier  word (PAPER) is  f u r t h e r  des-cribed.
Since t he re  i s  an en t ry  f o r  PAPER, t h e  cur ren t  p o s i t i o n  i n  the  modi-f i c a t i o n  chain f o r  ORGANIZATION i s  placed on a  push down s t ack  ( t h e  goa l  s tacwand the  algori thm recurses  on t h e  word paper.
After  adding the  a r t i c l e ,  thea d j e c t i v e  (PLANNED), and t h e  sub jec t  word (PAPER), the  desc r ip t i on  bu f f e r  con-t a i n s  THE ORGANIZATION OF THE PLANNED PAPER.
The system now begins processingthe  modif icat ion chain of PAPER.
The f i r s t  p iece  of t h e  chain adds ABOUT AUTSNOTE t o  t he  bu f f e r ,  Note tha t  t he re  was no recurs ion on AUTONOTE because t h a tword does not have a sub jec t s  table entry .
The po in te r  t o  the  next p i ece  oft he  modif icat ion chain,  (FOR) CONFERENCE, i s  then picked up from the  l i nk  f i e l dof the AUTONOTE entry.
Af te r  adding the  p repos i t ion  (FOR), the  algori thm re-curses  on CONFERENCE, adding THE, ACM, and CONFERENCE i n  t u r n  t o  the  bu f f e r .The goa l  stack is  then popped i n  search of remaining modif icat ion chain poin-ters.
The f i r s t  "pop" r e s t o r e s  t he  PAPER modif icat ion chain.
Since t h e r e  isno a d d i t i o n a l  modif icat ion of t he  paper, t h e  goal  s t ack  i s  popped again t or e s t o r e  the ORGANIZATION chain,  We a r e  a t  the  end of t h i s  chain a l so ,  andthus the process terminates with t he  desc r ip t i on  bu f f e r  reading: THE ORGANZ-ATION OF THE P W E D  PAPER ABOUT AUTONOTE FOR THE ACM CONFERNECE.SPEAKER h e u r i s t i c s .
The add i t ion  of phrases t o  a t o p i c  i n  many casescould reduce the r e a d a b i l i t y  of i t s  SPEAKER-generated descr ip t ion .
Forexample, suppose a t o p i c  is f i r s t  defined as SAMPLE DESCRIPTIONS FOR USE INTHE ACM PRESENTATION, and l a t e r  i s  r e f e r r ed  t o  a s  SAMPLE DESCRIPTIONS FOR USEIN THE NSF PROPOSAL.
Given only t he  algorithm j u s t  presented,  t h e  SPEAKERgenerated descr ip t ion  would be SAMPLE DESCRIPTIONS FOR USE I N  THE ACM PRESEN-TATION IN THE NSF PROPOSAL.
To avoid such unreadable descr ip t ions ,  wheneverthe  modification chain f o r  a sub jec t  noun contains two o r  more p repos i t i ona lphrases headed by the same preposi t ion ,  the SPEAKER sets off  each phrase a f t e rthe f i r s t  with parentheses.
The above example then becomes SAMPLE DESCRIP-TIONS FOR USE I N  THE ACM PRESENTATION (AND THE NSF PROPOSAL).
Note t h a t  adescr ip t ion  such a s  C O W T S  - ON SMITH'S ARTICLE - ON CLUSTERING i s  no t  processedi n  t h i s  manner s i n c e  (ON) ARVTCLE i s  i n  the  modif icat ion chain of COMMENTS,while (ON) CLUSTERING is i n  the  modif icat ion chain of t h e  work ARTICLE.
Notea l s o  t h a t  although p a r e n t h e t i ~ a l  phfases a r e  excluded from t o p i c  descr ip t ionsgenerated f o r  the purpoSe of Lnterrogating the  u se r ,  when the use r  reques ts  adescr ip t ion  of a t p p i c  v i a  t he  DESCRIBE command, t h e  complete desc r ip t i on  isprovided .Simpl i f ica t ion  of l i s t  processing.
It may be added here  t h a t  our decis-ion t o  maintain the  represen ta t iona l  network i n  d i sk  file s to rage  has g r e a t l ys impl i f ied  t he  l is t  processing i n  recurs ive  algorithms such as the SPEAKER,The network can be envisioned as a complex list structure where the l i n k s  aresimply l i n e  file numbers.
To i l l u s t r a t e  t h i s  po in t ,  consider t h e  recurs iveco l l ec t i on  of simple phrases carried out  i n  the f i r s t  s t e p  of t he  SPEAKER.The main body of t h e  rou t ine  c o l l e c t s  the simple phrases t h a t  d i r e c t l y  descr ibea node.
I f  the node processed has downward links t o  subordinate nodes, theyare placed on a push down stack.
Next t he  s t a c k  i s  popped and the rou t ine  i sc a l l e d  recurs ive ly  t o  opera te  on a new node number.
Thus a l l  the  concomitantproblems of s to rage  management t h a t  are normally present i n  l i s t  processingsystems are avoided.
Recursive de le t ion ,  discussed i n  the  next s ec t ion ,s imi l a r ly  is  s impl i f ied .
To d e l e t e  a po r t i on  of the  l i s t  s t r u c t u r e  requ i resonly the  removal of a l i n e  from a d i r ec to ry  f i l e .
Thus the process of "garbagecol lec t ion"  i s  both automatic and t ransparen t  t o  AUTONOTE2.V I I .
NETWORK MODIFICATIONProcedures f o r  modifying the  r ep re sen ta t i ona l  network a r e  required f o rseveral reasons.
Should t h e  system i n c o r r e c t l y  parse  a descr ip t ion ,  the  user 'sa b i l i t y  t o  r e f e r e n c e ~ t h e  associa ted  t o p i c  w i l l  be i m p a i r e d .
The user  may wisht o  alter t h e  descr ip t ion  of a top i c  t o  (a) make i t  more p rec i se ,  (b) i n s u r ethat  i t  i s  not confused with s i m i l a r l y  described top ics ,  o r  (c) enable a t o p i ct o  be  referenced i n  more than one way, Af ter  i n i t i a l l y  descr ib ing a t e x t  i t e m ,t he  user  may discover  t h a t  t he  i t e m  should a l s o  be associa ted  with o ther  t op i c si n  the  representa t ion .
Al te rna t ive ly ,  he may decide t h a t  a text item shouldbe dissociated from some topic .
The user may wish t o  d e l e t e  an obsolete  t o p i cfrom the  represen ta t ion  a l t oge the r ,  o r  rep lace  a descr ip t ion  i n  i t s  e n t i r e t yby a more s u i t a b l e  one while  maintaining t h e  same l is t  of associa ted  t e x t u a lreferences.
F ina l ly ,  when deal ing wi th  a group of s t r u c t u r a l l y  r e l a t e d  t op i c s ,t h e  user  may wish t o  d e l e t e  an e n t i r e  s t r u c t u r e ,  or c e r t a i n  components of as t r u c t u r e ,  from the  network.We cannot expect a t y p i c a l  use r  t o  t h ink  i n  terms of l ist  s t r u c t u r e s ,nodes, linkages, e t c .
Thus we sought t o  provide a command language andfeedback more or less independent of the internal data structures that imple-ment the representation.
In addition, care was taken to avoid(the possibilityof accidental damage to the representation steming from misunderstanding ormisapplication of the modification procedures.The resultant processor includes procedures for removing or adding itemreferences to a topic, deleting topics, adding or removing simple phrases fromthe description of a topic, e t c .
Rather than require the user to identify theparticular topic to be altered each time a modification is to be performed,primitives are implemented as local commands to a generalized modificattonprocessor.The modification processor is invoked by issuing a CHANGE command whichaccepts a phrasal description as its argument.
A node in the network is estab-lished as the currentjidentified topic.
The processor then prompts the userfor modification instructions.
After all modifications are completed, theuser types DONE and control is returned to the regular command monitor.
TheCHANGE command also may be issued while in modification mode, thereby changingthe current topic.
Each of the local commands is discussed separately below,using the hypothetical representation depicted in Fig.
21 for illustration.Adding References and Phrases to the NetworkThe ADD command associates additional text references with the currenttopic, and adds simple phrases to the topic's description.
To add item refer-ences, the user types ADD ITEM[S] followed by a list of item numbers.
Thisprocedure is quite useful if the user has a large set of items that pertain toa particular topic.
He simply identifies the topic and adds the list of refer-ences.Fig.
21 - Sample Representation for Discussion of Network ModificationI f  the supplied argument i s  a phrase, it i s  added t o  the current  node.For example, i f  the  current  topic  is THE PAPER FOR THE ACM CONFERENCE, thecommand ADD PAPER ABOUT AUTONOTE causes the  prepos i t iona l  phrase ABOUT AUTO-NOTE t o  become a p a r t  of the top ic  descript ion.
Adjectives may a l s o  be  addedt o  a descr ipt ion (example: ADD SMITH'S PAPER).
I f  only a s ing le  word occursa s  the  argument, i t  i s  assumed t o  be an ad jec t ive  which i s  t o  modify the  cur-r e n t  subject  noun.Moving through the NetworkThe MOVE command allows the user  t o  change the  current  node pointer  fromits present pos i t ion  t o  s t r u c t u r a l l y  proximate top ics  without having t o  en tera  description.
For example, i f  cur ren t ly  located a t  the  "paper" node, thecommand MOVE DOWN causes the ACM CONFERENCE t o  become the  current  topic.
I ft he  current top ic  i s  the  ACM CONFERENCE, MOVE UP w i l l  produce th reehigher order topics .
Each i s  saved, and the  leftmost  node becomes the currenttopic.
Subsequently, t he  user m y  MOVE LEFT o r  RIGHT t o  the other  topics.Mter a successful  move, a b r i e f  descr ipt ion of the new topic  i s  displayed.The Caching F a c i l i t yThe CACHE command s t o r e s  i t e m  references f o r  subsequent use.
If the com-mand i s  given with no argument, the set of text references associated with thecurrent  top ic  is  added t o  an i n t e r n a l  cache.
The caching f a c i l i t y  may be w e dt o  manipulate l a r g e  s e t s  of i t e m  references, f o r  example, i n  t ransfer ing  alli t e m  references from one top ic  t o  another.
This may be accomplished by ident i -fying the f i r s t  t o p i c  and issuing a CACHE command.
After  ident i fy ing  thesecond top i c ,  t he  command ADD CACHE causes t he  s e t  of cached i t e m s  t o  bemerged with those  of the  new topic .Re t r i eva l  CommandsThe r e t r i e v a l  commands of t he  network modification processor  a r e  analo-gous t o  t h e i r  counterpar ts  i n  AUTONOTE, LIST outputs  a l ist  of the  i t e m  num-bers associa ted  wi th  the  cur ren t  topic.
LIST CACHE d i s p l a y s  the  numbers oft he  i tems i n  t he  cache.
PRINT outputs  s e l ec t ed  text i t e m s .
A 1 1  i t e m s  associ-a ted  wi th  t h e  current  t op i c ,  o r  those In t h e  cache, dl1 be pr in ted  i n  responset o  RETRIEVE and RETRIEVE CACHE, respect Lvely,By employing the  IDENTIFY and MOVE commands, the  u se r  may explore therepresenta t ion ,  LISTing t h e  associa ted  references  f o r  each topic .
During theexplora t ion ,  t h e  CACHE command can be used t o  s t o r e  s e l ec t ed  references f o rlater retrieval, o r  t he  u se r  may choose t o  PRINT o r  RETRIEVE pe r t i nen t  re fe r -ences as he goes.
These procedures allow the  r e t r i e v a l  set t o  be shaped i n t e r -ac t i ve ly ,  and more s e l e c t i v e l y  than i s  poss ib le  wi th  the  FIND command discussedearlier.Removing References and Phrases from t h e  NetworkThe REMOVE command accepts  t he  same argument forms as the  ADD command andsimply performs the inverse  operat ions.
The argument ALL also i s  recognized,causing a l l  i t e m  references  t o  be removed from the  cur ren t  topic.Topic Delet ionDELETE may be employed t o  remove obso le te  top ics  from the  representa t ion ,o r  as the f irs t  s t e p  i n  replac ing a t o p i c  descr ip t ion  with a more appropr ia teone.
CREATE then may be used t o  enter the replacement t o p i c  i n t o  t he  network.The major problem i n  the  design of the  top ic  de le t ion  algorithm can bes t a t e d  as follows.
When de le t ing  a topic,  under what circumstances a r es t r u c t u r a l l y  r e l a t ed  nodes t o  be deleted as w e l l ?
Consider the  followingcases.
I n  the  hypothetical  network, a request t o  d e l e t e  the  ''paper" node in-volves a decision about de le t ing  (a) the  ou t l ine  of the  paper, and (b) smith'scomments on the  paper.
Note that i f  the  paper node were deleted and the twohigher order nodes were not ,  the  higher order nodes would no longer be struc-t u r a l l y  re la ted .
I n  addit ion,  t h e i r  descr ipt ions  w i l l  s t i l l  contain the word"paper," but  which paper no longer i s  specif ied.
For these  reaaons, we con-cluded t h a t  a top ic  de le t ion  should also e n t a i l  the  de le t ion  of more spec i f i -cally described topics .
I n  many cases, t h i s  convention is  an advantage, s incethe  user can d e l e t e  & entire s t r u c t u r e  by ident i fy ing  and de le t ing  a s ing lelower order node.The considerations involved i n  dealing with lower order nodes are a b i tmore complex.
Some lower order nodes serve only t o  augment the  descr ipt ionof superior  nodes.
In THE EXPERIMENT ON BLIND RATS, there w i l l  be  a subordin-ate node d i r e c t l y  described as BLIND RATS.
I n  t h i s  case, de le t ion  of the  EX-PERIMENT node should include de le t ion  of the  subordinate node.
On the  otherhand, dele t ion of the "paper" node i n  the  previous example does not  implydele t ion of the  ACM CONEXRENCE topic .
The ACM CONFERENCE node a l s o  plays ar o l e  i n  other  topics .In  the ins tances  we have examined, the  d i s t i n c t i o n  between the two casesseems t o  be t h a t  "unimportant" nodes have n e i t h e r  t ex tua l  references  nor up-ward pointers  t o  other  topics.
The dele t ion  process employs a h e u r i s t i c  basedupon t h i s  observation.
When a subordinate node i s  deemed unimportant, i t  i sde le ted ;  otherwise,  t h e  u se r  i s  asked t o  confirm i t 8  de le t ion .The d e l e t i o n  algorithm.
F i r s t ,  a list of a l l  nodes t o  be de le ted  i s  con-s t ruc t ed .
Af te r  t he  l i s t  is complete, the  u se r  i s  presented wi th  a b r i e f  sum-mary of the  de l e t i ons  t o  be  made and i s  prompted f o r  confirmation.The algori thm f o r  const ruct ing  t h e  d e l e t i o n s  l i s t  i s  recurs ive .
Two push-down stacks are employed: one f o r  s t o r i n g  upward node pa ths  y e t  t o  be ex-plored,  and one f o r  saving downward paths.
The procedure i s  most e a s i l y  ex-p la ined wi th  an example.
Suppose the  user  i d e n t i f i e s  t he  "paper" node and re-ques t s  its de le t ion .
The algori thm begins wi th  node 2 ,  f i r s t  pushing down anyupward po in t e r s  along wi th  t h e  node number (2) t h a t  w a s  being processed whent 1 t h e  po in t e r s  w e r e  added t o  t he  up stack."
I n  t h i s  case the  p a i r s  (1,Z) and(3,Z) are pushed down.
Next, t h e  downward po in t e r s  are placed on the  "downstack" along wi th  t h e  cur ren t  node number.
The cur ren t  node number i s  thenadded t o  t h e  de l e t i ons  list.
The cur ren t  s t a t e  of t he  pushdown s tacks  and thede l e t i bns  list i s  now:The down s t a c k  is  then popped and node 4 i s  es tab l i shed  as the next nodet o  be examined.
Af ter  s e t t i n g  a f l a g  i n d i c a t i n g  t h a t  w e  have j u s t  moved downa level i n  the network, t h e  algorithm recurses  on node 4.
The system d e t e c t st h r e e  upward po in t e r s  ( t o  nodes 2, 5, and 6 ) .
It should now be apparent whywe save t h e  fact  t h a t  node 4 was reached by moving down fram node 2.
When.UP STACK(1,2)(392)kDOWN STACK(4 ,2 )JDELETIONS LIST2placing a node's upward po in te r s  on the  up s tack ,  t h e  node t h a t  led down t othe current  node must be ignored.Upon not ing t h a t  node 4 has upward po in t e r s  i n  add i t ion  t o  node 2 ,  thesystem checks t o  see i f  i t  has just moved down.
In this case it  has; conse-quently, node-4 i s  deemed "important" and the  system asks DO YOU WANT THE ACMCONFERENCE DELETED?
Assume the  reply  i s  NO.
Since the ACM CONFERENCE nodewill remain, the system records t h a t  the l inkage between nodes 2 and 4 must besevered.
The algorithm then recurses  without adding node 4 t o  the  de l e t i onslist.
Note a l s o  t h a t  the  upward po in t e r s  from node 4 t o  nodes 5 and 6 are notplaced on the up stack.
The cur ren t  s t a t e  of the process i s  now:DOWN STACK DELETIONS LISTThe attempt t o  pop the  down s t a c k  f a i l s ,  so  the qp stack i s  popped and af l ag  set t o  i n d i c a t e  upward movement ( t o  node 3).
Node 3 has no upward poin-ters but  i t  has two downward po in te r s ,  t o  nodes 2 and 7.
Node 2 i s  ignored be-cause it l e d  up t o  node 3.
Node 7 i s  placed on t h e  down stack and node 3 i sadded t o  the de l e t i ons  l i s t  yie ld ing:The down stack is popped qnd the algorithm recurses  on node 7.
Node 7 hasneither text references, nor upward po in t e r s  (besides node 3 ) .
Consequently, i tl e  deemed unimportant and is added t o  the deletions l i s t .
We now have:The down s t a c k  is  empty s o  the  up s t ack  i s  popped and the  system recurseson node 1.
The node has no new upward o r  downwardpointers SO i t  i s  added t othe de l e t i ons  list.
Both stacks are now empty and the  algorithm terminateshaving co l l ec t ed  nodes 2, 3, 7 ,  and 1 f o r  de le t ion .Carrying out  t h e  de l e t i on  involves several s teps .
F i r s t ,  any l inkages  be-tween those nodes t h a t  are t o  be dele ted  and those that w i l l  remain a r e  sewzed.These changes w i l l  have been detec ted  and recorded during t h e  recurs ive  col-lection process.
Next the system executes a REMOVE ALL f o r  each node on thede l e t i ons  l is t  so t h a t  no associa ted  t e x t  reference  po in t s  t o  a non-existenttopic .
Then the system removes a l l  po in t e r s  from simple phrases t o  the obso-lete nodes.
Fina l ly ,  each deleted node i s  removed from the node d i r ec to ryf i l e .Creat ing New Topic RepresentationsCREATE enables the  use r  t o  def ine  a new top ic  f o r  the  representa t ion .
Thecommand takes  as argument a descr ip t ion  which i s  processed i n  the normal way,except t h a t  no i t e m  references  a r e  associa ted  with the  top ic .
The new t o p i cbecomes the  cur ren t  node.
AI)D i s  used t o  a s soc i a t e  any appropriate t e x t  refer-ences.
During top i c  de le t ion ,  the  system adds t o  the  cache a l l  t e x t  referencespreviously associa ted  wi th  dele ted  topics .
Consequently,  AD^ CACHE w i l l  nowassociate those items wi th  the  new descr ip t ion .JtL IUP STACK(1,2)*DOWN STACKemptyDELETTONS LIST237When processing a CREATE descr ip t ion ,  the  network loca tor  at tempts  t o  as-s o c i a t e  the descr ip t ion  with an e x i s t i n g  top i c ,  f o r  two reasons.
I f  the  des-c r i p t i o n  i s  t o  be a new top ic  but t he  network loca to r  confuses i t  wi th  anotherone, the user  may want t o  a l t e r  the  descr ip t ion .
Second, t h i s  permits use ofthe CREATE command i n  adding t o  an e x i s t i n g  descr ip t ion .VXfI.
A ,CASE STUDY OF SYSTEM PERFORMANCEThe Inapp l i cab i l i t y  of Recal l  and Prec i s ionThe most widely accepted methods f o r  r e t r i e v a l  systgm evaluat ion  a r e  basedupon recall  and prec i s ion  measures.
A s  applied t o  the  r e s u l t s  of r e t r i e v a lquer ies ,  p r ec i s ion  is defined as the  proportion of r e t r i eved  ma te r i a l  t ha t  i sdeemed re levant  t o  a query; r e c a l l  is the r a t i o  of r e levan t  documents re t r i evedt o  the  total re levan t  i n  the data base.
But r e c a l l  and prec i s ion  cannot mean-i ng fu l ly  be applied t o  the  evaluat ion of AUTONOTE2.
The AUTONOTE2 user  des-c r ibes  each piece of t e x t u a l  mate r ia l  himself.
Even within a l a r g e  personalda t a  base,  t he  user  w i l l  c e r t a in ly  r e c o l l e c t  some of h i s  t o p i c s  and the keywords and phrases t h a t  de f ine  them.
Furthermore, sub jec t  t o  the u s e r ' s  ownl imi t a t i ons  i n  describing h i s  mate r ia l s ,  the top i c  framework of AUTONOTE2 im-p l i e s  "perfect" p rec i s ion  and recall  once a p a r t i c u l a r  t o p i c  is  i d e n t i f i e d  dur-ing r e t r i e v a l .A pr inc ipa l  motivation f o r  the  AUTONOTE2 system w a s  the d e s i r e  t o  overcomethe disadvantages of keyword indexing techniques, which force  the  user t o  t r a plate ideas and concepts per t inen t  t o  a given document i n t o  d i s c r e t e  content in-d ica tors .
In  developing AUTONOTE2 we have sought t o  provide mechanisms f o rdefining and efficiently referencing these concepts directly.
An evaluationof AUTONOTE2 should therefore provide some comparisons of keyword indexing vs.indexing by topic.
To achieve a direct comparison, protocols of both types ofindexing activity with a common data base are required.The Sauvain Data BaseThe original AUTONOTE system was employed in a study (Sauvain, 1970)aimed at uncovering structural communication problems within a keyword-basedsystem.
The resulting data base is related primarily to Sauvain's dissertatlonresearch.
It includes reading notes, bibliographic references, research ideas,expository material, and so on.
The collection brings together a broad rangeof topics and ideas touching upon various aspects of computer science, infor-mation retrieval, man-machine interaction, and psychology.Copies of the item texts, the originally assigned keywords, and protocolso f  Sauvain's activities during data base indexing, organi8ation, and rekrievalwere acquired.
We then proceeded to re-index the collection with AUTONOTE2topic descriptions.
Each of the roughly 400 items in the data base was viewedand described in a sequential fashion; that is, there was no look-ahead or pre-planning of topic phrasings to facilitate network structuring.
Protocols werecollected of all interaction with the system and the state of the network wasrecorded at periodic intervals.
(For details, see Linn, 1972).ResultsFor brevity, AUTONOTE2 reports of parsing assumptions are excluded.However, system responses tha t  elicit a user reply are shown to provide afeeling for user interaction under AUTONOTEZ.Indexing activity.
The AUTONOTEL protocols show a high degree of terse,efficient referencing of previously defined topics.
The communicative effi-ciency was especially great in instances where several consecutive items wereentered on a common topic.
This situation frequently occurred when enteringa set of reading notes on a particular paper or collection of papers.
Typi-cally, the first item in such a set of entries was assigned to one or morenew topics, In describing the subsequent items, references to these topicsoften were conveyed by a s$ngle word or phrase, or by a null description (adescription line consisting of only a slash i s  treated as a reference to thetopic just mentioned).To illustrate, consider the materials dealing with various aspects ofartificial intelligence.
A total of 17 of these items contained notes takenat a 1968 conference at Case Western Reserve University.
Of the AUTONOTE2descriptions supplied for these items, three mention only the word CONFERENCE;five include the subphrase 1968 CONFERENCE; two include CWRU CONFERENCE; andseven make no explicit reference to the conference at all.
Each of the items,t t  however, was associated with a topic node linked in efome way to the confer-ence" node.
Furthermore, though none of the descriptions contain the wor'dsARTIFICIAL o r  INTELLIGENCE, each of the associated items can bedaccesseb Inthe network through the "artificial intelligence" node.In the AUTONOTE protocol for these materials, there was frequent use ofdescriptor abbreviations and other idiosyncratic tags (CWRUAICONF, AT, COGPSY,e t c . )
.
These suggest  a s t rong  d e s i r e  t o  e l imina te  repeated e n t r y  n f  lengthydesc r ip to r s  and phrases.
The major drawback of t h i s  s t r a t e g y ,  however, isthat abbrevia t ions  ( e spec i a l l y  t he  more uncommon ones) are no t  as e a s i l yremembered as t h e  words they represent .
I n  add i t i on ,  once an abbrevia t ion  hasbeen used, the  u se r  q ~ u s t  remember t h a t  he has  done so  i n  order  t o  maintaincons i s t en t  indexing.
I n  con t r a s t ,  there was l i t t l e  motivation f o r  desc r ip to rabbrevia t ions  under t he  AUTONOTE2 system.
Once a lengthy phrase had been de-f i ned  i n  the  network the re  was generally no need t o  reference  i t  again wi th  afull desc r ip t i on ,The Sauvain s tudy i d e n t i f i e d  a c l e a r  need f o r  mechanisms t o  assist theuser i n  maintaining cons i s t en t  indexing.The second type  of need (how -a d e s c r i p t o r  has been used)f requen t ly  occurs when a text  i t e m  is  being entered.
The userhas  some ideas  f o r  candidate d e s c r i p t o r s ,  suspects  t h a t  t he rehas  been p r i o r  usage of these words, and needs a way t o  checkt h e  p r i o r  usage t o  keep h i s  indexing cons i s t en t .
He a l s o  maywant t o  look a t  p r i o r  usage contexts  t o  g e t  i deas  about o the rdesc r ip to r s  t o  use,  o r  t o  weed out  candidates  t h a t  look too general.The t o p i t a l  view of the d a t a  base under AWONOTE2 e l imina tes  p a r t  of t h i sproblem.
When descr ib ing a - new top ic  t he  AUTONOTE2 user  need not  be a s  con-cerned about p r i o r  word usage i n  o the r  contexts .
The represen ta t iona l  networkprovides a means f o r  d i sc r imina t ing  among t h e  var ious  t op i c s  i n  which a par-t i c u l a r  word occurs.I f ,  on t h e  o the r  hand, the  user  suspects  t h a t  the  item a t  hand i s  somehowr e l a t e d  t o  a previously e x i s t i n g  top i c ,  t he re  i s  an analogous need t o  i n t e r ro -gate the  r ep re sen ta t i ona l  network f o r  candidate top ics .
This capab i l i t y  i sprovided by the  DESCRIBE command.
There were, i n  f a c t ,  numerous ins tances  inthe  AUTONOTE2 protocols  of network in t e r roga t ion  p r i o r  t o  en t e r ing  descrip-t ions .
An example i s  given i n  Fig.
22.
I n  response t o  t h e  u se r ' s  descript ionUSER: OPENUSBR: /SALTON'S ccs COLLOQUIUM ON EVALUATIONEJEW TOPIC ASSUMEDUSER: RELOCATEWHICH DO YOU MEAN:A. THIE COMPUTER EVALUATION OF INDEXING (AND TEXT PROCESSING)B.
EVALUATION OF CRT DISPLAY USAGEFig.
22 - Network in t e r roga t ion  d u r h g  desc r ip t i on  en t ryt he  system indicates that  no assoc ia t ion  w i l l  be made wi th  a p r i o r  top ic .
Theuser  r e c a l l s  talking about t h e  eva lua t ion  of automatic indexing techniquesearlier so  he reques ts  the  system t o  search f u r t h e r  by en te r ing  a RELOCATE com-mand.
Two candidates are generated, one of which is  the  des i red  r e f e r en t .Under the,keyword system, searching f o r  candidate desc r ip to r s  and usagecontexts  was much more tedious.
Typical ly,  a RETRIEVE: command was i ssued cal-l i n g  f o r  the  d i sp lay  of a l l  keyword l ines  of i t e m s  indexed by a p a r t i c u l a r  termo r  l o g i c a l  combination of terms.
I n  some cases a l a r g e  number of i tems wereaccessed neces s i t a t i ng  t i m e  consuming perusal  of  t h e  da t a  base.The d iscuss ion  thus  far should convey some f e e l i n g  for the degree of com-municative e f f i c i ency  achievable wi th  AUTONOTE2.
To provide a more precisei nd i ca t ion  of t h i s  aspect  of system performance w e  ca lcu la ted  the  r a t i o  ofcontent  words conveyed t o  content  words entered  f o r  th ree  samples of da ta  baseitems ( a r t i c l e s  and preposi t ions  were excluded).
The average number of AUTO-NOTE2 words entered  and conveyed were compared wi th  the  average number ofAUTONOTE keywords assigned wi th in  each sample (under the  keyword system t h i sr a t i o  w i l l  always equal one).
The th ree  samples taken were (1) a random sampleof 50 items, (2) 41 sequen t ia l  items, and (3)  a l l  items deal ing with some as-pect  of a r t i f i c i a l  i n t e l l i gence .The r e s u l t s  of t h i s  t abu la t ion  are summarized i n  Fig.
23.
In  a l l  t h r eesamples more than th ree  content words were conveyed f o r  every two entered,  onthe  average.
The conveyed-entered r a t i o  was lowest f o r  the  random sample andhighes t  f o r  t h e  a r t i f i c i a l  i n t e l l i g e n c e  i t e m s .
This i s  because most of theitems deal ing wi th  a r t i f i c i a l  i n t e l l i g e n c e  were entered wi th  a r i c h  g lobal  con-t e x t  of t op i c  nodes defined.
The sequen t ia l  items, on the  o ther  hand, were re-l a t e d  t o  several smaller, more local ized t o p i c  s t ruc tu re s .
Consequently, mapymore of these  items were described i n  f u l l .
The random sample lacked a consis-t e n t  contextual  framework, and consequently had the  l e a s t  communicative e f f i -ciency on the  average.Ret r ieval  a c t i v i t y .
W e  have seen t h a t  r e t r i e v a l  a c t i v i t y  i s  an e s s e n t i a lp a r t  of the  indexing and organizat ional  processes.
The protocols  show a f re -quent need t o  search f o r  r e l a t e d  mate r ia l  and i t e m  numbers i n  the keyword sys-t e m  and a corresponding need f o r  network in t e r roga t ion  p r i o r  t o  descr ip t ionen t ry  under AUTONOTE2.
However, the  AUTONOTE2 t op i c  framework el iminates  muchof the  t e x t  file perusa l  so common i n  the AUTONOTE protocols .
Each top ic  des-c r i p t i o n  typ i ca l ly  provides a c l ea r  i nd i ca t ion  of the  content of i t s  associa tedFig.
23 - A comparison of entered and conveyed content wordsf o r  t h r ee  samples of d a t a  base i t e m s1A r t i f i c i a lRandom Sequential  I n t e l l i g e n c eSample Sample SampleNo.
of items i n  sample 50 41 30No.
of keywords o r i g i n a l l y  assigned 270 251 155Avg.
No.
of keywords pe r  item 5.4 6.1 5.1No.
of content words entered 256 233 109Avg.
Now of content words entered per  5 .1  5.7 3 .
6i t e mNo.
of content words conveyed 388 396 235Avg.
Now of content words conveyed p e r  7.9 9.7 7.8i t e mNo.
of words conveyed per  word entered 1.5 1.7 2.2I L1items.
Consequently, the re  w a s  very l i t t l e  need t o  examine the  text  f i l ep r i o r  t o  describing new items or  r e l a t i n g  them t o o t h e r s  i n  t h e  d a t a  base.
Aperusal  of candidate top ics  generated by the  DESCRIBE command was s u f f i c i e n t  i nmost cases.The most outstanding improvement during r e t r i e v a l  a c t i v i t y  occurred i n  in-s tances of very general  queries .
Under the  keyword system a request  f o r  allitems pe r t i nen t  to, say, ARTIFICIAL INTELLIGENCE o r  PROBLEM SOLVING w i l l  accessa l a r g e  set of items.
Queries of t h i s  kind were employed t o  peruse large seg-ments of t h e  data  base re levant  t o  a general  top ic  area--for example, i n  searchof i t e m  candidates f o r  a p a r t i c u l a r  grouping.
The important d i f fe rence  betweenthe  two systems i n  t h i s  s i t u a t i o n  is  t h a t  AUTONOTE g ives  the  user  no ind i ca t ionof the subtopics wi th in  the  general topic area.
The AUT.ONOTE user e s s e n t i a l l yhas two a l t e rna t ives :  he may display  each of t he  accessed i temsCoptionallysuppressing t e x t ) ;  o r  he may f u r t h e r  r e s t r i c t  the  set of i t e m s w i t h  an addi-Jadditional set of descriptors.
Both options have notable drawbacks.
Thefirst entails time-consuming perusal of the data base.
The second raises amore significant problem.
Which descriptors should be used to restrict thesize of the accessed set of items?
Some descriptors may restrict the set toogreatly, eliminating relevant material; others may discriminate very little ornot at all.
In the absence of system feedback, this discrimination processplaces a major burden on the user's memory.The AUTONOTE2 system, on the other hand, provides the user with verymeaningful feedback in response to general queries.
Consider, fbr example,the retrieval protocol presented in Fig, 24.
At each level in the representa-tional network, the user is given an opportunity to choose among several sub-topics.
This example very effectively demonstrates a marked improvement overkeyword indexing--the ability to discriminate among subsets of material indexedunder a common set of general descriptors.ConclusionAn analysis of man-machine dialogs collected during the description of arealistically diverse collection of textual materials has shown the communica-tive ease and efficiency and the descriptive power attainable under the refer-ential system.
The results Indicate that the referential mechanisms developedin this study copstitute a viable alternative to keyword indexing techniquesas applied to personal information systems.
The referential approach offersfour primary contributions toward the improvement of man-machine communication;each corresponds to a particular kind of facilitation during storage and re-trieval activity.L SUSER: FIND ARTIFICIAL INTELLIGENCEDO YOU WANT:A.
THE 1968 ARTIFICIAL INTELLIGENCE CONFERENCE AT CWRUBe THE I N F L ~ c E  OF ARTIFICIAL INTELLIGENCE ON COGNITIVEPSYCHOLOGYC.
THE GENERAZ APPROACH TO ARTIFICIAL INTELLIGENCED.
ARTIFICIAL INTELLIGENCE USEARCH AT MITE.
RETATION OF ARTIFICIAL INTELLIGENCE TO PSYCHOLOGYUSER: A1 ITEM SAnD.
WANT TO EXPLORE?USER: YESDO YOU WANT:A. M L ' S  TALK AT THE CONFERENCE ON THE REPRESENTATION OF APROBLEM SOLVING SYSTEMB.
ROBINSON'S TALK AT THE CONFERENCE ON THEOREM PROVING SYSTEMSC.
LIN'S PAPER AT THE CONFERENCE ON THE HEURISTIC SOLUTION OF'LARGE COMBINATORIAL PROBLEMSD.
BANERJI'S OVERVIEW OF GAME PLAYING PROGRAMS AT THE CONFERENCEE.
SIMMONS REVIEW OF QUESTION ANSWERING SYSTEMS AT THE CONFERENCEF.
OTHER TALKS AT THE CONFERENCEG.
SLAGLE'S DISCUSSION AT THE CONFERENCE ON HEURISTIC SEARCHPROGRAMSHe FImS PRESENTATION AT THE CONFE'IIENCE OF AN ALGOL-LIKELANGUAGE FOR PROBLEM SOLVING PROCEDURESI.
FEIGENBAUM'S DISCUSSION AT THE CONFERENCE OF THE DENDRALJ.
BANERJI'SFig.
24 - Topic descriminat ion duringretrieval a c t i v i t yF i r s t ,  t he  concept of a r ep re sen ta t i ona l  network provides the use r  with ap a r t i c u l a r l y  n a t u r a l  view of both t he  content  and organiza t ion  of h i s  d a t a  baseIn essence, the  user  e x p l i c i t l y  de f ines  the important concepts and top i c s  w i t h -i n  h i s  own area of i n t e r e s t ;  he spec i f i ed  s t r u c t u r a l  r e l a t i onsh ips  among con-cep t s  and, i n  general, manipulates these informat ional  ob j ec t s  during a l l  phasesof  problem solving a c t i v i t y .
This t o p i c a l  view of the  d a t a  base i s ,  i n  a veryreal sense,rnore "meaningful" td t h e  user  than the a r t i f i c i a l  view inherent i nkeyword indexing systems.Second, t he  developed techniques provide a un i f i ed  treatment f o r  bo th  in-dexing and organiza t ional  a c t i v i t y .
The communication of s t r uc tu r a lassociations is achieved through exactly the same descriptive mechanisms usedin categorizing material.
In effect, the topic serves as the focal point inall aspects of communication with the system.Third, retrieval capability is considerably enhanced by the discriminatorypower of the referential system.
The representational network provides aneffective means for distinguishing among the many topics that may be partiallyindexed under a c o m n  set of words.
As noted earlier, this discriminatorypower is especially useful in providing meaningful user feedback in response togeneral retrieval queries.
Further, since each topic description serves toidentify the content of its associated items, the representational network maybe used as a retrieval intermediary.
That is, the user can essentially engagein retrieval activity by utilizing mechanisms for exploring the topic struc-tures in the network, This aspect of the system greatly reduces the need forlengthy perusal of document texts in search of desired materials.Finally, the utilization of the structural context provided by the networkapproach taakes it possible for the user to describe, organize, and retrievematerials with considerable communicative efficiency, This is a fundamentalaspect of the system design--to provide a framework for interpreting terse,efficient, sometimes ambiguous references to the topics in the information uni-verse.In light of the increasing availability of on-line computing facilitiestoday, it seems reasonable to expect that personalized retrieval systems willplay an expanding role in the computer support of individual research activity.It is hoped that thisstudywill suggest new directions for the design of suchsystems.REFERENCESDosert, B. H., & Th~mpson, F. B.
How features resolve syntactic ambiguity.In J. Minker & S. Rosenf ield ( ~ d s .  )
, Proceedings of Sytnposiwn of Infor-mation Storage and Retrieval, University of Maryland, April, 1971.Linn, W. E. Jr. Man-machine referential communication in a personal informa-tion retrieval system.
(Doctoral dissertation, The University ofMichigan) Ann Arbor, Michigan: University Microfilms, 1972.
No.
73-6867.Reitman, W. Cognition and thought.
New York: Wiley , 1965.Reitman, W,, Roberts, R. B., Sauvain, R e  W,, Wheeler, D, D., & Linn, W.AUTONOTE: A personal information storage and retrieval system, Proceed-ings of the 24th National Conference of the Associati~n for ComputinqMachinery, New York: Association for Computing Machinery, 1969.Pp.
67-76.Sauvain, Re W. Structural communication in a personal information storage andretrieval system.
(~octoral dissertation, The University of Michigan)Ann Arbor, Michigan: University Microfilms, 1970.
No, 70-21782.
