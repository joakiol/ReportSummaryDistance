Representing Constraints with AutomataFrank  Morawietz  and  Tom Corne l lSeminar  fiir Sprachwissenschaf tUn ivers i t?
t  T i ib ingenWi lhe lmst r .
11372074 T i ib ingen,  Germany{frank, cornell}~sfs, nphil, uni-tuebingen, deAbst rac tIn this paper we describe an approach toconstraint based syntactic theories in termsof finite tree automata.
The solutions toconstraints expressed in weak monadic sec-ond order (MSO) logic are represented bytree automata recognizing the assignmentswhich make the formulas true.
We showthat this allows an efficient representationof knowledge about the content of con-straints which can be used as a practicaltool for grammatical theory verification.We achieve this by using the intertrans-latability of formulae of MSO logic andtree automata nd the embedding of MSOlogic into a constraint logic programmingscheme.
The usefulness of the approach isdiscussed with examples from the realm ofPrinciples-and-Parameters ba ed parsing.1 In t roduct ionIn recent years there has been a continuing inter-est in computational linguistics in both model theo-retic syntax and finite state techniques.
In this pa-per we attempt o bridge the gap between the twoby exploiting an old result in logic, that the weakmonadic second order (MSO) theory of two successorfunctions (WS2S) is decidable (Thatcher and Wright1968, Doner 1970).
A "weak" second order theory isone in which the set variables are allowed to rangeonly over finite sets.
There is a more powerful resultavailable: it has been shown (Rabin 1969) that thestrong monadic second order theory (variables rangeover infinite sets) of even countably many successorfunctions is decidable.
However, in our linguistic ap-plications we only need to quantify over finite sets, sothe weaker theory is enough, and the techniques cor-respondingly simpler3 The decidability proof worksby showing a correspondence b tween formulas inthe language of WS2S and tree automata, devel-oped in such a way that the formula is satisfiableiff the set of trees accepted by the corresponding au-tomaton is nonempty.
While these results were wellknown, the (rather surprising) suitability of this for-malism as a constraint language for Principles andParameters (P&P) based linguistic theories has onlyrecently been shown by Rogers (1994).It should be pointed out immediately that thetranslation from formulas to automata, while effec-tive, is just about as complex as it is possible tobe.
In the worst case, the number of states can begiven as a function of the number of variables inthe input formula with a stack of exponents as tallas the number of quantifier alternations in the for-mula.
However, there is a growing body of workin the computer science literature motivated by thesuccess of the MONA decision procedure (Henriksenet al 1995) 2 on the application of these techniquesin computer science (Basin and Klarlund 1995, Kelbet al 1997), which suggests that in practical casesthe extreme xplosiveness of this technique can beeffectively controlled.
It is one of our goals to showthat this is the case in linguistic applications as well.The decidability proof for WS2S is inductiveon the structure of MSO formulas.
Therefore wecan choose our particular tree description languagerather freely, knowing (a) that the resulting logic1All of these are generalizations to trees of resultson strings and the monadic second order theory of onesuccessor function originally due to Biichi (1960).
Theapplications we mention here could be adapted to stringswith finite-state automata replacing tree automata.
Ingeneral, all the techniques which apply to tree au-tomata re straightforward generalizations of techniquesfor FSAs.2The current version of the MONA tool works only onthe MSO logic of strings.
There is work in progress at theUniversity of Aarhus to extend MONA to "MONA++",for trees (Biehl et al 1996).468will be decidable and (b) that the translation to au-tomata will go through as long as the atomic formu-las of the language represent relations which can betranslated (by hand if necessary) to tree automata.We will see how this is done ill the next section,but the point can be appreciated immediately.
Forexample, Niehren and Podelski (1992) and Ayari etal.
(1997) have investigated the usefulness of thesetechniques in dealing with feature trees which un-fold feature structures; there the attributes of anattribute-value t rm are translated to distinct suc-cessor functions.
On the other hand, Rogers (1996)has developed a language rich in long-distance r la-tions (dominance and precedence) which is more ap-propriate for work in Government-Binding (GB) the-ory.
Compact automata can be easily constructedto represent dominance and precedence relations.One can imagine other possibilities as well: as wewill see, the automaton for Kayne-style asymmet-ric, precedence-restricted c-command (Kayne 1994)is also very compact, and makes a suitable primitivefor a description language along the lines developedby Frank and Vijay-Shanker (1995).The paper is organized as follows.
First we presentsome of the mathematical background, then we dis-cuss (na'ive) uses of the techniques, followed bythe presentation of a constraint logic programming-based extension of MSO logic to avoid some of theproblems of the naive approach, concluding with adiscussion of its strengths and weaknesses.2 Def in ing  Automata  w i thConst ra in tsTree automata .
For completeness, we sketch thedefinitions of trees and tree automata here.
An in-troduction to tree automata can be found in G~csegand Steinby (1984), as well as in Thatcher andWright (1968) and Doner (1970).Assume an alphabet E = E0 LJ E2 with Eo = {A}and E2 being a set of binary operation symbols.
Wethink of (binary) trees over E as just the set of termsTr.
constructed from this alphabet.
That is, we letA be the empty tree and let a(tl,t2), for a E E2and tl,t2 E T~., denote the tree with label a andsubtrees tl, t2.
Alternatively, we can think of a treet as a function from the addresses in a binary treedomain T to labels in E. 3A deterministic (bottom-up) tree automaton .4onbinary trees is a tuple (A, E, a0, F, c~ / with A the set3The first approach is developed in Thatcher andWright (1968), the second in Doner (1970).
A tree do-main is a subset of strings over a linearly ordered setwhich is closed under prefix and left sister.of states, a0 E A the initial state, F C_ A the fi-nal states and a : (A x A x E) -+ A the transitionfunction.
The transition function can be thought ofas a homomorphism on trees inductively defined as:h~(~) : a0 and h~(a(tl, t2)) = a(h~(tl), ha(t2), a).An automaton .4 accepts a tree t iff ha (t) E F. Thelanguage recognized by A is denoted by T(A) ={tlh,(t) E F}.Emptiness of the language T(,4) is decidable by afixpoint construction computing the set of reachablestates.
The reachability algorithm is given belowin Figure 1.
R contains the reachable states con-structed so far, and R' contains possibly new statesconstructed on the current pass through the loop.T(A) is empty if and only if no final state is reach-1.
R := {ao}, R' := 0.2.
For all (ai,aj) E R x R, for all a E E,R' := R 'U {c~(ai,aj,a)}.3.
If R r -  R = 0 then return R,else R := R U R', go to step 2.Figure 1: Reachable states algorithm.able.
Naturally, if we want to test emptiness, we canstop the construction as soon as we encounter a finalstate in R r. Note that, given an automaton with kstates, the algorithm must terminate after at most kpasses through the loop, so the algorithm terminatesafter at most k 3 searches through the transition ta-ble.Sets of trees which are the language of some treeautomaton are called recognizable.
4 The recogniz-able sets are closed under the boolean operationsof conjunction, disjunction and negation, and theautomaton constructions which witness these clo-sure results are absolutely straightforward general-izations of the corresponding better-known construc-tions for finite state automata.
The recognizable s tsare also closed under projections (mappings fromone alphabet o another) and inverse projections,and again the construction is essentially that for fi-nite state automata.
The projection constructionyields a nondeterministic automaton, but, again asfor FSA's, bottom-up tree automata can be madedeterministic by a straightforward generalization ofthe subset construction.
(Note that top-down treeautomata do not have this property: determinis-tic top-down tree automata recognize a strictly nar-rower family of tree sets.)
Finally, tree automata can4The recognizable sets of trees yield the context freestring languages, so MSO logics are limited to contextfree power.
However, the CLP extension discussed belowcan be used to amplify the power of the formalism wherenecessary.469be minimized by a construction which is, yet again,a straightforward generalization of well known FSAtechniques.The weak  second order  theory  o f  two  succes -sor  funct ions .
One attraction of monadic secondorder tree logics is that they give us a principledmeans of generating automata from a constraint-based theory.
The connection allows the linguistto specify ideas about natural anguage in a concisemanner in logic, while at the same time providinga way of "compiling" those constraints into a formwhich can be efficiently used in natural anguage pro-cessing applications.The translation is provided via the weak monadicsecond order theory of two successor functions(WS2S).
The structure of two successor functions,H2, has for its domain (N2) the infinite binarybranching tree.
Standardly the language of WS2S isbased on two successor functions (left-daughter andright-daughter), but, as Rogers (1994) shows, thisis intertranslatable with a language based on domi-nance and precedence relations.
Because we choosethe monadic second order language over whicheverof these two signatures is preferred, we can quan-tify over sets of nodes in N2.
So we can use thesesets to pick out arbitrarily large finite trees embed-ded in N2.
Second order variables can also be usedto pick out other properties of nodes, such as cate-gory or other node-labeling features, and they canbe used to pick out higher order substructures suchas :~ projections or chains.As usual, satisfiability of a formula in the languageof WS2S by Af2 is relative to an assignment function,mapping individual variables to members of N2 (asin first order logic) and mapping monadic predicatevariables to subsets of N2.
Following Biichi (1960),Doner (1970) and Thatcher and Wright (1968) showthat assignment functions for such formulas can becoded by a labeling of the nodes in N2 in the follow-ing way.
First, we treat individual variables as setvariables which are constrained to be singleton sets(we can define the singletonhood property in MSOtree logic).
So, without loss of generality, we canthink of the domain of the assignment function asa sequence Xz , .
.
.
, X~ of the variables occurring inthe given formula.
We choose our labeling alphabetto be the set of length n bit strings: (0, 1} ~.
Then,for every node n E N2, if we intend to assign n tothe denotation of Xi, we indicate this by labeling nwith a bit string in which the ith bit is on.
(In effect,we are labelling every node with a list of the sets towhich it belongs.)
Now every assignment functionwe might need corresponds uniquely to a labelingfunction over N2.
What Doner, and Thatcher andWright (and, for strong $2S, Rabin) show is thateach formula in the language of WS2S correspondsto a tree automaton which recognizes just the sat-isfying "assignment labelings", and we can therebydefine a notion of "recognizable relation".
So theformula is satisfiable just in case the correspondingautomaton recognizes a nonempty language.
Notethat  any language whose formulas can be convertedto automata in this way is therefore guaranteed tobe decidable, though whether it is as strong as thelanguage of WS2S must still be shown.This approach to theorem-proving is rather dif-ferent from more general techniques for higher-ordertheorem proving in ways that the formalizer mustkeep in mind.
In particular, we are deciding mem-bership in the theory of a fixed structure, Af2, andnot consequence of an explicit set of tree axioms.So, for example, the parse tree shows up in the for-malization as a second order variable, rather thansimply being a satisfying model (cf.
Johnson (1994),on "satisfiability-based" grammar formalisms).As an example consider the following formuladenoting the relation of directed asymmetric -command 5 in the sense of Kayne (1994).
We use thetree logic signature of Rogers (1994), which, in a sec-ond order setting, is interdefinable with the languageof multiple successor functions.
Uppercase lettersdenote second order variables, lowercase ones firstorder variables, <~* reflexive domination, <~+ properdomination and -4 proper precedence:AC-Com(xl, x2)% x c-commands y:(Vz)\[z <~+ x =# z <~+ y\] A -~(x <1" y) A% y does not c-command x:4 + y z 4 + x\] A 4"  x)) A% x preceeds y:x-~yThe corresponding tree automaton is shown inFigure 2.
On closer examination of the transitions,we note that we just percolate the initial state aslong as we find only nodes which are neither xl norx2.
From the initial state on both the left and theright subtree we can either go to the state denoting"found xl" (al) if we read symbol 10 or to the statedenoting "found x2" (a2) if we read symbol 01.
Wecan then percolate a2 as long as the other branchdoes not immediately dominate xl.
When we have5This relation is not monadic, but reducible via syn-tactic substitution to an MSO signature.
In fact, we candefine relations of any arity as long as they are explicitlypresentable in MSO logic.470,4 = (A,~,ao,F,a) ,A = {ao,al,a2,a3,a4},= {11, 10, 01, 00}F = {a3},(ao,a0,00) = a0  (a0,a0, 10) = al(a0,a0,01) = a2  (a0,a2,00) =(a0, a3,00)  = a3  (a2, a0, 00) =(al, a: ,  00) = a3 a0,00) =all other transitions are to a4Figure 2: The automaton for AC-Com(xl ,  x2)al on the left subtree and a2 on the right one, we goto the final state aa which again can be percolatedas long as empty symbols are read.
Clearly, the au-tomaton recognizes all trees which have the desiredc-command relation between the two nodes.
It com-pactly represents the (infinite) number of possiblesatisfying assignments.The proof of the decidability of WS2S furnishesa technique for deriving such automata for recog-nizable relations effectively.
(In fact the above au-tomaton was constructed by a simple implementa-tion of such a compiler which we have running at theUniversity of Tiibingen.
See Morawietz and Cornell(1997).)
The proof is inductive.
In the base case,relations defined by atomic formulas are shown tobe recognizable by brute force.
Then the inductionis based on the closure properties of the recognizablesets, so that logical operators correspond to automa-ton constructions in the following way: conjunctionand negation just use the obvious corresponding au-tomaton operations and existential quantification isimplemented w~th the projection construction.
Theinductive nature of the proof allows us a fairly freechoice of signature, as long as our atomic relationsare recognizable.
We could, for example, investi-gate theories in which asymmetric c-command wasthe only primitive, or asymmetric c-command plusdominance, for example.The projection construction, as noted above,yields nondeterministic automata s output, andthe negation construction requires deterministic au-tomata s input, so the subset construction must beused every time a negated existential quantifier is en-countered.
The corresponding exponential blowupin the state space is the main cause of the non-elementary complexity of the construction.
Sincea quantifier prefix of the form 3- .
.
3V.
.
.V3.
.
.
isequivalent o 3 .
.
.
373- - -373 .
- -  we see that thestack of exponents involved is determined by thenumber of quantifier alternations.It is obviously desirable to keep the automata ssmall as possible.
In our own prototype, we min-imize the outputs of all of our automata construc-tions.
Note that this gives us another way of deter-mining satisfiability, since the minimal automatonrecognizing the empty language is readily detectable:its only state is the initial state, and it is not final.3 Def in ing  Const ra in ts  w i thAutomataAn obvious goal for the use of the discussed ap-proach would be the (offline) generation of a treeautomaton representing an entire grammar.
Thatis, in principle, if we can formalize a grammar inan MSO tree logic, we can apply these compilationtechniques to construct an automaton which recog-nizes all and only the valid parse trees.
6 In this set-ting, the parsing problem becomes the problem ofconjoining an automaton recognizing the input withthe grammar automaton, with the result being anautomaton which recognizes all and only the validparse trees.
For example, assume that we have anautomaton Gram(X)  such that X is a well-formedtree, and suppose we want to recognize the inputJohn sees Mary.
Then we conjoin a description ofthe input with the grammar automaton as given be-low.
(3x, y,z  E X)\[x E John A y E Sees A z E Mary Ax -< y -< z A Gram(X)\]The recognition problem is just the problem of deter-mining whether or not the resulting automaton rec-ognizes a nonempty language.
Since the automatonrepresents he parse forest, we can run it to generateparse trees for this particular input.Unfortunately, as we have already noted, theproblem of generating a tree automaton from anarbitrary MSO formula is of non-elementary com-plexity.
Therefore, it seems unlikely that a formal-ization of a realistic principle-based grammar couldbe compiled into a tree automaton before the heatdeath of the universe.
(The formalization of ideasfrom Relativized Minimality (Pdzzi 1990) presentedin Rogers (1994) fills an entire chapter without spec-ifying even the beginning of a full lexicon, for ex-ample.)
Nonetheless there are a number of waysin which these compilation techniques remain use-ful.
First, though the construction of a grammarautomaton is almost certainly infeasible for realis-tic grammars, the construction of a grammar-and-input automaton--which is a very much smaller6This is reminiscent of approaches associated withBernard Lang.
See van Noord (1995) and referencestherein.471machine--may not be.
We discuss techniques basedon constraint logic programming that are applicableto that problem in the next section.Another use for such a compiler is suggested bythe standard divide-and-conquer strategy for prob-lem solving: instead of compiling an entire gram-mar formula, we isolate interesting subformulas, andattempt to compile them.
Tree automata repre-sent properties of trees and there are many suchproperties less complex than global well-formednesswhich are nonetheless important to establish forparse trees.
In particular, where the definition ofa property of parse trees involves negation or quan-tification, including quantification over sets of nodes,it may be easier to express this in an MSO tree logic,compile the resulting formula, and use the resultingautomaton as a filter on parse trees originally gen-erated by other means (e.g., by a covering phrasestructure grammar).At the moment, at least, the question of whichgrammatical properties can be compiled in a reason-able time is largely empirical.
It is made even moredifficult by the lack of high quality software tools.This situation should be alleviated in the near futurewhen work on MONA++ at the University of Aarhusis completed; the usefulness of its older sister MONA(Henriksen et al 1995), which works on strings andFSA's, has been well demonstrated in the computerscience literature.
In the meantime, for tests, we areusing a comparatively simple implementation f ourown.
Even with very low-power tools, however, wecan construct automata for interesting rammaticalconstraints.For example, recall the definition of asymmetric c-command and its associated automaton in Figure 2.In linguistic applications, we generally use versionsof c-command which are restricted to be local, in thesense that no element of a certain type is allowedto intervene.
The general form of such a localitycondition LC might then be formalized as follows.LC(x,y)AC-Comm(x, y) A% there does not exist z with property P:(-~3z)\[z E P A% such that it intervenes between x and y:(3w) \ [w x A w ,a + z A z y\]\]Here property P is meant to be the property iden-tifying a relevant intervener for the relation meantto hold between x and y.
Note that this propertycould include that some other node be the left suc-cessor of z with certain properties, that is, this gen-eral scheme fits cases where the intervening item isnot itself directly on the path between x and y. Thisformula was compiled by us and yields the automa-ton in Figure 3.
Here the first bit position indicatesmembership in P, the second is for x and the thirdfor y.A = (A,E, ao,F,a),A = {no, al, a2, a3, a4 },F = {a3},a(ao,ao,O00) = ao a(ao,ao, 100) = aoa(ao,ao,OlO) -- a2 (~(ao,ao,ll0) = a2a(ao, ao, 001) = al a(ao, ao, 101) = ala(ao,al ,000) -- al ~(ao,a3,000) = a3a(ao,a3,100) = a3 ~(al,ao,000) = alOl(a2, al, 000) = a3 a(a2, al, I00) = a3o~(a3, ao, 000) = a3 a(a3, ao, 100) = a3all other transitions are to atFigure 3: Automaton for local c-command.This automaton could in turn be implemented it-self as Prolog code, and considered to be an op-timized implementation of the given specification.Note in particular the role of the compiler as an op-timizer.
It outputs a minimized automaton, and theminimal automaton is a unique (up to isomorphism)definition of the given relation.
Consider again thedefinition of AC-Command in the previous section.It is far from the most compact and elegant formuladefining that relation.
There exist much smaller for-mulas equivalent to that definition, and indeed someare suggested by the very structure of the automa-ton.
That formula was chosen because it is an ex-tremely straightforward formalization of the prosedefinition of the relation.
Nonetheless, the automa-ton compiled from a much cleverer formalizationwould still be essentially the same.
So no particulardegree of cleverness is assumed on the part of theformalizer; optimization is done by the compiler.
74 MSO Log ic  and  Const ra in t  Log icP rogrammingThe automaton for a grammar formula is presum-ably quite a lot larger than the parse-forest automa-ton, that is, the automaton for the grammar con-joined with the input description.
So it makes senseto search for ways to construct he parse-forest au-tomaton which do not require the prior constructionof an entire grammar automaton.
In this section weconsider how we might do this by by the embedding7The structure of the formula does often have an ef-fect on the time required by the compiler; in that sensewriting MSO formalizations i  still Logic Programming.472of the MSO constraint language into a constraintlogic programming scheme.
The constraint base isan automaton which represents the incremental c-cumulation of knowledge about the possible valua-tions of variables.
As discussed before, automataare a way to represent even infinite numbers of valu-ations with finite means, while still allowing for theefficient extraction of individual valuations.
We in-crementally add information to this constraint baseby applying and solving clauses with their associatedconstraints.
That is, we actually use the compiler online as the constraint solver.
Some obvious advan-tages include that we can still use our succinct andflexible constraint language, but gain (a) a more ex-pressive language, since we now can include induc-tive definitions of relations, and (b) a way of guid-ing the compilation process by the specification ofappropriate programs.We define a relational extension TC(WS2S) ofour constraint language following the HShfeld andSmolka scheme (HShfeld and Smolka 1988).
Fromthe scheme we get a sound and complete, but nowonly semi-decidable, operational interpretation of adefinite clause-based derivation process.
The result-ing structure is an extension of the underlying con-straint structure with the new relations defined viafixpoints.As usual, a definite clause is an implication withan atom as the head and a body consisting of a sat-isfiable MSO constraint and a (possibly empty) con-junction of atoms.
A derivation step consists of twoparts: goal reduction, which substitutes the bodyof a goal for an appropriate head, and constraintsolving, which means in our case that we have tocheck the satisfiability of the constraint associatedwith the clause in conjunction with the current con-straint store.
For simplicity we assume a standardleft-to-right, depth-first interpreter for the executionof the programs.
The solution to a search branch ofa program is a satisfiable constraint, represented in"solved form" as an automaton.
Note that automatado make appropriate solved forms for systems of con-straints: minimized automata re normal forms, andthey allow for the direct and efficient recovery of par-ticular solutions.Intuitively, we have a language which has an op-erational interpretation similar to Prolog with thedifferences that we interpret it not on the Herbranduniverse but on N2, that we use MS0 constraintsolving instead of unification and that we can usedefined (linguistic) primitives directly.The resulting system is only semi-decidable, dueto the fact that the extension permits monadic sec-ond order variables to appear in recursively definedclauses.
So if we view the inductively defined rela-tions as part of an augmented signature, this sig-nature contains relations on sets.
These allow thespecification of undecidable relations; for example,Morawietz (1997) shows how to encode the PCP.
Ifwe limit ourselves to just singleton variables in anydirectly or indirectly recursive clause, every relationwe define stays within the capacity of MSO logic, ssince, if they are first order inductively definable,they are explicitly second order definable (Rogers1994).
Since this does not take us beyond the powerof MSO logic and natural anguage is known not tobe context-free, the extra power of TC(WS2S) offersa way to get past the context-free boundary.To demonstrate how we now split the work be-tween the compiler and the CLP interpreter, wepresent a simple example.
Consider the followingnaive specification of a lexicon: 9Lexicon(x) ~:~ (x  E Sees  A x E V A .
.
.
)V (xE JohnAxENA.
.
.
)Y (xEMaryAxENA.
.
.
)We have specified a set called Lexicon via a disjunc-tive specification of lexical labels, e.g.
Sees, and theappropriate combination offeatures, e.g.V.
Naively,at least, every feature we use must have its own bitposition, since in the logic we treat features as setvariables.
So, the alphabet size with the encodingas bitstrings will be at least 2 IAlphabet\[.
It is immedi-ately clear that the compilation of such an automa-ton is extremely unattractive, if at all feasible.We can avoid having to compile the whole lexi-con by having separate clauses for each lexical en-try in the CLP extension.
Notational conventionswill be that constraints associated with clauses arewritten in curly brackets and subgoals in the bodyare separated by &'s.
Note that relations defined inTC(WS2S) are written lowercase.lexicon(x) t--- {x E Sees A x E V A .
.
.
}lexicon(x) +-- {x E John A x E N A .
.
.
}lexicon(x) e - -  {xEMaryAxENA.
.
.
}This shifts the burden of handling disjunctions to theinterpreter.
The intuitive point should be clear: it8Relations on individuals describe sets which are ex-pressible as monadic predicates.9Here and in the following we treat free variables asbeing stored in a global table so that we do not haveto present hem in each and every constraint.
In par-ticular, without this lexicon would have the additionalarguments Sees, V, John, N, Mary and all free vari-ables appearing in the other definitions.473is not the case that every constraint in the grammarhas to be expressed in one single tree automaton.We need only compile into the constraint store thosewhich are really needed.
Note that this is true evenfor variables appearing in the global table.
In theCLP extension the appearance in the table is notcoupled to the appearance in the constraint store.Only those are present in both which are part of theconstraint in an applied clause.We can also use offline compiled modules in aT~(WS2S) parsing program.
As a source of simpleexamples, we draw on the definitions from the lec-tures on P&P parsing presented in Johnson (1995).In implementing a program such as Johnson's sim-plified parse relation--see Figure 4--we can in prin-ciple define any of the subgoals in the body eithervia precompiled automata (so they are essentiallytreated as facts), or else providing them with morestandard efinite clause definitions.parse(Words, Tree){Tree(Words)} &yield(Words, Tree) &xbar(Tree) &ecp(Tree)Figure 4: parse as in Johnson (1995)In more detail, Words denotes a set of nodes la-beled according to the input description.
Our initialconstraint base, which can be automatically gener-ated from a Prolog list of input words, is the corre-sponding tree automaton.
The associated constraintTree is easily compilable and serves as the initializa-tion for our parse tree.
The yield and ecp predicatescan easily be explicitly defined and, if practicallycompilable (which is certainly the case for yield),could then be treated as facts.
The xbar predicate,on the other hand, is a disjunctive specification oflicensing conditions depending on different featuresand configurations, e.g., whether we are faced witha binary-, unary- or non-branching structure, whichis better expressed as several separate rules.
In fact,since we want the lexicon to be represented as sev-eral definite clauses, we cannot have xbar as a sim-ple constraint.
This is due to the limitation of theconstraints which appear in the definite clauses to(pure) MSO constraints.We now have another well-defined way of using theoffiine compiled modules.
This, at least, separatesthe actual processing issues (e.g., parse) from thelinguistically motivated modules (e.g., ecp).
One cannow see that with the relational extension, we cannot only use those modules which are compilable di-rectly, but also guide the compilation procedure.
Ineffect this means interleaving the intersection of thegrammar and the input description such that onlythe minimal amount of information to determine theparse is incrementally stored in the constraint base.Furthermore, the language of 7~(WS2S) is suffi-ciently close to standard Prolog-like programminglanguages to allow the transfer of techniques andapproaches developed in the realm of P&P-basedparsing.
In other words, it needs only little effortto translate a Prolog program to a T~(WS2S) one.5 Conc lus ions  and  Out lookIn this paper we presented a first step towards the re-alization of a system using automata-based theorem-proving techniques to implement linguistic process-ing and theory verification.
Despite the staggeringcomplexity bound the success of and the continu-ing work on these techniques in computer sciencepromises a useable tool to test formalization of gram-mars.
The advantages are readily apparent.
Thedirect use of a succinct and flexible description lan-guage together with an environment to test the for-malizations with the resulting finite, deterministictree automata offers a way of combining the needsof both formalization and processing.
And further-more, the CLP extension offers an even more power-ful language which allows a clear separation of pro-cessing and specification issues while retaining thepower and flexibility of the original.
Since it allowsthe control of the generation process, the additionof information to the constraint base is dependenton the input which keeps the number of variablessmaller and by this the automata more compact.Nevertheless it remains to be seen how far thesystem can be advanced with the use of an opti-mized theorem-prover.
The number of variables ourcurrent prototype can handle lies between eight andeleven.
1?
This is not enough to compile or test allinteresting aspects of a formalization.
So furtherwork will definitly involve the optimization of theprototype implementation, while we await the devel-opment of more sophisticated tools like MONA++.It seems to be promising to improve the (very ba-sic) CLP interpreter, too.
The HShfeld and Smolkascheme allows the inclusion of existential quantifi-cation into the relational extension.
We intend touse this to provide the theoretical background ofthe implementation of a garbage collection proce-dure which projects variables from the constraintstore which are either local to a definite clause orZ?Note that this corresponds to 256 to 2048 differentbitstrings.474explicitly marked for projection in the program sothat the constraint store can be kept as small aspossible.6 AcknowledgementsThis work has been supported by the project A8of the SFB 340 of the Deutsche Forschungsgemein-schaft.
We wish especially to thank Uwe MSnnichand Jim Rogers for discussions and advice.
Needlessto say, any errors and infelicities which remain areours alone.Re ferencesAyari, A., Basin, D. and Podelski, A.
(1997).
LISA:A specification language based on WS2S, Ms, Uni-versit~it Freiburg.
Submitted to CSL'97.Basin, D. and Klarlund, N. (1995).
Hardwareverification using monadic second-order logic,Computer-Aided Verification (CAV '95), LNCS939, Springer, pp.
31-41.Biehl, M., Klarlund, N. and Rauhe, T. (1996).
Algo-rithms for guided tree automata, Proc.
WIA '96,LNCS, Springer-Verlag.Biichi, J. R. (1960).
Weak second-order arithmeticand finite automata, Zeitschrift fiir mathematis-ehe Logik und Grundlagen der Mathematik 6: 66-92.Doner, J.
(1970).
Tree acceptors and some of theirapplications, Journal of Computer and SystemSciences 4: 406-451.Frank, R. and Vijay-Shanker, K. (1995).
C-command and grammatical primitives, Presenta-tion at the 18th GLOW Colloquium.
Universityof Troms0.G@cseg, F. and Steinby, M. (1984).
Tree Automata,Akad~miai Kiad6, Budapest.Henriksen, J. G., Jensen, J., J?rgensen, M., Klar-lund, N., Paige, R., Rauhe, T. and Sandhol, A.(1995).
MONA: Monadic second-order logic inpractice, in Brinksma, Cleaveland, Larsen, Mar-garia and Steffen (eds), TACAS '95, LNCS 1019,Springer, pp.
89-110.HShfeld, M. and Smolka, G. (1988).
Definite rela-tions over constraint languages, LILOG Report 53,IBM Deutschland, Stuttgart, Germany.Johnson, M. (1994).
Two ways of formalizing ram-mars, Linguistics and Philosophy 17: 221-248.Johnson, M. (1995).
Constraint-based natural lan-guage parsing, ESSLLI '95, Barcelona, Coursenotes.Kayne, R. S. (1994).
The Antisymmetry of Syntax,MIT Press, Cambridge, Mass.
and London, Eng-land.Kelb, P., Margaria, T., Mendler, M. and Gsot-tberger, C. (1997).
MOSEL: A flexible toolset formonadic second-order logic, in E. Brinksma (ed.
),TACAS '97.Morawietz, F. (1997).
Monadic second order logic,tree automata and constraint logic programming,Arbeitspapiere des SFB 340 86, SFB 340, Univer-sit~t Tiibingen.Morawietz, F. and Cornell, T. L. (1997).
On therecognizability of relations over a tree definable ina monadic second order tree description language,Arbeitspapiere des SFB 340 85, SFB 340, Univer-sit,it Tfibingen.Niehren, J. and Podelski, A.
(1992).
Feature au-tomata nd recognizable sets of feature trees, inM.-C. Gandel and J.-P. Jouannaud (eds), Pro-ceedings of the 4th International Joint Conferenceon Theory and Practice of Software Development,Springer, LNCS 668, pp.
356-375.Rabin, M. O.
(1969).
Decidability of second-ordertheories and automata on infinite trees, Transac-tions of the AMS 141: 1-35.Rizzi, L. (1990).
Relativized Minimality, MIT Press.Rogers, J.
(1994).
Studies in the Logic of Trees withApplications to Grammar Formalisms, PhD the-sis, University of Delaware.
CS-Technical ReportNo.
95-04.Rogers, J.
(1996).
A model-theoretic framework fortheories of syntax, Proc.
of the 34th Annual Meet-ing of the ACL, Santa Cruz, USA.Thatcher, J. W. and Wright, J.
B.
(1968).
Gener-alized finite automata theory with an applicationto a decision problem of second-order logic, Math-ematical Systems Theory 2(1): 57-81.van Noord, G. (1995).
The intersection offinite stateautomata nd definite clause grammars, Proc.
ofthe 33th Annual Meeting of the ACL, Boston.475
