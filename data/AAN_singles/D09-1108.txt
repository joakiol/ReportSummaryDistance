Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1037?1045,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPFast Translation Rule Matching for Syntax-based StatisticalMachine TranslationHui Zhang1, 2   Min Zhang1   Haizhou Li1   Chew Lim Tan21Institute for Infocomm Research                    2National University of Singaporezhangh1982@gmail.com   {mzhang, hli}@i2r.a-star.edu.sg   tancl@comp.nus.edu.sgAbstractIn a linguistically-motivated syntax-based trans-lation system, the entire translation process isnormally carried out in two steps, translationrule matching and target sentence decoding us-ing the matched rules.
Both steps are very time-consuming due to the tremendous number oftranslation rules, the exhaustive search in trans-lation rule matching and the complex nature ofthe translation task itself.
In this paper, we pro-pose a hyper-tree-based fast algorithm for trans-lation rule matching.
Experimental results onthe NIST MT-2003 Chinese-English translationtask show that our algorithm is at least 19 timesfaster in rule matching and is able to help tosave 57% of overall translation time over previ-ous methods when using large fragment transla-tion rules.1 IntroductionRecently linguistically-motivated syntax-basedtranslation method has achieved great success instatistical machine translation (SMT) (Galley et al,2004; Liu et al, 2006, 2007; Zhang et al, 2007,2008a; Mi et al, 2008; Mi and Huang 2008;Zhang et al, 2009).
It translates a source sentenceto its target one in two steps by using structuredtranslation rules.
In the first step, which is calledtranslation rule matching step, all the applicable1translation rules are extracted from the entire ruleset by matching the source parse tree/forest.
Thesecond step is to decode the source sentence intoits target one using the extracted translation rules.Both of the two steps are very time-consumingdue to the exponential number of translation rulesand the complex nature of machine translation as1 Given a source structure (either a parse tree or a parseforest), a translation rule is applicable if and only if theleft hand side of the translation rule exactly matches atree fragment of the given source structure.an NP-hard search problem (Knight, 1999).
In theSMT research community, the second step hasbeen well studied and many methods have beenproposed to speed up the decoding process, suchas node-based or span-based beam search withdifferent pruning strategies (Liu et al, 2006;Zhang et al, 2008a, 2008b) and cube pruning(Huang and Chiang, 2007; Mi et al, 2008).
How-ever, the first step attracts less attention.
The pre-vious solution to this problem is to do exhaustivesearching with heuristics on each tree/forest nodeor on each source span.
This solution becomescomputationally infeasible when it is applied topacked forests with loose pruning threshold or rulesets with large tree fragments of large rule heightand width.
This not only overloads the translationprocess but also compromises the translation per-formance since as shown in our experiments thelarge tree fragment rules are also very useful.To solve the above issue, in this paper, we pro-pose a hyper-tree-based fast algorithm for transla-tion rule matching.
Our solution includes twosteps.
In the first step, all the translation rules arere-organized using our proposed hyper-tree struc-ture, which is a compact representation of the en-tire translation rule set, in order to make the com-mon parts of translation rules shared as much aspossible.
This enables the common parts of differ-ent translation rules to be visited only once in rulematching.
Please note that the first step can beeasily done off-line very fast.
As a result, it doesnot consume real translation time.
In the secondstep, we design a recursive algorithm to traversethe hyper-tree structure and the input source forestin a top-down manner to do the rule matching be-tween them.
As we will show later, the hyper-treestructure and the recursive algorithm significantlyimprove the speed of the rule matching and theentire translation process compared with previousmethods.With the proposed algorithm, we are able tocarry out experiments with very loose pruning1037thresholds and larger tree fragment rules effi-ciently.
Experimental results on the NIST MT-2003 Chinese-English translation task shows thatour algorithm is 19 times faster in rule matchingand is able to save 57% of overall translation timeover previous methods when using large fragmenttranslation rules with height up to 5.
It also showsthat the larger rules with height of up to 5 signifi-cantly outperforms the rules with height of up to 3by around 1 BLEU score.The rest of this paper is organized as follows.Section 2 introduces the syntax-based translationsystem that we are working on.
Section 3 reviewsthe previous work.
Section 4 explains our solutionwhile section 5 reports the experimental results.Section 6 concludes the paper.2 Syntax-based TranslationThis section briefly introduces the forest/tree-based tree-to-string translation model whichserves as the translation platform in this paper.2.1 Tree-to-string modelXNA declaration is related to some regulationFigure 1.
A tree-to-string translation process.The tree-to-string model (Galley et al 2004; Liu etal.
2006) views the translation as a structure map-ping process, which first breaks the source syntaxtree into many tree fragments and then maps eachtree fragment into its corresponding target transla-tion using translation rules, finally combines thesetarget translations into a complete sentence.
Fig.
1illustrates this process.
In real translation, thenumber of possible tree fragment segmentationsfor a given input tree is exponential in the numberof tree nodes.2.2 Forest-based translationTo overcome parse error for SMT, Mi and Huang(2008) propose forest-based translation by using apacked forest instead of a single syntax tree as thetranslation input.
A packed forest (Tomita 1987;Klein and Manning, 2001; Huang and Chiang,2005) is a compact representation of many possi-ble parse trees of a sentence, which can be for-mally described as a triple , where V isthe set of non-terminal nodes, E is the set of hy-per-edges and S is a sentence represented as anordered word sequence.
A hyper-edge in a packedforest is a group of edges in a tree which connectsa father node to all its children nodes, representinga CFG-based parse rule.
Fig.
2 is a packed forestincorporating two parse trees T1 and T2 of a sen-tence as shown in Fig.
3 and Fig.
4.
Given a hy-per-edge e, let h be its father node, then we saythat e is attached to h.A non-terminal node in a packed forest can berepresented as ?label [start, stop]?, where ?label?is its syntax category and ?
[start, stop]?
is therange of words it covers.
For example, the node inFig.
5 pointed by the dark arrow is labelled as?NP[3,4]?, where NP is its label and [3,4] meansthat it covers the span from the 3rd word to the 4thword.
In forest-based translation, rule matching ismuch more complicated than the tree-based one.Figure 2.
A packed forestZhang et al (2009) reduce the tree sequenceproblem into tree problem by introducing virtualnode and related forest conversion algorithms, so1038the algorithm proposed in this paper is also appli-cable to the tree sequence-based models.Figure 3.
Tree 1 (T1)      Figure 4.
Tree 2 (T2)3 Matching Methods in Previous WorkIn this section, we discuss the two typical rulematching algorithms used in previous work.3.1 Exhaustive search by tree fragmentsThis method generates all possible tree fragmentsrooted by each node in the source parse tree orforest, and then matches all the generated treefragments against the source parts (left hand side)of translation rules to extract the useful rules(Zhang et al, 2008a).Figure 5.
Node NP[3,4] in packed forestFigure 6.
Candidate fragments on NP[3,4]For example, if we want to extract useful rulesfor node NP[3,4] in Fig 5, we have to generate allthe tree fragments rooted at node NP[3,4] asshown in Fig 6, and then query each fragment inthe rule set.
Let  be a node in the packed forest,represents the number of possible tree frag-ments rooted at node , then we have:???
??
??????
????????????
??
??
??
?
??????????????????
??
?The above equation shows that the number oftree fragments is exponential to the span size, theheight and the number of hyper-edges it covers.
Ina real system, one can use heuristics, e.g.
the max-imum number of nodes and the maximum heightof fragment, to limit the number of possible frag-ments.
However, these heuristics are very subjec-tive and hard to optimize.
In addition, they mayfilter out some ?good?
fragments.3.2 Exhaustive search by rulesThis method does not generate any source treefragments.
Instead, it does top-down recursivematching from each node one-by-one with eachtranslation rule in the rule set (Mi and Huang2008).For example, given a translation rule with itsleft hand side as shown in Fig.
7, the rule match-ing between the given rule and the node IP[1,4] inFig.
2 can be done as follows.1.
Decompose the left hand side of the transla-tion rule as shown in Fig.
7 into a sequence of hy-per-edges in top-down, left-to-right order as fol-lows:IP => NP VP;  NP => NP NP;  NP => NN;NN => ?
?Figure 7.
The left hand side of a rule2.
Pattern match these hyper-edges(rule) one-by-one in top-down left-to-right order from nodeIP[1,4].
If there is a continuous path in the forestmatching all of these hyper-edges in order, thenwe can say that the rule is useful and matchable1039with the tree fragment covered by the continuouspath.
The following illustrates the matching steps:1.
Match hyper-edge ?IP => NP VP?
with nodeIP[1,4].
There are two hyper-edges in the forestmatching it: ?IP[1,4] => NP[1,1] VP[2,4]?
and?IP[1,4] => NP[1,2] VP [3,4]?, which generatestwo candidate paths.2.
Since hyper-edge ?NP => NP NP?
fails tomatch NP[1,1], the path initiated with ?IP[1,4] =>NP[1,1] VP[2,4]?
is pruned out.3.
Since there is a hyper-edge ?NP[1,2] =>NP[1,1] NP[2,2]?
matching ?NP => NP NP?
onNP[1,2], then continue for further matching.4.
Since ?NP=>NN?
on NP[2,2] matches?NP[2,2] => NN[2,2]?, then continue for furthermatching.5.
?NN=>???
on NN[2,2] matches ?NN[2,2]=>???
and it is the last hyper-edge in the inputrules.
Finally, there is one continuous path suc-cessfully matching the left hand side of the inputrule.This method is able to avoid the exponentialproblem of the first method as described in theprevious subsection.
However, it has to do one-by-one pattern matching for each rule on each node.When the rule set is very large (indeed it is verylarge in the forest-based model even with a smalltraining set), it becomes very slow, and even muchslower than the first method.4 The Proposed Hyper-tree-based RuleMatching AlgorithmIn this section, we first explain the motivation whywe re-organize the translation rule sets, and thenelaborate how to re-organize the translation rulesusing our proposed hyper-tree structure.
Finallywe discuss the top-down rule matching algorithmbetween forest and hyper-tree.4.1 MotivationFigure 8.
Two rules?
left hand sideFigure 9.
Common part of the two rules?
left handsides in Figure 8Fig.
9 shows the common part of the left handsides of two translation rules as shown in Fig.
8.In previous rule matching algorithm, the commonparts are matched as many times as they appear inthe rule set, which reduces the rule matchingspeed significantly.
This motivates us to proposethe hyper-tree structure and the rule matching al-gorithm to make the common parts shared by mul-tiple translation rules to be visited only once in theentire rule matching process.4.2 Hyper-node, hyper-path and hyper-treeA hyper-tree is a compact representation of agroup of tree translation rules with common partsshared.
It consists of a set of hyper-nodes withedges connecting different hyper-nodes into a bigtree.
A hyper-tree is constructed from the transla-tion rule sets in two steps:1) Convert each tree translation rule into a hy-per-path;2) Construct the hyper-tree by incrementallyadding each individual hyper-path into thehyper-tree.A tree rule can be converted into a hyper-pathwithout losing information.
Fig.
10 demonstratesthe conversion process:1) We first fill the rule tree with virtual nodesto make all its leaves have the same depthto the root;2) We then group all the nodes in the sametree level to form a single hyper-node,where we use a comma as a delimiter toseparate the tree nodes with different fathernodes;3) A hyper-path is a set of hyper-nodes linkedin a top-down manner.The commas and virtual nodes  are introducedto help to recover the original tree from the hyper-path.
Given a tree node in a hyper-node, if thereare n commas before it, then its father node is the(n+1)th tree node in the father hyper-node.
If wecould find father node for each node in hyper-nodes, then it is straightforward to recover theoriginal tree from the hyper-path by just addingthe edges between original father and childrennodes except the virtual node .1040After converting each tree rule into a hyper-path, we can organize the entire rule set into a bighyper-tree as shown in Figure 11.
The concept ofhyper-path and hyper-tree could be viewed as anextension of the "prefix merging" ideas for CFGrules (Klein and Manning 2001).Figure 10.
Convert tree to hyper-pathFigure 11.
A hyper-tree exampleAlgorithm 1 shows how to organize the rule setinto a big hyper-tree.
The general process is thatfor each rule we convert it into a hyper-path andthen add the hyper-path into a hyper-tree incre-mentally.
However, there are many different hy-per-trees generated given a big rule set.
We thenintroduce a TOP label as the root node to link allthe individual hyper-trees to a single big hyper-tree.
Algorithm 2 shows the process of adding ahyper-path into a hyper-tree.
Given a hyper-path,we do a top-down matching between the hyper-tree and the input hyper-path from root hyper-node until a leaf hyper-node is reached or there isno matching hyper-node at some level found.Then we add the remaining unmatchable part ofthe input hyper-path as the descendants of the lastmatchable hyper-node.Please note that in Fig.
10 and Fig.
11, we ig-nore the target side (right hand side) of translationrules for easy discussion.
Indeed, we can easilyrepresent all the complete translation rules (notonly left hand side) in Fig.
11 by simply addingthe corresponding rule target sides into each hy-per-node as done by line 5 of Algorithm 1.Any hyper-path from the root to any hyper-node (not necessarily be a leaf of the hyper-tree)in a hyper-tree can represent a tree fragment.
As aresult, the hyper-tree in Fig.
11 can represent up to6 candidate tree fragments.
It is easy to understandthat the maximum number of tree fragments that ahyper-tree can represent is equal to the number ofhyper-nodes in it except the root.
It is worth not-ing that a hyper-node in a hyper-tree without anytarget side rule attached means there is no transla-tion rule corresponding to the tree fragment repre-sented by the hyper-path from the root to the cur-rent hyper-node.
The compact representation ofthe rule set by hyper-tree enables a fast algorithmto do translation rule matching.Algorithm 1.
Compile rule set into hyper-treeInput: rule setOutput: hyper-tree1.
Initialize hyper-tree as a TOP node2.
for  each rule in rule set  do3.
Convert the left hand side tree to a hyper-path p4.
Add hyper-path p into hyper-tree5.
Add rule?s right hand side to the leaf hyper-node ofa hyper-path in the hyper-tree6.
end forAlgorithm  2.
Add hyper-path into hyper-treeInput: hyper-path p and hyper-tree tNotation:h: the height of hyper-path pp(i) : the hyper-node of ith level (top-down) of pTN: the hyper-node in hyper-treeOutput: updated hyper-tree t1.
Initialize TN as TOP2.
for  i := 1 to h  do3.
if there is a child c of TN has the same label as p(i)then4.
TN := c5.
else6.
Add a child c to TN, label c as p(i)7.
TN := c4.3 Translation rule matching between forestand hyper-treeGiven the source parse forest and the translationrules represented in the hyper-tree structure, herewe present a fast matching algorithm to extract so-called useful translation rules from the entire ruleset in a top-down manner for each node of the for-est.As shown in Algorithm 3, the general processof the matching algorithm is as follows:1041Algorithm 3.
Rule matching on one nodeInput: hyper-tree T, forest F, and node nNotation:FP: a pair <FNS, TN>, FNS is the frontier nodes ofmatched tree fragment,TN is the hyper-tree node matching itSFP: the queue of FPOutput: Available rules on node n1.
if there is no child c of TOP having the same label as nthen2.
Return failure.3.
else4.
Initialize FP as <{n},c> and put it into SFP5.
for each FP in SFP do6.
SFP ?
PropagateNextLevel(FP.FNS, FP.TN)7.      for each FP in SFP do8.
if the rule set attached to FP.TN is not emptythen9.
Add FP to resultAlgorithm 4.
PropagateNextLevelInput: Frontier node sequence FNS, hyper-tree node TNNotation:CT: a child node of TNthe number of node sequence (separated bycomma, see Fig 11) in CT is equal to the numberof node in TN.CT(i) : the ith node sequence in hyper-node CTFNS(i): the ith node in FNSTFNS: the temporary set of frontier node sequenceRFNS: the result set of frontier node sequenceFP:  a pair of frontier node sequenceand hyper-tree nodeRFP: the result set of FPOutput: RFP1.
for each child hyper-node CT of TN do2.
for i:= 1 to the number of node sequence in CT do3.
empty TFNS4.
if CT(i) ==  then5.
Add FNS(i) to TFNS.6.
else7.
for each hyper-edge e attached to FNS(i) do8.
if e.children match CT(i) then9.
Add e.children to TFNS10.
if TFNS is empty then11.
empty RFNS12.
break13.
else if i == 1 then14.
RFNS := TFNS15.
else16.
RFNS := RFNS  TFNS17.
for each FNS in RFNS do18.
add <FNS, CT > into RFP1) For each node n of the source forest if nochild node of TOP in hyper-tree has the same labelwith it, it means that no rule matches any treefragments rooted at the node n (i.e., no usefulrules to be used for the node n) (line 1-2)2) Otherwise, we match the sub-forest startingfrom the node n against a sub-hyper-tree startingfrom the matchable child node of TOP layer bylayer in a top-down manner.
There may be manypossible tree fragments rooted at node n and eachof them may have multiple useful translation rules.In our implementation, we maintain a data struc-ture of FP = <FNS, TN> to record the currentlymatched tree fragment of forest and its corres-ponding hyper-tree node in the rule set, whereFNS is the frontier node set of the current treefragment and TN is the hyper-tree node.
The datastructure FP is used to help extract useful transla-tion rules and is also used for further matching oflarger tree fragments.
Finally, all the FPs for thenode n are kept in a queue.
During the search, thequeue size is dynamically increased.
The matchingalgorithm terminates when all the FPs have beenvisited (line 5-6 and Algorithm 4).3) In the final queue, each element (FP) of thequeue contains the frontier node sequence of thematched tree fragment and its corresponding hy-per-tree node.
If the target side of a rule in the hy-per-tree node is not empty, we just output thefrontier nodes of the matched tree fragment, itsroot node n and all the useful translation rules forlater translation process.Algorithm 4 describes the detailed process ofhow to propagate the matching process down tothe next level.
<FNS, TN> is the current levelfrontier node sequence and hyper-tree node.
Givena child hyper-node CT of TN (line 1), we try tofind the group of next level frontier node sequenceto match it (line 2-18).
As shown in Fig 11, a hy-per-node consists of a sequence of node sequencewith comma as delimiter.
For the ith node se-quence CT(i) in CT, If CT(i) is , that meansFNS(i) is a leaf/frontier node in the matched treefragment and thus no need to propagate to the nextlevel (line 4-5).
Otherwise, we try each hyper-edge e of FNS(i) to see whether its children matchCT(i), and put the children of the matched hyper-edge into a temp set TFNS (line 7-9).
If the tempset is empty, that means the current matching failsand no further expansion needs (line 10-12).
Oth-erwise, we integrate current matched children intothe final group of frontier node sequence (line 13-16) by Descartes Product ( ).
Finally, we con-struct all the <FNS, TN> pair for next levelmatching (line 17-18).It would be interesting to study the time com-plexity of our Algorithm 3 and 4.
Suppose themaximum number of children of each hyper-nodein hyper-tree is N (line 1), the maximum numberof node sequence in CT is M (line 2), the maxi-mum number of hyper-edge in each node inpacked forest is K (line 7), the maximum numberof hyper-edge with same children representationin each node in packed forest is C (i.e.
the maxi-mum size of TFNS in line 16, and the maximumcomplexity of the Descartes Product in line 161042would be CM), then the time complexity upper-bound of Algorithm 4 is O(NM(K+CM)).
For Al-gorithm 3, its time complexity is O(RNM(K+CM)),where R is the maximum number of tree fragmentmatched in each node.5 Experiment5.1 Experimental settingsWe carry out experiment on Chinese-EnglishNIST evaluation tasks.
We use FBIS corpus(250K sentence pairs) as training data with thesource side parsed by a modified Charniak parser(Charniak 2000) which can output a packed forest.The Charniak Parser is trained on CTB5, tuned on301-325 portion, with F1 score of 80.85% on 271-300 portion.
We use GIZA++ (Och and Ney, 2003)to do m-to-n word-alignment and adopt heuristic?grow-diag-final-and?
to do refinement.
A 4-gramlanguage model is trained on Gigaword 3 Xinhuaportion by SRILM toolkit (Stolcke, 2002) withKneser-Ney smoothing.
We use NIST 2002 asdevelopment set and NIST 2003 as test set.
Thefeature weights are tuned by the modified Koehn?sMER (Och, 2003, Koehn, 2007) trainer.
We usecase-sensitive BLEU-4 (Papineni et al, 2002) tomeasure the quality of translation result.
Zhang etal.
2004?s implementation is used to do significanttest.Following (Mi and Huang 2008), we use viterbialgorithm to prune the forest.
Instead of using astatic pruning threshold (Mi and Huang 2008), weset the threshold as the distance of the probabili-ties of the nth best tree and the 1st best tree.
Itmeans the pruned forest is able to at least keep allthe top n best trees.
However, because of the shar-ing nature of the packed forest, it may still containa large number of additional trees.
Our statisticshows that when we set the threshold as the 100thbest tree, the average number of all possible treesin the forest is 1.2*105 after pruning.In our experiments, we compare our algorithmwith the two traditional algorithms as discussed insection 3.
For the ?Exhaustive search by tree?
al-gorithm, we use a bottom-up dynamic program-ming algorithm to generate all the candidate treefragments rooted at each node.
For the ?Exhaus-tive search by rule?
algorithm, we group all ruleswith the same left hand side in order to remove theduplicated matching for the same left hand siderules.
All these settings aim for fair comparison.5.2 Accuracy, speed vs. rule heightsWe first compare the three algorithms?
perfor-mance by setting the maximum rule height from 1to 5.
We set the forest pruning threshold to the100th best parse tree.Table 1 compares the speed of the three algo-rithms.
It clearly shows that the speed of both ofthe two traditional algorithms increases dramati-cally while the speed of our hyper-tree based algo-rithm is almost linear to the tree height.
In the caseof rule height of 5, the hyper-tree algorithm is atleast 19 times (9.329/0.486) faster than the twotraditional algorithms and saves 8.843(9.329 -0.486) seconds in rule matching for each sentenceon average, which contributes 57% (8.843/(9.329+ 6.21)) speed improvement to the overall transla-tion.HRule MatchingD Exhaus-tiveby treeExhaus-tiveby ruleHyper-tree-based1 0.043 0.077 0.083   2.962 0.047 0.920 0.173   3.563 0.237 9.572 0.358   4.024 2.300 48.90 0.450   5.275 9.329 90.80 0.486   6.21Table 1.
Speed in seconds per sentence vs. ruleheight; ?H?
is rule height, ?D?
represents the de-coding time after rule matchingHeight BLEU1 0.16462 0.24983 0.28244 0.28745 0.2925Moses 0.2625Table 2.
BLEU vs. rule heightTable 2 reports the BLEU score with differentrule heights, where Moses, a state-of-the-artphrase-based SMT system, serves as the baselinesystem.
It shows the BLEU score consistentlyimproves as the rule height increases.
In addition,one can see that the rules with maximum height of5 are able to outperform the rules with maximumheight of 3 by 1 BLEU score (p<0.05) and signifi-cantly outperforms Moses by 3 BLEU score(p<0.01).
To our knowledge, this is the first timeto report the performance of rules up to height of 5for forest-based translation model.1043We also study the distribution of the rules usedin the 1-best translation output.
The results areshown in Table 3; we could see something inter-esting that is as the rule height increases, the totalnumber of rules with that height decreases, whilethe percentage of partial-lexicalized increasesdramatically.
And one thing needs to note is thepercentage of partial-lexicalized rules with heightof 1 is 0, since there is no partial-lexicalized rulewith height of 1 in the rule set (the father node ofa word is a pos tag node).H TotalRule Type Percentage (%)F P U1 9814   76.58     0 23.422 5289   44.99     46.40 8.603 3925   18.39     77.25 4.354 1810   7.90      87.68 4.415 511    6.46 90.50 3.04Table 3. statistics of rules used in the 1-best trans-lation output, ?F?
means full-lexicalized, ?P?means partial-lexicalized, ?U?
means unlexiclaizd.5.3 Speed vs. forest pruning thresholdThis section studies the impact of the forest prun-ing threshold on the rule matching speed whensetting the maximum rule height to 5.ThresholdRule MatchingExhaus-tiveby treeExhaus-tiveby ruleHyper-tree-based1 1.2 23.66 0.17110 3.1 36.42 0.23450 5.7 66.20 0.405100 9.3 90.80 0.486200 27.3 104.86 0.598500 133.6 148.54 0.873Table 4.
Speed in seconds per sentence vs. for-est  pruning thresholdIn Table 4, we can see that our hyper-tree basedalgorithm is the fastest among the three algorithmsin all pruning threshold settings and even 150times faster than both of the two traditional algo-rithms with threshold of 500th best.
Table 5 showsthe average number of parse trees embedded in apacked forest with different pruning thresholds persentence.
We can see that the number of trees in-creases exponentially when the pruning thresholdincreases linearly.
When the threshold is 500th best,the average number of trees per sentence is1.49*109.
However, even in this extreme case, thehyper-tree based algorithm is still capable of com-pleting rule matching within 1 second.Threshold Number of Trees1 110 3250 5922100 128860200 2.75*106500 1.49*109Table 5.
Average number of trees in packedforest with different pruning threshold.5.4 Hyper-tree compression rateAs we describe in section 4.2, theoretically thenumber of tree fragments that a hyper-tree canrepresent is equal to the number of hyper-nodes init.
However, in real rule set, there is no guaranteethat each tree fragment in the hyper-tree has cor-responding translation rules.
To gain insights intohow effective the compact representation of thehyper-tree and how many hyper-nodes withouttranslation rules, we define the compression rateas follows.Table 6 reports the different statistics on therule sets with different maximum rule heightsranging from 1 to 5.
The reported statistics are thenumber of rules, the number of unique left handside (since there may be more than one rules hav-ing the same left hand side), the number of hyper-nodes and the compression rate.H n_rules n_LHS n_nodes c_rate1 21588 10779 10779 100%2 141632 51807 51903 99.8%3 1.73*106 491268 494919 99.2%4 8.65*106 2052731 2083296 98.5%5 1.89*107 3966742 4043824 98.1%Table 6.
Statistics of rule set and hyper-tree.
?H?is rule height, ?n_rules?
is the number of rules,?n_LHS?
is the number of unique left hand side,?n_nodes?
is the number of hyper-nodes in hyper-tree and ?c_rate?
is the compression rate.Table 6 shows that in all the five cases, thecompression rates of hyper-tree are all more than104498%.
It means that almost all the tree fragmentsembedded in the hyper-tree have correspondingtranslation rules.
As a result, we are able to usealmost only one hyper-edge (i.e.
only the frontiernodes of a tree fragment without any internalnodes) to represent all the rules with the same lefthand side.
This suggests that our hyper-tree is par-ticularly effective in representing the tree transla-tion rules compactly.
It also shows that there are alot of common parts among different translationrules.All the experiments reported in this sectionconvincingly demonstrate the effectiveness of ourproposed hyper-tree representation of translationrules and the hyper-tree-based rule matching algo-rithm.6 ConclusionIn this paper2, we propose the concept of hyper-tree for compact rule representation and a hyper-tree-based fast algorithm for translation rulematching in a forest-based translation system.
Wecompare our algorithm with two previous widely-used rule matching algorithms.
Experimental re-sults on the NIST Chinese-English MT 2003 eval-uation data set show the rules with maximum ruleheight of 5 outperform those with height 3 by 1.0BLEU and outperform MOSES by 3.0 BLEU.
Inthe same test cases, our algorithm is at least 19times faster than the two traditional algorithms,and contributes 57% speed improvement to theoverall translation.
We also show that in a morechallenging setting (forest containing 1.49*109trees on average) our algorithm is 150 times fasterthan the two traditional algorithms.
Finally, weshow that the hyper-tree structure has more than98% compression rate.
It means the compact re-presentation by the hyper-tree is very effective fortranslation rules.ReferencesEugene Charniak.
2000.
A maximum-entropy inspiredparser.
NAACL-00.Michel Galley, Mark Hopkins, Kevin Knight and Da-niel Marcu.
2004.
What?s in a translation rule?HLT-NAACL-04.Liang Huang and David Chiang.
2005.
Better k-bestParsing.
IWPT-05.Liang Huang and David Chiang.
2007.
Forest rescor-ing: Faster decoding with integrated language mod-els.
ACL-07.
144?151The corresponding authors of this paper are Hui Zhang(zhangh1982@gmail.com) and Min Zhang(mzhang@i2r.a-star.edu.sg)Dan Klein and Christopher D. Manning.
2001.
Parsingand Hypergraphs.
IWPT-2001.Dan Klein and Christopher D. Manning.
2001.
Parsingwith Treebank Grammars: Empirical Bounds, Theo-retical Models, and the Structure of the Penn Tree-bank.
ACL - 2001.
338-345.Kevin Knight.
1999.
Decoding Complexity in Word-Replacement Translation Models.
CL: J99-4005.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, Ri-chard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.ACL-07.
177-180.
(poster)Yang Liu, Qun Liu and Shouxun Lin.
2006.
Tree-to-String Alignment Template for Statistical MachineTranslation.
COLING-ACL-06.
609-616.Yang Liu, Yun Huang, Qun Liu and Shouxun Lin.2007.
Forest-to-String Statistical Translation Rules.ACL-07.
704-711.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
ACL-HLT-08.
192-199.Haitao Mi and Liang Huang.
2008.
Forest-basedTranslation Rule Extraction.
EMNLP-08.
206-214Franz J. Och.
2003.
Minimum error rate training instatistical machine translation.
ACL-03.
160-167.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Mod-els.
Computational Linguistics.
29(1) 19-51Kishore Papineni, Salim Roukos, ToddWard and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
ACL-02.311-318.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
ICSLP-02.
901-904.Masaru Tomita.
1987.
An Efficient Augmented-Context-Free Parsing Algorithm.
ComputationalLinguistics 13(1-2): 31-46.Hui Zhang, Min Zhang, Haizhou Li, Aiti Aw and ChewLim Tan.
2009.
Forest-based Tree Sequence toString Translation Model.
ACL-IJCNLP-09.Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, ShengLi and Chew Lim Tan.
2007.
A Tree-to-Tree Align-ment-based Model for Statistical Machine Transla-tion.
MT-Summit-07.
535-542.Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, ChewLim Tan, Sheng Li.
2008a.
A Tree Sequence Align-ment-based Tree-to-Tree Translation Model.
ACL-HLT-08.
559-567.Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, ShengLi.
2008b.
Grammar Comparison Study for Transla-tional Equivalence Modeling and Statistical Ma-chine Translation.
COLING-08.
1097-1104.Ying Zhang, Stephan Vogel, Alex Waibel.
2004.
Inter-preting BLEU/NIST scores: How much improvementdo we need to have a better system?
LREC-041045
