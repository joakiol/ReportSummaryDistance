INTEGRATED TECHNIQUES FOR PHRASE EXTRACTIONFROM SPEECHMarie MeteerJ.
Robin RohlicekBBN Systems and TechnologiesCambridge, Massachusetts 02138mmeteer@bbn.comrohl icek@bbn.comABSTRACTWe present an integrated approach to speech and naturallanguage processing which uses a single parser to createtraining for a statistical speech recognition component andfor interpreting recognized text.
On the speech recognitionside, our innovation is the use of a statistical modelcombining N-gram and context-free grammars.
On thenatural language side, our innovation is the integration ofparsing and semantic interpretation to build references foronly targeted phrase types.
In both components, asemantic grammar and partial parsing facilitate robustprocessing of the targeted portions of a domain.
Thisintegrated approach introduces as much linguistic structureand prior statistical information as is available whilemaintaining a robust full-coverage statistical languagemodel for recognition.
In addition, our approach facilitatesboth the direct detection of linguistic constituents withinthe speech recognition algorithms and the creation ofsemantic interpretations of the recognized phrases.1.
INTRODUCTIONLanguage modeling for speech recognition has focused onrobustness, using statistical techniques such as n-grams,whereas work in language understanding and informationextraction has relied more on rule based techniques toleverage linguistic and domain information.
However, theknowledge needed in these two components of a speechlanguage system is actually very similar.
In our work, wetake an integrated approach, which uses a single grammarfor both language modeling and language understanding fortargeted portions of the domain and uses a single parser forboth training the language model and extractinginformation from the output of the recognizer.The goal of our work is provide speech recognitioncapabilities that are analogous to those of informationextraction systems: given large amounts of (often lowquality) speech, selectively interpret particular kinds ofinformation.
For example, in the air traffic controldomain, we want to determine the flight IDs, headings, andaltitudes of the planes, and to ignore other information,such as weather and ground movement.The following is a summary of the main techniques we usein our approach:Integration of N-gram and context free grammars forspeech recognition: While statistically based Markov-chain language models (N-gram models) have beenshown to be effective for speech recognition, there is,in general, more structure present in natural languagethan N-gram models can capture.
Linguistically basedapproaches that use statistics to provide probabilitiesfor word sequences that are accepted by a grammartypically require a full coverage grammar, and thereforeare only useful for constrained sublanguages.
In thework presented here, we combine linguistic structurein the form of a partial-coverage phrase structuregrammar with statistical N-gram techniques.
Theresult is a robust statistical grammar which explicitlyincorporates yntactic and semantic structure.
Asecond feature of our approach is that we are able todetermine which portions of the text were recognizedby the phrase grammars, allowing us to isolate thesephrases for more processing, thus reducing the overalltime needed for interpretation.Partial parsing: It is well recognized that full coveragegrammars for even subsets of natural anguage arebeyond the state of the art, since text is inevitablyerrorful and new words frequently occur.
There iscurrently aupsurge in research in partial parsing in thenatural language community (e.g., Hindle 1983,Weischedel, et al 1991), where rather than building asingle syntactic tree for each sentence, a forest isreturned, and phrases outside the coverage of thegrammar and unknown words are systematicallyignored.
We are using the partial parser "Sparser"(McDonald 1992), which was developed for extractinginformation from open text, such as Wall StreetJournal articles.228Figure 1:Semantic grammar."
Central to our approach is the useof a minimal, semantically based grammar.
Thisallows us to build targeted grammars pecific to thedomain.
It also makes the grammar much moreclosely tied to the lexicon, since the lexical itemsappear in the rules directly and in general there aremany categories, each covering only a small numberof lexical items.
As Schabes (1992) points out inreference to lexicalized stochastic tree adjoininggrammars (SLTAG), an effective linguistic modelmust capture both lexical and hierarchical information.Context free grammars using only syntacticinformation fail to capture lexical information.Figure 1 shows a block diagram of the overall approachwith the two components which use the parser shaded: themodel construction component and the interpretationcomponent.For both the language modeling and informationextraction, we are using the partial parser Sparser(McDonald 1992).
Sparser is a bottom-up chart parserwhich uses a semantic phrase structure grammar (i.e.
thenonterminals are semantic ategories, uch as HEADING orFLIGHT-ID, rather than traditional syntactic ategories, uchas CLAUSE or NOUN-PHRASE).
Sparser makes noassumption that the chart will be complete, i.e.
that a toplevel category will cover all of the input, or even that allterminals will be covered by categories, effectivelyallowing unknown words to be ignored.
Rather it simplybuilds constituent structure for those phrases that are in itsgrammar.In Section Two, we describe language modeling, and inThree, we focus on semantic interpretation.
In SectionFour, we present he results of our initial tests in the airtraffic control domain, and finally we conclude with futuredirections for the work.2.
LANGUAGE MODEL INGThere are two main inputs to the model constructionportion of the system: a transcribed speech training set anda phrase-structure grammar.
The phrase-structure grammarOverall Approachis used to partially parse the training text.
The output ofthis is: (1) a top-level version of the original text withsubsequences of words replaced by the non-terminals thataccept hose subsequences; and (2) a set of parse trees forthe instances of those nonterminals.3.1 Rule Probabi l i t iesFigure two below shows a sample of the rules in the ATCgrammar followed by examples of transcribed text and thetext modified by the parser.
Note that in this case, wheregoal is to model aircraft identifiers and a small set of airtraffic control commands, other phrases like theidentification of the controller, traffic information, etc., areignored.
They will be modelled by the n-gram, rather thanas specific phrases.R1 (def-rule land-action > ("land"))R2 (def-rule takeoff-action > ("takeoff"))R3 (def-rule takeoff-action > ("go"))R4 (def-rule clrd/land > ("cleared" to" land-action)R5 (def-rule clrd/takeoff >("cleared" to" takeoff-action))R6 (def-rule clrd/takeoff >("cleared" for" takeoff-action )))R7 (def-rule tower-clearance > (runway clrd/land)R8 (def-rule tower-clearance > (runway clrd/takeoff ))Figure 2: Phrase structure rules for tower clearance>Nera twenty one zero nine runway two two fight cleared for takeoff>COMMERCIAL-AIRPLANE TOWER-CLEARANCE>Nera thirty seven twelve Boston tower runway two two fight cleared for takeoff>COMMERCIAL-AIRPLANE Boston tower TOWER-CLEARANCE>Jet Link thirty eight sixteen Boston tower runway two two fight cleared fortakeoff traffic on a five mile final landing two two fight>COMMERCIAL-AIRPLANE Boston tower TOWER-CLEARANCE traffic on afive mile final landing RUNWAY>Jet Link thirty eight zero five runway two two fight cleared for takeoff sorry forthe delay>COMMERCIAL-AIRPLANE TOWER-CLEARANCE sorry for the delayFigure 3: Training text modified by parserUsing the modified training text we construct aprobabilistic model for sequences of words and non-terminals.
The parse trees are used to obtain statistics forthe estimation of production probabilities for the rules inthe grammar.
Since we assume that the productionprobabilities depend on their context, a simple count is229insufficient.
Smoothed maximum likelihood productionprobabilities are estimated based on context dependentcounts.
The context is defined as the sequence of rules andpositions on the right-hand sides of these rules leadingfrom the root of the parse tree to the non-terminal t theleaf.
The probability of a parse therefore takes into accountthat the expansion of a category may depend on its parents.However, it does not take into consideration the expansionof the sister nonterminals, though we are currentlyexploring means of doing this (cf.
Mark, et al 1992).In the above grammar (Figure 2), the expansion ofTAKEOFF-ACTION may be different depending on whether itis part of rule 5 or rule 6.
Therefore, the "context" of aproduction is a sequence of rules and positions that havebeen used up to that point, where the "position" is wherein the RHS of the rule the nonterminal is.
For example,in the parse shown below (Figure 4), the context of R2(TAKEOFF-ACTION > "takeoff') is rule 8/position 2, rule6/position 3.
We discuss the probabilities required toevaluate the probability of a parse in the next section.TOWER-CLEARANCE (R8)CLRD/'I'AKEOFF (R6)e ~*runway" RUNWA?-NUM,,,,,,,,,,,,.,,,,,,,,,,,,,"'r ~ .,,,,,,,,,,,.,,,,,,.
.cl OFF-ONES ONES LR-D AC~ON(R2)I I !
="two" "six" "right .
.
.
.
takeoff"Figure 4: Parse tree with path highlightedIn order to use a phrase-structure grammar directly in atime-synchronous recognition algorithm, it is necessary toconstruct a finite-state network representation If there is norecursion in the grammar, then this procedure isstraightforward: for each rule, each possible contextcorresponds toa separate subnetwork.
The subnetworks fordifferent rules are nested.
We are currently comparingmethods of allowing limited recursion (e.g.
followingPereira & Wright 1990).
Figure 5 shows the expansion ofthe rules in from Figure 2.There have been several attempts to use probabilityestimates with context free grammars.
The most commontechnique is using the Inside-Outside algorithm (e.g.Pereira & Schabes 1992, Mark, et al 1992) to infer agrammar over bracketed texts or to obtain Maximum-Likelihood estimates for a highly ambiguous grammar.However, most require a full coverage grammar, whereaswe assume that only a selective portion of the text will becovered by the grammar.
A second difference is that theyuse a syntactic grammar, which results in the parse beinghighly ambiguous (thus requiring the use of the Inside-Outside algorithm).
We use a semantic grammar, withwhich there is rarely multiple interpretations for a singleutterance.
13.2 Probability EstimationBoth the context-dependent production probabilities of thephrase grammar and one for the Markov chain probabilitiesfor the top-level N-gram model must be estimated.
We usethe same type of "backing-off' approach in both cases.
Forthe phrase grammar, we estimate probabilities of the formP(rn+ 1 I (r I, Pl), (r2, P2) .
.
.
.
.
(rn, Pn))where r i are the rules and P i  are the positions within therules.
In the N-gram case, we are estimatingP(Sn+l I sl, s2 ..... Sn)where Sl, s2 ..... Sn is the sequence of words and non-terminals leading up to Sn+l.
In both cases, the estimateis based on a combination of the Maximum-Likelihoodestimate, and the estimates in a reduced context:P(rn+l I (r 2, P2) .
.
.
.
.
(rn, Pn))andP(sn+ 1 I s2 ..... Sn).The Maximum-Likelihood (ML) estimate reduces to asimple relative-frequency computation i the N-gram case.In the phrase grammar case, we assume that the parses arein general unambiguous, which has been the case so far inour domain.
Specifically, we only consider a single parseand accumulate r lative frequency statistics for the variouscontexts in order to obtain the ML productionFigure 5: Finite state network230probabilities.The approach we use to backing off is described inPlaceway, et al (1993).
Specifically, we formpBO(y ix 1 ..... Xn ) = pML(y Ix 1 .... Xn) (1 - 0)+pBO(y lx  2 ..... x n) 0.The value of 0 depends on the context Xl ..... Xn and ismotivated by approximation of the probability of0= r / (n+r)where r is the number of different next symbols/rules seenin the context and n is the number of times the context wasobserved.3.
INFORMATION EXTRACTIONThe final stage of processing is the interpretation of therecognized word sequence.
We use the same phrasestructure grammar for interpretation as that used to buildthe recognition model.
However, in this last phase, wetake advantage of the semantic interpretation facility of theparser.Most approaches tonatural language understanding separateparsing (finding a structural description) from interpretation(finding a semantic analysis).
In the work presented here,we use a single component for both.
The Sparser systemintegrates parsing and interpretation todetermine "referents"for phrases incrementally as they are recognized, rather thanwaiting for the entire parse to finish.
The referent of aphrase is the object in the domain model that the phraserefers to.
For example, the initial domain model consistsof objects that have been created for entities which areknown to the system in advance, such as airlines.
Whenthe name of an airline is recognized, such as "Delta", itsreferent is the airline object, #<airline delta>.
Referents forentities that cannot be anticipated, such as numbersequences and individual airplanes, are created incrementallyController Transmission:when the phrase is recognized.
Figure 6 shows an exampleof the edges created by the parser and their referents.When a referent actually refers to an entity in the world,such as a runway or airplane, then the same referent objectis cataloged and reused each time that entity is mentioned.The referent for a number sequence is a number object withthe value the sequence represents.
The referent for theentire phrase "Delta three five nine" is an object of typeairplane.
In some cases, the object will also be indexed byvarious subparts (such as indexing a flight ID by the digitportion of the ID) to aid in disambiguating incompletesubsequent references.
For example, in the pilot reply inFigure 6, indexing allows the system to recognize that thenumber "three five nine" actually refers to the previouslymentioned Delta flight.We extend the notion of referent from simply things in theworld to utterance acts as well, such as commands.
Eachtime a command is uttered, a new referent is created.Command referents are templates which are created whensome core part is recognized and then added tocompositional s other (generally optional) information isrecognized.
So following our earlier example of towerclearances, rules 4, 5, and 6 instantiate a takeoff clearancetemplate and fill in the action type, whereas rules 7 and 8fill in the "runway" field.
We show examples of each ofthese groups and the templates in Figure 7 below:R6 (def-rule clrd/takeoff ("cleared" for" takeoff-action):referent (:function create-tower-clearance third))R8 (def-rule tower-clearance (runway clrd/takeoff):referent (:function add-to-tower-clearance second first))#<tower-clearanceType: TOWER-CLEARANCEACTION: #<TAKEOFF>RUNWAY: #<Runway 26L>>Figure 7: Rules with referents and completed template.Pilot Reply:CRD/TAKEOFFACTIONIcleared for takeoffI I ICOMMERCIAL AIRPLANE TOWER-COMMANDl #<airplane DEL359> li #<clearance>category + AIRLINE .
.
.
.
.
,-, II RUNWAY CLRDrrAKEOFFre ferent  .~  .
.. ,~um-o=u I I I  #<R26L> II #<clearance> I<amine  .
TAKEOFF- edge'-="\[ ~ delta:J\[ #<number359>\[ll I .Itokens--~ delta I three I fivel nine I runway I two I six I left I cleared i for I take?f f lCOMMERCIAL AIRPLANEI #<airplane DEL359>NUM-SEQI I #<number 359> \]three five nineI I I IFigure 6: Parse Diagram2314.
RESULTSThis approach was first applied in the Gisting system(Rohlicek, et al 1992), where the goal was to extract flightIDs from off-the-air ecordings of ATC communications.In this application, the input is extremely noisy andrecognition performance is generally quite poor.
We reportthe general word recognition accuracy and flight IDrecognition accuracy for both the combined phrase structureand n-gram language models (as described in section 2), andjust n-grams.
The training data consists of 2090transcribed controller transmissions.
Testing data consistsof 469 transmissions of average length 16.
The results arepresented for controller transmissions where the start andend times of the transmissions are known.As shown in Table 1, the overall word accuracy wasimproved only slightly (70% to 72%), which was expectedsince we only modeled a small portion of the domain.However, the best result was in the fraction of flight IDsdetected, where we halved the miss rate (from 11% down to5%).N-gram& phraseN-gramWord RecognitionSub.
Del.
Ins Acc.18.6 4.5 5.2 7220.4 5.0 4.3 70FID rec.accuracy5753Table 1: Results for Gisting experiment.The next set of experiments we ran focused on comparinggeneral word accuracy with word accuracy in the targetedportion of the domain (i.e.
that portion covered by thegrammar).
Using a different ATC dataset (still operationaldata, but recorded in the tower rather than off the air), wecompared bi-grams with our combined rule based and n-gram approach The grammar covered approximately 68%of the training data.
We tested not only the overall wordaccuracy, but also the word accuracy in those portions ofthe text that were modeled by the grammar.Integrated) rds  wordBi-gramwords word wo scorrect error correct errorOverall word 64.3 45.9 68.2 40.4accuracyWord accuracy 58.6 46.0 74.8 36.2in phrasesTable 2: Comparison between Bi-grams and integratedapproach.As shown in Table 2, not only was there an improvementin the overall word score using the integrated vs. the bi-gram language model, we can see that the improvement inaccuracy in the targeted portion of the domain was muchgreater in the integrated approach.Our third set of experiments focused on the informationextraction portion of the system.
We evaluated the abilityof the parser to extract wo kinds of commands from theoutput of recognition.
In these experiments, we took truthto be the performance of the parser on the transcribed text,since we did not have truth annotated for these phrases inour test data.
(It has been our experience in working w~hflight IDs, which were annotated, that in the ATC domainthe phrases are regular enough that the parser will extractnearly 100% of the information in the targeted categories.The errors that occur are generally caused by restarts,speech errors, or transcription errors.
)Using the same training and test conditions as the first setof experiments described above 1, we extracted phrases fortower clearances using the grammar partially shown above(Figure 2), and direction orders, which generally consistedof a direction to turn and some heading.
The test setconsisted of 223 controller utterances and we scored ascorrect only exact matches, where the same referent objectwas found and all of the fields matched exactly.
Results areshown in Table Three.Exact Match Direction TowerOrder ClearanceTotal in reference 38 118Total in recog.
35 117Precision 91.4% 43.6%Recall 81.6% 43.2%False Positives 1 11Misses 5 12Errors 2 7Partial MatchPrecision 64.4Recall 63.8Table 3: Precision and recall in extracting information.We observe that the precision and recall for direction ordersis drastically better than that for tower clearances, eventhough the grammars for the two are very similar in size.One difference, which we would like to explore further, is1 Note on difference was that these tests were done onrecognition results after automatic segmentation andclassification according to pilot and controller, whichgenerally decrease recognition accuracy.232that the direction orders grammar was part of the languagemodel which was used for recognition, whereas towerclearances were not modelled by the phrase grammar, onlythe n-gram.
To know if this was a factor, we need tocompare the actual word recognition accuracy for these twophrase types.In looking at the results for tower clearances, we found thatalthough the exact match score was very low, there weremany partial matches, where for example the runway and orthe action type (takeoff, land, etc.)
were found correctly,even though the entire tower clearance was not recognized.In order to take into account hese partial matches, werescored the precision and recall, counting each individualpiece of information (runway, action, and clearance), sothat an exact match gets a score of 3 and partial matchesscore a 1 or 2.
Using this measure, we got a significantlyimproved performance: precision 64.4 and recall 63.8.These results highlight one of the main the advantage ofthis approach, that even with errorful input, usefulinformation can be found.FUTURE WORKWe have shown the the approach described here bothimproves overall word accuracy in recognition and providesa means for extracting targeted information evenrecognition performance is quite poor.
Our next goal is toapply the technique to new domains.
As part of this effortwe are developing a set of tools for building and evaluatinggrammars.We are also also applying these techniques in newapplications.
In particular, we have recently performedexperiments in Event Spotting, which is an extension ofwordspotting where the goal is to determine the location ofphrases, rather than single keywords.
We used theparser/extraction portion of the system to find examples ofphrase types in the corpus and to evaluate the results, aswell as in the language model of the recognizer.
In anexperiment detecting time and date phrases in theSwitchboard corpus (which is conversational telephonequality data), we saw an increase in detection rate overstrictly bi-gram or phoneme loop language models(Jeanrenaud, et al 1994).Acknowledgement This work was funded by ARPA andthe Air Force Rome Laboratory under contract F30602-89-C-0170.REFERENCESHindle, Don (1983) "Deterministic Parsing of Syntactic Non-fluencies" Proc.
of the 21st Annual Meeting of theAssociation for Computational Linguistics, June 15-17, pp.123-128.Jeanrenaud, P., Siu, M., Rohlicek, R., M., Meteer, Gish, H.(1994) "Spotting Events in Continuous Speech" to appearin Proceedings of International Conference of Acoustics,Speech, and Signal Processing (ICASSP), April 1994,Adelaide, Australia.Mark, K., Miller, M., Grenander, U., & Abney, S. (1992)"Parameter Estimation for Constrained Context-freeLanguage Models" in Proceedings ofthe Speech and NaturalLanguage Workshop, February, 1992, Morgan Kaufmann,San Mateo, CA, p. 146-149.McDonald, David D. (1992) "An Efficient Chart-basedAlgorithm for Partial Parsing of Unrestricted Texts" inProceedings of the 3rd Conference on Applied NaturalLanguage Processing, April 1-3, 1992, Trento, Italy,pp.
193-200.Pereira, F. & Schabes, E. (1992) "Inside-Outside Reestimationfrom Partially Bracketed Corpora" in Proceedings of theSpeech and Natural Language Workshop, February, 1992,Morgan Kaufmann, San Mateo, CA, p. 122-127.Pereira, F. & Wright, R. (1991) "Finite-state approximation fphrase structured grammars" Proceedings ofthe 29th AnnualMeeting of the Association for Computational Linguistics,June 18-21, 1991, Berkeley, California, pp.246-255.Placeway, P., Schwartz, S., Fung, P., & Nguyen, L., (1993)"Estimation of Powerful Language Models from Small andLarge Corpora", in Proceedings of International Conferenceof Acoustics, Speech, and Signal Processing (ICASSP).Rohlicek, R., Ayuso, D., Bates, M., Bobrow, R., Boulanger,A., Gish, H., Jeanrenaud, M., Meteer, M., Siu, M. (1992)"Gisting Conversational Speech" in Proceedings ofInternational Conference of Acoustics, Speech, and SignalProcessing (ICASSP), Mar.
23-26, 1992, Vol.2, pp.
113-116.Schabes, E. (1992) "Stochastic Tree-Adjoining Grammars" inProceedings of the Speech and Natural Language Workshop,February, 1992, Morgan Kaufmann, San Mateo, CA, p. 140-145.Weischedel, R., Ayuso, D., Bobrow, R., Boisen, S., Ingria,R., Palmucci, J.
(1991) "Partial Parsing: A report on workin progress" in Proceedings of the Speech and NaturalLanguage Workshop, February, Morgan Kaufmann, PacificGrove, CA, p. 204-209.233
