Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 33?40,New York City, June 2006. c?2006 Association for Computational LinguisticsA Priority Model for Named EntitiesLorraine Tanabe W. John WilburNational Center for BiotechnologyInformationNational Center for BiotechnologyInformationBethesda, MD 20894 Bethesda, MD 20894tanabe@ncbi.nlm.nih.gov wilbur@ncbi.nlm.nih.govAbstractWe introduce a new approach to namedentity classification which we term a Pri-ority Model.
We also describe the con-struction of a semantic database calledSemCat consisting of a large number ofsemantically categorized names relevantto biomedicine.
We used SemCat as train-ing data to investigate name classificationtechniques.
We generated a statistical lan-guage model and probabilistic context-free grammars for gene and protein nameclassification, and compared the resultswith the new model.
For all three meth-ods, we used a variable order Markovmodel to predict the nature of strings notrepresented in the training data.
The Pri-ority Model achieves an F-measure of0.958-0.960, consistently higher than thestatistical language model and probabilis-tic context-free grammar.1 IntroductionAutomatic recognition of gene and protein namesis a challenging first step towards text mining thebiomedical literature.
Advances in the area of geneand protein named entity recognition (NER) havebeen accelerated by freely available tagged corpora(Kim et al, 2003, Cohen et al, 2005, Smith et al,2005, Tanabe et al, 2005).
Such corpora havemade it possible for standardized evaluations suchas Task 1A of the first BioCreative Workshop(Yeh et al, 2005).Although state-of-the-art systems now performat the level of 80-83% F-measure, this is still wellbelow the range of 90-97% for non-biomedicalNER.
The main reasons for this performance dis-parity are 1) the complexity of the genetic nomen-clature and 2) the confusion of gene and proteinnames with other biomedical entities, as well aswith common English words.
In an effort to allevi-ate the confusion with other biomedical entities wehave assembled a database consisting of namedentities appearing in the literature of biomedicinetogether with information on their ontologicalcategories.
We use this information in an effort tobetter understand how to classify names as repre-senting genes/proteins or not.2 BackgroundA successful gene and protein NER system mustaddress the complexity and ambiguity inherent inthis domain.
Hand-crafted rules alone are unableto capture these phenomena in large biomedicaltext collections.
Most biomedical NER systemsuse some form of language modeling, consisting ofan observed sequence of words and a hidden se-quence of tags.
The goal is to find the tag se-quence with maximal probability given theobserved word sequence.
McDonald and Pereira(2005) use conditional random fields (CRF) toidentify the beginning, inside and outside of geneand protein names.
GuoDong et al (2005) use anensemble of one support vector machine and twoHidden Markov Models (HMMs).
Kinoshita et al(2005) use a second-order Markov model.
Dingareet al (2005) use a maximum entropy Markovmodel (MEMM) with large feature sets.33NER is a difficult task because it requires boththe identification of the boundaries of an entity intext, and the classification of that entity.
In thispaper, we focus on the classification step.
Spasicet al (2005) use the MaSTerClass case-based rea-soning system for biomedical term classification.MaSTerClass uses term contexts from an annotatedcorpus of 2072 MEDLINE abstracts related to nu-clear receptors as a basis for classifying newterms.
Its set of classes is a subset of the UMLSSemantic Network (McCray, 1989), that does notinclude genes and proteins.
Liu et al (2002) clas-sified terms that represent multiple UMLS con-cepts by examining the conceptual relatives of theconcepts.
Hatzivassiloglou et al (2001) classifiedterms known to belong to the classes Protein, Geneand/or RNA using unsupervised learning, achievingaccuracy rates up to 85%.
The AZuRE system(Podowski et al, 2004) uses a separate modifiedNaive Bayes model for each of 20K genes.
A termis disambiguated based on its contextual similarityto each model.
Nenadic et al (2003) recognizedthe importance of terminological knowledge forbiomedical text mining.
They used the C/NC-methods, calculating both the intrinsic characteris-tics of terms (such as their frequency of occurrenceas substrings of other terms), and the context ofterms as linear combinations.
These biomedicalclassification systems all rely on the context sur-rounding named entities.
While we recognize theimportance of context, we believe one must strivefor the appropriate blend of information comingfrom the context and information that is inherent inthe name itself.
This explains our focus on nameswithout context in this work.We believe one can improve gene and proteinentity classification by using more training dataand/or using a more appropriate model for names.Current sources of training data are deficient inimportant biomedical terminologies like cell linenames.
To address this deficiency, we constructedthe SemCat database, based on a subset of theUMLS Semantic Network enriched with categoriesfrom the GENIA Ontology (Kim et al 2003), and afew new semantic types.
We have populated Sem-Cat with over 5 million entities of interest fromFigure 1.
SemCat Physical Object Hierarchy.
White = UMLS SN, Light Grey = GENIA semantictypes, Dark Grey = New semantic types.34standard knowledge sources like the UMLS(Lindberg et al, 1993), the Gene Ontology (GO)(The Gene Ontology Consortium, 2000), EntrezGene (Maglott et al, 2005), and GENIA, as well asfrom the World Wide Web.
In this paper, we useSemCat data to compare three probabilistic frame-works for named entity classification.3 MethodsWe constructed the SemCat database of biomedicalentities, and used these entities to train and testthree probabilistic approaches to gene and proteinname classification: 1) a statistical language modelwith Witten-Bell smoothing, 2) probabilistic con-text-free grammars (PCFGs) and 3) a new ap-proach we call a Priority Model for named entities.As one component in all of our classification algo-rithms we use a variable order Markov Model forstrings.3.1 SemCat Database ConstructionThe UMLS Semantic Network (SN) is an ongoingproject at the National Library of Medicine.
Manyusers have modified the SN for their own researchdomains.
For example, Yu et al (1999) found thatthe SN was missing critical components in the ge-nomics domain, and added six new semantic typesincluding Protein Structure and Chemical Com-plex.
We found that a subset of the SN would besufficient for gene and protein name classification,and added some new semantic types for better cov-erage.
We shifted some semantic types fromsuboptimal nodes to ones that made more sensefrom a genomics standpoint.
For example, therewere two problems with Gene or Genome.
Firstly,genes and genomes are not synonymous, and sec-ondly, placement under the semantic type FullyFormed Anatomical Structure is suboptimal from agenomics perspective.
Since a gene in this contextis better understood as an organic chemical, wedeleted Gene or Genome, and added the GENIAsemantic types for genomics entities under Or-ganic Chemical.
The SemCat Physical Object hier-archy is shown in Figure 1.
Similar hierarchiesexist for the SN Conceptual Entity and Event trees.A number of the categories have been supple-mented with automatically extracted entities fromMEDLINE, derived from regular expression pat-tern matching.
Currently, SemCat has 77 semantictypes, and 5.11M non-unique entries.
Additionalentities from MEDLINE are being manually classi-fied via an annotation website.
Unlike the Ter-mino database (Harkema et al (2004), whichcontains terminology annotated with morpho-syntactic and conceptual information, SemCat cur-rently consists of gazetteer lists only.For our experiments, we generated two sets oftraining data from SemCat, Gene-Protein (GP) andNot-Gene-Protein (NGP).
GP consists of specificterms from the semantic types DNA MOLECULE,PROTEIN MOLECULE, DNA FAMILY,PROTEIN FAMILY, PROTEIN COMPLEX andPROTEIN SUBUNIT.
NGP consists of entitiesfrom all other SemCat types, along with genericentities from the GP semantic types.
Generic enti-ties were automatically eliminated from GP usingpattern matching to manually tagged genericphrases like abnormal protein, acid domain, andRNA.Many SemCat entries contain commas and pa-rentheses, for example, ?receptors, tgf beta.?
Abetter form for natural language processing wouldbe ?tgf beta receptors.?
To address this problem,we automatically generated variants of phrases inGP with commas and parentheses, and found theircounts in MEDLINE.
We empirically determinedthe heuristic rule of replacing the phrase with itssecond most frequent variant, based on the obser-vation that the most frequent variant is often toogeneric.
For example, the following are the phrasevariant counts for ?heat shock protein (dnaj)?:?
heat shock protein (dnaj) 0?
dnaj heat shock protein  84?
heat shock protein  122954?
heat shock protein dnaj  41Thus, the phrase kept for GP is dnaj heat shockprotein.After purifying the sets and removing ambigu-ous full phrases (ambiguous words were retained),GP contained 1,001,188 phrases, and NGP con-tained 2,964,271 phrases.
From these, we ran-domly generated three train/test divisions of 90%train/10% test (gp1, gp2, gp3), for the evaluation.3.2    Variable Order Markov Model for StringsAs one component in our classification algorithmswe use a variable order Markov Model for strings.Suppose C represents a class and 1 2 3... nx x x x  repre-35sents a string of characters.
In order to estimate theprobability that 1 2 3... nx x x x  belongs to  we applyBayes?
Theorem to writeC( ) ( ) ( )( )1 2 31 2 3 1 2 3... || ......nnnp x x x x C p Cp C x x x xp x x x x=      (1)Because ( )1 2 3... np x x x x does not depend on theclass and because we are generally comparingprobability estimates between classes, we ignorethis factor in our calculations and concentrate ourefforts on evaluating ( ) ( )1 2 3... |np x x x x C p C .First we write( ) (1 2 3 1 2 3 11... | | ... ,nn kkp x x x x C p x x x x x C?==?
)k)(2)which is an exact equality.
The final step is to giveour best approximation to each of the num-bers ( 1 2 3 1| ... ,k kp x x x x x C?
.
To make these ap-proximations we assume that we are given a set ofstrings and associated probabilities ( ){ } 1, Mi i is p =where for each i ,  and 0ip > ip  is assumed torepresent the probability that  belongs to theclass C .
Then for the given stringis1 2 3... nx x x x  anda given  we let  be the smallest integer forwhichk 1r ?1 2...r r r kx x x x+ +  is a contiguous substring inat least one of the strings .
Now let is N?
be theset of all i  for which 1 2...r r r kx x x x+ +  is a substringof  and let  be the set of all  for which is N i1 2... 1r r r kx x x x+ + ?
is a substring of .
We set is( )1 2 3 1| ... , ii Nk kii Npp x x x x x Cp???
?= ??
.
(3)In some cases it is appropriate to assume that( )p C  is proportional to 1M ii p=?
or there may beother ways to make this estimate.
This basicscheme works well, but we have found that we canobtain a modest improvement by adding a uniquestart character to the beginning of each string.
Thischaracter is assumed to occur nowhere else but asthe first character in all strings dealt with includingany string whose probability we are estimating.This forces the estimates of probabilities near thebeginnings of strings to come from estimates basedon the beginnings of strings.
We use this approachin all of our classification algorithms.Table 1.
Each fragment in the left column appears in thetraining data and the probability in the right columnrepresents the probability of seeing the underlined por-tion of the string given the occurrence of the initial un-underlined portion of the string in a training string.GP!apoe 79.55 10?
?oe-e 32.09 10?
?e-epsilon 24.00 10??
( )|p apoe epsilon GP?
117.98 10??
( )|p GP apoe epsilon?
0.98448NGP!apoe 88.88 10?
?poe- 21.21 10?
?oe-e 26.10 10?
?e-epsilon 36.49 10??
( )|p apoe epsilon NGP?
134.25 10??
( )|p NGP apoe epsilon?
0.01552In Table 1, we give an illustrative example ofthe string apoe-epsilon which does not appear inthe training data.
A PubMed search for apoe-epsilon gene returns 269 hits showing the name isknown.
But it does not appear in this exact form inSemCat.3.3   Language Model with Witten-Bell Smooth-ingA statistical n-gram model is challenged when abigram in the test set is absent from the trainingset, an unavoidable situation in natural languagedue to Zipf?s law.
Therefore, some method forassigning nonzero probability to novel n-grams isrequired.
For our language model (LM), we usedWitten-Bell smoothing, which reserves probabilitymass for out of vocabulary values (Witten andBell, 1991, Chen and Goodman, 1998).
The dis-counted probability is calculated as)...()...(#)...(#)...(?1111111?+??+?+??+?
+= iniiniiniini wwDwwwwwwP    (4)36where  is the number of distinctwords that can appear after in thetraining data.
Actual values assigned to tokens out-side the training data are not assigned uniformlybut are filled in using a variable order MarkovModel based on the strings seen in the trainingdata.)...
( 11 ?+?
ini wwD11... ?+?
ini ww3.4   Probabilistic Context-Free GrammarThe Probabilistic Context-Free Grammar(PCFG) or Stochastic Context-Free Grammar(SCFG) was originally formulated by Booth(1969).
For technical details we refer the reader toCharniak (1993).
For gene and protein name classi-fication, we tried two different approaches.
In thefirst PCFG method (PCFG-3), we used the follow-ing simple productions:1) CATP ?
CATP CATP2) CATP ?
CATP postCATP3) CATP ?
preCATP CATPCATP refers to the category of the phrase, GPor NGP.
The prefixes pre and post refer to begin-nings and endings of the respective strings.
Wetrained two separate grammars, one for the positiveexamples, GP, and one for the negative examples,NGP.
Test cases were tagged based on their scorefrom each of the two grammars.In the second PCFG method (PCFG-8), wecombined the positive and negative training exam-ples into one grammar.
The minimum number ofnon-terminals necessary to cover the training setsgp1-3 was six {CATP, preCATP, postCATP, Not-CATP, preNotCATP, postNotCATP}.
CATPrepresents a string from GP, and NotCATP repre-sents a string from NGP.
We used the followingproduction rules:1) CATP ?
CATP CATP2) CATP ?
CATP postCATP3) CATP ?
preCATP CATP4) CATP ?
NotCATP CATP5) NotCATP ?
NotCATP NotCATP6) NotCATP ?
NotCATP postNotCATP7) NotCATP?
preNotCATP NotCATP8) NotCATP ?
CATP NotCATPIt can be seen that (4) is necessary for strings like?human p53,?
and (8) covers strings like ?p53pathway.
?In order to deal with tokens that do not ap-pear in the training data we use variable orderMarkov Models for strings.
First the grammar istrained on the training set of names.
Then any to-ken appearing in the training data will have as-signed to it the tags appearing on the right side ofany rule of the grammar (essentially part-of-speechtags) with probabilities that are a product of thetraining.
We then construct a variable orderMarkov Model for each tag type based on the to-kens in the training data and the assigned prob-abilities for that tag type.
These Models (three forPCFG-3 and six for PCFG-8) are then used to as-sign the basic tags of the grammar to any token notseen in training.
In this way the grammars can beused to classify any name even if its tokens are notin the training data.3.5   Priority ModelThere are problems with the previous ap-proaches when applied to names.
For example,suppose one is dealing with the name ?human liveralkaline phosphatase?
and class  represents pro-tein names and class  anatomical names.
In thatcase a language model is no more likely to favorthan .
We have experimented with PCFGsand have found the biggest challenge to be how tochoose the grammar.
After a number of attemptswe have still found problems of the ?human liveralkaline phosphatase?
type to persist.1C2C1C 2CThe difficulties we have experienced with lan-guage models and PCFGs have led us to try a dif-ferent approach to model named entities.
As ageneral rule in a phrase representing a named en-tity a word to the right is more likely to be the headword or the word determining the nature of theentity than a word to the left.
We follow this ruleand construct a model which we will call a PriorityModel.
Let  be the set of training data (names)for class  and likewise  for .
Let1T1C 2T 2C { } At?
?
?denote the set of all tokens used in names con-tained in .
Then for each token 1T T?
2 ,  t A?
?
?
,we assume there are associated two probabilitiesp?
and q?
with the interpretation that p?
is the37probability that the appearance of the token t?
in aname indicates that name belongs to class  and 1Cq?
is the probability that t?
is a reliable indicatorof the class of a name.
Let  becomposed of the tokens on the right in the givenorder.
Then we compute the probability( ) ( ) ( )1 2 kn t t t?
?
?= ?
( ) ( ) ( )( ) ( ) ( ) ( )( )1 1 22 1 .| 1 1k kj i iijp C n p q q p q?
?
??
== == ?
+ ???
?k jj i ?+(5)This formula comes from a straightforward in-terpretation of priority in which we start on theright side of a name and compute the probabilitythe name belongs to class  stepwise.
If  isthe rightmost token we multiple the reliabilitytimes the significance1C ( )kt?
( )kq?
( )kp?
to obtain, which represents the contribution of.
The remaining or unused probability isand this is passed to the next token to theleft, .
The probability  is scaled bythe reliability and then the significance of( ) ( )k kq p?
?
( )kt?
( )1 kq??
( )1kt?
?
( )1 kq??
( )1kt?
?
toobtain , which is the contri-bution of  toward the probability that thename is of class .
The remaining probability isnow  and this is againpassed to the next token to the left, etc.
At the lasttoken on the left the reliability is not used to scalebecause there are no further tokens to the left andonly significance( ) ( ) ( )1(1 )k k kq q p?
?
???
1?)k?
( )1kt?
?1C( )( ) ( )(11 1kq q?
??
?
( )1p?
is used.We want to choose all the parameters p?
andq?
to maximize the probability of the data.
Thuswe seek to maximize( )( ) ( )( )1 21log | log 2 |n T n TF p C n p C n?
?= +?
?
.
(6)Because probabilities are restricted to be in theinterval [ ]0,1 , it is convenient to make a change ofvariables through the definitions,1 1x yxep qe e?
?ye?
??
?= =+ + .
(7)Then it is a simple exercise to show that( ) (1 ,  1dp dqp p q qdx dy?
?
)?
?
??
?= ?
= ?
?
.
(8)From (5), (6), and (8) it is straightforward to com-pute the gradient of  as a function of F x?
and y?and because of (8) it is most naturally expressed interms of p?
and q?
.
Before we carry out the op-timization one further step is important.
Let Bdenote the subset of A?
?
for which all the oc-currences of t?
either occur in names in  or alloccurrences occur in names in .
For any such1T2T ?we set 1q?
=  and if all occurrences of t?
are innames in   we set 1T 1p?
= , while if all occur-rences are in names in  we set .
Thesechoices are optimal and because of the form of (8)it is easily seen that2T 0p?
=0F Fx y?
??
?= =?
?
(9)for such an ?
.
Thus we may ignore all the B?
?in our optimization process because the values ofp?
and q?
are already set optimally.
We thereforecarry out optimization of  using the F,  ,  x y A?
?
B?
?
?
.
For the optimization we havehad good success using a Limited Memory BFGSmethod (Nash et al, 1991).When the optimization of  is complete wewill have estimates for all theFp?
and q?
, A?
?
.We still must deal with tokens t?
that are not in-cluded among the t?
.
For this purpose we trainvariable order Markov Models 1MP  based on theweighted set of strings ( ){ }, At p?
?
??
and 2MPbased on ( ){ },1 At p?
?
???
.
Likewise we train1MQ  based on ( ){ }, At q?
?
??
and 2MQ  based on( ){ },1 At q?
?
???
.
Then if we allow ( )imp t?
torepresent the prediction from model iMP  and ( )imq t?
that from model iMQ , we set38( )( ) ( )( )( ) ( )11 2 1 2,mp t mq tp qmp t mp t mq t mq t??
??
?
?= =+1 ?
?+(10)This allows us to apply the priority model toany name to predict its classification based onequation 5.4 ResultsWe ran all three methods on the SemCat sets gp1,gp2 and gp3.
Results are shown in Table 2.
Forevaluation we applied the standard informationretrieval measures precision, recall and F-measure._( _ _ )rel retprecisionrel ret non rel ret= + ?_( _ _ _ )rel retrecallrel ret rel not ret= +2* *( )precision recallF measureprecision recall?
= +For name classification, rel_ret refers to true posi-tive entities, non-rel_ret to false positive entitiesand rel_ not_ret to false negative entities.Table 2.
Three-fold cross validation results.
P = Preci-sion, R = Recall, F = F-measure.
PCFG = ProbabilisticContext-Free Grammar, LM = Bigram Model with Wit-ten-Bell smoothing,  PM = Priority Model.Method Run P R FPCFG-3 gp1 0.883 0.934 0.908gp2 0.882 0.937 0.909gp3 0.877 0.936 0.906PCFG-8 gp1 0.939 0.966 0.952gp2 0.938 0.967 0.952gp3 0.939 0.966 0.952LM gp1 0.920 0.968 0.944gp2 0.923 0.968 0.945gp3 0.917 0.971 0.943PM gp1 0.949 0.968 0.958gp2 0.950 0.968 0.960gp3 0.950 0.967 0.9585 DiscussionUsing a variable order Markov model for stringsimproved the results for all methods (results notshown).
The gp1-3 results are similar within eachmethod, yet it is clear that the overall performanceof these methods is PM > PCFG-8 > LM > PCFG-3.
The very large size of the database and the veryuniform results obtained over the three independ-ent random splits of the data support this conclu-sion.The improvement of PCFG-8 over PCFG-3 canbe attributed to the considerable ambiguity in thisdomain.
Since there are many cases of term over-lap in the training data, a grammar incorporatingsome of this ambiguity should outperform one thatdoes not.
In PCFG-8, additional production rulesallow phrases beginning as CATPs to be overallNotCATPs, and vice versa.The Priority Model outperformed all other meth-ods using F-measure.
This supports our impres-sion that the right-most words in a name should begiven higher priority when classifying names.
Adecrease in performance for the model is expectedwhen applying this model to the named entity ex-traction (NER) task, since the model is based onterminology alone and not on the surroundingnatural language text.
In our classification experi-ments, there is no context, so disambiguation is notan issue.
However, the application of our model toNER will require addressing this problem.SemCat has not been tested for accuracy, butwe retain a set of manually-assigned scores thatattest to the reliability of each contributing list ofterms.
Table 2 indicates that good results can beobtained even with noisy training data.6 ConclusionIn this paper, we have concentrated on the infor-mation inherent in gene and protein names versusother biomedical entities.
We have demonstratedthe utility of the SemCat database in training prob-abilistic methods for gene and protein entity classi-fication.
We have also introduced a new model fornamed entity prediction that prioritizes the contri-bution of words towards the right end of terms.The Priority Model shows promise in the domainof gene and protein name classification.
We planto apply the Priority Model, along with appropriatecontextual and meta-level information, to gene andprotein named entity recognition in future work.We intend to make SemCat freely available.39AcknowledgementsThis research was supported in part by the Intra-mural Research Program of the NIH, National Li-brary of Medicine.ReferencesT.
L. Booth.
1969.
Probabilistic representation of for-mal languages.
In:  IEEE Conference Record of the1969 Tenth Annual Symposium on Switching andAutomata Theory, 74-81.Stanley F. Chen and Joshua T. Goodman.
1998.
Anempirical study of smoothing techniques for lan-guage modeling.
Technical Report TR-10-98, Com-puter Science Group, Harvard University.Eugene Charniak.
1993.
Statistical Language Learn-ing.
The MIT Press,  Cambridge, Massachusetts.K.
Bretonnel Cohen, Lynne Fox, Philip V. Ogren andLawrence Hunter.
2005.
Corpus design for biomedi-cal natural language processing.
Proceedings of theACL-ISMB Workshop on Linking Biological Litera-ture, Ontologies and Databases, 38-45.The Gene Ontology Consortium.
2000.
Gene Ontology:tool for the unification of biology, Nat Genet.
25: 25-29.Henk Harkema, Robert Gaizauskas, Mark Hepple, An-gus Roberts, Ian Roberts, Neil Davis and Yikun Guo.2004.
A large scale terminology resource for bio-medical text processing.
Proc BioLINK 2004, 53-60.Vasileios Hatzivassiloglou, Pablo A. Dubou?
and An-drey Rzhetsky.
2001.
Disambiguating proteins,genes, and RNA in text: a machine learning ap-proach.
Bioinformatics 17 Suppl 1:S97-106.J.-D. Kim, Tomoko Ohta, Yuka Tateisi and Jun-ichiTsujii.
2003.
GENIA corpus--semantically annotatedcorpus for bio-textmining.
Bioinformatics 19 Suppl1:i180-2.Donald A. Lindberg, Betsy L. Humphreys and Alexa T.McCray.
1993.
The Unified Medical Language Sys-tem.
Methods Inf Med 32(4):281-91.Hongfang Liu, Stephen B. Johnson, and Carol Fried-man.
2002.
Automatic resolution of ambiguous termsbased on machine learning and conceptual relations inthe UMLS.
J Am Med Inform Assoc 9(6): 621?636.Donna Maglott, Jim Ostell, Kim D. Pruitt and TatianaTatusova.
2005.
Entrez Gene: gene-centered informa-tion at NCBI.
Nucleic Acids Res.
33:D54-8.Alexa T. McCray.
1989.
The UMLS semantic network.In: Kingsland LC (ed).
Proc 13rd Annu Symp Com-put Appl Med Care.
Washington, DC: IEEE Com-puter Society Press, 503-7.Ryan McDonald and Fernando Pereira.
2005.
Identify-ing gene and protein mentions in text using condi-tional random fields.
BMC Bioinformatics 6 Supp1:S6.S.
Nash and J. Nocedal.
1991.
A numerical study of thelimited memory BFGS method and the truncated-Newton method for large scale optimization, SIAM J.Optimization1(3): 358-372.Goran Nenadic, Irena Spasic and Sophia Ananiadou.2003.
Terminology-driven mining of biomedical lit-erature.
Bioinformatics 19:8, 938-943.Raf M. Podowski, John G. Cleary, Nicholas T. Gon-charoff, Gregory Amoutzias and William S. Hayes.2004.
AZuRE, a scalable system for automated termdisambiguation of gene and protein Names IEEEComputer Society Bioinformatics Conference, 415-424.Lawrence H. Smith, Lorraine Tanabe, Thomas C. Rind-flesch and W. John Wilbur.
2005.
MedTag: A collec-tion of biomedical annotations.
Proceedings of theACL-ISMB Workshop on Linking Biological Litera-ture, Ontologies and Databases, 32-37.Lorraine Tanabe, Natalie Xie, Lynne H. Thom, WayneMatten and W. John Wilbur.
2005.
GENETAG: atagged corpus for gene/protein named entity recogni-tion.
BMC Bioinformatics 6 Suppl 1:S3.I.
Witten and T. Bell, 1991.
The zero-frequency prob-lem:  Estimating the probabilities of novel events inadaptive text compression.
IEEE Transactions on In-formation Theory 37(4).Alexander Yeh, Alexander Morgan, Mark Colosimo andLynette Hirschman.
2005.
BioCreAtIvE Task 1A:gene mention finding evaluation.
BMC Bioinformat-ics 6 Suppl 1:S2.Hong Yu, Carol Friedman, Andrey Rhzetsky andPauline Kra.
1999.
Representing genomic knowledgein the UMLS semantic network.
Proc AMIA Symp.181-5.40
