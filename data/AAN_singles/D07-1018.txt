Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
171?180, Prague, June 2007. c?2007 Association for Computational LinguisticsModelling Polysemy in Adjective Classes by Multi-Label ClassificationGemma BoledaGLiComUniversitat Pompeu Fabra08003 Barcelonagemma.boleda@upf.eduSabine Schulte im WaldeIMSUniversity of Stuttgart70174 Stuttgartschulte@ims.uni-stuttgart.deToni BadiaGLiComUniversitat Pompeu Fabra08003 Barcelonatoni.badia@upf.eduAbstractThis paper assesses the role of multi-labelclassification in modelling polysemy for lan-guage acquisition tasks.
We focus on the ac-quisition of semantic classes for Catalan ad-jectives, and show that polysemy acquisitionnaturally suits architectures used for multi-label classification.
Furthermore, we ex-plore the performance of information drawnfrom different levels of linguistic descrip-tion, using feature sets based on morphol-ogy, syntax, semantics, and n-gram distribu-tion.
Finally, we demonstrate that ensembleclassifiers are a powerful and adequate wayto combine different types of linguistic ev-idence: a simple, majority voting ensembleclassifier improves the accuracy from 62.5%(best single classifier) to 84%.1 IntroductionThis paper reports on a series of experiments to ex-plore the automatic acquisition of semantic classesfor Catalan adjectives.
The most important chal-lenge of the classification task is to model the assign-ment of polysemous lexical instances to multiple se-mantic classes, combining a) a state-of-the-art Ma-chine Learning architecture for Multi-label Classi-fication (Schapire and Singer, 2000; Ghamrawi andMcCallum, 2005) and an Ensemble Classifier (Di-etterich, 2002) with b) the definition of features atvarious levels of linguistic description.A proper treatment of polysemy is essential in thearea of lexical acquisition, since polysemy repre-sents a pervasive phenomenon in natural language.However, previous approaches to the automatic ac-quisition of semantic classes have mostly disre-garded the problem (cf.
Merlo and Stevenson, 2001and Stevenson and Joanis, 2003 for English seman-tic verb classes, or Schulte im Walde, 2006 for Ger-man semantic verb classes).
There are a few excep-tions to this tradition, such as Pereira et al (1993),Rooth et al (1999), Korhonen et al (2003), whoused soft clustering methods for multiple assign-ment to verb semantic classes.Our work addresses the lack of methodology inmodelling a polysemous classification.
We imple-ment a multi-label classification architecture to han-dle polysemy.
This paper concentrates on the clas-sification of Catalan adjectives, but the general na-ture of the architecture should allow related tasks toprofit from our insights.As target classification for the experiments, a setof 210 Catalan adjectives was manually classified byexperts into three simple and three polysemous se-mantic classes.
We deliberately decided in favourof a small-scale, broad classification.
So far, thereis little work on the semantic classification of adjec-tives, as opposed to verbal semantic classification.The semantic classification we propose is a first stepin characterising adjectival meaning, and can be re-fined and extended in subsequent work.The experiments also provide a thorough compar-ison of feature sets based on different levels of lin-guistic description (morphology, syntax, semantics).A set of features is defined for each level of descrip-tion, and its performance is assessed within the se-ries of experiments.
An ensemble classifier comple-171ments the classification architecture, by optimisingthe combination of these different types of linguisticevidence.Our task is motivated by the fact that adjectivesplay an important role in sentential semantics: theyare crucial in determining the reference of NPs,and in defining properties of entities.
Even usingonly three different classes, the information acquiredcould be applied to, e.g., identify referents in a givencontext in Dialog or Question Answering systems,and to induce properties of objects within Informa-tion Extraction tasks.
Furthermore, with the seman-tic classes corresponding to broad sense representa-tions, they can be exploited for Word Sense Disam-biguation.The remainder of this paper is organised as fol-lows.
Section 2 provides background on Catalan ad-jectives, and Section 3 presents the Gold Standardclassification.
Section 4 introduces the methodologyof the multi-label classification experiments, Sec-tion 5 discusses the results, and the improved en-semble classifier is presented in Section 6.2 Catalan adjective classesThe definition and characterisation of our target se-mantic classification follows the proposal by Raskinand Nirenburg (1998) within the framework of On-tological Semantics(Nirenburg and Raskin, 2004).In Ontological Semantics, an ontology of conceptsmodelling the world is explicitly defined, and thesemantics of words are mapped onto elements ofthe ontology.
The classification pursued in this pa-per is drawn up based on the ontological sort of ad-jectival denotation: all adjectives denote properties,but these properties can be instantiated as simple at-tributes (basic adjectives), relationships to objects(object-related adjectives), or relationships to events(event-related adjectives).Basic adjectives are the prototypical adjectiveswhich denote attributes or properties and cannot bedecomposed further (such as bonic ?beautiful?, gran?big?).
In Ontological Semantics, these adjectivesare mapped to concepts of type attribute.
For in-stance, the semantics of the adjective gran specifiesa mapping to the size-attribute element in the onto-logy.
As for event-related adjectives, they have anevent component in their meaning and are thereforemapped onto event concepts in the ontology.
Forinstance, the semantics of tangible (?tangible?)
in-cludes a pointer to the event element touch in theontology.
Similarly, object-related adjectives aremapped onto object concepts in the ontology: defor-maci?
nasal (?nasal deformity?)
can be paraphrasedas deformity that affects the nose, so nasal evokesthe object nose.The semantic distinctions are mirrored at sev-eral levels of linguistic description, such as mor-phology, syntax, and semantics.
For instance, thereis a clear relationship between morphological typeand semantic class: basic adjectives are typicallynon-derived, object adjectives tend to be denomi-nal, and event adjectives are usually deverbal.
Thisis the default mapping that one expects from themorphology-semantics interface.
As an example forsyntactic evidence, basic adjectives in Catalan canbe used non-restrictively (in a pre-nominal position)and also predicatively, while object adjectives typi-cally cannot.However, the correspondences between the lin-guistic properties and the semantic classes are notone-to-one mappings.
Taking the morphological le-vel as an example, some denominal adjectives arebasic (such as vergony?s ?shy?, from vergonya ?shy-ness?).
Conversely, some object adjectives are notsynchronically denominal (such as bot?nic ?botan-ical?
), and some deverbal adjectives are not event-related, such as amable (lit.
?suitable to be loved?
;has evolved to ?kind, friendly?).
In such cases, thesemantic class can be better traced in the distribu-tional properties, not the morphological propertiesof the adjective.The proposed classification accounts for somecases of adjectival polysemy.
For instance, familiarhas an object reading (related to the Catalan nounfor ?family?
), and a basic reading (corresponding tothe English adjective ?familiar?
):(1) reuni?meetingfamiliarfamiliar//carafacefamiliarfamiliar?family meeting / familiar face?Similarly, the participial adjective sabut(?known?)
has an event-related sense, corre-sponding to the verb saber (?know?
), and a basicsense equivalent to ?wise?
:172(2) conseq?
?nciaconsequencesabudaknown//homemansabutwise?known consequence / wise man?The polysemy between our proposed classes, asexemplified in (1) and (2), is the kind of polysemywe aim to model in the acquisition experiments re-ported in this paper.3 Gold Standard classesAs a Gold Standard for the experiments to fol-low, 210 Catalan adjectives were classified by threeexperts.
The adjectives were randomly sampledfrom an adjective database (Sanrom?, 2003), bal-ancing three factors of variability: frequency, mor-phological type, and suffix.
An equal number ofadjectives was chosen from three frequency bands(low, medium, high), from four derivational types(denominal, deverbal, non-derived, participle), andfrom a series of suffixes within each type.
Thederivational type and suffix of each adjective wereavailable in the adjective database, and had beenmanually encoded.Three experts assigned the 210 lemmata to oneout of six classes: each adjective was tagged as ba-sic (B), event (E), object (O), or as polysemous be-tween basic and event (BE), between basic and ob-ject (BO), or between event and object (EO).
Thedecisions were reached by consensus.
The distribu-tion of the Gold Standard material across classes isshown in the last column of Table 6 (Section 5.2).In the acquisition experiments, our aim is to auto-matically assign a class to each adjective that can besimple (B, E, O) or complex (BE, BO, EO), in caseof polysemy.4 Classification methodAdjective classification was performed within a two-level architecture for multi-label classification: first,make a binary decision on each of the classes, andthen combine the classifications to achieve a final,multi-label classification.
We therefore decomposedthe global decision on the (possibly polysemous)class of an adjective into three binary decisions: Is itbasic or not?
Is it event-related or not?
Is it object-related or not?
The individual decisions were thencombined into an overall classification that includedpolysemy.
For example, if a lemma was classifiedboth as basic and as object in each of the binary de-cisions, it was deemed polysemous (BO).
The mo-tivation behind this approach was that polysemousadjectives should exhibit properties of all the classesinvolved.
As a result, positive decisions on each bi-nary classification can be made by the algorithm,which can be viewed as implicit polysemous assign-ments.This classification architecture is very popu-lar in Machine Learning for multi-label problems,cf.
(Schapire and Singer, 2000; Ghamrawi and Mc-Callum, 2005), and has also been applied to NLPproblems such as entity extraction and noun-phrasechunking (McDonald et al, 2005).
The remainder ofthis section describes other methodological aspectsof our experiments.4.1 Classifier: Decision TreesAs classifier for the binary decisions we chose De-cision Trees, one of the most widely used Ma-chine Learning techniques for supervised experi-ments (Witten and Frank, 2005).
Decision Treesprovide a transparent representation of the decisionsmade by the algorithm, and thus facilitate the in-spection of results and the error analysis.
The ex-periments were carried out with the freely availableWeka software package.
The particular algorithmchosen, Weka?s J48, is the latest open source ver-sion of C4.5 (Quinlan, 1993).
For an explanation ofdecision tree induction and C4.5, see Quinlan (1993)and Witten and Frank (2005, Sections 4.3 and 6.1).4.2 Feature definitionFive levels of linguistic description, formalised asdifferent feature sets, were chosen for our task.
Theyincluded evidence from morphology (morph), syn-tax (func, uni, bi), semantics (sem), plus a combi-nation of the five levels (all).
Table 1 lists the lin-guistic levels, their explanations, and the number offeatures used on each level.1 Morphological fea-tures (morph) encode the derivational type (denomi-nal, deverbal, participial, non-derived) and the suffix(in case the adjective is derived) of each adjective,and correspond to the manually encoded informa-1In level all, different features were used for each of thethree classes.
Table 1 reports the mean number of featuresacross the three classes.173Level Explanation # Featuresmorph morphological (derivational) properties 2func syntactic function 4uni uni-gram distribution 24bi bi-gram distribution 50sem distributional cues of semantic properties 18all combination of the 5 linguistic levels 10.3Table 1: Linguistic levels as feature sets.tion from the adjective database.
Syntactic and se-mantic features encode distributional properties ofadjectives.
Syntactic features comprise three sub-types: (i) the syntactic function (level func) of theadjective, as assigned by a shallow Constraint Gram-mar (Alsina et al, 2002), distinguishing the modifier(pre-nominal or post-nominal) and predicative func-tions; (ii) a unigram distribution (level uni), inde-pendently encoding the parts of speech (POS) of thewords preceding and following the adjective, respec-tively; and (iii) a bigram distribution (level bi), thePOS bigram around the target adjective, consideringonly the 50 most frequent bigrams to avoid sparsefeatures.
Semantic features (level sem) expand syn-tactic features with heterogeneous shallow cues ofsemantic properties.
Table 2 lists the semantic prop-erties encoded in the features, as well as the numberof heuristic cues defined for each property.
As anexample, one of the shallow cues used for gradabil-ity was the presence of degree adverbs (m?s ?more?,menys ?less?)
to the left of the target adjectives.
Thelast set of features, all, combines features from alllevels of description.
However, it does not containall features, but a selection of the most relevant ones(further details in Section 4.3).property #non-restrictivity 1predicativity 4gradability 4syntactic function of head noun 3distance to the head noun 1binaryhood (adjectives with two arguments) 1agreement properties 2Table 2: Semantic features.4.3 Feature selectionIrrelevant features typically decrease performanceby 5 to 10% when using Decision Trees (Witten andFrank, 2005, p. 288).
We therefore applied a fea-ture selection algorithm.
We chose a feature selec-tion method available in Weka (WrapperSubsetEval)that selects a subset of the features according to itsperformance within the Machine Learning algorithmused for classification.
Accuracy for a given sub-set of features is estimated by cross-validation overthe training data.
Because the number of subsets in-creases exponentially with the number of features,this method is computationally very expensive, andwe used a best-first search strategy to alleviate thisproblem.We additionally used the feature selection pro-cedure to select the features for level all: for eachclass, we used only those features that were selectedby the feature selection algorithm in at least 30% ofthe experiments.4.4 Differences across linguistic levelsOne of our goals was to test the strengths and weak-nesses of each level of linguistic description for thetask of adjective classification.
This was done bycomparing the accuracy results obtained with eachof the feature sets in the Machine Learning experi-ments.
Following a standard procedure in MachineLearning, we created several partitions of the data toobtain different estimates of the accuracy of each ofthe levels, so as to be able to perform a significancetest on the differences in accuracy.
We performed10 experiments with 10-fold cross-validation (10x10cv for short), so that for each class 100 different bi-nary decisions were made for each adjective.
For thecomparison of accuracies, a standard paired t-testcould not be used, because of the inflated Type I er-174ror probability when reusing data (Dietterich, 1998).Instead, we used the corrected resampled t-test asproposed by Nadeau and Bengio (2003).25 Classification results5.1 Accuracy resultsThe accuracy results for each of the binary deci-sions (basic/non-basic, event/non-event, object/non-object) are depicted in Table 3.3 Level bl corre-sponds to the baseline: the baseline accuracy wasdetermined by assigning all lemmata to the most fre-quent class.
The remaining levels follow the nomen-clature in Table 1 above.
Each column contains themean and the standard deviation (marked by ?)
ofthe accuracy for the relevant level of informationover the 100 results obtained with 10x10 cv.Basic Event Objectbl 65.2 ?11.1 76.2 ?9.9 71.9 ?9.6morph 72.5 ?7.9 89.1 ?6.0 84.2 ?7.5func 73.6 ?9.3 76.0 ?9.3 81.7 ?7.4uni 66.1 ?9.4 75.1 ?10.6 82.2 ?7.5bi 67.4 ?10.6 72.3 ?10.2 83.0 ?8.3sem 72.8 ?9.0 73.8 ?9.6 82.3 ?8.0all 75.3 ?7.6 89.4 ?5.7 85.4 ?8.7Table 3: Accuracy results for binary decisions.As one might have expected, the best results wereobtained with the all level (bold faced in Table 3),which is the combination of all feature types.
Thislevel achieved a mean improvement of 12.3% overthe baseline.
The differences in accuracy resultsbetween most levels of information were, however,rather small.
For the object class, all levels exceptfor func and uni achieved a significant improvementover the baseline.
For the basic class, no improve-2Note that the corrected resampled t-test can only compareaccuracies obtained under two conditions (algorithms or, as isour case, feature sets); ANOVA would be more adequate.
Inthe field of Machine Learning, there is no established correc-tion for ANOVA for the purposes of testing differences in ac-curacy (Bouckaert, 2004).
Therefore, we used multiple t-testsinstead, which increases the overall error probability of the re-sults for the significance tests.3The accuracy for each decision was computed indepen-dently.
For instance, a BE adjective was judged correct withinthe basic class iff the decision was basic; correct within theevent class iff the decision was event; and correct within theobject class iff the decision was non-object.ment over the baseline was significant according tothe corrected resampled t-test.
And for the eventclass, only levels morph and all offered a significantimprovement in accuracy; the remaining levels evenobtained a slightly lower accuracy score.These results concern the three individual binarydecisions.
However, our goal was not to obtain threeseparate decisions, but a single classification includ-ing polysemy.
Table 4 shows the accuracy results forthe classification obtained by combining the threeindividual decisions for each adjective.
We reporttwo accuracy measures, full and partial: full ac-curacy required the class assignments to be identi-cal; partial accuracy only required some overlap inthe classification of the Machine Learning algorithmand the Gold Standard for a given class assignment.The motivation for calculating partial overlap wasthat a class assignment with some overlap with theGold Standard (even if they were not identical) isgenerally more useful than a class assignment withno overlap.Full Partialbl 51.0 ?0.0 65.2 ?0.0morph 60.6 ?1.3 87.8 ?0.4func 53.5 ?1.8 79.8 ?1.3uni 52.3 ?1.7 76.7 ?1.0bi 52.9 ?1.9 76.9 ?1.8sem 52.0 ?1.3 78.7 ?1.7all 62.3 ?2.3 90.7 ?1.6Table 4: Accuracy results for combined decisions.Again, the best results were obtained with the alllevel.
The second best results were obtained withlevel morph.
These results could have been expectedfrom the results obtained by the individual decisions(Table 3); however, note that the differences betweenthe various levels are much clearer in the combinedclassification than in the individual binary decisions.Table 5 shows the two-by-two comparisons of theaccuracy scores.
Each cell contains the difference inaccuracy means between two levels of description,as well as the level of significance of the difference.The significance is marked as follows: * for p <0.05, ** for p < 0.01, *** for p < 0.001.
If noasterisk is shown, the difference was not significant.Under the strictest evaluation condition (full accu-175agreement level bl morph func uni bi semfullmorph 9.7***func 2.5* -7.1***uni 1.4 -8.3*** -1.1bi 2.0 -7.7*** -0.6 0.6sem 1.0 -8.7*** -1.5 -0.4 1.0all 11.4*** 1.7 8.9*** 10.0*** 9.4*** 10.4***partialmorph -22.6***func 14.6*** -8.0***uni 11.4*** -11.1*** -3.1**bi 11.7*** -10.9*** -2.9** 0.2sem 13.4*** -9.1*** -1.1 2.0 1.8all 25.4*** 2.9* 10.9*** 14.0*** 13.8*** 12.0***Table 5: Comparison of accuracy scores across linguistic levels.racy), only levels morph, func, and all significantlyimproved upon the baseline.
Levels morph and allare better than the remaining levels, to a similar ex-tent.
In the partial evaluation condition, all levelsachieved a highly significant improvement over thebaseline (p < 0.001).
Therefore, the classificationsobtained with any of the feature levels are more use-ful than the baseline, in the sense that they presentmore overlap with the Gold Standard.The best result obtained for the full classifica-tion of adjectives with our methodology achieved amean of 62.3% (full accuracy) or 90.7% (partial ac-curacy), which represents an improvement of 11.3%and 25.5% over the baselines, respectively.
Levelsincluding morphological information were clearlysuperior to levels using only distributional informa-tion.These results suggest that morphology is the bestsingle source of evidence for our task.
However, re-call from Section 3 that the sampling procedure forthe Gold Standard explicitly balanced for morpho-logical factors.
As a result, denominal and particip-ial adjectives are underrepresented in the Gold Stan-dard, while non-derived and deverbal adjectives areoverrepresented.
Moreover, previous experimentson different datasets (Boleda et al, 2004; Boleda etal., 2005) provided some evidence that distributionalinformation outperforms morphological informationfor our task.
Therefore, we cannot conclude fromthe experiments that morphological features are themost important information for the classification ofCatalan adjectives in general.5.2 Error analysisThe error analysis focuses on the two best fea-ture sets, morph and all.
Table 6 compares the er-rors made by the experiment classifications (basedon the two sets of features) against the Gold Stan-dard classification.
To obtain a unique experimentclassification for each feature level in this compar-ison, we applied majority voting across the 10 dif-ferent classifications obtained in the 10 experimentruns for each of the linguistic levels.
The table rowscorrespond to the Gold Standard classification andthe columns correspond to the experiment classifi-cations with the feature levels all and morph, re-spectively.
The matches (the diagonal elements)are in italics, and off-diagonal cells representing thelargest numbers of mismatches are boldfaced.
Theoverall number of mistakes made by both levels withmajority voting is almost the same: 86 (morph) vs.89 (all).
However, the mismatches are qualitativelyquite different.Level morph uniformly mapped denominal adjec-tives to both basic and object (BO).
Because of thisovergeneration of BOs, 31 lemmata that were taggedas either basic or object in the Gold Standard wereassigned to BO.
In contrast, level all was overly dis-criminative: most of the BO cases (16 out of 23), aswell as 16 object adjectives, were assigned to basic.This type of confusion could be explained by the factthat some non-prototypical basic adjectives were as-176all morphB BE BO E EO O B BE BO E EO O TotalGSB 94 12 0 0 1 0 82 2 10 11 2 0 107BE 1 6 0 0 0 0 0 1 0 6 0 0 7BO 16 1 5 1 0 0 5 0 16 2 0 0 23E 5 23 1 7 1 0 4 7 0 25 1 0 37EO 0 2 0 0 4 0 0 0 0 6 0 0 6O 16 1 6 2 0 5 6 0 21 3 0 0 30Total 132 45 12 10 6 5 97 10 47 53 3 0 210Table 6: Levels all and morph against the Gold Standard.signed to the basic class in the Gold Standard, be-cause they did not fit the narrower definitions of theevent and object classes, but these adjectives do notbehave like typical basic adjectives.As for event adjectives, the morph level assignedalmost all deverbal adjectives to the event class,which worked well in most cases (26).
However,this mapping cannot distinguish deverbal adjectiveswith a basic meaning (11 basic and 6 BE adjectivesin the Gold Standard).
Level all, including morpho-logical and distributional cues, also shows difficul-ties with the event class, but of a different nature.Feature examination showed that the distributionaldifferences between basic and event adjectives arenot robust.
For instance, according to t-tests per-formed on the Gold Standard (?
= 0.05), only threeof the 18 semantic features exhibit significant meandifferences for classes basic and event.
In contrast,ANOVA across the 6 classes (?
= 0.05) yields signif-icant differences for 16 out of the 18 features, whichindicates that most features serve to distinguish ob-ject adjectives from basic and event adjectives.
As aresult of the lack of robust distributional differencesbetween basic and event adjectives, 35 basic or eventadjectives were classified as BE when using the alllevel as feature set.Further 23 event adjectives were incorrectly clas-sified as BE by the all level, but correctly classi-fied by the morph level, because they are deverbaladjectives.
These cases involved adjectives derivedfrom stative verbs, such as abundant (?abundant?)
orpreferible (?preferable?).
Feature analysis revealedthat deverbal adjectives derived from stative verbsare more similar to basic adjectives than those de-rived from process-denoting verbs.To sum up, the default morphological mappingmentioned in Section 2 works well in most casesbut has a clear ceiling, as it cannot account for de-viations from the expected mapping.
Distributionalcues are more sensitive to these deviations, but failmostly in the distinction between basic and event,because the differences in syntactic distribution be-tween these classes are not robust.6 An improved classifierThe error analysis in the previous section has shownthat, although the number of mistakes made with le-vel morph and all is comparable, the kinds of mis-takes are qualitatively very different.
This suggeststhat mixing features for the construction of a sin-gle Decision Tree, as is done in level all, is not theoptimal way to combine the strengths of each le-vel of description.
An alternative combination canbe achieved with an ensemble classifier, a type ofclassifier that has received much attention in the Ma-chine Learning community in the last decade (Diet-terich, 2002).
When building an ensemble classifier,several class proposals for each item are obtained,and one of them is chosen on the basis of majorityvoting, weighted voting, or more sophisticated deci-sion methods.
It has been shown that in most cases,the accuracy of the ensemble classifier is higher thanthe best individual classifier (Freund and Schapire,1996; Dietterich, 2000; Breiman, 2001).
WithinNLP, ensemble classifiers have been applied, for in-stance, to genus term disambiguation in machine-readable dictionaries (Rigau et al, 1997), using amajority voting scheme upon several heuristics, andto part of speech tagging, by combining the classpredictions of different algorithms (van Halteren et177Levels Full Ac.
Part.
Ac.morph+func+uni+bi+sem+all 84.0 ?0.06 95.7 ?0.02func+uni+bi+sem 81.5 ?0.04 95.9 ?0.01morph+func+sem+all 72.4 ?0.03 89.3 ?0.02bl 51.0 ?0.0 65.2 ?0.0all 62.3 ?2.3 90.7 ?1.6Table 7: Results for ensemble classifier.al., 1998).
The main reason for the general successof ensemble classifiers is that they gloss over the bi-ases introduced by the individual systems.We implemented an ensemble classifier by usingthe different levels of description as different subsetsof features, and applying majority voting across theclass proposals from each level.
Intuitively, this ar-chitecture is analogous to having a team of linguistsand NLP engineers, each contributing their knowl-edge on morphology, n-gram distribution, syntacticproperties, etc., and have them reach a consensusclassification.
We thus established a different classi-fication for each of the 10 cross-validation runs byassigning each adjective to the class that receivedmost votes.
To enable a majority vote, at least threelevels have to be combined.
Table 7 contains a rep-resentative selection of the combinations, togetherwith their accuracies.
Also, the accuracies obtainedwith the baseline (bl) and the best single level (all)are included for comparison.In any of the combinations tested, accuracy im-proved over 10% with respect to the all level.
Thebest result, a mean of 84% (full accuracy), was ob-tained by combining all levels of description.
Theseresults represent a raw improvement over the base-line of 33%, and 21.7% over the best single classi-fier.
Also note that with this procedure 95.7% of theclassifications obtained with the ensemble classifierpresent partial overlap with the class assignments inthe Gold Standard.These results show that the combination of differ-ent sources of linguistic evidence is more importantthan the type of information used.
As an example,consider the second ensemble classifier in Table 7:this classifier excludes the two levels that containmorphological information (morph and all), whichrepresents the most successful individual source ofinformation for our dataset.
Nevertheless, the com-bination achieved 19.2/20.9% more accuracy thanlevels all and morph, respectively.7 Related workAdjectives have received less attention than verbsand nouns within Lexical Acquisition.
Work byHatzivassiloglou and colleagues (Hatzivassiloglouand McKeown, 1993; Hatzivassiloglou and McKe-own, 1997; Hatzivassiloglou and Wiebe, 2000) usedclustering methods to automatically identify adjecti-val scales from corpora.Coordination information was used in Bohnet etal.
(2002) for a classification task similar to the taskwe pursue, using a bootstrapping approach.
Theauthors, however, pursued a classification that isnot purely semantic, between quantitative adjectives(similar to determiners, like viele ?many?
), referen-tial adjectives (heutige, ?of today?
), qualitative ad-jectives (equivalent to basic adjectives), classifica-tory adjectives (equivalent to object adjectives), andadjectives of origin (Stuttgarter, ?from Stuttgart?
).In a recent paper, Yallop et al (2005) reportedexperiments on the acquisition of syntactic subcat-egorisation patterns for English adjectives.Apart from the above research with a classifica-tory flavour, other lines of research exploited lexi-cal relations among adjectives for Word Sense Dis-ambiguation (Justeson and Katz, 1995; Chao andDyer, 2000).
Work by Lapata (2001), contrary tothe studies mentioned so far, focused on the mean-ing of adjective-noun combinations, not on that ofadjectives alone.8 ConclusionThis paper has presented an architecture for the se-mantic classification of Catalan adjectives that ex-plicitly includes polysemous classes.
The focus ofthe architecture was on two issues: (i) finding an ap-propriate set of linguistic features, and (ii) definingan adequate architecture for the task.
The investiga-tion and comparison of features at various linguis-tic levels has shown that morphology plays a majorrole for the target classification, despite the caveatsraised in the discussion.
Morphological features re-lated to derivational processes are among the sim-plest types of features to extract, so that the approachcan be straightforwardly extended to languages sim-ilar to Catalan with no extensive need of resources.178Furthermore, we have argued that polysemy ac-quisition naturally suits multi-label classification ar-chitectures.
We have implemented a standard archi-tecture for this class of problems, and demonstratedits applicability and success.
The general nature ofthe architecture should be useful for related tasksthat involve polysemy within the area of automaticlexical acquisition.Our work has focused on a broad classificationof the adjectives, similarly to Merlo and Stevenson(2001), who classified transitive English verbs intothree semantic classes.
The small number of classesmight be considered as an over-simplification of ad-jective semantics, but the simplified setup facilitatesa detailed qualitative evaluation.
In addition, asthere has been virtually no work on the acquisitionof semantic classes for adjectives, it seems sensibleto start with a small number of classes and incre-mentally build upon that.
Previous work has demon-strated that multi-label classification is applicablealso to a large number of classes as used in, e.g., doc-ument categorisation (Schapire and Singer, 2000).This potential can be exploited in future work, ad-dressing a finer-grained adjective classification.Finally, we have demonstrated that the combina-tion of different types of linguistic evidence booststhe performance of the system beyond the best singletype of information: ensemble classifiers are a moreadequate way to combine the linguistic levels of de-scription than simply merging all features for treeconstruction.
Using a simple, majority voting en-semble classifier, the accuracy jumped from 62.5%(best single classifier) to 84%.
This result is im-pressive by itself, and also in comparison to similarwork such as (Rigau et al, 1997), who achieved a9% improvement on a similar task.
Our insights aretherefore useful in related work which involves theselection of linguistic features in Machine Learningexperiments.Future work involves three main lines of re-search.
First, the refinement of the classificationitself, based on the results of the experiments pre-sented.
Second, the use of additional linguistic ev-idence that contributes to the semantic class dis-tinctions (e.g., selectional restrictions).
Third, theapplication of the acquired information to broaderNLP tasks.
For example, given that each semanticclass exhibits a particular syntactic behaviour, infor-mation on the semantic class should improve POS-tagging for adjective-noun and adjective-participleambiguities, probably the most difficult distinctionsboth for humans and computers (Marcus et al, 1993;Brants, 2000).
Also, semantic classes might be use-ful in terminology extraction, where, presumably,object adjectives participate in terms more often thanbasic adjectives.4AcknowledgementsWe thank Roser Sanrom?
for providing us with themanually annotated database of adjectives, and forbeing part of the Gold Standard annotation commit-tee.
Special thanks also to the Institut d?EstudisCatalans for proding us with the research corpus.The comments of three anonymous reviewers helpedimprove the paper.
Finally, the financial supportof the Universitat Pompeu Fabra and its Translationand Philology Department and the Fundaci?n CajaMadrid is gratefully acknowledged.References?.
Alsina, T. Badia, G. Boleda, S. Bott, ?.
Gil,M.
Quixal, and O. Valent?n.
2002.
CATCG: a generalpurpose parsing tool applied.
In Proceedings of ThirdInternational Conference on Language Resources andEvaluation (LREC-02), Las Palmas, Spain.B.
Bohnet, S. Klatt, and L. Wanner.
2002.
An approachto automatic annotation of functional information toadjectives with an application to German.
In Proceed-ings of the LREC Workshop on Linguistic KnowledgeAcquisition and Representation, Las Palmas, Spain.G.
Boleda, T. Badia, and E. Batlle.
2004.
Acquisitionof semantic classes for adjectives from distributionalevidence.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COLING2004), pages 1119?1125, Geneva, Switzerland.G.
Boleda, T. Badia, and S. Schulte im Walde.
2005.Morphology vs. syntax in adjective class acquisition.In Proceedings of the ACL-SIGLEX 2005 Workshopon Deep Lexical Acquisition, pages 1119?1125, AnnArbor, USA.R.
Bouckaert.
2004.
Estimating replicability of classifierlearning experiments.
In Proceedings of ICML.T.
Brants.
2000.
Inter-annotator agreement for a germannewspaper corpus.
In Second International Confer-ence on Language Resources and Evaluation (LREC-2000), Athens, Greece.4Horacio Rodr?guez, p. c., April 2007.179L.
Breiman.
2001.
Random forests.
Mach.
Learn., 45:5?23.G.
Chao and M. G. Dyer.
2000.
Word sense disambigua-tion of adjectives using probabilistic networks.
In Pro-ceedings of COLING, pages 152?158.T.G.
Dietterich.
1998.
Approximate statistical testsfor comparing supervised classification learning algo-rithms.
Neural Computation, 10(7):1895?1924.T.G.
Dietterich.
2000.
An experimental comparison ofthree methods for constructing ensembles of decisiontrees: Bagging, boosting, and randomization.
Mach.Learn., 40:5?23.T.G.
Dietterich.
2002.
Ensemble learning.
In M. A. Ar-bib, editor, The Handbook of Brain Theory and NeuralNetworks.
The MIT Press.Y.
Freund and R.E.
Schapire.
1996.
Experiments witha new boosting algorithm.
In Proceedings of ICML,pages 148?156.N.
Ghamrawi and A. McCallum.
2005.
Collective multi-label classification.
In Proceedings of 14th Conf.
onInformation and Knowledge Management.V.
Hatzivassiloglou and K. R. McKeown.
1993.
Towardsthe automatic identification of adjectival scales: Clus-tering adjectives according to meaning.
In Proceed-ings of ACL, pages 172?182.V.
Hatzivassiloglou and K.R.
McKeown.
1997.
Predict-ing the semantic orientation of adjectives.
In Proceed-ings of ACL/EACL, pages 174?181.V.
Hatzivassiloglou and J. M. Wiebe.
2000.
Effects ofadjective orientation and gradability on sentence sub-jectivity.
In Proceedings of COLING, pages 299?305,Morristown, NJ, USA.
Association for ComputationalLinguistics.J.
S. Justeson and S. M. Katz.
1995.
Principled disam-biguation: Discriminating adjective senses with modi-fied nouns.
Computational Linguistics, 21(1):1?27.A.
Korhonen, Y. Krymolowski, and Z. Marx.
2003.Clustering polysemic subcategorization frame distri-butions semantically.
In Proceedings of ACL, pages64?71.M.
Lapata.
2001.
A corpus-based account of regularpolysemy: The case of context-sensitive adjectives.
InProceedings of NAACL.M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: ThePenn Treebank.
Computational Linguistics, 19:313?330.R.
McDonald, K. Crammer, and F. Pereira.
2005.
Flexi-ble text segmentation with structured multilabel classi-fication.
In Proceedings of HLT-EMNLP, pages 987?994.P.
Merlo and S. Stevenson.
2001.
Automatic verb clas-sification based on statistical distributions of argumentstructure.
Comp.
Ling., 27(3):373?408.C.
Nadeau and Y. Bengio.
2003.
Inference for the gener-alization error.
Mach.
Learn., 52(3):239?281.S.
Nirenburg and V. Raskin.
2004.
Ontological Seman-tics.
MIT Press.F.
Pereira, N. Tishby, and L. Lee.
1993.
DistributionalClustering of English Words.
In Proceedings of ACL,pages 183?190.R.
Quinlan.
1993.
C4.5: Programs for Machine Learn-ing.
Morgan Kaufmann.V.
Raskin and S. Nirenburg.
1998.
An applied ontologi-cal semantic microtheory of adjective meaning for nat-ural language processing.
Mach.
Trans., 13(2-3):135?227.G.
Rigau, J. Atserias, and E. Agirre.
1997.
Combin-ing unsupervised lexical knowledge methods for wordsense disambiguation.
In Proceedings of EACL, pages48?55.M.
Rooth, S. Riezler, D. Prescher, G. Carroll, and F. Beil.1999.
Inducing a Semantically Annotated Lexicon viaEM-Based Clustering.
In Proceedings of ACL.R.
Sanrom?.
2003.
Aspectes morfol?gics i sint?ctics delsadjectius en catal?.
Master?s thesis, Universitat Pom-peu Fabra.R.E.
Schapire and Y.
Singer.
2000.
Boostexter: Aboosting-based system for text categorization.
Mach.Learn., 39(2-3):135?168.S.
Stevenson and E. Joanis.
2003.
Semi-supervised verbclass discovery using noisy features.
In Proceedingsof CoNLL.H.
van Halteren, J. Zavrel, and W. Daelemans.
1998.
Im-proving data driven wordclass tagging by system com-bination.
In Proceedings of ACL, pages 491?497.I.H.
Witten and E. Frank.
2005.
Data Mining: Practi-cal Machine Learning Tools and Techniques with JavaImplementations.
Morgan Kaufmann.J.
Yallop, A. Korhonen, and T. Briscoe.
2005.
Auto-matic acquisition of adjectival subcategorization fromcorpora.
In Proceedings of ACL, Ann Arbor, Michi-gan.180
