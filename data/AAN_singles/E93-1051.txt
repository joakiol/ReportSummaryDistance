Lexical Disambiguation UsingConstraint Handling In Prolog (CHIP) *George C.  Demetr iouCentre for Computer Analysis of Language And Speech (CCALAS)Artificial Intelligence Division, School of Computer Studies, University of LeedsLeeds, LS2 9JT, United Kingdom1 In t roduct ionAutomatic sense disambiguation has been recognisedby the research community as very important fora number of natural language processing applica-tions like information retrieval, machine translation,or speech recognition.
This paper describes exper-iments with an algorithm for lexieal sense disam-biguation, that is, predicting which of many possiblesenses of a word is intended in a given sentence.
Thedefinitions of senses of a given word are those used inLDOCE, the Longman Dictionary of ContemporaryEnglish \[Procter et al, 1978\].
The algorithm first as-signs a set of meanings or senses drawn from LDOCEto each word in the given sentence, and then choosesthe combination of word-senses (one for each word inthe sentence), yielding the maximum semantic over-lap.
The metric of semantic overlap is based on thefact that LDOCE sense definitions are made in termsof the Longman Defining Vocabulary, effectively a(large) set of semantic primitives.
Since the prob-lem of finding the word-sense-chain with maximumoverlap can be viewed as a specialised example ofthe class of constraint-based optimisation problemsfor which Constraint Handling In Prolog (CHIP) wasdesigned, we have chosen to implement our algorithmin CHIP.2 Background:  LDOCE,  Word  SenseD isambiguat ion  and  re la ted  workLDOCE's important feature is that its definitions(and examples) are written in a controlled vocab-ulary of 2187 words.
A definition is therefore al-ways written in simpler terms than the word it de-scribes.
These 2187 words effectively constitute se-mantic primitives, and any particular word-sense isdefined by a set of these primitives.Several researchers have been experimented withlexical disambiguation using MRDs, including \[Lesk,1986; Wilks et al, 1989; McDonald et al, 1990;Veronis and Ide, 1990; Guthrie et al, 1991; Guthrieet al, 1992\].
Lesk's technique decides the cor-rect sense of a word by counting the overlap be-tween a dictionary sense definition (of the word tobe disambiguated) and the definitions of the nearbywords in the phrase.
Performance (using brief ex-perimentation) was reported 50-70% and the results*This work was supported by the Greek EmploymentManpower Organisation (OAED), Ministry of Labour, aspart of an 1991-93 scholarship scheme.were roughly comparable between Webster's 7thCollegiate, Collins English Dictionary and OxfordAdvanced Learner's Dictionary of Current English.Methods based on co-occurence statistics have beenused by \[Wilks et al, 1989; McDonald et ai., 1990;Guthrie et al, 1991\].
By co-occurence is meant thepreference two words appear together in the samecontext.
\[Wilks ctal .
,  1989\] computed lexical neigh-bourhoods for all the words of the controlled vocab-ulary of LDOCE.
This neighbourhood informationis used for partitioning the words according to thesenses they correspond to in order to make a clas-sification of the senses.
Their results for using oc-curences of the word bank were about 53% for theclassification of each instance into one of the thirteensense definitions of LDOCE and 85-90% into one ofthe more general coarse meanings.
Neighbourhoodswere used by \[McDonald et al, 1990\] for expandingthe word sense definitions.
The union of neighbour-hoods is then intersected with the local context andthe largest overlap gives the most likely sense.
A sim-ilar technique is used by \[Guthrie t al., 1991\] exceptthat they define neighbourhoods according to sub-ject categories (i.e engineering, economic etc.)
basedon the subject code markings of the on-line versionof LDOCE.Closer to the work we describe in this paper is\[Guthrie t al., 1992\]'s.
They try to deal with large-scale text data disambiguation problems.
Theirmethod is based on the idea that the correct mean-ing of a complete phrase should be extracted by con-current evaluation of sets of senses for the words tobe disambiguated.
They count the overlap betweensense definitions of the words of the sentence as theyappear in the on-line version of LDOCE.
The prob-lem is that the number of sense combinations in-creases rapidly if the sentence contains ambiguouswords having a considerable number of sense defini-tions in LDOCE (say that word A has X differentsenses in LDOCE, B has Y and C has Z, then thenumber of possible sense combinations of the phraseABC is X*Y*Z, e.g if X=Y=Z=10 sense definitionsfor each word then we have 1000 possible sense com-binations).
Simulated annealing is used by \[Guthrieet al, 1992\] to reduce the search space and find anoptimal (or near-optimal) solution without generat-ing and evaluating all possible solutions, or pruningthe search space and testing a well-defined subspaceof reasonable candidate solutions.
The success oftheir algorithm is reported 47% at sense level and72% at homograph level using 50 example sentences431from LDOCE.3 CHIP: Constraint Handling InPrologWe decided it was worthwhile investigating the useof a constraint handling language so that we couldexhaustively search the space by applying CHIP's op-timisation procedures.
A CHIP compiler is availablefrom International Computers Limited (ICL) as partof its DecisionPower prolog-based toolkit 1.
CHIPextends usual Prolog-like logic programming by in-troducing three new computation domains of finiterestricted terms, boolean terms and linear rationalterms.
Another feature offered by CHIP is the demonconstructs used for user-defined constraints o imple-ment the local propagation.
For each of them CHIPuses specialised constraint solving techniques: con-sistency techniques for finite domains, equation solv-ing in Boolean algebra, and a symbolic simplex-likealgorithm.
CHIP's declarations are used to definethe domain of variables or to choose one of the spe-cialised unification algorithms; they can be: (1) finitedomains (i.e.
variables range over finite domains andterms are constructed from natural numbers, domainvariables over natural numbers and operators); (2)boolean declarations or (3) demon declarations (forspecifying a data-driven behaviour; they consist of aset of rules which describe how a constraint can besatisfied).
In addition, classes of built-in predicatesover finite domain variables exist for: (1) arithmeticand symbolic constraints (basic constraints for do-main variables), (2) choice predicates (help makingchoices), (3) higher order predicates (providing opti-misation methods for combinatorial problems usingdepth-first and branch and bound strategies) and(4) extra-logical predicates (for help in debuggingprocesses).
Forward checking and looking ahead in-ference rules are introduced for the control mecha-nism in the computation of constraints using finitedomains.
Auxiliary predicates to monitor or controlthe resolution process in the CHIP environment alsoexist.In our case we were particularly interested intransforming the general structure of our algorithminto a form usable by CHIP's choice and higher or-der built-in predicates.
Choice predicates are usedfor the automatic generation of word-sense combina-tions and higher order predicates facilitate the pro-cess of finding the most likely combination accordingto the 'score' of overlap.
To get an idea of this kindof implementation the main core of the optimisationpart of our program looks like this:opt imize  (Words, Choice,  Cost)  : -min:i~aize ( (makeChoice (Cho ice) ,f indCost  (Cho ice ,  Cost ) ) ,  Cost ) .1DecisionPower donated by ICL under the UniversityFunding Council's Knowledge and Constraint Manage-ment (KCM) Initiative.Minimize is one of CHIP's optimisation built-inpredicates.
Words represents the list of am-biguous words submitted to the program andChoice a list of domain variables for the selec-tion of sense definitions.
Cost is a domain vari-able whose domain is constrained to an arithmeticterm.
For our purposes, Cost was Max-0ver lapwhere Max (a maximum possible score) is largeenough so that Overlap (score of overlap in asense definition) can never exceed it.
Any answersubstitution that causes (makeChoice(Choice),f indCost(Choice,Cost)) to be ground also causesCost to be ground.
The search then back-tracks to the last choice point and continuousalong another branch.
The cost of any othersolution found in the sub-tree must be neces-sarily lower (i.e Overlap must be higher) thanthe last one found, because Cost is constrainedto that bound.
This process of backtrackingfor better solutions and imposing constraints onCost continues until the space has been searchedimplicitly.
At the end, (makeChoice(Choice),f indCost(Choice,Cost) is bound to the last solu-tion found which is the optimal one.4 AlgorithmOur method is based on the overlap between sensedefinitions of the words to be disambiguated.
This'is similar to \[Guthrie t hi., 1992\] although there aredistinct differences on the scoring method and theimplementation.
To illustrate our method we usethe following example and describe ach phase:The bank arranged for  an overdraft  on myacco~l t .4.1 Step 1All the common function words (particles) belongingto our 'stop list' (a set of 38 very common words)e.g.
for our example the set of words (the, for, an,on, my) should be removed.
Function words tend toappear very often both in context and in sense def-initions for syntactic and style reasons rather thanpure semantics.
Since our algorithm is intended tomaximise overlap the participation offunction wordsin a definition chain could lead to false interpreta-tion for the correct sense combination.
Moreover,function words are usually much more ambiguousthan content words (for example, there are 21 listedsenses of the word the and 35 of for in LDOCE).Thus, the searching process could be significantlyincreased without any obvious benefit to the reso-lution of ambiguity of context words as explainedabove.
Words of the 'stop list' have also been re-moved from the sense definitions and the remainingwords are stemmed so that only their roots appear inthe definition.
With this way, derived (or inflected)forms of the same word can be matched together.For this reason, the program also uses the primitive432or root forms of the input words.
After function-word-deletion the program is given the following setof words:bank arrange overdra f t  accountThese are processed according to their stemmedsense definitions in LDOCE, represented as Prologdatabase structures uch as:ba~k ( \[\[bank, land, along, side, river,lake\],\[bank, earth, heap, field, garden,make, border, division\],\[bank, mass, snow, cloud, mud\],\[bank, slope, make, bend, road, race,track, safer, car, go, round\],\[bank, sandbank\],\[bank, car ,  aircraft, move, side,higher, other, make, turn\],\[bank, row, oar, ancient, boat, key,typewriter\],\[bank, place, money, keep, pay,demand, relate, activity, go\],\[bank, place, something, hold, ready,use, organic, product, human,origin, medical, use\],\[bank, person, keep, supply, money,piece, payment, use, game, chance\],\[bank, win, money, game, chance\],\[bank, put, keep, money, bank\],\[keep, money, state, bank\ ] J ) .The conventions we use are: a) Each word to bedisambiguated is the functor of a predicate, contain-ing a list with stemmed sense definitions (in lists).b) We do not put a subject code in each sense defi-nition (as \[Guthrie t al., 1992\] do).
Instead we putthe word to be disambiguated as a member of thelist of each sense definition.
The rationale behindthis is that although a word put in its sense defini-tion cannot help with the disambiguation f itself, itcan provide help in the disambiguation of the otherwords if it appears in their sense definitions, c) Com-pound words of the form 'race-track' were used astwo words 'race' and 'track'.4.2 Step 2The algorithm generates sense combinations by go-ing through the sense definitions for each word oneby one.
For example, a sense combination can becalled by taking the 8th sense of bank (call it b8,see above), the first sense of arrange (al=\[arrange,set, good, please, order\]), the definition of over-draft (ol-\[overdraft, sum, lend, person, bank, more,money, have, bank\]), and the seventh of account(cT=\[accouat, sum, money, keep, bank, add, take\]).The scoring process for this sense combination isgiven by taking the definitions pairwise and count-ing the overlap of words between them.
Before theprogram proceeds to counting, redundancy of wordsis eliminated in each sense definition in order to pre-vent each word from being counted more than once.The algorithm checks for word overlap in advanceand in case this constraint is not satisfied, the com-bination is discarded and a new one generated sothat only overlapping combinations are considered.For each combination the total score is the sum ofall the overlaps pairwise.
This means that for n am-biguous words in the sentence the program countsthe overlap for all n//(~/(n-2)/) pair combinationsand add them together.
For the above example,score(b8alolc7)= overlap(b8al)+overlap(b8ol)+overlap(b8c7)+overlap(alol)+overlap(alcT)+overlap(olcT)=0+2+3+0+0+3 = 8This scoring method is quite different o the oneused by \[Lesk, 1986\].
Lesk simply counted overlapsby comparing each sense definition of a word withall the sense definitions of the other words.
\[Guthrieet al, 1992\] use a similar method.
It is differentin that if there is a subject (pragmatic) code for asense definition they put this subject code as a singleword in the definition list.
Then they go througheach list of the words, put the word in an array andbegin a counter at 0.
If the word is already in thelist they increment the counter.
So if, for example,three definitions have the same word they count it 2,while with our method this counts 3 and it seems thatour method generally overestimates.
Although noevidence of the best scoring scheme can be obtainedwithout results we think that our method may workbetter in chains where all definitions hare a commonword (and this overestimation goes higher comparedto \[Guthrie t al., 1992\]) which may indicate a strongpreference for that combination.4.3 S tep  3If a new generated combination has a higher score,it is considered as a better solution.
This new (tem-porary maximum) score acts as a constraint (a lowerminimum) to new generated combinations.
At theend, the most likely sense combination is the onewith the highest score.
Implementation i CHIPguarantees to give one and only solution (or no so-lution if no overlapping combination exists).
Theway choices are generated is by taking at the be-ginning the first sense definition for each word inthe sentence.
This is because the most common ormost typical meanings of a word are shown first inLDOCE.
Following choices replace the definitions ofthe words one by one according to the order thesewords are submitted to the program.
An examplesentence and its output is illustrated next \[Procteret al, 1978\]:Sentence: a tight feeling in the chest.433Tota l  number of  sense  combinat ions :  392Optimal solution found:t ight  : \ [ t ight ,  have,  produce,uncomfor tab le ,  fee l ing ,  c loseness ,part ,  body\]fee l ing  = \ [ fee l ing ,  consc iousness ,someth ing ,  fee l ,  mind, body\]chest  = \ [chest ,  upper, f ront ,  part ,  body,enc lose ,  hear t ,  lung\]I t s  Score i s :  $5 Resu l t sEvaluation of a dictionary-based l xical disambigua-tion routine is difficult since the preselection of thecorrect senses is in practice very difficult and time-consuming.
The most obvious technique would seemto be to start by creating a benchmark of sentences,disambiguating these manually using intuitive lin-guistic and lexicographical expertise to assign thebest sense-number to each word.
However, distinc-tions between senses are often delicate and fine-grained in a dictionary, and it is often hard to fita particular case into one and only one category.
Itis typical in work of this kind that researchers usehuman choices for the words or sentences to disam-biguate and the senses they will attempt to recognise\[Guthrie, 1993\].
In most of the cases \[Hearst, 1991;McDonald et al, 1990; Guthrie et al, 1991; Guthrieet al, 1992\], the number of test sentences i rathersmall (less than 50) so that no exact comparison be-tween different methods can be done.
Our tests in-cluded a set of 20 sentences, from sentences citedin an NLP textbook \[Harris, 1985\] (used to illus-trate non-MRD-based semantic disambiguation tech-niques) example sentences cited in \[Guthrie t al.,1992; Lesk, 1986; Hearst, 1991\] (for comparison be-tween different lexical disambiguation routines) andexamples taken from LDOCE (to assess the algo-rithm's performance with example sentences of par-ticular senses in the dictionary-this might also bea way of testing the consistency of the relationshipbetween different senses and their corresponding ex-amples of a word in LDOCE).
A sense chosen by ouralgorithm is compared with the 'intuitive' sense; butif there is not an exact match, we need to look furtherto judge how 'plausible' the predicted sense remains.After pruning of function words, length variedfrom 2 to 6 content words to be disambiguated, withan average of 3.1 ambiguous words per sentence.
Thenumber of different sense combinations ranged from15 to 126000.Of the 62 ambiguous words, 36 were assignedsenses exactly matching our prior intuitions, givingan overall success rate of 58%.
Although accuracy ofthe results is far from 100%, the method confirms thepotential contribution of the use of dictionary defini-tions to the problem of lexical sense disambiguation.Ambiguous words had between 2 and 44 differentsenses.
Investigating the success at disambiguatinga particular word depended on the number of alter-native senses given in the dictionary we had the fol-lowing results:No.
senses  No.
words Disambiguated Successper  word per range correct ly2-5 23 16 706-10 19 11 5811-15 II 5 4516-20 3 2 6721-44 6 2 33It might be expected that if the algorithm has tochoose between a very large number of alternativesenses it would be much likelier to fail; but in factthe algorithm held up well against the odds, showinggraceful degradation i success rate with increasingambiguity.
Furthermore, success rate showed littlevariation with increased number of ambiguous wordsper sentence:No.
amb.
words No.
sentences  Successper sentence per range2 7 643 8 S84 2 635 -6  3 50This presumably indicates abalanced trade-off be-tween competing factors.
One might expect thateach extra word brings with it more informationto help disambiguate other words, improving overallsuccess rate; on the other hand, it also brings withit spurious enses with primitives which may act as'red herrings' favouring alternative senses for otherwords.The average overlap score per sentence for the bestanalysis rose in line with sentence length, or rather,number of ambiguous words in the sentence:No.
ambiguous words Average over lap  fo rper sentence  best  d i sambiguat ion2 2 .23 3 .14 5 .06-6 6 .7434We noticed a trend towards choosing longer sense-definitions over shorter ones (i.e senses defined by alarger set of semantic primitives tended to be pre-ferred); 41 out of the 62 solutions given by the pro-gram (66%) were longer definitions than average.This is to be expected in an algorithm maximisingoverlap, as there are more primitives to overlap within a larger definition.
However, this tendency didNOT appear to imply wrong long sense were beingpreferred to correct short sense leading to a wors-ening overall success rate: of the 41 cases, 27 werecorrect, i.e 66% compared to 58% overall.
A betterinterpretation f this result might be that longer def-initions are more detailed and accurate, thus makinga better 'target'.Of the 26 'failures', 5 were assigned senses whichwere in fact incompatible with the syntactic word-class in the given sentence.
This indicates that ifthe algorithm was combined with a word-tagger suchas CLAWS \[Atwell, 1983; Leech, 1983\], and lexicalsenses were constrained to those allowed by the word-tags predicted by CLAWS, the success rate could riseto 66%.
This may also be necessary in cases whereLDOCE's definitions are not accurate nough.
Forexample, trying to disambiguate he words show, in.retest and music in the sentence 'He's showing aninterest in music' \[Procter et al, 1978\].
the pro-gram chose the eighth noun sense of show and thesecond verb sense of interest.
This was because theoccurence of the word 'do' in both definitions re-suited in a maximum overlap for that combination.However, the 'do's sense is completely different ineach case.
For the show 'do' was related to 'welldone ~ and for interest o 'do something'.Optimisation with CHIP performed well in findingthe optimal solution.
In all cases no other sense com-bination had a better score than the one found.
Thiswas confirmed by testing our algorithm in a separateimplementation without any of CHIP's optimisationprocedures but using a conventional method for ex-ploring the search space for the best solution.
Opti-misation with CHIP was found to be from 120% to600% faster than the conventional pproach.6 Conclus ions and Future Direct ionsIt is difficult to make a straightforward comparisonwith other methods for lexical disambiguation, par-ticularly \[Guthrie t al., 1992\]'s and \[Lesk, 1986\]'s, asthere is no standard evaluation benchmark; but thisapproach seems to work reasonably well for smalland medium scale disambiguation problems with abroadly similar success rate.
We could try produc-ing a much larger testbed for further comparativeevaluations; but it is not clear how large this wouldhave to he to become authoritative as an application-independent metric.
Future enhancements to the ap-proach incorporating the automatic use of the on-linesubject codes and cross reference and subcategorisa-tion systems of LDOCE can provide better results.Concerning CHIP, it provides a platform fromwhich we can build in order to deal with large scaledisambiguation; this could be used as an alternativeto numerical optimisation techniques.
The approachwill involve the modelling of the problem in a com-binatorial form so that constraint satisfaction logicprogramming \[Van Hentenryck, 1989\] can apply.
Foreach sense of a word we can specify a set of con-straints uch as its subject code(s), or part-of-speechinformation or both.
Forward checkable (or looka-head) rules can be introduced to decrease the num-ber of possible senses of other words in advance (say,for example, that the 'economic' sense for the word'bank' has been chosen, then only the 'economic' or'neutral' senses of the 'arrange', overdraft' and 'ac-count' will be taken into account).
This suggests adramatic reduction on the search space; CHIP offersall the necessary arithmetic and symbolic facilitiesfor the implementation.Our experiments will be based on the use the ma-chine version of LDOCE to verify the utility of thisdictionary for the specific kind of applications wehave in mind: the development methods and tech-niques that can assist large scale speech and hand-writing recognition systems using semantic knowl-edge from already available resources (MRDs andcorpora) \[Atwell et al, 1992\].
But the problem hereis somewhat different: semantic onstraints must beused for the correct choice between different candi-date Ascii interpretations of a spoken or handwrittenword.AcknowledgementsThis paper summarizes research reported in\[Demetriou, 1992\].I am grateful to Mr Eric Atwell, director ofCCALAS and my supervisor, for the motivating in-fluence and background material he provided me forthis project.I would also like to express my appreciation toDr Gyuri Lajos for the organisational support andadvice on CHIP programming and Mr Clive Souterfor his useful recommendations.Re ferences\[Atwell, 1983\] Eric Atwell.
Constituent-LikelihoodGrammar.
In ICAME Journal of the InternationalComputer Archive of Modern English no.
7, pages34-67, 1983.\[Atwell et al, 1992\] Eric Atwell, David Hogg andRobert Pocock.
Speech-Oriented ProbabilisticParser Project: Progress Reports l&2.
Techni-cal Reports, School of Computer Studies, LeedsUniversity, 1992.\[Demetriou, 1992\] George C. Demetriou.
LexicalDisambiguation Using Constraint Handling InProlog (CHIP).
MSc Dissertation, School of Com-puter Studies, University of Leeds, 1992.435\[Guthrie t al., 1991\] Joe Guthrie, Louise Guthrie,Yorick Wilks and H. Aidinejad.
Subject-dependent Co-occurence and Word Sense Disam-biguation.
In Proceedings of the 29th Annual Meet-ing of the Association for Computational Linguis-tics, pages 146-152, 1991.\[Guthrie t al., 1992\] Joe Guthrie, Louise Guthrieand Jim Cowie.
Lexical Disambiguation Us-ing Simulated Annealing.
In Proceedings of the14th Conference on Computational Linguistics,COLING-92, pages 359-364, 1992.\[Guthrie, 1993\] Louise Guthrie.
A Note on LexicalDisambiguation.
I  C. Sourer and E.Atwell (eds),Corpus-based Computational Linguistics, RodopiPress, Amsterdam, 1993.\[Harris, 1985\] Mary D. Harris.
An Introduction toNatural Language Processing.
Reston PublishingCompany, 1985.\[Hearst, 1991\] Marti Hearst.
Toward Noun Homo-graph Disambiguation Using Local Context inLarge Text Corpora.
In Proceedings of the 7thAnnual Conference of the UW Centre for the NewOED and TEXT Research, Using Corpora, pages1-22, 1991.\[Leech, 1983\] Geoffrey Leech, Roger Garside andEric Atwell.
The Automatic Grammatical Taggingof the LOB Corpus.
In 1CAME Journal of the In-ternational Computer Archive of Modern Englishno.
7, pages 13-33, 1983.\[Lesk, 1986\] Michael Lesk.
Automatic Sense Disam-biguation Using Machine Readable Dictionaries:how to tell a pine cone from an ice cream cone.In Proceedings of the ACM SIG-DOC Conference,Ontario, Canada, 1986.\[McDonald et al, 1990\] James E. McDonald, TonyPlate and R. Schvaneveldt.
Using Pathfinderto Extract Semantic Information from Text.
InPathfinder associative networks: studies in knowl-edge organisation, R. Schvaneveldt (ed), Norwood,NJ:Ablex, 1990.\[Procter et ai., 1978\] Paul Procter et al The Long-man Dictionary of Contemporary English.
Long-man, 1978.\[Van Hentenryck, 1989\]Pascal Van Hentenryck.
Constraint Satisfactionin Logic Programming.
MIT Press, Cambridge,Massachusetts, 1989.\[Veronis and Ide, 1990\] Jean Veronis and Nancy M.Ide.
Word Sense Disambiguation with Very LargeNeural Networks Extracted from Machine Read-able Dictionaries.
In Proceedings of the 13th Con-ference on Computational Linguistics, COLING-90, Helsinki, Finland, 2, pages 389-394, 1990.\[Wilks et aL, 1989\] Yorick Wilks, Dan Fass, Cheng-Ming Guo, James McDonald, Tony Plate andBrian Slator.
A Tractable Machine Dictionary asa Resource for Computational Semantics.
In Com-putational Lezicography for Natural Language Pro-cessing, B. Boguraev and T. Briscoe (eds), Long-man, 1989.436
