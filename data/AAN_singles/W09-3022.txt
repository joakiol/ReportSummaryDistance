Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 130?133,Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLPAnnotating language errors in texts: investigating argumentation anddecision schemasCamille ALBERT, Laurie BUSCAILMarie GARNIER, Arnaud RYKNERLLA, Universite?
Toulouse le Mirail31000 TOULOUSE Francemhl.garnier@gmail.comPatrick SAINT-DIZIERIRIT-CNRS, 118, route de Narbonne,31062 TOULOUSE Francestdizier@irit.frAbstractIn this short paper, we present annotationsfor tagging grammatical and stylistic er-rors, together with attributes about the na-ture of the correction which are then in-terpreted as arguments.
A decision modelis introduced in order for the author to beable to decide on the best correction tomake.
This introduces an operational se-mantics for tags and related attributes.1 Aims and SituationNon-native English speaking authors producingdocuments in English often encounter lexical,grammatical and stylistic difficulties that maketheir texts difficult for native speakers to under-stand.
As a result, the professionalism and thecredibility of these texts is often affected.
Ourmain aim is to develop procedures for the correc-tion of those errors which cannot (and will not inthe near future) be treated by the most advancedtext processing systems such as those proposed inthe Office Suite, OpenOffice and the like.
In thetype of errors taken into consideration, several lev-els are often intertwinned: morphology, lexicon,grammar, style, textual structure, domain usages,context of production, target audience, etc..While we attempt to correct errors, it turns outthat, in a large number of cases, (1) there maybe ambiguities in the analysis of the nature of er-rors, (2) errors can receive various types and lev-els of corrections depending on the type of docu-ment, reader, etc., and (3) some corrections can-not be successfully done without an interactionwith the author.
To achieve these aims we needto produce a model of the cognitive strategies de-ployed by human experts (e.g.
translators cor-recting texts, teachers) when they detect and cor-rect errors.
Our observations show that it is nota simple and straightforward strategy, but that er-ror diagnosis and corrections are often based on acomplex analytical and decisional process.
Sincewe want our system to have a didactic capacity,in order to help writers understand their errors,we propose an analysis of error diagnosis basedon argumentation theory, outlining arguments foror against a certain correction and their relativestrength paired with a decision theory.The modelling of correction strategies is basedon the annotation of a large variety of types of doc-uments in English produced by a large diversity ofFrench speakers.
Annotations allow us to iden-tify and categorize errors as well as the parame-ters at stake (e.g.
category change, length of newcorrected segment) at stake when making correc-tions.
This is carried out by bilingual correctorsin collaboration with didacticians.
Those parame-ters are a priori neutral in the annotation schemas.We then define a preference model that assigns po-larity (positive, negative) and a weight to each ofthese parameters, together with additional param-eters among which the target reader, the type ofdocument, etc.
An argumentation model that con-siders these parameters as weighted arguments, foror against a certain correction, can thus be intro-duced.
Paired with a decision model, optimal cor-rections can be proposed to the author, togetherwith explanations.
This approach confers a formalinterpretation to our annotation schema.Works on the correction of grammatical errorsmade by human authors (Brockett, 2006), (Han etal.
2005), (Lee et al 2006), (Tetreau et al2008),(Writer?s v. 8.2) recently started to appear.
The ap-proach presented here, which is still preliminary,is an attempt to include some didactic aspects intothe correction by explaining to the user the natureof her/his errors, whether grammatical or stylis-tic, while weighing the pros and cons of a cor-rection, via argumentation and decision theories(Boutiler et al.
1999), (Amgoud et al.
2008).Persuasion aspects also matter within the didacti-cal perspective (e.g.
Persuation Technology sym-130posiums), (Prakken 2006).In this document, we present the premisses ofan approach to correcting complex grammar andstyle errors, which allow us to evaluate difficulties,challenges, deadlocks, etc.
Annotations are usedhere for the development of an application.2 The annotated corpusThe documents analyzed range from spontaneousshort productions, with little control and proof-reading, such as personal emails or posts on fo-rums, to highly controlled documents such as pub-lications or professional reports.
We also considerpersonal web pages and wiki texts.
Within eachof these types, we also observed variation in thecontrol of the quality of the writing.
For exam-ple, emails sent to friends are less controlled thanthose produced in a professional environment, andeven in this latter framework, messages sent to thehierarchy or to foreign colleagues receive more at-tention than those sent to close colleagues.
Be-sides the level of control, other parameters, suchas style, are taken into consideration (e.g.
oralvs.
academic).
Therefore, the different corpora wehave collected form a certain continuum over sev-eral parameters (control, orality, etc.
); they allowus to observe a large variety of language produc-tions.More details on the elaboration of corpora, def-inition of attributes and their stability, and annota-tion scenarios can be found in (Albert et al, 2009).3 The Annotation SystemLet us now briefly introduce the annotationschema we have developed.
It is an ongoing ef-fort which is gradually evaluated by real users.This schema is an attempt to reflect, in a fac-tual and declarative way, the different parameterstaken into consideration by didacticians and hu-man translators when detecting and correcting er-rors.
It contains several groups of tags which aregiven below.
The values for each attribute arebased on a granularity level evaluated by the di-dacticians of our group.
They are still preliminaryand require evaluation and revisions.
Their struc-ture has been designed so that they can be used inan argumentation framework.
(a) Error delimitation and characterization:<error-zone> tags the group of words involved inthe error.
The zone is meant to be as minimal aspossible.
This tag has several attributes:comprehension: from 0 to 4 (0 being worse): indi-cates if the segment is understandable, in spite ofthe error,agrammaticality: from 0 to 2: indicates how un-grammtical the error is.categ: main category of the error: lexical, syntac-tic, stylistic, semantic, textual,source: calque (direct copy), overcorrection, etc.
(b) Delimitation of the correction:<correction-zone> tags the text fragment in-volved in the correction.
It is equal or larger thanthe error zone.
(c) Characterization of a given correction:Each correction is characterized by a tag<correction> and associated attributes, positivelyoriented ones are underlined:surface: size of the text segment affected by thecorrection: minimal, average, maximal,grammar: indicates, whenever appropriate, if thecorrection proposed is the standard one as sug-gested by grammar rules; values are: by-default,alternative, unlikely,meaning: indicates if the meaning has been al-tered: yes, somewhat, no,var-size: is an integer that indicates theincrease/decrease in number of words of the cor-rection w.r.t.
the original fragment,change: indicates if the changes in the correctionare syntactic, lexical, stylistic, semantic or textual,comp: indicates if the proposed correction is a textfragment which is easy to understand or not; val-ues are: yes, average, no,fix: indicates, when mentioned, that the error isvery specific to that string of words and that thecorrection is idiosyncratic and cannot be extendedto any other such structure.qualif: indicates the certainty level of the annota-tor and didacticians, it qualifies the certainty of theerror detection and of the proposed correction se-paretely,correct: gives the correction.An example is the N N construction (for thesake of readability, we do not consider longer Nchains), with erroneous segments like: the mean-ing utterance or goal failure:It is difficult to characterize <correction-zone><error-zone comprehension=?2?agrammaticality=?1?categ=?syntax?
source=?calque?>the meaning utterance<correction qualif=?high?
grammar=?by-default?131surface= ?minimal?
meaning= ?not altered?
Var-size=?+2?change=?synt?
comp=?yes?correct= ?the meaning of the utterance?></correction><correction qualif=?high?
grammar=?unlikely?surface= ?minimal?
meaning= ?somewhat?
Var-size=?0?change=?lexical+synt?
comp=?average?correct= ?the meaningful utterance?></correction></error-zone> </correction-zone> without a context.These tags are relatively simple and intuitive.After some basic training, 2 independent annota-tors covered about 25 pages (emails and reports)so that we can measure the stability of the annota-tions and the annotators comprehension and agree-ment/disagreement.
Results are not easy to ana-lyze in a simple way since annotators disagree onsome error existence and nature.
In about 20% ofthe cases we observed such forms of disagreement.Beside this observation, annotations turn out to bequite convenient, although, for each error, a con-siderable analysis effort is required for its analysis.Annotating texts is very much time consuming, inparticular when there are several possibilities ofcorrections.4 From annotations to correction rulesOur corpus (texts, emails) has been annotated fol-lowing the above schema.
Several steps are re-quired in order to reach the correction rule stage ofdrafting rules of corrections.
The approach is stillexploratory, and needs further elaborations andevaluations.
This is achieved through a gradualand manually controlled machine learning strat-egy.
As a result, we get 23 main categories oferrors based on the elements involved in the gram-matical and stylistic aspects, e.g.
: incorrect argu-ment structure, incorrect adverb position, incor-rect embedded clause construction, incorrect co-ordination, incorrect paragraph start.To define a correction rule, the segment ofwords in the error zone first gets a morphosyn-tactic tagging, so that it can be easily identifiedas an erroneous pattern in any circumstance.
Allthe errors that have the same erroneous pattern aregrouped to form a single correction procedure.
Inthat same category (named ?incorrect N N con-structions?
), another pattern is [N(+plural) N] (e.g.horses carriage), and it results in a different cor-rection rule.Concerning the pattern ?Det N N?, when all thecorresponding errors are grouped, another type ofcorrection is found that corresponds to the inver-sion (the predicate meaning ?
the meaning of thepredicate).
Informally, a correction rule is definedas the union of all the corrections found for thatparticular pattern:(1) merge all corrections which are similar, i.e.where the position of each word in the erroneoussegment is identical to the one it has in the cor-rection; the values of the different attributes of the<correction> tag are averaged,(2) append all corrections which have a differentcorrection following the word to word criterionabove, and also all corrections for which the at-tribute ?fix?
is true.
(3) tag the corrections with all the appropriatemorphosyntactic details,(4) remove the text segments or keep them as ex-amples.For the above example, we get the followingrule:<correction-rule><error-zone comprehension=?2?
agrammaticality=?1?categ=?syntax?
source=?calque?pattern=?
[Det N(1) N(2)?
]><correction qualif=?high?
grammar=?by-default?surface= ?minimal?
meaning= ?not altered?
Var-size=?+2?change=?synt?
comp=?yes?web-correct= ?
[Det N(1) of the N(2)]?
></correction><correction qualif=?high?
grammar=?unlikely?surface= ?minimal?meaning= ?somewhat?
Var-size=?0?change=?lexical+synt?
comp=?average?correct=?
[Det Adj(deriv(N(1)) N(2)]?exemple=?the meaningful utterance?></correction><correction qualif=?high?
grammar=?by-default?surface= ?minimal?meaning= ?not altered?
Var-size=?+2?change=?synt?
comp=?yes?web-correct= ?
[Det N(2) of the N(1)]?
></correction> </error-zone> </correction-rule>We observe here several competing solutions:when we have a segment like the meaning pred-icate we have no information as to the noun or-der and the type of preposition to insert (however,?of?
is the most frequent one).
In this example,the best solution is to use the web as a corpus.The attribute web-correct is a shortcut for a func-tion that triggers a web search: the instanciated132pattern is submitted to a search engine to evaluateits occurence frequency.
The most frequent one isadopted.
Other rules contain e.g.
interactions withthe user to get a missing argument or to correct apronoun.The form: pattern ?
correct (or) web-correctis a rewriting rule that operates the correction un-der constraints given in the ?correct?
attribute andunder didactic constraints given in the associatedattributes.
Several corrections from the same ruleor from different rules may be competing.
Thisis a very frequent situation, e.g.
: the position ofthe adverb which may equally be either before themain verb, or at the beginning, or at the end of thesentence.
A correction rule is active for a givencorrection iff all the constraints it contains in the?correct?
attribute are met.5 Using argumentation to structure thecorrection spaceOur goal, within an ?active didactics?
perspective,consists in identifying the best corrections andproposing them to the writer together with expla-nations, so that he can make the most relevant de-cisions.
Classical decision theory must be pairedwith argumentation to produce explanations.
Inour framework, argumentation is based on the at-tributes associated with the tags of the correctionrules.
This view confers a kind of operational se-mantics to the tags and attributes we have defined.Formally, a decision based on practical argu-ments is represented by a vector (D, K, G, R) de-fined as follows:(1) D is a vector composed of decision variablesassociated with explanations: the list of the differ-ent decisions which can be taken into considera-tion, including no correction.
The final decision isthen made by the writer,(2) K is a structure of stratified knowledge, pos-sibly inconsistent.
Stratifications encode priori-ties (e.g.
Bratman, 1987, Amgoud et al 2008).K includes, for example, knowledge about read-ers (e.g.
in emails they like short messages, closeto oral communication), grammatical and stylisticconventions or by-default behaviors, global con-straints on texts or sentences.
Each strata is asso-ciated with a weight wK ?
[0, 1](3) G is a set of goals, possibly inconsistent, thatcorrespond to positive attributes Ai to promote ina correction.
These goals depend on the type ofdocument being written.
For example, for emails,we may have the following goals: (meaning: no,comp: yes, grammar: by-default).
These goalsmay have different weights.
The form of a goalis:(attribute?
name, value,weight)where weight is: wAi ?
[0, 1].
(4) R is a set of rejections: i.e.
criteria that are notdesired, e.g., for emails: (surface: not(minimal),change: style, semantic, textual).
Format is thesame as for G. R and G have an empty intersec-tion.
These rejections may also have weights.Some attributes may remain neutral (e.g.
var-size)for a given type of document or profile.The global scenario for correcting an erroris as follows: while checking a text, when anerror pattern (or more if patterns are ambigu-ous) is activated, the corrections proposed in the<correction> tag are activated and a number ofthem become active because the corresponding?correct?
attribute is active.
Then, the attributes ineach of the correction, which form arguments, areintegrated in the decision process.
Their weight inG or R is integrated in a decision formula; theseweights may be reinforced or weakened via theknowledge and preferences given in K. For eachcorrection decision, a meta-argument that containsall the weighted pros and cons is produced.
Thismeta-argument is the motivation and explanationfor realizing the correction as suggested.
It has nopolarity.ReferencesAmgoud, L., Dimopoulos, Y., Moraitis, P., Making de-cisions through preference-based argumentation.
InProceedings of the International Conference on Prin-ciples of Knowledge Representation and Reasoning(KR08), AAAI Press, 2008.Bratman, M., Intentions, plans, and practical reason.Harvard University Press, Massachusetts, 1987.Brockett et al (2006) Correcting ESL Errors UsingPhrasal SMT Techniques, Proc of COLING/ACLHan et al, Detecting Errors in English Article Usageby Non-native Speakers, NLE, 2005Lee, H., Seneff, A., Automatic Grammar Correctionfor Second-language Learners, Proc of InterSpeech,2006Prakken, H., Formal systems for persuasion dialogue,Knowledge Engineering Review, 21:163188, 2006.Tetreault, M., Chodorow, C. Native Judgments of Non-native Usage, Proc of COLING Workshop on Hu-man Judgements in Comp.
Ling, 2008.133
