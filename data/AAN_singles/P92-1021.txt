LATT ICE-BASED WORD IDENTIF ICAT ION IN CLAREDavid M. CarterSRI InternationalCambridge Computer Science Research Centre23 Millers YardCambridge CB2 1RQ, U.K.dmc@cam, sri.
comABSTRACTI argue that because of spelling and typingerrors and other properties of typed text, theidentification of words and word boundariesin general requires syntactic and semanticknowledge.
A lattice representation is there-fore appropriate for lexical analysis.
I showhow the use of such a representation i  theCLARE system allows different kinds of hy-pothesis about word identity to be integratedin a uniform framework.
I then describe aquantitative valuation of CLARE's perfor-mance on a set of sentences into which ty-pographic errors have been introduced.
Theresults show that syntax and semantics can beapplied as powerful sources of constraint onthe possible corrections for misspelled words.1 INTRODUCTIONIn many language processing systems, uncer-tainty in the boundaries of linguistic units,at various levels, means that data are repre-sented not as a well-defined sequence of unitsbut as a lattice of possibilities.
It is commonfor speech recognizers to maintain a lattice ofoverlapping word hypotheses from which oneor more plausible complete paths are subse-quently selected.
Syntactic parsing, of eitherspoken or written language, frequently makesuse of a chart or well-formed substring ta-ble because the correct bracketing of a sen-tence cannot (easily) be calculated etermin-istically.
And lattices are also often used inthe task of converting Japanese text typed inkana (syllabic symbols) to kanji; the lack of in-terword spacing in written Japanese and thecomplex morphology of the language meanthat lexical items and their boundaries cannotbe reliably identified without applying syntac-tic and semantic knowledge (Abe et al 1986).In contrast, however, it is often assumedthat, for languages written with interwordspaces, it is sufficient o group an input char-acter stream deterministically into a sequenceof words, punctuation symbols and perhapsother items, and to hand this sequence tothe parser, possibly after word-by-word mor-phological analysis.
Such an approach issometimes adopted even when typographi-cally complex inputs are handled; see, for ex-ample, Futrelle et al 1991.In this paper I observe that, for typed in-put, spaces do not necessarily correspond toboundaries between lexical items, both for lin-guistic reasons and because of the possibil-ity of typographic errors.
This means that alattice representation, not a simple sequence,should be used throughout front end (pre-parsing) analysis.
The CLARE system underdevelopment at SRI Cambridge uses such arepresentation, allowing it to deal straightfor-wardly with combinations or multiple occur-rences of phenomena that would be difficultor impossible to process correctly under a se-quence representation.
As evidence for theperformance of the approach taken, I describe159an evaluation of CLARE's ability to deal withtyping and spelling errors.
Such errors are es-pecially common in interactive use, for whichCLARE is designed, and the correction of asmany of them as possible can make an appre-ciable difference to the usability of a system.The word identity and word boundary am-biguities encountered in the interpretation oferrorful input often require the applicationof syntactic and semantic knowledge on aphrasal or even sentential scale.
Such knowl-edge may be applied as soon as the problemis encountered; however, this brings majorproblems with it, such as the need for ad-equate lookahead, and the difficulties of en-gineering large systems where the processinglevels are tightly coupled.
To avoid these diffi-culties, CLARE adopts a staged architecture,in which indeterminacy is preserved until theknowledge needed to resolve it is ready to beapplied.
An appropriate representation is ofcourse the key to doing this efficiently.2 SPACES AND WORDBOUNDARIESIn general, typing errors are not just a matterof one intended input token being miskeyed asanother one.
Spaces between tokens may bedeleted (so that two or more intended wordsappear as one) or inserted (so that one wordappears as two or more).
Multiple errors,involving both spaces and other characters,may be combined in the same intended or ac-tual token.
A reliable spelling corrector mustallow for all these possibilities, which must,in addition, be distinguished from the use ofcorrectly-typed words that happen to fall out-side the system's lexicon.However, even in the absence of "noise" ofthis kind, spaces do not always correspondto lexical item boundaries, at least if lexicalitems are defined in a way that is most con-venient for grammatical purposes.
For exam-ple, "special" forms such as telephone num-bers or e-mail addresses, which are commonin many domains, may contain spaces.
InCLARE, these are analysed using regular ex-pressions (cf Grosz et al 1987), which mayinclude space characters.
When such an ex-pression is realised, an analysis of it, connect-ing non-adjacent vertices if it contains paces,is added to the lattice.The complexities of punctuation are an-other source of uncertainty: many punctu-ation symbols have several uses, not all ofwhich necessarily ead to the same way of seg-menting the input.
For example, periods mayindicate ither the end of a sentence or an ab-breviation, and slashes may be simple word-internal characters (e.g.
X11/Ne WS) or func-tion lexically as disjunctions, as in\[1\] I'm looking for suggestions forvendors to deal with/avoid.
1Here, the character string "with/avoid", al-though it contains no spaces, represents hreelexical items that do not even form a syntacticconstituent.CLARE's architecture and formalism allowfor all these possibilities, and, as an exten-sion, also permit multiple-token phrases, suchas idioms, to be defined as equivalent to othertokens or token sequences.
This facility isespecially useful when CLARE is being tai-lored for use in a particular domain, sinceit allows people not expert in linguistics orthe CLARE grammar to extend grammati-cal coverage in simple and approximate, butoften practically important, ways.
For ex-ample, if an application developer finds thatinputs such as "What number of employeeshave cars?"
are common, but that the con-struction "what number of ..." is not han-dled by the grammar, he can define the se-quence "what number of" as equivalent o"how many".
This will provide an extensionof coverage without the developer needing toknow how any of the phrases involved aretreated in the grammar.
Extending the gram-mar is, of course, a more thorough solution ifthe expertise is available; the phrasal equiv-alence suggested here will not, for example,aThese two examples are taken from the Sun-spotscomputer bulletin board.160cope correctly with the query "What numberof the employees have cars?
".3 CLARE 'S  PROCESSING STAGESThe CLARE system is intended to providelanguage processing capabilities (both anal-ysis and generation) and some reasoning fa-cilities for a range of possible applications.English sentences are mapped, via a num-ber of stages, into logical representations oftheir literal meanings, from which reasoningcan proceed.
Stages are linked by well-definedrepresentations.
The key intermediate r pre-sentation is that of quasi logical .form (QLF;Alshawi, 1990, 1992), a version of slightlyextended first order logic augmented withconstructs for phenomena such as anaphoraand quantification that can only be resolvedby reference to context.
The unification ofdeclarative linguistic data is the basic process-ing operation.The specific task considered in this paper isthe process of mapping single sentences fromcharacter strings to QLF.
Two kinds of issueare therefore not discussed here.
These arethe problem of segmenting a text into sen-tences and dealing with any markup instruc-tions (cf Futrelle et al 1991), which is logicallyprior to producing character strings; and pos-sible context-dependence of the lexical phe-nomena discussed, which would need to bedealt with after the creation of QLFs.In the analysis direction, CLARE's frontend processing stages are as follows.1.
A sentence is divided into a sequence ofclusters separated by white space.2.
Each cluster is divided into one or moretokens: words (possibly inflected), punc-tuation characters, and other items.
To-kenization is nondeterministic, and so alattice is used at this and subsequentstages.3.
Each token is analysed as a sequence ofone or more segments.
For normal lexi-cal items, these segments are morphemes...The lexicon proper is first accessed at thisstage.A variety of strategies for error recovery(including but not limited to spelling/typing correction) are attempted on to-kens for which no segmentation couldbe found.
Edges without segmentationsare then deleted; if no complete path re-mains, sentence processing is abandoned.Further edges, possibly spanning non-adjacent vertices, are added to the lat-tice by the phrasal equivalence mecha-nism discussed earlier.Morphological, syntactic and semantic stagesthen apply to produce one or more QLFs.These are checked for adherence to sortal (se-lectional) restrictions, and, possibly with thehelp of user intervention, one is selected forfurther processing.Because tokenization is nondeterministicand does not involve lexical access, it willproduce many possible tokens that cannot befurther analysed.
If sentence \[1\] above wereprocessed, with/avoid would be one such to-ken.
It is important hat analyses are foundfor as many tokens and token sequences aspossible, but that error recovery, especially ifit involves user interaction, is not attemptedunless really necessary.
More generally, thesystem must decide which techniques to applyto which problem tokens, and how the resultsof doing so should be combined.CLARE's token segmentation phase there-fore attempts to find analyses for all the sin-gle tokens in the lattice, and for any specialforms, which may include spaces and thereforespan multiple tokens.
Next, a series of recov-ery methods, which may be augmented or re-ordered by the application developer, are ap-plied.
Globalmethods apply to the lattice as awhole, and are intended to modify its contentsor create required lexicon entries on a scalelarger than the individual token.
Local meth-ods apply only to single still-unanalysed to-kens, and may either supply analyses for them161or alter them to other tokens.
The defaultmethods, all of which may be switched on oroff using system commands, supply facilitiesfor inferring entries through access to an ex-ternal machine-readable dictionary; for defin-ing sequences of capitalized tokens as propernames; for spelling correction (described indetail in the next section); and for interactingwith the user who may suggest a replacementword or phrase or enter the VEX lexical ac-quisition subsystem (Carter, 1989) to createthe required entries.After a method has been applied, the lat-tice is, if possible, pruned: edges labelled byunanalysed tokens are provisionally removed,as are other edges and vertices that then donot lie on a complete path.
If pruning suc-ceeds (i.e.
if at least one problem-free pathremains) then token analysis is deemed tohave succeeded, and unanalysed tokens (suchas with/avoid) are forgotten; any remainingglobal methods are invoked, because they mayprovide analyses for token sequences, but re-maining local ones are not.
If full pruningdoes not succeed, any subpath in the latticecontaining more unrecognized tokens than analternative subpath is eliminated.
Subpathscontaining tokens with with non-alphabeticcharacters are penalized more heavily; thisensures that if the cluster "boooks,"  is in-put, the token sequence "boooks ," (in which"boooks" is an unrecognized token and " ,"is a comma) is preferred to the single token"boooks,"  (where the comma is part of theputative lexical item).
The next method isthen applied.
24 SEGMENTATION ANDSPELL ING CORRECTIONA fairly simple affix-stripping approach to to-ken segmentation is adopted in CLARE be-Sin fact, for completeness, CLARE allows the ap-plication of two or more methods in tandem and willcombines the results without any intermediate prun-ing.
This option would be useful if, in a given appli-cation, two sources of knowledge were deemed to beabout equally reliable in their predictions.cause inflectional morphological changes inEnglish tend not to be complex enough towarrant more powerful, and potentially lessefficient, treatments uch as two-level mor-phology (Koskenniemi, 1983).
Derivationalmorphological relationships typically involvesemantic peculiarities as well, necessitatingthe definition of derived words in the lexiconin their own right.The rules for dividing clusters into :tokenshave the same form as those for segmentingtokens into morphemes, and are processed bythe same mechanism.
Thus " ," ,  like, say,"ed", is defined as a suffix, but one that istreated by the grammar as a separate wordrather than a bound morpheme.
Rules forpunctuation characters are very simple be-cause no spelling changes are ever involved.However, the possessive ending "' s" is treatedas a separate word in the CLARE grammar toallow the correct analysis of phrases such as"the man in the corner's wife", and spellingchanges can be involved here.
Like segmenta-tion, tokenization can yield multiple results,mainly because there is no reason for a com-plex cluster like Mr. or K ing 's  not also to bedefined as a lexical item.One major advantage of the simplicity ofthe affix-stripping mechanism is that spellingcorrection can be interleaved irectly with it.Root forms in the lexicon are represented ina discrimination et for efficient access (cfEmirkanian and Bouchard, 1988).
When thespelling corrector is called to suggest possiblecorrections for a word, the number of simpleerrors (of deletion, insertion, substitution andtransposition; e.g.
Pollock and Zamora, 1984)to assume is given.
Normal segmentation isjust the special case of this with the numberof errors set to zero.
The mechanism nonde-terministically removes affixes from each endof the word, postulating errors if appropriate,and then looks up the resulting string in thediscrimination et, again considering the pos-sibility of error.
33This is the reverse of Veronis' (1988) algorithm,where roots are matched before affixes.
However, it162Interleaving correction with segmentationlike this promotes efficiency in the followingway.
As in most other correctors, only upto two simple errors are considered along agiven search path.
Therefore, either the affix-stripping phase or the lookup phase is fairlyquick and produces a fairly small number ofresults, and so the two do not combine toslow processing down.
Another beneficial con-sequence of the interleaving is that no spe-cial treatment is required for the otherwiseawkward case where errors overlap morphemeboundaries; thus desigend is corrected to de-signed as easily as deisgned or designde are.If one or more possible corrections to a to-ken are found, they may either be presentedto the user for selection or approval, or, ifthe number of them does not exceed a pre-set threshold, all be preserved as alternativesfor disambiguation at the later syntactic orsemantic stages.
The lattice representationallows multiple-word corrections to be pre-served along with single-word ones.It is generally recognized that spelling er-rors in typed input are of two kinds: compe-tence errors, where the user does not know, orhas forgotten, how to spell a wordi and per-formance rrors, where the wrong sequence ofkeys is hit.
CLARE's correction mechanism isoriented towards the latter.
Other work (e.g.Veronis, 1988, Emirkanian and Bouchard,1988, van Berkel and De Smedt, 1988) em-phasizes the former, often on the grounds thatcompetence errors are both harder for the userto correct and tend to make a worse impres-sion on a human reader.
However, Emirka-nian and Bouchard identify the many-to-onenature of French spelling-sound correspon-dence as responsible for the predominance ofsuch errors in that language, which they saydoes not hold in English; and material typedto CLARE tends to be processed further (forseems easier and more efficient to match affixes first,because then the hypothesized root can be looked upwithout having to allow for any spelling changes; andif both prefixes and suffixes are to be handled, as theyare in CLARE,  there is no obvious single start ing pointfor searching for the root first.database access, translation, etc) rather thanreproduced for potentially embarrassing hu-man consumption.
A performance-error ap-proach also has the practical advantage ofnot depending on extensive linguistic knowl-edge; and many competence errors can be de-tected by a performance approach, especiallyif some straightforward adjustments (e.g.
toprefer doubling to other kinds of letter inser-tion) are made to the algorithm.As well as coping quite easily with mor-pheme boundaries, CLARE's algorithm canalso handle the insertion or deletion of wordboundary spaces.
For the token witha,CLARE postulates both with and with a ascorrections, and (depending on the currentswitch settings) both may go into the lat-tice.
The choice will only finally be madewhen a QLF is selected on sortal and othergrounds after parsing and semantic analy-sis.
For the token pair hey er, CLARE pos-tulates the single correction never, becausethis involves assuming only one simple er-ror (the insertion of a space) rather thantwo or more to "correct" each token individ-ually.
Multiple overlapping possibilities canalso be handled; the input Th m n workedcauses CLARE to transform the initial latticeth m n workedinto a corrected lattice containing analyses ofthe words shown here:th.e/to / man/men.
a /an / in /th :m /no /on / , /1 / I  -workedThe edges labelled "them" and "man/men"are constructed first by the "global" spellingcorrection method, which looks for possiblecorrections across token boundaries.
The edgefor the token "m" is then removed because,given that it connects only to errorful tokenson both sides, it cannot form part of anypotentially optimal path through the lattice.Corrections are, however, sought for "th" and\ ]63"n" as single tokens when the local spellingcorrection method is invoked.
The correctedlattice then undergoes syntactic and semanticprocessing, and QLFs for the sequences "theman worked" and "the men worked", but notfor any sequence starting with "them" or "to",are produced.5 AN EVALUATIONTo assess the usefulness of syntactico-semantic onstraints in CLARE's spelling cor-rection, the following experiment, intendedto simulate performance (typographic) er-rors, was carried out.
Five hundred sen-tences, of up to ten words in length, fallingwithin CLARE's current core lexical (1600root forms) and grammatical coverage weretaken at random from the LOB corpus.
Thesesentences were passed, character by charac-ter, through a channel which transmitted acharacter without alteration with probability0.99, and with probability 0.01 introduced asimple error.
The relative probabilities of thefour different kinds of error were deduced fromTable X of Pollock and Zamora, 1984; wherea new character had to be inserted or sub-stituted, it was selected at random from theoriginal sentence set.
This process produced atotal of 102 sentences that differed from theiroriginals.
The average length was 6.46 words,and there were 123 corrupted tokens in all,some containing more than one simple error.Because longer sentences were more likely tobe changed, the average length of a changedsentence was some 15% more than that of anoriginal one.The corrupted sentence set was then pro-cessed by CLARE with only the spelling cor-rection recovery method in force and withno user intervention.
Up to two simple er-rors were considered per token.
No domain-specific or context-dependent k owledge wasused.Of the 123 corrupted tokens, ten were cor-rupted into other known words, and so nocorrection was attempted.
Parsing failed innine of these cases; in the tenth, the cor-rupted word made as much sense as the orig-inal out of discourse context.
In three furthercases, the original token was not suggested asa correction; one was a special form, and forthe other two, alternative corrections involvedfewer simple errors.
The corrections for twoother tokens were not used because a corrup-tion into a known word elsewhere in the samesentence caused parsing to fail.Only one correction (the right one) was sug-gested for 59 of the remaining 108 tokens.Multiple-token correction, involving the ma-nipulation of space characters, took place in24 of these cases.This left 49 tokens for which more than onecorrection was suggested, requiring syntacticand semantic processing for further disam-biguation.
The average number of correctionssuggested for these 49 was 4.57.
However,only an average of 1.69 candidates (including,because of the way the corpus was selected,all the right ones) appeared in QLFs satis-fying selectional restrictions; thus only 19%of the wrong candidates found their way intoany QLF.
If, in the absence of frequency in-formation, we take all candidates as equallylikely, then syntactic and semantic processingreduced the average ntropy from 1.92 to 0.54,removing 72% of the uncertainty (see Carter,1987, for a discussion of why entropy is thebest measure to use in contexts like this).When many QLFs are produced for a sen-tence, CLARE orders them according to a setof scoring functions encoding syntactic andsemantic preferences.
For the 49 multiple-candidate tokens, removing all but the best-scoring QLF(s) eliminated 7 (21%) of the 34wrong candidates surviving to the QLF stage;however, it also eliminated 5 (10~) of theright candidates.
It is expected that futuredevelopment of the scoring functions will fur-ther improve these figures, which are summa-rized in Table 1.The times taken to parse lattices containingmultiple spelling candidates reflect the char-acteristics of CLARE's parser, which uses a\ ]64Stage Right Wrong Averagecand's cand's numberSuggested 175 4.57 4949 In any QLF 34 1.69In best-scoring 44 27 1.45QLF(s)Table 1: Correction candidates for the 49multiple-candidate tokensbacktracking, left-corner algorithm and storeswell-formed constituents so as to avoid repeat-ing work where possible.
In general, when aproblem token appears late in the sentenceand/or when several candidate corrections axesyntactically plausible, the lattice approach isseveral times faster than processing the al-ternative strings separately (which tends tobe very time-consuming).
When the problemtoken occurs early and has only one plausi-ble correction, the two methods are about thesame speed.For example, in one case, a corrupted to-ken with 13 candidate corrections occurredin sixth position in an eight-word sentence.Parsing the resulting lattice was three timesfaster than parsing each alternative full stringseparately.
The lattice representation avoidedrepetition of work on the first six words, tIow-ever, in another case, where the corruptedtoken occurred second in an eight-word sen-tence, and had six candidates, only one ofwhich was syntactically plausible, the latticerepresentation was no faster, as the incorrectcandidates in five of the strings led to theparse being abandoned early.An analogous experiment was carried outwith 500 sentences from the same corpuswhich CLARE could not parse.
131 of thesentences, with average length 7.39 words, suf-fered the introduction of errors.
Of these, onlyseven (5%) received a parse.
Four of the sevenreceived no sortally valid QLFs, leaving onlythree (2%) "false positives".
This low figureis consistent with the results from the origi-naJly parseable sentence set; nine out of theten corruptions into known words in that ex-periment led to parse failure, and only 19%of wrong suggested candidates led to a sor-tal lyval id QLF.
If, as those figures suggest,the replacement of one word by another onlyrarely maps one sentence inside coverage toanother, then a corresponding replacement ona sentence outside coverage should yield some-thing within coverage ven more rarely, andthis does appear to be the case.6 CONCLUSIONSThese experimental results suggest hat gen-eral syntactic and semantic information is aneffective source of constraint for correctingtyping errors, and that a conceptually fairlysimple staged architecture, where word iden-tity and word boundary ambiguities are onlyresolved when the relevant knowledge is readyto be applied, can be acceptably efficient.
Thelattice representation also allows the systemto deal cleanly with word boundary uncer-tainty not caused by noise in the input.A fairly small vocabulary was used inthe experiment.
However, these words wereoriginally selected on the basis of frequencyof occurrence, so that expanding the lexi-con would involve introducing proportionatelyfewer short words than longer ones.
Mistypedshort words tend to be the ones with manycorrection candidates, so the complexity ofthe problem should grow less fast than mightbe expected with vocabulary size.
Further-more, more use could be made of statisticalinformation: relative frequency of occurrencecould be used as a criterion for pruning rela-tively unlikely correction candidates, as couldmore sophisticated statistics in the sugges-tion algorithm, along the lines of Kernighanet al(1990).
Phonological knowledge, to al-low competence errors to be tackled more di-rectly, would provide another useful source ofconstraint.165ACKNOWLEDGMENTSCLARE is being developed as part of a collab-orative project involving SRI International,British Aerospace, BP Research, British Tele-com, Cambridge University, the UK DefenceResearch Agency, and the UK Department ofTrade and Industry.REFERENCESAbe, M., Y. Oshima, K. Yuura and N. Take-ichi (1986) "A Kana-Kanji TranslationSystem for Non-Segmented Input Sen-tences Based on Syntactic and Seman-tic Analysis", Proceedings ofthe EleventhInternational Conference on Computa-tional Linguistics, pp 280-285.Alshawi, H. (1990) "Resolving Quasi LogicalForms", Computational Linguistics 16:3,pp.
133-144.Alshawi, H.
(ed.)
(1992) The Core LanguageEngine, M.I.T.
Press.van Berkel, B., and K. De Smedt (1988) "Tri-phone Analysis: A Combined Method forthe Correction of Orthographical and Ty-pographical Errors", Proceedings of theSecond Conference on Applied NaturalLanguage Processing, pp.
77-83.Carter, D.M.
(1987) "An Information-theoretic Analysis of Phonetic DictionaryAccess", Computer Speech and Language,2:1-11.Carter, D.M.
(1989) "Lexical Acquisition inthe Core Language Engine", Proceedingsof the Fourth Conference of the EuropeanChapter of the Association for Computa-tional Linguistics, pp 137-144.Emirkanian, L., and L.H.
Bouchard (1988)"Knowledge Integration in a Robustand Efficient Morpho-syntactic Analyserfor French", Proceedings of the TwelfthInternational Conference on Computa-tional Linguistics, pp 166-171.Futrelle, R.P., C.E.
Dunn, D.S.
Ellis andM.J.
Pescitelli, Jr. (1991) "Preprocessingand Lemcon Design for Parsing TechnicalText", Proceedings of the Second \[nter-national Workshop on Parsing Technolo-gies, pp.
31-40.Grosz, B. J., D. E. Appelt, P. Martin, andF.
Pereira (1987).
"TEAM: An Exper-iment in the Design of TransportableNatural-Language Interfaces".
ArtificialIntelligence 32: 173-243.Kernighan, M.D., K.W.
Church, and W.A.Gale (1990).
"A Spelling Correction Pro-gram Based on a Noisy Channel Model",Proceedings of the Thirteenth Interna-tional Conference on Computational Lin-guistics, pp 205-210.Koskenniemi, K. (1983) Two-level morphol-ogy: a general computational model forword-form recognition and production.University of Helsinki, Department ofGeneral Linguistics, Publications, No.
11.Pollock, J.J., and A. Zamora (1984) "Au-tomatic Spelling Correction in Scientificand Scholarly Text", Communications ofthe ACM, 27:4, pp 358-368.Veronis, J.
(1988) "Morphosyntactic Correc-tion in Natural Language Interfaces",Proceedings of the Twelfth InternationalConference on Computational Linguis-tics, pp 708-713.166
