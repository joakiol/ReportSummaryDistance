Software Support for Practical Grammar DevelopmentBran BOGURAEV, John CARROLL Ted BRISCOE, Claire GROVER ~Computer Laboratory, University of CambridgePembroke Street, Cambridge CB2 3QG, EnglandDepartment of Linguistics, University of LancasterBailrigg, Lancaster LA1 4YT, EnglandAbstractEven though progress in theoretical linguistics does not necessarilyrely on the construction of working programs, a large proportion ofcurrent research in syntactic theory is facilitated by suitablecomputational tools.
However, when natural language processingapplications eek to draw on the results from new developments intheories of grammar, not only the nature of the tools has to change,but they face the challenge of reconciling the seemingly contradictoryrequirements of notational perspicuity and efficiency of performance.In this paper, we present a comparison and an evaluation of a numberof software systems for grammar development, and argue that theyare inadequate as practical tools for building wide-coveragegrammars.
We discuss a number of factors characteristic of this task,demonstrate how they influence the design of a suitable softwareenvironment, and describe the implementation f a system which hassupported efficient development of a large computational grammar ofEnglish?1.
Tools for Grammar DevelopmentA number of researzh projects within the broad area of naturallanguage processing (NLP) and theoretical linguistics make use ofspecial purpose programs, which are beginning to be known under thegeneral term of "gm.nmar development environments" (GDEs).Particularly well known examples are reported in Kaplan (1983) (seealso Kiparsky, 1985), Shieber (1984), Evans (1985), Phillips andThompson (1985), Jensen et al (1986) and Karttunen (1986).
In allinstances the software packages cited above fall in the class ofcomputational tools used in theoretical (rather than applied) Projects.Thus Kaplan's Grammar-writer's Workbench is an implementation fa particular linguistic theory (Lexical Functional Grammar;, Kaplanand Bresnan, 1982); similarly, Evans' ProGram incorporated an earlyversion of Generalized Phrase Structure Grammar (GPSG, Gazdar andPullum, 1982), whilst PATR-II is a "virtual linguistic machine",developed by Shieber as a tool for experimenting with a variety ofsyntactic theories.These systems differ in their goals.
Particular implementations of atheory may be used for observing how theory-internal devices interactwith each other, or to maintain internal consistency as the grammar isbeing developed.
On the other hand, formalisms for encodinglinguistic information in a uniform way underpin effm~s to compareand evaluate alternative linguistic theories (Shieber, 1987).
Neithertype O f system is adequate to the task of grammar development on alarge scale or for incorporating such a grammar into a practical NLPsystem, due to factors such as efficiency of encoding (largelyneglected in such systems) or verbosity and redundancy of the formalnotation.
Within the frameworks of their aecomodating projects, theseare in no way inadequacies of the computational tools; still, theapplicability of the tools remains limited outside the strictly theoreticalconcem.developed at Yorktown Heights (Jensen et al, 1986).
Both are capableof impressive coverage and this is, to some extent, due to the moreflexible formalisms employed.
A common feattne of these formalismsis that they all fall prey to what Kaplan 0987) refers to as "theprocedural seduction" of computational linguistics: whatever the basisfor the notation is, it incorporates a handle for explicit interventioninto the interpretation f the grammar at hand.Sometimes the nature of the task for which the g~ammar is beingdeveloped justifies a form~J notation incolporating 'hooks' for explicitprocedures.
Thus a number of matchine translation (MT) projects~especially ones employing a ~ransfer strategy, make use of formatsystems for grammar specification, which, in addition to mappingsurface strings into con~esponding language structures, identifyoperations to be associated with nodes and / or subtrees (Vauquois &Boitet, 1985; Nagao et al, 1985).In general, the effects of the temptation to allow, for example, theEVALuation of arbitrary LISP expressions on the ares of the ATN orthe addition of "procedural programming facilities" to the rule-basedskeleton of 1BM's PLNLP have been discussed at length in the recentliterature addressing the issues of declarative formalisms from atheoretical perspective (see Shieber, 1986a, and references therein).However, from the point of view of developing a realistic grammarwith substantial coverage, the opening of the procedural 'back door',while perhaps useful fo: 'patching' the inadequacies in the linguistictheory during the exercise, can turn the whole process of grammardevelopment and maintenance into an orgea~isational ightmare, as sideeffects accumulate and ripple effects propagate.A ~parate problem with allowing procedural attachment into thegrammar formalism stems from the inevitable commitment to aparticular version of a particular theory.
Even wben a deliberate ffortis made to develop a flexible and general framework capable ofaccomodating a range of 'underlying' linguistic operations, such aframework is bound eventually to become inadequate, especially asmodem theories of grammar (strive to) become more declarative andtend to make reference to larger bodies of knowledge.
A case ha pointis the ARIANE system (Vauquois & Boitet, 1985): even though it wasdesigned as a completely integrated programmaing environment, withthe aim of enabling implementation of, and experimentation with,different linguistic theories, in reality the system has been unable tocope with radically new grammatical frameworks and computationalstrategies for text analysis.The question then arises of the optimal way of developing apractical grammar.
This paper will report on our experience inbuilding such a grammar, with a particular emphasis on how a numberof constraining factors have influenced the design and implementationof the software tools for supporting the linguist's work.2.
Design ConsiderationsOn the other hand, a number of syntactic formalisms have beenused to develop wide-coverage grammars for use in practical NLPsystems.
The best known of these is the Augmented TransitionNetwork formalism due to Woods (1970).
More recent examples arethe DIAGRAM grammar (Robinson, 1982) of SRI's TEAM naturallanguage interface (Grosz et al, 1987) and the PEG grammarCurrently with the IBM (UK) Science Centre.The work described here was supported by research grantGR/D/87321 from the UK Science and Engineering ResearchCouncil.For the last two yearn we have been engaged in a project aimed atsubstantial grammar development, as part of a larger effort to producean integrated system for wide-coverage morphological and syntacticanalysis of English.
The overall objectives of tile combined effort arcdescribed in a number of papers (see Russell et at., 1986; Phillips aridThompson, 1987, and Briscoe et al, 1987).
We aimed to achievecomprehensive coverage of English in two years, using only onelinguist and one programmer full-time; the complete natural anguagetoolkit was to be made available to the research community outsidethe immediate nviromnent whetx~ the grammar was being developed.Consequently, the software support for the linguist had to exhibit anumber of characteristics to encourage high productivity, Particularly54critical among these are e.flicieney of implementation, perspicuity ofrewesentatlon, ease of use and robt, stness of pofo~mance.Current theories of syntax have much to otter to practical systems;such theories, however, are under coustant development.
For veu?pragmatic reasons, a project like outs ought to exploit a developedtheory, For equally pragmatic reasons, it ought to be able to takeadvantage both of developments within the particular theory and of theevolving treatment of wuious linguislie phenomena.
The question oftim relationship between the thcoretic~d Rn'malism and the formalismadopted m implement a practical grammar based on that theory thenbecomes of ceutral iml;~)rtance.
For i~stance, it would bc inappropriateto adopt a direct imp!ementation of, say GPSG, since tire rate ofchange of the theory itself is likely to make such an implementationobsolete (or at least incapable of irmorporating subsequent linguisticanalyses) quite rapidly - .
file bdcf lifcspan of Ewms' ProGram is acase in point.
()nly when theou and grammar are beiug developed invery close collaboration, or even wifltin the same group -- - as in, forexample, the })ewlctt.-Packard NLP project, whose cornerstotm is thelinguistic framewolk of Head-Driven t'hrase Structm'e Grannnar(Proudian and Pollard, 1985; PollaN aud Sag, 1987) - -  could such ~ulapproach work.l}owever, itr mJ effint like om"a, it is of critical impmtauce to strikethe right balance between i)eit~g failhfu\[ to the spirit nf a tbeo~y midbeing uncommii:ted with respect o a particular vcrsien of it, as well asremaiuing tlexiNe within tile overall iianlcwoN of 'close' or relatedtheories.
Attempts to be too flexible, however, arc iikely to lead titsituations of wqich the PATII..II system is an example: the ability tomodel a wide t' rage of theoretical devices and mr(lyrical ti'amcworks ipenalised by its unsuitability "for any major attempt at buildingnatural-language rannnars" (Shicber, 1984:364).3o Our App~'ot4chFor a varict~/ of rea:;ons0 iuiollectual ~aid pragmatic, we chose tocarry out the ~:rammar devclopnmni within ihe li'amewofl~ of GPSG(see Bogm'aev, 1988, iir mine detail~;).
Ihiscoe et al (1987) discussfurther stone o:~' the major issues concerning tile dynamic intcractioubetween the vltl'ions rtfle ty0es lind constrait~ls i~ (;PSG a~d theirimpact on the mplememability of the fl~co~y presented iu Gazdar etal.
(1985).
Frnm flm practical pempcetiw o1' computational grammardevelopment, lberc are we impmtant COHCll.ISiOIIS.
In order to achieveimplementability, tire interpretation of the GPSG lonnaiism ~equires anumber of ms|dcfions.
In order to provide flexibility and expressivepower, the lbn~alism itself needs a nmnber of extensions.
In this light,the design of software support for gr~:urunar development becmnessimilar to the task of designing a special tin,pose, high level computerhnlgtlage, lollowed by an h~qfl~mentatkm of an interactiveprogramming oMiomnent for it.3,1 7he FormalismThe gmmma," specification formalism, presented in detail in Can'o\]let al (1988), i~; in flint a metaogrummaticN formalism which avoidstire direct implementatimr of one particular synlactie lheory.
Whileremaining close to the nf:~talion of GPSG, this formalism is nonethc!es:~capable of specifying a range of syntactic thcoxie.,', and grammars.
Thespecific choices during he design of such language have been heavilyinfluenced by tile desire to be moderately committed to a theoreticalframework without being unrteeessafily constrained wit(fin thatframework.
Fielding the fight balance places out' system half waybetween the extreme positions exemplified by ProGram and theGrammar..wliter~s Workbench, on the one hal(!, and PATR-II, on tireother.The recta-grammatical lbrmalism is designed to sttpl?ut a pariictdarmodel of grammar development, suggested by, for example, Kay(1985).
We maintain clear separation between a recta-grammar, whichis "the seat of linguistic universals" (Kay, 1985:276), and anequivalent (in the sense that it describes exactly the same language)object grammar, coupled directly to the l)alscr.
The process ofcompiling the fonner into the latter constitutes the core of otlr GI)E.A nnmber of iV(l' projects, also seeking substantial coverage, make aseemingly similar distinction between a source and objectgrammar-see, for instance, ARIANE's static and dynamic (orprocednraI) grammars (Vanquois & Boitet, 1985).
However, there aredifferences, tirsly in interpretation--the dynamic grammar largelyincorporates whatever execution strategy is employed lbr transfer--.andsecondly ill emphasis--a dynamic grammar is (necessarily) derivedmanually Ii'mn astatk: one.
Such efforts, then, do not have the notionof recta-grammar compilation, and consequently require lessfunctionality from their suPtx, rt environments.
We amplify this pointbelow.Tim scparatiou between source and object grammars i the key totwo of the eousiderations discussed in the previous section.
Bystopping short of embodying a particular theory, the fonnalism of therecta-grammar provides the linguist with an expressively flexible andpowerful device Ibr grammar writing.
By assuming a parser, whoseunderlying operation is based on a restrictive version of unification,the ohject gram,nat allows an efficient implementation.
Mornspecifically, the object grammar is made up of phrase structure ruleswith feature complexes as categories; parsing with it is based on flxed-arity, term unification.The recta-grammatical formalism is flexible and powerful.
Forexample, it incolporates rule types for explicitly specifying featurepropagation patterns, rather than 'hard-wiring' feature propagation i totile interpretion of Ihe rules (as in GPSG), arid provides a variety ofalternative rule formats, for example, PS er ID/LP rules, (non)-linear,(non)-lexieed metarules, and so forth.
The meta-grammar can bedesigned to be perspicuous, flexible aud expressively powerful withlittle regard lor issues of computational cmnplexity because thiscomplexity 'disappears' during compilation into the object grammar,1caving a well-defined, invariant and computationally tractable objectgrammar to be deployed at parse time.
The process of compilation isbased on ordered application of the various types of meta-grammaticalntle to a set of 'base' PS or ID rules.3.2 The EnvironmentThe questions of optimal software envirmm~ent fro' supportinggrammar development, particularly in a rule-based folanalism like ours,are very similar to the questions of interactive support for programdevelopmant.
A ~annber of special-pulpose tools have to be broughttogether in a lightly inzegrated 'sbeli' and organiscd around the corelinguistic 'engine', which performs the reduction (compilation) oflneta- into object grammar.
These tools must suport(1) rapid, incremental grammar development,(2) interactive granmar debugging, and(3) version maintenance and control.The grammar development environment incorporates a number ofmoduh's, oLganised round the compilation process.
In particular, tirecore functionality is provided by a morphological analyser, a parserlor ihe object grammar, and a generator.
Tire user interface consists ofa comntalld line inteqgreter, a number of special puqmse viewingmodules for recta-grammatical constructs, and a component fordisplaying parse trees on non-graphics terminals.
The system isdesigned to be completely portable and machine-independent, whichinfluenced tire deliberate choice not to use any advanced graphicsfacilities.
(These can incmporated if desired --- indeed the system hasbeen ported to both the Apple Macintosh and Xerox 1186workstation).3.2.1 Detecting OvergenerationThe need lor a pa~er fro' grammar development is uncontroversial;it assists thc linguist in finding gaps in grammatical coverage,checking the correctness of the syntactic description and weeding outspurious analyses.
Our parser provides facilities for viewing syntacticdescriptions in a variety of ways and batch parsing a growing corpusof examples to check the consistency of the developing rammar.
Lessobvious is the utility cf a generator.
Karttunen & Kay (1985:2950discuss the use of such a component o generally explore thepredictions made by a grammar concerning particular constructions.55However, their approach would not highlight the roles involved inovergcneration, particularly as the granlmar grows in size.
Ourgenerator allows the linguist to guide generation either implicitly, byspecifying rule-sets of interest, or explicitly, by directly manipulating(partial) syntax trees.
For example, if the focus of interest is relativeclauses, then she can request he GDE to ignore inappropriate rules(for example, those relating to coordination) and ask for automaticgeneration of examples with a specified maximum length whose rootnode is that appropriate to dominate a relative clause.
Alternatively,she can build a syntax tree interacfively by selecting the rule to applyfrom a menu of rule names generated automatically on specification ofthe next node to expand.
Combining the two approaches allowsautomatic generation, fcr example, of specific types of relative clause;generation after building the partial syntax tree:r,e iNP\[+wh\] S \ [SLASH NP\]would produce oNectrelative clansessuch as:who every cat l ikedwho k im l ikes e "Automatic generation is a more natural technique for aiding discoveryof ovcrgencration than parsing, because with the latter it is necessaryfor the linguist to guess where overgeneration may occur.3.2.2 Efficient Grammar CompilationThe major potential bottleneck in grammar development iscompilation, since changes to the grammar can only be fully evaluatedby parsing or generating relevant examples.
Complete grammarcompilation is increasingly time consuming as the grammar grews;however, it does not have to he performed that often, given the abilityto perlbrm incremental grammar compilation.
Tile term "incremental"here is taken to mean both as little as possible and as rarely aspossible.
By analogy with high-level anguages for rapid prototyping,where disruptions of the program development cycle ale avoided at allcosts (consider, for instance, asynchronous garbage collection in Lisp),the intrusion of the grammar compiler into the linguist's work is keptto a minimum.
Firstly, gran~mar compilation takes place 'on demand',so that the user need never worry about having to explicitly invoke it.Secondly, even though rules in large grammars tend to interact quiteclosely, it is rarely necessary to recompile the whole source every timean individual rule is changed.
The GDE software caches compiled datato minimise the effort required during recompilation, and, bymaintaining a model of the dynamic dependencies between a cluster ofinterconnected rules, it '.s able to ensure that the minimum amount ofcached data is discarded when the grammar is changed.
Aconsequence of this design is that individual components and rules atsource level can be declared, and redefined, in any order.
For example,the roleS - ->  NP, VP.nmy be defined before it is even decided which features make up Ss,NPs and Vps.
The user may postpone this decision until she actually~vants o use the ride for parsing a sentence.
This experimental style ofdcvclopmcnt parallels even turther that promoted by highly interactivesystems, since it allows easy experimentation with small fragments ofthe grammar, without requiring, for instance, compilation of thecomplete source or loading of all declarations.Incremental compilation is made possible by designing the grammarcompiler as a modular unit, comprising separate components for theinterpretation of each of the statement ypes (for example aliasdeclarations, feature propagation rules, or feature default statements) inthe source (meta-grammatical) l nguage.
This has made it possible tocombine these components into an integral package for efficientgrammar compilation, as well as m incorporate them into individualcommands, directly available to the linguist.3.2.3 Effective Grammar DebuggingThere are two further important consequences of our grammarcompilation design.
The first is the ability to monitor the effects ofgrammar expansion, by selectively filtering subsets of source grammarrules through specific compilation procedures.
So, for example, theeffects of a particular metarule can be assessed by applying it to aspecified subset of 'base' rules.
The second is the crucial capacity ofsource level debugging.
In a development model which distinguishesbetween meta- and object grammars, efficient work is only possible ifl%ulty grammar rules can be traced back to their original source in therecta-grammar.
In our system, the output of a single command isusually sufficiant to pinpoint an error in the source.
Nodes in parsetrees are labelled with the name of the gramnmr ule licensing thelocal tree rooted at that node.
Unlike some other systems, such asProGram, the name of an object grammar talc always uniquelyencodes the complete derivation path of the rule.
Thus, for example,the rule name VP/TAKES NP (PASSIVE/+) uniquely identifies therule derived from the application of the PASSIVE metarule to therule introducing vps taking a single NP complement which requires aPP 'agent' phrase (distinguished from the version without the PP by/+).
"Ihus faults in object grmnmar rules can easily be traced back totheir meta-grammatical source.The use of unique rule names enhances the ability to view all orparts of the recta-grammar, as well as the results of partialcompilation, along a number of dimensions, by means of patterns,with wild cards ranging over rule types and the names of rules.
Tofacilitate this type of grammar browsing, arbitrary view requests canbe constructed by using patterns eompositionally; thus in a particulargrammar of ours, the patteruVP/PHRASAL* (*) & =NULLrefers to the collection of VP rules introducing phrasal verbs whichhave had metarales applied to them resulting in the imroduction of thefeature NULL.
View requests may be further modified by indicatingthe level of detail required, i.e.
whether the rules should be shown intheir original source form, or partially or fully compiled.Viewing parse trees particularly facilitates ource level debugging.Displaying a tree from the perspective of role names associated withthe nodes, for example that resulting from parsing the phrase 'men andwomen':N/COORDICONJ/NA CONJ/NBmen and  womencan reveal whether ight or wrong rules get activated.
Fully displayingthe category structures on tree nodes (Figure 1) gives an indicationwhether feature propagation regimes have been specified correctly.Viewing the gross structure of the tree, in this case((men) (and women))suggests whether the parse is correct or not; furthermore, in the caseof multiple parses, nodes with common analyses can be factored out,thus helping localise the source of the error.Errors are only dealt with at source level; editing facilitiesincorporate knowledge about file syntax of all constructs in the metaogrammatical formalism The process of editing is integrated withextensive bookkeeping, which frees the grammar writer from the taskof explicitly maintaining version backups and checks for consistencyof the object grammar with respect o a particular meta-grmnmar.The command interpreter is sensitive to work context and iscapable, at any stage, to prompt for input appropriate to the currentstate in tile grammar development process.
For example, if the linguisthas parsed a sentence which resulted in three analyses, she can displaythe category associated with any node of any of the analyses by typing56N/COORDIN\[-POSS, +PLU, -PRO,SUBCAT NULL, PN -\]CON,}/N~N\[-POS~, +PLU, -PART, -PRO, +COUNT, CONJ NULL,.SUBCAT NULL, NFORM NORM, PER 3, PN- \ ]N\[-POSS, +PLU, -PART, -PRO, +COUNT, CONJ  AND,SUBCAT NULL, NFORM NORM, PER 3, PN -\]menN\[..-POSS, +PLU, -PART, -PRO, +COUNT, SUBCATNULL, NFORM NORM, PER 3, PN -\]~d\[SUBCAT AND,CONJN +\]womenN\[-POSS, +PLU, -.PART, -PRO, +COUNT, SUBCATNULL~ NFORM NORM, PER 3, PN -\]Figure 1.
Fully Detailed Parse Tree for 'men and women'.a single command lequiring two arguments.
Alternatively, by justtyping carria\[~e r turn after the command name, she can request heGDE command interpieter to prompt for values tbr these parametersby displaying menus of values only applicable to the current workcontext, for e>mmple> v iewRu les /Fu l l /CAtegory  .
..?
Catego~Paxse tree number (I to 3)?
IAppropr ia te  tree nodes are:i. N/COORD'I 2.
CONJ /NA 3. men4.
CONJ /NB 5. and 6. womenWhich (ine (give its number)?
1IN +, w -., BAR 0, SUBCAT NULL, PRD @544,NFOt~M @545, PER @546, PLU +, COUNT @547,CASt', @548, PN -, PRO -, PART @549, POSS -\]In this fashion, potentially highly-ambiguous commands, uch as vieware localised to the current context.
One of the unexpectedconsequences of this design is that it makes the system relativelyaccessible to inexperienced users and has made tcasible the use of thesystem tbr educational purposes.4.
Collc|usiol~The desig, of a software system for grammar development clearlydepeuds on 01e linguistic choices for, aud pragmatic requirements of,the NLP task.
It is not surprising timt a number of MT efforts,motivated by the need tbr st~bstantial coverage, have implementedtheir own GOEs.
Pethaps file most comprehensive of these is theMETAL-SHOP research environment of the METAL MT system(White, 1987), wltich includes facilities for selective viewing of parsetrees, tracing of the grammar rules as they are invoked by the parser,and editing the grammar at source.
The system makes, and conformsto, a clear-cat distinction between descriptive grammar rules andseparate mechanisms for their interpretation, tlowever, since theformal model used is titat of augmented phrase structure grammarwhich does not undergo auy compilation into object grammar, thefimetionality of the METAL-SHOP GDE, while adequate in thepractical context it is used in, remahts below that of the system wedescribe.Even though we have worked within a particular theoreticalfi'~wuework, thole are genoralisations to be made concerning practicalgrammar development within the framework of any of the currentsyntactic thee, ties.
In particular, it is important to realise that softwaresupport br :inch a task does not imply, arm should not be reduced to,tile provision of' a set of computational tools for e.g.
gtanlmar editing,inspocting th4; output from a parser, or comfortably interacting withthe system..Ln effozt of this scale crucially requi~es critical evaluationof the u,deriylng lingntstle theory, so that the right combination o\[pragmatically motivated and linguistically correct modifications andrevisions is ~bund and implementexl, We are not alone in our findings;our approach to making computational sense of GPSG is similar to the(unimplemenled) plvposals of Shieber (1986b) and Ristad (1987).The system described above is fully implemented and running on anumber of hardware configurations.
A wide-coverage grarmnarinvolving two woman/yeal~ of effort has been developed.
A set ofprograms in Common Lisp, together with a user manual (Carroll et al,1988) and description of our grammar (Grover et al, 1988) areavailable through the Artificial Intelligence Applications Institute inEdinburgh.ReferelteesBoguraev, B.
(1988) 'A natural language toolkit: reconciling theorywith practice' in Rohrer C. & U. Reyle (ed.
), Natural LanguageParsing and Linguistic Theories, Reidel, Dordl~echt, pp.
95-130.Briscoe, E., C. Grover, B. Boguraev & J.
Can'oll (1987) ~A formalismand environment for the development of a lalge grammar ofEnglish', Proceedings of lOth International Cot~ference on ArtilicialIntelligence, Milan, Italy, pp.
'103-'/08.Carroll, J., B. Boguraev, C. Grover & E. Briscoe (1988) The GrammarDevelopment Envb'onment: User Manual, Technical Report no.
127,Computer Imboratory, University of Cambridge.Evans, R. (1985) 'ProGram --- a development tool for GPSGgrammars', Linguistics, vol.
23(2), pp.
213-243.Gazdar, G., E. Klein, G. Pullum & I.
Sag (1985) Generalized PhraseStructure Gratmnar, Oxlbrd: Blackwell and Cambridge: HarvardUniversity Press.Grover, C., E. Briscoe, B. Boguraev & J. Carn311 (1988) The AlveyNatural Language Too& Project Grammar: A Wide-CoverageComputational Gratrmlar of English, Lancaster Working Papers inLinguistics, no.
47.Grosz, B., D. Appelt, M. Douglas & F. Pelcira (1987) "II~,AM: Anexperiment in the design of transportable natural languageinterfaces', Artificial Intelligence, vol.
32(2), pp.
173-244.Jensen, K., G. Heidom, S. Richardson & N. Haas (1986) PLNLP,PEG a~ul CRITIQUE: ?7tree contributions to computing in theht#nanities, Research Report RC 11841, Computer ScienceDepartment, IBM TJ Watson Research Center, Yorktown Heights,NY.Kaplan, R. & J. Bresnan (1982) 'Lexical-functional grammar: a formalsystem for graramatical representation' in J. Bresnan (ed.
), TheMental Representation of Grammatical Relations, MIT Press,Cambridge, MA, pp.
173-281.Kaplan, R. (1987) 'Three seductions of computationalpsycholinguistics' in P. Whiteloek et al (ed.
), Linguistic Theoryand Computer Applications, Academic Press, New York,pp.
149-188.Karttunen, L. (1986) 'D-PATR: A development envil~nment forunification-based grammars', Proceedings of l l th InternationalCongress on Computational Linguistics, Bonn, Germany, pp.
74-80.57Karttunen, L. & M. Kay (1985) 'Parsing in a free word orderlanguage' in Dowty, D., L. Karttunen & A. Zwicky (ed.
), NaturalLanguage Parsing, Cambridge University Press, Cambridge,pp.
279-306.Kay, M. (1985) 'Parsing in functional unification grammar' in Dowty,D., L. Karttunen & A. Zwicky (ed.
), Natural Language Parsing,Cambridge University Press, Cambridge, pp.
251-278.Kiparsky, C. (1985) LFG manual, Manuscript, XEROX Palo AltoResearch Center, Palo Alto, CA.Nagao, M., Tsujii, J.
& Nakamura, J.
(1985) 'The JapaneseGovernment Project for Machine Translation', ComputationalLinguistics, vol.
11(2), pp.
91-110,Phillips, J.
& H. Thompson (1985) 'GPSGP - -  A parser forgeneralised phrase structure grammars', Linguistics, vol.
23(2),pp.
245-261.Phillips, J.
& H. Thompson (1987) 'A parser and an appropriatecomputational representation for GPSG' in Klein, E. & N.Haddock (ed.
), Cognitive Science Working Papers, Centre forCognitive Science, University of Edinburgh.Pollard, C. & I.
Sag (1987) Head-driven Phrase Structure Grammar,CSLI Lecture Notes Number 12, CSLI, Stanford, CA.Proudian, D. & C. Pollard (1985) 'Parsing head-driven phrase structuregrammar', Proceedings of 23rd Annual Meeting of the Associationfor Computational Linguistics, Chicago, IL, pp.
167-171.Ristad, E. (1987) 'Revised generalized phrase structure grammar',Proceedings of 25th Annual Meeting of the Association forComputational Linguistics, Stanford, CA, pp.
243-250.Robinson, J.
(1982) 'DIAGRAM: A grammar for dialogues',Communications of the ACM, vol.
25(1), pp.
27-47.Russell, G., S. Pulman, G. Ritchie & A.
Black (1986) 'A dictionaryand morphological analyser for English', Proceedings of 11thInternational Congress on Computational Linguistics, Bonn,Germany, pp.
277-279.Shieber, S. (1984) 'Th~ design of a computer language for linguisticinformation', Proceedings of lOth International Congress onComputational Lingu:stics, Stanford, California, pp.
362-366.Shieber, S. (1986a) An Introduction to Unification-based Approachesto Grammar, CSLI Lecture Notes Number 4, CSLI, Stanford, CA,and University of Chicago Press.Shieber, S. (1986b) 'A simple reconstruction f GP3G', Proceedingsof l lth International Conference on Computational Linguistics,Bonn, Germany, pp.
211-215.Shieber, S. (1987) 'Separating linguistic analyses from linguistictheories' in P. Whitelock et al (ed.
), Linguistic Theory andComputer Applications, Academic Press, New York, pp.
1-36.Vauquois, B.
& Boitet, C. (1985) 'Automated Translation at GrenobleUniversity', Computational Linguistics, vol.
11(1), pp.
28-36.White, J.
(1987) 'The research environment ill the METAL project' inNirenburg, S.
(ed.
), Machine translation: Theoretical andmethodological issues, Cambridge University Press, Cambridge,UK, pp.
225-246.Woods, W. (1970) 'Transition etwork grammars for natural anguageanalysis', Communications of the ACM, vol.
13(8), pp.
591-606.58
