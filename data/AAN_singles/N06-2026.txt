Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 101?104,New York, June 2006. c?2006 Association for Computational LinguisticsAccurate Parsing of the Proposition BankGabriele MusilloDepts of Linguistics and Computer ScienceUniversity of Geneva2 Rue de Candolle1211 Geneva 4 Switzerlandmusillo4@etu.unige.chPaola MerloDepartment of LinguisticsUniversity of Geneva2 Rue de Candolle1211 Geneva 4 Switzerlandmerlo@lettres.unige.chAbstractWe integrate PropBank semantic role la-bels to an existing statistical parsingmodel producing richer output.
We showconclusive results on joint learning and in-ference of syntactic and semantic repre-sentations.1 IntroductionRecent successes in statistical syntactic parsingbased on supervised techniques trained on a largecorpus of syntactic trees (Collins, 1999; Charniak,2000; Henderson, 2003) have brought the hope thatthe same approach could be applied to the more am-bitious goal of recovering the propositional contentand the frame semantics of a sentence.
Moving to-wards a shallow semantic level of representation hasimmediate applications in question-answering andinformation extraction.
For example, an automaticflight reservation system processing the sentence Iwant to book a flight from Geneva to New York willneed to know that from Geneva indicates the originof the flight and to New York the destination.
(Gildea and Jurafsky, 2002) define this shallowsemantic task as a classification problem where thesemantic role to be assigned to each constituent isinferred on the basis of probability distributions ofsyntactic features extracted from parse trees.
Theyuse learning features such as phrase type, position,voice, and parse tree path.
Consider, for example,a sentence such as The authority dropped at mid-night Tuesday to $ 2.80 trillion (taken from section00 of PropBank (Palmer et al, 2005)).
The fact thatto $ 2.80 trillion receives a direction semantic labelis highly correlated to the fact that it is a Preposi-tional Phrase (PP), that it follows the verb dropped,a verb of change of state requiring an end point, thatthe verb is in the active voice, and that the PP is ina certain tree configuration with the governing verb.All the recent systems proposed for semantic role la-belling (SRL) follow this same assumption (CoNLL,2005).The assumption that syntactic distributions willbe predictive of semantic role assignments is basedon linking theory.
Linking theory assumes the ex-istence of a hierarchy of semantic roles which aremapped by default on a hierarchy of syntactic po-sitions.
It also shows that regular mappings fromthe semantic to the syntactic level can be positedeven for those verbs whose arguments can take sev-eral syntactic positions, such as psychological verbs,locatives, or datives, requiring a more complex the-ory.
(See (Hale and Keyser, 1993; Levin and Rappa-port Hovav, 1995) among many others.)
If the inter-nal semantics of a predicate determines the syntacticexpressions of constituents bearing a semantic role,it is then reasonable to expect that knowledge aboutsemantic roles in a sentence will be informative of itssyntactic structure, and that learning semantic rolelabels at the same time as parsing will be beneficialto parsing accuracy.We present work to test the hypothesis that a cur-rent statistical parser (Henderson, 2003) can outputrich information comprising both a parse tree andsemantic role labels robustly, that is without any sig-nificant degradation of the parser?s accuracy on theoriginal parsing task.
We achieve promising resultsboth on the simple parsing task, where the accuracyof the parser is measured on the standard Parsevalmeasures, and also on the parsing task where more101complex labels comprising both syntactic labels andsemantic roles are taken into account.These results have several consequences.
First,we show that it is possible to build a single inte-grated system successfully.
This is a meaningfulachievement, as a task combining semantic role la-belling and parsing is more complex than simplesyntactic parsing.
While the shallow semantics ofa constituent and its structural position are oftencorrelated, they sometimes diverge.
For example,some nominal temporal modifiers occupy an objectposition without being objects, like Tuesday in thePenn Treebank representation of the sentence above.The indirectness of the relation is also confirmed bythe difficulty in exploiting semantic information forparsing.
Previous attempts have not been success-ful.
(Klein and Manning, 2003) report a reductionin parsing accuracy of an unlexicalised PCFG from77.8% to 72.9% in using Penn Treebank function la-bels in training.
The two existing systems that usefunction labels sucessfully, either inherit Collins?modelling of the notion of complement (Gabbard,Kulick and Marcus, 2006) or model function labelsdirectly (Musillo and Merlo, 2005).
Furthermore,our results indicate that the proposed models are ro-bust.
To model our task accurately, additional pa-rameters must be estimated.
However, given the cur-rent limited availability of annotated treebanks, thismore complex task will have to be solved with thesame overall amount of data, aggravating the diffi-culty of estimating the model?s parameters due tosparse data.2 The Data and the Extended ParserIn this section we describe the augmentations to ourbase parsing models necessary to tackle the jointlearning of parse tree and semantic role labels.PropBank encodes propositional information byadding a layer of argument structure annotation tothe syntactic structures of the Penn Treebank (Mar-cus et al, 1993).
Verbal predicates in the Penn Tree-bank (PTB) receive a label REL and their argumentsare annotated with abstract semantic role labels A0-A5 or AA for those complements of the predicativeverb that are considered arguments while those com-plements of the verb labelled with a semantic func-tional label in the original PTB receive the com-posite semantic role label AM-X , where X standsfor labels such as LOC, TMP or ADV, for locative,temporal and adverbial modifiers respectively.
Prop-Bank uses two levels of granularity in its annotation,at least conceptually.
Arguments receiving labelsA0-A5 or AA do not express consistent semanticroles and are specific to a verb, while arguments re-ceiving an AM-X label are supposed to be adjuncts,and the roles they express are consistent across allverbs.To achieve the complex task of assigning seman-tic role labels while parsing, we use a family ofstate-of-the-art history-based statistical parsers, theSimple Synchrony Network (SSN) parsers (Hender-son, 2003), which use a form of left-corner parsestrategy to map parse trees to sequences of deriva-tion steps.
These parsers do not impose any a pri-ori independence assumptions, but instead smooththeir parameters by means of the novel SSN neu-ral network architecture.
This architecture is ca-pable of inducing a finite history representation ofan unbounded sequence of derivation steps, whichwe denote h(d1, .
.
.
, di?1).
The representationh(d1, .
.
.
, di?1) is computed from a set f of hand-crafted features of the derivation move di?1, andfrom a finite set D of recent history representationsh(d1, .
.
.
, dj), where j < i ?
1.
Because the his-tory representation computed for the move i ?
1is included in the inputs to the computation of therepresentation for the next move i, virtually any in-formation about the derivation history could flowfrom history representation to history representationand be used to estimate the probability of a deriva-tion move.
In our experiments, the set D of ear-lier history representations is modified to yield amodel that is sensitive to regularities in structurallydefined sequences of nodes bearing semantic rolelabels, within and across constituents.
For moreinformation on this technique to capture structuraldomains, see (Musillo and Merlo, 2005) where thetechnique was applied to function parsing.
Giventhe hidden history representation h(d1, ?
?
?
, di?1) ofa derivation, a normalized exponential output func-tion is computed by the SSNs to estimate a proba-bility distribution over the possible next derivationmoves di.To exploit the intuition that semantic role labelsare predictive of syntactic structure, we must pro-102vide semantic role information as early as possibleto the parser.
Extending a technique presented in(Klein and Manning, 2003) and adopted in (Merloand Musillo, 2005) for function labels with state-of-the-art results, we split some part-of-speech tagsinto tags marked with AM-X semantic role labels.As a result, 240 new POS tags were introduced topartition the original tag set which consisted of 45tags.
Our augmented model has a total of 613 non-terminals to represent both the PTB and PropBanklabels, instead of the 33 of the original SSN parser.The 580 newly introduced labels consist of a stan-dard PTB label followed by one or more PropBanksemantic roles, such as PP-AM-TMP or NP-A0-A1.These augmented tags and the new non-terminalsare included in the set f , and will influence bottom-up projection of structure directly.These newly introduced fine-grained labels frag-ment our PropBank data.
To alleviate this problem,we enlarge the set f with two additional binary fea-tures.
One feature decides whether a given preter-minal or nonterminal label is a semantic role labelbelonging to the set comprising the labels A0-A5and AA.
The other feature indicates if a given la-bel is a semantic role label of type AM-X , or oth-erwise.
These features allow the SSN to generalisein several ways.
All the constituents bearing an A0-A5 and AA labels will have a common feature.
Thesame will be true for all nodes bearing an AM-X la-bel.
Thus, the SSN can generalise across these twotypes of labels.
Finally, all constituents that do notbear any label will now constitute a class, the classof the nodes for which these two features are false.3 Experiments and DiscussionOur extended semantic role SSN parser was trainedon sections 2-21 and validated on section 24 fromthe PropBank.
Testing data are section 23 from theCoNLL-2005 shared task (Carreras and Marquez,2005).We perform two different evaluations on ourmodel trained on PropBank data.
We distinguish be-tween two parsing tasks: the PropBank parsing taskand the PTB parsing task.
To evaluate the formerparsing task, we compute the standard Parseval mea-sures of labelled recall and precision of constituents,taking into account not only the 33 original labels,but also the newly introduced PropBank labels.
Thisevaluation gives us an indication of how accuratelyand exhaustively we can recover this richer set ofnon-terminal labels.
The results, computed on thetesting data set from the PropBank, are shown in thePropBank column of Table 1, first line.
To evaluatethe PTB task, we ignore the set of PropBank seman-tic role labels that our model assigns to constituents(PTB column of Table 1, first line to be compared tothe third line of the same column).To our knowledge, no results have yet been pub-lished on parsing the PropBank.1 Accordingly, itis not possible to draw a straightforward quantita-tive comparison between our PropBank SSN parserand other PropBank parsers.
However, state-of-the-art semantic role labelling systems (CoNLL, 2005)use parse trees output by state-of-the-art parsers(Collins, 1999; Charniak, 2000), both for trainingand testing, and return partial trees annotated withsemantic role labels.
An indirect way of compar-ing our parser with semantic role labellers suggestsitself.
2 We merge the partial trees output by a se-mantic role labeller with the output of the parser onwhich it was trained, and compute PropBank parsingperformance measures on the resulting parse trees.The third line, PropBank column of Table 1 reportssuch measures summarised for the five best seman-tic role labelling systems (Punyakanok et al, 2005b;Haghighi et al, 2005; Pradhan et al, 2005; Mar-quez et al, 2005; Surdeanu and Turmo, 2005) inthe CoNLL 2005 shared task.
These systems alluse (Charniak, 2000)?s parse trees both for train-ing and testing, as well as various other informationsources including sets of n-best parse trees, chunks,or named entities.
Thus, the partial trees output bythese systems were merged with the parse trees re-turned by Charniak?s parser (second line, PropBankcolumn).3These results jointly confirm our initial hypothe-1(Shen and Joshi, 2005) use PropBank labels to extractLTAG spinal trees to train an incremental LTAG parser, but theydo not parse PropBank.
Their results on the PTB are not di-rectly comparable to ours as calculated on dependecy relationsand obtained using gold POS.2Current work aims at extending our parser to recovering theargument structure for each verb, supporting a direct compari-son to semantic role labellers.3Because of differences in tokenisations, we retain only2280 sentences out of the original 2416.103PTB PropBankSSN+Roles model 89.0 82.8CoNLL five best - 83.3?84.1Henderson 03 SSN 89.1 -Table 1: Percentage F-measure of our SSN parser onPTB and PropBank parsing, compared to the origi-nal SSN parser and to the best CoNLL 2005 SR la-bellers.sis.
The performance on the parsing task (PTB col-umn) does not appreciably deteriorate compared toa current state-of-the-art parser, even if our learnercan output a much richer set of labels, and there-fore solves a considerably more complex problem,suggesting that the relationship between syntacticPTB parsing and semantic PropBank parsing is strictenough that an integrated approach to the problemof semantic role labelling is beneficial.
Moreover,the results indicate that we can perform the morecomplex PropBank parsing task at levels of accuracycomparable to those achieved by the best seman-tic role labellers (PropBank column).
This indicatesthat the model is robust, as it has been extended to aricher set of labels successfully, without increase intraining data.
In fact, the limited availability of datais increased further by the high variability of the ar-gumental labels A0-A5 whose semantics is specificto a given verb or a given verb sense.Methodologically, these initial results on a jointsolution to parsing and semantic role labelling pro-vide the first direct test of whether parsing is neces-sary for semantic role labelling (Gildea and Palmer,2002; Punyakanok et al, 2005a).
Comparing se-mantic role labelling based on chunked input to thebetter semantic role labels retrieved based on parsedtrees, (Gildea and Palmer, 2002) conclude that pars-ing is necessary.
In an extensive experimental in-vestigation of the different learning stages usuallyinvolved in semantic role labelling, (Punyakanok etal., 2005a) find instead that sophisticated chunkingcan achieve state-of-the-art results.
Neither of thesepieces of work actually used a parser to do SRL.Their investigation was therefore limited to estab-lishing the usefulness of syntactic features for theSRL task.
Our results do not yet indicate that pars-ing is beneficial to SRL, but they show that the jointtask can be performed successfully.Acknowledgements We thank the Swiss NSF for sup-porting this research under grant number 101411-105286/1,James Henderson and Ivan Titov for sharing their SSN software,and Xavier Carreras for providing the CoNLL-2005 data.ReferencesX.
Carreras and L. Marquez.
2005.
Introduction to the CoNLL-2005 shared task: Semantic role labeling.
Procs of CoNLL-2005.E.
Charniak.
2000.
A maximum-entropy-inspired parser.Procs of NAACL?00, pages 132?139, Seattle, WA.M.
Collins.
1999.
Head-Driven Statistical Models for NaturalLanguage Parsing.
Ph.D. thesis, Pennsylvania.CoNLL.
2005.
Ninth Conference on Computational NaturalLanguage Learning (CoNLL-2005), Ann Arbor, MI.R.
Gabbard, S. Kulick and M. Marcus 2006.
Fully parsing thePenn Treebank.
Procs of NAACL?06, New York, NY.D.
Gildea and D. Jurafsky.
2002.
Automatic labeling of seman-tic roles.
Computational Linguistics, 28(3):245?288.D.
Gildea and M. Palmer.
2002.
The necessity of parsing forpredicate argument recognition.
Procs of ACL 2002, 239?246, Philadelphia, PA.A.
Haghighi, K. Toutanova, and C. Manning.
2005.
A jointmodel for semantic role labeling.
Procs of CoNLL-2005,Ann Arbor, MI.K.
Hale and J. Keyser.
1993.
On argument structure and thelexical representation of syntactic relations.
In K. Hale andJ.
Keyser, editors, The View from Building 20, 53?110.
MITPress.J.
Henderson.
2003.
Inducing history representationsfor broad-coverage statistical parsing.
Procs of NAACL-HLT?03, 103?110, Edmonton, Canada.D.
Klein and C. Manning.
2003.
Accurate unlexicalized pars-ing.
Procs of ACL?03, 423?430, Sapporo, Japan.B.
Levin and M. Rappaport Hovav.
1995.
Unaccusativity.
MITPress, Cambridge, MA.M.
Marcus, B. Santorini, and M.A.
Marcinkiewicz.
1993.Building a large annotated corpus of English: the Penn Tree-bank.
Computational Linguistics, 19:313?330.L.
Marquez, P. Comas, J. Gimenez, and N. Catala.
2005.
Se-mantic role labeling as sequential tagging.
Procs of CoNLL-2005.P.
Merlo and G. Musillo.
2005.
Accurate function parsing.Procs of HLT/EMNLP 2005, 620?627, Vancouver, Canada.G.Musillo and P. Merlo.
2005.
Lexical and structural biasesfor function parsing.
Procs of IWPT?05, 83?92, Vancouver,Canada.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
The PropositionBank: An annotated corpus of semantic roles.
Computa-tional Linguistics, 31:71?105.S.
Pradhan, K. Hacioglu, W. Ward, J. Martin, and D. Jurafsky.2005.
Semantic role chunking combining complementarysyntactic views.
Procs of CoNLL-2005.V.
Punyakanok, D. Roth, and W. Yih.
2005a.
The necessityof syntactic parsing for semantic role labeling.
Procs of IJ-CAI?05, Edinburgh, UK.V.
Punyakanok, P. Koomen, D. Roth, and W. Yih.
2005b.
Gen-eralized inference with multiple semantic role labeling sys-tems.
Procs of CoNLL-2005.L.Shen and A. Joshi.
2005.
Incremental LTAG parsing.
Procsof HLT/EMNLP 2005, Vancouver, Canada.M.
Surdeanu and J. Turmo.
2005.
Semantic role labeling usingcomplete syntactic analysis.
Procs of CoNLL-2005.104
