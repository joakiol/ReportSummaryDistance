Reasoning about Quantities in Natural LanguageSubhro RoyUniversity of Illinois,Urbana Champaignsroy9@illinois.eduTim VieiraJohns Hopkins Universitytim.f.vieira@gmail.comDan RothUniversity of Illinois,Urbana Champaigndanr@illinois.eduAbstractLittle work from the Natural LanguageProcessing community has targeted therole of quantities in Natural LanguageUnderstanding.
This paper takes some keysteps towards facilitating reasoning aboutquantities expressed in natural language.We investigate two different tasks ofnumerical reasoning.
First, we considerQuantity Entailment, a new task formulatedto understand the role of quantities ingeneral textual inference tasks.
Second,we consider the problem of automaticallyunderstanding and solving elementary schoolmath word problems.
In order to addressthese quantitative reasoning problems we firstdevelop a computational approach which weshow to successfully recognize and normalizetextual expressions of quantities.
We thenuse these capabilities to further developalgorithms to assist reasoning in the contextof the aforementioned tasks.1 IntroductionEvery day, newspaper articles report statistics topresent an objective assessment of the situationsthey describe.
From election results, number ofcasualties in accidents, to changes in stock prices,textual representations of quantities are extremelyimportant in communicating accurate information.However, relatively little work in Natural LanguageProcessing has analyzed the use of quantities intext.
Even in areas where we have relatively maturesolutions, like search, we fail to deal with quantities;for example, one cannot search the financial mediafor ?transactions in the 1-2 million pounds range.
?Language understanding often requires the abilityto reason with respect to quantities.
Consider, forexample, the following textual inference, which wepresent as Textual Entailment query.
RecognizingTextual Entailment (RTE) (Dagan et al., 2013)has become a common way to formulate textualinference and we follow this trend.
RTE is the taskof determining whether the meaning of a given textpassage T entails that of a hypothesis H.Example 1T:A bomb in a Hebrew University cafeteria killed fiveAmericans and four Israelis.H:A bombing at Hebrew University in Jerusalemkilled nine people, including five Americans.Here, we need to identify the quantities ?fiveAmericans?
and ?four Israelis?, as well as use thefact that ?Americans?
and ?Israelis?
are ?people?.A different flavour of numeric reasoning isrequired in math word problems.
For example, inExample 2Ryan has 72 marbles and 17 blocks.
If he shares themarbles among 9 friends, how many marbles doeseach friend get?one has to determine the relevant quantities inthe question.
Here, the number of blocks in Ryan?spossession has no bearing on the answer.
The secondchallenge is to determine the relevant mathematicaloperation from the context.In this paper, we describe some key stepsnecessary to facilitate reasoning about quantities innatural language text.
We first describe a systemdeveloped to recognize quantities in free form text,infer units associated with them and convert them to1Transactions of the Association for Computational Linguistics, vol.
3, pp.
1?13, 2015.
Action Editors: Johan Bos, Lillian Lee.Submission batch: 6/2014; Revision batch 9/2014; Published 1/2015.
c?2015 Association for Computational Linguistics.a standardized form.
For example, inExample 3About six and a half hours later , Mr. Armstrongopened the landing craft?s hatch.we would like to extract the number 6.5, thecorresponding unit, ?hour?, and also determine thatthe quantity describes an approximate figure, notan exact one.
One of the difficulties is that anynoun or noun phrase can be a unit, and inferringthem requires analyzing contextual cues and localsentence structure.
As we show, in some casesdeeper NLP techniques are required to support that.We then develop a reasoning framework forquantities that we believe can play an importantrole in general purpose textual inference.
Isolatingthe quantity reasoning component of the RTE task,we define Quantity Entailment (QE) - the taskof determining whether a given quantity can beinferred from a given text snippet, and then describeour approach towards solving it.
This allows us tosupport the inference presented in Example 1.As an additional evaluation, we also show theeffectiveness of our system on an application of QE,a search for ranges of currency values.
Given a queryrange, say from 1 million USD to 3 million USD, wewant to find all mentions of money with values inthis range.
Using standard search engine technologyto query all values in the range, in the various formsthey could be expressed, is not feasible.
Instead,we use our proposed approach to extract monetarymentions from text and normalize them, and then weuse QE to verify them against the query.We next develop a reasoning framework forelementary school math word problems.
Ourreasoner makes use of several classifiers to detectdifferent properties of a word problem, and finallycombines the decisions of individual classifiers toobtain the correct answer.We develop and annotate datasets1 for evaluation,and show that our approach can handle theaforementioned reasoning tasks quite well.The next section presents some related workon quantities and reasoning.
We then formallydefine a quantity and describe our knowledge1The datasets are available for download athttp://cogcomp.cs.illinois.edu/page/resource view/95.The related software is available athttp://cogcomp.cs.illinois.edu/page/software view/Quantifier.representation.
The following sections describequantities extraction and standardization.
We nextpresent the formulation of Quantity Entailment,and describe our reasoning framework for it.
Wethen describe our approach towards understandingelementary school math problems, and concludewith experimental evaluation.2 Related WorkThe importance of reasoning about quantitieshas been recognized and studied from multipleperspectives.
Quantities have been recognized as animportant part of a textual entailment system (deMarneffe et al., 2008; Maccartney and Manning,2008; Garoufi, 2007; Sammons et al., 2010), and(de Marneffe et al., 2008) claims that discrepanciesin numbers are a common source of contradictionsin natural language text.
The authors describe acorpus of real-life contradictory pairs from multiplesources such as Wikipedia and Google News inwhich they found that 29% of the contradictionswere due to numeric discrepancies.
In addition, theyanalyzed several Textual Entailment datasets (Daganet al., 2006) and found that numeric contradictionsconstitute 8.8% of contradictory entailment pairs.Quantitative reasoning has also been addressedfrom the perspective of formal semantics.
Montague(Montague, 1973) investigates identity ambiguitiesin sentences, e.g., whether ?The temperature isninety but it is rising.?
implies ?ninety is rising?.His solution suggests that ?temperature?
should betreated as a concept, and ?temperature is ninety?asserts an attribute of temperature at a particularinstance of time, and not an attribute of theconcept ?temperature?.
Reasoning about quantitiesoften depends on reasoning about monotonicity.The role of monotonicity in NL reasoning hasbeen described in (Barwise and Cooper, 1981).The authors categorize noun phrases as upward ordownward monotonic, and also detect constructswhere monotonicity depends on context.
Thelarge role of monotonicity in reasoning motivatedattempts to reason directly at the surface level(Purdy, 1991), rather than converting first to logicalforms.
Our approach advocates this direction too.
(Kuehne, 2004a) investigates the various casesin which physical quantities are represented2in descriptions of physical processes.
Later, in(Kuehne, 2004b), a system to extract QualitativeProcess Theory (Forbus, 1984) representationsis implemented for a controlled subset of theEnglish language.
Other works that are relevant toquantities, such as work on the plural semantics ofnoun phrases (Schwertel, 2003), were also done oncontrolled English.
While these approaches do notscale to unrestricted English, they have influencedthe quantity representation that we use.The importance of quantities has also beenrecognized in some application areas.
For example,(Banerjee et al., 2009) investigates ranking ofsearch results involving quantities.
In order to detectquantities in text, they use a rule based system,comprising 150 rules.
However, the rules werespecific to the queries used, and do not extend wellto unrestricted English.
In contrast, our system isdesigned to detect any quantity mentioned in naturallanguage text, as well as infer the unit associatedwith it.
There has also been some work on quantitiesin specific domains, such as the temporal domain,the most significant being the TimeML project(Pustejovsky et al., 2003; Saur et al., 2005; Pratt-Hartmann, 2005; Do et al., 2012).
The problemof automatically solving math word problems hasalso been investigated.
Approaches range from usingrule-based methods (Bobrow, 1964; Lev et al., 2004;Mukherjee and Garain, 2008) to recent templatematching techniques (Kushman et al., 2014) .3 Representing QuantitiesIn general, quantity refers to anything whichis measurable.
Our quantities representation isinfluenced by the one proposed in (Forbus, 1984)but we propose a simpler version of their QualitativeProcess theory:Definition (Quantity-Value Representation) InQuantity-Value Representation (QVR), a quantity isrepresented as a triple (v, u, c), where constituentsin the triple correspond, respectively, to:1.
Value: a numeric value, range, or set of valueswhich measure the aspect, e.g.
more than 500,one or two, thousands, March 18, 1986.
Thevalue can also be described via symbolic value(e.g., ?below the freezing point?).
We do notstore surface forms explicitly, but convert themto a set or range.
For example, ?more than 500?is stored as the range (500,+?).
Details ofthese conversions are given in Section 4.2.2.
Units: a noun phrase that describes what thevalue is associated with.
e.g., inches, minutes,bananas.
The phrase ?US soldiers?
in thephrase ?Five US soldiers?
is a unit.3.
Change: specifies how the parameter ischanging, e.g., increasing.
This constituentoften serves as an indication of whether or notthe value is relative to another.
For example,?She will receive an [additional 50 cents perhour]?, ?The stock [increased 10 percent]?,?Jim has [5 balls more] than Tim?.4 Extraction of QuantitiesIn this section we describe the first component of ourapproach, that of identifying quantities and units intext and standardizing their representation.
We use aa two step approach to extract quantities from freeform text.1.
Segmentation This step takes raw text andfinds segments of contiguous text whichdescribe quantities.2.
Standardization Using the phrases extractedin the previous step, we derive the QVR.An overview of our method is given in Algorithm 1.Algorithm 1 QuantityExtraction( T )Input: Text TOutput: Set of Quantity-value triples extractedfrom T1: Q?
?2: S ?
Segmentation( T )3: for all segment s ?
S do4: q ?
Standardization( s )5: if unit of q not inferred then6: q ?
InferUnitFromSemantics( q, s, T )7: end if8: Q?
Q ?
{q}9: end for10: return QWe model the segmentation step as a sequencesegmentation task because quantities often appear3as segments of contiguous text.
We adapt andcompare two approaches that were found successfulin previous sequential segmentation work in NLP:1.
A Semi-CRF model (Sarawagi and Cohen,2004), trained using a structured Perceptronalgorithm (Collins, 2002), with ParameterAveraging (Freund and Schapire, 1998).2.
A bank of classifiers approach (Punyakanokand Roth, 2001) that we retrain with a new setof features.The same feature set was used for bothapproaches.
Despite the additional expressive powerof CRFs, we found that the bank of classifiers(which is followed by a simple and tractableinference step) performs better for our task, and alsorequires significantly less computation time.4.1 FeaturesFor each token xi in the input sequence we extractthe following features:1.
Word class features: xi appears in a listof known scientific units (e.g., meters,Fahrenheit), written numbers (e.g., two,fifteen), names of a months, day of the week,miscellaneous temporal words (e.g.
today,tomorrow), currency units, etc.2.
Character-based: xi contains a digit, is alldigits, has a suffix (st,nd,rd,th).3.
Part of speech tags: we use the Illinois POSTagger (Roth and Zelenko, 1998).4.
Most of the features were generated from awindow of [?3, 3] around the current word.Additional features were generated from theseby conjoining them with offset values from thecurrent word.4.2 Mapping Text Segments into QVRWe develop a rule-based standardization step, thatis informed, as needed, by deeper NL processing,including semantic role labeling (SRL, (Palmer etal., 2010)) and Co-reference resolution.
Some keysteps of this procedure are as follows:1.
Convert written numbers to floating point: e.g.,three thousand five hundred twenty?
3520.02.
Convert dates to an internal date type: e.g.,March 18th?
Date(03/18/XXXX)3.
Replace known names for ranges: e.g., teenage?
[13, 19] years-old.4.
Convert all scientific units to a standard baseunit: e.g., 1 mile?
1609.344 meters.5.
Replace non-scientific units with WordNetsynsets6.
Rewrite known units to a standard unit: e.g.,USD, US$, dollars ?
US$.7.
Standardize changing quantity: e.g.,?additional 10 books??
+10 [book].8.
Extract bounds: we use a list of phrases, such as?more than?, ?less than?, ?roughly?, ?nearly?.By default, if a bound keyword is not presentwe assume the bound is ?=?.9.
Modify value using bounds : We convert valueswhich have a bound to a range of values.Scalar implicature is taken into considerationhere.
Consider the sentence ?John bought 10books.
?, although it can be interpreted thatbuying 5 books is a corollary of buying 10,in this case, we make the assumption that 5books were not purchased.
See section 5.2 fora discussion on the subject.We use the following rules, where v is the valueextracted before using bound information.?
?
v ?
(?
?, v], similarly for ?, <,>.?
= v ?
{v}?
?
v ?
[v ?
c.v, v + c.v], we use c = 0.2.4.3 Extraction of UnitsIn most cases, the units related to the numericvalues appear adjacent to them.
For example, inthe sentence ?There are two books on the table?,the unit ?book?
follows ?two?.
The sequencesegmentation groups these words together, fromwhich it is easy to extract the unit.
However, in somecases, a better understanding of the text is needed toinfer the units.
Consider the following example:4Example 4A report from UNAIDS, the Joint United NationsProgram on HIV/AIDS, released on Tuesday, showsthe number of adults and children with HIV/AIDSreached 39.4 million in 2004.Here, we need to know that ?39.4 million?refers to ?the number of adults and children withHIV/AIDS?.
Also, in:Example 5The number of member nations was 80 in 2000, andthen it increased to 95.we need to know that the pronoun ?it?
refers to ?thenumber of member nations?.We employ a sequential process in ourstandardization.
In case the first step describedabove fails to extract units, we make use of deeperprocessing of the sentence to accomplish that (seean evaluation of the contribution of this in theexperimental section).
These steps are denotedby the function InferUnitFromSemantics() inAlgorithm 1.
We apply coreference resolutionto identify pronoun referents and then apply aSemantic Role Labeler, to recognize which termsare associated with the quantity, and can be potentialunits.
In the case of example 4, the SRL tells us thatfor the verb ?reached?, the associated subject is?the number of adults and children with HIV/AIDS?and the object is the mention ?39.4 million?.
Hence,we conclude that the subject can be a candidatefor the unit of ?39.4 million?.
For the purpose ofentailment, we keep the entire set of possible wordchunks, which are linked by the SRL to our quantitymention, as candidate units.Since most units are found in positions adjacentto the numeric mention, we optimize on runtimeby applying the SRL and coreference resolveronly when the segmented chunk does not haveadequate information to infer the unit.
We usethe Illinois Coreference Resolver (Bengtson andRoth, 2008; Chang et al., 2013) and the IllinoisSRL (Punyakanok et al., 2008), for coreference andsemantic role labelling, respectively.5 Quantity EntailmentIn this section we describe our approach toquantitative reasoning from natural language text.We first formulate the task of Quantity Entailment,and then describe our reasoning framework.Definition (Quantity Entailment) Given a textpassage T and a Quantity-Value triple h(ch, vh, uh),Quantity Entailment is a 3-way decision problem:1. entails: there exists a quantity in T whichentails h.2.
contradicts: no quantity in T entails h, butthere is a quantity in T which contradicts h.3.
no relation: there exists no quantity in T,which is comparable with h.The need to identify sub-problems of textualinference, in the context of the RTE task, has beenmotivated by (Sammons et al., 2010).
QuantityEntailment can be considered as one such step.Since we envision that our QE module will beone module in an RTE system, we expect thatthe RTE system will provide it with some controlinformation.
For example, it is often important toknow whether the quantity is mentioned in anupward or downward monotonic context.
Since weare evaluating our QE approach in isolation, wewill always assume upward monotonicity, whichis a lot more common.
Monotonicity has beenmodeled with some success in entailment systems(Maccartney and Manning, 2008), thus providinga clear and intuitive framework for incorporatingan inference resource like the Quantity Entailmentmodule into a full textual entailment system.5.1 Reasoning FrameworkOur Quantity Entailment process has two phases:Extraction and Reasoning.
In the Extraction Phase,we take a text passage T and extract Quantity-Value triples (value, units, change) from it.
In theReasoning phase, we apply a lightweight logicalinference procedure to the triples extracted from Tto check if h can be derived.There are two types of rules applied in theReasoning phase: Implicit Quantity Productions andQuantity Comparisons.
The combination of theserules provides good coverage for the QE task.5.1.1 Quantity ComparisonQuantity Comparison compares a quantity t :(vt, ut, ct) extracted from T and the quantity h :(vh, uh, ch) and decides whether h can be derivedvia some truth preserving transformation of t. There5are three possibilities: (t entails h), (t contradictsh), or (t has no relation with h).
The overviewis given in Alg.
2, which is designed under ourassumption that entailing quantities should respectupward monotonicity.
This requires monotonicityverification of both units and values.In order for a quantity to contradict orentail another, their units must be comparable.Determining the comparability of scientific unitsis direct since they form a closed set.
Comparingnon-scientific units is more involved.
The inferencerule used here is as follows: if the syntactic headsof the unit phrases match (i.e., there is an Is-Aor synonymy relation in either direction), thenthe phrases are comparable.
These comparisonsare encoded as a function comparableUnits(ut,uh), which returns true if the units ut and uh arecomparable, or else returns false.If the units are comparable, the direction ofmonotonicity (i.e., the direction of the Is-Arelation between the heads and the effects ofany relevant modifiers) is verified.
The functioncheckMonotonicityOfUnits(ut, uh) returns true, ifut is more specific than uh, false otherwise.To compute the Is-A and synonymy relationswe use WordNet (Miller et al., 1990), an ontologyof words which contains these relations.
We alsoaugment WordNet with two lists from Wikipedia(specifically, lists of Nationalities and Jobs).Next, we check whether the values of thequantities compared obey the monotonicityassumption; we say that vt is more specific thanvh if vt is a subset of vh.
(Note that vt and vhare both represented as sets and hence, checkingsubset relation is straightforward.)
For example,?more than 50?
?
?at least 10?.
This rule alsoapplies to dates, e.g.
?03/18/1986?
?
?March1986?.
Respecting scalar implicature, we assumethat ?5?
is subset of ?less than 10?, but not ?10?.Similar to the case of units, we use the functioncheckMonotonicityOfValues(vt, vh) which returnstrue, if vt is more specific than vh, and falseotherwise.A quantity which represents some form of changeof a quantity cannot be derived from a quantitywhich does not represent change and vice versa.We set ct = true if t denotes change in a quantity,otherwise we set ct = false.Algorithm 2 QuantityComparison( t, h )Input: Quantity-value triples t(vt, ut, ct) andh(vh, uh, ch)Output: Returns whether t entails, contradicts orhas no relation with h1: if ct 6= ch then2: return no relation3: end if4: if comparableUnits( ut, uh )= false then5: return no relation6: end if7: if checkMonotonicityOfUnits( ut, uh )= truethen8: if checkMonotonicityOfValues( vt, vh )=true then9: return entails10: end if11: end if12: return contradicts5.1.2 Implicit Quantity Production RulesThere are many relationships among quantitieswhich can be the source of implicit information.The following is an incomplete, but relatively broadcoverage list of common patterns:1.
Range may imply duration, e.g., ?John lived inMiami from 1980 to 2000?
implies that Johnlived in Miami for a duration of 20 years.2.
Compatible terms may be combined andabstracted.
The sentence ?I bought 3 bananas,2 oranges, and 1 apple?
implies that 6 fruitswere purchased.3.
Ratios can imply percentages.
The sentence ?9out of the 10 dentists interviewed recommendbrushing your teeth?
implies that 90% of thedentists interviewed recommend brushing.4.
Composition: Quantities and units maysometimes be composed.
Consider thefollowing examples, the phrase ?six Koreancouples?
means that there are 12 people; thephrase ?John gave six 30-minute speeches?implies that John spoke for 180 minutes.The rules used for producing implicit quantitiesemployed in our system are the following:6?
(a ratio b) if a is a percentage, then multiplyits value with the value of b to obtain a newquantity with the units of b.?
(a ratio b) if a is not percentage, divide itsvalue with the value of b to obtain a newquantity with the units of b.?
(a range b) take the difference of the twovalues to obtain a new quantity with theappropriate change of units, e.g., time-stampminus time-stamp results in units of time.Algorithm 3 QuantityEntailment( T, h )Input: Text T and a quantity-value triplesh(vh, uh, ch)Output: Returns whether T entails, contradicts orhas no relation with h1: Q?
QuantityExtraction( T )2: Q?
?
GenerateImplicitQuantities( Q )3: Q?
Q ?Q?4: contradict?
false5: for all quantity-value triple q ?
Q do6: if QuantityComparison( q, h )= entails then7: return entails8: end if9: if QuantityComparison( q, h )= contradictsthen10: contradict?
true11: end if12: end for13: if contradict= true then14: return contradicts15: else16: return no relation17: end if5.1.3 Lightweight Logical InferenceThe QE inference procedure simply applies eachof the implicit quantity production rules to theQuantity-Value triples extracted from the passageT, until no more quantities are produced.
Then itcompares each quantity t extracted from T with thequantity h, according to the quantity comparisonrules described in Algorithm 2.
If any quantity inT entails h, then ?entails?
is reported; if there isno quantity in T which can explain h, but thereexists one which contradicts h, then ?contradiction?is reported; otherwise ?no relation?
is reported.
Thecomplete approach to Quantity Entailment is givenin Algorithm 3.5.2 Scope of QE InferenceOur current QE procedure is limited inseveral ways.
In all cases, we attribute theselimitations to subtle and deeper languageunderstanding, which we delegate to the applicationmodule that will use our QE procedure as asubroutine.
Consider the following examples:T : Adam has exactly 100 dollars in the bank.H1 : Adam has 50 dollars in the bank.H2 : Adam?s bank balance is 50 dollars.Here, T implies H1 but not H2.
However for bothH1 and H2, QE will infer that ?50 dollars?
is acontradiction to sentence T, since it cannot makethe subtle distinction required here.T : Ten students passed the exam, but six studentsfailed it.H : At least eight students failed the exam.Here again, QE will only output that T implies?At least eight students?, despite the second part ofT .
QE reasons about the quantities, and there needsto be an application specific module that understandswhich quantity is related to the predicate ?failed?.There also exists limitations regarding inferenceswith respect to events that could occur over a periodof time.
In ?It was raining from 5 pm to 7 pm?
oneneeds to infer that ?It was raining at 6 pm?
although?6 pm?
is more specific than ?5 pm to 7 pm?.
Thereis a need to understand the role of associated verbsand entities, and the monotonicity of the passages toinfer the global entailment decision.
Some aspects ofthis problem is handled in the math word problemsin Section 6, but there is still a need to formalizethe role of associated predicates and its associationswith quantities in natural language.6 Solving Math Word ProblemsIn this section, we describe our approach towardsautomatically understanding and solving elementaryschool math word problems.
We considered wordproblems having the following properties:1.
The question mentions two or three quantities.2.
The answer can be computed by choosing7two quantities from the question and applyingone of the four basic operations (addition,subtraction, multiplication, division) on them.We use a cascade of classifiers approach for thisproblem.
We develop the following three classifiersto detect different properties of the word problem.1.
Quantity Pair Classifier This classifier isrelevant only for problems mentioning threequantities in the question text.
The input tothe classifier is the text of the question Qof the problem, and the quantities q1, q2, q3extracted from the question Q.
The outputis the relevant pair of quantities, that is, thepair of quantities required to get the answer,denoted as (qi, qj).
The inference problem canbe written as follows:(qi, qj)?
argmaxp?P wTqp?qp(Q, p)where P = {(q1, q2), (q2, q3), (q3, q1)}, ?qp(?
)is a feature function, and wqp is a learnedweight vector.2.
Operation Classifier This classifier takes asinput the question Q of the problem, andthe relevant quantity pair (qi, qj) (decided byQuantity Pair Classifier in case of questionswith three quantities), and outputs which of thefour operations is required for the problem.
Theinference in this case isop?
arg maxop?OwTopr?opr(Q, (qi, qj), op)where O = {+,?,?, /}.3.
Order Classifier This classifier is relevantonly for problems which require subtractionor division.
It takes as input the question Qof the problem, the relevant pair of quantities(qi, qj) and the operation op being performed,and decides the most likely order of quantitiesin the operation, that is, whether we shouldperform (qi op qj) or (qj op qi).
The inferencecan be written as(q?i, q?j)?
argmaxp?P wTor?or(Q, (qi, qj), op, p)where P = {(qi, qj), (qj , qi)}Algorithm 4 SolveWordProblem( Q )Input: Text of question QOutput: Returns answer to question Q1: (q1, q2, q3)?
QuantityExtraction( Q )2: (qi, qj)?
QuantityPairClassifier(Q)3: op?
OperationClassifier(Q,(qi, qj))4: (q?i, q?j)?
OrderClassifier(Q,(qi, qj),op)5: return (q?i op q?j)The inference procedure is given in Algorithm4.
For our classifiers, we use a sparse averagedperceptron implemented with the SNOW framework(Carlson et al., 1999).
Each classifier is trainedon gold annotations for that particular task.
Thefeatures used are as follows:1.
Unigrams and bigrams from sentencescontaining quantities.2.
POS tags from sentences with quantities.3.
Relevant pair of quantities, and whether theirunits match and whether their units are presentin the last sentence of the question.4.
Relevant operation for the problem (forOperation and Order classifiers)5.
Relevant order of quantities for the operation(for Order classifier).6.
Various conjunctions of the above features.7 Experimental StudyIn this section, we seek to validate our proposedmodeling.
We evaluate our system?s performanceon four tasks: Quantity Segmentation, QuantityEntailment, Currency Range Search, and AnsweringMath Word Problems.
We do not directly evaluateour system?s ability to map raw text segmentsinto our representation, but instead evaluate thiscapability extrinsically, in the context of theaforementioned tasks, since good Standardization isnecessary to perform quantitative inference.7.1 DatasetsQE: Due to lack of related work, an adequatelyannotated corpus does not exist.
Thus, in order toevaluate our system, we used two collections:81.
Sub-corpus of the RTE Datasets (Daganet al., 2006) We choose text-hypothesispairs from RTE2?RTE4 datasets, which havequantity mentions in the hypothesis.
Overall,we selected 384 text-hypothesis pairs withquantities in the hypothesis.2.
Newswire Text 600 sentences of newswire textwere selected, all containing quantity mentions.Both these datasets were manually annotatedwith the phrase boundaries of quantity mentionsand had an inter-annotator agreement of 0.91.
Werestricted annotation to contiguous segments of text.No instances of implicit quantities were annotated.We also did not annotate these mentions with QVRs.Limiting the annotations to contiguous spansof text results in a few instances of quantitieswhich contain missing information, such as missingor ambiguous units, and several range and ratiorelationships which were not annotated (e.g., we donot annotate the range expressed in ?from [5 million]in [1995] to [6 million] in [1996]?, but do so in?
[from 5 million to 6 million]?
).In the RTE sub-corpus we also annotatedentailment pairs with information about whichquantities entail, in addition to the boundaryinformation.
For each quantity in the hypothesiswe labeled it as either ?entails?, ?no relation?,or ?contradicts?, with an inter-annotator agreementof 0.95.
There were 309 entailing quantities, 71contradicting quantities and 56 quantities whichwere unrelated to the corresponding text.
Wealso maintained the information about generalentailment, that is, whether the hypothesis can beexplained by the text.
An example of an annotatedRTE example is shown below.Annotation Example for RTE sub-corpusT:A bomb in a Hebrew University cafeteria killed[five Americans] and [four Israelis].H:A bombing at Hebrew University in Jerusalemkilled [nine people], including [five Americans].
?nine people?
: entails?five Americans?
: entailsGlobal entailment decision : entailsAlthough we limit our scope to infer theentailment decision for individual quantitiesmentioned in hypothesis, we hope to see futureapproaches use these individual decisions andcombine them appropriately to obtain the globalentailment decision.Currency Search We developed a new datasetfor evaluating currency search.
Queries of variousamounts of money like ?1000$?, ?USD 2 million?,etc.
were made on a search engine, and paragraphscontaining monetary mentions were taken from thetop search results.
We collected 100 paragraphscontaining various mentions of monetary values, andlabeled them with the amount mentioned in them.We restricted the denominations to US dollars.
Theinter-annotator agreement was 0.98.Math Word Problems We created a new datasetwith elementary math word problems.
The problemswere collected from http://www.k5learning.com/and http://www.dadsworksheets.com/.
The list wasfurther pruned to keep problems with the propertieslisted in section 6.
We also manually removedproblems requiring background knowledge, forexample, ?Roger reads 2 books each day.
Howmany books will he read in 3 weeks ?
?, whichrequires knowing that a week comprises 7 days.Problems with rounding issues were also excluded.For example, ?Each basket can hold 9 apples.
Howmany baskets are required to hold 10 apples ?
?.Each problem was annotated with the operationrequired to solve the problem, and the final answer.Table 1 shows some statistics of our dataset.#quantities Relevant OperationAdd Subtract Multiply Divide2 228 214 257 2603 107 132 75 131Table 1: Statistics of math word problems dataset7.2 Quantity SegmentationWe evaluate the phrase boundary recognizer onthe annotated RTE and newswire datasets describedin the previous section, using the phrase-basedF1 score.
We compare the accuracy and runningtimes of the Semi-CRF model (SC) (Sarawagi andCohen, 2004) and the bank of classifiers model(C+I) (PR) (Punyakanok and Roth, 2001), using10-fold cross-validation.
Note that the standardizercan often recover from mistakes made at thesegmentation level.
Therefore, this performancedoes not necessarily upper bound the performance9of the next step in our pipeline.The segmentation we are aiming for doesnot directly follow from syntactic structure of asentence.
For example, in the sentence ?
Theunemployment rate increased 10%?, we would liketo segment together ?increased 10%?, since thistells us that the quantity denotes a rise in value.Also, in the sentence ?Apple restores push email inGermany, nearly two years after Motorola shut itdown?
we would like to segment together ?nearlytwo years after?
.
We consider a quantity to becorrectly detected only when we have the exactphrase that we want, otherwise we consider thesegment to be undetected.Model P% R% F% Train TestTime TimeSemi-CRF (SC) 75.6 77.7 76.6 15.8 1.5C+I (PR) 80.3 79.3 79.8 1.0 1.0Table 2: 10-fold cross-validation results of segmentationaccuracy and time required for segmentation, the columns forruntime have been normalized and expressed as ratiosTable 2 describes the segmentation accuracy, aswell as the ratio between the time taken by bothapproaches.
The bank of classifiers approach givesslightly better accuracy than the semi-CRF model,and is also significantly faster.7.3 Quantity EntailmentWe evaluate the complete Quantity Entailmentsystem, determining the overall loss due to thesegmentation, as well as the contribution of theCoreference Resolver and SRL.
We show theperformance of 4 systems.1.
GOLDSEG : Uses gold segmentation, and doesnot use SRL and Coreference Resolver.2.
GOLDSEG+SEM : Uses gold segmentation,and also uses SRL and Coreference Resolverto infer units.3.
PREDSEG : Performs segmentation, and doesnot use SRL and Coreference Resolver.4.
PREDSEG+SEM : Performs segmentation, anduses SRL and Coreference Resolver.The baseline is an exact string matchingalgorithm.
It answers ?entails?
if the quantity unitand value are present in the text, and answers?contradicts?
if only the unit matches and thevalue does not.
Otherwise, it returns ?no relation?.The results are shown in Table 3.
Note thatexact match only supports 43.3% of the entailmentdecisions.
It is also evident that the deeper semanticanalysis using SRL and Coreference improves thequantitative inference.Task System P% R% F%EntailmentBaseline 100.0 43.3 60.5GOLDSEG 98.5 88.0 92.9+SEM 97.8 88.6 93.0PREDSEG 94.9 76.2 84.5+SEM 95.4 78.3 86.0ContradictionBaseline 16.6 48.5 24.8GOLDSEG 61.6 92.9 74.2+SEM 64.3 91.5 75.5PREDSEG 51.9 79.7 62.8+SEM 52.8 81.1 64.0No RelationBaseline 41.8 71.9 52.9GOLDSEG 81.1 76.7 78.8+SEM 80.0 78.5 79.3PREDSEG 54.0 75.4 62.9+SEM 56.3 72.7 63.5Table 3: Results of QE; Adding Semantics(+SEM)consistently improves performance; Only 43.3% of entailingquantities can be recovered by simple string matching7.4 Currency Range SearchTable 4 shows the performance of our systemin detecting currency phrases.
We evaluate oursystem on the proportion of monetary mentions itrecognized and standardized correctly from queriedranges of currency values, and report micro-averaged scores.
Note that range search is a directapplication of QE, where the quantity is a range ofvalues, and the text is the corpus we want to search.All instances of ?entails?
correspond to searchhits.
The baseline here is also a string matchingalgorithm, which searches for numbers in the text.System P% R% F%Baseline 72.0 69.2 70.5PREDSEG+SEM 96.0 93.5 94.8Table 4: Micro-averaged accuracy in detecting monetarymentions107.5 Elementary Math Word ProblemsTable 5 shows the performance of individualclassifiers as well as the ability of our system toanswer correctly math word problems, using theoutput of the classifiers.
The results are reportedwith respect to 2-fold cross-validation.
The accuracyof each classifier is based only on the relevantexamples for that particular classifier.
For example,Quantity Pair classifier is evaluated on problemswith three quantities in its question text, andOrder classifier is evaluated on problems concerningsubtraction or division.
Correct Answer denotes theend to end system, which outputs the answer, afterreceiving as input the question text of the problem.Module AccuracyQuantity Pair 94.3Operation 91.8Order 95.9Correct Answer 86.9Table 5: 2-fold cross-validation results of math word problemunderstanding.
Correct Answer indicates performance of end toend system, others represent individual classifier performanceWe find that the individual classifiers have highaccuracy, and hence our system performs well on theend to end task.
A potential future direction can beto propagate the uncertainty in each classifier, whichmight further improve performance of the system.7.6 Qualitative AnalysisThe segmentation module made mistakes indetecting exact boundaries for uncommon phrases,e.g., ?hundreds of thousands of people?, and ?mid-1970?s?.
Detection of missing units is problematicin cases like ?Three eggs are better than two?.The SRL returns ?Three eggs?
as a candidateunit, which needs to be pruned appropriately toobtain the correct unit.
The primary limitation ofthe reasoning system in both tasks is the lackof an extensive knowledge base.
Wordnet basedsynsets prove to be insufficient to infer whether unitsare compatible.
Also, there are certain reasoningpatterns and various implicit relations betweenquantities which are not currently handled in thesystem.
For example, inferring from the sentence?Militants in Rwanda killed an [average of 8,000people per day] for [100 days]?
that ?around800,000 people were killed?.
Also, implication ofratios can be involved.
For example, the sentence?
[One out of 100 participating students] willget the award?
implies that there were ?100participating students?, whereas ?
[9 out of 10dentists] recommend brushing?
does not imply therewere 10 dentists.
In case of word problems, oursystem missed non-standard questioning patternswith involved reasoning.
For example, ?Bryan has50 skittles.
Ben has 20 M&Ms.
Who has more?
Howmany more does he have?
?8 ConclusionWe studied reasoning about quantities in naturallanguage text.
We have identified and defined aninteresting and useful slice of the Textual Entailmentproblem, the Quantity Entailment task, and studiedalso quantitative reasoning problems that arise inelementary math word problems.Our ability to support quantitative reasoningbuilds on a method we proposed for detecting andnormalizing quantities in unrestricted English text;we developed a framework to remove variabilityand ambiguity from unstructured text by mappingit into a representation which makes reasoningmore tractable.
Once quantities are mapped intoour representation we can support the reasoningrequired by Quantity Entailment and elementaryschool level math word problems.
Our experimentsexhibit quite impressive performance on a rangeof quantitative reasoning problems, including 87%success on solving math word problems that aretargeted at elementary school kids.Our future work will focus on alleviating someof the limitations of the inference module describedin Section 5.2.
We would also like to extend thescope of reasoning to the case of partially-orderedquantities, and focus on deeper semantic analysis tohandle more involved math word problems.AcknowledgmentsThis research was sponsored by the Army Research Laboratory(ARL) (under agreement W911NF-09-2-0053), DARPA (underagreement number FA8750-13-2-0008), and a grant from AI2.Any opinions, findings, conclusions or recommendations arethose of the authors and do not necessarily reflect the view ofthe agencies.11ReferencesS.
Banerjee, S. Chakrabarti, and G. Ramakrishnan.2009.
Learning to rank for quantity consensusqueries.
In Proceedings of the 32nd internationalACM SIGIR conference on Research and developmentin information retrieval, SIGIR ?09, pages 243?250,New York, NY, USA.
ACM.J.
Barwise and R. Cooper.
1981.
Generalized quantifiersand natural language.
Linguistics and Philosophy,4(2):159?219.E.
Bengtson and D. Roth.
2008.
Understanding the valueof features for coreference resolution.
In EMNLP.D.
Bobrow.
1964.
Natural language input for a computerproblem solving system.
Technical report, Cambridge,MA, USA.A.
Carlson, C. Cumby, J. Rosen, and D. Roth.
1999.
TheSNoW learning architecture.
Technical report, UIUCComputer Science Department.K.-W. Chang, R. Samdani, and D. Roth.
2013.
Aconstrained latent variable model for coreferenceresolution.
In EMNLP.M.
Collins.
2002.
Discriminative training methods forhidden Markov models: Theory and experiments withperceptron algorithms.
In EMNLP.I.
Dagan, O. Glickman, and B. Magnini, editors.2006.
The PASCAL Recognising Textual EntailmentChallenge.I.
Dagan, D. Roth, M. Sammons, and F. Zanzotto.2013.
Recognizing textual entailment: Models andapplications.Marie-Catherine de Marneffe, Anna N. Rafferty,and Christopher D. Manning.
2008.
Findingcontradictions in text.
In ACL.Q.
Do, W. Lu, and D. Roth.
2012.
Joint inference forevent timeline construction.
In EMNLP.K.
Forbus.
1984.
Qualitative process theory.
ArtificialIntelligence, 24:85?168.Y.
Freund and R. Schapire.
1998.
Large marginclassification using the Perceptron algorithm.
InCOLT.K.
Garoufi.
2007.
Towards a better understanding ofapplied textual entailment: Annotation and evaluationof the rte-2 dataset.
Master?s thesis, SaarlandUniversity, Saarbrucken.S.
Kuehne.
2004a.
On the representation of physicalquantities in natural language text.
In Proceedings ofTwenty-sixth Annual Meeting of the Cognitive ScienceSociety.S.
Kuehne.
2004b.
Understanding natural languagedescriptions of physical phenomena.
Ph.D. thesis,Northwestern University, Evanston, Illinois.N.
Kushman, L. Zettlemoyer, R. Barzilay, and Y. Artzi.2014.
Learning to automatically solve algebra wordproblems.
In ACL (1), pages 271?281.I.
Lev, B. Maccartney, C. Manning, and R. Levy.
2004.Solving logic puzzles: From robust processing toprecise semantics.
In In Proc.
of 2nd Workshop onText Meaning and Interpretation, ACL-04.Bill Maccartney and Christopher D. Manning.
2008.Modeling semantic containment and exclusion innatural language inference.
In Proceedings of the22nd International Conference on ComputationalLinguistics (Coling 2008).G.
Miller, R. Beckwith, C. Fellbaum, D. Gross, and K.J.Miller.
1990.
Wordnet: An on-line lexical database.International Journal of Lexicography.R.
Montague.
1973.
The proper treatment ofquantification in ordinary english.
In Patrick Suppes,Julius Moravcsik, and Jaakko Hintikka, editors,Approaches to Natural Language, volume 49, pages221?242.
Dordrecht.A.
Mukherjee and U. Garain.
2008.
A review of methodsfor automatic understanding of natural languagemathematical problems.
Artificial IntelligenceReview, 29(2):93?122.M.
Palmer, D. Gildea, and N. Xue.
2010.
Semantic RoleLabeling.I.
Pratt-Hartmann.
2005.
From timeml to TPL.
InAnnotating, Extracting and Reasoning about Time andEvents, 10.-15.
April 2005.V.
Punyakanok and D. Roth.
2001.
The use of classifiersin sequential inference.
In NIPS.V.
Punyakanok, D. Roth, and W. Yih.
2008.
Theimportance of syntactic parsing and inference insemantic role labeling.
Computational Linguistics.W.
Purdy.
1991.
A logic for natural language.
NotreDame Journal of Formal Logic, 32(3):409?425, 06.J.
Pustejovsky, J. Castao, R. Ingria, R. Saur,R.
Gaizauskas, A. Setzer, and G. Katz.
2003.TimeML: Robust specification of event and temporalexpressions in text.
In in Fifth International Workshopon Computational Semantics (IWCS-5.D.
Roth and D. Zelenko.
1998.
Part of speechtagging using a network of linear separators.
InCOLING-ACL, The 17th International Conference onComputational Linguistics.M.
Sammons, V.G.
Vydiswaran, and D. Roth.
2010.
?asknot what textual entailment can do for you...?.
In ACL.Sunita Sarawagi and William W. Cohen.
2004.
Semi-markov conditional random fields for informationextraction.
In NIPS.R.
Saur, R. Knippen, M. Verhagen, and J. Pustejovsky.2005.
Evita: a robust event recognizer for qasystems.
In Proceedings of the conference on12Human Language Technology and Empirical Methodsin Natural Language Processing, HLT ?05, pages700?707, Stroudsburg, PA, USA.
Association forComputational Linguistics.U.
Schwertel.
2003.
Plural Semantics for NaturalLanguage UnderstandingA Computational Proof-Theoretic Approach.
Ph.D. thesis, University ofZurich.1314
