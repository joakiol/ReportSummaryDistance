LXGram in the Shared Task?Comparing SemanticRepresentations?of STEP 2008Ant?nio BrancoFrancisco CostaUniversidade de Lisboa (Portugal)email: Antonio.Branco@di.fc.ul.ptAbstractLXGram is a hand-built Portuguese computational grammar based onHPSG (syntax) and MRS (semantics).
The LXGram system participatedin the STEP 2008 shared task which aims at comparing semantic repre-sentations produced by NLP systems such as LXGram.
Every partici-pating team had to contribute a small text.
The text that we submittedfor the shared task was originally in Portuguese (an excerpt from a news-paper) and translated into English, to make a meaningful comparison atthe shared task possible.
Likewise, the English texts contributed by theother participating teams were translated into Portuguese.
Because theLXGram generates many different analyses (mainly due to PP attach-ment ambiguities), the preferred analysis was selected manually.
It wasrequired to extend LXGram?s lexicon and inventory of syntax rules to beable to get a reasonable performance on the shared task data.
Eventually,our system was able to produce an analysis for 20 out of the 30 sentencesof the shared task data.299300 Branco and Costa1 IntroductionThis paper describes the participation of the Portuguese grammar LXGram in theShared Task of STEP 2008 ?Comparing Semantic Representations?
(Bos, 2008).
ThisShared Task was held in the University of Venice on 22?24 September 2008, with thepurpose of comparing semantic representations produced by different natural languageprocessing systems.
This task had seven participating teams.
Each team contributedwith a small text (up to five sentences long) to be processed by all the systems.LXGram is a hand-built, general purpose computational grammar for the deep lin-guistic processing of Portuguese.
It is developed under the grammatical frameworkof Head-Driven Phrase Structure Grammar, HPSG (Pollard and Sag, 1987, 1994; Saget al, 2003) and uses Minimal Recursion Semantics, MRS (Copestake et al, 2005) forthe representation of meaning.
This grammar implementation is undertaken with theLKB (Copestake, 2002) grammar development environment and its evaluation andregression testing is done via [incr tsdb()] (Oepen, 2001).
It is also intended to becompatible with the PET parser (Callmeier, 2000).The LinGO Grammar Matrix (version 0.9), an open-source kit for the rapid devel-opment of grammars based on HPSG and MRS, was used as the initial code uponwhich to build LXGram.
The grammar is implemented in the LKB using the T DLformalism (Krieger and Sch?fer, 1994), based on unification and on typed featurestructures, and whose types are organized in a multiple inheritance hierarchy.For more information, please refer to a detailed implementation report (Branco andCosta, 2008a) or on pages 31?43 of this volume (Branco and Costa, 2008b).
A freeversion of the grammar can also be obtained at http://nlx.di.fc.ul.pt/lxgram,under an ELDA research license.Section 2 introduces the main features of the Minimal Recursion Semantics for-mat, which is employed in the semantic representations produced by LXGram.
InSection 3, the sample text that the LXGram team submitted is described, togetherwith an explanation of the representations derived by the grammar.
Finally, Section 4discusses the results for the full data set of the Shared Task.2 Semantic FormalismIn LXGram, semantic information is encoded following Minimal Recursion Seman-tics (MRS) format for semantic representation (Copestake et al, 2005).
MRS hasseveral properties that makes it an interesting semantic representation format from thepoint of view of computational semantics.Notoriously, it allows underspecification of the scope of relevant operators, whichpermits that a sentence with scope ambiguities can be given a single, underspeci-fied representation.
For some applications, for instance machine translation betweenclosely related languages from the same language family, the underspecified repre-sentations may be sufficient and bring the benefit of avoiding possible combinatorialexplosion into as many parses as readings.In a nutshell, the underspecification of scope is achieved by associating every basicrelation to a handle (in the feature structure for a relation, the feature LBL encodesthis handle) and describing the constraints that hold between these handles (in thefeature HCONS, handle constraints).
These constraints can be stated in a way such thatLXGram in the Shared Task ?Comparing Semantic Representations?
301some scope resolution options are allowed while others are discarded.
Nevertheless,there may applications for which it may be important to get fully specified semanticrepresentations.
In this case, MRS permits that the different scope possibilities becomputed on demand from the underspecified representation.Also worth referring in this very brief presentation of the gist of MRS, it is therepresentation of conjunction with the relative order of conjuncts underspecified, bygiving the same handle to the different conjuncts.
This avoids computing associativityand commutativity of conjunction in situations where spurious overgeneration mayarise.Please consult Branco and Costa (2008a) in this volume (pages 31?43) for an ex-ample illustrating quantifier scope ambiguities and underspecification.
Due to spacelimitations, it is not possible to provide further details on the MRS formalism here.For the presentation of MRS, please consult Copestake et al (2005).3 Sample TextThe following sentences are our examples for the shared task:(1) Atheprimeirafirstescolaschooldeoftreinotrainingdeofc?es-guiasleader dogsdoof thePa?scountryvaigoesnascerto be borneminMort?guaMort?guaeandtreinar?will train2222c?es-guiasleader dogsporperano.yearThe first school for the training of leader dogs in the country is going to becreated in Mort?gua and will train 22 leader dogs per year.
(2) EminMort?gua,Mort?guaJo?oJo?oPedroPedroFonsecaFonsecaeandMartaMartaGomesGomescoordenamcoordinateotheprojectoprojectquethatsetesevenpessoaspeopledesenvolvemdevelopnestain thisescola.schoolIn Mort?gua, Jo?o Pedro Fonseca and Marta Gomes coordinate the projectthat seven people develop in this school.
(3) Visitaramthey visitedv?riosseveralespa?osspacessemelhantessimilareminInglaterraEnglandeandeminFran?a,France,eandnumain onedasof theescolasschoolsfrancesasFrenchest?oarej?alreadyeminest?giointernshipduastwofuturasfuturetreinadoras.trainersThey visited several similar places in England and in France, and two futuretrainers are already doing internship in one of the French schools.
(4) Osthefundosfundingcomunit?rioscommunitarianasseguramensureathemanuten?
?omaintenancedaof theescolaschoolat?until1999.1999The communitarian funding ensures the operation of the school until 1999.302 Branco and Costa(5) Gostar?amoswe would likequethatathenossaourescolaschoolfuncionasseworked?to thesemelhan?asimilaritydasof thefrancesas,Frenchquewhichvivemlivedefromd?divas,donationsdofrom themerchandisingmerchandisingeandat?evendasfrom therifasrafflesquethatasthecrian?aschildrenvendemsellnasin theescolas.schoolsWe would like our school to work similarly to the French ones, which livefrom donations, from the merchandising and even from the raffles that chil-dren sell in school.These sentences were adapted from newspaper text.
We have chosen them becausethey display interesting phenomena.The semantic representations that LXGram produces for these sentences are pre-sented at the Shared Task website http://www.sigsem.org.
An example is includedin Appendix B.
Several analyses are obtained for these examples (e.g.
one of the sen-tences got 540 parses), the main reason being PP attachment ambiguity.
The semanticrepresentations we present are the ones associated to the preferred analyses, whichwere selected manually.Note that since the representations could not be displayed in a single page, the valueof the feature RELS was split across multiple pages.
To ensure readability, the valuesof the other features (LTOP, INDEX and HCONS) are repeated on every page pertainingto the same representation.Some comments are in order concerning these representations:?
The morphological person, number and gender are encoded as features (PER-SON, NUMBER, GENDER) of the relevant index (quantified variable) that ispresent there.
For indices, the boolean feature DIV is also used, that showsthe value + for plurals and mass nouns.?
Event variables are included for the relations introduced by verbs, adjectives,prepositions and adverbs (under their ARG0 feature).
The morphological in-formation on the verbs is also encoded as features of these events.
This is thepurpose of the features MOOD, TENSE and ASPECT.
There is also a featureSF (sentence force) that represents whether a sentence denotes a proposition, aquestion or a command.
The feature ELLIPTICAL-PUNCT denotes whether thesentence ends with an ellipsis (.
.
.)
and is useful in order to constrain what isgenerated by the grammar.?
There is a tense_rel relation associated to each verb form.
Its ARG0 feature isthe same as the ARG0 of the verb it is associated with.
The purpose of this extrarelation is to make an event variable present in the semantic representations forthe copular sentences where the relevant predicate is provided by a noun (noneof these examples).
In such cases this event will contain the morphologicalinformation of the copular verb.?
Note that the information about whether adjectives have intersective semantics(see ?franc?s???French?
?in sentence (3)) or non-intersective semantics (seeLXGram in the Shared Task ?Comparing Semantic Representations?
303?futuro???future?
?in sentence (5)) is visible in the corresponding semanticrepresentations.The names of the predicates that correspond to lexical items of several classes(common nouns, verbs, adjectives, adverbs, prepositions, etc.)
follow a naming con-vention that includes a lemma field, a part-of-speech field and an optional sense field(often reflecting subcategorization).
Table 1 lists the predicates present in these rep-resentations and provides the corresponding English lemmas.
There are other specialrelations in these representations:?
udef_q_relthe quantifier for bare NPs?
proper_q_relthe quantifier for proper names?
tense_relassociated to every verbal relation (see discussion above)?
named_relassociated to proper names?
name-precedes_relassociated to proper names?
string-equals_relequality between strings?
indef_q_relassociated to some indefinites.
In particular it is the quantifier used for NPs thatare introduced by elements that can also follow determiners (e.g.
cardinals andvague quantifiers like ?v?rios???several?)?
cardinal_relconstrains the cardinality of the set denoted by the expression linked to its ARG1feature?
greater-or-equal_relthe integer in its ARG0 is greater than or equal to the integer in its ARG1 feature?
plus_relthe integer in its ARG0 is the result of summing the two integers in the TERM0and TERM1 features?
int-equals_relequality between integers?
ellipsis-or-generic_n_1_relplaceholder relation when there are missing nouns304 Branco and CostaTable 1: Correspondence of Portuguese MRS relations and English lemmasMRS Relation English lemma_ano_n_rel year_?_semelhan?a_a_-de-_rel similarly_assegurar_v_rel to ensure_at?_a_rel even_at?_p_rel until_c?o-guia_n_rel leader dog_comunit?rio_a_rel communitarian_coordenar_v_rel to coordinate_crian?a_n_rel child_d?diva_n_-de-a-_rel donation_de_p_rel of, from_desenvolver_v_rel to develop_e_coord_rel and_em_p_rel in_espa?o_n_rel space_est?gio_n_rel internship_este_a_rel this_escola_n_rel school_franc?s_a_rel French_funcionar_v_rel to work_fundo_n_rel funding_futuro_a_rel future_gostar_v_rel to like_ir_v_aux_rel to be going to_j?_a_rel already_manuten?
?o_n_-de-por-_rel maintenance_merchandising_n_rel merchandising_nascer_v_rel to be born_o_q_rel the_pa?s_n_rel country_por_p_rel per_pessoa_n_rel person_primeiro_a_rel first_projecto_n_-de-por_rel project_rifa_n_rel raffle_semelhante_a_-a-_rel similar_treinador_n_-de-_rel trainer_treinar_v_rel to train_treino_n_-de-por-_rel training_um_q_rel a_v?rios_a_scop_rel several_vender_v_-a-_rel to sell_visitar_v_rel to visit_viver_v_rel to liveLXGram in the Shared Task ?Comparing Semantic Representations?
305Sometimes some details of the semantic representations that are possible to obtaindepend on the features of the system where LXGram is developed and runs.
In partic-ular, for each feature that represents an argument of a relation (ARG0, ARG1, ARG2,CARG, .
.
.
), it must be stated in the configuration files whether it will contain a constant(e.g.
a string literal).
For instance, we must say that the feature CARG always containsa value, for visualization purposes.
This fact sometimes constrains the display of thesemantic representations.
It is the reason why the semantics for proper names and forcardinals is more copious than what would seem necessary at first.For instance, the semantics associated to ?7 pessoas?
(?7 people?)
in sentence (2)is roughly ?x.cardinal_rel(e,_pessoa_n_rel(x), j1)?
greater-or-equal_rel( j1, j2)?int-equals( j2,7) (note that conjunction is denoted in MRS via identical labels forrelations).
The information conveyed by the last two predicates could be simply givenby greater-or-equal_rel( j1,7).
However, for that to display correctly we would haveto configure the system to display the second argument of the greater-or-equal_relrelation as a constant.
This will not always be the case: in the semantics for ?22?
thatargument is the integer that is the result of summing ?20?
and ?2?
(number expressionsreceive compositional semantics), represented with the help of the plus_rel relation.The LKB does not allow one to compute arithmetic expressions.These few sentences present some interesting problems for the computation of se-mantic representation in general.Typically, one is not able to resolve missing nouns, as this sometimes requiresaccess to pragmatic information.
As a consequence, the semantics produced for sen-tences with a missing noun (see sentence (5)) includes an ellipsis-or-generic_n_1_relinstead of the relation corresponding to that noun.Also, it is very hard if not impossible to recover missing arguments.
See for in-stance the semantics for the adjective ?semelhante?
(?similar?)
in sentence (3).
Themissing argument is given the type r, instead of the type x of quantified variables, sothat we can omit a quantifier for it in the semantics and still be able to ask the systemfor scoped solutions (the system would complain about free variables if these elementswere given the type x).Finally, it is worth noting that there are some limitations of the semantic represen-tations obtained given that the empirical coverage of the grammar is still in develop-ment.
Currently, the grammar does not make yet any distinction between restrictiveand non-restrictive relative clauses, as we have not focused on the fully-fledged im-plementation of the semantics of non-restrictive relative clauses yet.
This can be seenin the semantics for the last example, where both relative clauses are semanticallycombined with their head in the same way.4 Performance in the Shared TaskThere are seven small texts in the Shared Task.
The sample text we submitted is text4.
We translated the other six texts into Portuguese before passing them to the system.Translation of the TextsThe translations were done by the authors.
We tried to make them as literal as possi-ble in order to support comparability of the different systems taking part in the SharedTask, but some bits were not literally translated as that would have produced unnatural306 Branco and Costasentences.
We also tried not to make the texts easy to parse by the system by simpli-fying the texts in the translations.
We present the translation for the texts 1, 2, 3, 5, 6and 7 in the Appendix A, with English glosses.Initial CoverageWhen we tried to parse the other six texts of the Shared Task, we got 0% coverage.The causes for parse failure were missing words in the lexicon and missing syntacticconstructions.Since the aim of the Shared Task is not to evaluate data coverage but rather tocompare the semantic representations output by different NLP systems, we made aneffort to expand LXGram by enlarging the lexicon and implementing some syntaxrules, with the purpose of producing semantic representations for as many sentencesin the Shared Task data as possible, within the time constraints.During this grammar expansion, we tried not to tune the grammar to these particularsentences.
We tried to make the implementation of new phenomena general.
For thisreason, some phenomena were not implemented deliberately, because we felt that wewould not be able to produce general solutions for them within the time limit.
This isthe case of WH- questions (present in the first text), which are not yet supported byLXGram and whose implementation we did not want to rush.Grammar ExpansionWe added 97 lexical entries to the grammar.
For some of these items, we had to createnew lexical types, because they have subcategorization frames for which there wasstill no lexical type in the grammar.
One example is the noun ?pedido?
(order), whichwas implemented as having two arguments realized by prepositional phrases, the firstone headed ?de?
and the second one headed by ?a?.
LXGram already contained lex-ical types for nouns with two arguments, but introduced by different prepositions.Although these two arguments of the noun were not present in the example wherethis noun occurs (the third sentence of text 3), we nevertheless created a new lexicaltype for this subcategorization frame.
We could have used an existing lexical type fornouns with no complements and that particular sentence would have parsed fine, butthe predicate for that noun would not be a two-place predicate in the MRS represen-tation.
We added 10 new lexical types.The constructions that were implemented in LXGram in order to parse these sen-tences were:?
the progressive.
In European Portuguese, the progressive is expressed via aform of the verb ?estar?
(to be) combined with an infinitive preceded by thepreposition ?a?.?
temporal expressions headed by the verb ?haver?
(there to be).
The temporalexpression for some time (second sentence of text 2) is expressed in Portugueseas ?h?
algum tempo?
(literally: there is some time).
The verb form cannot beanalyzed as a preposition, because this sort of expression is syntactically com-positional.
For instance, the verb inflects for tense (it can appear in the imper-fect if the main verb of the clause is in a past tense) and there can be adverbsmodifying it to its right (?h?
j?
algum tempo?, there is already some time, i.e.LXGram in the Shared Task ?Comparing Semantic Representations?
307for some time now).
We created a unary syntax rule that takes as daughter aclause headed by this verb and produces a mother node with the syntactic char-acteristics of a clause introduced by a subordinating conjunction and modifyinganother clause.
This rule adds a relation similar to a relation introduced bya subordinating conjunction, and it?s called abstract-temporal_x_rel.
We takethis relation as having the meaning of ?since?, but with the two arguments re-versed, and the Portuguese clause for that is known for some time gets analyzedas meaning roughly there is some time (some time has passed) since that isknown.
That is a very literal semantic representation, but it allows us to keepthe semantic composition mechanism completely monotonic.?
the impersonal pronoun ?se?.
The most naturally sounding translation of it wassuspected that (last sentence of text 5) is ?suspeitou-se que?, with a verb in theactive voice and its subject being realized by a clitic pronoun.
This clitic has toappear adjacently to the verb, which is atypical for subjects in Portuguese.?
NP appositives.
We also implemented a rule to allow NP apposition.
This wasbecause of sentences like the second sentence in text 6.Additionally, a few preprocessor rules were expanded.
For instance, sentences likethe last sentence of text 7 require integer literals to be considered as proper names.
Wecannot create lexical entries for all integers, so we added preprocessor rules in orderto contemplate the possibility of integers as proper names.Final ResultsAfter grammar expansion, 20 sentences out of the 30 sentences in all the texts of theShared Task got an analysis.
The sentences that could not be parsed are the following:?
Text 1: sentences (c) and (d).?
Text 5: sentences (a), (c) and (d)?
Text 6: all sentences?
Text 7: sentences (a) and (b)The two sentences of text 1 that could not be parsed contain WH- questions, whichare currently not supported by the system.The sentence (a) of text 5 could not be parsed because it contains two sentences asthe complement of a verb.
LXGram cannot yet combine two independent sentences,and we chose to not implement this possibility because the combination of an n-wayambiguous sentence with another m-way ambiguous sentence would be n ?
m-wayambiguous.The sentence (c) of the same text was not parsed because of a semantically vacuousclitic (not implemented yet) and a relative clause modifying another clause (also notcovered).
LXGram does not support sentence relatives and we chose not to imple-ment them yet because, if the relative pronoun is filling a subject position (as in thatsentence), the verb has to allow for propositional subjects.
In LXGram, we currentlyonly have subcategorization frames for verbs that take NPs as subjects, and we haveto review all lexical entries for verbs before we can parse that sentence.308 Branco and CostaFor the remaining sentences without a parse, the reason was efficiency.
Several ofthe sentences in the Shared Task data translate to Portuguese sentences that are verylong (over 40 words) or have a very high number of prepositions, producing manyattachment possibilities.
Note that we were doing exhaustive search.
In many casesthe parser would run out of memory.
In order to alleviate this problem, we used thePET parser instead of the LKB parser for the longer sentences.
PET is considerablyfaster, because it is implemented in C (the LKB is in Lisp), and it precompiles thegrammar into a binary format.
Also, the input to PET can be preprocessed by a POStagger, in order to reduce lexical ambiguity.
We did this preprocessing for some of thelonger sentences.However, PET dumps MRS representations as text, and choosing the best parsefrom this sort of output is not practical, especially for sentences with many readings.So we exported the results into a format that can be read by [ incr tsdb() ], a tool forthe management of test suites and corpora.
With this tool, it is possible to chooseparses by choosing discriminants derived from all analyses.
Choosing or rejecting asingle discriminant can eliminate a large number of analyses in one step.
However,[ incr tsdb() ] calls the LKB to reconstruct the trees based on the output of PET (whichincludes the names of the rules used and syntactic constituency), when one wants tochoose the best parse.
Even though the parse forest has already been built by thePET parser, the LKB can still run out of memory when it is reconstructing the featurestructures if the number of analyses is sufficiently large (we had a sentence with over18000 parses).We also tried commenting out some rules that were not necessary to parse thesesentences, with the purpose of reducing the search space.
Examples include robustnessrules, for parsing strings with no verb.In the near future, we will be working on a stochastic disambiguation module,which PET supports, in order to constrain the parser?s search space and to keep onlythe best n parses, so that we can avoid the efficiency problems that we are facing atthe moment.AnalysesThe semantic representations for the sentences that LXGram parsed successfully arepresented in the appendix.
As mentioned before, we performed exhaustive search.
Wechose the best parse manually.We used [ incr tsdb() ] associated to the LKB in order to choose the preferredreading.
After that we exported the MRS representation.
The LKB exports LaTeXdirectly.
We edited the exported LaTeX in order to make the representations fit intothe pages of the appendix.
This involved manually adding newlines and page breaks.We also corrected characters with diacritics, which did not display correctly, and weremoved characterization information: after the name of each predicate, there is apair of character positions indicating the substring in the input spanned by the lexicalitems or rules associated to that predicate; they were removed because they are notinterpretable by someone who does not know the implementation details, e.g.
thesemantics for null subjects span the substring of the entire VP since this piece ofsemantics is introduced by a unary rule that takes a VP as daughter.LXGram in the Shared Task ?Comparing Semantic Representations?
309Discussion of the ResultsWe would like to comment on some of the semantic representations obtained withLXGram.As we have pointed out before, some details of the semantics are not completelyindependent of language.
For an example, see the discussion above about temporalexpressions headed by the verb ?haver?.MRS does not directly support a treatment of intentionality.
For instance, sentence(c) of text 2 contains an intentional context: it does not assert the existence of ?othercancers caused by viruses?.
There is no standard way of representing this sort ofintentionality with MRS.Also, MRS does not support conjunction of quantifiers.
There is no MRS equiva-lent to a lambda expression like ?P.Quant1(x,P(x))?Quant2(y,P(y)).
The usual MRSrepresentations associated with NP coordination have to include an explicit relation forthe truth function involved (but taking referential indices as arguments), as well as anextra quantifier relation (the relation used in these cases is called ude f_q_rel, whichis also the name for the quantifier of bare NPs).Some phenomena are difficult to analyze.
An example is in sentence (c) of text 7.In the Portuguese translation, we have two coordinated NPs at the end of the sentence(the best sounding translation requires a determiner before each of the two nouns),which are followed by a PP.
The Portuguese translation interprets this PP as realizingan argument of both nouns (cf.
federal government interest and federal governmenttax incentives).
We could not get this reading, because we do not allow PP argumentsto attach higher than determiners.
The analysis that we present leaves the first nounwith this argument underspecified, as this PP attaches directly to the second noun inthe corresponding syntax tree.
This possibility of PP attachment seems to be requiredfor cases of NP coordination like this one, but it can be a source of overgenerationfor NPs that are not coordinated.
This phenomenon affects other NP elements, likeadjective phrases, that can also take scope over a coordination of NPs.
The currentimplementation forces all noun dependents that have a restrictive interpretation toattach lower than determiners, as that is the place where the restrictor of the quantifierfor that NP is visible in the feature structures.ReferencesBos, J.
(2008).
Introduction to the Shared Task on Comparing Semantic Representa-tions.
In J. Bos and R. Delmonte (Eds.
), Semantics in Text Processing.
STEP 2008Conference Proceedings, Volume 1 of Research in Computational Semantics, pp.257?261.
College Publications.Branco, A. and F. Costa (2008a).
A computational grammar for deep linguistic pro-cessing of Portuguese: LXGram, version A.4.1.
Technical report, University ofLisbon, Department of Informatics.Branco, A. and F. Costa (2008b).
High Precision Analysis of NPs with a Deep Pro-cessing Grammar.
In J. Bos and R. Delmonte (Eds.
), Semantics in Text Processing.STEP 2008 Conference Proceedings, Volume 1 of Research in Computational Se-mantics, pp.
31?43.
College Publications.310 Branco and CostaCallmeier, U.
(2000).
PET ?
A platform for experimentation with efficient HPSGprocessing techniques.
Natural Language Engineering 6(1), 99?108.
(SpecialIssue on Efficient Processing with HPSG).Copestake, A.
(2002).
Implementing Typed Feature Structure Grammars.
Stanford:CSLI Publications.Copestake, A., D. Flickinger, I.
A.
Sag, and C. Pollard (2005).
Minimal RecursionSemantics: An introduction.
Journal of Research on Language and Computa-tion 3(2?3), 281?332.Krieger, H.-U.
and U. Sch?fer (1994).
T DL ?
A type description language forconstraint-based grammars.
In Proceedings of the 15th International Conferenceon Computational Linguistics, Kyoto, Japan, pp.
893?899.Oepen, S. (2001).
[incr tsdb()] ?
competence and performance laboratory.
Usermanual.
Technical report, Computational Linguistics, Saarland University, Saar-br?cken, Germany.
In preparation.Pollard, C. and I.
Sag (1987).
Information-Based Syntax and Semantics, Vol.
1.
Num-ber 13 in CSLI Lecture Notes.
Stanford: CSLI Publications.Pollard, C. and I.
Sag (1994).
Head-Driven Phrase Structure Grammar.
Stanford:Chicago University Press and CSLI Publications.Sag, I.
A., T. Wasow, and E. M. Bender (2003).
Syntactic Theory ?
A Formal Intro-duction (2nd ed.).
Stanford: CSLI Publications.LXGram in the Shared Task ?Comparing Semantic Representations?
311Appendix A: Translations of the Texts for the Shared TaskText 1(1) Umanobjectoobject?islan?adothrowncomwithumaavelocidadespeedhorizontalhorizontaldeof2020m/sm/sdefromumapenhascocliffquethattemhas125125mmdeofaltura.heightAn object is thrown with a horizontal speed of 20 m/s from a cliff that is 125 m high.
(2) Otheobjectoobjectcaifallspelafor thealturaheightdoof thepenhasco.cliffThe object falls for the height of the cliff.
(3) Seifatheresist?nciaresistancedoof thearair?isnegligenci?vel,negligiblequantohow muchtempotimedemoratakesotheobjectoobjectatocairfallaoto thech?o?groundIf air resistance is negligible, how long does it take the object to fall to the ground?
(4) Qualwhat?isathedura?
?odurationdaof thequeda?fallWhat is the duration of the fall?Text 2(1) Othecancrocancercervicalcervical?iscausadocausedporbyumav?rus.virusCervical cancer is caused by a virus.
(2) Issothat?isconhecidoknownh?there isalgumsometempotimeeandlevouledatoumaavacinavaccinequethatpareceseemspreveni-lo.to prevent itThat has been known for some time and it has led to a vaccine that seems to prevent it.
(3) Ostheinvestigadoresresearcherst?mhaveprocuradolookedoutrosothercancroscancersquethatpossammayserbecausadoscausedporbyv?rus.virusesResearchers have been looking for other cancers that may be caused by viruses.Text 3(1) OtheJohnJohnfoiwentatoumarestaurante.restaurantJohn went into a restaurant.
(2) Haviathere wasumaamesatablenoin thecanto.cornerThere was a table in the corner.
(3) Otheempregadowaiteranotouwrote downothepedido.orderThe waiter took the order.
(4) Atheatmosferaatmosphereerawasacolhedorawarmeandsimp?tica.friendlyThe atmosphere was warm and friendly.
(5) Elehecome?oubeganatolerreadotheseuhislivro.bookHe began to read his book.312 Branco and CostaText 5(1) Enquantoasosthe33canh?esgunsdoof thetorre?oTurret22eramwerecarregados,loadedumamembromemberdaof theequipacrewquewhoestavawasatooperaroperateothecanh?c?oguncentralcentralgritouyelledaoto thetelefonephone?TenhoI haveaquihereumaproblema.problem.AindaStilln?onotestouI ampreparado?.readyAs the 3 guns of Turret 2 were being loaded, a crewman who was operating the center gun yelledinto the phone, ?I have a problem here.
I am not ready yet.?
(2) Ent?othenotheexplosivopropellantrebentou.explodedThen the propellant exploded.
(3) Quandowhenosthemembrosmembersdaof theequipacrewdoof thecanh?ogunmorreram,diedestavamthey wereagachadoscrouchingdeofformawayn?onotnatural,naturalo quewhichsugeriasuggestedquethatsabiamthey knewquethatseDUMMY CLITICdariawould happenumaanexplos?o.explosionWhen the gun crew was killed they were crouching unnaturally, which suggested that they knew thatan explosion would happen.
(4) Otheexplosivopropellantquethatfoiwasusadousederawasfeitomadedefrompeda?oschunksdeofnitrocelulosenitrocellulosequethatforamwereproduzidosproducedduranteduringatheSegundasecondGuerraworldMundialwareandforamwerereembaladosrepackagedemin19871987eminsacosbagsquethatforamwerefeitosmadeemin1945.1945The propellant that was used was made from nitrocellulose chunks that were produced during WorldWar II and were repackaged in 1987 in bags that were made in 1945.
(5) Inicialmente,initiallysuspeitou-sesuspected IMPERSONAL SUBJECTquethatestethisarmazenamentostoragepoderiamightterhavereduzidoreducedatheestabilidadestabilitydaof thep?lvora.powderInitially it was suspected that this storage might have reduced the powder?s stability.Text 6(1) Entreamidasthefilasrowscerradastightly packeddeofcasashousesdoof thenortenorthdeofFilad?lfia,Philadelphiaumaaquintafarmurbanaurbanpioneirapioneeringest?isatoproduzirproducecomidafoodlocallocalfrescafreshparaforumaacomunidadecommunityquethatfrequentementeoftenn?onotaittem,haseandatogerargeneratedinheiromoneycomwithisso.itAmid the tightly packed row houses of North Philadelphia, a pioneering urban farm is providingfresh local food for a community that often lacks it, and making money in the process.
(2) Greensgrow,Greensgrowumaterrenoplotdeofumoneacreacredeofcanteirosbedselevadosraisedeandestufasgreenhousesnoon thelocalsitedeofumaaantigaformerf?bricafactorydeofgalvaniza?
?ogalvanizationdeofa?o,steelest?isatoterhavelucroprofitvendendosellingosthepr?priosownvegetaisvegetableseandervasherbsassim comoas well asumaagamarangedeofprodutosproductsdefromagricultoresfarmerslocais,localeandgerindomanagingumaviveironurseryquethatvendesellsplantasplantseandpl?ntulas.seedlingsGreensgrow, a one-acre plot of raised beds and greenhouses on the site of a former steel-galvanizingfactory, is turning a profit by selling its own vegetables and herbs as well as a range of producefrom local growers, and by running a nursery selling plants and seedlings.LXGram in the Shared Task ?Comparing Semantic Representations?
313(3) Athequintafarmlucrouearnedcerca deabout1000010000d?laresdollarscomwithumaareceitarevenuedeof450000450000d?laresdollarsemin2007,2007eandesperahopesterto haveumalucroprofitdeof5%5%sobreonosthe650000650000d?laresdollarsdeofreceitasrevenuenestein thisano,yearotheseuits10?
?10thano,yearparain orderpoderto be ableabrirto openoutraanotheractividadeoperationnoutroin anothers?tioplacedeofFilad?lfia.PhiladelphiaThe farm earned about $10,000 on revenue of $450,000 in 2007, and hopes to make a profit of 5percent on $650,000 in revenue in this, its 10th year, so it can open another operation elsewhere inPhiladelphia.Text 7(1) Othedesenvolvimentodevelopmentmodernomoderndaof thetecnologiatechonologyeandaplica?
?esapplicationsdeofenergiaenergye?licawind.ADJECTIVEj?alreadyestavawasnumain afasephaseavan?adaadvancednosby theanosyears30,30quandowhenporbyestimativaestimationcerca deabout600000600000moinhosmillsforneciamsupplied?reasareasruraisruralcomwithelectricidadeelectricityeandservi?osservicesdeofbombeamentopumpingdeof?gua.waterModern development of wind-energy technology and applications was well underway by the 1930s,when an estimated 600,000 windmills supplied rural areas with electricity and water-pumping ser-vices.
(2) Quandowhenathedistribui?
?odistributioneminlargabroadescalascaledeofelectricidadeelectricitychegouarrived?sto thequintasfarmseand?sto theterrassmallpequenas,townsotheusousedeofenergiaenergye?licawind.ADJECTIVEnosin theEstados UnidosUnited Statescome?oustartedatodiminuir,subsidemasbutvoltouit went backatosubirraisedepoisafterdaof thefaltashortagedeofpetr?leooilnosin theEUAUSnoin thecome?obeginningdosof theanosyears70.70Once broad-scale electricity distribution spread to farms and country towns, use of wind energy inthe United States started to subside, but it picked up again after the U.S. oil shortage in the early1970s.
(3) Nosin the?ltimoslast3030anos,yearsatheinvestiga?
?oresearcheandothedesenvolvimentodevelopmentt?mhaveosciladofluctuatedde acordoin accordancecomwithotheinteresseinteresteandosthebenef?ciosbenefitsfiscaisfiscaldoof thegovernogovernmentfederal.federalOver the past 30 years, research and development has fluctuated with federal government interestand tax incentives.
(4) Eminmeadosmiddledosof theanosyears80,80astheturbinasturbinese?licaswind.ADJECTIVEtinhamhadtipicamentetypicallyumaapot?nciapower ratingm?ximamaximumdeof150150kW.kWIn the mid-?80s, wind turbines had a typical maximum power rating of 150 kW.
(5) EmIn2006,2006astheturbinasturbinescomerciaiscommercialdeofgrandelargeescalascales?oarecomummentecommonlyavaliadasratedematmaismoredethan11MWMWeandest?oaredispon?veisavailableeminnoat them?ximomost44MWMWdeofcapacidade.capacityIn 2006, commercial, utility-scale turbines are commonly rated at over 1 MW and are available inup to 4 MW capacity.314 Branco and CostaAppendix B: MRS Representation for Text 4, Sentence 1??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?mrsLTOP h1 hINDEX e2 eRELS?????????????????
?_o_q_relLBL h3 hARG0 x4??????
?xPNG.PERSON 3rdPNG.NUMBER singularPNG.GENDER feminineDIV -??????
?RSTR h6 hBODY h5 h?????????????????,????
?_primeiro_a_relLBL h7 hARG0 e8 eARG1 h9 h?????,??
?_escola_n_relLBL h9ARG0 x4???,????????????????
?_de_p_relLBL h9ARG0 e10 eARG1 x4ARG2 x11??????
?xPNG.PERSON 3rdPNG.NUMBER singularPNG.GENDER masculineDIV +????????????????????????,??????
?udef_q_relLBL h12 hARG0 x11RSTR h14 hBODY h13 h???????,????????????????
?_treino_n_-de-por-_relLBL h15 hARG0 x11ARG1 r17 rARG2 x16??????
?xPNG.PERSON 3rdPNG.GENDER masculinePNG.NUMBER pluralDIV +????????????????????????,??????
?udef_q_relLBL h18 hARG0 x16RSTR h20 hBODY h19 h???????,??
?_c?o-guia_n_relLBL h21 hARG0 x16???,????????????????
?_de_p_relLBL h9ARG0 e22 eARG1 x4ARG2 x23??????
?xDIV -PNG.NUMBER singularPNG.GENDER masculinePNG.PERSON 3rd????????????????????????,??????
?_o_q_relLBL h24 hARG0 x23RSTR h26 hBODY h25 h???????,??
?_pa?s_n_relLBL h27 hARG0 x23???,??????????????
?tense_relLBL h28 hARG0 e29?????????
?eSF propositionELLIPTICAL-PUNCT -E.MOOD indicativoE.TENSE presenteE.ASPECT.PERF -?????????????????????????,????
?_ir_v_aux_relLBL h28ARG0 e29ARG1 h30 h?????,????????????
?tense_relLBL h31 hARG0 e32??????
?eSF propositionELLIPTICAL-PUNCT boolE.MOOD infinitivo-nao-flexionadoE.ASPECT.PERF -????????????????????,????
?_nascer_v_relLBL h31ARG0 e32ARG1 x4?????,????????????????
?_em_p_relLBL h31ARG0 e33 eARG1 e32ARG2 x34??????
?xPNG.PERSON 3rdPNG.NUMBER singularPNG.GENDER feminineDIV -????????????????????????,??????
?proper_q_relLBL h35 hARG0 x34RSTR h37 hBODY h36 h???????,????
?named_relLBL h38 hARG0 x34ARG1 s39 s?????,????
?string-equals_relLBL h38ARG0 s39CARG mort?gua?????,???????????????????????
?_e_coord_relLBL h40 hC-ARG e2L-HNDL h28L-INDEX e29R-HNDL h42 hR-INDEX e41?????????
?eSF propositionELLIPTICAL-PUNCT -E.MOOD indicativoE.TENSE futuroE.ASPECT.PERF -??????????????????????????????????,??
?tense_relLBL h42ARG0 e41???,????????????????
?_treinar_v_relLBL h42ARG0 e41ARG1 x4ARG2 x43??????
?xPNG.NUMBER pluralPNG.GENDER masculinePNG.PERSON 3rdDIV +????????????????????????,??????
?indef_q_relLBL h44 hARG0 x43RSTR h45 hBODY h46 h???????,???????
?cardinal_relLBL h47 hARG0 e49 eARG1 h50 hARG2 j48 j????????,?????
?greater-or-equal_relLBL h47ARG0 j48ARG1 j51 j??????,???????
?plus_relLBL h47ARG0 j51TERM0 j53 jTERM1 j52 j????????,????
?int-equals_relLBL h47ARG0 j53CARG 20?????,????
?int-equals_relLBL h47ARG0 j52CARG 2?????,??
?_c?o-guia_n_relLBL h50ARG0 x43???,????????????????
?_por_p_relLBL h42ARG0 e54 eARG1 e41ARG2 x55??????
?xPNG.PERSON 3rdPNG.NUMBER singularPNG.GENDER masculineDIV +????????????????????????,??????
?udef_q_relLBL h56 hARG0 x55RSTR h58 hBODY h57 h???????,??
?_ano_n_relLBL h59 hARG0 x55????HCONS???
?qeqHARG h1LARG h40???,??
?qeqHARG h6LARG h7???,??
?qeqHARG h14LARG h15???,??
?qeqHARG h20LARG h21???,??
?qeqHARG h26LARG h27???,??
?qeqHARG h30LARG h31???,??
?qeqHARG h37LARG h38???,??
?qeqHARG h45LARG h47???,??
?qeqHARG h58LARG h59??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?
