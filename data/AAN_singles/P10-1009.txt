Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 79?87,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsA Risk Minimization Framework for ExtractiveSpeech SummarizationShih-Hsiang Lin and Berlin ChenNational Taiwan Normal UniversityTaipei, Taiwan{shlin, berlin}@csie.ntnu.edu.twAbstractIn this paper, we formulate extractivesummarization as a risk minimizationproblem and propose a unified probabilis-tic framework that naturally combines su-pervised and unsupervised summarizationmodels to inherit their individual merits aswell as to overcome their inherent limita-tions.
In addition, the introduction of vari-ous loss functions also provides the sum-marization framework with a flexible butsystematic way to render the redundancyand coherence relationships among sen-tences and between sentences and thewhole document, respectively.
Experi-ments on speech summarization show thatthe methods deduced from our frameworkare very competitive with existing summa-rization approaches.1 IntroductionAutomated summarization systems which enableuser to quickly digest the important informationconveyed by either a single or a cluster of docu-ments are indispensible for managing the rapidlygrowing amount of textual information and mul-timedia content (Mani and Maybury, 1999).
Onthe other hand, due to the maturity of text sum-marization, the research paradigm has been ex-tended to speech summarization over the years(Furui et al, 2004; McKeown et al, 2005).Speech summarization is expected to distill im-portant information and remove redundant andincorrect information caused by recognition er-rors from spoken documents, enabling user toefficiently review spoken documents and under-stand the associated topics quickly.
It would alsobe useful for improving the efficiency of a num-ber of potential applications like retrieval andmining of large volumes of spoken documents.A summary can be either abstractive or extrac-tive.
In abstractive summarization, a fluent andconcise abstract that reflects the key concepts ofa document is generated, whereas in extractivesummarization, the summary is usually formedby selecting salient sentences from the originaldocument (Mani and Maybury, 1999).
The for-mer requires highly sophisticated natural lan-guage processing techniques, including semanticrepresentation and inference, as well as naturallanguage generation, while this would make ab-stractive approaches difficult to replicate or ex-tend from constrained domains to more generaldomains.
In addition to being extractive or ab-stractive, a summary may also be generated byconsidering several other aspects like being ge-neric or query-oriented summarization, single-document or multi-document summarization, andso forth.
The readers may refer to (Mani andMaybury, 1999) for a comprehensive overviewof automatic text summarization.
In this paper,we focus exclusively on generic, single-document extractive summarization which formsthe building block for many other summarizationtasks.Aside from traditional ad-hoc extractive sum-marization methods (Mani and Maybury, 1999),machine-learning approaches with either super-vised or unsupervised learning strategies havegained much attention and been applied withempirical success to many summarization tasks(Kupiec et al, 1999; Lin et al, 2009).
For super-vised learning strategies, the summarization taskis usually cast as a two-class (summary and non-summary) sentence-classification problem: Asentence with a set of indicative features is inputto the classifier (or summarizer) and a decision isthen returned from it on the basis of these fea-tures.
In general, they usually require a trainingset, comprised of several documents and theircorresponding handcrafted summaries (or labeleddata), to train the classifiers.
However, manuallabeling is expensive in terms of time and per-sonnel.
The other potential problem is the so-called ?bag-of-sentences?
assumption implicitlymade by most of these summarizers.
That is, sen-tences are classified independently of each other,79without leveraging the dependence relationshipsamong the sentences or the global structure ofthe document (Shen et al, 2007).Another line of thought attempts to conductdocument summarization using unsupervisedmachine-learning approaches, getting around theneed for manually labeled training data.
Mostprevious studies conducted along this line havetheir roots in the concept of sentence centrality(Gong and Liu, 2001; Erkan and Radev, 2004;Radev et al, 2004; Mihalcea and Tarau, 2005).Put simply, sentences more similar to others aredeemed more salient to the main theme of thedocument; such sentences thus will be selectedas part of the summary.
Even though the perfor-mance of unsupervised summarizers is usuallyworse than that of supervised summarizers, theirdomain-independent and easy-to-implementproperties still make them attractive.Building on these observations, we expect thatresearches conducted along the above-mentionedtwo directions could complement each other, andit might be possible to inherit their individualmerits to overcome their inherent limitations.
Inthis paper, we present a probabilistic summariza-tion framework stemming from Bayes decisiontheory (Berger, 1985) for speech summarization.This framework can not only naturally integratethe above-mentioned two modeling paradigmsbut also provide a flexible yet systematic way torender the redundancy and coherence relation-ships among sentences and between sentencesand the whole document, respectively.
Moreover,we also illustrate how the proposed frameworkcan unify several existing summarization models.The remainder of this paper is structured asfollows.
We start by reviewing related work onextractive summarization.
In Section 3 we for-mulate the extractive summarization task as arisk minimization problem, followed by a de-tailed elucidation of the proposed methods inSection 4.
Then, the experimental setup and aseries of experiments and associated discussionsare presented in Sections 5 and 6, respectively.Finally, Section 7 concludes our presentation anddiscusses avenues for future work.2 BackgroundSpeech summarization can be conducted usingeither supervised or unsupervised methods (Furuiet al, 2004, McKeown et al, 2005, Lin et al,2008).
In the following, we briefly review a fewcelebrated methods that have been applied toextractive speech summarization tasks with goodsuccess.2.1 Supervised summarizersExtractive speech summarization can be treatedas a two-class (positive/negative) classificationproblem.
A spoken sentence iS  is characterized by set of T  indicative features ?
?iTii xxX ,,1 ??
, and they may include lexical features (Koumpisand Renals, 2000), structural features (Maskeyand Hirschberg, 2003), acoustic features (Inoueet al, 2004), discourse features (Zhang et al,2007) and relevance features (Lin et al, 2009).Then, the corresponding feature vector iX  of iS  is taken as the input to the classifier.
If the output(classification) score belongs to the positive class,iS  will be selected as part of the summary; oth-erwise, it will be excluded (Kupiec et al, 1999).Specifically, the problem can be formulated asfollows: Construct a sentence ranking model thatassigns a classification score (or a posteriorprobability) of being in the summary class toeach sentence of a spoken document to be sum-marized; important sentences are subsequentlyranked and selected according to these scores.
Tothis end, several popular machine-learning me-thods could be utilized, like Bayesian classifier(BC) (Kupiec et al, 1999),  Gaussian mixturemodel (GMM) (Fattah and Ren, 2009) , hiddenMarkov model (HMM) (Conroy and O'leary,2001), support vector machine (SVM) (Kolcz etal., 2001), maximum entropy (ME) (Ferrier,2001), conditional random field (CRF) (Galley,2006; Shen et al, 2007), to name a few.Although such supervised summarizers are ef-fective, most of them (except CRF) usually im-plicitly assume that sentences are independent ofeach other (the so-called ?bag-of-sentences?
as-sumption) and classify each sentence individual-ly without leveraging the relationship among thesentences (Shen et al, 2007).
Another majorshortcoming of these summarizers is that a set ofhandcrafted document-reference summary ex-emplars are required for training the summarizers;however, such summarizers tend to limit theirgeneralization capability and might not be readi-ly applicable for new tasks or domains.2.2 Unsupervised summarizersThe related work conducted along this directionusually relies on some heuristic rules or statistic-al evidences between each sentence and the doc-ument, avoiding the need of manually labeledtraining data.
For example, the vector spacemodel (VSM) approach represents each sentenceof a document and the document itself in vectorspace (Gong and Liu, 2001), and computes therelevance score between each sentence and thedocument (e.g., the cosine measure of the simi-80larity between two vectors).
Then, the sentenceswith the highest relevance scores are included inthe summary.
A natural extension is to representeach document or each sentence vector in a latentsemantic space (Gong and Liu, 2001), instead ofsimply using the literal term information as thatdone by VSM.On the other hand, the graph-based methods,such as TextRank (Mihalcea and Tarau, 2005)and LexRank (Erkan and Radev, 2004), concep-tualize the document to be summarized as a net-work of sentences, where each node represents asentence and the associated weight of each linkrepresents the lexical or topical similarity rela-tionship between a pair of nodes.
Documentsummarization thus relies on the global structuralinformation conveyed by such conceptualizednetwork, rather than merely considering the localfeatures of each node (sentence).However, due to the lack of document-summary reference pairs, the performance of theunsupervised summarizers is usually worse thanthat of the supervised summarizers.
Moreover,most of the unsupervised summarizers are con-structed solely on the basis of the lexical infor-mation without considering other sources of in-formation cues like discourse features, acousticfeatures, and so forth.3 A risk minimization framework forextractive summarizationExtractive summarization can be viewed as adecision making process in which the summariz-er attempts to select a representative subset ofsentences or paragraphs from the original docu-ments.
Among the several analytical methodsthat can be employed for the decision process,the Bayes decision theory, which quantifies thetradeoff between various decisions and the po-tential cost that accompanies each decision, isperhaps the most suited one that can be used toguide the summarizer in choosing a course ofaction in the face of some uncertainties underly-ing the decision process (Berger, 1985).
Statedformally, a decision problem may consist of fourbasic elements: 1) an observation O  from a ran-dom variable O , 2) a set of possible decisions(or actions) ?
?a , 3) the state of nature ???
,and 4) a loss function ?
?
?,iaL  which specifies the cost associated with a chosen decision ia  given that ?
is the true state of nature.
The expectedrisk (or conditional risk) associated with takingdecision ia  is given by?
?
?
?
?
?
,| ?d?|Op,?aLOaR ?
ii ??
(1)where ?
?
?|Op  is the posterior probability of thestate of nature being ?
given the observation O .Bayes decision theory states that the optimumdecision can be made by contemplating each ac-tion ia , and then choosing the action for which the expected risk is minimum:?
?.|minarg* OaRa iai?
(2)The notion of minimizing the Bayes risk hasgained much attention and been applied withsuccess to many natural language processing(NLP) tasks, such as automatic speech recogni-tion (Goel and Byrne, 2000), statistical machinetranslation (Kumar and Byrne, 2004) and statis-tical information retrieval (Zhai and Lafferty,2006).
Following the same spirit, we formulatethe extractive summarization task as a Bayes riskminimization problem.
Without loss of generality,let us denote ???
as one of possible selectionstrategies (or state of nature) which comprises aset of indicators used to address the importanceof each sentence iS  in a document D  to be summarized.
A feasible selection strategy can befairly arbitrary according to the underlying prin-ciple.
For example, it could be a set of binaryindicators denoting whether a sentence should beselected as part of summary or not.
On the con-trary, it may also be a ranked list used to addressthe significance of each individual sentence.Moreover, we refer to the k -th action ka  as choosing the k -th selection strategy k?
, and the observation O  as the document D  to be summa-rized.
As a result, the expected risk of a certainselection strategy k?
is given by?
?
?
?
?
?
.|,| ?????
?
dDpLDR kk ??
(3)Consequently, the ultimate goal of extractivesummarization could be stated as the search ofthe best selection strategy from the space of allpossible selection strategies that minimizes theexpected risk defined as follows:?
??
?
?
?
.|,minarg|minarg*?????????dDpLDRkkkk???
(4)Although we have described a general formu-lation for the extractive summarization problemon the grounds of the Bayes decision theory, weconsider hereafter a special case of it where theselection strategy is represented by a binary deci-sion vector, of which each element correspondsto a specific sentence iS  in the document D  and designates whether it should be selected as partof the summary or not, as the first such attempt.More concretely, we assume that the summary81sentences of a given document can be iterativelychosen (i.e., one at each iteration) from the doc-ument until the aggregated summary reaches apredefined target summarization ratio.
It turnsout that the binary vector for each possible actionwill have just one element equal to 1 and all oth-ers equal to zero (or the so-called ?one-of-n?coding).
For ease of notation, we denote the bi-nary vector by iS  when the i -th element has a value of 1.
Therefore, the risk minimizationframework can be reduced to?
??
?
?
?,~|,minarg~|minarg~~~*?????
?DSjjiDSiDSjiiDSPSSLDSRS(5)where D~  denotes the remaining sentences thathave not been selected into the summary yet (i.e.,the ?residual?
document); ?
?DSP j ~|  is the post-erior probability of a sentence jS  given D~ .
Ac-cording to the Bayes?
rule, we can further ex-press ?
?DSP j ~|  as (Chen et al, 2009)?
?
?
?
?
??
?
,~|~~| DPSPSDPDSP jjj ?
(6)where ?
?jSDP |~  is the sentence generative prob-ability, i.e., the likelihood of D~  being generatedby jS ; ?
?jSP  is the prior probability of jS  being important; and the evidence ?
?DP ~  is the marginalprobability of D~ , which can be approximated by?
?
?
?
?
?.|~~ ~??
?DS mmm SPSDPDP               (7)By substituting (6) and (7) into (5), we obtainthe following final selection strategy for extrac-tive summarization:?
?
?
?
?
??
?
?
?.|~|~,minarg ~~~* ?
????
?DSDSmmjjjiDS jmi SPSDPSPSDPSSLS  (8)A remarkable feature of this framework lies inthat a sentence to be considered as part of thesummary is actually evaluated by three differentfundamental factors: (1) ?
?jSP  is the sentence prior probability that addresses the importance ofsentence jS  itself; (2) ?
?jSDP |~  is the sentence generative probability that captures the degree ofrelevance of jS to the residual document D~ ; and (3) ?
?ji SSL ,  is the loss function that characteriz-es the relationship between sentence iS  and any other sentence jS .
As we will soon see, such a framework can be regarded as a generalization ofseveral existing summarization methods.
A de-tailed account on the construction of these threecomponent models in the framework will be giv-en in the following section.4 Proposed MethodsThere are many ways to construct the abovementioned three component models, i.e., the sen-tence generative model ?
?jSDP |~ , the sentence prior model ?
?jSP , and the loss function ?
?ji SSL , .
In what follows, we will shed light on one possi-ble attempt that can accomplish this goal elegant-ly.4.1 Sentence generative modelIn order to estimate the sentence generativeprobability, we explore the language modeling(LM) approach, which has been introduced to awide spectrum of IR tasks and demonstrated withgood empirical success, to predict the sentencegenerative probability.
In the LM approach, eachsentence in a document can be simply regardedas a probabilistic generative model consisting ofa unigram distribution (the so-called ?bag-of-words?
assumption) for generating the document(Chen et al, 2009):?
?
?
?
?
?, ~ ~,~ DwcDw jj SwPSDP ??
?
(9)where ?
?Dwc ~,  is the number of times that indexterm (or word) w  occurs in D~ , reflecting that wwill contribute more in the calculation of ?
?
~ jSDP  if it occurs more frequently in D~ .
Note that the sentence model ?
?jSwP  is simply esti-mated on the basis of the frequency of indexterm w  occurring in the sentence jS  with the maximum likelihood (ML) criterion.
In a sense,(9) belongs to a kind of literal term matchingstrategy (Chen, 2009) and may suffer the prob-lem of unreliable model estimation owing partic-ularly to only a few sampled index terms presentin the sentence (Zhai, 2008).
To mitigate thispotential defect, a unigram probability estimatedfrom a general collection, which models the gen-eral distribution of words in the target language,is often used to smooth the sentence model.
In-terested readers may refer to (Zhai, 2008; Chenet al, 2009) for a thorough discussion on variousways to construct the sentence generative model.4.2 Sentence prior modelThe sentence prior probability ?
?jSP  can be re-garded as the likelihood of a sentence being im-portant without seeing the whole document.
Itcould be assumed uniformly distributed over sen-tences or estimated from a wide variety of factors,such as the lexical information, the structuralinformation or the inherent prosodic properties ofa spoken sentence.A straightforward way is to assume that thesentence prior probability ?
?jSP  is in proportion to the posterior probability of a sentence jS  be-82ing included in the summary class when observ-ing a set of indicative features jX  of jS  derived from such factors or other sentence importancemeasures (Kupiec et al, 1999).
These featurescan be integrated in a systematic way into theproposed framework by taking the advantage ofthe learning capability of the supervised ma-chine-learning methods.
Specifically, the priorprobability ?
?jSP  can be approximated by:?
?
?
?
?
??
?
?
?
?
?
?
?
,|| | SSSS SS PXPPXP PXpSP jj jj ??
(10)where ?
?S|jXP  and ?
?S|jXP  are the likelihoods that a sentence jS  with features jX  are generat-ed by the summary class S  and the non-summary class S , respectively; the prior proba-bility ?
?SP  and ?
?SP  are set to be equal in thisresearch.
To estimate ?
?S|jXP  and ?
?S|jXP , several popular supervised classifiers (or summa-rizers), like BC or SVM, can be leveraged forthis purpose.4.3 Loss functionThe loss function introduced in the proposedsummarization framework is to measure the rela-tionship between any pair of sentences.
Intuitive-ly, when a given sentence is more dissimilarfrom most of the other sentences, it may incurhigher loss as it is taken as the representativesentence (or summary sentence) to represent themain theme embedded in the other ones.
Conse-quently, the loss function can be built on the no-tion of the similarity measure.
In this research,we adopt the cosine measure (Gong and Liu,2001) to fulfill this goal.
We first represent eachsentence iS  in vector form where each dimension specifies the weighted statistic itz , , e.g., the product of the term frequency (TF) and inversedocument frequency (IDF) scores, associatedwith an index term tw  in sentence iS .
Then, the cosine similarity between any given two sen-tences ?
?ji SS ,  is?
?
.,12,12,1 ,,????
????
?Tt jtTt itTt jtitji zzzzSSSim          (10)The loss function is thus defined by?
?
?
?.,1, jiji SSSimSSL ??
(11)Once the sentence generative model ?
?jSDP |~ , the sentence prior model ?
?jSP  and the loss func-tion ?
?ji SSL ,  have been properly estimated, the summary sentences can be selected iteratively by(8) according to a predefined target summariza-tion ratio.
However, as can be seen from (8), anew summary sentence is selected without con-sidering the redundant information that is alsocontained in the already selected summary sen-tences.
To alleviate this problem, the concept ofmaximum marginal relevance (MMR) (Carbonelland Goldstein, 1998), which performs sentenceselection iteratively by striking the balance be-tween topic relevance and coverage, can be in-corporated into the loss function:?
?
?
??
?
?
?
,',max1,1,' ???????????????SSSimSSSimSSLiSjijiSumm??
(12)where Summ  represents the set of sentences thathave already been included into the summaryand the novelty factor ?
is used to trade off be-tween relevance and redundancy.4.4 Relation to other summarization modelsIn this subsection, we briefly illustrate the rela-tionship between our proposed summarizationframework and a few existing summarizationapproaches.
We start by considering a specialcase where a 0-1 loss function is used in (8),namely, the loss function will take value 0 if thetwo sentences are identical, and 1 otherwise.Then, (8) can be alternatively represented by?
?
?
??
?
?
??
?
?
??
?
?
?
,|~|~maxarg|~|~minarg~~,~ ~~*???
???????
?DS mmiiDSSSDSDS mmjjDSmiijjmiSPSDPSPSDPSPSDPSPSDPS(13)which actually provides a natural integration ofthe supervised and unsupervised summarizers(Lin et al, 2009), as mentioned previously.If we further assume the prior probability ?
?jSP  is uniformly distributed, the important (or summary) sentence selection problem has nowbeen reduced to the problem of measuring thedocument-likelihood ?
?jSDP |~ , or the relevance between the document and the sentence.
Alone asimilar vein, the important sentences of a docu-ment can be selected (or ranked) solely based onthe prior probability ?
?jSP  with the assumption of an equal document-likelihood ?
?jSDP |~ .5 Experimental setup5.1 DataThe summarization dataset used in this researchis a widely used broadcast news corpus collectedby the Academia Sinica and the Public Televi-sion Service Foundation of Taiwan between No-vember 2001 and April 2003 (Wang et al, 2005).Each story contains the speech of one studioanchor, as well as several field reporters and in-terviewees.
A subset of 205 broadcast news doc-83uments compiled between November 2001 andAugust 2002 was reserved for the summarizationexperiments.Three subjects were asked to create summariesof the 205 spoken documents for the summariza-tion experiments as references (the gold standard)for evaluation.
The summaries were generated byranking the sentences in the reference transcriptof a spoken document by importance withoutassigning a score to each sentence.
The averageChinese character error rate (CER) obtained forthe 205 spoken documents was about 35%.Since broadcast news stories often follow arelatively regular structure as compared to otherspeech materials like conversations, the position-al information would play an important (domi-nant) role in extractive summarization of broad-cast news stories; we, hence, chose 20 docu-ments for which the generation of referencesummaries is less correlated with the positionalinformation (or the position of sentences) as theheld-out test set to evaluate the general perfor-mance of the proposed summarization frame-work, and 100 documents as the development set.5.2 Performance evaluationFor the assessment of summarization perfor-mance, we adopted the widely used ROUGEmeasure (Lin, 2004) because of its higher corre-lation with human judgments.
It evaluates thequality of the summarization by counting thenumber of overlapping units, such as N-grams,longest common subsequences or skip-bigram,between the automatic summary and a set of ref-erence summaries.
Three variants of the ROGUEmeasure were used to quantify the utility of theproposed method.
They are, respectively, theROUGE-1 (unigram) measure, the ROUGE-2(bigram) measure and the ROUGE-L (longestcommon subsequence) measure (Lin, 2004).The summarization ratio, defined as the ratio ofthe number of words in the automatic (or manual)summary to that in the reference transcript of aspoken document, was set to 10% in this re-search.
Since increasing the summary lengthtends to increase the chance of getting higherscores in the recall rate of the various ROUGEmeasures and might not always select the rightnumber of informative words in the automaticsummary as compared to the reference summary,all the experimental results reported hereafter areobtained by calculating the F-scores of theseROUGE measures, respectively (Lin, 2004).
Ta-ble 1 shows the levels of agreement (the Kappastatistic and ROUGE measures) between thethree subjects for important sentence ranking.They seem to reflect the fact that people may notalways agree with each other in selecting the im-portant sentences for representing a given docu-ment.5.3 Features for supervised summarizersWe take BC as the representative supervisedsummarizer to study in this paper.
The input toBC consists of a set of 28 indicative featuresused to characterize a spoken sentence, includingthe structural features, the lexical features, theacoustic features and the relevance feature.
Foreach kind of acoustic features, the minimum,maximum, mean, difference value and mean dif-ference value of a spoken sentence are extracted.The difference value is defined as the differencebetween the minimum and maximum values ofthe spoken sentence, while the mean differencevalue is defined as the mean difference betweena sentence and its previous sentence.
Finally, therelevance feature (VSM score) is use to measurethe degree of relevance for a sentence to thewhole document (Gong and Liu, 2001).
Thesefeatures are outlined in Table 2, where each ofthem was further normalized to zero mean andunit variance.6 Experimental results and discussions6.1 Baseline experimentsIn the first set of experiments, we evaluate thebaseline performance of the LM and BC summa-rizers (cf.
Sections 4.1 and 4.2), respectively.The corresponding results are detailed in Table 3,Kappa ROGUE-1 ROUGE-2 ROUGE-L0.400 0.600 0.532 0.527Table 1: The agreement among the subjects for impor-tant sentence ranking for the evaluation set.Structuralfeatures1.Duration of the current sentence2.Position of the current sentence3.Length of the current sentenceLexicalFeatures1.Number of named entities2.Number of stop words3.Bigram language model scores4.Normalized bigram scoresAcousticFeatures1.The 1st formant2.The 2nd formant3.The pitch value4.The peak normalized cross-correlation of pitchRelevanceFeature 1.VSM scoreTable 2: Basic sentence features used by BC.84where the values in the parentheses are the asso-ciated 95% confidence intervals.
It is also worthmentioning that TD denotes the summarizationresults obtained based on manual transcripts ofthe spoken documents while SD denotes the re-sults using the speech recognition transcriptswhich may contain speech recognition errors andsentence boundary detection errors.
In this re-search, sentence boundaries were determined byspeech pauses.
For the TD case, the acoustic fea-tures were obtained by aligning the manual tran-scripts to their spoken documents counterpart byperforming word-level forced alignment.Furthermore, the ROGUE measures, in es-sence, are evaluated by counting the number ofoverlapping units between the automatic sum-mary and the reference summary; the corres-ponding evaluation results, therefore, would beseverely affected by speech recognition errorswhen applying the various ROUGE measures toquantify the performance of speech summariza-tion.
In order to get rid of the cofounding effectof this factor, it is assumed that the selectedsummary sentences can also be presented inspeech form (besides text form) such that userscan directly listen to the audio segments of thesummary sentences to bypass the problem causedby speech recognition errors.
Consequently, wecan align the ASR transcripts of the summarysentences to their respective audio segments toobtain the correct (manual) transcripts for thesummarization performance evaluation (i.e., forthe SD case).Observing Table 3 we notice two particulari-ties.
First, there are significant performance gapsbetween summarization using the manual tran-scripts and the erroneous speech recognitiontranscripts.
The relative performance degrada-tions are about 15%, 34% and 23%, respectively,for ROUGE-1, ROUGE2 and ROUGE-L meas-ures.
One possible explanation is that the errone-ous speech recognition transcripts of spoken sen-tences would probably carry wrong informationand thus deviate somewhat from representing thetrue theme of the spoken document.
Second, thesupervised summarizer (i.e., BC) outperforms theunsupervised summarizer (i.e., LM).
The betterperformance of BC can be further explained bytwo reasons.
One is that BC is trained with thehandcrafted document-summary sentence labelsin the development set while LM is instead con-ducted in a purely unsupervised manner.
Anotheris that BC utilizes a rich set of features to charac-terize a given spoken sentence while LM is con-structed solely on the basis of the lexical (uni-gram) information.6.2 Experiments on the proposed methodsWe then turn our attention to investigate the utili-ty of several methods deduced from our pro-posed summarization framework.
We first con-sider the case when a 0-1 loss function is used (cf.
(13)), which just show a simple combination ofBC and LM.
As can be seen from the first row ofTable 4, such a combination can give about 4%to 5% absolute improvements as compared to theresults of BC illustrated in Table 3.
It in somesense confirms the feasibility of combining thesupervised and unsupervised summarizers.Moreover, we consider the use of the loss func-tions defined in (11) (denoted by SIM) and (12)(denoted by MMR), and the corresponding re-sults are shown in the second and the third rowsof Table 4, respectively.
It can be found thatText Document (TD) Spoken Document (SD)ROGUE-1 ROUGE-2 ROUGE-L ROGUE-1 ROUGE-2 ROUGE-LBC  0.445 (0.390 - 0.504) 0.346 (0.201 - 0.415) 0.404 (0.348 - 0.468) 0.369 (0.316 - 0.426) 0.241 (0.183 - 0.302) 0.321 (0.268 - 0.378)LM  0.387  (0.302 - 0.474) 0.264 (0.168 - 0.366) 0.334 (0.251 - 0.415) 0.319 (0.274 - 0.367) 0.164 (0.115 - 0.224) 0.253 (0.215 - 0.301)Table 3: The results achieved by the BC and LM summarizers, respectively.Text Document (TD) Spoken Document (SD)Prior Loss ROGUE-1 ROUGE-2 ROUGE-L ROGUE-1 ROUGE-2 ROUGE-LBC0-1 0.501  0.401  0.459  0.417  0.281  0.356SIM 0.524  0.425  0.473  0.475  0.351  0.420MMR 0.529  0.426  0.479  0.475 0.351 0.420Uniform SIM 0.405 0.281 0.348 0.365 0.209 0.305 MMR 0.417 0.282 0.359 0.391 0.236 0.338Table 4: The results achieved by several methods derived from the proposed summarization framework.85MMR delivers higher summarization perfor-mance than SIM (especially for the SD case),which in turn verifies the merit of incorporatingthe MMR concept into the proposed frameworkfor extractive summarization.
If we further com-pare the results achieved by MMR with those ofBC and LM as shown in Table 3, we can findsignificant improvements both for the TD andSD cases.
By and large, for the TD case, the pro-posed summarization method offers relative per-formance improvements of about 19%, 23% and19%, respectively, in the ROUGE-1, ROUGE-2and ROUGE-L measures as compared to the BCbaseline; while the relative improvements are29%, 46% and 31%, respectively, in the samemeasurements for the SD case.
On the other hand,the performance gap between the TD and SDcases are reduced to a good extent by using theproposed summarization framework.In the next set of experiments, we simply as-sume the sentence prior probability ?
?jSP  de-fined in (8) is uniformly distributed, namely, wedo not use any supervised information cue butuse the lexical information only.
The importanceof a given sentence is thus considered from twoangles: 1) the relationship between a sentenceand the whole document, and 2) the relationshipbetween the sentence and the other individualsentences.
The corresponding results are illu-strated in the lower part of Table 4 (denoted byUniform).
We can see that the additional consid-eration of the sentence-sentence relationship ap-pears to be beneficial as compared to that onlyconsidering the document-sentence relevanceinformation (cf.
the second row of Table 3).
Italso gives competitive results as compared to theperformance of BC (cf.
the first row of Table 3)for the SD case.6.3 Comparison with conventional summa-rization methodsIn the final set of experiments, we compare ourproposed summarization methods with a fewexisting summarization methods that have beenwidely used in various summarization tasks, in-cluding LEAD, VSM, LexRank and CRF; thecorresponding results are shown in Table 5.
Itshould be noted that the LEAD-based methodsimply extracts the first few sentences in a doc-ument as the summary.
To our surprise, CRFdoes not provide superior results as compared tothe other summarization methods.
One possibleexplanation is that the structural evidence of thespoken documents in the test set is not strongenough for CRF to show its advantage of model-ing the local structural information among sen-tences.
On the other hand, LexRank gives a verypromising performance in spite that it only uti-lizes lexical information in an unsupervisedmanner.
This somewhat reflects the importanceof capturing the global relationship for the sen-tences in the spoken document to be summarized.As compared to the results shown in the ?BC?part of Table 4, we can see that our proposedmethods significantly outperform all the conven-tional summarization methods compared in thispaper, especially for the SD case.7 Conclusions and future workWe have proposed a risk minimization frame-work for extractive speech summarization, whichenjoys several advantages.
We have also pre-sented a simple yet effective implementation thatselects the summary sentences in an iterativemanner.
Experimental results demonstrate thatthe methods deduced from such a framework canyield substantial improvements over severalpopular summarization methods compared in thispaper.
We list below some possible future exten-sions: 1) integrating different selection strategies,e.g., the listwise strategy that defines the lossfunction on all the sentences associated with adocument to be summarized, into this framework,2) exploring different modeling approaches forthis framework, 3) investigating discriminativetraining criteria for training the component mod-els in this framework, and 4) extending and ap-plying the proposed framework to multi-document summarization tasks.ReferencesJames O. Berger Statistical decision theory andBayesian analysis.
Springer-Verlap, 1985.Berlin Chen.
2009.
Word topic models for spokendocument retrieval and transcription.
ACMTransactions on Asian Language InformationProcessing, 8, (1): 2:1 - 2:27.Jaime Carbonell and Jade Goldstein.
1998.
The use ofmmr, diversity-based reranking for reorderingdocuments and producing summaries.
In Proc.
ofAnnual International ACM SIGIR Conference onROGUE-1 ROUGE-2 ROUGE-LLEAD TD 0.320 0.197 0.283 SD 0.312 0.168 0.251VSM TD 0.345  0.220 0.287 SD 0.337  0.189 0.277LexRank TD 0.435  0.314 0.377 SD 0.348   0.204 0.294CRF TD 0.431 0.315 0.383 SD 0.358 0.220 0.291Table 5: The results achieved by four conventionalsummarization methods.86Research and Development in InformationRetrieval: 335 - 336.Yi-Ting Chen, Berlin Chen and Hsin-Min Wang.2009.
A probabilistic generative framework forextractive broadcast news speech summarization.IEEE Transactions on Audio, Speech andLanguage Processing, 17, (1): 95 - 106.John M. Conroy and Dianne P. O?Leary.
2001.
Textsummarization via hidden Markov models.
InProc.
of Annual International ACM SIGIRConference on Research and Development inInformation Retrieval: 406 - 407.G?ne?
Erkan and Dragomir R. Radev.
2004.
LexRank:graph-based lexical centrality as salience in textsummarization.
Journal or Artificial IntelligenceResearch, 22: 457 - 479.Mohamed Abdel Fattah and Fuji Ren.
2009.
GA, MR,FFNN, PNN and GMM based models forautomatic text summarization.
Computer Speechand Language, 23, (1): 126 - 144.Louisa Ferrier A maximum entropy approach to textsummarization.
School of Artificial Intelligence,University of Edinburgh, 2001.Sadaoki Furui, Tomonori Kikuchi, Yousuke Shinnakaand Chiori Hori.
2004.
Speech-to-text and speech-to-speech summarization of spontaneous speech.IEEE Transactions on Speech and AudioProcessing, 12, (4): 401 - 408.Michel Galley.
2006.
A skip-chain conditionalrandom field for ranking meeting utterances byimportance.
In Proc.
of Conference on EmpiricalMethods in Natural Language Processing: 364 -372.Vaibhava Goel and William Byrne.
2000.
MinimumBayes-risk automatic speech recognition.Computer Speech and Language, 14, (2): 115 -135.Yihong Gong and Xin Liu.
2001.
Generic textsummarization using relevance measure and latentsemantic analysis.
In Proc.
of AnnualInternational ACM SIGIR Conference onResearch and Development in InformationRetrieval: 19 - 25.Akira Inoue, Takayoshi Mikami and YoichiYamashita.
2004.
Improvement of speechsummarization using prosodic information, InProc.
of Speech Prosody: 599 - 602.Shankar Kumar and William Byrne.
2004.
MinimumBayes-risk decoding for statistical machinetranslation.
In Proc.
of Human LanguageTechnology conference / North American chapterof the Association for Computational Linguisticsannual meeting: 169 - 176.Aleksander Kolcz, Vidya Prabakarmurthi and JugalKalita.
2001.
Summarization as feature selectionfor text categorization.
In Proc.
of Conference onInformation and Knowledge Management: 365 -370.Julian Kupiec, Jan Pedersen and Francine Chen.
1999.A trainable document summarizer.
In Proc.
ofAnnual International ACM SIGIR Conference onResearch and Development in InformationRetrieval: 68 - 73.Konstantinos Koumpis and Steve Renals.
2000.Transcription And Summarization Of VoicemailSpeech.
In Proc.
of International Conference onSpoken Language Processing: 688 - 691.Chin-Yew Lin.
2004.
ROUGE: a Package forAutomatic Evaluation of Summaries.
In Proc.
ofWorkshop on Text Summarization Branches Out.Shih-Hsiang Lin, Berlin Chen and Hsin-Min Wang.2009.
A comparative study of probabilisticranking models for Chinese spoken documentsummarization.
ACM Transactions on AsianLanguage Information Processing, 8, (1): 3:1 -3:23.Shih-Hsiang Lin, Yueng-Tien Lo, Yao-Ming Yeh andBerlin Chen.
2009.
Hybrids of supervised andunsupervised models for extractive speechsummarization.
In Proc.
of Annual Conference ofthe International Speech CommunicationAssociation: 1507 - 1510.Inderjeet Mani and Mark T. Maybury Advances inautomatic text summarization.
MIT Press,Cambridge, 1999.Sameer R. Maskey and Julia Hirschberg.
2003.Automatic Summarization of Broadcast Newsusing Structural Features.
In Proc.
of the Euro-pean Conf.
Speech Communication and Technolo-gy: 1173 - 1176.Kathleen McKeown, Julia Hirschberg, Michel Galleyand Sameer Maskey.
2005.
From text to speechsummarization.
In Proc.
of IEEE InternationalConference on Acoustics, Speech, and SignalProcessing: 997 - 1000.Rada Mihalcea and Paul Tarau.
2005.
TextRank:bringing order into texts.
In Proc.
of Conferenceon Empirical Methods in Natural LanguageProcessing: 404 - 411.Dragomir R. Radev, Hongyan Jing, Ma?gorzata Stysand Daniel Tam.
2004.
Centroid-basedsummarization of multiple documents.Information Processing and Management, 40: 919- 938.Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang andZheng Chen.
2007.
Document summarizationusing conditional random fields.
In Proc.
ofInternational Joint Conference on ArtificialIntelligence: 2862 - 2867.Hsin-Min Wang, Berlin Chen, Jen-Wei Kuo and Shih-Sian Cheng.
2005.
MATBN: A Mandarin Chinesebroadcast news corpus.
International Journal ofComputational Linguistics and Chinese LanguageProcessing, 10, (2): 219 - 236.ChengXiang Zhai and John Lafferty.
2006.
A riskminimization framework for information retrieval.Information Processing & Management, 42, (1):31 - 55.ChengXiang Zhai.
Statistical language models forinformation retrieval.
Morgan & ClaypoolPublishers, 2008.Justin Jian Zhang, Ho Yin Chan and Pascale Fung.2007.
Improving Lecture Speech SummarizationUsing Rhetorical Information.
In Proc.
of Workshopof Automatic Speech Recognition Understanding:195 - 200.87
