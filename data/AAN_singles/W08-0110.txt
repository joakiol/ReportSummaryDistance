Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 72?75,Columbus, June 2008. c?2008 Association for Computational LinguisticsSpeaking without knowing what to say?
or when to endAnna HjalmarssonCentre for Speech TechnologyKTHSE-10044, Stockholm, Swedenannah@speech.kth.seAbstractHumans produce speech incrementally andon-line as the dialogue progresses using in-formation from several different sources inparallel.
A dialogue system that generatesoutput in a stepwise manner and not in pre-planned syntactically correct sentences needsto signal how new dialogue contributions re-late to previous discourse.
This paper de-scribes a data collection which is thefoundation for an effort towards more human-like language generation in DEAL, a spokendialogue system developed at KTH.
Two an-notators labelled cue phrases in the corpuswith high inter-annotator agreement (kappacoefficient 0.82).1 IntroductionThis paper describes a data collection with the goalof modelling more human-like language generationin DEAL, a spoken dialogue system developed atKTH.
The DEAL objectives are to build a systemwhich is fun, human-like, and engaging to talk to,and which gives second language learners ofSwedish conversation training (as described inHjalmarsson et al, 2007).
The scene of DEAL isset at a flea market where a talking animated agentis the owner of a shop selling used objects.
Thestudent is given a mission: to buy items from theshop-keeper at the best possible price by bargain-ing.
From a language learning perspective and tokeep the students motivated, the agent?s languageis crucial.
The agent needs to behave human-like ina way which allows the users to suspend some oftheir disbeliefs and talk to DEAL as if talking toanother human being.
In an experimental study(Hjalmarsson & Edlund, in press), where a spokendialogue system with human behaviour was simu-lated, two different systems were compared: a rep-lica of human behaviour and a constrained versionwith less variability.
The version based on humanbehaviour was rated as more human-like, politeand intelligent.1.1 Human language productionHumans produce speech incrementally and on-lineas the dialogue progresses using information fromseveral different sources in parallel (Brennan,2000; Aist et al, 2006).
We anticipate what theother person is about to say in advance and startplanning our next move while this person is stillspeaking.
When starting to speak, we typically donot have a complete plan of how to say somethingor even what to say.
Yet, we manage to rapidlyintegrate information from different sources in par-allel and simultaneously plan and realize new dia-logue contributions.
Pauses, corrections andrepetitions are used to stepwise refine, alter andrevise our plans as we speak (Clark & Wasow,1998).
These human behaviours bring valuableinformation that contains more than the literalmeanings of the words (Arnold et al, 2003).In order to generate output incrementally inDEAL we need extended knowledge on how tosignal relations between different segments ofspeech.
In this paper we report on a data collectionof human-human dialogue aiming at extending theknowledge of human interaction and in particularto distinguish different types of cue phrases used inthe DEAL domain.722 The DEAL corpus collectionThe dialogue data recorded was informal, human-human, face-to-face conversation.
The task and therecording environment were set up to mimic theDEAL domain and role play.2.1 Data collectionThe data collection was made with 6 subjects (4male and 2 female), 2 posing as shop keepers and 4as potential buyers.
Each customer interacted withthe same shop-keeper twice, in two different sce-narios.
The shop-keepers and customers were in-structed separately.
The customers were given amission: to buy items at a flea market at the bestpossible price from the shop-keeper.
The task wasto buy 3 objects for a specific purpose (e.g.
to buytools to repair a house).
The customers were givena certain amount of toy money, however notenough to buy what they were instructed to buywithout bargaining.
The shop-keeper sat behind adesk with images of different objects pinned to thewall behind him.
Some of the object had obviousflaws, for example a puzzle with a missing piece,to open up for interesting negotiation.
None of theshop-keepers had any professional experience ofbargaining, which was appropriate since we weremore interested in capturing na?ve conceptualmetaphors of bargaining rather than real life pricenegotiation.
Each dialogue was about 15 minuteslong, so about 2 hours of speech were collectedaltogether.
The shop-keepers used an average of13.4 words per speaker turn while the buyers?
turnswere generally shorter, 8.5 words per turn (in thispaper turn always refers to speaker turns).
In total16357 words were collected.3 AnnotationAll dialogues were first transcribed orthographi-cally including non-lexical entities such as laughterand hawks.
Filled pauses, repetitions, correctionsand restarts were also labelled manually.3.1 Cue phrasesLinguistic devices used to signal relations betweendifferent segments of speech are often referred toas cue phrases.
Other frequently used terms arediscourse markers, pragmatic markers or discourseparticles.
Typical cue phrases in English are: oh,well, now, then, however, you know, I mean, be-cause, and, but and or.
Much research within dis-course analysis, communicative analysis andpsycholinguistics has been concerned with theseconnectives and what kind of relations they hold(for an overview see Schourup, 1999).
Our defini-tion of cue phrases is broad and all types of lin-guistic entities that the speakers use to hold thedialogue together at different communicative lev-els are included.
A rule of thumb is that cuephrases are words or chunks of words that havelittle lexical impact at the local speech segmentlevel but serve significant pragmatic function.
Togive an exact definition of what cue phrases are isdifficult, as these entities often are ambiguous.
Ac-cording to the definition used here, cue phrases canbe a single word or larger units, occupy variouspositions, belong to different syntactic classes, andbe realized with different prosodic contours.The first dialogue was analyzed and usedto decide which classes to use in the annotationscheme.
Nine of the classes were a subset of thefunctional classification scheme of discoursemarkers presented in Lindstr?m (2008).
A tenthclass, referring, was added.
There were 3 differentclasses for connectives, 3 classes for responsivesand 4 remaining classes.
The classes are presentedin Table 1; the first row contains an example in itscontext from data, the word(s) in bold are the la-belled cue phrase, and the second row presents fre-quently used instances of that class.Additive Connectives (CAD)och gr?nt ?r ju fint[and green is nice]och, allts?, s?
[and, therefore, so]Contrastive Connectives (CC)men den ?r ganska antik[but it is pretty antique]men, fast, allts?
[but, although, thus]Alternative Connectives (CAL)som jag kan titta p?
ist?llet[which I can look at instead]eller, ist?llet [or, instead]Responsive (R)ja jag tycker ju det[yeah I actually think so]ja, mm, jaha, ok[yes, mm, yeah, ok]Responsive New Information (RNI)jaha har du n?gra s?dana[right do you have any of those]jaha, ok, ja, mm[right, ok, yes, mm]73Responsive Disprefrence (RD)ja men det ?r klart dom funkar[yeah but of course they work]ja, mm, jo [yes, mm, sure]Response Eliciting (RE)vad ska du ha f?r den d?
[how much do you want for that one then]d?, eller hur [then, right]Repair Correction (RC)nej nu sa jag fel[no now I said wrong]nej, jag menade [no, I meant]Modifying (MOD)ja jag tycker ju det[yeah I actually think so]ju, liksom, jag tycker ju det [of course, so to speak, I like]Referring (REF)fyra hundra kronor sa vi[four hundred crowns we said]sa vi, sa vi inte det [we said, wasn?t that what we said]Table 1: The DEAL annotation schemeThe labelling of cue phrases included a two-foldtask, both to decide if a word was a cue phrase ornot ?
a binary task ?
but also to classify whichfunctional class it belongs to according to the an-notation scheme.
The annotators could both see thetranscriptions and listen to the recordings whilelabelling.
81% of the speaker turns contained atleast one cue phrase and 21% of all words werelabelled as cue phrases.
Table 2 presents the distri-bution of cue phrases over the different classes.0%15%30%MOD R CAD CC RD RNI RE REF RC CALTable 2: Cue phrase distribution over the different classesTwo of the eight dialogues were annotated by twodifferent annotators.
A kappa coefficient was cal-culated on word level.
The kappa coefficient forthe binary task, to classify if a word was a cuephrase or not, was 0.87 (p=0.05).
The kappa coef-ficient for the classification task was 0.82 (p=0.05).Three of the classes, referring, connective alterna-tive and repair correction, had very few instances.The agreement in percentage distributed over thedifferent classes is presented in Table 3.0%20%40%60%80%100%MOD RCAD CC RD RNIRE REFRC CALTable 3: % agreement for the different classes4 Data analysisTo separate cue phrases from other lexical entitiesand to determine what they signal is a complextask.
The DEAL corpus is rich in disfluencies andcue phrases; 86% of the speaker turns contained atleast one cue phrase or disfluency.
The annotatorshad access to the context and were allowed to lis-ten to the recordings while labelling.
The respon-sives were generally single words or non lexicalunits (e.g.
?mm?)
and appeared in similar dialoguecontexts (i.e.
as responses to assertions).
The clas-sification is likely based on their prosodic realiza-tion.
Acoustic analysis is needed in order to see ifand how they differ in prosodic contour.
InHirschberg & Litman (1993) prosodic analysis isused to distinguish between discourse and senten-tial use of cue phrases.
Table 4 presents how thedifferent cue phrases were distributed over speakerturns, at initial, middle or end position.0%20%40%60%80%100%MOD RCADCC RD RNIRE REF RCCAL AllendmiddleinitialTable 4: Turn position distribution5 Generation in DEALThe collected and labelled data is a valuable re-source of information for what cue phrases signalin the DEAL domain as well as how they are lexi-cally and prosodically realized.
To keep the re-74sponse times constant and without unnaturally longdelays, DEAL needs to be capable of grabbing theturn, hold it while the system is producing the restof the message, and release it after completion.DEAL is implemented using components from theHiggins project (Skantze et al, 2006) an off-the-shelf ASR system and a GUI with an embodiedconversational agent (ECA) (Beskow, 2003).
Acurrent research challenge is to redesign the mod-ules and architecture for incremental processing, toallow generation of conversational speech.
Deepgeneration in DEAL ?
the decision of what to sayon an abstract semantic level ?
is distributed overthree different modules; (1) the action manger, (2)the agent manager and the (3) communicativemanager.
The action manger is responsible for ac-tions related to user input and previous discourse1.The agent manager represents the agents?
personalmotivations and personality.
DEAL uses mixedinitiative and the agent manager takes initiatives.
Itmay for example try to promote certain objects orsuggest prices of objects in focus.
It also generatesemotional facial gestures related to events in thedialogue.
The communicative manager generatesresponses on a communicative level based on shal-low analysis of input.
For example, it initiates re-quests for confirmations if speech recognitionconfidence scores are low.
This module initiatesutterances when the user yields the floor, regard-less of whether the system has a complete plan ofwhat to say or not.
Using similar strategies as thesubjects recorded here, the dialogue system cangrab the turn and start to say something beforehaving completed processing input.
Many cuephrases were used in combination, signalling func-tion on different discourse levels; first a simpleresponsive, saying that the previous message wasperceived, and then some type of connective tosignal how the new contribution relates.6 Final remarksSince DEAL focuses on generation in role play, weare less interested in the ambiguous cue phrasesand more concerned with the instances where theannotators agreed.
The DEAL users are secondlanguage learners with poor knowledge in Swed-ish, and it may even be advisable that the agent?sbehaviour is exaggerated.1For more details on the discourse modeller see Skantze et al2006.AcknowledgmentsThis research was carried out at Centre for SpeechTechnology, KTH.
The research is also supportedby the Swedish research council project #2007-6431, GENDIAL and the Graduate School for Lan-guage Technology (GSLT).
Many thanks to JennyKlarenfjord for help on data collection and annota-tion and thanks to Rolf Carlson, Preben Wik andJens Edlund for valuable comments.ReferencesG.
Aist, J. Allen, E. Campana, L. Galescu, C. A. G?mezGallo, S. Stoness, M. Swift, and M. Tanenhaus.2006.
Software Architectures for Incremental Under-standing of Human Speech.
In Proc.
of Interspeech.J.
Arnold, M. Fagano, and M. Tanenhaus.
2003.
Disflu-encies signal theee, um, new information.
Journal ofPsycholinguistic Research, 32, 25-36.J.
Beskow.
2003.
Talking heads - Models and applica-tions for multimodal speech synthesis.
Doctoral dis-sertation, KTH.S.
Brennan.
2000.
Processes that shape conversation andtheir implications for computational.
In Proc.
of the38th Annual Meeting of the ACL.H.
Clark, and T. Wasow.
1998.
Repeating words inspontaneous speech.
Cognitive Psychology, 37(3),201-242.J.
Hirschberg, and D. Litman.
1993.
Empirical studieson the disambiguation of cue phrases.
ComputationalLinguistics, 19(3), 501-530.A.
Hjalmarsson, and J. Edlund.
In press.
Human-likeness in utterance generation: effects of variability.To be published in Proc.
of the 4th IEEE Workshopon Perception and Interactive Technologies forSpeech-Based Systems.
Kloster Irsee, Germany.A.
Hjalmarsson, P. Wik, and J. Brusk.
2007.
Dealingwith DEAL: a dialogue system for conversationtraining.
In Proc.
of SigDial.
Antwerp, Belgium.J.
Lindstr?m.
2008.
Diskursmark?rer.
In Tur ochordning; introduktion till svensk samtalsgrammatik(pp.
56-104).
Norstedts Akademiska F?rlag.
Stock-holm, Sweden.L.
Schourup.
1999.
Discourse markers.
Lingua, 107(3-4), 227-265.G.
Skantze, J. Edlund, and R. Carlson.
2006.
Talkingwith Higgins: Research challenges in a spoken dia-logue system.
In Perception and Interactive Tech-nologies (pp.
193-196).
Berlin/Heidelberg: Springer.75
