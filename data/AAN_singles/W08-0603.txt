BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 19?27,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsUsing Automated Feature Optimisation to Create an AdaptableRelation Extraction SystemBarry HaddowSchool of Informatics, University of Edinburgh,2 Buccleuch Place, Edinburgh, Scotland, EH8 9LWbhaddow@inf.ed.ac.ukAbstractAn adaptable relation extraction system for thebiomedical domain is presented.
The systemmakes use of a large set of contextual and shal-low syntactic features, which can be automati-cally optimised for each relation type.
The sys-tem is tested on three different relation types;protein-protein interactions, tissue expressionrelations and fragment to parent protein rela-tions.1 IntroductionIn biomedical information extraction, research innamed entity recognition (ner) and relation extrac-tion (re) has tended to focus on the extracting pro-teins and their interactions, with less thought givento how to adapt such systems to other entities andrelations of biomedical interest.
This is especiallytrue for re, where there is very little work on rela-tions other than protein-protein interactions.
Nev-ertheless, in order to create applications of use tobiologists such as curation assistants and improvedinformation extraction and retrieval systems it willbe necessary to treat a broader range of semantic re-lations.
The recent release of the Genia event corpus(Kim et al, 2008) will help to drive this research.The aim of this paper is to address the problem ofhow to create an re system, which can be adapted todifferent biomedical re problems with a minimum ofmanual intervention.
Since this paper focuses on re-lation extraction, it will be assumed that the namedentities are given, in other words the human anno-tated entities are used in all experiments.
The ap-proach taken to re is to treat it as a supervisedclassification problem on relation candidates, usinga large collection of shallow syntactic and contextualfeatures.
Relation candidates are pairs of entities,picked out using an appropriate candidate generationstrategy.
The use of shallow (as opposed to deep)syntactic features means that the system can relyon relatively robust linguistic tools such as part-of-speech taggers and chunkers, rather than more brit-tle and less widely available tools such as parsers.The difficulty with feature-based methods is, how-ever, how to select the best performing feature set,as simply adding all possible features does not nec-essarily give the best results (Guyon and Elisseeff,2003).
The approach taken here is to implement alarge feature set and then use a greedy search toexplore the feature set and select the best subsetof features.
This method of feature set optimisa-tion is not new (for example, it was applied by oneteam (Ganchev et al, 2007) on the BioCreative IIGene Mention task ), but in this work a comparisonof search starting points and feature groupings willbe presented.All re systems require a human-annotated corpusfor testing, and since a supervised machine learningapproach is employed, a corpus is also required fortraining the system.
The experiments described inthis paper make use of the ITI TXM corpora (Alexet al, 2008), which include the ppi corpus address-ing protein-protein interactions, and the te corpusaddressing tissue expression.
Both corpora consist ofapproximately 200 full-text biomedical research pa-pers annotated with entities, normalisations of enti-ties to standard databases, relations, and with en-riched information added to the relations.
Only theentities and relations will be considered here.This paper is organised as follows: after reviewingrelated work in the following section, the re systemis described in Section 3, including a description ofthe corpora, the relation candidate extraction strate-gies, the features employed, the feature optimisationmethods and the evaluation method.
In Section 4the results of the optimisation experiments are pre-sented and discussed, with some concluding remarksin Section 5.192 Related WorkRecent interest in the extraction of protein-proteininteractions has been given added impetus by sharedtasks such as the Language Learning in Logic(Cussens and Ne?dellec, 2005), and the BioCreativeII Interaction Pairs Subtask (Krallinger et al, 2008).It should be noted that the latter task, rather thanbeing concerned with the extraction of specific inter-action relation mentions, required systems to list the(curatable) interactions at a document level.
Manyteams, however, extracted the interaction mentionsas a first step and then processed these to give thedocument level list of curatable interactions.The extraction of protein-protein interactions hasalso been helped by the availability of annotated cor-pora, such as AIMed (Bunescu et al, 2005), whichconsists of around 1000 Medline abstracts annotatedwith proteins and their interactions.
In common withthe LLL corpus, the AIMed corpus only containsintra-sentential relations, and is somewhat smallerthan the corpus used in the current work.
In addi-tion to the work by the corpus creators (Bunescu andMooney, 2007), other authors have achieved good re-sults on AIMed by making use of dependency parsesin different ways (Erkan et al, 2007; Katrenko andAdriaans, 2006).
It is not clear, however, how wellthese techniques would transfer to other, similar, reproblems, and how much work would be involved intuning the systems for a new problem.Supervised learning based on shallow syntactic fea-tures has also been applied to the biomedical do-main, again focusing on protein-protein interactions(Nielsen, 2006; Giuliano et al, 2006).
A system-atic exploration of a set of such features for protein-protein interaction extraction was recently providedby Jiang and Zhai (2007), who also used features de-rived from the Collins parser.
They did not, however,experiment with the automated optimisation of thefeature sets.
In the news domain, the best reportedresults on the ACE dataset1 have been achieved bya composite kernel which depends partially on a fullparse, and partially on a collection of shallow syn-tactic features (Zhou et al, 2007).Aside from protein-protein interactions, there hasbeen little work directed at other types of relationsin the biomedical domain.
Recent corpus annota-tion projects such as Genia (Kim et al, 2008) andBioInfer (Pyysalo et al, 2007) include multiple typesof relations, however many of the relation types arerepresented in fairly small quantities.
In earlier work(Skounakis et al, 2003), the extraction of cell local-isation relations was studied using an automaticallycreated corpus.1http://www.nist.gov/speech/tests/ace/3 Methods3.1 CorporaThe ITI TXM corpora contain annotations relatedto protein-protein interactions (in the ppi corpus),and annotations related to tissue expression exper-iments (in the te corpus).
Each corpus consists ofbiomedical research articles, selected from PubMedand PubMedCentral either because they contain ex-perimentally proven protein-protein interactions (forthe ppi corpus), or because they contain tissue ex-pression experiments (for the te corpus).The articles were annotated by a team of quali-fied biologists.
The annotations consisted of entities(Table 1), normalisations of selected entities to stan-dard databases, relations (Table 2) and enrichmentof relations with additional information of interestto curators.
For each corpus, the entities markedwere those involved in the relation which formed theprincipal focus of that corpus (either ppi or te), andthose which could affect this relation.
In the te cor-pus, te relations were marked when the text statedthat a particular gene or gene product was present orabsent in a particular tissue, whilst ppi relations weremarked whenever a statement (positive or negative)was made about the interaction of a pair of Proteins,Mutants, Fragments, Complexes or Fusions.
In ad-dition, both corpora were annotated with frag re-lations which connect Fragments and Mutants withtheir parent Proteins.Corpus Entitiesppi CellLine, Complex, DrugCompound,ExperimentalMethod, Fragment, Fusion,Modification, Mutant, Proteinte Complex, DevelopmentalStage, Disease,DrugCompound, ExperimentalMethod,Fragment, Fusion, GOMOP, Gene,Mutant, Protein, Tissue, mRNAcDNATable 1: The entity types in the te and ppi corpora.Note that GOMOP stands for ?Gene or mRNAcDNAor Protein?
and was used when the annotators felt theauthor was using the term in an ambiguous way.In order to monitor annotation quality, and tomeasure of the difficulty of the task, some documentswere multiply annotated.
The counts of the numbersof unique documents in each section, together withthe numbers of annotated documents are shown inTable 3.
Note that the multiply annotated docu-ments were not reconciled, but the multiple copieswere included in the corpus.
Each corpus was splitinto three sections ?
train, devtest and test ?with the first two sections being used for system de-velopment, and the last reserved for final testing.20Corpus RelationtypeEntity 1 Types Entity 2 Types Countppi ppi Protein, Fusion, Mutant, Fragment orComplexProtein, Fusion, Mutant, Fragment orComplex11,523frag Protein Mutant or Fragment 16,002te te Gene, Protein, mRNAcDNA, GOMOP,Fusion, Mutant, Complex or FragmentTissue 12,426frag Protein Mutant or Fragment 4,735Table 2: Relation types in each corpus.Corpus Segment Unique Doc-umentsAnnotatedDocumentsppi train 133 221devtest 39 58train 45 57te train 151 221devtest 41 48test 46 59Table 3: Counts of documents and annotations in eachcorpus.Corpus Relation Intra Interppi ppi 10,607(92.1%) 916(7.9%)frag 10,176(63.6%) 5,826(36.4%)te te 10,356(83.3%) 2,070(16.7%)frag 3,335(70.4%) 1,400(29.6%)Table 4: Counts of inter and intra-sentential relations.Annotators were permitted to mark relationsbetween entities in the same sentence (intra-sentential), or between entities in different sentences(inter-sentential).
The majority of relations wereintra-sentential, with frag relations showing thehighest proportion of inter-sententials.
Table 4 showsthe counts of inter/intra-sentential relations of eachtype.Some examples of each type of relation will nowbe presented.
The first example is from PubMed16436664, and is a te relation:Our recent observations that ?
?v?5?1 is up-regulated in ?scleroderma fibroblasts?1 andthat the transient overexpression of ?v?5increases the human ?
?2(I) collagen?2 geneexpression in normal ?fibroblasts?2 .
.
.There are two different te relations in this sentencefragment, indicated by the numerical subscripts; thefirst connects a Tissue and a Complex, and the sec-ond connects a Tissue with a Gene.
Another examplefrom the same paper shows a frag relation.Because ?
?5?1 has a ?cytoplasmic domain?1highly homologous to that of ?6-subunit, 42we made a hypothesis that ?v?5 activatesSLC by the nonproteolytic pathway.The annotators could also mark negative te and ppirelations, as shown in the following example of a ppirelation taken from PubMedCentral 1075921.It was also previously reported that twotruncated versions of ?p53?1,2, consistingof residues ?2-45?1,3 and ?46-71?2,4, do notbind ?hRPA70?3,4 (47)Here the ppi relations connect the two Fragments(?2-45?
and ?46-71?)
to the Protein ?hRPA70?,whilst frag relations connect the Fragments withtheir parent Protein ?p53?.In contrast with the straightforward intra-sentential relations shown above, the following (fromPubMed 16399077) is an example of an inter-sentential te relation (only the related entities areshown).To test whether SPE can activate Toll sig-naling, we expressed activated SPE in ?S2cells?1 and in flies, and we then assayedthe expression of the gene for Drosomycin(Drs), an antifungal peptide known to beinduced by Toll signaling in response to mi-crobial infection (Lemaitre et al, 1996).
Inboth cases, ?Drs?2 expression was signifi-cantly induced in the absence of infection,In this example, the annotator has connected a Tis-sue on the first sentence, with an mRNAcDNA inthe second.The multiply annotated documents in the corpuswere used to calculate the inter-annotator agreement(iaa), by scoring different versions of the annota-tion of the same document against each other.
Foreach corresponding pair of annotations, one anno-tator was selected as the ?gold?, and the other an-notator scored against the first using precision, re-call and F1 on relations.
Only relations where bothannotators agreed on the participating entities wereconsidered.
The scores for each annotated documentpair were then micro-averaged (where each example21Corpus Type Intra Inter Allppi ppi 69.7 41.1 67.0frag 90.5 73.9 84.6All 78.7 67.3 76.1te te 72.8 59.4 70.1frag 89.7 69.0 84.0All 77.4 62.7 74.1Table 5: iaa for relation annotation, split by inter- andintra-sententialis given equal weight) to produce overall iaa scoresfor the corpus, shown in Table 5.The main observations from Table 5 are that teand ppi relations are harder to annotate than fragrelations, and that inter-sentential are harder thanintra-sentential.
In particular, the iaa for intra-sentential frag relations is very high, probably be-cause many of these are very straightforward con-structions such as ?Fragment of Protein?.
Inter-sentential relations are often less clear as they in-volve linking information between several sentences,for example using coreferences.Both corpora were pre-processed before re wasapplied.
The pre-processing involved tokenisation,sentence boundary detection, lemmatising.
part-of-speech tagging, head word detection and chunking.The part-of-speech tagging uses the Curran & Clarkmaximum entropyMarkovmodel tagger (Curran andClark, 2003) trained on MedPost data (Smith etal., 2004), whilst the other preprocessing stages areall rule-based.
The tokenisation, sentence bound-ary detection, head word identification and chunk-ing components were implemented with the lt-xml2tools (Grover and Tobin, 2006), and the lemmatisa-tion used morpha (Minnen et al, 2000).3.2 The Relation Extraction SystemRelation extraction is treated a classification prob-lem, by generating candidate relations, and classify-ing them as either true or false.
In the optimisa-tion experiments described in this paper, Zhang Le?smaximum entropy (maxent) classifier2 was used,since its performance was very competitive and itsfast training time permitted extensive feature exper-imentation.
The Gaussian prior was set to 0.1, andthe maximum training iterations to 100.
In order toassess the performance of the final system, maxentwas compared with support vector machines (svm)using the SVM light toolkit (Joachims, 1999).
Sinceboth the classifiers assign a confidence to each pre-diction, a varying threshold can be applied to theoutput of the classifier to provide a precision-recall2http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.htmltradeoff.Candidate relations were generated by consider-ing entity pairs of the appropriate type, taking intoaccount the distance between the entities.
It wasthought that inter-sentential and intra-sentential re-lations would require different feature sets and differ-ent models, so inter- and intra-sentential candidateswere generated separately.
For intra-sentential rela-tions, all entity pairs of the appropriate type (as inTable 2) in the same sentence were permitted as can-didates, with the sole exclusion being that any enti-ties contained in a Fusion entity were not allowed toparticipate in candidate te relations.
This restric-tion was in place in the annotation guidelines, so nosuch relations were annotated.
For intra-sententialrelations in the training data, around 25-30% of thecandidate relations are actual relations.Generating inter-sentential candidates is moreproblematic, as measures must be taken to limit thenumber of candidates.
Inter-sentential frag candi-dates are restricted to a distance of no more than 5sentences, whilst inter-sentential ppi and te candi-dates are restricted to participants in adjacent sen-tences.
Inter-sentential re is performed after intra-sentential re, so the candidate generation strategyhas access to the annotated intra-sentential relations(in training) and the predicted intra-sentential rela-tions (in testing).
For te and ppi, candidates areonly created for those entities not already in a rela-tion, and for frag candidates are only created if theMutant or Fragment is not already in a relation.
Fur-thermore, for frag relations, if there is more thanone Protein instance with the same lexical form inthe 5 sentence window, then a candidate relation isonly created between a given Fragment/Mutant andthe nearest occurrence of this Protein.
For inter-sentential frag relations, around 20% of the candi-dates are actual relations, however for te and ppi,only about 1% of the candidate relations are actualrelations.3.3 FeaturesEach candidate relation is mapped to a feature rep-resentation, where the features are binary or real-valued functions of relations.
The majority of thefeatures are binary, although these are actually spe-cial cases of real-valued functions, taking values 0 or1.
A feature representation of a relation is normallywritten as a sequence of strings, each correspondingto a different feature, and the presence or absence ofa binary feature indicating whether it is on or off.
Inorder that the relation extractor could be applied todifferent problems and optimised, a large number offeatures were implemented, with the intention thatthe feature space could be automatically searched tofind the best subset.22Features are normally grouped into feature tem-plates and, as is common in the literature, the featuretemplates may also be referred to as features.
For in-stance, a feature template may be ?the token to theright of the second entity in the relation?, which thengives rise to a set of boolean features with the pre-fix ctxt-w-rf1-.
One such feature in this set is thefeature which indicates that the token to the rightof the second entity is ?the?, i.e.
ctxt-w-rf1-the.The feature templates are then collected into fea-ture groups, such as ?context features?, which arereally just a convenient way of conceptualising, im-plementing and managing the features, and do notnecessarily reflect any common behaviour amongstthe features in a group.The following is a comprehensive list of the featureimplemented in the re system with features listedby group, and the possible options for each featuregroup given.
The options are used to turn on or offfeature templates in the group, or change templates,and may be boolean or numerical.
The nature ofthe options will be important in the feature explo-ration experiments since they influence the type ofsearch operations which may be used to explore thefeature space.
The features are virtually all domainindependent, except for perhaps the SignSlashSignfeature which is specific to te.
The RelationKey-wordFeature can easily be ported to a new domainby generating a list of keywords appropriate for thegiven relation.In the feature group descriptions which follow, theterm ?participants?
refers to the entities within thecandidate relation.
Some of the features make use ofthe ?vlw backoff?, which for a given token is definedas the verb stem, backing off to the lemma if that isnot available, backing off to the token itself.Chunk This group has three optional templates; onewhich adds the concatenated sequence of chunk typesbetween the participants, and two templates whichadd the count of chunks between the participants asbinary and numeric features, respectively.
So if thechunk count is, for example 4, the binary featurewould be chunk-bwcount-4 and the numeric featurewould have name chunk-bwcount and value 4.EntitiesBetween This has templates to indicate thetype and relative position of the entities between thetwo participants.
For te relations, only Tissue en-tities are considered, whilst for other relations onlyProteins are considered.Entity Features derived from the participating enti-ties are added by the templates in this group, whichhas options to turn on the entity?s text, class andbigrams of these.
There is also a feature templatewhich adds all words in the entities as separate fea-tures, and one that adds all words in the second en-tity only, plus options to add features which indicatewhen the two entities have the same textual form, orwhen one is a substring of the other.EntityContext The entity context can include to-kens, part-of-speech tags, chunk tags and vlw back-offs, each within window sizes determined by numer-ical options.
A further option can switch on a tem-plate which adds the concatenation of all vlw back-offs in the context, on either side of each entity, andthere is also an option to convert all tokens and vlwbackoffs to lower case before creating the features.EntityDistance Options on this group allow the ad-dition of the token distance and sentence distancebetween the entities, as numeric or binary features.There is also an option to add a coarse three-wayclassification of the token distance.EntityFrequency Counts are made of the number ofoccurrences of each entity surface form in the docu-ment, limited to Tissue entities for te relations, andProteins for frag and ppi relations.
The only optionfor this feature group adds a template which gener-ates a binary feature indicating the frequency rankof the participants?
surface forms in the document.EntityPattern The entity pattern for a given intra-sentential candidate relation shows how its partic-ipants lie with respect to the other entities in thesentence.
The pattern is a concatenated sequenceof the entity types in the sentence, with the par-ticipants in upper case and other entities in lowercase.
Only entity types which are valid participantsin the relation in question are included.
For exampleprotein-PROTEIN-TISSUE would indicate a relationbetween a Protein and a Tissue, with another Pro-tein occurring first in the sentence.
Options in thisgroup add the patterm, the total number of entitiesin the sentence, and the numbers of entities for eachtype.Frame The frame is the concatenation of the tokensbetween the two participants.
Two boolean optionson this group specify whether or not to include thetoken concatenation, and whether or not to includethe part-of-speech concatenation.
A further numericoption is used to limit the maximum frame length;when this is set to a non-zero value longer frames arediscarded.HeadWord All the headwords of the chunks in thesentences containing and between the participantsare listed and used to construct the features in thisgroup.
Options specify whether to include headnouns and/or head verbs, and whether to convertthe headwords to lower case or replace them by theirvlw backoffs.
A further option allows an additionalmarker to be added to each headword feature to in-dicate whether it is before, between or after the par-ticipants.NestedEntity This feature indicates whether theparticipants are contained in other entities, or in each23other.
The first option adds a feature template whichindicates which type of entity containing the two par-ticipants, if they are both contained.
The second op-tion adds a feature to indicate whether one of theentities is contained within the other, and the thirdadds a feature to indicate whether or not there is anywhitespace between the two entities.Ngram Three options specify what type of ngramsto add; whether to add unigrams of the tokens inthe sentences containing the participants, whether toadd bigrams of the same tokens, and whether to addcross-bigrams, which are bigrams of tokens beforeand between the participants, and of tokens betweenand after the participants.
Additional options spec-ify whether to convert tokens to vlw backoff or lowercase and whether to replace all sequences of digitsby ?0?.
Further options can be used to indicate thatonly ngrams in between the participants should beadded, that each ngram feature should be marked asbefore, between or after, or that all entities shouldreplaced in the text by their type.RelationKeyword Relation keywords are terms an-notated as relation indicators for ppi and te, andlinked to relations.
For ppi they are interactionwords, and for te they are expression level words.Keywords are matched from a list generated duringtraining and there are feature options to match thesekeywords before, between and after the participants,and to add templates for the existence of a keyword,the text of the keyword, and whether or not it is ahead word.RelativeEntityPosition The only option on thisgroup specifies whether or not to sort the partici-pant entities, alphabetically by entity type.
Binaryfeatures are added indicating whether the first entityin the candidate relation is the first in the document,whether it is the second, whether the participantsoverlap or whether they coincide.SignSlashSign This group is only used for te re-lations and is designed to detected the presence ofindicators like +/+ and ?/+ in the sentence(s) con-taining the relation.
Options allow the existence andtype of the one of these expressions to be indicated,and also its position relative to the participants, andwhether it is adjacent to one of the participants.3.4 OptimisationFeature selection methods include wrapper methodswhere feature sets are assessed according to their ef-fectiveness for a given learner, and filter methodswhere features are removed using some criterion be-fore being passed to the learner (Guyon and Elisseeff,2003).
In building the re system, it was found thatfilter methods did not work well, probably due to thelarge number of interactions between the features, soa wrapper optimisation method was employed, con-sisting of greedy search through the space of possiblefeature sets.In the greedy search method, an initial feature setis selected and a model trained on the train setand tested on the devtest set.
A series of searchoperators (see below) are applied to the feature setto produce a list of proposed new feature sets, onecorresponding to each operator, and the new featuresets are tested in the same way.
If any of these newfeature sets produces better results than the origi-nal initial set, then the best set replaces the initialfeature set and the process is iterated.
The greedysearch terminates when none of the search operatorsleads to an improvement.
Three types of search oper-ators are used in the greedy search, defined in termsof the feature set structure described in Section 3.3:1.
The deletion of a feature group.2.
The increase or decrease of a numerical optionon a feature group (e.g.
context size), where thesize of the change is not greater than 2.3.
The flipping of a boolean option on a featuregroup.In theory search operators which add or remove in-dividual features could be used, but due to the largenumber of features the use of such operators is notpractical.
In addition, it may have been possibleto achieve more robust results using cross-validationrather than heldout testing, but that would also re-sult in a large increase in search time.3.5 EvaluationIn all re experiments, the annotated entities wereassumed as given so that only re performance wasbeing assessed.
The performance was measured us-ing precision-recall break-even point (bep), which isfound by adjusting the decision boundary (thresh-old) of the classifier until the precision and recall areequal then taking the value of the F1 at this thresh-old.
The bep has the advantage over F1 that itsdefinition is independent of the choice of threshold,but it can still be compared easily to the iaa and isbased on the familiar concepts of precision and recall.4 ResultsPerformance of the re system on each of the four re-lation types was optimised using the greedy featureexploration method described in Section 3.4.
Interand intra-sentential relations were treated separately,with intra-sentential relation performance optimisedfirst.
The inter-sentential performance was then as-sessed using a ?pipeline?
consisting of the best intra-sentential relation extractor, and the inter-sententialsystem being optimised.The greedy search experiments for intra-sentential24relations used two different starting feature sets, anall set in which all features groups and options wereswitched on, and the context sizes in EntityContextwere set to 3, and a base set which used just Ngramand RelativeEntityPosition features.
The modelswere trained on train and scored on devtest us-ing bep.
In the calculation of bep, all relationsof the appropriate type were considered, includinginter-sententials.
The results of the greedy search onintra-sentential relations are shown in Table 6.Corpus RelationTypeInitialFeaturesInitialbepFinalbepppi ppi base 36.8 52.2all 51.6 53.4frag base 49.2 56.0all 55.9 57.4te te base 45.9 51.9all 50.6 53.8frag base 53.7 62.7all 60.1 61.2Table 6: Greedy search feature exploration for intra-sentential relations.
Performance is measured on all re-lations, testing on devtest.For all relation types, the greedy search improvesthe performance over the base and all feature sets,usually reaching the highest performance when start-ing from all.
Comparing the results in Table 6with the iaa figures provided in Table 5 shows thatthe system performance is around 75-80% of iaa,with the lowest relative performances observed forfrag relations.
These relations include a higher pro-portion of inter-sententials, so systems which ignoreinter-sententials suffer a larger loss in performance.After choosing the best system for intra-sententialrelations, the same greedy optimisation was per-formed on the inter-sentential relations using virtu-ally the same initial feature sets.
The only differ-ence in the feature sets is that additional options areadded to the EntityDistance feature to indicate thesentential distance between the entities.
The resultof the greedy search on the inter-sentential relationsis shown in Table 7.The inter-sentential relation optimisation is onlyreally successful for the frag relations in the ppicorpus.
For te and ppi inter-sentential relations, thenumber of negative examples dwarfs the few posi-tive examples making it very difficult for the ma-chine learner.
For frag relations in both corpora,some progress is made on the performance on inter-sentential relations (detailed breakdown not shown)but in the te corpus this does not translate to anoverall improvement in bep.
This is because theinter- and intra-sentential probabilities have quiteCorpus RelationTypeInitialFeaturesInitialbepFinalbepppi ppi base 53.4 53.4all 53.4 53.4frag base 59.6 62.2all 61.7 62.5te te base 53.9 54.0all 53.9 54.0frag base 60.4 62.8all 62.6 62.7Table 7: Greedy search feature exploration for inter-sentential relations.
Performance is measured on all re-lations, testing on devtest.different ranges for frag relations meaning that thethreshold probabilities would have to be chosen sep-arately to give the best F1 score.The greedy search results just presented werebased on a partitioning of the feature sets into groupswhich correspond to the way in which the featureswere implemented.
Since the search operators applyat group granularity, and are not able to select fea-tures from within a group, the way in which the fea-tures are grouped is likely to have a bearing on theperformance of the best system found by the algo-rithm.
The next set of experiments investigates theeffective the feature grouping by conducting greedysearch with groups chosen randomly.Corpus RelationTypeInitialbepFinal bep Ensemblebepppi ppi 51.1 52.9, 52.4, 52.7,52.8, 52.652.5frag 55.7 56.3, 56.1, 56.1,56.3, 56.456.3te te 51.4 52.0 , 51.8, 52.5,51.9, 52.952.1frag 60.1 60.8, 60.5, 60.4,60.7, 60.560.4Table 8: Greedy search feature exploration with randomfeature groupings for intra-sentential relations.
The ini-tial feature set is a slightly modified all in each case, andthe search was run 5 times, testing on devtest.
Theensemble system combines the 5 optimised feature setsusing the geometric mean probability.Using a variant of the all feature set where the con-text sizes in EntityContext were set to 5, a greedysearch for the best performing system was imple-mented by first dividing the feature set randomlyinto 50 groups, and at each iteration testing theperformance with each group added and removedin turn.
The search was iterated until no furtherimprovement in performance was obtained, where25performance was measured using bep.
As for theprevious greedy feature optimisations, the relationextractor was trained on train and tested on de-vtest.
The results for intra-sentential relations areshown in Table 8, where the experiment was repeatedseveral times with different (randomly chosen) par-titions.
After performing the five random knockoutsearches of the feature space, an ensemble systemwas created for each relation type by training a sys-tem with each feature set and combining the five bytaking the geometric mean of the probabilities.
Theperformance of the ensemble system is shown in thefinal column of Table 8.Comparing the results in Table 8 with the corre-sponding results for intra-sentential relations in Ta-ble 6, it can be seen that splitting the features into re-lated groups works better than random groups.
Theensemble does not improve on the individual scores,probably because the systems in the ensemble arenot diverse enough (Dietterich, 2000)To see how well the best feature sets generalise tounseen data, re systems were trained on train anddevtest combined, and tested on test using dif-ferent feature sets; the baseline sets (base and all),and the fully optimised set (best).
In addition, toensure that the greedy feature optimisation was notbiasing the feature set towards the particular learneremployed (i.e.
maxent), systems were also trainedand tested using svm.
The maxent system had itsGaussian prior optimised on the devtest set, whilstsvm was found to work best with a linear kernel, andits cost factor was optimised on devtest.
The valueof the decision function was used for thresholding thesvm model in order to calculate the bep.
The com-parison of all systems on test is shown in Table 9.Corpus RelationType LearnerFeature Setbase all bestppi ppi maxent 39.7 48.3 49.1svm 39.6 49.2 49.9ppi frag maxent 56.9 68.0 69.4svm 54.9 68.2 69.5te te maxent 39.0 47.9 46.8svm 39.6 49.8 50.1te frag maxent 60.1 63.4 68.9svm 59.7 67.7 70.4Table 9: The performance of the system trained on trainand devtest, and tested on test.
Performance is com-pared across the baseline feature sets (base and all) andthe optimised feature set (best) using each classifier.The results in Table 9 show that, in general, bothclassifiers perform better with the all feature set thanwith the base feature set, and best of all with thebest feature set.
The svm classifier preserves thisordering throughout, and actually performs betterthan the maxent classifier overall, even though thefeatures were optimised for maxent.
For maxent,the best model outperforms all in three out of fourcases, with the exception being te.5 ConclusionsIt has been shown that a relation extraction systembased on a supervised classifier and a large collectionof shallow linguistic features can be applied to threedifferent types of relations in two different biomedicalcorpora.
Automated feature optimisation producedsmall gains in performance which were still apparenton a blind test set.
Even though a wrapper methodwas used using a specific classifier (maxent), thefeature set optimisations were still valid for an svmclassifier.Since the greedy search through feature space isessentially a beam search with a beam size of one, itcould be extended by using a larger beam-size, run-ning the feature set comparisons in parallel to reducetotal running time to a manageable size.
Ad-hoc ex-periments have suggested that better results couldbe obtained by restarting the feature optimisationin different positions, indicating that local optimacould be a problem, but a thorough investigationof the search space nature has been left for futurework.
Furthermore, the hyperparameter optimisa-tion of the classifiers (for example the Gaussian priorin maxent) could be incorporated into the search.Whilst the relation extractor was successful onintra-sentential relations, it is less successful on inter-sentential relations, perhaps becuase of the lingusiticcomplexity of these, and the sparsity of positive ex-amples.
The split into inter- and inter-sententialexamples in the current system seems justified asthey have quite different characteristic, but theremay also be a case for splitting the intra-sententialsfurther, into intra- and inter-clausals, as suggestedby Maslennikov and Chua (2007), and then treatinginter-clausals and inter-sententials together.
Whilstintra-clausals are more likely to use simple construc-tions and be amenable to modelling with shallow lin-guistic features, inter-sententials and inter-clausalsare more likely to use complex linguistic phenomenasuch as corefereces.AcknowledgementsThis work was supported by the Text Mining Pro-gramme of ITI Life Sciences Scotland (http://www.itilifesciences.com).26ReferencesBea Alex, Claire Grover, Barry Haddow, Mijail Kabad-jov, Ewan Klein, Michael Matthews, Stuart Roebuck,Richard Tobin, and Xinglong Wang.
2008.
TheITI TXM Corpora: Tissue Expressions and Protein-Protein Interactions.
In Proceedings of LREC.Razvan C. Bunescu and Raymond J. Mooney.
2007.
Ex-tracting relations from text: From word sequences todependency paths.
In Anne Kao and Steve Poteet, ed-itors, Text Mining and Natural Language Processing,pages 29?44.
Springer.Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M.Marcotte, Raymond J. Mooney, Arun K. Ramani,and Yuk W. Wong.
2005.
Comparative experimentson learning information extractors for proteins andtheir interactions.
Artificial Intelligence in Medicine,33(2):139?155.James Curran and Stephen Clark.
2003.
Language in-dependent NER using a maximum entropy tagger.
InProceedings of CoNLL.James Cussens and Claire Ne?dellec, editors.
2005.
Pro-ceedings of Language Learning in Logic.Thomas G. Dietterich.
2000.
Ensemble methods in ma-chine learning.
Lecture Notes in Computer Science,1857:1?15.Gunes Erkan, Arzucan Ozgur, and Dragomir R. Radev.2007.
Semi-supervised classification for extracting pro-tein interaction sentences using dependency parsing.In Proceedings of EMNLP-CoNLL.Kuzman Ganchev, Koby Crammer, Fernando Pereira,Gideon Mann, Kedar Bellare, Andrew McCallum,Steven Carroll, Yang Jin, and Peter White.
2007.Penn/UMass/CHOP Biocreative II systems.
In Pro-ceedings of the Second BioCreative Challenge Evalua-tion Workshop.Claudio Giuliano, Alberto Lavelli, and Lorenza Romano.2006.
Exploiting shallow linguistic information for re-lation extraction from biomedical literature.
In Pro-ceedings of EACL.Claire Grover and Richard Tobin.
2006.
Rule-basedchunking and reusability.
In Proceedings of LREC.Isabelle Guyon and Andre?
Elisseeff.
2003.
An intro-duction to variable and feature selection.
Journal ofMachine Learning Research, 3(Mar):1157?1182.Jing Jiang and Chengxiang Zhai.
2007.
A systematicexploration of the feature space for relation extraction.In Proceedings of NAACL.Thorsten Joachims.
1999.
Making large-scale supportvector machine learning practical.
In Advances in Ker-nel Methods: Support Vector Machines.
MIT Press,Cambridge, MA.S.
Katrenko and P. W. Adriaans.
2006.
Learning rela-tions from biomedical corpora using dependency treelevels.
In Proceedings of Benelearn.Jin D. Kim, Tomoko Ohta, and Jun?ichi Tsujii.
2008.Corpus annotation for mining biomedical events fromliterature.
BMC Bioinformatics, 9(1).Martin Krallinger, Florian Leitner, Carlos Rodriguez-Penagos, and Alfonso Valencia.
2008.
Overview ofthe protein-protein interaction annotation extractiontask of BioCreative II.
Genome Biology (in press).Mstislav Maslennikov and Tat S. Chua.
2007.
A multi-resolution framework for information extraction fromfree text.
In Proceedings of ACL.Guido Minnen, John Carroll, and Darren Pearce.
2000.Robust, applied morphological generation.
In Proceed-ings of INLG.Leif Arda Nielsen.
2006.
Extracting protein-protein in-teractions using simple contextual features.
In Pro-ceedings of BioNLP.Sampo Pyysalo, Filip Ginter, Juho Heimonen, JariBjorne, Jorma Boberg, Jouni Jarvinen, and TapioSalakoski.
2007.
Bioinfer: A corpus for informationextraction in the biomedical domain.
BMC Bioinfor-matics, 8(1).Marios Skounakis, Mark Craven, and Soumya Ray.
2003.Hierarchical hidden markov models for information ex-traction.
In Georg Gottlob, Toby Walsh, Georg Gott-lob, and Toby Walsh, editors, Proceedings of IJCAI.L.
Smith, T. Rindflesch, and W. J. Wilbur.
2004.
Med-Post: a part-of-speech tagger for biomedical text.Bioinformatics, 20(14):2320?2321.Guodong Zhou, Min Zhang, Donghong Ji, and QiaomingZhu.
2007.
Tree kernel-based relation extraction withcontext-sensitive structured parse tree information.
InProceedings of EMNLP-CoNLL.27
