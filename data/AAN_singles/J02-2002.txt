c?
2002 Association for Computational LinguisticsThe Combinatory Morphemic LexiconCem Bozsahin?Middle East Technical UniversityGrammars that expect words from the lexicon may be at odds with the transparent projection ofsyntactic and semantic scope relations of smaller units.
We propose a morphosyntactic frameworkbased on Combinatory Categorial Grammar that provides flexible constituency, flexible categoryconsistency, and lexical projection of morphosyntactic properties and attachment to grammar inorder to establish a morphemic grammar-lexicon.
These mechanisms provide enough expressivepower in the lexicon to formulate semantically transparent specifications without the necessityto confine structure forming to words and phrases.
For instance, bound morphemes as lexicalitems can have phrasal scope or word scope, independent of their attachment characteristics butconsistent with their semantics.
The controls can be attuned in the lexicon to language-particularproperties.
The result is a transparent interface of inflectional morphology, syntax, and semantics.We present a computational system and show the application of the framework to English andTurkish.1.
IntroductionThe study presented in this article is concerned with the integrated representation andprocessing of inflectional morphology, syntax, and semantics in a unified grammar ar-chitecture.
An important issue in such integration is mismatches in morphological,syntactic, and semantic bracketings.
The problem was first noted in derivational mor-phology.
Williams (1981) provided examples from English; the semantic bracketingsin (1a?2a) are in conflict with the morphological bracketings in (1b?2b).
(1) a.hydro electric-ity b. hydroelectric -ity(2) a.Go?del number-ing b.
Go?delnumber -ingIf the problem were confined to derivational morphology, we could avoid it bymaking derivational morphology part of the lexicon that does not interact with gram-mar.
But this is not the case.
Mismatches in morphosyntactic and semantic bracketing?
Computer Engineering and Cognitive Science, Middle East Technical University, 06531 Ankara, Turkey.E-mail: bozsahin@metu.edu.tr.146Computational Linguistics Volume 28, Number 2also abound.
This article addresses such problems and their resolution in a computa-tional system.1Mu?ller (1999, page 401) exemplifies the scope problem in German prefixes.
(3a) isin conflict with the bracketing required for the semantics of the conjunct (3b).
(3) a. Wenn [ Ihr Lust ] und [noch nichts anderes vor- ]habt,if you pleasure and yet nothing else intendko?nnen wir sie ja vom Flughafen abholencan we them PARTICLE from.the airport pick up?If you feel like it and have nothing else planned, we can pick themup at the airport.?b.
Ihr Lust habt UND noch nichts anderes vorhabtSimilar problems can be observed in Turkish inflectional suffixes.
In the coordi-nation of tensed clauses, the tense attaches to the verb of the rightmost conjunct (4a)but applies to all conjuncts (4b).
Delayed affixation appears to apply to all nominalinflections (4c?e).
(4) a. Zorunlu deprem sigortas?
[yu?ru?rlu?g?e girmis? ]
amamandatory earthquake insurance effect enter-ASP but[ tam anlam?yla uygulanamam?s?
]-t?exactly apply-NEG-ASP-TENSE?Mandatory earthquake insurance had gone into effect, but it had notbeen enforced properly.?b.
yu?ru?rlu?g?e girmis?-ti ama tam anlam?yla uygulanamam?s?-t?c.
Adam-?n [araba ve ev ]-iman-GEN car and house-POSS?the man?s house and car?d.
Araba-y?
[adam ve c?ocuk ]-lar-a go?ster-di-mCar-ACC man and child-PLU-DAT show-TENSE-PERS1?
(I) showed the car to the men and the children.?e.
Araba-y?
sen-in [dost ve tan?d?k ]-lar-?n-a go?ster-di-mCar-ACC you-GEN friend and acq.-PLU-POSS-DAT showed?
(I) showed the car to the your friends and acquaintances.
?1 Our use of the term morphosyntax needs some clarification.
Some authors, (e.g., Jackendoff 1997),take it to mean the syntax of words, in contrast to the syntax of phrases.
By morphosyntax we meanthose aspects of morphology and syntax that collectively contribute to grammatical meaningcomposition.
This is more in line with the inflectional-morphology-is-syntax view.
In this respect, wewill not address problems related to derivational morphology; its semantics is notoriouslynoncompositional and does not interact with grammatical meaning.
Moreover, without a semanticallypowerful lexicon such as Pustejovsky?s (1991), even the most productive fragment of derivationalmorphology is hard to deal with (Sehitoglu and Bozsahin 1999).147Bozsahin The Combinatory Morphemic LexiconPhrasal scope of inflection can be seen in subordination and relativization as well.In (5a), the entire nominalized clause marked with the accusative case is the objectof want.
In (5b), the relative participle applies to the relative clause, which lacks anobject.
The object?s case is governed by the subordinate verb, whose case requirementsmight differ from that of the matrix verb (5c).
As we show later in this section, thecoindexing mechanisms in word-based unification accounts of unbounded extractionface a conflict between the local and the nonlocal behavior of the relativized noun,mainly due to applying the relative participle -dig?-i to the verbal stem ver rather thanthe entire relative clause.
A lexical entry for -dig?-i would resolve the conflict andcapture the fact that it applies to nonsubjects uniformly.
(5) a.
Can [Ays?e?nin kitab-?
oku-ma-s?
]-n?
iste-diC.NOM A.-GEN book-ACC read-INF-AGR-ACC want-TENSE?Can wanted Ays?e to read the book.?lit.
?Can wanted Ays?e?s-reading-the-book.?b.
Ben [ Mehmet?in c?ocug?-a/*-u ver ]-dig?-i kitab-?
oku-du-mI.NOM M-GEN child-DAT/*ACC give-REL.OP book-ACC read-TENSE-PERS1?I read the book that Mehmet gave to the child.?c.
Ben [ Mehmet?in kitab-?
ver ]-dig?-i c?ocug?-u/*-a go?r-du?-mI.NOM M-GEN book-ACC give-REL.OP child-ACC/*DAT see-TENSE-PERS1?I saw the child to whom Mehmet gave the book.
?The morphological/phrasal scope conflict of affixes is not particular to morpho-logically rich languages.
Semantic composition of affixes in morphologically simplerlanguages poses problems with word (narrow) scope of inflections.
For instance, faketrucks needs the semantics (plu(fake truck)), which corresponds to the surface brack-eting [ fake truck ]-s, because it denotes the nonempty nonsingleton sets of things thatare not trucks but fake trucks (Carpenter 1997).
Four trucks, on the other hand, has thesemantics (four(plu truck)), which corresponds to four [ truck ]-s, because it denotes thesubset of nonempty nonsingleton sets of trucks with four members.The status of inflectional morphology among theories of grammar is far fromsettled, but, starting with Chomsky (1970), there seems to be an agreement that deriva-tional morphology is internal to the lexicon.
Lexical Functional Grammar (LFG)(Bresnan 1995) and earlier Government and Binding (GB) proposals e.g.
(Anderson1982) consider inflectional morphology to be part of syntax, but it has been del-egated to the lexicon in Head-Driven Phase Structure Grammar (HPSG) (Pollardand Sag 1994, page 35) and in the Minimalist Program (Chomsky 1995, page 195).The representational status of the morpheme is even less clear.
Parallel develop-ments in computational studies of HPSG propose lexical rules to model inflectionalmorphology (Carpenter and Penn 1994).
Computational models of LFG (Tomita 1988)and GB (Johnson 1988; Fong 1991), on the other hand, have been noncommittal re-garding inflectional morphology.
Finally, morphosyntactic aspects have alwaysbeen a concern in Categorial Grammar (CG) (e.g., Bach 1983; Carpenter 1992; Dowty1979; Heylen 1997; Hoeksema 1985; Karttunen 1989; Moortgat 1988b; Whitelock1988), but the issues of constraining the morphosyntactic derivations and re-solving the apparent mismatches have been relatively untouched in computationalstudies.We briefly look at Phrase Structure Grammars (PSGs), HPSG, and MultimodalCGs (MCGs) to see how word-based alternatives for morphosyntax would deal with148Computational Linguistics Volume 28, Number 2the issues raised so far.
For convenience, we call a grammar that expects words fromthe lexicon a lexemic grammar and a grammar that expects morphemes a morphemicgrammar.
A lexemic PSG provides a lexical interface for inflected words (X0s) suchthat a regular grammar subcomponent handles lexical insertion at X0.2 In (4d), theright conjunct c?ocuk-lar-a is analyzed as N0 ?
c?ocuk-PLU-DAT (or N0 ?
N0?
-DAT,N0?
?
N0??
-PLU, N0??
?
Stem, as a regular grammar).
Assuming a syncategorematiccoordination schema, that is, X ?
X and X, the N0 in the left and right conjunctsof this example would not be of the same type.
Revising the coordination schemasuch that only the root features coordinate would not be a solution either.
In (4e),the relation of possession that is marked on the right conjunct must be carried overto the left conjunct as well.
What is required for these examples is that the syntac-tic constituent X in the schema be analyzed as X-PLU(-POSS)-DAT, after N0 and N0coordination.What we need then is not a lexemic but a morphemic organization in which brack-eting of free and bound morphemes is regulated in syntax.
The lexicon, of course,must now supply the ingredients of a morphosyntactic calculus.
This leads to a the-ory in which semantic composition parallels morphosyntactic combination by virtueof bound morphemes?
being able to pick their domains just like words (above X0,if needed).
A comparison of English and Turkish in this regard is noteworthy.
TheEnglish relative pronouns that/whom and the Turkish relative participle -dig?-i wouldhave exactly the same semantics when the latter is granted a representational statusin the lexicon (see Section 6).Furthermore, rule-based PSGs project a rigid notion of surface constituency.
Steed-man (2000) argued, however, that syntactic processes such as identical element dele-tion under coordination call for flexible constituency, such as SO (subject-object) inthe SVO & SO gapping pattern of English and SV (subject-verb) constituency inthe OSV & SV pattern of Turkish.
Nontraditional constituents are also needed inspecifying semantically transparent constituency of words, affixes, clitics, andphrases.Constraint-based PSGs such as HPSG appeal to coindexation and feature passingvia unification, rather than movement, to deal with such processes.
HPSG also makesthe commitment that inflectional morphology is internal to the lexicon, handled eitherby lexical rules (Pollard and Sag 1994) or by lexical inheritance (Miller and Sag 1997).We look at (5c) to highlight a problem with the stem-and-inflections view.
As words en-ter syntax fully inflected, the sign of the verb ver-dig?-i in the relative clause (5c) wouldbe as in (6a), in which the SUBCAT list of the verb stem is, as specified in the lexi-cal entry for ver, unsaturated.
The participle adds coindexation in MOD| ?
?
?
|INDEX.The HPSG analysis of this example would be as in Figure 1.
Although passing theagreement features of the head separately (Sehitoglu 1996) solves the case problemalluded to in (5c), however, structure sharing of the NPdat with the SLASH, INDEX,and CONTENT features of ver-dig?-i is needed for semantics (GIVEE), but this conflictswith the head features of the topmost NPacc in the tree.
The relative participle as alexical entry (e.g., (6b)) would resolve the problem with subcategorization because itsSUBCAT list is empty (like the relative pronoun that in English), hence there would beno indirect dependence of the nonlocal SLASH feature and the local SUBCAT featurevia semantics (CONTENT).
Such morphemic alternatives are not considered in HPSG,however, and require a significant revision in the theory.
Furthermore, HPSG?s lexical2 But see Creider, Hankamer, and Wood (1995), which argues that the morphotactics of human languagesis not regular but linear context free.149Bozsahin The Combinatory Morphemic Lexiconassignment for trace introduces phonologically null elements into the lexicon, which,as we show later, is not necessary.
(6) a. ver-dig?-i := ????????????????LOCAL?????????????CAT????
?HEAD[AGR[PERSON thirdNUMBER sing]CASE dat]SUBCAT < 3 NP[gen], 2 NP[acc], 1 NP[dat]>MOD | MODSYN | LOCAL | CONT | INDEX 1?????CONTENT??
?RELN giveGIVER 3GIVEE 1GIFT 2???????????????
?NONLOCAL | TO-BIND | SLASH{1}????????????????b.
-dig?-i := ?????LOCAL??
?CAT[HEAD noun[acc or dat]SUBCAT <>]CONTENT npro[INDEX 1]??
?NONLOCAL | INHER | SLASH{1}????
?MCGs (Hepple 1990a; Morrill 1994; Moortgat and Oehrle 1994) allow differentmodes of combination in the grammar.
In addition to binary modes such as wrappingand commutative operations, unary modalities provide finer control over the cate-gories.
Heylen (1997, 1999) uses unary modalities as a way of regulating morphosyn-tactic features such as case, number, and person for economy in lexical assignments.For instance, Frau has the category ?case?fem?sg?3p?declN, which underspecifies it forcase and declension.
Underspecification is dealt with in the grammar using inclusionpostulates (e.g., (7)).
The interaction of different modalities is regulated by distributionpostulates.
(7) ?case?
 X?nom?
 X?case?
 X?acc?
 XLexical assignments to inflected words carry unary modalities: boys has the type?plN, in contrast to ?sgN for boy.
Although such regulation of inflectional featuressuccessfully mediates, for example, subject-verb agreement or NP-internal case agree-ment (as in German), it is essentially word-based, because type assignments are toinflected forms; morphemes do not carry types.
This reliance on word types neces-sitates a lexical rule?based approach to some morphosyntactic processes that createindefinitely long words, such as ki-relativization in Turkish (see Section 6.5).
But lexicalrules for such processes risk nontermination (Sehitoglu and Bozsahin 1999).
Our mainpoint of departure from MCG accounts is the morphemic versus lexemic nature of thelexicon: The morphosyntactic and attachment modalities originate from the lexicon;they are not properties of the grammar (we elaborate more on this later).
This pavesthe way to the morphemic lexicon by licensing type assignments to units smaller thanwords.Besides problems with lexical rules, the automata-theoretic power of MCGs isproblematic: Unrestricted use of structural modalities and postulates leads to Tur-ing completeness (Carpenter 1999).
Indeed, one of the identifiable fragments of Mul-150Computational Linguistics Volume 28, Number 2Figure 1HPSG analysis of (5c).timodal languages that is computationally tractable is Combinatory Categorial lan-guages (Kruijff and Baldridge 2000), which we adopt as the basis for the frameworkpresented here.
We propose a morphosyntactic Combinatory Categorial Grammar(CCG) in which the grammar and the morphemic lexicon refer to morphosyntactictypes rather than syntactic types.
We first introduce the syntactic CCG in Section 2.Morphosyntactic CCG is described in Section 3.
In Section 4, we look at the compu-tational aspects of the framework.
We then show its realization for some aspects ofEnglish (Section 5) and Turkish (Section 6).151Bozsahin The Combinatory Morphemic Lexicon2.
Syntactic TypesCG is a theory of grammar in which the form-meaning relation is conceived as atransparent correspondence between the surface-syntactic and semantic combinatorics(Jacobson 1996).
A CCG sign can be represented as a triplet ?
?
?
:?, where ?
is theprosodic element, ?
is its syntactic type, and ?
its semantic type.
For instance, thelexical assignment for read is (8).3(8) read := read ?
(S\NP)/NP:?x.
?y.read xyDefinition (Syntactic Types)?
The set of basic syntactic categories: As = {N,NP,S,S?t,S+t}?
The set of complex syntactic categories: Bs?
As ?
Bs?
If X ?
Bs and Y ?
Bs, then X\Y and X/Y ?
BsThe classical Ajdukiewicz/Bar-Hillel (AB) CG is weakly equivalent to Context-Free Grammars (Bar-Hillel, Gaifman, and Shamir 1960).
It has function applicationrules, defined originally in a nondirectional fashion.
The directional variants and theirassociated semantics are as follows:(9) Forward Application (>):4 X/Y: f Y: a ?
X: faBackward Application (<): Y: a X\Y: f ?
X: faCCG (Steedman 1985, 1987, 1988; Szabolcsi 1983, 1987) is an extended version ofAB that includes function composition (10), substitution, and type raising (11).
Theseextensions make CCGs mildly context sensitive.
(10) Forward Composition (>B): X/Y: f Y/Z: g ?
X/Z:?x.f (gx)Backward Composition (<B): Y\Z: g X\Y: f ?
X\Z:?x.f (gx)(11) Forward Type Raising (>T):5 X: a ?
T/(T\X):?f .f [a]Backward Type Raising (<T): X: a ?
T\(T/X):?f .f [a]Type raising is an order-preserving operation.
For instance, Lambek?s (1958) cat-egory S/(S\NP) is a positional encoding of the grammatical subject as a function3 We take ?
to be the surface string for simplicity.
We use the ?result-first?
convention for CG.
Forinstance, transitive verbs of English are written as (S\NP)/NP, which translates to (NP\S)/NP in the?result-on-top?
convention.4 We omit the prosodic element for ease of exposition.
For instance, the complete definition of forwardapplication is s1 ?
X/Y: f s2 ?
Y: a ?
s1 ?
s2 ?
X: fa, where ?
is prosodic combination and fa is theapplication of f to a.
The ?
will play a crucial role in the lexicalization of attachment later on.5 The lambda term f [a] denotes internal one-step ?-reduction of f on a.
In parsing, we achieve the sameeffect by partial execution (Pereira and Shieber 1987).
?f .f [a] is encoded as (a^F)^F in Prolog, where ?is lambda abstraction.
We opted for the explicit f [a] notation mainly for ease of exposition (cf.
thesemantics of raising verbs, relative participles, etc.
in Section 6).
Moreover, as Pereira and Shiebernoted, (a^F)^F is not a lambda term in the strict sense because a is not a variable.152Computational Linguistics Volume 28, Number 2looking for a VP (= S\NP) to the right to become S. The reversal of directionality suchas topicalization (e.g., This book, I recommend) requires another schema.
The reversalis with respect to the position of the verb, which we shall call contraposition andformulate as in (12).6 (<XP) is leftward extraction of a right constituent, and (>XP)is rightward extraction of a left constituent, both of which are marked constructions.Directionally insensitive types such as T|(T|X) cause the collapse of directionality insurface grammar (Moortgat 1988a).
(12) Leftward Contraposition (<XP): X: a ?
S+t/(S/X):?f .f [a]S+t/(S+t/X):?f .f [a]Rightward Contraposition (>XP): X: a ?
S?t\(S\X):?f .f [a]S?t\(S?t\X):?f .f [a]The semantics of contraposition depends on discourse properties as well.
We leavethis issue aside by (1) noting that it is related to type raising in changing the function-argument relation and (2) categorizing the sentence as S+t (topicalized) or S?t (detopi-calized), which are not discourse equivalent to S. Syntactic characterization as suchalso helps a discourse component do its work on syntactic derivations.CCG?s notion of interpretation is represented in the Predicate-Argument Structure(PAS).
Its organization is crucial for our purposes, since the bracketing in the PAS isthe arbitrator for reconciling the bracketings in morphology and syntax via properlexical type assignments.
It is the sole level of representation in CCG (Steedman 1996,page 89).7 It is the level at which the conditions on objects of interpretation, such asbinding and control, are formulated.
For instance, Steedman (1996) defines c-commandand binding conditions A, B, and C over the PAS.
The PAS also reflects the obliquenessorder of the arguments:Predicate .
.
.
Tertiary-Term Secondary-Term Primary-TermAssuming left associativity for juxtaposition, this representation yields the brack-eting in (13) for the PAS.
Having the primary argument as the outermost term ismotivated by the observations on binding asymmetries between subjects and comple-ments in many languages (e.g., *Himself saw John, *heself).(13)3.
Morphosyntactic TypesA syntactic type such as N does not discriminate morphosyntactically.
A finer dis-tinction can be made as singular nouns, plural nouns, case-marked nouns, etc.
For6 In fact, topicalization of nonperipheral arguments (This book, I would give to Mary) requires that (12) befinitely schematized over valencies, such as S, S/NP, S/PP (Steedman 1985).7 We will not elaborate on the theoretical consequences of having this level of representation; see, forinstance, Dowty (1991) and Steedman (1996).153Bozsahin The Combinatory Morphemic Lexiconn-relbase n-rootn-nums-causs-reflex s-recip(x)(r)(n)n-possn-comp (m)n-case (c)free(a)s-tenses-abils-negs-imps-pass(s)(m)(t)(g)(i)(p)s-tensen-base s-base(b)(t)(v)(b)(n)s-persons-modaln-num(f)(a)(c)s-base  (v)(l)n-base (b)(o)(u)free (f)Figure 2The lattice of diacritics for (a) Turkish and (b) English.instance, the set of number-marked nouns can be represented asn?N, where ?
is amorphosyntactic modality (?equals?)
and n is a diacritic (for number).
Books is of typen?N, but book is not.
The type for books can be obtained morphosyntactically by as-signing -s (-PLU) the functor typen?N\ b?N, where b stands for base.
A syntactic typesuch as N\N overgenerates.Another modality, < (?up to and equals?
), allows wider domains in morphosyn-tactic typing.
For instance,n< N represents the set of nouns marked on number orany other diacritic that is lower than number in a partial order (e.g., Figure 2).
Theinflectional paradigm of a language can be represented as a partial ordering us-ing the modalities.8 For instance, if the paradigm is Base-Number-Case, we have?
(b< N) ?
?
(n< N) ?
?
(c< N), where ?(?)
is the valuation function from the mor-phosyntactic type ?
to the set of strings that have the type ?
.
The ?
modality is morestrict than < to provide finer control; although ?
(n< N) ?
?
(c< N), ?
(n?N) ?
?
( c?N),because a noun can be number marked but not case marked or vice versa.
Also,?
(i?N) ?
?
(i< N) for any diacritic i since, for instance, the set of nouns marked up toand including case includes case-marked, number-marked, and unmarked nouns.The lattice consistency condition is imposed on the set of diacritics to ensurecategory unity.9 In other words, the syntactic type X can be viewed as an abbreviationfor the morphosyntactic type< X where  is the universal upper bound.
It is the8 See Heylen (1997) on use of unary modalities for a similar purpose in lexemic MCG.9 In a lattice L, x ?
y (morphosyntactically, x < y) is equivalent to the consistency properties x ?
y = xand x ?
y = y.
We use the join operator for this check, thus it suffices to have a join semilattice.154Computational Linguistics Volume 28, Number 2most underspecified category of X which subsumes all morphosyntactically decoratedversions of X.
Figure 2 shows the lattice for English and Turkish.Definition (Morphosyntactic Types)?
D = finite set of diacritics?
Join semilattice L = (D,?, =)?
The set of basic morphosyntactic types: Ams.
?i< X ?
Ams andi?X ?
Ams if i ?
D and X ?
As (see definition ofsyntactic types for As)?
(?
corresponds to lattice condition =)?
(< corresponds to lattice condition ?)?
The set of complex morphosyntactic types: Bms?
Ams ?
Bms?
If X ?
Bms and Y ?
Bms, then X\Y and X/Y ?
BmsFor instance, the infinitive marker -ma in (14a) can be lexically specified to lookfor untensed VPs?functions ontoa< S?to yield a complex noun base (14b), which, asa consequence of nominalization (result type N), receives case to become an argumentof the matrix verb.
The adjective in fake trucks can be restricted to modify unmarkedNs to get the bracketing [ fake truck ]-s (14c).
(14) a. Mehmet [ [kitab-?
oku ]-ma ]-y?
istiyorM.NOM book-ACC read-INF-ACC wants?Mehmet wants to read the book.?b.
-INF := ma ?b< N\(a< S\f< NPnom):?f .fc.
fake := fake ?b< N/b< N:?x.fake xDifferent attachment characteristics of words, affixes, and clitics must be factoredinto the prosodic domain as a counterpart of refining the morphosyntactic description.In Montague Grammar, every syntactic rule is associated with a certain mode of at-tachment, and this tradition is followed in MCG; attachment types are related with theslash (e.g., /w for wrapping), which is a grammatical modality.10 In the present frame-work, however, attachment is projected from the lexicon to the grammar as a prosodicproperty of the lexical items.11 The grammar is unimodal in the sense that / and \simply indicate the function-argument distinction in adjacent prosodic elements.
Thelexical projection of attachment further complements the notion of morphemic lexiconso that bound morphemes are no longer parasitic on words but have an independent10 See Dowty (1996) and Steedman (1996) for a discussion of bringing nonconcatenative combination intogrammar.11 There is a precedent of associating attachment characteristics with the prosodic element rather than theslash in CG (Hoeksema and Janda 1988).
In Hoeksema and Janda?s notation, arguments can beconstrained on phonological properties and attachment.
For instance, the English article a has its NP/Ncategory spelled out as </CX/N,NP,Pref>, indicating a consonantal first segment for the nounargument and concatenation to the left.155Bozsahin The Combinatory Morphemic LexiconTable 1Attachment properties of some Turkish morphemes.uzun (long) :=s?
uzun ?b< N/b< N uzun yollong road?long road?oku (read) :=s?
oku ?v< S\f< NPnom\f< NPacc adam kitab-?
oku-duman book-ACC read-TENSE?the man read the book.
?-EMPH :=c?
de ?
X\X Ben de yaz-ar-?mI too write-TENSE-PERS?I write too.
?-LOC :=a?
de ?c< N\o< N Ben-de kalem varI-LOC pen exist?I have a pen.
?representational status of their own.
We writei?
s to denote the attachment modalityi (affixation, syntactic concatenation, cliticization) of the prosodic element s.Table 1 shows some lexical assignments for Turkish (e.g., the signa?
s ?
X\Y:?characterizes a suffix).
The morphosyntactic calculus of CCG is defined with the ad-dition of morphosyntactic types and attachment modalities as follows (similarly, forother combinatory rules):(15) Forward Application (>):i?
s1 ?
X/ ?1?1 Y: fj?
s2?
?2?2 Y: a>k?
(s1k?
s2) ?
X: faif ?2?1?1 in lattice L, for: ?1,?2 ?
{?,<},?1,?2 ?
D in L,i, j, k ?
{a, s, c},i?j?
ak?Forward Composition (>B):i?
s1 ?
X/ ?1?1 Y: fj?
s2?
?2?2 Y/Z: g>Bk?
(s1k?
s2) ?
X/Z:?x.f (gx)if ?2?1?1 in lattice L, for: ?1,?2 ?
{?,<},?1,?2 ?
D in L,i, j, k ?
{a, s, c},i?j?
ak?The main functor?s argument specification (?1 of?1?1 Y in (15)) determines thelattice condition in derivations.12 Hence the morphosyntactic decoration in lexical as-signments propagates its lattice condition to grammar as in ?2?1?1 (cf.
Heylen [1997],in which the grammar rule imposes a fixed partial order, e.g., X/Y combines with Z if12 This coincides with Steedman?s (1991b) observation that directionality of the main functor?s slash isalso a property of the same argument.
The main functor is the one whose result type determines theoverall result type (i.e., X/Y in (15)).156Computational Linguistics Volume 28, Number 2Z ?
Y).
This is another prerequisite that must be fulfilled for the morphemic lexiconto project the lexical specification of scope.The grammar is not fixed on the attachment modality either (unlike a lexemicgrammar, which is fixed on combination of words).
Hence another requirement is thepropagation of attachment to grammar.
This is facilitated by the lexical typesm?
s??
:?,where m is an attachment type.
The attachment calculusi?j?
ak?
in (15), which reads?attachment types i and j yield type k,?
relates attachment to prosodic combination inthe grammar.13 It can be attuned to language-particular properties.We can specify some prosodic properties of the attachment calculus for Turkish asfollows (x?
indicates stress on the prosodic element x):syntactic concatenation x?s?
y?
= x?y?affixation x?a?
y = xy?cliticization x?c?
y = x?y?4.
Morpheme-Based ParsingTo contrast lexemic and morphemic processing, consider the Turkish example in (16a).We show some stages of the derivation to highlight prosodic combination (?)
as well.Every item in the top row is a lexical entry.
Allomorphs, such as that of tense, have thesame category in the lexicon (16b).
Vowel harmony, voicing, and other phonologicalrestrictions are handled as constraints on the prosodic element.
Constraint checkingcan be switched off during parsing to obtain purely morphosyntactic derivations.
(16) a.
Can Ays?e nin kitab ?
oku mas?
n?
iste diC.NOM -GEN(agr) book -ACC read -SUB1G -ACC want -TENSEb Nb Nc NPgen\o Nb Nc Nacc\o Nv S\f NPnomo N\f NPgenc N\o N TV (t S\f NP)\f NPacc \(a S\f NPnom ) \(a S\f NP)...istea?
di?t S\f NPnomkitaba?
?s?
oku?v S\f NPnom \f NPacc(kitaba?
?s?
oku)a?
mas?
?o N\f NPgen...((ays?ea?
nin)s?
(kitaba?
?s?
oku)a?
mas?)a?
n??
(t S\f NPnom)/(t S\f NPnom\f NPacc)...cans?
(ays?ea?
nins?
kitaba?
?s?
okua?
mas?a?
n?)s?
(istea?
di)?t S: want(read book ays?e)can?Can wanted Ays?e to read the book.?b.
-TENSE :=a?
d?|di|du|du?|t?|ti|tu|tu?
?
(t< S\f< NP)\(a< S\f< NP):?f .f13 Clearly, much more needs to be done to incorporate intonation into the system.
The motive forattachment types is to provide the representational ingredients on behalf of the morphemic lexicon.
Asone reviewer noted, CCG formulation of the syntax-phonology interface moved from autonomousprosodic types (Steedman 1991a) to syntax-directed prosodic features (Steedman 2000b).
The presentproposal for attachment modality is computationally compatible with both accounts: Combinatoryprosody can match prosodic types with morphosyntactic types.
Prosodic features are associated withthe basic categories of a syntactic type in the latter formulation, hence they become part of the featuralinference that goes along with the matching of categories in the application of combinatory rules.157Bozsahin The Combinatory Morphemic LexiconThe lexicalization of attachment modality helps to determine the prosodic domainof postconditions.
For instance, for Turkish, vowel harmony does not apply over wordboundaries, which can be enforced by applying it when the modality isa?
and c?
, butnots?
.
Voicing applies to a?
and s?
, but not to c?
.The basic categories N, NP, S, S+t, and S?t carry agreement features of fixed arity(e.g., tense and person for S, S+t, and S?t, and case, number, person, and gender for Nand NP).
Positional encoding of such information as in Pulman (1996) allows efficientterm unification for the propagation of these features.14 Term unification also handlesthe matching of complex categories in the CCG schema.
For instance, ?1?1 A/(?2?2 B\ ?3?3 C)combines with ?2?4 B\ ?3?5 C via (>) for B, C ?
As, if ?2 ?2 ?2, ?3 ?3 ?3 (?i ?
{< ,?}).
Apartfrom the matching of syntactic types and agreement, unification does no linguisticwork in this framework, in contrast to structure-sharing in HPSG and slash passingin Unification CG (Calder, Klein, and Zeevat 1988).CCG is worst-case polynomially parsable (Vijay-Shanker and Weir 1993).
This re-sult depends on the finite schematization of type raising and bounded composition.Assuming a maximum valence of four in the lexicon (Steedman 2000a), composition(Bn) is bounded by n ?
3.
The refinement of the type raising schema (11) for finiteschematization is shown in (17).
(17) a.
Revised Forward Type Raising (>T): NP : a ?
T/(T\NP ):?f .f [a]b.
Revised Backward Type Raising (<T): NP : a ?
T\(T/NP ):?f .f [a]T ?
{S,S\NP, S\NP\NP, S\NP\NP\NP}.The finite schematization of type raising suggests that it can be delegated to thelexicon, for example, by a lexical rule that value-raises all functions onto NP to theirtype-raised variety, such as NP/N to (S/(S\NP))/N.
But this move presupposes thepresence of such functions in the lexicon, that is, a language with determiners.
To betransparent with respect to the lexicon, we make type raising and other unary schema(contraposition) available in the grammar.
Since both are finite schemas in the revisedformulation, the complexity result of Vijay-Shanker and Weir still holds.
Checking thelattice condition as in (15) incurs a constant factor with a finite lattice.Type raising and composition cause the so-called spurious-ambiguity problem(Wittenburg 1987): Multiple analyses of semantically equivalent derivations are pos-sible in parsing.
This is shown to be desirable from the perspective of prosody; forexample, different bracketings are needed to match intonational phrasing with syn-tactic structure (Steedman 1991).
From the parsing perspective, the redundancy ofanalyses can be controlled by (1) grammar rewriting (Wittenburg 1987), (2) checkingthe chart for PAS equivalence (Karttunen 1989; Komagata 1997), (3) making the proces-sor parsimonious on using long-distance compositions (Pareschi and Steedman 1987),or (4) parsing into normal forms (Eisner 1996; Hepple 1990b; Hepple and Morrill 1989;Ko?nig 1989; Morrill 1999).
We adopt Eisner?s method, which eliminates chains of com-positions in O(1) time via tags in the grammar, before derivations are licensed.
Thereis a switch that can be turned off during parsing to obtain all surface bracketings.14 Mediating agreement via unification, type subsumption, or set-valued indeterminacy has importantconsequences on underspecification, the domain of agreement, and the notion of ?like categories?
incoordination (see Johnson and Bayer 1995; Dalrymple and Kaplan 2000; Wechsler and Zlatic?
2000).Rather than providing an elaborate agreement system, we note that Pulman?s techniques provide themechanism for implementing agreement as atomic unification, subsumption hierarchies represented aslattices, or set-valued features.
The categorial ingredient of phrase-internal agreement can be providedby endotypic functors when necessary (see Sections 5 and 6).158Computational Linguistics Volume 28, Number 2There is also a switch for checking the PAS equivalence, with the warning that theequivalence of two lambda expressions is undecidable.The parser is an adaptation of the Cocke-Kasami-Younger (CKY) algorithm (Ahoand Ullman 1972, page 315), modified to handle unary rules as well: In the kth iterationof the CKY algorithm to build constituents of length k, the unary rules apply to the CKYtable entries T[?i,?i+k ], i = 0, 1, .
.
.
, n ?
k; that is, k-length results of binary rules areinput to potential unary constituents of length k. In practice, this allows, for instance,a nominalized clause to be type-raised after it is derived as a category of type N.The remaining combinatory schema is already in Chomsky Normal Form, as requiredby CKY.
The finite schematization of CCG rules and constant costs incurred by thenormal form and lattice checking provide a straightforward extension of CKY-stylecontext-free parsing for CCG.
Komagata (1997) claims that the average complexity ofCCG parsing is O(n3) even without the finite schematization of type raising (based onthe parsing of 22 sentences consisting of around 20 words, with a lexicon of 200 entriesand no derivation of semantics in the grammar; a morphological analyzer providedfive analyses per second to the parser).
Statistical techniques developed for lexicalizedgrammars (e.g., Collins 1997), readily apply to CCG to improve the average parsingperformance in large-scale practical applications (Hockenmaier, Bierner, and Baldridge2000).
Both Collins and Hockenmeier, Bierner, and Baldridge used section 02-21 of theWall Street Journal Corpus of Penn Treebank for training, which contains 40,886 words(70,151 lexical entries).
A recent initiative (Oflazer, et al 2001) aims to provide such aresource of around one million words for Turkish.
It encodes in the Treebank surface-syntactic relations and the morphological breakdown of words.
The latter is invaluablefor training morphemic grammars and lexicons.In morpheme-based parsing, lattice conditions help eliminate the permutationproblem in endotypic categories.
Such categories are typical of inflectional morphemes.For instance, assume that three morphemes m1, m2, and m3 have endotypic categories(say N\N), that they can appear only in this order, and that they are all optional.
Thecategorization of mi as?
?i< N\?i< N such that ?
?i ?
?i for all i, and ?
?j?1 ?
?j for j = 1, 2, 3allows omissions (18a?b) but rules out the permutations (18c?d).15(18) a. stem m1 m2 m3?0< N?
?1< N\?1< N?
?2< N\?2< N?
?3< N\?3< N<?
?1< N because ?0 ?
?1<?
?2< N because ?
?1 ?
?2<?
?3< N because ?
?2 ?
?3b.
stem m3<?
?3< N because ?0 ?
?315 Three asterisks in the line indicate that the derivation is not licensed.159Bozsahin The Combinatory Morphemic Lexiconc.
*stem m2 m1 m3<?
?2< N because ?0 ?
?2*** <?
?2 ?
?1 because ?1 < ?
?1 ?
?2 < ??2d.
*stem m1 m3 m2<?
?1< N because ?0 ?
?1<?
?3< N because ?
?1 ?
?3*** <?
?3 ?
?2 because ?2 < ?
?2 ?
?3 < ?
?3The lattice and its consistency condition on derivability offer varying degrees offlexibility.
A lattice with only  and the relation ?
would undo all the effects ofparameterization; it would be equivalent to a syntactic grammar in which every basiccategory X stands for< X.
To enforce a completely lexemic syntax, a lattice with and free would define all functional categories as functions over free forms.Morphological processing seems inevitable for languages like Turkish, and mor-phological and lexical ambiguity such as that shown in (19) must be passed on tosyntax irrespective of how inflectional morphology is processed (isolated from or in-tegrated with syntax).
For the verbal paradigm, Jurafsky and Martin (2000) reportsOflazer?s estimation that inflectional suffixes alone create around 40,000 word formsper root.
In the nominal paradigm, iterative processes such as ki-relativization (Sec-tion 6.5) can create millions of word forms per nominal root (Hankamer 1989).
(19) a. kazma-lar?pickaxe-POSS3p?their pickaxe?b.
kazma-lar-?pickaxe-PLU-POSS3p?their pickaxes?c.
kazma-lar-?pickaxe-PLU-POSS3s?his/her pickaxes?d.
kaz-ma-lar?dig-SUB-AGR?their digging?The questions that need to be answered related to processing are (1) What should a(super)linear fragment of processing for morphology deliver to (morpho)syntax?
and(2) Is the syntax lexemic or morphemic?
The problems with lexemic syntax, whichstem from mismatches with semantics, were highlighted in the introduction.
In other160Computational Linguistics Volume 28, Number 2interpretationsyntax andkazmakazkazma?POSS3pkazma?PLU?POSS3pkazma?PLU?POSS3skaz?SUB?AGRkazmakazkazma?POSS3pkazma?PLU?POSS3pkazma?PLU?POSS3skaz?SUB?AGRpairsroot lexiconaffix lexicon ?ma?lar?i?larikazkazma?lar?i?lariroot lexiconmorpheme?semanticsmatchingmorphologicalparsinglexiconroot and affixmorphologicalparsing interpretationsyntax and(a) Lexemic syntax and lexicon(b) Morphemic syntax and split lexicon(c) Morphemic syntax and lexiconpairsinterpretationsyntax and?maPF?LFPF?LFpairsPF?LFPhonological Form (PF)Logical Form (LF)Figure 3The processing of kazmalar?
in three different architectures (see Example (19) for glosses).words, a lexemic grammar (e.g., Figure 3a) is computationally nontransparent wheninterpretation is a component of an NLP system.Regarding the first question, let us consider two architectures from the perspectiveof the lexicon for the purpose of morphology, morphemic syntax, and semantics inter-face.
The architecture in Figure 3b incorporates the current proposal as an interpretivefront end to a morphological analyzer such as Oflazer?s (1994), which delivers the anal-yses of words as a stream of morphemes out of which the bound morphemes have tobe matched with their semantics from the affix lexicon to be interpretable in grammar.The advantage of this model is its efficiency; morphological parsing of words is?inprinciple?linear context free; hence, finite-state techniques and their computationaladvantages readily apply.
But the uninterpretable surface forms of bound morphemesmust match with those of the affix lexicon, and this is not necessarily a one-to-onemapping because of multiple lexical assignments for capturing syntactic?semantic dis-tinctions (e.g., dative case as a direct object, indirect object, or adjunct marker or -ias a possessive and/or compound marker).
Surface form?semantics pairing is not atrivial task, particularly in the case of lexically composite affixes, which require se-mantic composition as well as tokenization.
The matching process needs to be awareof all the syntactic contexts in which certain affix sequences act as a unit, for exam-ple, relative participles and agreement markers (-dig?-i relative participle as -OP-POSSor -OP-AGR), possessive and compound markers, etc., for Turkish.
The factorizationof syntactic issues into a morphological analyzer would also make the separate mor-phological component nonmodular or expand its number of states to factor in theseconcerns (e.g., treating the -OP-POSS sequence as a state different from -OP followed161Bozsahin The Combinatory Morphemic LexiconTable 2Parsing performance.Average numberSample text Number of items of parses/grammatical Average CPU timetype in text input per test (milliseconds)Normal NormalPAS form PAS formtests words morphs check parse Unrestr.
check parseWord order and 58 216 384 1.26 3.68 39 39 30caseSubordination 14 70 137 3.00 5.09 267 270 180Relativization 23 130 232 2.04 2.32 796 783 266Control verbs 33 147 291 1.42 3.34 166 163 137Possessives and 26 109 200 1.23 2.47 137 135 98compoundsAdjuncts 14 57 100 1.12 4.87 89 88 72-ki relatives 24 66 179 1.07 1.54 36 36 35Note: CPU times are for a Sun UltraSparc-4 running SICStus Prolog; lexical items include stems and inflec-tional affixes.by -POSS, in which -POSS is not interpreted with the semantics of possession but thatof agreement marking).
Not knowing how many of the syntactic distinctions are han-dled by the morphological analyzer, a subsequent interpreter may need to reconsultthe grammar if scoping problems arise.The architecture in Figure 3c describes the current implementation of the pro-posal.
Bound morphemes are fed to the parser along with their interpretation.
Thismodel is preferred over that presented in Figure 3b for its simplicity in design andextendibility.16 The price is lesser efficiency due to context-free processing of inflec-tional morphology.
By one estimate (Oflazer, Gocmen, and Bozsahin 1994), Turkishhas 59 inflectional morphemes out of a total of 166 bound morphemes, and Oflazer(personal communication) notes that the average number of bound morphemes perword in unrestricted corpora is around 2.8, including derivational affixes.
In a newscorpus of 850,000 words, the average number of inflections per word is less than two(Oflazer et al 2001).
This is tolerable for sentences of moderate length in terms of theextra burden it puts on the context-free parser.
Table 2 shows the results of our testswith a Prolog implementation of the system on different kinds of constructions.
Thetest cases included 10 lexical items on average, with an average parsing time of 0.32seconds per sentence.
A relatively long sentence (12 words, 21 morphemes) took 2.9seconds to parse.
The longest sentence (20 words, 37 morphemes) took 40 seconds.The lexicon for the experiment included 700 entries; 139 were free morphemes and561 were bound morphemes compiled out of 105 allomorphic representations (includ-ing all the ambiguous interpretations of bound morphemes and the results of lexicalrules).
For a rough comparison with an existing NLP system with no disambiguation16 The morphological analyzer would be in no better position to handle morpheme?semantics pairing ifthe architecture in Figure 3b were implemented with an integrated lexicon of roots and affixes.
Forinstance, -POSS would still require distinct states because of the difference in the semantics ofpossession and agreement marking coming from the lexicon.162Computational Linguistics Volume 28, Number 2aids, Gu?ngo?rdu?
and Oflazer (1995) reported average parsing times of around 10 sec-onds per sentence for a lexicon of 24,000 free morphemes, and their morphologicalanalyzer delivered around two analyses per second to a lexemic grammar.
Oflazer?slater (1996) morphological analyzer contained an abstract morphotactic component ofaround 50 states for inflections, which resulted in compilation to 30,000 states and100,000 transitions when the morphophonemic rules were added to the system.In conclusion, we note that the current proposal for a morphemic lexicon andgrammar is compatible with both a separate morphological component (Figure 3b) andsyntax-integrated inflectional morphology (Figure 3c).
The architecture in Figure 3bmay in fact be more suitable for inflecting languages (e.g., Russian) in which thesurface forms of bound morphemes are difficult to isolate (e.g., me?ste, locative singularof me?sto) but can be delivered as a sequence of morpheme labels by a morphologicalanalyzer (e.g.
me?sto-SING-LOC) to be matched with the lexical type assignments to-SING and -LOC for grammatical interpretation.It might be argued that in computational models of the type in Figure 3b, the latticeis not necessary, because the morphological analyzer embodies the tactical component.But not only tactical problems (cf.
Example (18) and its discussion) but also transparentscoping in syntax and semantics is regulated by the use of lattice in type assignments,and that is our main concern.
We show examples of such cases in the remainder of thearticle.
Thus the nonredundant role of the lattice decouples the morphemic grammar?lexicon from the kind of morphological analysis performed in the back end.5.
Case Study: The English PluralIn this section, we present a morphosyntactic treatment of the English plural mor-pheme.
The lattice for English is shown in Figure 2b.
We follow Carpenter (1997) incategorizing numerical modifiers and intersective adjectives as plural noun modifiers:four boys is interpreted as four(plu boy) and green boxes as green(plu box).
This bracketingreflects the ?set of sets?
interpretation of the plural noun; four(plu boy) denotes the setof nonempty nonsingleton sets of boys with four members.
The type assignments in(20) correctly interpret the interaction of the plural and these modifiers (cf.
21a?b).The endotypic category of the plural also allows phrase-internal number agreementfor languages that require it; the agreement can be regulated over the category Nbefore the specifier is applied to the noun group to obtain NP.
(20) -PLU :=a?
s ?n< N\b< N:?x.plu xfour :=s?
four ?n< N/n?N:?x.four xgreen :=s?
green ?n< N/n< N:?x.green x(21) a. four boy -sn< N/n?Nb< Nn< N\b< N<n< N: plu boy>n< N : four(plu boy)163Bozsahin The Combinatory Morphemic Lexiconb.
four boy -s*** >n< N: four boyn< N\b< Nbecause n-base = n-num***n< N: * plu(four boy)Carpenter (1997) points out that nonintersective adjectives (e.g, toy, fake, alleged) areunlike numerical modifiers and intersective adjectives in that their semantics requiresphrasal (wide) scope for -PLU, corresponding to the ?set of things?
interpretationof the plural noun.
Thus, toy guns is interpreted as plu(toy gun) because the pluraloutscopes the modification.
It denotes a nonempty nonsingleton set of things that arenot really guns but toy guns.
*toy(plu gun) would interpret plu over guns.
The situationis precisely the opposite of (21); we need the second derivational pattern to go throughand the first one to fail.
The following category for nonintersective adjectives derivesthe wide scope for -PLU but not the narrow scope:(22) toy :=s?
toy ?b< N/b< N:?x.toy x(23) a. toy gun -s<b< N/b< Nn< N: plu gun***n< N : *toy(plu gun)because n-num ?
n-baseb.
toy gun -sb< N/b< Nb< Nn< N\b< N>b< N: toy gun<n< N : plu(toy gun)Carpenter (1997) avoided rebracketing because of the plural through lexical typeassignments to plural nouns and a phonologically null lexical entry to obtain differ-ent semantic effects of the plural.
In our formulation, there is no lexical entry forinflected forms and no phonologically null type assignment to account for the dis-tinction in different types of plural modification; there is only one (phonologicallyrealized) category for -PLU.17 The modifiers differ only in the kind and degree of mor-phosyntactic control.
Strict control (?)
on four disallows four boy, and flexible control(< ) on green also handles green box.
Four green boxes is interpreted as four(green(plu box)),17 This is not to say that there is only one model-theoretic interpretation of plu.
?Sets of sets?
and ?set ofindividuals?
valuations of plu can be carried over the PAS.164Computational Linguistics Volume 28, Number 2not as *four(plu(green box)), and four toy guns is interpreted as four(plu(toy gun)), not as*plu(four(toy gun)).
These derivations preserve the domain of the modifiers and theplural without rebracketing.6.
Case Study: Turkish MorphosyntaxThere have been several computational studies to model morphology?syntax inter-action in Turkish.
These unification-based approaches represent varying degrees ofintegration.
Gu?ngo?rdu?
and Oflazer (1995) isolates morphology from syntax by havingseparate modules (a finite-state transducer for the former, and an LFG component forthe latter), that is, the syntax is lexemic.
The morphological component is expected tohandle all aspects of morphology, including inflections and derivations.
In Sehitogluand Bozsahin (1999), lexical rules implement inflectional morphology, and derivationsare assumed to take place in the lexicon.
Hoffman?s (1995) categorial analysis of Turk-ish is also lexemic; all lexical entries are fully inflected.
Interpretive components ofthese systems face the aforementioned difficulties because of their commitment to lex-emic syntax.
Inflectional morphology is incorporated into syntax in another categorialapproach (Bozsahin and Go?c?men 1995), but morphotactic constraints are modeled withnonmonotonic unification, such as nonexistence checks for features and overrides.
Thesystem cannot make finer distinctions in morphosyntactic types either.
The result is anovergenerating and nontransparent integration of morphology and syntax because ofthe possibility of rebracketing and the unresolved representational basis of the lexicon.In this section, we outline the application of the proposed framework to Turkish.We analyze a large fragment of the language, without any claims for a comprehensivegrammar.
The phenomena modeled here exhibit particular morphosyntactic problemsdescribed in the preceding sections.
We assume the binding theory in Steedman (1996),which is predicated over the PAS.
In each section, we provide a brief empirical observa-tion about the phenomenon, propose lexical type assignments, exemplify derivationsof the parser, and briefly discuss the constraints imposed by morphosyntactic types.Because of space considerations, we sometimes use abbreviated forms in derivationssuch as the genitive affix?s (N/(N\N))\N category for (o< N/(o?Npn\o?Npn))\o< Npn,but the parser operates on full morphosyntactic representations.6.1 Case Marking and Word OrderTurkish is regarded as a free constituent order language; all permutations of thepredicate and its arguments are grammatical in main clauses, being subject to con-straints on discourse and semantic properties such as definiteness and referentialityof the argument and topic?focus distinctions.
The mapping of surface functions togrammatical relations is mediated by case marking.
Word order variation has lesserfunctionality in embedded clauses because embedded arguments are less accessibleto surface discourse functions like topic and focus.
Embedded clauses are verb fi-nal.6.1.1 Lexical Types.
We start with the lexical type assignments for the verbs.
We usethe abbreviations in (24a) when no confusion arises about the arguments?
case or mor-phosyntactic type.
Verb-final orders are regarded as basic, which suggests the categoryS\NP\NP for transitive verbs.
But Janeway (1990) argued that such underspecificationfor verb-peripheral languages causes undesirable ambiguity.
Grammatical relations of165Bozsahin The Combinatory Morphemic Lexiconthe arguments are determined not by directionality but by case in such languages.
Thecategory S\NPnom\NPacc resolves the ambiguity (24b?c).
(24) a. IV = S\NPTV = S\NP\NPDV = S\NP\NP\NPb.
sev (like) :=s?
sev ?v< S\f< NPnom\f< NPacc:?x.
?y.like xyc.
ver (give) :=s?
ver ?v< S\f< NPnom\f< NPdat\f< NPacc:?x.?y.
?z.give yxzd.v< S\f< NPnom\f< NPacc :?x.
?y.like xy ?v< S\f< NP+refacc \f< NPnom :?y.
?x.like xye.
-ACC :=a?
i|?|u|u?|yi|y?|yu|yu?
?c< Nacc\o< N:?f .ff.
-LOC :=a?
de|da|te|ta ?
(?< S/?< S)\o< N:?x.
?f .at fxGapping behavior seems to indicate that Turkish is verb final, not just SOV.
SOand OS syntactic types must be distinguished to account for SO & SOV, OS & OSV,*SO & OSV and *OS & SOV.
The OS & OSV pattern requires the lexical categoryS\NPacc\NPnom for the verb (Bozsahin 2000b).
SOV and OSV base orders can be cap-tured uniquely in the lexicon in set-CCG notation as S\{NPacc,NPnom}.
Set-CCG isstrongly equivalent to CCG (Baldridge 1999).
We distinguish SOV and OSV lexically,however, because OSV requires referential objects (25a?b).
OSV is generated from SOVby a lexical rule (24d).
This is genuine lexical ambiguity, because the two related entriesdiffer in semantics (referentiality).
(25) a. Kitab-?
adam oku-duBook-ACC man.NOM read-TENSE?The man read the book.?b.
*Kitap adam oku-duBook man.NOM read-TENSERegarding the relationship between case and the specifiers, it is questionablewhether Turkish has a discernible syntactic category for determiners.
There is no lex-ical functor that takes an N and yields an NP.
The only article, the indefinite bir (?a?
),makes a distinction in discourse properties (26).
Specifying case as a determiner (e.g.,NP\N) does not alleviate the problem, either.
Ignoring the problem of case stackingfor a moment, zero marking of the surface subject and the indefinite object takes usback to where we started.
(26) C?ocuk yes?il bir elma/elma/elma-y?
ye-mis?child.NOM green an apple/apple/apple-ACC eat-TENSE?The child ate a green apple.?
(indefinite but referential apple)?The child ate green apple.?
(indefinite and nonreferential apple)?The child ate the green apple.?
(definite and referential apple)166Computational Linguistics Volume 28, Number 2Making the nouns lexically ambiguous (N or NP) would also require that all func-tions onto nouns be ambiguous (N\N and NP\NP for inflections, N/N and NP/NP foradjectives, etc.).
Redundancy of this kind in the lexicon is not desirable, since it is in-troduced purely for formal reasons with no distinction in meaning.
We accommodatethese concerns by positing a special case of type raising for Turkish (27).
Similarly,contraposition turns Ns into functors looking for NPs.
(27) Type Raising for Turkish: Nagr : a ?
T/(T\f< NPagr):?f .f [a]?
T\(T/f< NPagr):?f .f [a]T ?
{S,S\NP,S\NP\NP, S\NP\NP\NP}The noun that is type raised can be a syntactically derived noun (28).
SO (and OS)constituency required for gapping is provided by >T and >B.
(28) Mehmet ku?c?u?k yes?il kitab-?, c?ocuk da yeni gelen dergi-yi oku-duM.NOM little green book-ACC child-COORD new come mag.-ACC read-TENSENnom Nacc Nnom Nacc S\NPnom\NPacc>T >TS/(S\NPnom) (S\NP)/(S\NP\NPacc)...>B >BS/(S\NPnom\NPacc) S/(S\NPnom\NPacc)&S/(S\NPnom\NPacc)>S?Mehmet read the little green book, and the child, the newly arrived magazine?.Our lexical type assignment to case morphemes (24e?f) departs from other CCGanalyses of case (e.g., Steedman 1985, 1991a, Bozsahin 1998).
These studies correlatemorphological case with type raising of arguments, in the case of Bozsahin (1998), viaa value-raised category assignment to case morphemes.
Evidence from NP-internalcase agreement and case stacking (Kracht 1999) challenges the type-raising approach.Agreement phenomena require that case (which can be marked on articles, adjectives,and nouns) be regulated as an agreement feature within the category N before thecase-marked argument looks for the verb via type raising.
Kracht observes that, incase stacking, there may be other morphemes between two case morphemes.
Thus,treating the two cases as composite affixes for the purpose of type raising is notfeasible.
If the first case type-raises the noun to say, T/(T\NP), the second case wouldrequire a category, (T/(T\NP))\(T/(T\NP)); that is, it is endotypic.
Hence, an endotypiccategory for case (like other inflections in the paradigm) subsumes the type-raisinganalysis of case provided that type raising is available in the grammar, not necessarilyanchored to case.We analyze case as an endotypic functor of type N\N (24e)?hence allow forphrase-internal agreement for languages that require it and provide type raising ingrammar as in (27).
Abandoning the type-raising analysis of case does not necessitatetaking liberties in the directionality of the categories, such as the use of nondirectionalslash (|) in multiset-CCG (Hoffman 1995).
Contraposition and type raising in grammar167Bozsahin The Combinatory Morphemic Lexiconcan account for free word order and gapping facts with fully directional syntactic types(Bozsahin 2000a).6.1.2 Derivations.
The wide scope of case is captured by treating its argument type asnon-case-marked N (o< N) and the type of noun modifiers as functions onto non-case-marked nouns of a particular domain, for example,b< N for nonintersective adjectivesandn< N for intersective adjectives (29a).
The same strategy in type assignments toother nominal inflections allows them to outscope nominal modification, for exam-ple, (29b).
(29) a. Mehmet [ [ oyuncak araba ] -lar ] -?
sev-erM.NOM toy car -PLU -ACC like-TENSE<Bb< Nnomb< N/b< Nb< Nn< N\b< Nc< Nacc\o< Nt< S\f< NPnom:mehmet :?x.toy x : car :?x.plu x :?f .f \f< NPacc>TS/(S\f< NPnom) :?x.
?y.like xy:?f .f [mehmet]>b< N: toy car<n< N: plu(toy car)<c< Nacc: plu(toy car)>T(S\NP)/(S\NP\f< NPacc):?g.g[plu(toy car)]>t< S\f< NPnom:?y.like(plu(toy car))y>S: like(plu(toy car))mehmet?Mehmet likes toy cars.?b.
Adam-?n [ku?c?u?k k?rm?z?
araba ]-s?Man-GEN little red car-POSS?the man?s little red car?
= poss(little(red car))manA word-based alternative for reconciling the semantic (wide) scope of inflectionsand their morphological (narrow) attachment to stems runs into difficulties even ifwe assume that morphemes carry type assignments?and hence have representationalstatus?but that they always combine with stems first.
We use syntactic types to showthe problem.
If -PLU and -ACC in (29a) combine with the stem first, only the narrow-scope reading of the plural and case is possible (30a).
Plu(toy car) is not derivable with168Computational Linguistics Volume 28, Number 2word-based modification.
The morphosyntactic categories, however, are transparentto the scope of nominal modification (cf.
(29a) and (30b)).
(30) a. oyuncak [ [araba ] -lar ] -?toy car -PLU -ACCN/N N N\N Nacc\N:?x.toy x : car :?x.plu x :?f .f<N: plu car<Nacc: plu car>N: ?
toy(plu car)b.
[yes?il [araba ] -lar ] -?green car -PLU -ACCn< N/n< Nb< Nn< N\b< Nc< Nacc\o< N:?x.green x : car :?x.plu x :?f .f<n< N: plu car>n< N: green(plu car)<c< Nacc: green(plu car)Surface case annotations on categories enable the grammar to capture the correctPAS in all permutations of S, O, and V while maintaining the discourse-relevant dis-tinctions (31).
Verb-final subordinate clauses are enforced by the directionality of thesubordination morphemes in the lexicon.
(31) a.
S O V>T >TS/(S\f< NPnom) (S\NP)/(S\NP\f< NPacc) S\NPnom\NPacc>S\NPnom>Sb.
O S V>T >TS/(S\f< NPacc) (S\NP)/(S\NP\f< NPnom) S\NPacc\NPnom>S\NPacc>S169Bozsahin The Combinatory Morphemic Lexiconc.
O V S>T >XP(S\NP)/(S\NP\f< NPacc) S\NPnom\NPacc S?t\(S\NPnom)>S\NPnom<S?td.
S V O>T >XP(S\NP)/(S\NP\f< NPnom) S\NPacc\NPnom S?t\(S\NPacc)>S\NPacc<S?te.
V S O>XP >XPS\NPnom\NPacc S?t\(S\NPnom) S?t\(S?t\NPacc)<BS?t\NPacc<S?tf.
V O S>XP >XPS\NPacc\NPnom S?t\(S\NPacc) S?t\(S?t\NPnom)<BS?t\NPnom<S?t6.2 SubordinationSubordinate clauses can be classified as unmarked clauses (32a), infinitival clauses(32b), verbal nouns (32c), and nominalizations (32d).
The latter two types require agenitive embedded subject, which agrees with the subordinate verb.
(32) a. Mehmet [ c?ocuk ev-e git-ti ] san-d?M.NOM child.NOM house-DAT go-TENSE assume-TENSE?Mehmet assumed that the child went home.?b.
C?ocuk [ k?z-a kalem-i ver-me ] -yi unut-tuchild.NOM girl-DAT pen-ACC give-SUB1i -ACC forget-TENSE?The child forgot to give the pen to the girl.?c.
[ C?ocug?-un araba-da uyu-ma-s?]
Mehmet?i k?z-d?r-d?child-GEN car-LOC sleep-SUB1g-POSS M-ACC anger-CAUS-TENSE?Child?s sleeping in the car made Mehmet angry.
?170Computational Linguistics Volume 28, Number 2d.
Deniz [ c?ocug?-un uyu-dug?-u ] -na inan-m-?yorD.NOM child-GEN sleep-SUB2g-POSS -DAT believe-NEG-TENSE?Deniz does not believe the child?s sleeping.?
(33) a. Denizi [kendisi-nini uyu-ma-d?g?-?]-n?
so?yle-diD.NOM self-GEN sleep-NEG-SUB2g-POSS-ACC2 say-TENSE?Denizi said that hei did not sleep.?b.
*kendisii [Deniz?ini uyu-ma-d?g?-?
]-n?
so?yle-dic.
Denizi adam-?j [ kendii/j arkadas?-?-n?n go?r-du?g?-u?
]-ne inan-?yorD.NOM man-ACC self friend-POSS see-SUB2g-POSS-DAT2 believe-TENSE?Denizi believes that hisi/j friend saw the manj.?d.
Denizi adam-aj [ kendii/?j kitab-?-n?
oku-dug?-u ]-nu so?yle-diD.NOM man-DAT self book-POSS-ACC2 read-SUB2g-POSS-ACC2 say-TENSE?Denizi told the manj that he read hisi/?j book.
?6.2.1 Lexical Types.
The asymmetries in (33) show that the obliqueness order in bind-ing relations is preserved in subordination.
This suggests the following bracketing, inwhich the embedded clause?s position in the PAS of the matrix predicate is determinedby its grammatical function.Matrix-Pred .
.
.
Matrix-Argument .
.
.
Embedded-Clause .
.
.
Matrix-Argument(34) -SUB1i (-ma) :=a?
ma ?b< N\(a< S\f< NPnom):?f .f(infinitive)-SUB1g (-mas?)
:=a?
mas?
?o< N\f< NPagr\(a< S\f< NPnom):?f .f(verbal noun)-SUB2g (-d?g??)
:=a?
d?g??
?o< Ncase=obl\f< NPagr\(a< S\f< NPnom):?f .f(nominalization)The wide scope of case markers on subordinate clauses implies that the subor-dinate markers themselves must have phrasal scope as well.
Since case is a nominalinflection, the category of a subordinate marker must be a function onto N. Its ar-gument is IV for infinitives and NPagr\IV for others, which require genitive subjects(34).
This yields two families of functors for subordination.
The verb-final characteris-tics of the embedded clauses is ensured by the backward-looking main functor of thesubordinate marker.For morphosyntactic modality, the resulting nominalized predicate can receiveonly case, hence it haso< N control.
Verbal nouns refer to actions, and nominaliza-tions refer to facts.
Subordinate markers for the former are tenseless.
A subordinatemarker replaces the tense of the subordinate verb in nominalizations, yieldinga< S171Bozsahin The Combinatory Morphemic Lexiconcontrol on the verb.
For subject raising, the result may undergo any nominal inflection(b< N).Word order variation within the subordinate clause is constrained by the subjecton the left and the verb on the right.
This constraint is achieved by categorizing theembedded subjects as NPagr and having a result category of N for all subordinate mark-ers.
If there were any contraposed element NP in the embedded clause, the categoryof the clause would be S\NP, and the clause could not combine with the contraposedcategory such as S?t\(S\NP) on the right because the extraction category combineswith a subordinate marker first, which is onto N, not S\NP, hence composition (<B)could not take place.6.2.2 Derivations.
Example (35a) is the derivation of subject raising (we use N?
asan abbreviation for a type-raised N when space is limited).
We use Steedman?s (1996)ana function to denote the binding of the embedded subject.
Infinitive -SUB1i hasphrasal scope in this example; the DV must be reduced to an IV before the infinitivecan apply.
Hence the subordination of intransitive clauses is only a special case inwhich the morphological scope of the infinitive works without rebracketing.
Subjectraising and coindexation with the matrix subject are made explicit in the raising cate-gory of unut.
The systematic relationship between the raised and nonraised categoryof such verbs can be captured by a lexical rule, for example, TV:?x.
?y.forget xy ?TV:?f .
?y.forget(f [ana y])y.
(35b?c) contrast subject and nonsubject nominalizations.
The difference is cap-tured with the case distinction of the result type (o< N) for -SUB1g and -SUB2g.
Theseexamples also show the possibility of affix composition in the lexicon.
For instance,we write -mas?
in (35b), which marks subordination and agreement together, insteadof -ma-s?.
Otherwise, -ma (SUB1g) would have to look to the right as a functor toenforce agreement, and the verb-final property of subordination could not be as-sured.
(35) a.
C?ocuk k?z-a kalem-i ver -me -yi unut-tuchild.NOM girl-DAT pen-ACC give -SUB1i -ACC forgot>T >T >T <BN?nom N?dat N?acc DVb< N\(a< S\f< NPnom)c< Nacc\o< N TV:?f .f [child] :?g.g[girl] :?h.h[pen] :?x.?y.?z.
:?f .f :?f .f :?f .
?x.give yxz forget(f [ana x])x>v< S\f< NPnom\f< NPdat>v< S\f< NPnom<b< N<c< Nacc>T(S\NP)/(S\NP\f< NPacc)>t< S\f< NPnom>t< S: forget(give girl pen(ana child))child?The child forgot to give the pen to the girl.
?172Computational Linguistics Volume 28, Number 2b.
C?ocug?-un uyu -mas?
Mehmet?i k?zd?r-d?child-GEN sleep -SUB1g M-ACC anger-TENSE>T >T <BNPagr IV N\NPagr\IV IV/TV TV< >N\NPagr IV<N>TS/IV>S: anger(sleep child)mehmet?The child?s sleeping angered Mehmet.?c.
*C?ocug?-un uyu-dug?u Mehmet?i k?zd?r-d?sleep-SUB2g6.3 The Morphosyntax of ControlThe control verb?s controlled argument is marked by the infinitive -ma, and the re-sulting nominalized embedded clause can undergo nominal inflections (36a?b).
Theinfinitive -ma has the lexical type in (34).
A potential conflict between an object con-trol verb?s subcategorization and PAS is resolved by case decoration: zorla ?force?
andtavsiye et ?recommend?
differ in their case requirements and what is controlled (36b?c).tavsiye et?s infinitive complement is accusative, whereas zorla?s is dative.
(36) a.
C?ocuk [kitab-?
oku-ma ]-ya c?al?s?-t?child.NOM book-ACC read-SUB1i-DAT try-TENSE?The childi tried [to i read the book].?b.
Mehmet c?ocug?-u [kitab-?
oku-ma]-ya zorla-d?M.NOM child-ACC book-ACC read-SUB1i-DAT force-TENSE?Mehmetj forced the childi [to i/?j read the book].?c.
Mehmet c?ocug?-a/*-u [kitab-?
oku-ma]-y?/*-ya tavsiye et-tiM.NOM child-DAT/ACC book-ACC read-SUB1i-ACC/DAT recommend-TENSE?Mehmet recommended the childi [to i read the book].
?6.3.1 Lexical Types.
Subject control verbs (e.g., c?al?s?
?try?
; so?z ver ?promise?)
and objectcontrol verbs (e.g., zorla; tavsiye et) have the control property indicated in their PAS(37).
The nonraising variety of these verbs is obtained via a lexical rule.
(37) c?al?s?
:=s?
c?al?s?
?
TV:?q.
?z.try(q[ana z])zso?z ver :=s?
so?z ver ?
DV:?q.?z.
?w.promise z(q[anaw])wzorla :=s?
zorla ?
DV:?z.?q.
?w.force(q[ana z])zwtavsiye et :=s?
tavsiye et ?
DV:?z?q?w.recommend(q[ana z])zw173Bozsahin The Combinatory Morphemic Lexicon6.3.2 Derivations.
The types in (37), coupled with the raising category of the infinitive,yield the derivations in (38).
These examples compose the infinitive complement beforea case can be applied on the nominalized predicate.
This is possible because of thephrasal scope of -ma and the case markers.
(38b) shows that although there may be twoaccusative-marked NPs, the arguments of the infinitive complement are identifiable;the IV scope of -ma implies that any (di)transitive subordinate verb must find itsnonsubject arguments before the matrix verb gets its arguments.
This type assignmentstrategy handles word order variations inside the infinitive complement and the matrixclause transparently.
(38) a.
C?ocuk kitab-?
oku -ma -ya c?al?s?-t?child.NOM book-ACC read -SUB -DAT try-TENSE>T >T <BS/IV IV/TV TV N\IV Ndat\N TV>IV<N<Ndat>TIV/TV>IV>S: try(read book(ana child))child?The child tried to read the book.?b.
Mehmet c?ocug?-u kitab-?
oku -ma -ya zorla-d?M.NOM child-ACC book-ACC read -SUB -DAT force-TENSE>T >T >T <BS/IV IV/TV IV/TV TV N\IV Ndat\N DV>IV<N<Ndat>TTV/DV>TV>IV>S: force(read book(ana child))childmehmet?Mehmet forced the child to read the book.
?174Computational Linguistics Volume 28, Number 26.4 RelativizationThere are two strategies for forming relative clauses: the subject participle strategy(SP) and the nonsubject participle strategy (OP).
SP is realized by the affixes -(y)An,-(y)AcAk, and -mIs?, and OP by -dIk- and -(y)AcAk-.
OP triggers agreement similar tothat of possessive constructions between the subject and the predicate of the relativeclause (39b).
(39) a. kitab-?
oku-yan adambook-ACC read-SP man?the man that read/reads the book?b.
adam-?n oku-dug?-u kitapman-GEN(AGR) read-OP-POSS(AGR) book?the book that the man read?6.4.1 Lexical Types.
The categories in (40) make explicit the unbounded nature ofrelativization; type raising and composition can combine an indefinitely large sequenceof constituents onto S\NP.
(40) -SP :=a?
yan ?
(N ?/f< N)\(a< S\f< NPnom):?P.?x.
?Q.and(Q[x])(P[x])-OP.AGR :=a?
d?g??
?
(N ?/f< N)\(a< S\f< NPcase=obl)(argument) :?P.?x.
?Q.and(Q[x])(P[x])-OP.AGR :=a?
d?g??
?
(N ?/f< N)\a< S(adjunct) :?P.?x.
?Q.and(Q[x])(at(P[x])x)We present a formulation of relativization without any use of empty categories,traces, or movement.
We follow the Montagovian treatment of relative clauses as nounrestrictors of the semantic type ?P.
?Q.and(Q[x])(P[x]), where P is the semantics of therelative clause and Q is the semantics of the predicate taking the relativized noun(x) as the argument.
Montagovian analysis assumes a generalized quantifier (GQ)category for the determiner; that is, NP is the functor and VP is the argument.
Thedeterminer takes the relativized noun (and its semantically type-raised category) as anargument as well.
In a language with determiners, the functor category of the overallNP can be made explicit by lexically value-raising the determiner with GQ semanticsfrom, for example, NP/N to (S/(S\NP))/N = (S/VP)/N.
To achieve the same effect ina language that lacks determiners, we make NP the functor by lexically value-raisingthe relative participle from (N/N)\(S\NP) to (N?/N)\(S\NP), in which N?/N denotesa value-raised noun, since N?
is a type-raised category.
The category of the relativeparticiple unfolds to ((S/(S\NP))/N)\(S\NP) and (((S\NP)/(S\NP\NP))/N)\(S\NP).Relativization is strictly head final in Turkish.
This implies that all relative par-ticiples are backward-looking functors that differ only in case requirements (cf.
En-glish relatives, which require different directionality, e.g., (N\N)/(S\NP) for subjectsand (N\N)/(S/NP) for nonsubjects).
For morphosyntactic modality, the head noun has175Bozsahin The Combinatory Morphemic Lexiconflexible control (f< N), because any further grammatical marking on the head must beshared (41).
(41) Adam-?n go?r-du?g?-u?
c?ocuk-lar uyu-duman-GEN see-OP-POSS child-PLU sleep-TENSE?The children that the man saw slept.?
= and(sleep(plu child))(see(plu child)man)=*and(sleep(plu child))(see childman)Morphologically, the agreement marker -POSS in OP strategy is a function overthe -OP morpheme, but syntactically, the -OP morpheme triggers the agreement inthe relative clause.
Hence -OP-POSS can be treated as a lexically composite affix andglossed as -OP.AGR.
This also ensures the verb-final property of the relativized clauseby not positing a rightward-looking functor for -OP.
As for attachment modality, rel-ative participles are bound morphemes that are affixed to the predicate.6.4.2 Derivations.
(42a?d) show example derivations for subject, object, indirect object,and adjunct relativization.
All nonsubject arguments are handled by a single -OP type(42b?c).
Relativizing the specifier of an argument uses the same strategy as the argu-ment.
This phenomenon calls for another well-regulated lexical assignment schema,for example, (N?/N)\(N\N)\IV for the relativized specifier of the subject.
(42e) is an ex-ample of relativizing the subject?s specifier.
Configurationality within the noun groupis maintained by backward directionality of the categories.
(42) a. kitab-?
oku -yan adam uyu-dubook-ACC read -SP man sleep-TENSE>T <BIV/TV TV (N?/N)\IV N IV:?f .f [book] :?x.
?y.read xy :?P.?x.
?Q.and(Q[x])(P[x]) :man :?x.sleep x>IV:?y.read book y<N?/N:?x.
?Q.and(Q[x])(read book x)>N?=S/(S\NP):?Q.and(Q[man])(read bookman)>S: and(sleepman)(read bookman)?The man who read the book slept.?b.
adam-?n go?r -du?g?u?
c?ocuk uyu-duman-GEN read -OP.AGR child sleep-TENSE< <BNPagr TV (N?/N)\IVagr N IV<IVagr<N?/N<N?=S/IV>S: and(sleep child)(see childman)?The child whom the man saw slept.
?176Computational Linguistics Volume 28, Number 2c.
c?ocug?-un kitab-?
ver -dig?i adam uyu-duchild-GEN book-ACC give -OP.AGR man sleep-TENSE< >T <BNPagr TV/DV DV (N?/N)\IVagr N IV>TV<IVagr<N?/N>N?=S\IV>S: and(sleepman)(giveman book child)?The man to whom the child gave the book slept.?d.
c?ocug?-un uyu -dug?u araba bozul-duchild-GEN sleep -OP.AGR car break-TENSE< <BNPagr IV (N?/N)\S N IV<S<N?/N>N?=S/IV>S: and(break car)(at(sleep child)car)?The car that the child slept in broke.?e.
c?ocug?
-u uyu -yan adam k?z-d?child -POSS sleep -SP man anger-TENSE<BN N\N\N IV (N?/N)\(N\N)\IV N IV< <N\N (N?/N)\(N\N)<N?/N>N?=S/IV>S: and(sleep(poss childman))(angerman)?The man whose child slept got angry.
?As these examples indicate, -SP and -OP do not range over the verb stem insemantic scope; they cover the entire relative clause.
The wide scope of -SP and -OPresolves the inconsistency pointed out in the introduction (5b?c), which was mainlydue to coindexation in unification accounts and the lexemic nature of the lexicon.Isolating the relative participle inflections in a morphological component underminesthe transparency of derivations.
Note also that -OP is categorially transparent to thearity of the verb; a DV must be reduced to an IV before -OP applies to the verbcomplex (42c).
This is possible only when -OP has phrasal scope.177Bozsahin The Combinatory Morphemic Lexicon6.5 Ki-relativizationKi-relativization is a morphosyntactic process that can generate indefinitely long wordsof relative pronouns and relative adjectives.
-ki can be attached to case-marked nounswhose case relation is one of possession, time, or place (i.e., the genitive and thelocative).
Its effect is to create a nominal stem on which all inflections can start again(43a?b).
It produces relative pronouns (43c) and relative adjectives (43d) with thelocative and relative pronouns with the genitive.
(43) a. araba-da-kicar-LOC-REL?the one in the car?b.
c?ocug?-un ev-i-nde-ki-ler-in-kichild-GEN house-POSS-LOC2-REL-PLU-GEN-RELlit.
?The one that belongs to the ones that are in the child?s house?c.
Ben ev-de-ki-ni hic?
kullan-ma-d?-mI.NOM house-LOC-REL-ACC2 never use-NEG-TENSE-PERS.1s?I never used the one at home.?d.
ev-de-ki hediyehouse-LOC-REL present?the presenti, the onei at home?6.5.1 Lexical Types.
(44) a.
-PROki :=a?
ki ?
l?N\ c?Nloc:?x.
?f .and(at PRO x)(f [PRO])(locative)b.
-ADJki :=a?
ki ?
( l?N/n< N)\ c?Nloc:?x.?y.
?f .and(at xy)(f [y])c. -PROki :=a?
ki ?
l?N\N ?gen:?x.
?f .and(poss PRO x)(f [PRO])(genitive)d. sabahki :=s?
sabahki ?
l?N/n< N:?x.
?f .and(atmorning x)(f [x])e. ki (that) :=c?
ki ?
(N ?\f< N)/(v< S\f< NPnom):?P.?x.
?Q.and(Q[x])(P[x])N?gen is a shorthand for the N/(N\N) category of a type-raised genitive.
In (43c),pronominal one (PRO) cannot be bound to ev (44a).
Adjectival interpretation (43d)associates the relative adjective with the relativized noun (44b).
For morphosyntac-tic modality, ki-marked nouns behave like possessive-marked nouns in case marking,which requires strict control over the possessive (o?N).
This presents a dilemma: Mor-phologically, -ki creates a nominal stem that can undergo all nominal inflections again,but, as (45a) indicates, the stem does not take the CASE (ACC, DAT, etc.)
that is com-mon to nouns unmarked on the possessive.
Thus CASE2 in (45c) must refer to anotherdiacritic (n-relbase, orl? )
to eliminate (45b).
This diacritic controls the result categoryof -ki.
The value-raised varieties of (44a?c) are assigned a type similar to the type ofrelative participles.
Inherently temporal nouns such as sabah (?morning?)
can take -ki178Computational Linguistics Volume 28, Number 2without the locative.
They can be lexicalized without overgeneration with the help ofthe morphosyntactic modalityl?
(44d).
(45) a.
*ev-de-ki-yihouse-LOC-REL-ACCb.
*ev-nihouse-ACC2c.
ev-de-ki-nihouse-LOC-REL-ACC2d.
ev-ihouse-ACC6.5.2 Derivations.
-ki ranges over the case-marked noun, which, as (46a?b) indicate,can be lexical or phrasal.
In a lexemic analysis, the entire ki-marked noun would haveto be rebracketed before the adjective ku?c?u?k can apply to its right scope (which is ev,not c?ocuk).
(46) a. ev -de -kihouse -LOC -PROkib< Nc< N\o< Nl?N\ c?Nloc<c< Nloc<l?N:?f .and(at PROhouse)(f [PRO])?the one that is in the house?b.
ku?c?u?k ev -de -ki c?ocuklittle house -LOC -ADJki childb< N/b< Nb< Nc< N\o< N (l?N/n< N)\ c?Nlocb< N>b< N<c< Nloc<l?N/n< N>l?N:?f .and(at(little house)child)(f [child])?the childi, the onei at the little house?There is another ki in Turkish that forms nonrestrictive relative clauses as post-modifiers.
It is a Persian borrowing and follows the Indo-European pattern of relativeclause formation (47).
It can be distinguished from the bound morpheme -ki lexically.Its attachment characteristic is also different than that of -ki (44e).
(47) Adam ki hep uyurman that always sleep-TENSE?the man, who always sleeps?179Bozsahin The Combinatory Morphemic Lexicon6.6 Possessive Constructions and Syntactic CompoundsThe grammatical marking of possession is realized through the genitive case on thepossessor (Ngen) and the possessive marker on the possessee (Nposs).
Ngen and Nposs mustagree in person and number (48a), and the resulting noun group is configurational.Possessives can be nested (48c).
(48) a. ev-in kap?-s?house-GEN3 door-POSS3s?the door of the house?b.
* ev-in kap?
/ *ev-in kap?-lar (door-PLU)c. ben-im arkadas?-?m-?n ev-i-nin kap?-lar-?I-GEN1 friend-POSS1s-GEN3 house-POSS3s door-PLU-POSS3s?my friend?s house?s doors?d.
ben-im arkadas?-?m-?ni dost-u-nunj kendisi?i/jI-GEN1 friend-POSS1s-GEN3 buddy-POSS3s-GEN3 self?my friend?s buddy himself?e.
Her c?al?s?an-?n baz?
hak-lar-?
vard?revery worker-GEN3 some right-PLU-POSS3s exists?x?y((worker(x) ?
right(y)) ?
has(x, y))but not ?y?x(right(y) ?
(worker(x) ?
has(x, y)))6.6.1 Lexical Types for Possessives.
Type assignments for the genitive and the pos-sessive can be schematized over person (p) and number (n) features, as in (49).
(49) -GENpn :=a?
s ?
(o< N/(o?Npn\o?Npn))\o< Npn:?x.
?y.poss yx-POSSpn :=a?
s ?
( o?Npn\o?Npn)\n< Npn:?f .fThe possessive marker?s result category is a functor because it enforces agreementwith the type raised specifier.18 (48d?e) indicate that the genitive marker is a typeraiser; the possessor scopes over the possessee.
For morphosyntactic modality, thegenitive marker can be attached to nouns that are inflected up to and including apossessive marker (o< N).
Moreover, nesting in possessives implies that the specifiermay be a genitive.
Hence, the stem?s category must beo< N.But there is a finer control over the possessee argument?s category, because it mustbe inflected with the possessive marker to signify relation of possession (cf.
(48a?b)).Semantically, the possessive must outscope nominal modification.
For instance, (50a)has the PAS as indicated, hence both markers must range over a noun group, not just18 An ?inert?
category such as N may be motivated by the prodrop phenomenon, in which the specifiermay be dropped under pragmatically conditioned circumstances.
But this analysis disregards the pointthat binding relations (hence semantics) still require the coindexation of the specifier with some overtreferent, which can be inferred from the discourse.
Such an interface phenomenon seems to be bettersuited for handling by interactions in the components of a multidimensional grammar, rather than as apurely syntactic phenomenon.180Computational Linguistics Volume 28, Number 2the stem.
Binding relations require an organization of the type (poss possee possessor)(50b?c).
(50) a. yas?l?
adam-?n ku?c?u?k k?z-?old man-GEN3 little daughter-POSS3s?old man?s little daughter?
= poss(little daughter)(oldman)b. adami-?n kendii-siman-GEN self-POSS?the man himself?c.
*kendii adami-?6.6.2 Derivation of Possessive Constructions.
Example (51) shows the wide scope ofthe genitive (51a) and nested genitives (51b).
(51) a. yas?l?
adam -?n ku?c?u?k k?z -?old man -GEN little daughter -POSSb< N/b< Nb< No< N/(o?N\ o?N)\o< Nb< N/b< Nb< No?N\ o?N\n< N> >b< Nb< N< <o< N/(o?N\ o?N) o?N\ o?N>o< N: poss(little daughter)(oldman)?old man?s little daughter?b.
ben -im arkadas?
-?m -?n ev -iI -GEN friend -POSS -GEN house -POSSN N/(N\N)\N N N\N\N N/(N\N)\N N N\N\N< < <N/(N\N) N\N N\N>N<N/(N\N)>N: poss house(poss friend i)?my friend?s house?181Bozsahin The Combinatory Morphemic Lexicon6.6.3 Lexical Types for Compounds.
Syntactic compounds exhibit syntactic patternssimilar to possessive constructions, but they signify semantic relations of a differentkind.
In what follows, we use the function comp to signify that the arguments in thePAS form a compound but say nothing about the range of productivity of this function.The lexical semantics of the arguments and a qualia structure (Pustejovsky 1991) mayindicate the function?s range of applicability.
Lexical type assignments for compoundmarkers are as in (52).
(52) -COMP :=a?
s ?
m?N\n< N\ b?N:?x.
?y.comp xy-COMP2 :=a?
s ?
m?N\ m?N\n< N\ b?N:?x.?y.
?z.comp(comp xy)z(nested comp)Syntactic compounds are formed by means of compound markers that are attachedto the head of the compound.
For morphosyntactic modality, nonreferentiality of thehead implies no inflection (b?N) or modification (53a?b).
The left component can bea noun group (53c) in which there is ambiguity in the scope of modification.
Thisis regulated by typing, for example, the intersective adjectives ambiguous as nounmodifiers (n< N/n< N) and compound modifiers (m?N/m?N).19 The overall compoundmay be inflected only for case (see, e.g., (53d) and (53e)).
(53) a.otobu?s bilet-ibus ticket-COMP?bus ticket?b.
*otobu?s yes?il bilet-igreenc.yes?il otobu?s bilet-igreen bus ticket-COMPgreen(comp ticket bus)or comp(ticket(green bus))d.otobu?s bilet-i-niticket-COMP-ACC2e.
*otobu?s bilet-i-siticket-COMP-POSSCompound markers serve the dual function of compounding and agreement inpossessive constructions; double marking of the possessive is suppressed (cf.
54a?b).The -COMP2 type assignment in (52) handles nested compounds.
(54) a.banka-n?n faiz oran-?bank-GEN interest rate-COMP.POSS?interest rate of the bank?b.
*banka-n?n faiz oran-?-s?rate-COMP-POSSWe claim that plural compounds are lexically composite functions in a similarvein.
This claim has some empirical support from the lexicalization of -leri as athird person plural possessive marker; see (55b?c).
It follows that -leri has the lexi-19 I am grateful to the anonymous reviewer who proposed this alternative.182Computational Linguistics Volume 28, Number 2cal types of -COMP and -COMP2 with plural and possessive composition: ?x.
?y.plu(comp xy).
(55) a.otobu?s bilet-leribus ticket-COMP.PLU?bus tickets?b.onlar-?n ev-lerithey-GEN3 house-POSS3p?their house?c.onlar-?n ev-ler-ithey-GEN3 house-PLU-POSS3s?their houses?6.6.4 Derivation of Compounds.
(56) exemplifies derivations with the type assign-ments in (52).
(56a?b) show that both the narrow and the wide scope of the modifiercan be accounted for.
(56c?d) show that the compound marker interacts with the pos-sessive.
Hence, it must carry both poss and comp in possessive constructions involvingcompounds.
(56e?f) are examples of nested compounds.
(56f?g) show the effect ofstrict control (b?N) over the compound?s head.
(56) a. yes?il otobu?s bilet -igreen bus ticket -COMPn< N/n< Nb< Nb< Nm?N\n< N\ b?N> <n< Nm?N\n< N<m?N: comp ticket(green bus)b. yes?il otobu?s bilet -i<m?N/m?Nb< Nm?N\n< N<m?N>m?N: green(comp ticket bus)c. banka -n?n faiz oran -?bank -GEN interest rate -COMP.POSSN N/(N\N)\N N N N\N\N\N> <N/(N\N) N\N\N<N\N>N: poss(comp rate interest)bank?interest rate of the bank?183Bozsahin The Combinatory Morphemic Lexicond.
banka -n?n faiz oran -lar?bank -GEN interest rate -COMP.POSS.PLUN N/(N\N)\N N N N\N\N\N> <N/(N\N) N\N\N<N\N>N: poss(plu(comp rate interest))bank?interest rates of the bank?e.
kredi kart -?
faiz oran -?credit card -COMP interest rate -COMP2N N N\N\N N N N\N\N\N< <N\N N\N\N< <N N\N<N: comp(comp rate interest)(comp card credit)?credit card interest rate?f.kredi kart-?
y?ll?k faiz oran-?annual?credit card annual interest rate?g.
*kredi kart-?
faiz y?ll?k oran-?7.
ConclusionTheoretical and computational commitment to word-based grammar?and to regardinflectional morphology as a word-internal process?puts artificial limits on specify-ing the syntactic and semantic domains of all meaning-bearing elements and on thetransparent projection of scope from the lexicon.
Designating words as minimal unitsof the lexicon is too constraining for many languages.
This traditional notion is alsochallenged in current linguistic theorizing (e.g., Jackendoff 1997 and Keenan and Sta-bler 1997).
Marslen-Wilson (1999) argues on psycholinguistic grounds that the lexiconmust be morphemic even for morphologically simpler languages such as English.We have argued in this article that the key to the integration of inflectional mor-phology and syntax is granting representational status to morphemes, which, in acomputational system, requires certain precautions.
What we propose is enriching theexpressive power of the combinatory morphemic lexicon to factor in morphosyntactictypes and attachment modalities.
Coupled with flexible constituency in the grammarand directionality information coming from the lexicon, these extensions provide thegrammar with the information it requires to compute the transparent semantics ofmorphosyntactic phenomena.
This flexibility causes neither inefficiency in parsing noruncontrolled expressivity.
The extensions do not affect the polynomial worst-case com-plexity results, and category unity is preserved by lattice consistency.
The result is amorphemic grammar?lexicon with computationally desirable features such as mod-ularity and transparency.
The system is available at ftp://ftp.lcsl.metu.edu.tr/pub/tools/msccg.184Computational Linguistics Volume 28, Number 2AcknowledgmentsI am very grateful to four anonymous CLreviewers for extensive commentary andsuggestions.
Thanks to Wolf Ko?nig andStefan Mu?ller for the data; and to JasonBaldridge, Gann Bierner, Aysenur Birtu?rk,Ruken C?akici, Nissim Francez, StasinosKonstantopoulos, Markus Kracht, Geert-JanKruijff, Alan Libert, Mark Steedman, U?mitTuran and Deniz Zeyrek for comments,advice, and criticism.ReferencesAho, Alfred V. and Jeffrey D. Ullman.
1972.The Theory of Parsing, Translation, andCompiling.
Vol.
1.
Prentice-Hall.Anderson, Stephen R. 1982.
Where?smorphology?
Linguistic Inquiry,13(4):571?612.Bach, Emmon.
1983.
On the relationshipbetween word-grammar andphrase-grammar.
Natural Language andLinguistic Theory, 1:65?89.Baldridge, Jason.
1999.
Strong equivalenceof CCG and Set-CCG.
Unpublishedmanuscript, University of Edinburgh.Bar-Hillel, Yehoshua, Chaim Gaifman, andEliyahu Shamir.
1960.
On categorial andphrase structure grammars.
Bulletin of theResearch Council of Israel, 9F:1?16.Bozsahin, Cem.
1998.
Deriving thePredicate-Argument structure for a freeword order language.
In Proceedings ofCOLING-ACL 1998, Montreal,pages 167?173.Bozsahin, Cem.
2000a.
Directionality andthe lexicon: Evidence from gapping.Unpublished manuscript, Middle EastTechnical University, Ankara.Bozsahin, Cem.
2000b.
Gapping and wordorder in Turkish.
In Proceedings of the 10thInternational Conference on TurkishLinguistics, Istanbul.Bozsahin, Cem and Elvan Go?c?men.
1995.
Acategorial framework for composition inmultiple linguistic domains.
In Proceedingsof the 4th International Conference onCognitive Science of NLP, Dublin.Bresnan, Joan.
1995.
Lexical?Functionalsyntax.
Course notes.
Seventh EuropeanSummer School in Logic, Language, andInformation, Barcelona.Calder, Jonathan, Ewan Klein, and HenkZeevat.
1988.
Unification categorialgrammar.
In Proceedings of the 12thInternational Conference on ComputationalLinguistics, Budapest, pages 83?86.Carpenter, Bob.
1992.
Categorial Grammar,lexical rules, and the English predicative.In R. Levine, editor, Formal Grammar:Theory and Application.
Oxford UniversityPress, pages 168?242.Carpenter, Bob.
1997.
Type-Logical Semantics.MIT Press.Carpenter, Bob.
1999.
TheTuring-completeness of MultimodalCategorial Grammars.
In Papers Presentedto Johan van Benthem in Honor of his 50thBirthday.
ESSLLI, Utrecht.Carpenter, Bob and Gerald Penn.
1994.
TheAttribute Logic Engine User?s Guide, Version2.0.
Carnegie Mellon University.Chomsky, Noam.
1970.
Remarks onnominalization.
In R. Jacobs andP.
Rosenbaum, editors, Readings in EnglishTransformational Grammar.
Ginn, Waltham,MA, pages 184?221.Chomsky, Noam.
1995.
The MinimalistProgram.
MIT Press.Collins, Michael.
1997.
Three generative,lexicalised models for statistical parsing.In Proceedings of the 35th Annual Meeting ofthe ACL.Creider, Chet, Jorge Hankamer, and DerickWood.
1995.
Preset two-head automataand natural language morphology.International Journal of ComputerMathematics, 58:1?18.Dalrymple, Mary and Ronald M. Kaplan.2000.
Feature indeterminacy and featureresolution.
Language, 76:759?798.Dowty, David.
1979.
Word Meaning andMontague Grammar.
Kluwer, Dordrecht.Dowty, David.
1991.
Toward a minimalisttheory of syntactic structure.
In TilburgConference on Discontinuous Constituency,January 1989.Dowty, David.
1996.
Non-constituentcoordination, wrapping, and MultimodalCategorial Grammars.
In InternationalCongress of Logic, Methodology, andPhilosophy, Florence, August.Eisner, Jason.
1996.
Efficient normal-formparsing for Combinatory CategorialGrammar.
In Proceedings of the 34th AnnualMeeting of the ACL, pages 79?86.Fong, Sandiway.
1991.
ComputationalProperties of Principle-Based GrammaticalTheories.
Ph.D. dissertation, MIT.Gu?ngo?rdu?, Zelal and Kemal Oflazer.
1995.Parsing Turkish using theLexical-Functional Grammar formalism.Machine Translation, 10:293?319.Hankamer, Jorge.
1989.
Morphologicalparsing and the lexicon.
In W.Marslen-Wilson, editor, LexicalRepresentation and Process.
MIT Press.185Bozsahin The Combinatory Morphemic LexiconHepple, Mark.
1990a.
The Grammar andProcessing of Order and Dependency: ACategorial Approach.
Ph.D. dissertation,University of Edinburgh.Hepple, Mark.
1990b.
Normal form theoremproving for the Lambek Calculus.
InProceedings of COLING 1990.Hepple, Mark and Glyn Morrill.
1989.Parsing and derivational equivalence.
InProceedings of the 4th EACL, Manchester.Heylen, Dirk.
1997.
Underspecification inType-Logical Grammars.
In Logical Aspectsof Computational Linguistics (LACL), Nancy.Heylen, Dirk.
1999.
Types and Sorts: ResourceLogic for Feature Checking.
Ph.D.dissertation, Utrecht University.Hockenmaier, Julia, Gann Bierner, and JasonBaldridge.
2000.
Providing robustness fora CCG system.
Unpublished manuscript,University of Edinburgh.Hoeksema, Jack.
1985.
Categorial Morphology.Garland, New York.Hoeksema, Jack and Richard D. Janda.
1988.Implications of process-morphology forCategorial Grammar.
In Richard T.Oehrle, Emmon Bach, and DeirdreWheeler, editors, Categorial Grammars andNatural Language Structures.
D. Reidel,Dordrecht, pages 199?247.Hoffman, Beryl.
1995.
The ComputationalAnalysis of the Syntax and Interpretation of?Free?
Word Order in Turkish.
Ph.D.dissertation, University of Pennsylvania.Jackendoff, Ray.
1997.
The Architecture of theLanguage Faculty.
MIT Press.Jacobson, Pauline.
1996.
The syntax/semantics interface in CategorialGrammar.
In Shalom Lappin, editor, TheHandbook of Contemporary Semantic Theory.Blackwell, 89?116.Janeway, Roger.
1990.
Unacceptableambiguity in Categorial Grammar.
InProceedings of the Ninth West CoastConference on Formal Linguistics, pages305?316.Johnson, Mark.
1988.
Deductive parsingwith multiple levels of representation.
InProceedings of the 26th Annual Meeting of theACL, pages 241?248.Johnson, Mark and Sam Bayer.
1995.Features and agreement in LambekCategorial Grammar.
In Proceedings of the1995 ESSLLI Formal Grammar Workshop,pages 123?137.Jurafsky, Daniel and James H. Martin.
2000.Speech and Language Processing.Prentice-Hall.Karttunen, Lauri.
1989.
Radical lexicalism.In Mark Baltin and Anthony Kroch,editors, Alternative Conceptions of PhraseStructure.
University of Chicago Press,pages 43?65.Keenan, Edward L. and Edward Stabler.1997.
Bare grammar.
Course notes, NinthEuropean Summer School on Logic,Language, and Information,Aix-en-Provence.Komagata, Nobo.
1997.
Efficient parsing forCCGs with generalized type-raisedcategories.
In Proceedings of the Fifth Int.Workshop on Parsing Technologies, pages135?146.Ko?nig, Esther.
1989.
Parsing as naturaldeduction.
In Proceedings of the 27th AnnualMeeting of the ACL, pages 272?279.Kracht, Markus.
1999.
Referent systems,argument structure, and syntax.
ESSLLIlecture notes, Utrecht.Kruijff, Geert-Jan M. and Jason M.Baldridge.
2000.
Relating categorial typelogics and CCG through simulation.Unpublished manuscript, University ofEdinburgh.Lambek, Joachim.
1958.
The mathematics ofsentence structure.
American MathematicalMonthly, 65:154?170.Marslen-Wilson, William.
1999.
Abstractnessand combination: The morphemic lexicon.In Simon Garrod and Martin J. Pickering,editors, Language Processing.
PsychologyPress, East Sussex, UK, pages 101?119.Miller, Philip H. and Ivan A.
Sag.
1997.French clitic movement without clitics ormovement.
Natural Language and LinguisticTheory, 15:573?639.Moortgat, Michael.
1988a.
CategorialInvestigations: Logical and Linguistic Aspectsof the Lambek Calculus.
Foris, Dordrecht.Moortgat, Michael.
1988b.
Mixedcomposition and discontinuousdependencies.
In Richard T. Oehrle,Emmon Bach, and Deirdre Wheeler,editors, Categorial Grammars and NaturalLanguage Structures.
D. Reidel, Dordrecht,pages 319?348.Moortgat, Michael and Richard T. Oehrle.1994.
Adjacency, dependency and order.In Proceedings of the Ninth AmsterdamColloquium.Morrill, Glyn V. 1994.
Type Logical Grammar:Categorial Logic of Signs.
Kluwer.Morrill, Glyn V. 1999.
Geometry oflexico-syntactic interaction.
In Proceedingsof the Ninth EACL, Bergen.Mu?ller, Stefan.
1999.
Deutsche Syntaxdeklarativ.
Head-Driven Phrase StructureGrammar fu?r das Deutsche.
LinguistischeArbeiten 394.
Max Niemeyer Verlag,Tu?bingen.Oflazer, Kemal.
1994.
Two-level descriptionof Turkish morphology.
Literary andLinguistic Computing, 9(2).186Computational Linguistics Volume 28, Number 2Oflazer, Kemal.
1996.
Error-tolerantfinite-state recognition with applicationsto morphological analysis and spellingcorrection.
Computational Linguistics,22:73?89.Oflazer, Kemal, Elvan Go?c?men, and CemBozsahin.
1994.
An outline of Turkishmorphology.
Report to NATO ScienceDivision SfS III (TU-LANGUAGE),Brussels.Oflazer, Kemal, Bilge Say, Dilek ZeynepHakkani-Tu?r, and Go?khan Tu?r.
2001.Building a Turkish treebank.
In AnneAbeille, editor, Building and ExploitingSyntactically-Annotated Corpora.
Kluwer.Pareschi, Remo and Mark Steedman.
1987.A lazy way to chart-parse with CategorialGrammars.
In Proceedings of the 25thAnnual Meeting of the ACL, pages 81?88.Pereira, Fernando C. N. and Stuart M.Shieber.
1987.
Prolog and Natural-LanguageAnalysis.
CSLI, Stanford, CA.Pollard, Carl and Ivan A.
Sag.
1994.Head-Driven Phrase Structure Grammar.University of Chicago Press.Pulman, Stephen G. 1996.
Unificationencodings of grammatical notations.Computational Linguistics, 22:295?327.Pustejovsky, James.
1991.
The generativelexicon.
Computational Linguistics,17(4):409?441.Sehitoglu, Onur.
1996.
A sign-based phrasestructure grammar for Turkish.
Master?sthesis, Middle East Technical University.Sehitoglu, Onur and Cem Bozsahin.
1999.Lexical rules and lexical organization:Productivity in the lexicon.
In EvelyneViegas, editor, Breadth and Depth ofSemantic Lexicons.
Kluwer, pages 39?57.Steedman, Mark.
1985.
Dependency andcoo?rdination in the grammar of Dutchand English.
Language, 61(3):523?568.Steedman, Mark.
1987.
Combinatorygrammars and parasitic gaps.
NaturalLanguage and Linguistic Theory, 5:403?439.Steedman, Mark.
1988.
Combinators andgrammars.
In Richard T. Oehrle, EmmonBach, and Deirdre Wheeler, editors,Categorial Grammars and Natural LanguageStructures.
D. Reidel, Dordrecht, pages417?442.Steedman, Mark.
1991a.
Structure andintonation.
Language, 67:260?298.Steedman, Mark.
1991b.
Type raising anddirectionality in Combinatory Grammar.In Proceedings of the 29th Annual Meeting ofthe ACL, pages 71?78.Steedman, Mark.
1996.
Surface Structure andInterpretation.
MIT Press.Steedman, Mark.
2000a.
The SyntacticProcess.
MIT Press.Steedman, Mark.
2000b.
Informationstructure and the syntax-phonologyinterface.
Linguistic Inquiry, 31(4): 649?689.Szabolcsi, Anna.
1983.
ECP in categorialgrammar.
Unpublished manuscript,Max-Planck Institute.Szabolcsi, Anna.
1987.
Bound variables insyntax: Are there any?
In Proceedings of the6th Amsterdam Colloquium, pages 331?350.Tomita, Masaru.
1988.
The Generalized LRParser/Compiler.
Technical report, Centerfor Machine Translation, Carnegie MellonUniversity.Vijay-Shanker, K. and David J. Weir.
1993.Parsing some constrained grammarformalisms.
Computational Linguistics,19:591?636.Wechsler, Stephen and Larisa Zlatic?.
2000.
Atheory of agreement and its application toSerbo-Croatian.
Language, 76:799?832.Whitelock, Pete J.
1988.
A feature-basedcategorial morpho-syntax for Japanese.
InUwe Reyle and C. Rohrer, editors, NaturalLanguage Parsing and Linguistic Theories.
D.Reidel, pages 230?261.Williams, Edwin.
1981.
On the notions?lexically related?
and ?head of a word.
?Linguistic Inquiry, 12(2):245?274.Wittenburg, Kent.
1987.
Predictivecombinators.
In Proceedings of the 25thAnnual Meeting of the ACL, pages 73?79.
