Proceedings of the 4th International Workshop on Computational Terminology, pages 42?51,Dublin, Ireland, August 23 2014.Bilingual Termbank Creation via Log-Likelihood Comparison andPhrase-Based Statistical Machine TranslationRejwanul Haque, Sergio Penkale, Andy Way?Lingo24, Edinburgh, UK{rejwanul.haque, sergio.penkale}@lingo24.com?CNGL, Centre for Global Intelligent ContentSchool of Computing, Dublin City UniversityDublin 9, Irelandaway@computing.dcu.ieAbstractBilingual termbanks are important for many natural language processing (NLP) applications, es-pecially in translation workflows in industrial settings.
In this paper, we apply a log-likelihoodcomparison method to extract monolingual terminology from the source and target sides of aparallel corpus.
Then, using a Phrase-Based Statistical Machine Translation model, we create abilingual terminology with the extracted monolingual term lists.
We manually evaluate our novelterminology extraction model on English-to-Spanish and English-to-Hindi data sets, and observeexcellent performance for all domains.
Furthermore, we report the performance of our monolin-gual terminology extraction model comparing with a number of the state-of-the-art terminologyextraction models on the English-to-Hindi datasets.1 IntroductionTerminology plays an important role in various NLP tasks including Machine Translation (MT) andInformation Retrieval.
It is also exploited in human translation workflows, where it plays a key rolein ensuring translation consistency and reducing ambiguity across large translation projects involvingmultiple files and translators over a long period of time.
The creation of monolingual and bilingualterminological resources using human experts are, however, expensive and time-consuming tasks.
Incontrast, automatic terminology extraction is much faster and less expensive, but cannot be guaranteedto be error-free.
Accordingly, in real NLP applications, a manual inspection is required to amend ordiscard anomalous items from an automatically extracted terminology list.The automatic terminology extraction task starts with selecting candidate terms from the input domaincorpus, usually in two different ways: (i) linguistic processors are used to identify noun phrases that areregarded as candidate terms (Kupiec, 1993; Frantzi et al., 2000), and (ii) non-linguistic n-gram wordsequences are regarded as candidate terms (Deane, 2005).Various statistical measures have been used to rank candidate terms, such as C-Value (Ananiadou etal., 1994), NC-Value (Frantzi et al., 2000), log-likelihood comparison (Rayson and Garside, 2000), andTF-IDF (Basili et al., 2001).
In this paper, we present our bilingual terminology extraction model, whichis composed of two consecutive and independent processes:1.
A log-likelihood comparison method is employed to rank candidate terms (n-gram word sequences)independently from the source and target sides of a parallel corpus,2.
The extracted source terms are aligned to one or more extracted target terms using a Phrase-BasedStatistical Machine Translation (PB-SMT) model (Koehn et al., 2003).We then evaluate our novel bilingual terminology extraction model on various domain corpora consid-ering English-to-Spanish and low-resourced and less-explored English-to-Hindi language-pairs and seeexcellent performance for all data sets.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/42The remainder of the paper is organized as follows.
In Section 2, we discuss related work.
In Section3, we describe our two-stage terminology extraction model.
Section 4 presents the results and analysesof our experiments, while Section 5 concludes, and provides avenues for further work.2 Related WorkSeveral algorithms have been proposed to extract terminology from a domain-specific corpus, which canbe divided into three broad categories: linguistic, statistical and hybrid.
Statistical or hybrid approachesdominate this field, with some of the leading work including the use of frequency-based filtering (Dailleet al., 1994), NC-Value (Frantzi et al., 2000), log-likelihood and mutual information (Rayson and Gar-side, 2000; Pantel and Lin, 2001), TF-IDF (Basili et al., 2001; Kim et al., 2009), weirdness algorithm(Ahmad et al., 1999), Glossex (Kozakov et al., 2004) and Termex (Sclano and Velardi, 2007).In this work, we focus on extracting bilingual terminology from a parallel corpus.
He et al.
(2006)demonstrate that using log-likelihood for term discovery performs better than TF-IDF.
Accordingly, sim-ilarly to Rayson and Garside (2000) and Gelbukh et al.
(2010), we extract terms independently from bothsides of a parallel corpus using log-likelihood comparisons with a generic reference corpus.
Some of themost influential research on bilingual terminology extraction includes Kupiec (1993), Gaussier (1998),Ha et al.
(2008) and Lefever et al.
(2009).
Lefever et al.
(2009) proposed a sub-sentential alignment-based terminology extraction module that links linguistically motivated phrases in parallel texts.
Unlikeour approach, theirs relies on linguistic analysis tools such as PoS taggers or lemmatizers, which mightbe unavailable for under-resourced languages (e.g., Hindi).
Gaussier (1998) and Ha et al.
(2008) appliedstatistical approaches to acquire parallel term-pairs directly from a sentence-aligned corpus, with the lat-ter focusing on improving monolingual term extraction, rather than on obtaining a bilingual term list.
Incontrast, we build a PB-SMT model (Koehn et al., 2003) from the input parallel corpus, which we useto align a source term to one or more target terms.
While Rayson and Garside (2000) and Gelbukh et al.
(2010) only allowed the extraction of single-word terms, we focus on extraction of up to 3-gram terms.3 MethodologyIn this section, we describe our two-stage bilingual terminology extraction model.
In the first stage, weextract monolingual terms independently from either side of a sentence-aligned domain-specific parallelcorpus.
In the second stage, the extracted source terms are aligned to one or more extracted target termsusing a PB-SMT model.3.1 Monolingual Terminology ExtractionThe monolingual term extraction task involves the identification of terms from a list of candidate termsformed from all n-gram word sequences from the monolingual domain corpus (i.e.
in our case, each sideof the domain parallel corpus, cf.
Section 4.1).
On both source and target sides, we used lists of language-specific stop-words and punctuation marks in order to filter out anomalous items from the candidatetermlists.
In order to rank the candidate terms in those lists, we used a log-likelihood comparison methodthat compares the frequencies of each candidate term in both the domain corpus and the large generalcorpus used as a reference.1The log-likelihood (LL) value of a candidate term (Cn) is calculated using equation (1) from Gelbukhet al.
(2010).LL = 2 ?
((Fd?
log(Fd/Ed)) + (Fg?
log(Fg/Eg))) (1)where Fdand Fgare the frequencies of Cnin the domain corpus and the generic reference corpus,respectively.
Edand Egare the expected frequencies of Cn, which are calculated using (2) and (3).Ed= Nnd?
(Fd+ Fg)/(Nnd+ Nng) (2)Eg= Nng?
(Fd+ Fg)/(Nnd+ Nng) (3)1Before the term-extraction process begins, we apply a number of preprocessing methods including tokenisation to the inputdomain corpus and the generic reference corpus.43where Nndand Nngare the numbers of n-grams in the domain corpus and reference corpus, respectively.Thus, each candidate term is associated with a weight (LL value) which is used to sort the candidateterms: those candidates with the highest weights have the most significant differences in frequency in thetwo corpora.
However, we are interested in those candidate terms that are likely to be terms in the domaincorpus.
Gelbukh et al.
(2010) used the condition in (4) in order to filter out those candidate terms whoserelative frequencies are bigger in the domain corpus than in the reference corpus, and we do likewise.Fd/Nnd> Fg/Nng(4)In contrast with Gelbukh et al.
(2010), we extract multi-word terms up to 3-grams, whereas they focusedsolely on extracting single word terms.3.2 Creating a Bilingual TermbankWe obtained source and target termlists from the bilingual domain corpus using the approach describedin Section 3.1.
We use a PB-SMT model (Koehn et al., 2003) to create a bilingual termbank from theextracted source and target termlists.This section provides a mathematical derivation of the PB-SMT model to show how we scored can-didate term-pairs using the PB-SMT model.
We built a source-to-target PB-SMT model from the bilin-gual domain corpus using the Moses toolkit (Koehn et al., 2007).
In PB-SMT, the posterior probabilityP(eI1|fJ1) is directly modelled as a (log-linear) combination of features (Och and Ney, 2002), that usuallycomprise M translational features, and the language model, as in (5):log P(eI1|fJ1) =M?m=1?mhm(fJ1, eI1, sK1) + ?LMlog P(eI1) (5)where eI1= e1, ..., eIis the probable candidate translation for the given input sentence fJ1= f1, ..., fJand sK1= s1, ..., skdenotes a segmentation of the source and target sentences respectively into the se-quences of phrases (?f1, ...,?fk) and (e?1, ..., e?k) such that (we set i0:= 0):?k ?
[1,K] sk:= (ik; bk, jk), (bkcorresponds to starting index of fk)e?k:= e?ik?1+1, ..., e?ik,?fk:=?fbk, ...,?fjkEach feature hmin (5) can be rewritten as in (6):hm(fJ1, eI1, sK1) =K?k=1?hm(?fk, e?k, sk) (6)Therefore, the translational features in (5) can be rewritten as in (7):M?m=1?mhm(fJ1, eI1, sK1) =M?m=1?mK?k=1?hm(?fk, e?k, sk) (7)In equation (7),?hmis a feature defined on phrase-pairs (?fk, e?k), and ?mis the feature weight of?hm.These weights (?m) are optimized using minimum error-rate training (MERT) (Och, 2003) on a held-out500 sentence-pair development set for each of the experiments.We create a list of probable source?target term-pairs by taking each source and target term from thesource and target termlists, respectively, provided that those source?target term-pairs are present in thePB-SMT phrase-table.
We calculate a weight (w) for each source?target term-pair (essentially, a phrase-pair, i.e.
(e?k,?fk)) using (8):2w(e?k,?fk) =M?m=1?m?hm(?fk, e?k) (8)2Equation (8) is derived from the right-hand side of equation (7) for a single source?target phrase-pair.44In order to calculate w, we used the four standard PB-SMT translational features (?hm), namely forwardphrase translation log-probability (log P(e?k|?fk)), its inverse (log P(?fk|e?k)), the lexical log-probability(log Plex(e?k|?fk)), and its inverse (log Plex(?fk|e?k)).
We considered a higher threshold value for weightsand considered those term-pairs whose weights exceeded this threshold.
For each source term, we con-sidered a maximum of the four highest-weighted target terms.Domain Parallel CorpusDomain Sentences Words (English)English-to-SpanishBanking, Finance and Economics 50,112 548,594Engineering 91,896 1,165,384IT 33,148 367,046Tourism and Travel 50,042 723,088Science 79,858 1,910,482Arts and Culture 9,124 100,620English-to-HindiEILMT 7,096 173,770EMILLE 9,907 159,024Launchpad 67,663 380,546KDE4 84,089 324,289Reference CorpusLanguage Sentences WordsEnglish 4,000,000 82,048,154Spanish 4,132,386 128,005,190Hindi 10,000,000 182,066,982Table 1: Corpus Statistics.4 Experiments and Discussion4.1 Data UsedWe conducted experiments on several data domains for two different language-pairs, English-to-Spanishand English-to-Hindi.
For English-to-Spanish, we worked with client-provided data taken from six dif-ferent domains in the form of translation memories.
For English-to-Hindi, we used three parallel corporafrom three different sources (EILMT, EMILLE and Launchpad) taken from HindEnCorp3(Bojar et al.,2014) released for the WMT14 shared translation task,4and a parallel corpus of KDE4 localization files5(Tiedemann, 2009).
The EMILLE corpus contains leaflets from the UK Government and various localauthorities.
The domain of the EILMT6corpus is tourism.We used data from a collection of translated documents from the United Nations (MultiUN)7(Tiede-mann, 2009) and the European Parliament (Koehn et al., 2005) as the monolingual English and Spanishreference corpora.
We used the HindEnCorp monolingual corpus (Bojar et al., 2014) as the monolingualHindi reference corpus.
The statistics of the data used in our experiments are shown in Table 1.4.2 Runtime PerformanceOur terminology extraction model is composed of two main processes: (i) Moses training and tuning(restricting the number of iterations of MERT to a maximum of 6), and (ii) terminology extraction.
InTable 2, we report the actual runtimes of these two processes on the six domain corpora.
As Table3http://ufallab.ms.mff.cuni.cz/ bojar/hindencorp/4http://www.statmt.org/wmt14/5http://opus.lingfil.uu.se/KDE4.php6English-to-Indian Language Machine Translation (EILMT) is a Ministry of IT, Govt.
of India sponsored project.7http://opus.lingfil.uu.se/MultiUN.php452 demonstrates, both MT system-building (training and tuning combined) and terminology extractionprocesses are very short on each corpus.
Given the crucial influence of bilingual terminology on qualityin translation workflows, we believe that the creation of such assets from scratch in less than 30 minutesmay prove to be a significant breakthrough for translators.MT System TerminologyBuilding ExtractionEnglish-to-SpanishBanking, Finance and Economics 05:49 04:23Engineering 06:47 04:33IT 04:10 04:31Tourism and Travel 05:34 04:24Science 15:26 04:52Arts and Culture 03:20 04:16English-to-HindiEILMT 12:41 15:47EMILLE 05:41 17.18Launchpad 04:37 24.11KDE4 04:05 16:50Table 2: Runtimes (minutes:seconds) for MT system-building and bilingual terminology extraction onthe different domain data sets.4.3 Human EvaluationOf course, it is one thing to rapidly create translation assets such as bilingual termbanks, and another en-tirely to ensure the quality of such resources.
Accordingly, we evaluated the performance of our bilingualterminology extraction model on each English-to-Spanish and English-to-Hindi domain corpus reportedin Table 1, with the evaluation goals being twofold: (i) measuring the accuracy of the monolingual ter-minology extraction process, and (ii) measuring the accuracy of our novel bilingual terminology creationmodel.As mentioned in Section 3.2, a source term may be aligned with up to four target terms.
For evaluationpurposes, we considered the top-100 source terms based on the LL values (cf.
(1)) and their target coun-terparts (i.e.
one to four target terms).
The quality of the extracted terms was judged by native Spanishand Hindi speakers, both with excellent English skills, and the evaluation results are reported in Table3.
Note that we were not able to measure recall of the term extraction model on the domain corpora dueto the unavailability of a reference terminology set.
The evaluator counted the number of valid terms inthe source term list for the domain in question, and the percentage of valid terms with respect to the totalnumber of terms (i.e.
100) is reported in the second column in Table 3.
We refer to this as VST (ValidSource Terms).
For each valid source term there are one to four target terms that are ranked according tothe weights in (8).
In theory, therefore, the top-ranked target term is the most suitable target translation ofthe aligned source term.
The evaluator counted the number of instances where the top-ranked target termwas a suitable target translation of the source term; the percentage with respect to the number of validsource terms is shown in the third column in Table 3, and denoted as VTT (Valid Target Terms).
Theevaluator also reported the number of cases where any of the four target terms was a suitable translationof the source term; the percentage with respect to the number of valid source terms is given in the fourthcolumn in Table 3.
Furthermore, the evaluator counted the number of instances where any of the fourtarget terms with minor editing can be regarded as suitable target translation; the percentage with respectto the number of valid source terms is reported in the last column of Table 3.
In Table 4, we show threeEnglish?Spanish term-pairs extracted by our automatic term extractor where the target terms (Spanish)are slightly incorrect.
In all these examples the edit distance between the correct term and the one pro-posed by our automatic extraction method is quite low, meaning that just a few keystrokes can transform46the candidate term into the correct one.
In these cases editing the candidate term is much cheaper (interms of time) than creating the translations from scratch.VST VTT1 VTT4 VTTME4(%) (%) (%) (%)English-to-SpanishBanking, Finance and Economics 76 92.1 93.4 94.7Engineering 84 90.5 91.7 94.1IT 89 90.0 97.8 97.8Tourism and Travel 72 86.1 93.1 93.1Science 94 93.6 93.6 93.6Arts and Culture 89 91.9 96.5 96.5English-to-HindiEILMT 91 81.3 83.5 96.7EMILLE 79 62.1 83.5 98.7Launchpad 88 95.4 98.8 98.8KDE4 79 88.6 89.8 94.9Table 3: Manual evaluation results obtained on the top-100 term pairs.
VST: Valid Source Terms, VTT1:Valid Target Terms (1-best), VTT4: Valid Target Terms (4-best), VTTME4: Valid Target Terms withMinor Editing (4-best).Source Terms Target Terms Target Terms Edit(using Bilingual Term Extractor) corrected with Minor Editing DistanceShutter Obturaci?on Obturador 5comment: wrong choice of inflection is likely caused by the term being most frequently used as?shutter speed?Lenses Objetivos EF Objetivos 3comment: The qualifier ?EF?
should not be present in the target, as it is not in the sourceLeave Cancel Cancelaci?on Vacaciones Cancelaci?on de Vacaciones 3comment: The preposition ?de?
is missing in the target termTable 4: Slightly wrong target terms corrected with minor editing.In Table 3, we see that the accuracy of the monolingual term extraction model varies from 72% to 94%for both English-to-Spanish and English-to-Hindi.
For English-to-Spanish, the accuracy of our bilingualterminology creation model ranges from 86.1% to 93.6%, 91.7% to 97.8% and 93.1% to 97.8% whenthe 1-best, 4-best and 4-best with slightly edited target terms are considered, respectively.
For English-to-Hindi, the accuracy of our bilingual terminology creation model ranges from 62.1% to 95.4%, 83.5%to 98.8% and 94.9% to 98.8% when the 1-best, 4-best and 4-best with slightly edited target terms areconsidered, respectively.We are greatly encouraged by these results, as they demonstrate that our novel bilingual termbankcreation method is robust in the face of the somewhat noisy monolingual term-extraction results; as aconsequence, if better methods for suggesting monolingual term candidates are proposed, we expect theperformance of our bilingual term-creation model to improve accordingly.We calculated the distributions of unigram, bigram and trigram in the valid source terms (cf.
Table 3)and reported in Table 5.
We also calculated the percentages of their distributions in the valid source termsaveraged over all 10 data sets.
As can be seen from Table 3, the percentage of the average distribution ofthe trigram terms is quite low (i.e.
2.5%).
This result justifies our decision for extraction of up to 3-gramterms.47Unigram Bigram TrigramEnglish-to-SpanishBanking, Finance and Economics 55 20 1Engineering 64 18 2IT 75 12 2Tourism and Travel 49 18 5Science 91 3 0Arts and Culture 76 10 3English-to-HindiEILMT 73 17 1EMILLE 35 37 7Launchpad 85 3 0KDE4 74 5 0Average 80.4% 17.0 % 2.5%Table 5: Distributions of unigram, bigram and trigram in the valid source term pairs (cf.
second columnin Table 3).4.4 Comparison: Monolingual Terminology ExtractionIn this section we report the performance of our monolingual terminology extraction model (cf.
Section3.1) comparing with the performance of several state-of-the-art terminology extraction algorithms capa-ble of recognising multiword terms.
In order to extract monolingual multiword terms we used the JATEtoolkit8(Zhang et al., 2008).
This toolkit first extracts candidate terms from a corpus using linguistictools and then applies term extraction algorithms to recognise terms specific to the domain corpus.
TheJATE toolkit is currently available only for the English language.
For evaluation purposes, we consideredthe source-side of the English-to-Hindi domain corpora.Algorithm Reference EILMT EMILLE Launchpad KDE4LLC (Bilingual) cf.
VST in Table 3 91 79 88 79LLC 77 53 80 71STF 46 04 54 44ACTF 42 15 62 48TF-IDF 50 36 45 17Glossex Kozakov et al.
(2004) 76 43 76 71JK Justeson & Katz (1995) 42 13 58 42NC-Value Frantzi et al.
(2000) 46 34 52 25RIDF Church & Gale (1995) 27 16 23 21TermEx Sclano et al.
(2007) 42 08 46 41C-Value Ananiadou (1994) 49 44 62 40Weirdness Ahmed et al.
(1999) 77 57 82 63Table 6: Monolingual evaluation results.
LLC: Log-Likelihood Comparison, STF: Simple Term Fre-quency, ACTF: Average Corpus Term Frequency, JK: Justeson KatzFor comparison, we considered the top-100 source terms based on the log-likelihood values (cf.
(1)).The automatic term extraction algorithms in JATE assign weights (domain representativeness) to thecandidate terms giving an indication of the likelihood of being a good domain-specific term.
The qualityof the extracted terms (top-100 highest weighted) was judged by an evaluator with excellent Englishskills, and the evaluation results are reported in Table 6.
The evaluator counted the number of valid terms8https://code.google.com/p/jatetoolkit/48in the highest weighted 100 terms that were extracted using different state-of-the-art term extractionalgorithms.The third row of Table 6 represents the percentage of the valid source terms extracted by our log-likelihood comparison (LLC) based monolingual term extraction algorithm.
The next three rows rep-resent three basic monolingual term extraction algorithms (STF: simple term frequency, ACTF: aver-age corpus term frequency and TF-IDF) available in the JATE toolkit.
The last seven rows representseven state-of-the-art terminology extraction algorithms.
As can be seen from Table 6, LLC is the best-performing algorithm with the Weirdness (Ahmad et al., 1999) and the Glossex (Kozakov et al., 2004)algorithms on the EILMT and the KDE4 corpora, respectively.
The LLC is also the second-best per-forming algorithm on the EMILLE and the Lauchpad corpora.We see in Table 6 that the percentage of valid source terms is quite low on the EMILLE corpus.This might be caused by it containing information leaflets in a variety of domains (consumer, education,housing, health, legal, social), which might bring down the percentage of valid source terms on thiscorpus.Note that the percentage of valid source terms (VST) reported in Table 3 is calculated taking thetop-100 source terms from the bilingual term-pair list that were extracted using the method described inSection 3.2.
For comparison purposes we again report this percentage (VST in Table 3) in the second rowin Table 6.
Our bilingual term extraction method discards any anomalous pairs from the initial candidateterm-pair list (cf.
Section 3.2).
This essentially removes some of the source entries that are not pertinentto the domain.
As a result, the percentage of the valid source terms extracted applying our bilingualterminology extraction method (Table 3) is higher than the percentage of the valid source terms extractedapplying our monolingual terminology extraction algorithm (LLC) (Table 6).
We clearly see from Tables3 and 6 that this bilingual approach to term extraction not only achieves remarkable performance on thebilingual task, but that when used in a monolingual context it outperforms most state-of-the-art extractionalgorithms, and is comparable with the best ones.
We should also note that JATE?s implementation ofthese algorithms (including Weirdness) uses language-dependent modules such as a lemmatizer, unlikeour implementation of LLC which is language-independent.5 Conclusions and Future WorkIn this paper we presented a bilingual multi-word terminology extraction model based on two inde-pendent consecutive processes.
Firstly, we employed a log-likelihood comparison method to extractsource and target terms independently from both sides of a parallel domain corpus.
Secondly, we useda PB-SMT model to align source terms to one or more target terms.
The manual evaluation resultson ten different domain corpora of two syntactically divergent language-pairs showed the accuracy ofour bilingual terminology extraction model to be very high, especially in the light of the rather noisiermonolingual candidate terms presented to it.
Given the reported high levels of performance ?
minimumlevels of 93.1% and 94.9% in the 4-best set-up across all six domains for English-to-Spanish and all fourdomains for English-to-Hindi, respectively ?
we are convinced that the extracted bilingual multiwordtermbanks are useful ?as is?, and with a small amount of post-processing from domain experts would becompletely error-free.The proposed bilingual terminology extraction model has been tested on a highly investigatedlanguage-pair, English-to-Spanish, and a less-explored and low-resourced English-to-Indic language-pair, English-to-Hindi.
Interestingly, the performance of the bilingual terminology extraction modelis excellent for the both language-pairs.
We also tested several state-of-the-art monolingual terminol-ogy extraction algorithms including our own (log-likelihood comparison) on the source-side of the fourEnglish-to-Hindi domain data sets.
According to the manual evaluation results, our monolingual multi-word term extraction model proves to be the best-performing algorithm on two domain data sets and thesecond best-performing algorithm on the remaining two domain data sets.
Our monolingual multiwordterminology extraction method is clearly comparable to the state-of-the-art monolingual terminologyextraction algorithms.In this work, we considered all n-gram word sequences from the domain corpus as candidate terms.49In future work, we would like to incorporate the candidate phrasal term identification model of Deane(2005), which would omit irrelevant multiword units, and help us extend our evaluation beyond the top-100 terms.
We also plan to demonstrate the impact of the created termbanks on translator productivity ina number of workflows ?
different language pairs, domains, and levels of post-editing ?
in an industrialsetting.AcknowledgementsThis work was partially supported by the Science Foundation Ireland (Grant 07/CE/I1142) as part ofCNGL at Dublin City University, and by Grant 610879 for the Falcon project funded by the EuropeanCommission.ReferencesS.
Ananiadou.
1994.
A methodology for automatic term recognition.
In COLING: 15th International Conferenceon Computational Linguistics, pages 1034?1038.K.
Ahmad, L. Gillam and L. Tostevin.
1999.
University of Surrey Participation in TREC8: Weirdness Indexing forLogical Document Extrapolation and Retrieval (WILDER).
In the Eighth Text REtrieval Conference (TREC-8).National Institute of Standards and Technology, Gaithersburg, MD., pp.717?724.R.
Basili, A. Moschitti, M. Pazienza and F. Zanzotto.
2001.
A contrastive approach to term extraction.
In Pro-ceedings of the 4th Conference on Terminology and Artificial Intelligence (TIA 2001).
Nancy, France, 10pp.K.
Church and W. Gale.
1995.
Inverse Document Frequency (IDF): A Measure of Deviation from Poisson.
InProceedings of the 3rd Workshop on Very Large Corpora, pages 121?130.
Cambridge, MA.B.
Daille, E. Gaussier and J-M. Lang?e.
1994.
Towards automatic extraction of monolingual and bilingual termi-nology.
In COLING 94, The 15th International Conference on Computational Linguistics, Proceedings.
Kyoto,Japan, pp.515?521.P.
Deane.
2007.
A nonparametric method for extraction of candidate phrasal terms.
In ACL-05: 43rd AnnualMeeting of the Association for Computational Linguistics.
Ann Arbor, Michigan, USA, pp.605?613.K.
Frantzi, S. Ananiadou and H. Mima.
2000.
Automatic Recognition of Multi-word Terms: the C-value/NC-valueMethod.
International Journal of Digital Libraries.
3(2): 115?130.E.
Gaussier.
1998.
Flow Network Models for Word Alignment and Terminology Extraction from Bilingual Cor-pora.
In COLING-ACL ?98, 36th Annual Meeting of the Association for Computational Linguistics and 17thInternational Conference on Computational Linguistics, Proceedings of the Conference, Volume II.
Montreal,Quebec, Canada, pp.444?450.A.
Gelbukh, G. Sidorov, E. Lavin-Villa and L. Chanona-Hernandez.
2010.
Automatic Term Extraction UsingLog-Likelihood Based Comparison with General Reference Corpus.
In 15th International Conference on Ap-plications of Natural Language to Information Systems, NLDB 2010, Proceedings.
LNCS vol.
6177.
Berlin:Springer.
pp.248?255.L.
Ha, G. Fernandez, R. Mitkov and G. Corpas.
2008.
Mutual bilingual terminology extraction.
In LREC 2008:6th Language Resources and Evaluation Conference.
Marrakech, Morocco, pp.1818?1824.T.
He, T., X. Zhang and Y. Xinghuo.
2006.
An Approach to Automatically Constructing Domain Ontology.
InProceedings of the 20th Pacific Asia Conference on Language, Information and Computation, PACLIC 2006.Wuhan, China, pp.150?157.J.
S. Justeson, and S. M. Katz.
1995.
Technical terminology: some linguistic properties and an algorithm foridentification in text.
Natural language engineering, 1(1) 9?27.S.
Kim, T. Baldwin and M-Y.
Kan. 2009.
An Unsupervised Approach to Domain-Specific Term Extraction.
InProceedings of the Australasian Language Technology Association Workshop 2009.
Sydney, Australia, pp.94?98.P.
Koehn.
2005.
Europarl: a parallel corpus for statistical machine translation.
In MT Summit X: The TenthMachine Translation Summit.
Phuket, Thailand, pp.79?86.50P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,R.
Zens, C. Dyer, O. Bojar, A. Constantin and E. Herbst.
2007.
Moses: Open Source Toolkit for StatisticalMachine Translation.
In ACL 2007, Proceedings of the Interactive Poster and Demonstration Sessions.
Prague,Czech Republic, pp.177?180.P.
Koehn, F. Och and H. Ney.
2003.
Statistical Phrase-Based Translation.
In HLT-NAACL 2003: conferencecombining Human Language Technology conference series and the North American Chapter of the Associationfor Computational Linguistics conference series.
Edmonton, Canada, pp.
48?54.L.
Kozakov, Y.
Park, T. H. Fin, Y. Drissi, Y. N. Doganata, and T. Cofino.
2004.
Glossary extraction and knowledgein large organisations via semantic web technologies.
In Proceedings of the 6th International Semantic WebConference and the 2nd Asian Semantic Web Conference.J.
Kupiec.
1993.
An algorithm for finding noun phrase correspondences in bilingual corpora.
In 31st AnnualMeeting of the Association for Computational Linguistics, Proceedings of the Conference.
Columbus, Ohio,USA, pp.17?22.E.
Lefever, L. Macken and V. Hoste.
2009.
Language-Independent Bilingual Terminology Extraction from aMultilingual Parallel Corpus.
In EACL ?09 Proceedings of the 12th Conference of the European Chapter of theAssociation for Computational Linguistics.
Athens, Greece, pp.496?504.F.
Och.
2003.
Minimum Error Rate Training in Statistical Machine Translation.
In 41st Annual Meeting of theAssociation for Computational Linguistics, Proceedings of the Conference.
Sapporo, Japan, pp.160?167.F.
Och and H. Ney.
2002.
Discriminative Training and Maximum Entropy Models for Statistical Machine Transla-tion.
In 40th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference.Philadelphia, PA, USA, pp.295?302.O.
Bojar, V. Diatka, P. Rychl?y, P. Stra?n?ak, A. Tamchyna, and D. Zeman.
2014.
Hindi-English and Hindi-onlyCorpus for Machine Translation.
In Proceedings of the Ninth International Language Resources and EvaluationConference (LREC?14).
Reykjavik, Iceland.P.
Pantel and D. Lin.
2001.
A Statistical Corpus-Based Term Extractor.
In E. Stroulia and S. Matwin (eds.
)Advances in Artificial Intelligence, 14th Biennial Conference of the Canadian Society for Computational Studiesof Intelligence, AI 2001, Ottawa, Canada, Proceedings.
LNCS vol.
2056.
Berlin: Springer, pp.36?46.P.
Rayson and R. Garside.
2000.
Comparing corpora using frequency profiling.
In Proceedings of the Workshopon Comparing Corpora, held in conjunction with the 38th Annual Meeting of the Association for ComputationalLinguistics (ACL 2000).
Hong Kong, pp.1?6.F.
Sclano and P. Velardi.
2007.
TermExtractor: a web application to learn the shared terminology of emergent webcommunities.
In Proceedings of the 3rd International Conference on Interoperability for Enterprise Softwareand Applications (I-ESA 2007).
Funchal, Madeira Island, Portugal, pp.287?290.J.
Tiedemann.
2009.
News from OPUS - A Collection of Multilingual Parallel Corpora with Tools and Interfaces.In N. Nicolov and K. Bontcheva and G. Angelova and R. Mitkov (eds.)
Recent Advances in Natural LanguageProcessing (vol V), pages 237?248, John Benjamins, Amsterdam/Philadelphia.Z.
Zhang, J. Iria, C. Brewster and F. Ciravegna.
2008.
A Comparative Evaluation of Term Recognition Algorithms.In Proceedings of The sixth international conference on Language Resources and Evaluation, (LREC 2008),pages 2108?2113, Marrakech, Morocco.51
