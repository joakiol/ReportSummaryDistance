General ized Augmented  Transi t ion Network  GrammarsFor Generat ion From Semant ic  Networks  1Stuar t  C. Shap i roDepartment of Computer ScienceState University of New York at BuffaloAmherst,  New York 14226The augmented transition network (ATN) is a formalism for writing parsing grammarsthat has been much used in Artificial Intelligence and Computational Linguistics.
A fewresearchers have also used ATNs for writing grammars for generating sentences.
Previous-ly, however, either generation ATNs did not have the same semantics as parsing ATNs, orthey required an auxiliary mechanism to determine the syntactic structure of the sentenceto be generated.
This paper reports a generalization of the ATN formalism that allowsATN grammars to be written to parse labelled directed graphs.
Specifically, an ATNgrammar can be written to parse a semantic network and generate a surface string as itsanalysis.
An example is given of a combined parsing-generating rammar that parsessurface sentences, builds and queries a semantic network knowledge representation, andgenerates urface sentences in response.1.
IntroductionAugmented transition network (ATN) grammarshave, since their development by Woods 1970,1973,become the most used method of describing grammarsfor natural language understanding and question an-swering systems.
The advantages of the ATN notationhave been summarized as "1) perspicuity, 2) genera-tive power, 3) eff iciency of representation, 4) theability to capture linguistic regularities and generali-ties, and 5) efficiency of operat ion" \[Bates 1978, p.191\].The usual method of utilizing an ATN grammar ina natural language system is to provide an interpreterthat can take any ATN grammar, a lexicon, and asentence-as data, and produce either a parse of a sen-tence or a message that the sentence does not conformto the grammar.
The input sentence is assumed to bea linear sequence of symbols, while the parse is usuallya tree (often represented by a LISP S-expression) orsome "knowledge representation" such as a semanticnetwork.
Compilers have been written \[Burton 1976;Burton and Woods 1976\] that take an ATN grammar1 This paper is a revised and expanded version of one givenat the 17th Annual Meeting of the Association for ComputationalLinguistics.
The work reported here was supported in part by theNational Science Foundation under Grants MCS78-02274 andMCS80-06314.as input and produce a specialized parser for thatgrammar, but in this paper we assume that an inter-preter is being used.Several methods have been described for usingATN grammars for sentence generation.
One method\[Bates 1978, p. 235\] is to replace the usual interpreterby a generation interpreter that can take an ATNgrammar written for parsing and use it to producerandom sentences conforming to the grammar.
This isuseful for testing and debugging the grammar.Simmons 1973 uses a standard ATN interpreter togenerate sentences from a semantic network.
In thismethod, an ATN register is initialized to hold a nodeof the semantic network and the input to the grammaris a linear string of symbols providing a pattern of thesentence to be generated.
For example, the inputstring might be (CA1-LOCUS VACT THEME) ,where CA1-LOCUS and THEME are labels of arcsemanating from the semantic node, and VACT standsfor "act ive verb."
This pattern means that the sen-tence to be generated is to begin with a string denot-ing the CA1-LOCUS,  then have the active form of theverb, and end with a string denoting the THEME.The method also assumes that semantic nodes havesuch syntactic information stored with them as numberand definiteness of nominals, and tense, aspect, mood,and voice of propositions.Copyright 1982 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or  specific permission.0362-613X/82/010012-14501.0012 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Stuart C. Shapiro Generalized Augmented Transition Network GrammarsShapiro 1979 also generates entences from a se-mantic network.
In this method, input to the grammaris the semantic network itself (starting at some node).That is, instead of successive symbols of a linear sen-tence pattern being scanned as the ATN grammar istraversed by the interpreter, different nodes of thesemantic network are scanned.
The grammar controlsthe syntax of the generated sentence, but bases specif-ic decisions on the structural properties of the seman-tic network and on the information contained therein.The original goal in Shapiro 1975 was that a singleATN interpreter could be used both for standard ATNparsing and for generation.
However, a special inter-preter was written for generation grammars; indeed,the semantics of the ATN formalism given in thatpaper, though based on the standard ATN formalism,were inconsistent enough with the standard notationthat a single interpreter could not be used.
For exam-ple, standard ATNs use a register named "*"  to holdthe input symbol (word) currently being scanned.
Un-like other registers, whose values are set explicitly byactions on the ATN arcs, the * register is manipulateddirectly by the ATN interpreter.
In Shapiro 1975 the *register was used to hold the string being generatedrather than the input symbol being scanned.
The in-terpreter written for Shapiro 1975 also manipulatedthe * register directly, but in a manner inconsistentwith standard ATN interpreters.This paper reports the results of work carried outto remove the inconsistencies mentioned above.
Ageneralization of the ATN formalism has now beenderived that supplies consistent semantics (and soallows a single interpreter to be used) for both parsingand generating rammars.
In fact, one grammar caninclude both parsing and generating sub-networks thatcan call each other.
For example, an ATN grammarcan be constructed so that the "parse"  of a naturallanguage question is the natural language statementthat answers it, interaction with representat ion andinference routines being done on arcs along the way.The new formalism is a strict generalization in thesense that it interprets all old ATN grammars as hav-ing the same semantics (carrying out the same actionsand producing the same parses) as before.The generalized ATN formalism can be used towrite grammars for parsing labelled directed graphs.In this paper, however, we only discuss its use in pars-ing two particular kinds of labelled di-graphs.
One isthe kind that is generally called a semantic network.We consider parsing a semantic network, as viewedfrom some node, into a particular linear symbol struc-ture that constitutes a surface string of English.
Theother kind of labelled di-graph is a linear graph all ofwhose arcs have the same label and whose nodes aresuccessive words in a surface sentence.
This kind ofdi-graph is so special that a subset of the generalizedATN formalism, namely the original formalism, hasbuilt-in facilities for traversing its arcs.Since many people have implemented their ownATN interpreters, this paper is written to describe theextension to be made to any ATN interpreter to allowit to interpret generation grammars as well as parsinggrammars.
A key ingredient in such an extension is asystematic treatment of the input buffer and the *register.
This is explained in Section 4, which is essen-tially a description of a set of program assertions forATN interpreters.2.
Generat ion  f rom a Semant ic  Network  - Br ief  Over-v iewIn our view, each node of a semantic network rep-resents a concept.
The goal of the generator is, givena node, to express the concept represented by thatnode in a natural language surface string.
The syntac-tic category of the surface string is determined by thegrammar, which can analyze the structure of the se-mantic network connected to the node.
In order toexpress the concept, it is often necessary to include inthe string substrings that express the concepts repre-sented by adjacent nodes.
For example, if a noderepresents a proposit ion to be expressed as a state-ment, part of the statement may be a noun phraseexpressing the concept represented by the node con-nected to the original node by an AGENT case arc.This can be done by a recursive call to a section of thegrammar in charge of building noun phrases.
Thissection will be passed the adjacent node.
When itfinishes, the original statement section of the grammarwill continue adding additional substrings to the grow-ing statement.In ATN grammars written for parsing, a recursivepush does not change the input symbol being exam-ined, but when the original level continues, parsingnormally continues at a different symbol.
In the gen-eration approach we use, a recursive push normallyinvolves a change in the semantic node being exam-ined, and the original level continues with the originalnode.
This difference is a major motivation of someof the generalizations to the ATN formalism discussedbelow.
The other major motivation is that, in parsinga string of symbols, the "next"  symbol is defined bythe system, but in "parsing" a network, "next"  mustbe specified in the grammar.3.
The  Genera l i zat ionThe following sub-sections how the generalizedsyntax of the ATN formalism, and assume a knowl-edge of the standard formalism (Bates 1978 is an ex-cellent introduction).
Syntactic structures alreadyfamiliar to ATN users but not discussed here remainunchanged.
Parentheses and terms in upper case let-ters are terminal symbols.
Lower case terms in angleAmerican Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 13Stuart  C. Shapiro Generalized Augmented Transition Network Grammarsbrackets are non-terminals.
Terms enclosed in squarebrackets are optional.
Terms followed by "..." mayoccur zero or more times in succession.3.1 Termina l  Act ionsSuccessful traversal of an ATN arc might or mightnot consume an input symbol.
When parsing, suchconsumption ormally occurs; when generating it nor-mally does not, but if it does, the next symbol(semantic node) must be specified.
To allow for thesechoices, we have returned to the technique of Woods1970 of having two terminal actions, TO and JUMP,and have added an optional second argument o TO.The syntax is:(TO <state> \[<form>\])(JUMP <state>)Both cause the parser to enter the given state.
JUMPnever consumes the input symbol; TO always does.
Ifthe <form> is absent in the TO action, the next sym-bol to be scanned will be the next one in the inputbuffer.
If < form> is present, its value will be thenext symbol to be scanned.
All traditional ATN arcsexcept JUMP and POP end with a terminal action.The explanation given in Burton 1976 for the re-placement of the JUMP terminal action by the JUMParc was that, "since POP, PUSH and VIR arcs neveradvance the input, to decide whether or not an arcadvanced the input required knowledge of both the arctype and termination action.
The introduction of theJUMP arc ... means that the input advancement is afunction of the arc type alone."
That our reintroduc-tion of the JUMP terminal action does not bring backthe confusion is explained in Section 4.3.2 ArcsWe retain a JUMP arc as well as a JUMP terminalaction.
The JUMP arc provides a place to make anarbitrary test and perform some actions without con-suming an input symbol.
For symmetry, we introducea TO arc:(TO (<state> \[<form>\]) <test><action>.. .
)If <test> is successful, the <act ion>s are performedand transfer is made to <state>.
The input symbol isconsumed.
The next symbol to be scanned is the val-ue of <form> if it is present, or the next symbol inthe input buffer if <form> is missing.Neither the JUMP arc nor the TO arc are reallyrequired if the TST arc is retained (Bates 1978, how-ever, does not mention it), since they are equivalent tothe TST arc with the JUMP or TO terminal action,respectively.
However, they require less typing andprovide clearer documentation.
They are used in theexample in Section 6.The PUSH arc makes two assumptions: 1) the firstsymbol to be scanned in the subnetwork is the currentcontents of the * register; 2) the current input symbolwill be consumed by the subnetwork, so the contentsof * can be replaced by the value returned by the sub-network.
We need an arc that causes a recursive callto a subnetwork, but makes neither of these two as-sumptions, so we introduce the CALL  arc:(CALL <state> <form> <test><preact ion or act ion>.. .<register> <act ion>.. .<terminal  act ion> )where <preact ion or act ion> is <preact ion> or<act ion>.
If the <test> is successful, all the<act ion>s of <preact ion or act ion> are performedand a recursive push is made to the state <state>where the next symbol to be scanned is the value of<form> and registers are initialized by the<preact ion>s.
If the subnetwork succeeds, its value isplaced into <register> and the <act ion>s and<terminal action> are performed.Just as the normal TO terminal action is the gener-alized TO terminal action without the optional form,the PUSH arc (which we retain) is equivalent o thefollowing CALL arc:(CALL <state> * <test> <preact ion>..
.?
<act ion>.. .
<terminal  act ion> )3.3 FormsThe generalized TO terminal action, the generalizedTO arc, and the CALL  arc all include a form whosevalue is to be the next symbol to be scanned.
If thisnext symbol is a semantic network node, the primaryway of identifying it is as the node at the end of adirected arc with a given label from a given node.
Thisidentification mechanism requires a new form:(GETA <arc> \[<node form>\])where <node form> is a form that evaluates to a se-mantic node.
If absent, <node form> defaults to *The value of GETA is the node at the end of the arclabelled <arc> from the specified node, or a list ofsuch nodes if there are more than one.3.4 Tests,  Preact ions,  and Act ionsThe generalization of the ATN formalism to onethat allows for writing grammars which generate sur-face strings from semantic networks, yet can be inter-preted by the same interpreter which handles parsinggrammars, requires no changes other than the onesdescribed above.
Specifically, no new tests, preac-tions, or actions are required.
Of course each imple-mentation of an ATN interpreter contains slight differ-ences in the set of tests and actions implemented be-yond the basic ones.14 Amer ican Journal  of Computational Linguistics, Volume 8, Number  1, January-March 1982Stuart  C. Shapiro Generalized Augmented Transition Network Grammars4.
The Input BufferInput to the ATN parser can be thought of as beingthe contents of a stack, called the input buffer.
If theinput is a string of words, the first word will be at thetop of the input buffer and successive words will be insuccessively deeper positions of the input buffer.
Ifthe input is a graph, the input buffer might containonly a single node of the graph.Adequate treatment of the * register is crucial forthe correct operation of a grammar interpreter thatdoes both parsing and generation.
This is dealt with inthe present section.On entering an arc, the * register is set to the topelement of the input buffer, which must not be empty.The only exceptions to this are the CAT, VIR, andPOP arcs.
On a CAT arc, * is the root form of thetop element of the input buffer.
(Since the CAT arc istreated as a "bundle" of arcs, one for each sense ofthe word being scanned, and is the only arc so treated,it is the only arc on which (GETF <feature> *) isguaranteed to be well-defined.)
VIR sets * to an ele-ment of the HOLD register.
POP leaves * undefinedsince * is always the element o be accounted for bythe current arc, and a POP arc is not trying to accountfor any element.
The input buffer is not changed be-tween the time a PUSH arc is entered and the time anarc emanating from the state pushed to is entered, sothe contents of * on the latter arc will be the same ason the former.
A CALL arc is allowed to specify thecontents of * on the arcs of the called state.
This isaccomplished by replacing the top element of the inputbuffer by that value before transfer to the called state.If the value is a list of elements, we push each elementindividually onto the input buffer.
This makes it par-ticularly easy to loop through a set of nodes, each ofwhich will contribute the same syntactic form to thegrowing sentence (such as a string of adjectives).While on an arc (except for POP), i.e.
during eval-uation of the test and the acts, the contents of * andthe top element of the input buffer remain the same.This requires special processing for VIR, PUSH, andCALL arcs.
Since a VIR arc gets the value of * fromHOLD, rather than from the input buffer, after setting?
the VIR arc pushes the contents of * onto the inputbuffer.
The net effect is to replace the held constitu-ent in a new position in the string.
When a PUSH arcresumes, and the lower level has successfully returneda value, the value is placed into * and also pushedonto the input buffer.
The net effect of this is to re-place a sub-string by its analysis.
When a CALL re-sumes, and the lower level has successfully returned avalue, the value is placed into the specified register,and the contents of * is pushed onto the input buffer.
(Recall that it was replaced before the transfer.
Seethe previous paragraph.)
The specified register mightor might not be *.
In either case the contents of * andthe top of the input buffer are the same.There are two possible terminal acts, JUMP andTO.
JUMP does not affect the input buffer, so thecontents of * will be the same on the successor arcs(except for POP and VIR) as at the end of the currentarc.
TO pops the input buffer, but if provided with anoptional form, also pushes the value of that form ontothe input buffer.POPping from the top level is only legal if the in-put buffer is empty.
POPping from any level shouldmean that a constituent has been accounted for.
Ac-counting for a constituent should entail removing itfrom the input buffer.
From this we conclude thatevery path within a level from an initial state to a POParc must contain at least one TO transfer, and in mostcases, it is proper to transfer TO rather than to JUMPto a state that has a POP arc emanating from it.
TOwill be the terminal act for most VIR and PUSH arcs.In any ATN interpreter having the operationalcharacteristics given in this section, advancement ofthe input is a function of the terminal action alone, inthe sense that, at any state JUMPed to, the top of theinput buffer will be the last value of *, and, at anystate jumped TO, it will not be.5.
The LexiconParsing and generating require a lexicon - a file ofwords giving their syntactic ategories and lexical fea-tures, as well as the inflectional forms of irregularlyinflected words.
Parsing and generating require differ-ent information, yet we wish to avoid duplication asmuch as possible.
This section discusses how a lexiconmight be organized when it is to be used both forparsing and for generation.
Figure 1 shows the lexi-con used for the example in Section 6.During parsing, morphological analysis is per-formed.
The analyzer is given an inflected form andmust segment it, find the root in the lexicon, and mod-ify the lexical entry of the root according to its analy-sis of the original form.
Irregularly inflected forms,such as "seen" in Figure 1, must have their own en-tries in the lexicon.
An entry in the lexicon may belexically ambiguous, such as "saw" in Figure 1, soeach entry must be associated with a list of one ormore lexical feature lists.
Each such list, whetherstored in the lexicon or constructed by the morpholog-ical analyzer, must include a syntactic category and aroot, as well as other features needed by the grammar.The lexical routines we use supply certain default fea-tures if they are not supplied explicitly.
These are asfollows: the root is the lexeme itself; nouns have(NUM.
SING); verbs have (TENSE .
PRES).
InFigure 1, BE and DOG get default features, while theentries for SAW override several of them.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 15Stuart  C. Shapiro Generalized Augmented Transition Network Grammars(A(BE(DOG(ISLUCYSAWSAWISEESEENSWEET(WAS(YOUNGCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYCTGYDETv))N))v)NPRN)V)N)V)V)im Jv)ADJ))ROOT .
BE)))ROOT .
SAWI ) )ROOT .
SEE)  (TENSE .
PAST)ROOT .
SAW)) )PAST  .
SAW) (PASTP  .
SEEN)ROOT .
SEE)  (TENSE .
PASTP))ROOT .
BE)))(NUM.
S ING)  (TENSE .
PRES) ) )))(PPRT .
T)))(NUM.
SING) (TENSE .
PAST)))Figure 1.
Example Lexicon.In the semantic network, some nodes are associatedwith lexical entries.
In Figure 3, nodes SWEET,YOUNG,  LUCY,  BE, SEE, and SAWl are.
Duringgeneration, these entries, along with other informationfrom the semantic network, are used by a morphologi-cal synthesizer to construct an inflected word.
Weassume that all such entries are unambiguous roots,and so contain only a single lexical feature list.
Thisfeature list must contain any irregularly inflectedforms.
For example, the feature list for "see"  in Fig-ure 1 lists "saw" as its past tense and "seen"  as itspast participle.
SAW1 represents the unambiguoussense of "saw" as a noun.
It is used in that way inFigure 3.
In Figure 1, SAW1 is given as the ROOT ofthe noun sense of SAW, but for purposes of morpho-logical synthesis, the ROOT of SAW1 is given asSAW.In summary, a single lexicon may be used for bothparsing and generating under the following conditions.The entry of an unambiguous root can be used forboth parsing and generating if its one lexical featurelist contains features required for both operations.
Anambiguous lexical entry (such as SAW) will only beused during parsing.
Each of its lexical feature listsmust contain a unique but arbitrary " root"  (SEE andSAW1) for connection to the semantic network andfor holding the lexical information required for genera-tion.
Every lexical feature list used for generatingmust contain the proper natural language spelling of itsroot (SAW for SAW1) as well as any irregularly in-flected forms.
Lexical entries for irregularly inflectedforms will only be used during parsing.
In the lexiconof Figure 1, the entries for A, DOG,  LUCY,  SEE,SWEET, and YOUNG are used during both parsingand generation.
Those for BE, IS, SAW, SEEN, andWAS are only used during parsing.
The entry forSAW1 is only used during generation.
Our morpho-logical synthesizer ecognizes "be"  as a special case,and computes its inflected forms without referring tothe lexicon.For the purposes of this paper, it should be irrele-vant whether the " root"  connected to the semanticnetwork is an actual surface word like "give",  a deep-er sememe such as that underlying both "g ive"  and" take" ,  or a primitive such as "ATRANS" .6.
ExampleIn this section, we discuss an example of naturallanguage interaction (in a small fragment of English)using an ATN parsing-generating grammar and SNePS,the Semantic Network Processing System \[Shapiro1979\].
The purpose of the example is to demonstratethe use of the generalized ATN formalism for writinga parsing-generating grammar for which the "parse"  ofan input sentence is a generated sentence response,using a knowledge representation and reasoning sys-tem as the sentence is processed.
Both the fragmentof English and the semantic network representat iontechnique have been kept simple to avoid obscuringthe use of the generalized ATN formalism.Figure 2 shows an example interaction using SNeP-SUL, the SNePS User Language.
The numbers in theleft margin are for reference in this section.
Thestring "**"  is the SNePSUL prompt.
The rest of eachline so marked is the user's input.
The following lineis the result returned by SNePSUL.
The last line ofeach interaction is the CPU time in milliseconds takenby the interaction.
(The system is running as compiledLISP on a CDC CYBER 170/730.
The ATN gram-mar is interpreted.)
Figure 3 shows the semantic net-work built as a result of the sentences in Figure 2.The first interaction creates a new semantic net-work node, shown as B1 in Figure 3, to represent heinstant of time "now".
The symbol "#"  represents aSNePSUL function to create this node and make it thevalue of the variable NOW.
From then on, the ex-16 Amer ican Journal  of Computational Linguistics, Volume 8, Number  1, January-March 1982Stuart C. Shapiro Generalized Augmented Transition Network Grammars(1)(2)(3)(4)** #NOW(BI)4 MSECS** (: YOUNG LUCY SAW A SAW)(I UNDERSTAND THAT YOUNG LUCY SAW A SAW)2481MSECS** (: WHO SAW A SAW)(YOUNG LUCY SAW A SAW)875 MSECS** (: LUCY IS SWEET)(I UNDERSTAND THAT YOUNG LUCY IS SWEET)397 MSECS** (: WHAT WAS SEEN BY LUCY)(A SAW WAS SEEN BY SWEET YOUNG LUCY)862 MSECSFigure 2.
Example interaction.BEFOREETMIBEFORENOWI14xFigure 3.
The semantic network built by the example interaction.pression *NOW evaluates to B1.
We will see *NOWused on some arcs of the grammar.The rest of the user inputs are calls to the SNeP-SUL funct ion ":".
This funct ion passes its argumentlist to the parser as the input buffer.
The parser startsin state S. The form popped by the top level ATNgrammar is returned as the value of the call to :, and isthen printed as ment ioned above.
Thus, the line fol-lowing the call to : may be v iewed as the "parse"  ofthe sentence passed to :.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 17Stuart C. Shapiro Generalized Augmented Transition Network GrammarsWe will trace the first example sentence throughthe ATN grammar, referring to the other examplesentences at various points.
The parse starts in state S(Figure 4) with the input buffer being (YOUNGLUCY SAW A SAW).
The one arc out of state Spushes to state SP, which is the beginning of a net-work that parses a sentence.
The first arc out of stateSP recognizes that inputs (2) and (4) are questions.In these cases the register TYPE is set to Q both onthis level (by the SETR action) and on the top level(by the L IFTR action).
The register SUBJ is also setto %X, which is a free variable in SNePSUL.
In thecases of sentences (1) and (3), however, the secondarc from SP is taken.
This is a PUSH to the networkbeginning at state NPP, which will parse a nounphrase.
Register TYPE is initialized to D (for"declarative") at the lower level by SENDR.
Whenthe noun phrase is parsed, the TYPE register is set toD at this and the top level, and the SUBJ register isset to the parse of the noun phrase.At state NPP (Figure 5) the JUMP arc is followedsince the * register is YOUNG rather than A.
At stateNPDET, the CAT ADJ arc is followed and a semanticnode representing the concept of YOUNG is put inthe HOLD register for later use.
The SNePSUL form(F INDORBUILD LEX (^(GETR *))) finds in thenetwork a node with a LEX arc to YOUNG (the con-tents of the * register) or builds such a node if onedoes not exist, and returns that node as the value ofthe form.
In this case, node M1 of Figure 3 is builtand placed in HOLD.
The parser then loops TONPDET with the input buffer being (LUCY SAW ASAW).
This time, the * register contains LUCY, sothe fourth arc is followed.
This time the SNePSULform builds nodes M2, M3, and M4 of Figure 3, andplaces M4 in the register NH.
Node M4 representssomeone named LUCY.
Node M3 represents the prop-osition that this person is named LUCY.
Node M2represents the name LUCY.
(When this arc is takenwhile parsing LUCY in sentences (3) and (4), thesesemantic nodes will be found.)
The parser then trans-fers TO state NPA at which the modifying propertiesare removed from the HOLD register and asserted tohold of the concept stored in NH.
In this case, thereis only one property, and node M5 is built.
Node M4,representing someone who is named LUCY and isYOUNG is popped to the PUSH arc emanating fromstate SP, and is placed in the SUBJ register as men-tioned earlier.
The parser then transfers TO state Vwith an input buffer of (SAW A SAW).The CAT arc from state V (Figure 6) wants a wordof category V. The first word in the input buffer isSAW, which is two-ways lexically ambiguous (seeFigure 1), so we can think of the CAT arc as beingtwo arcs, on one of which * contains the singular ofthe Noun SAW1, and on the other of which * containsthe past tense of the Verb SEE.
The second of thesearcs can be followed, setting the register VB to nodeM6, and the register TNS to PAST.
The parser thangoes TO state COMPL with input buffer (A SAW).At COMPL, neither CAT arc can be followed, so theparser JUMPs to state SV.
The first CAT arc is fol-lowed in sentence 4, while the second CAT arc is fol-lowed in sentence 3.At state SV (Figure 7), a semantic network tempo-ral structure is built for events.
Each event is given astarting time and an ending time.
Present tense isinterpreted to mean that the present ime, the value of?
NOW, is after the starting time and before the endingtime.
Past tense is interpreted to mean that the endingtime is before *NOW.
In this case, the tense is past,so the third arc is taken and builds nodes M7 and M8.M7 is made the SNePSUL value of *ETM, and M8 isplaced in the ATN register STM.
For simplicity in thisexample, the first arc ignores the tense of questions.Control then passes to state O.The first arc of state O (Figure 8) recognizes thebeginning of a "by"  prepositional phrase in a passivesentence.
This arc will be followed in the case ofsentence 4 to the state PAG where the object of BYwill replace the previous contents of the SUBJ register.In the case of sentence (1), the second arc will betaken, which is a PUSH to state NPP with input buff-er, (A SAW).
(S ; Parse  a sentence  and generate  a response.
(PUSH SP T (JUMP RESPOND)) )(SP ; Parse  a sentence.
(WRD (WHO WHAT); If it s tar ts  w i th  "Who" or "What",  i t 's a quest ion .T (SETR TYPE 'Q) (L IFTR TYPE) (SETR SUBJ  ZX) (TO V))(PUSH NPP ; A s ta tement  s tar ts  w i th  a Noun Phrase  -- its sub ject .T (SENDR TYPE 'm) (SETR TYPE 'D) (L IFTR TYPE) (SETR SUBJ  *)(TO V)))Figure 4.
ATN Grammar .18 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Stuart C. Shapiro Generalized Augmented Transition Network GrammarsAt state NPP (Figure 5), the first arc is taken, set-ting register INDEF to T, and transferring TO stateNPDET with input buffer (SAW).
The second arc istaken from NPDET interpreting SAW as a noun, thesingular form of SAW1.
A semantic node is found orbuilt (in this case M9 is built) to represent the class ofSAWls ,  M l l  is built to represent a new SAW1, andM10 is built to assert that M l l  is a SAW1.
In the caseof a question, such as sentence (2), the third arc findsall known SAWls  using the SNePSUL function DE-DUCE,  so that whatever can be inferred to be aSAW1 is found.
In either case the SAWI(s)  are(NPP ; Parse a noun phrase.
(WRD A T (SETR INDEF T)(JUMP NPDET T))(TO NPDET(NPDET ; Parse a NP after the determiner.
(CAT ADJ T ; Hold adject ives for later.
(HOLD 'ADJ (FINDORBUILD LEX (A(GETR *)))) (TO NPDET))(CAT N (AND (GETR INDEF) (EQ (GETR TYPE) 'D)); "a N" means some member of the class Noun,(SETR NH ; but not necessar i ly  any one already known.
(BUILD MEMBER-(BUILD CLASS (FINDORBUILD LEX (A(GETR *))))))(TO mPi))(CAT m (AND (GETR INDEE) (EQ (GETR TYPE) 'Q)); "a N" in a quest ion refers to an a lready known Noun.
(SETR NH(FIND MEMBER-(DEDUCE MEMBER ZY CLASS (TBUILD LEX (A(GETR *))))))(TO NPA))(CAT NPR T ; A proper noun is someone's name.
(SETR NH (FINDORBUILD NAMED-(FINDORBUILD NAME (FINDORBUILD LEX (A(GETR *))))))(TO NPA))(NPA ; Remove all held adject ives and bui ld WHICH-ADJ  proposit ions.
(VIR ADJ T(FINDORBUILD WHICH (A (GETR NH)) ADJ (A (GETR *)))(TO mmi))(POP NH T))Figure 5.
ATN Grammar (continued).
(V (CAT V T ; The next word must be a verb.
(SETR VB (FINDORBUILD LEX (A(GETR *))))(TO COMPL)))(SETR TNS (GETF TENSE))(COMPL ; Consider the word after the verb.
(CAT V (AND (GETF PPRT) (OVERLAP (GETR VB) (GETA LEX- 'BE))); It must be a pass ive sentence.
(SETR OBJ (GETR SUBJ)) (SETR SUBJ NIL) (SETR VC 'PASS)(SETR VB (FINDORBUILD LEX (A(GETR *)))) (TO SV))(CAT ADJ (OVERLAP (GETR VB) (GETA LEX- 'BE)); a predicate adjective.
(SETR ADJ (FINDORBUILD LEX (A (GETR *)))) (TO SVC))(JUMP SV T))Figure 6.
ATN Grammar (continued).American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 19Stuart C. Shapiro Generalized Augmented Transition Network Grammarsplaced in register NH,  and the parser transfers TOstate NPA with an empty input buffer, and the valueof NH is popped back to the PUSH arc from state Oor PAG where it becomes the value of the * registerand the first (and only) item on the input buffer.
Af-ter setting the SUBJ or OBJ register, these PUSH arcsLIFTR the proper voice to the VC register on the topATN level and transfer TO state SVO (Figure 9).When dealing with sentence (1), the first POP arcat state SVO builds node M12 and pops it to the toplevel.
The second POP arc finds M12 for both sen-tences (2) and (4).
In the case of sentence (3), theCAT ADJ arc is fo l lowed from state COMPL to stateSVC, on the first arc of which node M15 is built.
Thesecond arc from SVC is not used in these examples.The pop from state SVO or SVC returns to thePUSH arc from state S which JUMPs to the state RE-SPOND with the input buffer containing either thenode built to represent an input statement or the nodethat represents the answer to an input question.
Inour example, this is node M12 for inputs (1), (2), and(4), and node M15 for input (3).
Remember  thatnodes M14 and M15 do not exist until sentence (3) isanalyzed.The state RESPOND (Figure 10) is the initial stateof the generation network.
In this network the regis-ter STRING is used to col lect the surface sentencebeing built.
The only difference between the two arcsin state RESPOND is that the first, responding toinput statements, starts the output sentence with the(SV ; Start bu i ld ing the temporal  structure.JUMP O (EQ (GETR TYPE) 'Q)) ; Ignore the tense of a question.JUMP O (EQ (GETR TNS) 'PRES); Present means start ing before and ending after now.
(SETR STM (BUILD BEFORE *NOW BEFORE (BUILD AFTER *NOW) : ETM)))JUMP O (EQ (GETR TNS) 'PAST); Past means start ing and ending before now.
(SETR STM (BUILD BEFORE (BUILD BEFORE *NOW) = ETM))))Figure 7.
ATN Grammar (continued).
(O ; Parse what fol lows the verb group.
(WRD BY (EQ (GETR VC) 'PASS) ; Passive sentences have(TO PAG))(PUSH NPP T ; A<tive sentences have an object NP.
(SENDR TYPE) (SETR OBJ *) (LIFTR VC) (TO SVO)))"by NP".
(PAG (PUSH NPP T ; Parse the subject NP of a pass ive sentence.
(SENDR TYPE) (SETR SUBJ *) (LIFTR VC) (TO SVO)))Figure 8.
ATN Grammar (continued).
(SVO ; Return a semantic node.
(POP (BUILD AGENT (^(GETR SUBJ)) VERB (A(GETR VB))OBJECT (^(GETR OBJ)) STIME (A(GETR STM)) ETIME *ETM)(EQ (GETR TYPE) 'D)) ; An Agent -Verb-Object  statement.
(POP (DEDUCE AGENT (A(GETR SUBJ)) VERB (^(GETR VB))OBJECT (^(GETR OBJ)))(EQ (GETR TYPE) 'Q))) ; An Agent -Verb-Object  question.
(SVC (POP (EVAL (BUILDQ (FINDORBUILD WHICH + ADJ +) SUBJ ADJ))(EQ (GETR TYPE) 'D)) ; A Noun-be-Adj  statement.
(POP (DEDUCE WHICH (A(GETR SUBJ)) ADJ (A(GETR ADJ)))(EQ (GETR TYPE) 'Q))) ; A Noun-be-Adj  question.Figure 9.
ATN Grammar (continued).20 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Stuart C. Shapiro Generalized Augmented Transition Network Grammars(RESPOND; Generate  the response  represented  by the semant ic  node in * .
(JUMP G (EQ (GETR TYPE) 'D); The input  was a s ta tement  represented  by *.
(SETR STRING ' (I UNDERSTAND THAT)))(JUMP G (EQ (GETR TYPE) 'Q))); The input  was a quest ion  answered  by *.Figure 10.
ATN Grammar (continued).phrase I UNDERSTAND THAT.
Then both arcsJUMP to state G. We follow the generation processassuming that the input buffer is now (M12).In state G (Figure 11), the node representing thestatement to be generated is analyzed to decide whatkind of sentence will be produced.
The first arc, for apassive version of M12, sets the SUBJ register to M11(the saw), the OBJ register to M4 (Lucy), and thePREP register to the word BY.
(Note the use ofGETA, defined in Section 3.3.)
The second arc, foran active version of M12, sets SUBJ to M4, OBJ toM l l ,  and leaves PREP empty.
It also makes sure VCis set to ACT, since active voice is the default if VC isempty.
The third arc is for generating sentences fornodes such as M15.
In that case it sets SUBJ to M4,OBJ to M14 (the property SWEET), VC to ACT, andleaves PREP empty.
All three arcs then JUMP tostate GS.The CALL  arc at state GS (Figure 12) sets theNUMBR register to SING or PL to determine whetherthe subject and verb of the sentence will be singular orplural, respectively.
It does this by CALLing the net-work beginning at state NUMBR, sending it the con-tents of the SUBJ register, and placing the form re-turned by the lower network into the NUMBR regis-ter.
Let us assume we are generating an active versionof M12.
In that case when state NUMBR (Figure 12)is reached, the input buffer will be (M4), and whenthe parser returns to the CALL  arc the input bufferwill again be (M12).At state NUMBR, the semantic network attachedto the node in the * register is examined to determineif it represents a (singular) individual or a (plural)class of individuals.
The first arc decides on PL if thenode has a SUB-, SUP-, or CLASS- are emanatingfrom it.
These arcs are the converses of SUB, SUP,and CLASS arcs, respectively.
The first would occurif the node represented the subset of some class.
Thesecond would occur if the node represented the super-set of some class.
The third would occur if the noderepresented a class with at least one member.
In ourexample, the only semantic node that would be recog-nized by this arc as representing a class would be M9.The second arc from state NUMBR decides on SINGif none of the three mentioned arcs emanate from thenode in *, and in our case this is the successful arc.The decision is made by placing SING or PL in theNUMBR register, and transferring TO state NUMBR1.There the input buffer is empty and the contents ofNUMBR is popped to the CALL arc in the state GSas discussed above.
The last thing the CALL arc instate GS does is set the DONE register to the node in?
This register is used to remember the node beingexpressed in the main clause of the sentence so that itis not also used to form a subordinate clause or de-scription.
For example, we would not want to gener-ate "Lucy, who saw a saw, saw a saw."
This is used(G ; Generate  a sentence  to express  the semant ic  node in * .
(JUMP GS (AND (GETA OBJECT) (OVERLAP (GETR VC) 'PASS)); A pass ive  sentence  is "OBJECT VERB by AGENT".
(SETR SUBJ (GETA OBJECT))  (SETR OBJ (GETA AGENT))(SETR PREP 'BY))(JUMP GS (AND (GETA AGENT) (DIS JOINT (GETR VC) 'PASS)); An act ive  sentence  is "AGENT VERB OBJECT".
(SETR SUBJ (GETA AGENT))  (SETR OBJ (GETA OBJECT))(SETR VC 'ACT))(JUMP GS (GETA WHICH) (SETR SUBJ  (GETA WHICH)); A WHICH-ADJ  sentence  is "WHICH be ADJ".
(SETR OBJ (GETA ADJ)) (SETR VC 'ACT)))Figure 1 h ATN Grammar (continued).American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 21Stuart C. Shapiro Generalized Augmented Transition Network  Grammarseffectively in the response to statement 3 to preventthe response from being "I UNDERSTAND THATSWEET YOUNG LUCY IS SWEET".
We will seewhere DONE is used in the ATN network shortly.The parser then JUMPs to state GS1, where NP isCALLed with input buffer (M4), DONE set to M12,and NUMBR set to SING.State NP (Figure 13) is the beginning of a networkthat generates a noun phrase to describe the conceptrepresented by the semantic node in the * register (inthis case, M4).
The first arc just uses the node at theend of the LEX arc if one exists, as it does for nodesM1, M2, etc.
WRDIZE is a LISP function that doesmorphological synthesis for nouns.
Its first argumentmust be SING or PL, and its second argument must bea non-ambiguous lexeme in the lexicon.
Nouns whosesingular or plural forms are irregular must have themexplicitly noted in the lexical feature list.
The regularrule is to use the ROOT form as the singular, and topluralize according to rules built into WRDIZE thatoperate on the ROOT form.
For example, the singu-lar of SAW1 is its ROOT, SAW, and its plural isSAWS.The second arc in the state NP uses a proper nameto describe *, if it has one, and if the proposition thatthis name is *'s name is not the point of the main(GS ; Set the NUMBR reg is ter  to the number  of the subject ,; and the DONE reg is ter  to the propos i t ion  of the main  c lause.
(CALL NUMBR SUBJ  T NUMBR (SETR DONE *) (JUMP GSl)))(GSI (CALL NP SUBJ  T ; Generate  a NP to express  the subject .
(SENDR DONE) (SENDR NUMBR) REG(ADDR STRING REG) (JUMP SVB)))(NUMBR; The proper  number  is PL for a class, S ING for an ind iv idua l .
(TO (NUMBRI) (OR (GETA SUB-) (GETA SUP-) (GETA CLASS-))(SETR NUMBR 'PL))(TO (NUMBRI) (NOT (OR (GETA SUB-) (GETA SUP-) (GETA CLASS-) ) )(SETR NUMBR 'SING)))(NUMBRI (POP NUMBR T)) ; Return  the number.Figure 12.
ATN Grammar (Continued).
(NP ; Generate  a NP to express  *.
(TO (END) (GETA LEX); Just  use the word  at the end of the LEX arc if present .
(SETR STRING (WRDIZE (GETR NUMBR) (GETA LEX))))(CALL ADJS (GETA WHICH-)  ; If it has a name,(AND (GETA NAMED-) (DIS JOINT (GETA NAMED-) DONE))(SENDR DONE) REG(ADDR STRING REG) ; add an ad jec t ive  str ing,(TO NPGA (GETA NAME (GETA NAMED-) ) ) )  ; and cons ider  its name.
(CALL ADJS (GETA WHICH-)  ; If it has a class,(AND (GETA MEMBER-)  (DIS JOINT (GETA MEMBER-)  DONE))(SENDR DONE) REG ; add 'A and an ad jec t ive  str ing,(ADDR STRING 'A REG) ; and cons ider  its class.
(TO NPGA (GETA CLASS (GETA MEMBER- ) ) ) ) )(NPGA ; Generate  a noun phrase  for the name or class.
(PUSH NP T (SENDR DONE) (ADDR STRING *) (TO END)))(END (POP STRING T)) ; Return  the s t r ing  that  has been bui l t .Figure 13.
ATN Grammar (continued).22 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Stuart  C. Shapiro Generalized Augmented Transition Network Grammarsclause.
The third arc uses the phrase "a <c lass>"  if *is known to be a member of some class, and if thatfact is not the main clause of the sentence.
Both arcsfirst call ADJS to form an adjective string to be in-cluded in the noun phrase.The network starting at ADJS (Figure 14) isCALLed to generate a string of adjectives.
For thispurpose, it is "passed" the set of property assertionnodes, and its DONE register is set.
Let us considerthe four cases in which a noun phrase is being generat-ed to describe M4.
In sentences (1) and (2), the inputbuffer at state ADJS is (M5) and DONE contains(M12).
In sentence (3), the input buffer is (M15 M5)and DONE is (M15).
In sentence (4), the input buff-er is (M15 M5) and DONE contains (M12).
TheCALL arc in state ADJS calls the NP network to gen-erate a description of the property at the end of theADJ arc from the node in * (the first node in the in-put buffer) as long as the node in * is not also inDONE.
It adds this description to the registerSTRING and loops back TO ADJS, consuming thenode in * from the input buffer.
We have alreadyseen how the NP network will generate SWEET forM14 and YOUNG for M1.
The second arc in stateADJS consumes the first node in the input bufferwithout generating a description for its property.
Thethird arc POPs back to the CALLing arc, returning theconstructed adjective string in STRING.
If we viewthe ATN as a non-deterministic machine, the result ofthe ADJS network is a string of zero or more of theadjectives that describe the individual of the nounphrase, but not the adjective, if any, in the predicateof the higher clause.
Viewed deterministically, sincemost ATN interpreters try arcs in strict order, thenetwork will generate a string of all appropriate adjec-tives.Returning to our main example of sentence (1), thestring YOUNG is POPped into the REG register onthe first CALL  arc in state NP, where it is added tothe end of the register STRING (previously empty).The parser then jumps TO state NPGA,  and, becauseof the form in the terminal action, the input buffer ischanged from (M4) to (M2).
At state NPGA,  theparser PUSHes to state NP where, as we have seen,LUCY will be generated and POPped back into the *register.
This is added to STRING, forming (YOUNGLUCY),  and the parser goes TO state END, emptyingthe input buffer.
At END, the contents of STRING,(YOUNG LUCY)  is POPped to the register REG inthe CALL  arc of state GS1 (Figure 12), and added tothe top level of STRING, which is now (I UNDER-STAND THAT YOUNG LUCY) .
The parser thenJUMPs to state SVB with the input buffer restored to(M12).At state SVB (Figure 15), the network beginning atstate PRED is CALLed.
At that level the input bufferis (M12), * contains M12, NUMBR contains SING,VC contains ACT (PASS in the case of sentence 4),and VB contains SEE.
Notice that if the main propo-sition node has no VERB arc, BE is placed in VB.This is the situation in the case of sentence (3), re-flecting the theory that in copulative sentences BE isonly a dummy verb used to carry tense, mood, andaspect.The arcs at state PRED (Figure 15) determine andplace in the TENSE register the tense of the sentencebeing generated.
For simplicity in this example, weonly consider simple present, past, and future.
This isone of the most interesting sections of this generationgrammar, because it is a grammar that analyzes(parses) a piece of the semantic network.
The firstCALL  arc of state PRED calls a network that recog-nizes the temporal structure indicating past tense.
Thesecond CALL arc calls a network that recognizes thetemporal structure indicating future tense.
The third,TO, arc chooses present tense as the default.
TheCALL arcs pass to the lower network the appropriatesemantic temporal nodes.
Since past tense is indicatedby the action ending before *NOW, the first arc pas-ses the node at the end of the ET IME arc from theproposition node.
Since future tense is indicated bythe action starting after *NOW, the second arc passesthe node at the end of the STIME arc.
In our case,the tense will be past, so we turn to the PAST sub-network (Figure 16).The first are in state PAST transfers TO state PAS-TEND, which simply POPs the atom PAST if the con-tents of * OVERLAPs  the value of *NOW, that is, ifthe * register contains the semantic node representingnow.
If it doesn't,  the second arc in PRED replacesthe first node in the input buffer by the node(s) repre-senting times known to be after it, and loops back toPRED.
This sub-network can only succeed, returning(ADJS; Generate  a s t r ing  of ad ject ives ,  one for each WHICH-ADJ  node in *.
(CALL NP (GETA ADJ) (DISJOINT * DONE) (SENDR DONE) *(ADDR STRING *) (TO ADJS))(TO (ADJS) T)(POP STRING T))Figure 14.
ATN Grammar (continued).American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 23Stuart C. Shapiro Generalized Augmented Transition Network Grammars(SVB (CALL PRED * T; Generate a verb group.
Use "be" if no other verb.
(SENDR NUMBR) (SENDR VC)(SENDR VB (OR (GETA LEX (GETA VERB)) 'BE))REG (ADDR STRING REG) (JUMP SUROBJ)))(SUROBJ (CALL NP OBJ OBJ; Generate a NP to express the OBJ if there is one.
(SENDR DONE) * (ADDR STRING PREP *) (TO END))(TO (END) T))(PRED ; F igure out the proper  tense.
(CALL PAST (GETA ETIME) T TENSE (TO GENVB)); Past tense depends on ending time.
(CALL FUTR (GETA STIME) T TENSE (TO GENVB)); Future tense depends on start ing time.
(TO (GENVB) T (SETR TENSE 'PRES))) ; Present tense is the default.
(GENVB ; Return the verb group.
(POP (VERBIZE (GETR NUMBR) (GETR TENSE) (GETR VC) (GETR VB)) T))Figure 15.
ATN Grammar (continued).
(PAST ; If we can get to *NOW by BEFORE arcs,(TO (PASTEND) (OVERLAP * *NOW))(TO (PAST (GETA BEFORE)) T))(PASTEND (POP 'PAST T))it is past tense.
(FUTR ; If we can get to *NOW by AFTER arcs,(TO (FUTREND) (OVERLAP * *NOW))(TO (FUTR (GETA AFTER)) T))(FUTREND (POP 'FUTR T))it is future tense.Figure 16.
ATN Grammar (continued).PAST, if there is a path of BEFORE arcs from thenode representing the ending time of the action to*NOW.
If there isn't, the sub-network will eventuallyblock, causing the CALL  PAST arc in state PRED tofail.
The FUTR sub-network works in a similar fash-ion.
Similar sub-networks can easily be written torecognize the temporal structure of future perfect("Lucy will have seen a saw.
"), which is a path ofBEFORE arcs followed by a path of AFTER arcsfrom the ending time to now, and the temporal struc-tures of other tenses.In our example, the CALL  PAST arc succeeds,TENSE is set to PAST, and the parser transfers TOstate GENVB (Figure 15), where the appropriate verbgroup is generated and POPped to the CALL  arc instate SVB.
The verb group is constructed by VER-BIZE, which is a LISP function that does morphologi-cal synthesis on verbs.
Its arguments are the number,tense, voice, and verb to be used.Back on the CALL  arc in state SVB (Figure 15),the verb group POPped into the register REG is addedto the STRING, which is now (I UNDERSTANDTHAT YOUNG LUCY SAW), and the parser JUMPsto state SUROBJ.
There, the NP sub-network (Figure13) is CALLed to generate a noun phrase for the con-tents of OBJ (M l l ) .
Since M l l  has neither a LEXarc nor a name, but does have a class, the third arc isused, and (A SAW) is generated and POPped.
Thisnoun phrase is added to STRING preceded by thecontents of PRED, which is empty in sentences (1),(2), and (3), but which contains BY in sentence (4).The CALL  arc then transfers TO state END, emptyingthe input buffer at the top level.
The POP arc at stateEND POPs the contents of STRING, which is finallyprinted by the system, and the interaction is complete.24 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Stuart C. Shapiro Generalized Augmented Transition Network Grammars7.
ConclusionsA generalization of the ATN formalism has beenpresented which allows grammars to be written forgenerating surface sentences from semantic networks.The generalization has involved: adding an optionalargument o the TO terminal act; reintroducing theJUMP terminal act; introducing a TO arc similar tothe JUMP arc; introducing a CALL arc that is a gen-eralization of the PUSH arc; introducing a GETAform; clarifying the management of the input buffer.The benefits of these few changes are that parsing andgenerating rammars may be written in the same fa-miliar notation, may be interpreted (or compiled) by asingle program, and may use each other in the sameparser-generator network grammar.AcknowledgmentsThe help provided by the following people with theATN parsing and generating interpreters and compiler,the morphological analyzer and synthesizer, and mov-ing the software across several LISP dialects is greatlyappreciated: Stan Kwasny, John Lowrance, DarrelJoy, Don McKay, Chuck Arnold, Ritch Fritzson, Ger-ard Donlon.
Associate editor Michael McCord andthe reviewers provided valuable comments on earlierdrafts of this paper.ReferencesBates, M. 1978 The theory and practice of augmented transitionnetwork grammars.
In Bole, L., Ed., Natural Language Commu-nication with Computers.
Springer Verlag, Berlin: 191-259.Burton, R.R.
1976 Semantic grammar: an engineering techniquefor constructing natural anguage understanding systems.
BBNReport No.
3453, Bolt Beranek and Newman, Inc., Cambridge,MA., December.Burton, R.R.
and Woods, W.A.
1976 A compiling system foraugmented transition etworks.
Preprints of COLING 76: TheInternational Conference on Computational Linguistics, Ottawa(June).Shapiro, S.C. 1975 Generation as parsing from a network into alinear string.
AJCL Microfiche 33, 45-62.Shapiro, S.C. 1979 The SNePS semantic network processingsystem.
In Findler, N.V., Ed., Associative Networks: Representa-tion and Use of Knowledge by Computers.
Academic Press, NewYork, 179-203.Simmons, R.F.
1973 Semantic networks: their computation anduse for understanding English sentences.
In Schank, R.C.
andColby, K.M., Ed., Computer Models of Thought and Language.W.
H. Freeman and Co., San Francisco: 63-113.Woods, W.A.
1970 Transition network grammars for naturallanguage analysis.
CACM 13, 10 (October) 591-606.Woods, W.A.
1973 An experimental parsing system for transitionnetwork grammars.
In Rustin, R., Ed., Natural LanguageProcessing.
Algorithmics Press, New York: 111-154.Stuart C. Shapiro is an associate professor in theDepartment of Computer Science at the State Universityof New York at Buffalo.
He received the Ph.D. degreein computer sciences f rom the University o f  Wisconsin in1971.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 25
