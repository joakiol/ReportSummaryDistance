Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 153?156,New York, June 2006. c?2006 Association for Computational LinguisticsUnsupervised Induction of Modern Standard Arabic Verb ClassesNeal SniderLinguistics DepartmentStanford UniversityStanford, CA 94305snider@stanford.eduMona DiabCenter for Computational Learning SystemsColumbia UniversityNew York, NY 10115mdiab@cs.columbia.eduAbstractWe exploit the resources in the Ara-bic Treebank (ATB) for the novel taskof automatically creating lexical semanticverb classes for Modern Standard Arabic(MSA).
Verbs are clustered into groupsthat share semantic elements of meaningas they exhibit similar syntactic behavior.The results of the clustering experimentsare compared with a gold standard set ofclasses, which is approximated by usingthe noisy English translations provided inthe ATB to create Levin-like classes forMSA.
The quality of the clusters is foundto be sensitive to the inclusion of informa-tion about lexical heads of the constituentsin the syntactic frames, as well as parame-ters of the clustering algorithm .
The bestset of parameters yields an F?=1 scoreof 0.501, compared to a random baselinewith an F?=1 score of 0.37.1 IntroductionThe creation of the Arabic Treebank (ATB) fa-cilitates corpus based studies of many interestinglinguistic phenomena in Modern Standard Arabic(MSA).1 The ATB comprises manually annotatedmorphological and syntactic analyses of newswiretext from different Arabic sources.
We exploit theATB for the novel task of automatically creating lex-ical semantic verb classes for MSA.
We are inter-ested in the problem of classifying verbs in MSAinto groups that share semantic elements of mean-ing as they exhibit similar syntactic behavior.
This1http://www.ldc.orgmanner of classifying verbs in a language is mainlyadvocated by Levin (1993).
The Levin Hypothesis(LH) contends that verbs that exhibit similar syn-tactic behavior share element(s) of meaning.
Thereexists a relatively extensive classification of Englishverbs according to different syntactic alternations,and numerous linguistic studies of other languagesillustrate that LH holds cross linguistically, in spiteof variations in the verb class assignment (Guersselet al, 1985).For MSA, the only test of LH has been the workof Mahmoud (1991), arguing for Middle and Unac-cusative alternations in Arabic.
To date, no generalstudy of MSA verbs and alternations exists.
We ad-dress this problem by automatically inducing suchclasses, exploiting explicit syntactic and morpholog-ical information in the ATB.Inducing such classes automatically allows fora large-scale study of different linguistic phenom-ena within the MSA verb system, as well as cross-linguistic comparison with their English counter-parts.
Moreover, drawing on generalizations yieldedby such a classification could potentially be usefulin several NLP problems such as Information Ex-traction, Event Detection, Information Retrieval andWord Sense Disambiguation, not to mention the fa-cilitation of lexical resource creation such as MSAWordNets and ontologies.2 Related WorkBased on the Levin classes, many researchers at-tempt to induce such classes automatically (Merloand Stevenson, 2001; Schulte im Walde, 2000) .
No-tably, in the work of Merlo and Stevenson , they at-tempt to induce three main English verb classes on alarge scale from parsed corpora, the class of Unerga-153tive, Unaccusative, and Object-drop verbs.
They re-port results of 69.8% accuracy on a task whose base-line is 34%, and whose expert-based upper boundis 86.5%.
In a task similar to ours except for itsuse of English, Schulte im Walde clusters Englishverbs semantically by using their alternation behav-ior, using frames from a statistical parser combinedwith WordNet classes.
She evaluates against thepublished Levin classes, and reports that 61% of allverbs are clustered into correct classes, with a base-line of 5%.3 ClusteringWe employ both soft and hard clustering techniquesto induce the verb classes, using the clustering algo-rithms implemented in the library cluster (Kaufmanand Rousseeuw, 1990) in the R statistical comput-ing language.
The soft clustering algorithm, calledFANNY, is a type of fuzzy clustering, where each ob-servation is ?spread out?
over various clusters.
Thus,the output is a membership function P (xi, c), themembership of element xi to cluster c. The mem-berships are nonnegative and sum to 1 for each fixedobservation.
The algorithm takes k, the number ofclusters, as a parameter and uses a Euclidean dis-tance measure.The hard clustering used is a type of k-means clus-tering The canonical k-means algorithm proceedsby iteratively assigning elements to a cluster whosecenter (centroid) is closest in Euclidian distance.4 FeaturesFor both clustering techniques, we explore three dif-ferent sets of features.
The features are cast as thecolumn dimensions of a matrix with the MSA lem-matized verbs constituting the row entries.Information content of frames This is the mainfeature set used in the clustering algorithm.
Theseare the syntactic frames in which the verbs occur.The syntactic frames are defined as the sister con-stituents of the verb in a Verb Phrase (VP) con-stituent.We vary the type of information resulting fromthe syntactic frames as input to our clustering algo-rithms.
We investigate the impact of different lev-els of granularity of frame information on the clus-tering of the verbs.
We create four different datasets based on the syntactic frame information reflect-ing four levels of frame information: FRAME1 in-cludes all frames with all head information for PPsand SBARs, FRAME2 includes only head informa-tion for PPs but no head information for SBARs,FRAME3 includes no head information for neitherPPs nor SBARs, and FRAME4 is constructed withall head information, but no constituent ordering in-formation.
For all four frame information sets, theelements in the matrix are the co-occurrence fre-quencies of a verb with a given column heading.Verb pattern The ATB includes morphologicalanalyses for each verb resulting from the Buckwal-ter 2 analyzer.
Semitic languages such as Arabichave a rich templatic morphology, and this analy-sis includes the root and pattern information of eachverb.
This feature is of particular scientific interestbecause it is unique to the Semitic languages, andhas an interesting potential correlation with argu-ment structure.Subject animacy In an attempt to allow the clus-tering algorithm to use information closer to actualargument structure than mere syntactic frames, weadd a feature that indicates whether a verb requiresan animate subject.
Following a technique suggestedby Merlo and Stevenson , we take advantage of thistendency by adding a feature that is the number oftimes each verb occurs with each NP types as sub-ject, including when the subject is pronominal orpro-dropped.5 Evaluation5.1 Data PreparationThe data used is obtained from the ATB.
The ATB isa collection of 1800 stories of newswire text fromthree different press agencies, comprising a totalof 800, 000 Arabic tokens after clitic segmentation.The domain of the corpus covers mostly politics,economics and sports journalism.
Each active verbis extracted from the lemmatized treebank alongwith its sister constituents under the VP.
The ele-ments of the matrix are the frequency of the row verbco-occuring with a feature column entry.
There are2074 verb types and 321 frame types, correspondingto 54954 total verb frame tokens.
Subject animacy2http://www.ldc.org154information is extracted and represented as four fea-ture columns in our matrix, corresponding to thefour subject NP types.
The morphological patternassociated with each verb is extracted by looking upthe lemma in the output of the morphological ana-lyzer, which is included with the treebank release.5.2 Gold Standard DataThe gold standard data is created automatically bytaking the English translations corresponding to theMSA verb entries provided with the ATB distribu-tions.
We use these English translations to locate thelemmatized MSA verbs in the Levin English classesrepresented in the Levin Verb Index.
Thereby creat-ing an approximated MSA set of verb classes corre-sponding to the English Levin classes.
Admittedly,this is a crude manner to create a gold standard set.Given the lack of a pre-existing classification forMSA verbs, and the novelty of the task, we considerit a first approximation step towards the creation ofa real gold standard classification set in the near fu-ture.5.3 Evaluation MetricThe evaluation metric used here is a variation onan F -score derived for hard clustering (Rijsber-gen, 1979).
The result is an F?
measure, where?
is the coefficient of the relative strengths of pre-cision and recall.
?
= 1 for all results we re-port.
The score measures the maximum overlap be-tween a hypothesized cluster (HYP) and a corre-sponding gold standard cluster (GOLD), and com-putes a weighted average across all the HYP clus-ters: F?
=?A?A?A?VtotmaxC?C(?2 + 1)?A ?
C??2?C?
+ ?A?Here A is the set of HYP clusters, C is the setof GOLD clusters, and Vtot =?A?A?A?
is the totalnumber of verbs that were clustered into the HYPset.
This can be larger than the number of verbs tobe clustered because verbs can be members of morethan one cluster.5.4 ResultsTo determine the best clustering of the extractedverbs, we run tests comparing five different pa-rameters of the model, in a 6x2x3x3x3 design.For the first parameter, we examine six differentframe dimensional conditions, FRAME1+ SUB-JAnimacy + VerbPatt,FRAME2 + SUBJAnimacy+ VerbPatt,FRAME3 + SUBJAnimacy + VerbPatt,FRAME4 + SUBJAnimacy + VerbPatt, FRAME1+ VerbPatt only; and finally, FRAME1+ SUBJAn-imacy only .
The second parameter is hard vs. softclustering.
The last three conditions are the num-ber of verbs clustered, the number of clusters, andthe threshold values used to obtain discrete clustersfrom the soft clustering probability distribution.We compare our best results to a random baseline.In the baseline, verbs are randomly assigned to clus-ters where a random cluster size is on average thesame size as each other and as GOLD.3 The highestoverall scored F?=1 is 0.501 and it results from us-ing FRAME1+SUBJAnimacy+VerbPatt, 125 verbs,61 clusters, and a threshold of 0.09 in the soft clus-tering condition.
The average cluster size is 3, be-cause this is a soft clustering.
The random baselineachieves an overall F?=1 of 0.37 with comparablesettings of 125 verbs randomly assigned to 61 clus-ters of approximately equal size.
A representativemean F?=1 score is 0.31, and the worst F?=1 scoreobtained is 0.188.
This indicates that the cluster-ing takes advantage of the structure in the data.
Tosupport this observation, a statistical analysis of theclustering experiments is undertaken in the next sec-tion.6 DiscussionFor further quantitative error analysis of the data,we perform ANOVAs to test the significance of thedifferences among the various parameter settingsof the clustering algorithm.
We find that informa-tion type is highly significant (p < .001).
Withinvarying levels of the frame information parameter,FRAME2 and FRAME3 are significantly worse thanusing FRAME1 information (p < .02).
The effectsof SUBJAnimacy, VerbPatt, and FRAME4 are notsignificantly different from using FRAME1 aloneas a baseline, which indicates that these features donot independently contribute to improve clustering,i.e.
FRAME1 implicitly encodes the information inVerbPatt and SUBJAnimacy.
Also, algorithm type(soft or hard) is found to be significant (p < .01),3It is worth noting that this gives an added advantage to therandom baseline, since a comparable to GOLD size implicitlycontibutes to a higher overlap score.155with soft clustering being better than hard clustering,while controlling for other factors.
Among the con-trol factors, verb number is significant (p < .001),with 125 verbs being better than both 276 and 407verbs.
The number of clusters is also significant(p < .001), with more clusters being better thanfewer.As evident from the results of the statistical anal-ysis, the various informational factors have an inter-esting effect on the quality of the clusters.
Includ-ing lexical head information in the frames signifi-cantly improves clustering, confirming the intuitionthat such information is a necessary part of the alter-nations that define verb classes.
However, as long ashead information is included, configurational infor-mation about the frames does not appear to help theclustering, i.e.
ordering of constituents is not signif-icant.
It seems that rich Arabic morphology playsa role in rendering order insignificant.
Nonetheless,this is an interesting result from a linguistic perspec-tive that begs further investigation.
Also interestingis the fact that SUBJAnimacy and the VerbPatt donot help improve clustering.
The non-significanceof SUBJAnimacy is indeed surprising, given its sig-nificant impact on English clusterings.
Perhaps thecues utilized in our study require more fine tuning.The lack of significance of the pattern informationcould indicate that the role played by the patternsis already encoded in the subcategorization frame,therefore pattern information is superfluous.The score of the best parameter settings with re-spect to the baseline is considerable given the nov-elty of the task and lack of good quality resourcesfor evaluation.
Moreover, there is no reason to ex-pect that there would be perfect alignment betweenthe Arabic clusters and the corresponding translatedLevin clusters, primarily because of the quality ofthe translation, but also because there is unlikely tobe an isomorphism between English and Arabic lex-ical semantics, as assumed here as a means of ap-proximating the problem.In an attempt at a qualitative analysis of the re-sulting clusters, we manually examine several HYPclusters.
As an example, one includes the verbs>aloqaY [meet], $ahid [view], >ajoraY [run an in-terview], {isotaqobal [receive a guest], Eaqad [holda conference], >aSodar [issue].
We note that theyall share the concept of convening, or formal meet-ings.
The verbs are clearly related in terms of theirevent structure (they are all activities, without an as-sociated change of state) yet are not semanticallysimilar.
Therefore, our clustering approach yields aclassification that is on par with the Levin classes inthe coarseness of the cluster membership granular-ity.
In summary, we observe very interesting clustersof verbs which indeed require more in depth lexicalsemantic study as MSA verbs in their own right.7 ConclusionsWe successfully perform the novel task of apply-ing clustering techniques to verb frame informationacquired from the ATB to induce lexical semanticclasses for MSA verbs.
In doing this, we find thatthe quality of the clusters is sensitive to the inclu-sion of information about lexical heads of the con-stituents in the syntactic frames, as well as param-eters of the clustering algorithm.
Our classificationperforms well with respect to a gold standard clus-ters produced by noisy translations of English verbsin the Levin classes.
Our best clustering conditionwhen we use all frame information and the most fre-quent verbs in the ATB and a high number of clustersoutperforms a random baseline by F?=1 differenceof 0.13.
This analysis leads us to conclude that theclusters are induced from the structure in the dataOur results are reported with a caveat on the goldstandard data.
We are in the process of manuallycleaning the English translations corresponding tothe MSA verbs.ReferencesM.
Guerssel, K. Hale, M. Laughren, B. Levin, and J.
White Eagle.
1985.
A crosslinguistic study of transitivity alternations.
In Papers from the Parasession onCausatives and Agentivity, volume 21:2, pages 48?63.
CLS, Chicago.L.
Kaufman and P.J.
Rousseeuw.
1990.
Finding Groups in Data.
John Wiley andSons, New York.Beth Levin.
1993.
English Verb Classes and Alternations: A Preliminary Investi-gation.
University of Chicago Press, Chicago.Abdelgawad T. Mahmoud.
1991.
A contrastive study of middle and unaccusativeconstructions in Arabic and English.
In B. Comrie and M. Eid, editors, Per-spectives on Arabic Linguistics, volume 3, pages 119?134.
Benjamins, Ams-terdam.Paola Merlo and Suzanne Stevenson.
2001.
Automatic verb classification basedon statistical distributions of argument structure.
Computational Linguistics,27(4).C.J.
Van Rijsbergen.
1979.
Information Retrieval.
Butterworths, London.Sabine Schulte im Walde.
2000.
Clustering verbs semantically according to theiralternation behaviour.
In 18th International Conference on ComputationalLinguistics (COLING 2000), Saarbrucken, Germany.156
