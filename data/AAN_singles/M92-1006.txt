GE ADJUNCT TEST REPORT :OBJECT-ORIENTED DESIGN AND SCORING FOR MUC- 4George Krupka and Lisa RauArtificial Intelligence Laborator yGE Research and DevelopmentSchenectady, NY 12301 US AE-mail : rau@crd .ge.comPhone: (518) 387 - 505 9AbstractThis paper reports on the results of the adjunct test performed by GE for the MUC-4 evaluationof text processing systems .
In this test, we evaluated the effect of an object-oriented templat edesign and associated matching conditions on the scores .
The results indicate that the curren tMUC- .
{ "flat" templade design with cross-references closely approximates a true object-oriente ddesign .
However the object-oriented design allows for additional performance data to be calculated ,facilitating diagnosis .INTRODUCTIONIn this adjunct test, we investigate the issues and effect of transforming the MUC-4 template design au-tomatically into an object-oriented design, with associated object-level matching conditions affecting th eoverall score .An object is simply a collection of slots that all refer to one item originating in the text .
This collectionof slots is logically connected due to their implicit reference to one particular filler .
In addition, objectsmay be nested so that one object contains another object, or may be recursive, with one object pointing t oanother and back again .
Finally, there may be multiple instances of any given object .In MUC-4 is is possible to isolate three distinct levels of objects .
The first level contains a STORY object .Attached to a STORY object are INCIDENT objects, each of which contains participant objects ; TARGET ,INSTRUMENT and PERPETRATOR.
The Figure 1 illustrates an object-oriented template design .The MUC template design has been moving from a flat structure to a more object-oriented structur ewith cross-references tying together multiple slots into what has been termed a "pseudo-object" .
Slots tie dtogether with cross-references are pseudo-objects and not true objects because the cross-references are no tenforced.
For example, consider the following scenario depicted in Figure 2 .
Although the human target("MARY") is wrong, the system is allowed partial credit for the other slots, even though they are clearl ycross-referenced to different, and equal incorrect, fills .MOTIVATIO NThere are a variety of reasons why an object-oriented design is desirable .
First, an object-oriented designis conceptually easier to understand .
Instead of a flat listing of all slots of a template, slots pertaining to asingle fill are grouped together .
Cross-references are no longer needed, as indentation indicates the grouping ,so the visual design is cleaner .Asthetics aside, there are additional performance data that can be obtained when groups of slots ar econnected as objects .
Systems can be scored on how well a given object aligns, in a way analogous t otemplate matching alignment scores (template ID score) .
Moreover, it is possible to construct an objecttotal that does not consider whether any given object appears in a matching template or not .
For exampl ein our system, we found that data such as a human target was correctly extracted by the program with all it sassociated fields, but was put in the wrong template .
This resulted in missing and spurious points for all th e78Storyslot: incidentIncidentslot: dateslot: locationslot: typeslot: stageslot: inst idslot: inst typeslot: perp idslot: perp orgslot: INSTRUMENTslot: perp confslot: category slot: phys tgt idslot: PERPETRATORslot: TARGETslot:hum tot numslot: phys tot numslot: phys tgt typeslot: phys tgt numberslot: phys tgt for natslot: phys tgt effectslot: hum tgt nameslot: hum tgt descslot: hum tgt typeslot: hum numberslot: hum for natslot: hum tgt effec tFigure 1 : Object-oriented MUC-4 Template Desig nfields in the object, although it could be argued that all that was incorrect was the association of the objectwith an incorrect incident .
Finally, with objected-oriented totals, it is very easy to isolate performanc eproblems down to the object-level .
With a flat design, less-than-perfect templates must be examined t odetermine where the problems occurred .
With object matching totals, it is possible to immediately isolat eobject-level errors which facilitates the error diagnosis process .The rest of this paper maps out the processes used to transform the flat MUC-4 template design to a nobject-oriented design .
We then overview the scoring experiments we performed to test the effect of variou sconfigurations .
Finally, we present detailed analyses of the effect of object-oriented design and scoring o nthe data from MUC-4 systems performance .KEYRESPONSEHUM TGT : ID :"MARY"HUM TGT : ID :"JOSE"HUM TGT : DESC : "WIFE" : "MARY"HUM TGT : DESC :"WIFE" : "GEORGE"HUM TGT : TYPECIVILIAN: "MARY"HUM TGT : TYPECIVILIAN : " PEDRO "HUM TGT : EFFECT : DEATH : "MARY"HUM TGT : EFFECT : DEATH : "RAUL "Figure 2 : Example of Unenforced Cross-reference s79TRANSFORMATION TO 0-0 DESIGNThe first step in performing this test was to automatically transform the existing template design to theobject-oriented design illustrated in Figure 1.
This process was aided by the existing cross-references, but wascomplicated by a variety of special cases we encountered.
These special cases fell into two general categories;system glitches, and problems with the MUC-4 template format.
The first three problems described beloware system glitches; the last three are issues in the design of the templates.1.
Inconsistent cross-references: We encountered inconsistent cross-reference strings.
For example, ' 'PEOPLE' Jmay have been present as a human target description, but a slot intended to cross-reference to it mayhave read "TWO PEOPLE j .2.
Violation of Templa te  Filling Rules: Some sites cross-referenced the perpetrator confidence to a nullvalue, or to  the PERP ID slot for example.3.
Multiple  Set  Fills: We encountered fills such as NO INJURY NO DEATH INJURY DEATH.4.
Inconsistent t reatments:  The treatment of repeated fills, as could be required in sentences such as"KILLED 3 PEOPLE AND INJURED 2 a was handled in different ways, with PEOPLE repeated as a fill,or with two EFFECTS cross-referenced to one fill..
When an EFFECT has a blank value, its scoping is ambiguous.
When we attempt 5.
Ambigui ty of ' ' - ' 'to group targets into objects, we cannot decide which object this effect belongs to.6.
Ambigui ty of Optional  Fills: It is impossible with the current template design to determine when anoptional fill of an optional object was meant, as opposed to a required fill of an optional object.For the system problems, we manually intervened and allowed the conversion process to  proceed.
Howeverone sites' responses were too unusual too allow us to  transform the output without a great deal of manualinteraction.
For the template design problems, we came up with adequate methods of working around theproblems.OBJECT-ORIENTED SCORINGAfter all (execept one) of the sites' answers were transformed into the object-oriented design, a modifiedversion of the MUC-4 scoring program was run in a variety of configurations to test the effect of enforcingobject-level matching.
This program used the merged history file, and took 10 seconds to score an averagerun.
It took one person-week to convert all the sites' answer templates to the object oriented design, andcreate a new version of the scoring program to use this design.We experimented with a variety of conditions for aligning templates and objects.
These were:1.
Only incident type match.
This was closer to the MUC-2 scoring conditions.2.
Must match on incident type, plus either a match on ID or type for target or ID or ORG for perpetrator.This duplicated the MUC-4 scoring, in that either a match on target or perpetrator would cause theincident to align.3.
Must match on incident type plus a match on the string ID slot of a target.
With this condition, weonly aligned templates if the targets aligned according to a stricter matching condition.
This matchingcondition required at least a partial match on the target string.
Note that virtually no templates haveno targets.4.
Free-floating object match.
For this design, we computed the score if objects were allowed to matcheach other without considering if they happen to belong to an aligning template object.
That is, if asystem mistyped an ATTACK as an ARSON but correctly extracted any human or physical targets, creditwould be given for these objects.SITE MUC-4 conditionDelta from scoreString PrimacyDelta from scoreBBN 4.80 1 .0 3GE 1 .53 0 .0GE-CMU 1 .50 -1.0 1LSI 2 .72 0,3 1MDC 5.51 0.0NMSU 5.02 1.0 1NYU 1 .43 -2 .0 1PARA MAX 1 .33 - .0 1PRC 1 .68-2 .0 8SRA 1 .82 -1 .1 0SRI 2.02 0 .
0UMASS 1 .41 -2 .43UMICH 3 .00 -1 .52Figure 4: Effect of 00-Alignment and String Primacy on ScoresSITE Original Object Tot Free-Floating Tot DeltaBBN 30 .00 31 .77 1 .7 7GE 51 .46 55 .00 3 .5 4GE-CMU 45 .90 49 .50 3 .7 0LSI 16 .61 20 .87 4 .2 6MDC 18 .44 20 .62 2 .1 8NMSU 15 .44 18 .16 2.7 2NYU 36.93 41 .18 4 .2 2PARAMAX 23.09 27 .77 4.68PRC 23.29 26 .89 3 .60SRA 22.96 28 .13 5 .1 7SRI 42 .53 47 .68 5 .1 5UMASS 43 .03 47 .34 4 .3 1UMICH 33 .00 39 .78 6 .78Figure 5 : Effect of Free-Floating Object Scores8 2META SLOT POS ACT COR PAR INC MIS SPU REC PRE OVG PR 2PR P2Rinstrument sperpetrator stargetsincidents5 213721 61145 311 826 912346 213 988000000001 87 57 726195613 0346 5456477645352723 64 74 82864 .5 048 .6757 .3874 .4264 .2 051 .1 854 .0372 .9564 .8 046 .4061 .1 875 .95TOTAL 519 562 323 0 0 196 239 62 57 43 59 .39 57 .93 60 .93OBJECT TOT POS ACT COR PAR INC MIS SPU REC PRE OVG PR 2PR P2RPHYS-TGT 247 269 101 4 11 131 153 42 38 57 39 .90 38 .74 41 .1 3HUM-TGT 609 679 353 19 26 211 281 60 53 41 56 .28 54 .27 58 .4 6INSTRUMENT 85 89 52 7 0 26 30 65 62 34 63 .46 62 .58 64 .3 8PERP-ORG 103 85 36 1 8 58 40 35 43 47 38 .59 41 .12 36 .3 5PERP-INDIV 85 75 34 5 0 46 36 43 49 48 45 .80 47 .67 44 .0 8INCIDENT 521 558 324 47 23 127 164 67 62 29 64 .40 62 .94 65 .9 4TOTAL 1650 1755 900 83 68 599 704 57 54 40 55 .46 54 .57 56 .3 7FF-OBJECT TOT POS ACT COR PAR INC MIS SPU REC PRE OVG PR 2PR P2RPHYS-TGT 276 269 129 4 15 128 121 47 49 45 47 .98 48 .59 47 .3 9HUM-TGT 638 679 381 22 29 206 247 61 58 36 59 .46 58 .58 60 .3 8INSTRUMENT87 89 54 8 0 25 27 67 65 30 65 .98 65 .39 66 .59PERP-ORG 117 85 40 1 10 66 34 35 48 40 40 .48 44 .68 37 .0 0PERP-INDIV 93 75 39 6 0 48 30 45 56 40 49 .90 53 .39 46 .8 4INCIDENT 535 558 354 46 21 114 137 70 68 25 68 .99 68 .39 69 .5 9TOTAL 1746 1755 997 87 75 587 596 60 59 34 59 .50 59 .20 59 .8 0PSUEDO TOT POS ACT COR PAR INC MIS SPU REC PRE OVG PR 2PR P2Rinc-total 539 574 339 57 21 0 20 157 122 209 68 64 2 7perp-total 258 233 113 7 22 5 6 91 116 271 45 50 3 9phys-tgt-total 249 269 95 15 23 5 10 136 116 628 41 38 5 0hum-tgt-total 615 693 342 64 34 18 55 253 175 516 61 54 36Figure 6 : Sample Object Totals for GE Syste min the next section .DISCUSSIO NOne of the advantages of object-oriented scoring is that it is possible to obtain object alignment totals, an dobject matching totals .
Figure 6 illustrates this type of data for our system on MUC-3 (a description of ou rsystem and a summary of our performance can be found in this volume) .
The META SLOT table contains ameasurement of how well our system aligned objects .The OBJECT-TOT table is useful to compare the totals for object matches when objects that appear indifferent templates are not scored, with the FF-OBJECT TOT table which presents the "free-floating" objec ttotals, allowing for matches between unaligned objects that appear in incorrect templates to contribute t orecall and precision .
The PSEUDO TOT table gives the pseudo-object numbers presented at the bottom of ourscore report for comparison .FUTURE WORKOne benefit of object-oriented design is that there can be only one representation of each unique object .
Thisrepresentation can be pointed to by a variety of slots .
This allows for credit to be assigned once for eac hmatching object, with separate credit assigned for attaching the object correctly in whichever relationship s8 3it participates in .Primarly to ensure that the total number of points in this adjunct test was comparable to the the tota lnumber of points in the official scores, we did not make objects unique .
However we believe that assignin gcredit for extracting information from an object once would increase the accuracy of the evaluation.SUMMARYThis paper has reported on an adjunct test performed in connection with MUC-4 to investigate the utilit yand issues involved in object-oriented template design and scoring.
We have shown that an object-oriente ddesign, even when modified to enforce partial string matching as the criterion for object alignment, doe snot significantly alter the MUC-4 scores .
Object-oriented design is a more intuitive method of representin ginformation that is related .
Moreover, objects can be aligned, allowing for object-level scoring.
This increase sthe usefulness of an automated scoring program to perform selective diagnosis for performance evaluation.Also, object-oriented alignment allows for the scoring of objects that match even when they are placed i nan incorrect template.
This yields a more accurate evaluation of performance than scoring all the slots of amisplaced object as missing and spurious .84PART II: TEST RESULTS AND ANALYSI S(SITE REPORTS)The papers in this section were prepared by each of the sites that complete dthe MUC-4 evaluation .
The papers are intended to provide the reader with som econtext for interpreting the test results, which are presented more fully i nappendices G and H of the proceedings .
The sites were asked to comment on thefollowing aspects of their MUC-4 experience :* Explanation of test settings (precision/recall/overgeneration)and how these settings were chosen* Where bulk of effort was spent, and how much time was spen toverall on MUC- 4* What the limiting factor was (time, people, CPU cycles ,knowledge, .
.
.
)* How the training of the system was doneWhat proportion of the training data was used (and how )Whether/Why/How the system improved over time, an dhow much of the training was automate d* What was successful and what wasn't, and what system moduleyou would most like to rewrit e* What portion of the system is reusable on a different applicatio n* What was learned about the system, about a MUC-like task ,about evaluation
