Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 346?355,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsClustering-based Stratified Seed Sampling for Semi-Supervised RelationClassificationLonghua Qian Guodong ZhouNatural Language Processing Lab Natural Language Processing LabSchool of Computer Science and Technology School of Computer Science and TechnologySoochow University Soochow University1 Shizi Street, Suzhou, China 215006 1 Shizi Street, Suzhou, China 215006qianlonghua@suda.edu.cn gdzhou@suda.edu.cnAbstractSeed sampling is critical in semi-supervisedlearning.
This paper proposes a clustering-based stratified seed sampling approach tosemi-supervised learning.
First, various clus-tering algorithms are explored to partition theunlabeled instances into different strata witheach stratum represented by a center.
Then,diversity-motivated intra-stratum sampling isadopted to choose the center and additionalinstances from each stratum to form the unla-beled seed set for an oracle to annotate.
Fi-nally, the labeled seed set is fed into abootstrapping procedure as the initial labeleddata.
We systematically evaluate our stratifiedbootstrapping approach in the semantic rela-tion classification subtask of the ACE RDC(Relation Detection and Classification) task.In particular, we compare various clusteringalgorithms on the stratified bootstrapping per-formance.
Experimental results on the ACERDC 2004 corpus show that our clustering-based stratified bootstrapping approachachieves the best F1-score of 75.9 on the sub-task of semantic relation classification, ap-proaching the one with golden clustering.1 IntroductionSemantic relation extraction aims to detect andclassify semantic relationships between a pair ofnamed entities occurring in a natural language text.Many machine learning approaches have been pro-posed to attack this problem, including supervised(Miller et al, 2000; Zelenko et al, 2003; Culottaand Soresen, 2004; Kambhatla, 2004; Zhao andGrishman, 2005; Zhou et al, 2005; Zhang et al,2006; Zhou and Zhang, 2007; Zhou et al, 2007;Qian et al, 2008; Zhou et al, 2010), semi-supervised (Brin, 1998; Agichtein and Gravano,2000; Zhang, 2004; Chen et al, 2006; Qian et al,2009; Zhou et al, 2009), and unsupervised meth-ods (Hasegawa et al, 2004; Zhang et al, 2005;Chen et al, 2005).Current work on relation extraction mainlyadopts supervised learning methods, since theyachieve much better performance.
However, theynormally require a large number of manually la-beled relation instances, whose acquisition is bothtime consuming and labor intensive.
In contrast,unsupervised methods do not need any manuallylabeled instances.
Nevertheless, it is difficult toassess their performance due to the lack of evalua-tion criteria.
As something between them, semi-supervised learning has received more and moreattention recently.
With the plenitude of unlabelednatural language text at hand, semi-supervisedlearning can significantly reduce the need for la-beled data with only limited sacrifice in perform-ance.
For example, Abney (2002) proposes abootstrapping algorithm which chooses the unla-beled instances with the highest probability of be-ing correctly labeled and add them in turn into thelabeled training data iteratively.This paper focuses on bootstrapping-based semi-supervised learning in relation extraction.
Since theperformance of bootstrapping depends much on thequality and quantity of the seed set and researcherstend to employ as few seeds as possible (e.g.
100instances) to save time and labor, the quality of theseed set plays a critical role in bootstrapping.
Fur-thermore, the imbalance of different classes and346the inherent structural complexity of instances willseverely weaken the strength of bootstrapping andsemi-supervised learning as well.
Therefore, it iscritical for a bootstrapping procedure to select anappropriate seed set, which should be representa-tive and diverse.
However, most of current semi-supervised relation extraction systems (Zhang,2004; Chen et al, 2006) use a random seed sam-pling strategy, which fails to fully exploit the affin-ity nature in the training data to derive the seed set.Alternatively, Zhou et al (2009) bootstrap a set ofweighted support vectors from both labeled andunlabeled data using SVM and feed these instancesinto semi-supervised relation extraction.
However,their seed set is sequentially generated only to en-sure that there are at least 5 instances for each rela-tion class.
Our previous work (Qian et al, 2009)attempts to solve this problem via a simple strati-fied sampling strategy for selecting the seed set.Experimentation on the ACE RDC 2004 corpusshows that the stratified sampling strategy achievespromising results for semi-supervised learning.Nevertheless, the success of the strategy relies onthe assumption that the true distribution of all rela-tion types is already known, which is impracticalfor real NLP applications.This paper presents a clustering-based stratifiedseed sampling approach for semi-supervised rela-tion extraction, without the assumption on the truedistribution of different relation types.
The motiva-tions behind our approach are that the unlabeleddata can be partitioned into a number of strata us-ing a clustering algorithm and that representativeand diverse seeds can be derived from such stratain the framework of stratified sampling (Neyman,1934) for an oracle to annotate.
Particularly, weemploy a diversity-motivated intra-stratum sam-pling scheme to pick a center and additional in-stances as seeds from each stratum.
Experimentalresults show the effectiveness of the clustering-based stratified seed sampling for semi-supervisedrelation classification.The rest of this paper is organized as follows.First an overview of the related work is given inSection 2.
Then, Section 3 introduces the stratifiedbootstrapping framework including an intra-stratum sampling scheme while Section 4 describesvarious clustering algorithms.
The experimentalresults on the ACE RDC 2004 corpus are reportedin Section 5.
Finally we conclude our work andindicate some future directions in Section 6.2 Related WorkIn semi-supervised learning for relation extraction,most of previous work construct the seed set eitherrandomly (Zhang, 2004; Chen et al, 2006) or se-quentially (Zhou et al, 2009).
Qian et al (2009)adopt a stratified sampling strategy to select theseed set.
However, their method needs a stratifica-tion variable such as the known distribution of therelation types, while our method uses clustering todivide relation instances into different strata.In the literature, clustering techniques have beenemployed in active learning to sample representa-tive seeds in a certain extent (Nguyen andSmeulders, 2004; Tang et al, 2002; Shen et al,2004).
Our work is similar to the formal frame-work, as proposed in Nguyen and Smeulders(2004), in which K-medoids clustering is incorpo-rated into active learning.
The cluster centers areused to construct a classifier and which in turnpropagates classification decision to other exam-ples via a local noise model.
Unlike their probabil-istic models, we apply various clusteringalgorithms together with intra-stratum sampling toselect a seed set in discriminative models likeSVMs.
In active learning for syntactic parsing,Tang et al (2002) employ a sampling strategy of?most uncertain per cluster?
to select representa-tive examples and weight them using their clusterdensity, while we pick a few seeds (the number ofthe sampled seeds is proportional to the clusterdensity) from a cluster in addition to its center.Shen et al (2004) combine multiple criteria tomeasure the informativeness, representativeness,and diversity of examples in active learning fornamed entity recognition.
Unlike our samplingstrategy of clustering for representativeness andstratified sampling for diversity, they either selectcluster centroids or diverse examples from a pre-chosen set in terms of some combined metrics.
Tothe best of our knowledge, this is the first work toaddress the issue of seed selection using clusteringtechniques for semi-supervised learning with dis-criminative models.3 Stratified Bootstrapping FrameworkThe stratified bootstrapping framework consists ofthree major components: an underlying supervisedlearner and a bootstrapping algorithm on top of it347as usual, plus a clustering-based stratified seedsampler.3.1 Underlying Supervised LearnerDue to recent success in tree kernel-based relationextraction, this paper adopts a tree kernel-basedmethod in the underlying supervised learner.
Fol-lowing the previous work in relation extraction(Zhang et al, 2006; Zhou et al, 2007; Qian et al,2008), we use the standard convolution tree kernel(Collins and Duffy, 2001) to count the number ofcommon sub-trees as the structural similarity be-tween two parse trees.
Besides, to properly repre-sent a relation instance, this paper adopts theUnified Parse and Semantic Tree (UPST), as pro-posed in Qian et al (2008).
To our knowledge, theUSPT has achieved the best performance in rela-tion extraction so far on the ACE RDC 2004 cor-pus.In particular, we use the SVMlight-TK1 packageas our classifier.
Since the package is a binary clas-sifier, we adapt it to the multi-class tasks of rela-tion extraction by applying the one vs. othersstrategy, which builds K binary classifiers so as toseparate one class from all others.
The final classi-fication decision of an instance is determined bythe class that has the maximal SVM output margin.3.2 Bootstrapping AlgorithmFollowing Zhang (2004), we have developed abaseline self-bootstrapping procedure, which keepsaugmenting the labeled data by employing themodels trained from previously available labeleddata, as shown in Figure 1.Since the SVMlight-TK package doesn?t outputany probability that it assigns to the class label onan instance, we devise a metric to measure the con-fidence with regard to the classifier?s prediction.Given a sequence of output margins of all K binaryclassifiers at some iteration, denoted as{m1,m2,?mK} with mi the margin for the i-th clas-sifier, we compute the margin gap between thelargest and the mean of the others, i.e.)1/()max(max111???====?
KmmmH KiiKiiiKi(1)Where K denotes the total number of relationclasses, and mi denotes the output margin of the i-1 http://ai-nlp.info.uniroma2.it/moschitti/Require: labeled seed set LRequire: unlabeled data set URequire: batch size SRepeatTrain a single classifier on LRun the classifier on UFind at most S instances in U that the classifier hasthe highest prediction confidenceAdd them into LUntil: no data points available or the stoppagecondition is reachedAlgorithm self-bootstrappingFigure 1: Self-bootstrapping algorithmth classifier.
Intuitively, the bigger the H, thegreater the difference between the maximal marginand all others, and thus the more reliably the classi-fier makes the prediction on the instance.3.3 Clustering-based Stratified Seed SamplerStratified sampling is a method of sampling instatistics, in which the members of a population aregrouped into relatively homogeneous subgroups(i.e.
strata) according to one certain property, andthen a sample is selected from each stratum.
Thisprocess of grouping is called stratification, and theproperty on which the stratification is performed iscalled the stratification variable.
Previous workjustifies theoretically and practically that stratifiedsampling is more appropriate than random sam-pling for general use (Neyman, 1934) as well as forrelation extraction (Qian et al, 2009).
However,the difficulty lies in how to find the appropriatestratification variable for complicated tasks, suchas relation extraction.The idea of clustering-based stratification cir-cumvents this problem by clustering the unlabeleddata into a number of strata without the need toexplicitly specify a stratification variable.
Figure 2illustrates the clustering-based stratified seed sam-pling strategy employed in the bootstrapping pro-cedure, where RSET denotes the whole unlabeleddata, SeedSET the seed set to be labeled and|RSETi| the number of instances in the i-th cluster2RSETi.
Here, a relation instance is represented us-ing USPT and the similarity between two instancesis computed using the standard convolution tree2 Hereafter, when we refer to clusters from the viewpoint ofstratified sampling, they are often called ?strata?.348kernel, as described in Section 3.1 (i.e., both theclustering and the classification adopt the samestructural representation, since we want the repre-sentative seeds in the clustering space to be alsorepresentative in the classification space).
Afterclustering, a certain number of instances fromevery stratum are sampled using an intra-stratumscheme (c.f.
Subsection 3.4).
Normally, this num-ber is proportional to the size of that stratum in thewhole data set.
However, in case this number is 0due to the rounding of real numbers, it is set to 1 toensure the existence of at least one seed from thatstratum.
Furthermore, to ensure that the total num-ber of instances being sampled equals the pre-scribed NS, the number of seeds from dominantstrata may be slightly adjusted accordingly.
Finally,these instances form the unlabeled seed set for anoracle to annotate as the input to the underlyingsupervised learner in the bootstrapping procedure.3.4 Intra-stratum samplingGiven the distribution of clusters, a simple way toselect the most representative instances is tochoose the center of each cluster with the clusterprior as the weight of the center (Tang et al, 2002;Nguyen and Smeulders, 2004).
Nevertheless, forthe complicated task of relation extraction on theACE RDC corpora, which is highly skewed acrossdifferent relation classes, only considering the cen-ter of each cluster would severely under-representthe high-density data.
To overcome this problem,we adopt a sampling approach, in particular strati-fied sampling, which takes the size of each stratuminto consideration.Given the size of the seed set NS and the numberof strata K, a natural question will arise as how toselect the remaining (NS-K) seeds after we haveextracted the K centers from the K strata.
We viewthis problem as intra-stratum sampling, which isrequired to choose the remaining number of seedsfrom inside individual stratum (excluding the cen-ters themselves).At the first glance, sampling a certain number ofseeds from one particular stratum (e.g., RSETi),seems to be the same sampling problem as we haveencountered before, which aims to select the mostrepresentative and diverse seeds.
This will natu-rally lead to another application of a clustering al-gorithm to the stratification of the stratum RSETi.Require: RSET ={R1,R2,?,RN}, the set of unlabeledrelation instances and K, the number of strata beingclusteredOutput: SeedSET with the size of NS (100)ProcedureInitialize SeedSET = NULLCluster RSET into K strata using a clusteringalgorithm and perform stratum pruning ifnecessary.Calculate the number of instances being sampledfor each stratum i={1,2,?,K}Sii NNRSETN ?= ||    (2)and adjust this number if necessary.Perform intra-strata sampling to form SeedSETifrom each stratum RSETi, by selecting the centerCi and (Ni-1) additional instancesGenerate SeedSET by summating RSETi from eachstratumFigure 2: Clustering-based stratified seed samplingNevertheless, remember the fact that, this time forthe stratum RSETi, the center Ci has been chosen,so it may not be reasonable to extract additionalcenters in this way.
Therefore, in order to avoidrecursion and over-complexity, we employ a diver-sity-motivated intra-stratum sampling scheme(Shen et al, 2004), called KDN (K-diverseneighbors), which aims to maximize the trainingutility of all seeds from a stratum.
The motivationis that we prefer the seeds with high variance toeach other, thus avoiding repetitious seeds from asingle stratum.
The basic idea is to add a candidateinstance to the seed set only if it is sufficiently dif-ferent from any previously selected seeds, i.e., thesimilarity between the candidate instance and anyof the current seeds is less than a threshold ?.
Inthis paper, the threshold ?
is set to the averagepair-wise similarity between any two instances in astratum.4 Clustering AlgorithmsThis section describes several typical clusteringalgorithms in the literature, such as K-means, HAC,spectral clustering and affinity propagation, as wellas their application in this paper.4.1 K-medoids (KM)As a simple yet effective clustering method, the K-means algorithm assigns each instance to the clus-ter whose center (also called centroid) is nearest.
In349particular, the center is the average of all the in-stances in the cluster, i.e., with its coordinates thearithmetic means for each dimension separatelyover all the instances in the cluster.One problem with K-means is that it does notyield the same result with each run while the otherproblem is the requirement for the concept of amean to be definable, which is unfortunately notavailable in our setting (we employ a parse treerepresentation for a relation instance).
Hence, weadopt a variant of K-means, namely, K-medoids,where a medoid, rather than a centroid, is definedas a representative of a cluster.
Besides, K-medoids has proved to be more robust to noise andoutliers in comparison with K-means.4.2 Hierarchical Agglomerative Clustering(HAC)Different from K-medoids, hierarchical clusteringcreates a hierarchy of clusters which can berepresented in a tree structure called a dendrogram.The root of the tree consists of a single clustercontaining all objects, and the leaves correspond toindividual object.Typically, hierarchical agglomerative clustering(HAC) starts at the leaves and successively mergestwo clusters together as long as they have theshortest distance among all the pair-wise distancesbetween any two clusters.Given a specified number of clusters, the keyproblem is to determine where to cut the hierarchi-cal tree into clusters.
In this paper, we generate thefinal flat cluster structures greedily by maximizingthe equal distribution of instances among differentclusters.4.3 Spectral Clustering (SC)Spectral clustering has become more and morepopular recently.
Taking as input a similaritymatrix between any two instances, spectralclustering makes use of the spectrum of thesimilarity matrix of the data to performdimensionality reduction for clustering in fewerdimensions.Compared to the ?traditional algorithms?
suchas K-means or HAC, spectral clustering has manyfundamental advantages.
Results obtained byspectral clustering often outperform the traditionalapproaches.
Furthermore, spectral clustering isvery simple to implement and can be solvedefficiently using standard linear algebra methods(von Luxburg, 2006).4.4 Affinity Propagation (AP)As a new emerging clustering algorithm, affinitypropagation (AP) (Frey and Dueck, 2007) is basi-cally an iterative message-passing procedure inwhich the instances being clustered compete toserve as cluster exemplars by exchanging twotypes of messages, namely, ?responsibility?
and?availability?.
After the procedure converges orhas repeated a finite number of iterations, eachcluster is represented by an exemplar.
AP was re-ported to find clusters with much lower error thanthose found by other methods.For our application, affinity propagation takes asinput a similarity matrix, whose elements representeither the similarity between two different in-stances or the preference (a real number p) for aninstance when two instances are the same.
Oneproblem with AP is that the number of clusterscannot be pre-defined, which is indirectly deter-mined by the preference as well as the convergenceprocedure itself.5 ExperimentationThis section systematically evaluates the boot-strapping approach using clustering-based strati-fied seed sampling, in the relation classification(i.e., given the relationship already detected) sub-task of relation extraction on the ACE RDC 2004corpus.5.1 Experimental SettingThe ACE RDC 2004 corpus 3  is gathered fromvarious newspapers, newswire and broadcasts.
Itcontains 451 documents and 5702 positive relationinstances of 7 relation types and 23 subtypes be-tween 7 entity types.
For easy reference with re-lated work in the literature, evaluation is done on347 documents (from nwire and bnews domains),which include 4305 relation instances.
Table 1 liststhe major relation types and subtypes, includingtheir corresponding instance numbers and ratios inour evaluation set.
One obvious observation fromthe table is that the numbers of different relationtypes is highly imbalanced.
These 347 documentsare then divided into 3 disjoint sets randomly, with3 http//www.ldc.upenn.edu/ Projects/ACE/350Types Subtypes # %Located 738 17.1Near 87 2.0 PHYSPart-Whole 378 8.8Business 173 4.0Family 121 2.8 PER-SOCOther 55 1.3Employ-Executive 489 11.4Employ-Staff 539 12.5Employ-Undeter.
78 1.8Member-of-Group 191 4.4Subsidiary 206 4.8Partner 12 0.3EMP-ORGOther 80 1.9User-or-Owner 200 4.6Inventor-or-Man.
9 0.2 ARTOther 2 0.0Ethnic 39 0.9Ideology 48 1.1 OTHER-AFFOther 54 1.3Citizen-or-Resid.
273 6.3Based-In 215 5.0 GPE-AFFOther 39 0.9DISC   279 6.5Total   4305 100.0Table 1: Relation types and their corresponding instancenumbers and ratios in the ACE RDC 2004 corpus10% of them (35 files, around 400 instances) heldout as the test data set, 10% of them (35 files,around 400 instances) used as the developmentdata set to fine-tune various settings and parame-ters, while the remaining 277 files (over 3400 in-stances) used as the training data set, from whichthe seed set will be sampled.The corpus is parsed using Charniak?s parser(Charniak, 2001) and relation instances are gener-ated by extracting all pairs of entity mentions oc-curring in the same sentence with positiverelationships.
For easy comparison with relatedwork, we only evaluate the relation classificationtask on the 7 major relation types of the ACE RDC2004 corpus.
For the SVMlight-TK classifier, thetraining parameters C (SVM) and ?
(tree kernel)are fine-tuned to 2.4 and 0.4 respectively.The performance is measured using the standardP/R/F1 (Precision/Recall/F1-measure).
For eachrelation type, P is the ratio of the true relation in-stances in all the relation instances being identified,R is the ratio of the true relation instances beingidentified in all the true relation instances in thecorpus, and F1 is the harmonic mean of P and R.The overall performance P/R/F1 is then calculatedusing the micro-average measure over all majorclass types.5.2 Experimental ResultsComparison of various seed sampling strategieswithout intra-stratum sampling on the devel-opment dataTable 2 compares the performance of bootstrap-ping-based relation classification using variousseed sampling strategies without intra-stratumsampling on the development data.
Here, the sizeof the seed set L is set to 100, and the top 100 in-stances with the highest confidence (c.f.
Formula 1)are augmented at each iteration.
For samplingstrategies marked with an asterisk, we performed10 trials and calculated their averages.
Since forthese strategies the seed sets sampled from differ-ent trials may be quite different, their performancescores vary in a great degree accordingly.
This ex-perimental setting and notation are also used in allthe subsequent experiments unless specified.
Be-sides, two additional baseline sampling strategiesare included for comparison: sequential sampling(SEQ), which selects a sequentially-occurring Linstances as the seed set, and random sampling(RAND), which randomly selects L instances asthe seed set.Table 2 shows that1) RAND outperforms SEQ by 1.2 units in F1-score.
This is due to the fact that the seed setvia RAND may better reflect the distribution ofthe whole training data than that via SEQ, nev-ertheless at the expense of collecting the wholetraining data in advance.2) While HAC performs moderately better thanRAND, it is surprising that both KM and APperform even worse than SEQ, and that SC per-forms worse than RAND.
Furthermore, all thefour clustering-based seed sampling strategiesachieve much smaller performance improve-ment in F1-score than RAND, among whichKM performs worst with performance im-provement of only 0.1 in F1-score.351Samplingstrategies P(?P) R(?R) F1(?F1)RAND* 69.1(3.1) 66.4(0.2) 67.8(2.0)SEQ* 65.8(2.6) 68.0(0.1) 66.6(1.3)KM* 62.0(0.9) 61.0(-0.5) 61.3(0.1)HAC 69.9(1.3) 70.4(0.4) 70.1(0.8)SC* 67.1(1.5) 68.1(0.0) 67.5(0.8)AP 66.6(2.0) 66.2(0.1) 66.4(1.1)Table 2: Comparison of various seed sampling strate-gies without intra-stratum sampling on the developmentdata3) All the performance improvements from boot-strapping largely come from the improvementsin precision.
While the bootstrapping proceduremakes the SVM classifier more accurate, itlacks enough generalization ability.To explain above special phenomena, we have alook at the clustering results.
Our inspection re-veals that most of them are severely imbalanced,i.e., some clusters are highly dense while others areextremely sparse.
This indicates that merely select-ing the centers from each cluster cannot properlyrepresent the overall distribution.
Moreover, thecenters with high density lack the generalizationability due to its solitude in the cluster, leading toless performance enhancement than expected.The only exception is HAC, which much outper-forms RAND by 2.3 in F1-score, although HAC isusually not considered as an effective clusteringalgorithm.
The reason may be that HAC creates ahierarchy of clusters in the top-down manner bycutting a cluster into two.
Therefore, the centers inthe two sibling clusters will be closer to each otherthan they are to the centers in other clusters.
Be-sides, the final flat cluster structures given a spe-cial number of clusters are generated greedily fromthe cluster hierarchy by maximizing the equal dis-tribution of instances among different clusters.
Inother words, when the cluster number reaches acertain threshold, the dense area will get moreseeds represented in the seed set.
As a consequence,the distribution of all the seeds sampled by HACwill approximate the distribution of the wholetraining data in some degree, while the seeds sam-pled by other clustering algorithm are kept as far aspossible due to the objective of clustering and thelack of intra-stratum sampling.These observations also justify the applicationof the stratified seed sampling to the bootstrappingprocedure, which enforces the number of seedssampled from a cluster to be proportional to itsdensity, presumably approximated by its size inthis paper.Comparison of different cluster numbers withintra-stratum sampling on the developmentdataIn order to fine-tune the optimal cluster numbersfor seed sampling, we compare the performance ofdifferent numbers of clusters for each clusteringalgorithm on the development data set and reporttheir F-scores in Table 3.
For reference, we alsolist the F-score for golden clustering (GOLD), inwhich all instances are grouped in terms of theirannotated ground relation major types (7), majortypes considering relation direction (13), subtypes(23), and subtypes considering direction (38).
Be-sides, the performance of clustering-based semi-supervised relation classification is also measuredover other typical cluster numbers (i.e., 1, 50, 60,80, 100).
Particularly, when the cluster numberequals 1, it means that only diversity other thanrepresentativeness is considered in the seed sam-pling.
Among these clustering algorithms, one ofthe distinct characteristics with the AP algorithm isthat the number of clusters cannot be specified inadvance, rather, it is determined by the pre-definedpreference parameter (c.f.
Subsection 4.4).
There-fore, we should tune the preference parameter so asto get the pre-defined cluster number.
However,sometimes we still couldn?t get the exact numberof clusters as we expected.
In these cases, we usethe approximate cluster numbers for AP instead.Table 3 shows that1) The performance for all the clustering algo-rithms varies in some degree with the numberof clusters being grouped.
Interestingly, theperformance with only one cluster is betterthan those of clustering-based strategies with100 clusters, at most cases.
This implies thatthe diversity of the seeds is at least as impor-tant as their representativeness.
And this couldbe further explained by our observation that,with the increase of cluster numbers, the clus-ters get smaller and denser while their centersalso come closer to each other.
Therefore, therepresentativeness and diversity as well as thedistribution of the seeds sampled from themmay vary accordingly, leading to different per-formance.352# ofClusters GOLD KM* HAC SC* AP1 -  68.7  68.7  - -7 73.9 70.3  73.3 72.1 -13 70.2 68.9  70.3 67.3 -23 64.9 72.3  72.9 68.9 71.138 60.8 69.9  71.6 68.0 71.650 - 68.5  69.9 68.5 70.460 - 66.3  68.5 68.6 69.780 - 64.2  65.9 68.0 68.1100 - 61.3  70.1 67.5 66.4Table 3: Performance in F1-score over different clusternumbers with intra-stratum sampling on the develop-ment data2) Golden clustering achieves the best performanceof 73.9 in F1-score when the cluster number isset to 7, significantly higher than the perform-ance using other cluster numbers.
Interestingly,this number coincides with the number of majorrelation types needed to be classified in our task.This is reasonable since the instances with thesame relation type should be much more similarthan those with different relation types and it iseasy to discriminate the seed set of one relationtype from that of other relation types.3) Among the four clustering algorithms, HACachieves best performance over most of clusternumbers.
This further verifies the aforemen-tioned analysis.
That is, as a hierarchical clus-tering algorithm, HAC can sample seeds thatbetter capture the distribution of the trainingdata.4) For KM, the best performance is achievedaround the number of 23 while for both HACand SC, the optimal cluster number is consis-tent with GOLD clustering, namely, 7.
For AP,the optimal cluster number for AP is 38.
This islargely due to that we fail to cluster the trainingdata into about 7 and 13 groups no matter howwe vary the preference parameter.Final comparison of different clustering algo-rithms on the held-out test dataAfter the optimal cluster numbers are determinedfor each clustering algorithm, we apply these num-bers on the held-out test data and report the per-formance results (P/R/F1 and their respectiveimprovements) in Table 4.
For easy reference, wealso include the performance for GOLD, RAND,and SEQ sampling strategies.Samplingstrategies P(?P) R(?R) F1(?F1)GOLD 79.5(7.8) 72.7(2.1) 76.0(4.8)RAND* 71.9(3.7) 69.7(0.1) 70.8(1.8)SEQ* 71.9(2.6) 65.2(0.1) 69.3(1.3)KM* 73.6(2.1) 72.3(0.3) 72.9(1.2)HAC 79.0(10.2) 73.0(1.1) 75.9(5.6)SC* 72.3(2.1) 72.1(0.4) 72.2(1.2)AP 75.7(2.5) 72.0(0.4) 73.7(1.4)Table 4: Performance of various clustering-based seedsampling strategies on the held-out test data with theoptimal cluster number for each clustering algorithmTable 4 shows that1) Among all the clustering algorithms, HACachieves the best F1-score of 75.9, significantlyhigher than RAND and SEQ by 5.1 and 6.6 re-spectively.
The improvement comes not onlyfrom significant precision boost, but also frommoderate recall increase.
This further justifiesthe merits of HAC as a clustering algorithm forstratified seed sampling in semi-supervised re-lation classification.2) HAC approaches the best F1-score of 76.0 forgolden clustering.
Obviously, this doesn?t meanHAC performs as well as golden clustering interms of clustering quality measures, rather itdoes imply that HAC achieves the performanceimprovement by making the seed set better rep-resent the overall distribution over inherentstructure of relation instances, while goldenclustering accomplishes this using the distribu-tion over relation types.
Since the distributionover relation types doesn?t always conform tothat over instance structures, and for a statisticaldiscriminative classifier, often the latter is moreimportant than the former, it will be no surpriseif HAC outperforms golden clustering in somereal applications, e.g.
clustering-based stratifiedsampling.6 Conclusion and Future WorkThis paper presents a stratified seed samplingstrategy based on clustering algorithms for semi-supervised learning.
Our strategy does not rely onany stratification variable to divide the traininginstances into a number of strata.
Instead, the strataare formed via clustering, given a metric measur-ing the similarity between any two instances.
Fur-ther, diversity-motivated intra-strata sampling is353employed to sample additional instances fromwithin each stratum besides its center.
We comparethe effect of various clustering algorithms on theperformance of semi-supervised learning and findthat HAC achieves the best performance since thedistribution of its seed set better approximates thatof the whole training data.
Extensive evaluation onthe ACE RDC 2004 benchmark corpus shows thatour clustering-based stratified seed sampling strat-egy significantly improves the performance ofsemi-supervised relation classification.We believe that our clustering-based stratifiedseed sampling strategy can not only be applied toother semi-supervised learning tasks, but also canbe incorporated into active learning, where the in-stances to be labeled at each iteration as well as theseed set could be selected using clustering tech-niques, thus further reducing the amount of in-stances needed to be annotated.For the future work, it is possible to adapt ourone-level clustering-based sampling to the multi-level one, where for every stratum it is still possi-ble to divide it into lower sub-strata for furtherstratified sampling in order to make the seeds bet-ter represent the true distribution of the data.AcknowledgmentsThis research is supported by Projects 60873150,60970056, and 90920004 under the National Natu-ral Science Foundation of China.ReferencesS.
Abney.
2002.
Bootstrapping.
ACL-2002.E.
Agichtein and L. Gravano.
2000.
Snowball: Extract-ing relations from large plain-text collections.
InProceedings of the 5th ACM international Conferenceon Digital Libraries (ACMDL 2000).S.
Brin.
1998.
Extracting patterns and relations from theworld wide web.
In WebDB Workshop at 6th Interna-tional Conference on Extending Database Technol-ogy (EDBT 98).E.
Charniak.
2001.
Intermediate-head Parsing for Lan-guage Models.
ACL-2001: 116-123.M.
Collins and N. Duffy.
2001.
Convolution Kernels forNatural Language.
NIPS 2001: 625-632.J.X.
Chen, D.H. Ji, C.L.
Tan, and Z.Y.
Niu.
2005.
Un-supervised Feature Selection for Relation Extraction.CIKM-2005: 411-418.J.X.
Chen, D.H. Ji, and C. L. Tan.
2006.
Relation Ex-traction using Label Propagation Based Semi super-vised Learning.
ACL/COLING-2006: 129-136.A.
Culotta and J. Sorensen.
2004.
Dependency tree ker-nels for relation extraction.
ACL-2004: 423-439.B.J.
Frey and D. Dueck.
2007.
Clustering by PassingMessages between Data Points.
Science, 315: 972-976.T.
Hasegawa, S. Sekine, and R. Grishman.
2004.
Dis-covering Relations among Named Entities fromLarge Corpora.
ACL-2004.N.
Kambhatla.
2004.
Combining lexical, syntactic andsemantic features with Maximum Entropy models forextracting relations.
ACL-2004(posters): 178-181.S.
Miller, H. Fox, L. Ramshaw, and R. Weischedel.2000.
A novel use of statistical parsing to extract in-formation from text.
In Proceedings of the 6th Ap-plied Natural Language Processing Conference.J.
Neyman.
1934.
On the Two Different Aspects of theRepresentative Method: The Method of StratifiedSampling and the Method of Purposive Selection.Journal of the Royal Statistical Society, 97(4): 558-625.H.T.
Nguyen and A. Smeulders.
2004.
Active LearningUsing Pre-clustering, ICML-2004.L.H.
Qian, G.D. Zhou, Q.M.
Zhu, and P.D.
Qian.
2008.Exploiting constituent dependencies for tree kernel-based semantic relation extraction.
COLING-2008:697-704.L.H.
Qian, G.D. Zhou, F. Kong, and Q.M.
Zhu.
2009.Semi-Supervised Learning for Semantic RelationClassification using Stratified Sampling Strategy.EMNLP-2009: 1437-1445.D.
Shen, J. Zhang, J. Su, G. Zhou and C. Tan.
2004.Multi-criteria-based active learning for named entityrecognition.
ACL-2004.M.
Tang, X. Luo and S. Roukos.
2002.
Active Learningfor Statistical Natural Language Parsing.
ACL-2002.U.
von Luxburg.
2006.
A tutorial on spectral clustering.Technical report, Max Planck Institute for BiologicalCybernetics.D.
Zelenko, C. Aone, and A. Richardella.
2003.
KernelMethods for Relation Extraction.
Journal of MachineLearning Research, (2): 1083-1106.M.
Zhang, J. Su, D. M. Wang, G. D. Zhou, and C. L.Tan.
2005.
Discovering Relations between NamedEntities from a Large Raw Corpus Using Tree Simi-larity-Based Clustering.
IJCNLP-2005: 378-389.M.
Zhang, J. Zhang, J. Su, and G.D. Zhou.
2006.
AComposite Kernel to Extract Relations between Enti-ties with both Flat and Structured Features.ACL/COLING-2006: 825-832.Z.
Zhang.
2004.
Weakly-supervised relation classifica-tion for Information Extraction.
CIKM-2004.S.B.
Zhao and R. Grishman.
2005.
Extracting relationswith integrated information using kernel methods.ACL-2005: 419-426.354G.D.
Zhou, J. Su, J. Zhang, and M. Zhang.
2005.
Ex-ploring various knowledge in relation extraction.ACL-2005: 427-434.G.D.
Zhou, L.H.
Qian, and J.X.
Fan.
2010.
Tree kernel-based semantic relation extraction with rich syntacticand semantic information.
Information Sciences,(179): 1785-1791.G.D.
Zhou, L.H.
Qian, and Q.M.
Zhu.
2009.
Labelpropagation via bootstrapped support vectors for se-mantic relation extraction between named entities.Computer Speech and Language, 23(4): 464-478.G.D.
Zhou and M. Zhang.
2007.
Extraction relationinformation from text documents by exploring vari-ous types of knowledge.
Information Processing andManagement, (42):969-982.G.D.
Zhou, M. Zhang, D.H. Ji, and Q.M.
Zhu.
2007.Tree Kernel-based Relation Extraction with Context-Sensitive Structured Parse Tree Information.EMNLP/CoNLL-2007: 728-736.355
