c?
2004 Association for Computational LinguisticsOptimizing Referential Coherencein Text GenerationRodger Kibble?
Richard Power?University of London University of BrightonThis article describes an implemented system which uses centering theory for planning of coherenttexts and choice of referring expressions.
We argue that text and sentence planning need to bedriven in part by the goal of maintaining referential continuity and thereby facilitating pronounresolution: Obtaining a favorable ordering of clauses, and of arguments within clauses, is likelyto increase opportunities for nonambiguous pronoun use.
Centering theory provides the basis forsuch an integrated approach.
Generating coherent texts according to centering theory is treatedas a constraint satisfaction problem.
The well-known Rule 2 of centering theory is reformulated interms of a set of constraints?cohesion, salience, cheapness, and continuity?and we show sampleoutputs obtained under a particular weighting of these constraints.
This framework facilitatesdetailed research into evaluation metrics and will therefore provide a productive research tool inaddition to the immediate practical benefit of improving the fluency and readability of generatedtexts.
The technique is generally applicable to natural language generation systems, which performhierarchical text structuring based on a theory of coherence relations with certain additionalassumptions.1.
OverviewA central task for natural language generation (NLG) systems is to produce text thatis coherent, in the sense in which (1a) is noticeably more coherent than (1b):1. a. Elixir is a white cream.It is used in the treatment of cold sores.It contains aliprosan.Aliprosan relieves viral skin disorders.b.
Elixir contains aliprosan.Viral skin disorders are relieved by aliprosan.Elixir is used in the treatment of cold sores.It is a white cream.We can observe various ways in which text organization influences coherence: thesequence in which certain facts are presented, the order in which entities are mentionedin a clause, and the possibilities available for identifying the intended reference ofpronouns.
Generally, (1a) seems to conform better to a reader?s expectations of whatwill be referred to next and of how to resolve underspecified referring expressions,?
Department of Computing, Goldsmiths College, University of London, London SE14 6NW, U. K.E-mail: r.kibble@gold.ac.uk?
Information Technology Research Institute, University of Brighton, Brighton BN2 4GJ, U. K. E-mail:Richard.Power@itri.brighton.ac.ukSubmission received: 17 October 2002; Revised submission received: 22 May 2004; Accepted forpublication: 6 August 2004402Computational Linguistics Volume 30, Number 4in particular pronouns.
These are issues which the well-known centering theory (CT)of Grosz, Joshi, and Weinstein (1995; henceforth GJW) is concerned with.
Previousalgorithms for pronominalization such as those of McCoy and Strube (1999), Henschel,Cheng, and Poesio (2000), and Callaway and Lester (2002) have addressed the task ofdeciding whether to realize an entity as a pronoun on the basis of given factors such asits syntactic role and discourse history within a given text structure; what is essentiallynovel in our approach is that we treat referential coherence as a planning problem, onthe assumption that obtaining a favorable ordering of clauses, and of arguments withinclauses, is likely to increase opportunities for nonambiguous pronoun use.
Centeringtheory provides the basis for such an integrated approach.1Of course coherence of a text depends on the realization of rhetorical relations(Mann and Thompson 1987) as well as referential continuity, and the latter is to anextent a byproduct of the former, as clauses that are rhetorically related also tendto mention the same entities.
However, even when a set of facts is arranged in ahierarchical RST structure, there are still many possible linear orderings with notice-able differences in referential coherence.
This article concentrates on the influence ofreferential continuity on overall coherence and describes a method for applying CTto problems in text planning and pronominalization in order to improve the fluencyand readability of generated texts.
This method is applicable in principle to any sys-tem which produces hierarchically structured text plans using a theory of coherencerelations, with the following additional assumptions:?
There is a one-to-one correspondence between predicates and verbs, sothat the options for syntactic realization can be predicted from theargument structure of predicates.
Such ?shallow?
lexicalization appearsto be standard in applied NLG systems (Cahill 1999).?
Pronominalization is deferred until grammatical relations and wordorder have been determined.Our exposition will refer to an implemented document generation system, Icon-oclast, which uses the technique of constraint satisfaction (van Hentenryck 1989;Power 2000; Power, Scott, and Bouayad-Agha 2003) with CT principles implementedamong a set of soft constraints.
The Iconoclast system allows the user to specifycontent and rhetorical structure through an interactive knowledge-base editor andsupports fine-grained control over stylistic and layout features.
The user-determinedrhetorical structure is transformed into a text structure or a set of candidate text struc-tures which respect various text formation rules encoded as hard constraints.
Not allof the resulting text structures will give rise to stylistically acceptable documents, andof those which may be judged acceptable, some will be noticeably preferable to others.The text-structuring phase is followed by an evaluation of the candidate structures inwhich they are ranked according to a set of preferences encoded as soft constraints.Centering preferences are weighted along with other stylistic constraints to fix thepreferred final ordering both of propositions in the text and of arguments within aclause.It is not our primary aim in this short article to provide an empirical assessmentof the claims of CT, for which we refer the reader to the relevant papers, such as1 Callaway and Lester (2002) note that CT-based pronominalization algorithms ?assume that thediscourse tree was constructed with Centering theory in mind?
(page 91); in our case this assumptionis justified.403Kibble and Power Optimizing Referential Coherencethose collected in Walker, Joshi, and Prince (1998a) as well as Poesio et al (2002)and other works cited there.
We report elsewhere (Kibble and Power 2004) on twoongoing empirical studies: A paired-comparison study of judgments by naive subjectsindicates that centering constraints make an appreciable difference to the acceptabilityof texts, and a corpus study using what we believe to be a novel technique involvingperturbations provides clear evidence of preferences between the different constraints.One of the strengths of our framework is that it can be used as a research tool forthe evaluation of variants of CT, as different realizations of an input sequence can begenerated by varying control parameters, and one can very quickly see the results ofalternative choices.1.1 Related WorkOther researchers have applied CT to generation, though to our knowledge none haveapplied it to text planning, sentence planning, and pronominalization in the integratedway that we present in this article.
This general approach is anticipated by McKeown?s(1985) text-planning system, in which referential coherence is taken to be one of thefactors determining fluency, though McKeown?s work predates RST and centering.Mittal et al (1998) apply what we term salience to sentence planning, with the goal ofrealizing the Cb as subject, though the text planner does not have a goal of attemptingto maintain the same Cb.
We regard Cheng?s (2000) work on the interaction of centeringpreferences and aggregation in text planning as complementary to our enterprise.Karamanis (2001), Kibble (2001), and Beaver (2004), have argued for a ranking of thecentering principles as opposed to weighting, and indeed Beaver provides a unifiedformulation of the centering rules and constraints as a ranked set of OT constraints.However, we believe that such a ranking stands in need of empirical justification,and Beaver?s data actually provide little evidence for strict ranking as opposed toweighting of constraints (see Kibble 2003).
Constraint satisfaction search was appliedby Marcu (1996, 1997) to the far harder task of constructing RST trees given a setof facts and a repertoire of rhetorical relations; Mellish et al (1998) argue that thisapproach may not scale up to the generation of larger texts and propose an alternativeusing stochastic search.
We address the issue of computational complexity in section4; however we do not face the same problems as Marcu, since the task for our textplanner is to convert a given RST tree into a (possibly singleton) set of text structuresrather than to build the RST tree from scratch.2.
Centering ParametersWe assume some familiarity with the basic concepts of CT.
In this section we brieflyand informally summarize the main assumptions of the theory and explain how wehave interpreted and applied these assumptions:1.
For each utterance in a discourse there is said to be at most one entity that is thecenter of attention or center (Constraint 1).
The center in an utterance Un is the mosthighly ranked entity realized in Un?1, which is also realized in Un (Constraint 3).
Thisis also referred to as the backward-looking center or Cb.
(The set of entities mentionedin an utterance Un is defined by Constraint 2 as the set of forward-looking centersor Cfs.)
It is not entirely clear whether Constraint 1 is to be taken as an empiricalclaim or as a stipulation that some entity must be designated as Cb, if necessary byconstructing an indirect anaphoric link.2.
There is a preference for consecutive utterances within a discourse segment tokeep the same entity as the center and for the center to be realized as the highest-ranked entity or preferred center (Cp).
Kibble (1999) dubbed these principles cohe-404Computational Linguistics Volume 30, Number 4Table 1Centering transitions.Continue Cohesion and Salience both hold; same center (or Cb(Un) undefined),realized as Cp in Un+1Retain Cohesion only; that is, center remains the same but is not realizedas Cp in Un+1Smooth Shift Salience only; center of Un+1 realized as Cp but not equal to Cb(Un)Rough Shift Neither cohesion nor salience holdssion and salience, respectively.
Combinations of these preferences provide the familiarcanonical set of transitions shown in Table 1, ranked in the stipulated order of pref-erence first set out as Rule 2 by Brennan, Friedman, and Pollard (1987) and adoptedby Walker, Joshi, and Prince (1998b).3.
The center is the entity which is most likely to be pronominalized: GJW?s Rule 1in its weakest form states that if any entity is referred to by a pronoun, the Cb must be.As Poesio et al (2002) point out, CT can be viewed as a ?parametric?
theory inthat key notions such as utterance and previous utterance, realization of entities, andranking are not given precise definitions by GJW, and subsequent applied studieshave had to begin by fixing particular instantiations of these notions.2.1 RankingSince Brennan, Friedman, and Pollard (1987), a ranking in terms of grammatical roles(or obliqueness) has become standard; for example: subject > direct object >indirect object > others.We have simplified matters somewhat for the purposes of this implementation.
First,we assume that syntactic realization serves only to distinguish the Cp from all otherreferents, which are ranked on the same level: Thus effectively subject > others.Secondly, we assume that the system already knows, from the argument structureof the proposition, which entities can occur in subject position: Thus in realizing aproposition ban(fda, elixir), both arguments are potential Cps because active and pas-sive realizations are both allowed; for contain(elixir, gestodene), only elixir is a potentialCp because we disallow Gestodene is contained by Elixir.2.2 RealizationGJW?s original formulation distinguished between ?direct?
realization, or coreference,and ?indirect?
realization, which corresponds to bridging reference.
As an example,in (1a) the terms cold sores and viral skin disorders are not strictly coreferential and so donot count as direct realizations of the same entity, but if we allow indirect realization,then there is the potential for one of these to be identified as Cb, in a sequence suchas Elixir is used to treat cold sores.
Viral skin disorders are relieved by aliprosan.
Again, wekeep things simple at this stage by treating nominal expressions as realizations of thesame entity only if they strictly corefer.
As Poesio et al (2002) observe, under thisinterpretation of realization, a number of utterances will lack an identifiable Cb, so wehave to allow for a ?no-Cb?
transition in addition to the canonical transitions listedin Table 1.22 Of course, even with indirect realization we would still have to allow for the possibility of no-Cbtransitions.405Kibble and Power Optimizing Referential Coherence2.3 Utterance and Previous UtteranceTwo different approaches to the realization of ?utterance?
have become associated withthe work of Kameyama (1998) and Suri, McCoy, and DeCristoforo (1999).
To simplifysomewhat: Kameyama argued that the local focus is updated in a linear manner bytensed clauses rather than by sentences, while Suri, McCoy, and DeCristoforo presentevidence that the subject of the main clause in a complex sentence is likely to bethe preferred antecedent for a subject pronoun in an immediately following sentence,winning out over candidates in an intervening subordinate clause, as in example (2):2.
Dodgei was robbed by an ex-convict j the other night.The ex-convictj tied himi up because hei wasn?t cooperating.Then hej took all the money and ran / #he i started screaming for help.In fact we would argue that Suri, McCoy, and DeCristoforo?s analysis does not estab-lish whether the accessibility effects are due to the syntactic or the rhetorical structureof utterances.
The examples they present all involve sentences of the form Sx becauseSy corresponding to the rhetorical pattern nucleus?connective?satellite.
Their resultsare therefore consistent with the hypothesis that the nucleus of a preceding segmentis more accessible than the satellite.
We allow the user of our system to choose be-tween two strategies: a linear, Kameyama-style approach or a hierarchical approachin which the utterance is effectively identified with a rhetorical span.
Our approach ismore general than that of Suri, McCoy, and DeCristoforo as it covers cases in whichthe components of a complex rhetorical span are realized in different sentences.
Veinstheory (Cristea, Ide, and Romary 1998) provides a possible formalization of the intu-ition that some earlier propositions become inaccessible as a rhetorical boundary iscrossed.
The theory could be applied to centering in various ways; we have imple-mented perhaps the simplest approach, in which centering transitions are assessed inrelation to the nearest accessible predecessor.
In many cases the linear and hierarchi-cal definitions give the same result, but sometimes they diverge, as in the followingschematic example:3. ban(fda, elixir) since contain(elixir, gestodene).However, approve(fda, elixirplus).Following Veins Theory, the predecessor of approve(fda, elixirplus) is ban(fda, elixir); itslinear predecessor contain(elixir, gestodene) (an embedded satellite) is inaccessible.
Thismakes a considerable difference: Under a hierarchical approach, fda can be the Cb ofthe final proposition; under a linear approach, this proposition has no Cb.2.4 Transitions versus ConstraintsKibble (1999, 2001) argued for a decomposition of the canonical transition types intothe principles of cohesion and salience, partly on the architectural grounds that thismakes it easier to apply CT to the generation task, and partly on the empirical groundsthat the preference ordering assumed by GJW is not strongly supported by corpusevidence and that transitions are better seen as epiphenomenal, emerging in a partialordering from the interaction of more fundamental constraints.
We follow this generalapproach, including among the constraints the principle of continuity: Each utteranceshould have at least one referent in common with the preceding utterance, whichis effectively a restatement of GJW?s Constraint 1.
If we assign a weight of 1 eachto cohesion and salience and 2 to continuity, we obtain a partial ordering over the406Computational Linguistics Volume 30, Number 4canonical transitions as follows:0 : Continue > 1 : {Retain | Smooth Shift} > 2 : {Rough Shift | No Cb}Any relative weighting or ranking of coherence over salience would need to be mo-tivated by evidence that Retain is preferred over Smooth Shift, and we are not awareof any conclusive evidence of this in the literature (see Kipple [1999] for further dis-cussion).This approach also means that Strube and Hahn?s (1999) principle of cheapnesscan be naturally incorporated as an additional constraint: This is a requirement thatCp(Un?1) = Cb(Un).
The principle of cheapness effectively cashes out the informaldefinition of the Cp as ?represent[ing] a prediction about the Cb of the followingutterance?
(Walker, Joshi, and Prince, 1998b, page 3).
In classic variants of centeringtheory, this happens only indirectly as a result of transition preferences, and onlyfollowing a Continue or Smooth Shift, since the Cp is also the Cb and Rule 2 predictsthat the preferred transition will maintain the same Cb.
However, the prediction isnot entailed by the theory following a Retain, Rough Shift, or no-Cb transition orindeed for the first sentence in a discourse, when there is effectively no predictionconcerning the Cp.
Strube and Hahn claim that the cheapness principle is motivatedby the existence of Retain-Shift patterns, which are evidently a common means ofintroducing a new topic (see also Brennan, Friedman, and Pollard 1987 [henceforthBFP]).
To summarize, our system incorporates the following constraints:cohesion: Cb(Un?1) = Cb(Un)salience: Cp(Un) = Cb(Un)cheapness: Cp(Un?1) = Cb(Un)continuity: Cfs(Un?1) ?
Cfs(Un) = ?2.5 Preferences: Transitions, Pairs, or Sequences?The original version of GJW?s Rule 2 specified that sequences of Continue transitionsare preferred over sequences of Retains, and so on; in BFP?s implementation, how-ever, transitions are evaluated incrementally and the preference applies to individ-ual transitions such as Continue versus Retain rather than to sequences.
Strube andHahn (1999) take an intermediate position: In their formulation, pairs of transitions?
?Ui, Uj?, ?Uj, Uk??
are preferred that are cheap, that is, Cp(Uj) = Cb(Uk).
Strube andHahn intended the preference for cheap transition pairs to replace GJW?s Rule 2 intoto, which seems a rather weak requirement.
On the other hand the original GJWformulation is difficult to verify, since as Poesio et al (2002, page 66) found, sequencesof multiple occurrences of the same transition type turn out to be relatively rare.Our position is a little more complex, as we do not directly aim to generate particulartransitions or sequences of transitions but to minimize violations of the constraints con-tinuity, cohesion, salience, and cheapness.
Violations are computed on individual nodesand summed for each candidate text structure, so we may expect that the candidatewith the fewest violations will have a preponderance of the preferred transitions.
Thesystem is certainly more slanted toward global optimization than BFP?s incrementalmodel but may be said to achieve this in a more natural way than a strategy of tryingto produce uniform sequences of transitions.2.6 PronominalizationGJW?s Rule 1 is rather weak as a guide to pronominalization decisions in general, asit only mentions the Cb and gives little guidance on when or whether to pronomi-407Kibble and Power Optimizing Referential Coherencenalize non-Cbs.
An important consideration for NLG is to minimize the possibility ofambiguity, and so we adopt a cautious strategy: The user can choose between invari-ably pronominalizing the Cb or using a fairly simple algorithm based on parallelismof grammatical roles.
A possible future development is to supplement our CT-basedtext planner with a more sophisticated pronominalization algorithm as proposed byHenschel, Cheng, and Poesio (2000) or Callaway and Lester (2002).3.
Generation IssuesCT has developed primarily in the context of natural language interpretation, focussingon anaphora resolution (see, e.g., Brennan, Friedman, and Pollard 1987).
As statedabove, the novel contribution of this article is an integrated treatment of pronomi-nalization and planning, aiming to determine whether the principles underlying theconstraints and rules of the theory can be ?turned round?
and used as planning oper-ators for generating coherent text.
We have assumed some familiarity in the foregoingwith terms such as text planning and sentence planning.
These are among the distincttasks identified in Reiter?s ?consensus architecture?
for natural language generation(Reiter 1994):Text planning/content determination: deciding the content of a message and or-ganizing the component propositions into a text structure (typically a tree)Sentence planning: aggregating propositions into clausal units and choosing lex-ical items corresponding to concepts in the knowledge base; this is thelevel at which the order of arguments and choice of referring expressionswill be determinedLinguistic realization: surface details such as agreement and orthographyReiter observed that these functions can often be identified with discrete modulesin applied NLG systems and that a de facto standard had emerged in which thesemodules are organized in a pipeline such that data flows only in one direction andonly between consecutive modules.Breaking down the generation task in this way makes it evident that there are var-ious ways the distinct principles of CT can be incorporated.
Continuity and cohesionnaturally come under text planning: respectively, ordering a sequence of utterances toensure that each has a backward-looking center and maintaining the same entity asthe center within constraints on ordering determined by discourse relations.
Salienceand cheapness, on the other hand, would come under sentence planning, since in eachcase a particular entity is to be realized as subject.
However, we encounter an appar-ent paradox in that identifying the center itself depends on grammatical salience asdetermined by the sentence planner: for example, choice of active or passive voice.Consequently, the text planner appears to rely on decisions made at the sentence-planning level, which is incompatible with the fact that ?pipelined systems cannotperform general search over a decision space which includes decisions made in morethan one module?
(Reiter 2000, page 252).We can envisage three possibilities for incorporating CT into a generation archi-tecture:1.
?Incremental?
sentence-by-sentence generation, in which the syntactic structureof Un is determined before the semantic content of Un+1 is planned.
That is, the textplanner would plan the content of Un+1 by aiming to realize a proposition in theknowledge base which mentions an entity which is salient in Un.
We are not aware408Computational Linguistics Volume 30, Number 4Figure 1Rhetorical structure.of any system which performs all stages of generation in a sentence-by-sentence way,and in any case this type of architecture would not allow for global planning overmultisentence sequences, which we take to be essential for a faithful implementationof centering.2.
A pipelined system in which the ?topic?
or ?theme?
of a sentence is desig-nated independently as part of the semantic input and centering rules reflect theinformation structure of a discourse.
Prince (1999) notes that definitions of topic inthe literature do not provide objective tests for topichood and proposes that thetopic should be identified with the center of attention as defined by CT; however,what would be needed here would be a more fundamental definition that would ac-count for a particular entity?s being chosen to be the center of attention in the firstplace.3.
The solution we adopt is to treat the task of identifying Cbs and Cps as anoptimization problem.
We assume that certain options for syntactic realization can bepredicted on the basis of the argument structure of predicates, which means that cen-tering constructs can be calculated as part of text planning before syntactic realizationtakes place, so that the paradox noted above is resolved.
Pronominalization decisionsare deferred until a point at which grammatical relations and word order have beenfixed.4.
Generation as Constraint SatisfactionIn this section we give an overview of our text-planning component in order to set theimplementation of CT in context.
The methodology is more fully described by Power,Scott, and Bouayad-Agha (2003).The text planner was developed within Iconoclast, a project that investigatedapplications of constraint-based reasoning in natural language generation using as sub-ject matter the domain of medical information leaflets.
Following Scott and de Souza(1990), we represent rhetorical structure by graphs like Figure 1, in which nontermi-nal nodes represent RST relations, terminal nodes represent propositions, and linearorder is unspecified.
The task of the text planner is to realize the rhetorical structureas a text structure in which propositions are ordered, assigned to textual units (e.g.,sentences, paragraphs, vertical lists), and linked where appropriate by discourse con-nectives (e.g., since, however).
The boundary between text and sentence planning isdrawn at the realization of elementary propositions rather than at the generation ofindividual sentences.
If a rhetorical subtree is realized as a complex sentence, the effect409Kibble and Power Optimizing Referential Coherenceis that ?text planning?
trespasses into the higher-level syntax of the sentence, leavingonly the elementary propositions to be realized by ?sentence planning.
?3Even for a simple rhetorical input like figure 1, many reasonable text structurescan be generated.
Since there are two nucleus-satellite relations, the elementary propo-sitions can be ordered in four ways.
Several discourse connectives can be employedto realize each rhetorical relation (e.g., concession can be realized by although, but, andhowever).
At one extreme, the text can be spread out over several paragraphs, while atthe other extreme, it can be squeezed into a single sentence.
With fairly restrictive con-straint settings, the system generates 24 text structure patterns for figure 1, includingthe following (shown schematically):A.
Since contain(elixir, gestodene), ban(fda, elixir).However, approve(fda, elixirplus).B.
approve(fda, elixirplus), although since contain(elixir, gestodene),ban(fda, elixir).The final output texts will depend on how the propositions are realized syntactically;among other things, this will depend on centering choices within each proposition.In outline, the procedure that we propose is as follows:1.
Enumerate all text structures that are acceptable realizations of therhetorical structure.2.
For each text structure, enumerate all permissible choices for the Cb andCp of each proposition.3.
Evaluate the solutions, taking account of referential coherence amongother considerations, and choose the best.For the example in figure 1, centers can be assigned in four ways for each text structurepattern, making a total of 96 solutions.As will probably be obvious, such a procedure could not be applied for rhetoricalstructures with many propositions.
For examples of this kind, based on the relationscause and concession (each of which can be marked by several different connectives), wefind that the total number of text structures is approximately 5N?1 for N propositions.Hence with N = 5, we would expect around 600 text structures; with perhaps fiveto ten ways of assigning centers to each text structure, the total number of solutionswould approximate to 5,000.
Global optimization of the solution therefore becomesimpracticable for texts longer than about five propositions; we address this problemby a technique of partial optimization in which a high-level planner fixes the large-scale structure of the text, thus defining a set of local planning problems, each smallenough to be tackled by the methods described here.Stage 1 of the planning procedure is described in more detail by Power, Scott,and Bouayad-Agha (2003).
A brief summary follows, after which we focus on stages 2and 3, in which the text planner enumerates the possible assignments of centers andevaluates which is the best.3 See Power, Scott, and Bouayad-Agha (2003) for detailed motivation of this concept of text structure as alevel of representation distinct from both rhetorical structure and syntactic structure.410Computational Linguistics Volume 30, Number 44.1 Generating and Evaluating Text StructuresA text structure is defined in Iconoclast as an ordered tree in which each node has afeature named text?level.
Values of text?level are represented by integers in therange 0 .
.
.Lmax; these may be interpreted in various ways, but we will assume herethat Lmax = 4 and that integers are paired with descriptive labels as follows:0 text phrase1 text clause2 text sentence3 paragraph4 sectionInformally, a text structure (TS) is well-formed if it respects the hierarchy of textuallevels, so that sections are composed of paragraphs, paragraphs of text sentences,and so forth.
An example of an ill-formed structure would be one in which a textsentence contained a paragraph; such a structure can occur only when the paragraphis indented?a possibility we are excluding here.
As well as being a well-formed textstructure, a candidate solution must realize a rhetorical structure (RS) ?correctly,?
ina sense that we need to make precise.
Roughly, a correct solution should satisfy threeconditions:1.
The terminal nodes of the TS should express all the elementarypropositions in the RS; they may also contain discourse connectivesexpressing rhetorical relations in the RS, although for some relationsdiscourse connectives are optional.2.
The TS must respect rules of syntax when it combines propositions anddiscourse connectives within a text clause; for instance, a conjunctionsuch as but linking two text phrases must be coordinated with thesecond one.3.
The TS must be structurally compatible with the RS.The first two conditions are straightforward, but what is meant by ?structural compat-ibility??
We suggest the crucial criterion for such compatibility should be as follows:Any grouping of the elementary propositions in the TS must also occur in the RS.
Inother words, the text structurer is allowed to eliminate groupings, but not to add any.More formally:?
If a node in the TS dominates terminal nodes expressing a set ofelementary propositions, there must be a corresponding node in the RSdominating the same set of propositions.?
The converse does not hold: For instance, an RS of the formR1(R2(p1, p2), p3) can be realized by a paragraph of three sentences, onefor each proposition, even though this TS contains no node dominatingthe propositions p1 and p2 that are grouped by R2.
However, when thishappens, the propositions grouped together in the RS must remainconsecutive in the TS; solutions in which p3 comes in between p1 and p2are prohibited.411Kibble and Power Optimizing Referential CoherenceTable 2Examples of text-structuring constraints.Name Type DescriptionRoot domination Hard The text?level of the root node r must exceedLp > Ld that of any daughter d.Parental domination Hard The text?level of a parent node p must be equal toLp ?
Ld or greater than the text?level of any daughter d.Sister equality Hard If nodes a and b are descended from the sameLa = Lb parent, they must have the same text?level.Sister order Hard If nodes a and b are descended from the sameOa = Ob parent, they must have different values of order.Connective Hard Governs choice of discourse connective.Rhetorical grouping Soft Failure to express a rhetorical grouping can betreated as a defect.Oversimple paragraph Soft A paragraph containing only one text sentence canbe treated as a defect.Centering Soft Constraints derived from centering theory.Our procedure for generating candidate solutions is based on a technique for for-mulating text structuring as a constraint satisfaction problem (CSP) (van Hentenryck,1989), using the Eclipse logic programming environment.4 In general, a CSP is char-acterized by the following elements:?
a set of variables V1 .
.
.VN?
For each variable Vi, a finite domain Di of possible values?
a set of constraints on the values of the variables (for integer domainsthese often use ?greater than?
and ?less than?
; other domains usuallyrely on ?equal?
or ?unequal?.
)A solution assigns to each variable Vi a value from its domain Di while respectingall constraints.
For instance each node of the rhetorical structure is annotated witha text?level variable with the domain 0 .
.
.Lmax and an order variable with thedomain 1 .
.
.N, where N is the number of sisters.
Depending on the constraints, theremay be multiple solutions, or there may be no solution at all.
We distinguish betweenhard constraints, which are applied during the enumeration phase, determining whichcandidate structures will be considered, and soft constraints, which apply during anevaluation phase in which the enumerated solutions are ordered from best to worst.Some examples of hard and soft constraints are shown in Table 2.4.2 Choosing CentersGiven a text structure, we enumerate all permissible centering assignments as follows:1.
Determine the predecessor Un?1 (if any) of each proposition Un.2.
List the potential Cbs and Cps of each proposition (henceforth denotedby ?Cb and ?Cp).4 See http://www-icparc.doc.ic.ac.uk/eclipse/.412Computational Linguistics Volume 30, Number 4Table 3Cbs and Cps for solution A.U Proposition ?Cb(U) ?Cp(U)U1 contain(elixir, gestodene) [ ] [elixir]U2 ban(fda, elixir) [elixir] [fda, elixir]U3 approve(fda, elixir-plus) [fda] [fda, elixir-plus]3.
Compute all combinations from ?Cb and ?Cp that respect thefundamental centering constraint that Cb(Un) should be the most salientcandidate in Un?1.As stated earlier, two criteria for determining the predecessor have been implemented;the user can select one or the other criterion, thus using the NLG system to test differentapproaches.
Following a linear criterion, the predecessor is simply the proposition thatprecedes the current proposition in the text, regardless of structural considerations.Following a hierarchical criterion, the predecessor is the most accessible previousproposition, in the sense defined by Veins Theory (Cristea, Ide, and Romary, 1998).For now we assume the criterion is linear.
?Cb(Un) (potential Cbs of proposition Un) is given by the intersection betweenCf (Un) and Cf (Un?1)?that is, all the referents they have in common.
The potentialCps are those referents in the current proposition that can be realized as most salient.Obviously this should depend on the linguistic resources available to the generator; thesystem actually uses a simpler rule based on argument types within the proposition.Table 3 shows the potential Cbs and Cps for the proposition sequence in solution A pre-sented at the beginning of this section.
As stated earlier, our treatment of salience heresimplifies in two ways: We assume that syntactic realization serves only to distinguishthe Cp from all other referents and that the system already knows, from the argumentstructure of the proposition, which entities can occur in subject position.
With thesesimplifications, the enumeration of centering assignments is straightforward; in theabove example, four combinations are possible, since there are two choices each forCp(U2) and Cp(U3).4.3 Evaluating SolutionsThe system evaluates candidate solutions by applying a battery of tests to each node ofthe text plan.
Each test identifies whether the node suffers from a particular defect.
Forinstance, one stylistic defect (at least for the rhetorical relations occurring in figure 1)is that of placing nucleus before satellite; in general, the text reads better if importantmaterial is placed at the end.
For each type of defect, we specify a weight indicatingits importance: In evaluating continuity of reference, for example, the defect ?no Cb?is regarded as more significant than other defects.
Other violations are recorded onlyin the case in which a Cb is present, so if all violations were weighted equally, thiscould result in a ?no-Cb?
transition?s being treated as less serious than an ?expensive?Smooth Shift, for example (violating cheapness and cohesion).
Summing the weightedcosts for all defects, we obtain a total cost for the solution; our aim is to find thesolution with the lowest total cost.Regarding centering, the tests currently applied are as follows:Salience violation: A proposition Un violates salience if Cb(Un) = Cp(Un).
Thisdefect is assessed only on propositions that have a backward-looking cen-ter.413Kibble and Power Optimizing Referential CoherenceCohesion violation: A transition ?Un?1, Un?
violates cohesion if Cb(Un) =Cb(Un?1).
This defect is not recorded when either Un or Un?1 has no Cb.Cheapness violation: A transition ?Un?1, Un?
violates cheapness if Cb(Un) =Cp(Un?1).
This defect is assessed only on propositions that have abackward-looking center.Continuity violation: This defect is recorded for any proposition with no Cb,except the first proposition in the sequence (which by definition cannothave a Cb).Relative weightings for these defects can be chosen by the user; for the current exam-ples we have chosen a neutral scheme with a weight of 3 for continuity violations and1 each for the others, so that a no-Cb transition is ranked equally bad as an ?expen-sive?
Rough Shift.5 Applied to the four solutions to text structures A and B presentedin this section, these definitions yield costs shown in Table 4.
According to our metric,solutions A1 and A2 should be preferred because they incur less cost than any others,with B3 and B4 the least preferred.Although this article focuses on centering issues, it is important to remember thatother aspects of text quality are evaluated at the same time: The aim is to compute aglobal measure so that disadvantages in one factor can be weighed against advantagesin another.
For instance, text pattern B is bound to yield poor continuity of referencebecause it orders the propositions so that U1 and U2 have no referents in common.Text pattern A avoids this defect, but this does not automatically mean that A is betterthan B; there may be other reasons, unconnected with centering, for preferring B toA.
The constraints which have an effect on clause ordering include:Satellite before nucleus: For nucleus-satellite relations, place the satellite beforethe nucleus.Right-branching structure: If an elementary proposition is coordinated with acomplex rhetorical structure, place the elementary proposition first.Centering constraints: Penalize orderings which violate centering preferences.Text pattern B is favored by ?right-branching structure,?
but in this case the centeringconstraints will ?conspire?
with ?satellite before nucleus?
to favor pattern A overall.5.
ConclusionWe have described a technique for generating texts which will be coherent accordingto a reasonably faithful interpretation of centering theory.
NLG systems need someprincipled means of deciding on the preferred orderings of clauses and of argumentswithin clauses, and CT appears a good candidate to provide a basis for these decisions,in tandem with other stylistic considerations.
We have reported on a particular imple-mentation in the Iconoclast document generation system, but the technique can beapplied to other NLG systems that perform hierarchical text structuring based on atheory of coherence relations (with additional assumptions as detailed in Section 1):?
For systems which generate a single text plan, CT can determine themost coherent ordering of arguments within clauses.5 See Kibble and Power (2004) for initial results of empirical research on constraint weightings.414Computational Linguistics Volume 30, Number 4Table 4Realizations of text patterns A and B, with weights: cohesion | salience | cheapness = 1,continuity = 3.Version Text Cb Cp Defects SumSince Elixir contains gestodene ?
elixir noneA1 the FDA bans Elixir.
elixir fda sal 2However, it approves Elixir+.
fda fda cohSince Elixir contains gestodene ?
elixir noneA2 it is banned by the FDA.
elixir elixir none 2However, the FDA approves Elixir+.
fda fda coh, chSince Elixir contains gestodene ?
elixir noneA3 the FDA bans Elixir.
However, elixir fda sal 3Elixir+ is approved by the FDA.
fda elixir+ sal, cohSince Elixir contains gestodene ?
elixir noneA4 it is banned by the FDA.
However, elixir elixir none 3Elixir+ is approved by the FDA.
fda elixir+ sal, coh, chThe FDA approves Elixir+ although ?
fda noneB1 since Elixir contains gestodene ?
elixir cont 3it is banned by the FDA.
elixir elixir noneElixir+ is approved by the FDA ?
elixir+ noneB2 although since Elixir contains gestodene ?
elixir cont 3it is banned by the FDA.
elixir elixir noneThe FDA approves Elixir+ although ?
fda noneB3 since Elixir contains gestodene ?
elixir cont 4the FDA bans Elixir.
elixir fda salElixir+ is approved by the FDA ?
elixir+ noneB4 although since Elixir contains gestodene ?
elixir cont 4the FDA bans Elixir.
fda elixir salNote: ch = cohesion, coh=cohesion, cont=continuity, sal=salience.?
For systems which generate multiple text plans, CT can be used toevaluate the different plans as well as to determine the optimalrealization of any particular plan.We have carried out empirical studies that provide clear evidence that centering fea-tures make a difference to the acceptability of texts and demonstrate one way todetermine weightings (Kibble and Power 2004).
It may turn out that different weight-415Kibble and Power Optimizing Referential Coherenceings are appropriate for different text genres or for speech as opposed to ?written?text.
Our framework will facilitate detailed research into evaluation metrics and willtherefore provide a productive research tool in addition to the immediate practicalbenefit of improving the fluency and readability of generated texts.AcknowledgmentsThe essential ideas of this work wereoriginally presented at the ACL Workshopon Discourse Structure and Reference (1999),the 12th Amsterdam Colloquium (1999),and COLING 2000.
An earlier version ofthis article was presented at INLG 2000.
Weare grateful to the audiences on thoseoccasions for useful feedback and also tocolleagues on the GNOME project as wellas Nikiforos Karamanis and the anonymousreviewers for Computational Linguistics.
Thiswork was supported in part by the U.K.EPSRC under grant references L51126,L77102, and M36960.ReferencesBeaver, David.
2004.
The optimization ofdiscourse anaphora.
Linguistics andPhilosophy, 27(1):3?56.Brennan, Susan, Marilyn Walker Friedman,and Carl Pollard.
1987.
A centeringapproach to pronouns.
In Proceedings of25th ACL, pages 155?162, Stanford, CA.Cahill, Lynne.
1999.
Lexicalisation inapplied NLG systems.
Technical ReportITRI-99-04, Information TechnologyResearch Institute, University of Brighton.Callaway, Charles B. and James C. Lester.2002.
Pronominalization in generateddiscourse and dialogue.
In Proceedings ofthe 40th Annual Meeting of the Association forComputational Linguistics (ACL), pages88?95, Philadelphia.Cheng, Hua.
2000.
Experimenting with theinteraction between aggregation and textplanning.
In Proceedings of ANLP-NAACL,pages 1?6, Seattle.Cristea, Dan, Nancy Ide, and LaurentRomary.
1998.
Veins theory: A model ofglobal discourse cohesion and coherence.In Proceedings of COLING/ACL?98, pages281?285, Montreal.Grosz, Barbara, Aravind Joshi, and ScottWeinstein.
1995.
Centering: A frameworkfor modelling the local coherence ofdiscourse.
Computational Linguistics,21(2):203?225.Henschel, Renate, Hua Cheng, andMassimo Poesio.
2000.
Pronominalisationrevisited.
In Proceedings of 18th COLING,pages 306?312, Saarbru?cken, Germany.Kameyama, Megumi.
1998.
Intrasententialcentering: A case study.
In MarilynWalker, Aravind Joshi, and Ellen Prince,editors, Centering Theory in Discourse,pages 89?112.
Clarendon, Oxford.Karamanis, Nikiforos.
2001.
Exploringentity-based coherence.
In Proceedings ofFourth CLUK, pages 18?26, University ofSheffield, Sheffield, England.Kibble, Rodger.
1999.
Cb or not Cb?Centering theory applied to NLG.
InProceedings of ACL Workshop on Discourseand Reference Structure, pages 72?81,University of Maryland, College Park.Kibble, Rodger.
2001.
A reformulation ofrule 2 of centering theory.
ComputationalLinguistics, 27(4):579?587.Kibble, Rodger.
2003.
Towards theelimination of centering theory.
In IvanaKruijff-Korbayova?
and Claudia Kosny,editors, DiaBruck 2003: Proceedings of theSeventh Workshop on the Semantics andPragmatics of Dialogue, Universita?t desSaarlandes, Saarbru?cken, Germany.Kibble, Rodger and Richard Power.
2004.Optimising referential coherence as aconstraint satisfaction problem.
TechnicalReport RK/2004/1, Department ofComputing, Goldsmiths College, andITRI-04-07, Information TechnologyResearch Institute, University of Brighton.Mann, William and Sandra Thompson.1987.
Rhetorical structure theory: Atheory of text organisation.
TechnicalReport ISI/RS-87-190, InformationSciences Institute, Los Angeles.Marcu, Daniel.
1996.
Building up rhetoricalstructure trees.
In Proceedings of AAAI-96,pages 1069?1074, Portland, OR.Marcu, Daniel.
1997.
From local to globalcoherence: A bottom-up approach to textplanning.
In Proceedings of AAAI-97, pages629?635, Providence, RI.McCoy, Kathleen and Michael Strube.
1999.Generating anaphoric expressions:Pronoun or definite description?
InProceedings of ACL Workshop on Discourseand Reference Structure, pages 63?71,University of Maryland, College Park.McKeown, Kathleen R. 1985.
Text Generation.Cambridge University Press, Cambridge.Mellish, Chris, Alistair Knott, JonOberlander, and Mick O?Donnell.
1998.Experiments using stochastic search fortext planning.
In Proceedings of the NinthInternational Workshop on Natural Language416Computational Linguistics Volume 30, Number 4Generation, pages 97?108,Niagara-on-the-Lake, Ontario.Mittal, Vibhu, Johanna Moore, GiuseppeCarenini, and Steven Roth.
1998.Describing complex charts in naturallanguage: A caption generation system.Computational Linguistics, 24(3):431?467.Poesio, Massimo, Rosemary Stevenson, HuaCheng, Barbara di Eugenio, and JanetHitzeman.
2002.
A corpus-basedevaluation of centering theory.
TechnicalReport TN-02-01/CSM-369, NaturalLanguage Engineering Group, Universityof Essex.Power, Richard.
2000.
Planning texts byconstraint satisfaction.
In Proceedings ofCOLING 2000, pages 642?648,Saarbru?cken, Germany.Power, Richard, Donia Scott, and NadjetBouayad-Agha.
2003.
Document structure.Computational Linguistics, 29(2):211?260.Prince, Ellen.
1999.
How not to mark topics:?Topicalization?
in English and Yiddish.Unpublished manuscript, LinguisticsDepartment, University of Pennsylvania.Reiter, Ehud.
1994.
Has a consensus NLgeneration architecture appeared, and is itpsycholinguistically plausible?
InProceedings of the Seventh InternationalNatural Language Generation Workshop,pages 163?170, Kennebunkport, ME.Reiter, Ehud.
2000.
Pipelines and sizeconstraints.
Computational Linguistics,26(2):251?259.Scott, Donia and Clarisse de Souza.
1990.Getting the message across in RST-basedtext generation.
In Robert Dale, ChrisMellish, and Michael Zock, editors,Current Research in Natural LanguageGeneration, pages 47?73.
Academic Press,London.Strube, Michael and Udo Hahn.
1999.Functional centering?Groundingreferential coherence in informationstructure.
Computational Linguistics,25(3):309?344.Suri, Linda, Kathleen McCoy, and JonathanDeCristofaro.
1999.
A methodology forextending focussing franeworks.Computational Linguistics, 25(2):173?194.van Hentenryck, P. 1989.
ConstraintSatisfaction in Logic Programming.
MITPress, Cambridge, MA.Walker, Marilyn, Aravind Joshi, and EllenPrince, editors.
1998a.
Centering Theory inDiscourse.
Clarendon, Oxford.Walker, Marilyn, Aravind Joshi, and EllenPrince.
1998b.
Centering in naturallyoccurring discourse.
In Marilyn Walker,Aravind Joshi, and Ellen Prince, editors,Centering Theory in Discourse, pages 1?28.Clarendon, Oxford.
