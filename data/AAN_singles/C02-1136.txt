Stochastic Dependency Parsing ofSpontaneous Japanese Spoken LanguageShigeki Matsubara?
Takahisa Murase?
Nobuo Kawaguchi?and Yasuyoshi Inagaki?
?Information Technology Center/CIAIR, Nagoya University?Graduate School of Engineering, Nagoya UniversityFuro-cho, Chikusa-ku, Nagoya, 464-8601, Japanmatubara@itc.nagoya-u.ac.jpAbstractThis paper describes the characteristic featuresof dependency structures of Japanese spokenlanguage by investigating a spoken dialogue cor-pus, and proposes a stochastic approach to de-pendency parsing.
The method can robustlycope with inversion phenomena and bunsetsuswhich don?t have the head bunsetsu by relax-ing the syntactic dependency constraints.
Themethod acquires in advance the probabilitiesof dependencies from a spoken dialogue corpustagged with dependency structures, and pro-vides the most plausible dependency structurefor each utterance on the basis of the probabili-ties.
An experiment on dependency parsing fordriver?s utterances in CIAIR in-car spoken dia-logue corpus has been made.
The experimentalresult has shown our method to be effective forrobust parsing of spoken language.1 IntroductionWith the recent advances of the continuousspeech recognition technology, a considerablenumber of studies have been made on spokendialogue systems.
For the purpose of smoothinteraction with the user, it is necessary for thesystem to understand the spontaneous speech.Since spoken language includes a lot of gram-matically ill-formed linguistic phenomena suchas fillers, hesitations and self-repairs, grammar-oriented approaches are not necessarily suitedto spoken language processing.
A technique forrobust parsing is thus strongly required.This paper describes the characteristic fea-tures of Japanese spoken language on the ba-sis of investigating a large-scale spoken dialoguecorpus from the viewpoint of dependency, andmoreover, proposes a method of dependencyparsing by taking account of such the features.The conventional methods of dependency pars-ing have assumed the following three syntacticconstraints (Kurohashi and Nagao, 1994):1.
No dependency is directed from right toleft.2.
Dependencies don?t cross each other.3.
Each bunsetsu 1 , except the last one, de-pends on only one bunsetsu.As far as we have investigated the corpus, how-ever, many spoken utterance do not satisfythese constraints because of inversion phenom-ena, bunsetsus which don?t have the head bun-setsu, and so on.
Therefore, our parsing methodrelaxes the first and third ones among the abovethree constraints, that is, permits the depen-dency direction from right to left and the bun-setsu which doesn?t depend on any bunsetsu.The parsing results are expressed by partial de-pendency structures.The method acquires in advance the proba-bilities of dependencies from a spoken dialoguecorpus tagged with dependency structures, andprovides the most plausible dependency struc-ture for each utterance on the basis of the prob-abilities.
Several techniques for dependencyparsing based on stochastic approaches havebeen proposed so far.
Fujio and Matsumotohave used the probability based on the fre-quency of cooccurrence between two bunsetsusfor dependency parsing (Fujio and Matsumoto,1998).
Uchimoto et al have proposed a tech-nique for learning the dependency probabilitymodel based on a maximum entropy method(Uchimoto et al, 1999).
However, since these1A bunsetsu is one of the linguistic units in Japanese,and roughly corresponds to a basic phrase in English.A bunsetsu consists of one independent word and morethan zero ancillary words.
A dependency is a modifica-tion relation between two bunsetsus.techniques are for written language, whetherthey are available for spoken language or notis not clear.
As the technique for stochas-tic parsing of spoken language, Den has sug-gested a new idea for detecting and parsingself-repaired expressions, however, the phenom-ena with which the framework can cope are re-stricted (Den, 1995).On the other hand, our method provides themost plausible dependency structures for nat-ural speeches by utilizing stochastic informa-tion.
In order to evaluate the effectiveness of ourmethod, an experiment on dependency parsinghas been made.
In the experiment, all driver?sutterances in 81 spoken dialogues of CIAIR in-car speech dialogue corpus (Kawaguchi et al,2001) have been used.
The experimental resulthas shown our method to be available for robustparsing of spontaneously spoken language.2 Linguistic Analysis of SpontaneousSpeechWe have investigated spontaneously spoken ut-terances in an in-car speech dialogue corpuswhich is constructed at the Center for Inte-grated Acoustic Information Research (CIAIR),Nagoya University (Kawaguchi et al, 2001) Thecorpus contains speeches of dialogue betweendrivers and navigators (humans, a Wizard ofOZ system, or a spoken dialogue system) andtheir transcripts.2.1 CIAIR In-car Speech DialogueCorpusData collection project of in-car speech dia-logues at CIAIR has started in 1999 (Kawaguchiet al, 2002).
The project has developed a pri-vate car, and been collecting a total of about140 hours of multimodal data such as speeches,images, locations and so on.
These data wouldbe available for investigating in-car speech dia-logues.The speech files are transcribed into ASCIItext files by hand.
The example of a tran-script is shown in Figure 1.
As an advanceanalysis, discourse tags are assigned to fillers,hesitations, and so on.
Furthermore, eachspeech is segmented into utterance units bya pause, and the exact start time and endtime are provided for them.
The environ-mental information about sex (male/female),speaker?s role (driver/navigator), dialogue taskFigure 1: Sample transcription of dialoguespeech(navigation/information retrieval/...), noise(noisy/clean) is provided for each utteranceunit.In order to study the features of in-car dia-logue speeches, we have investigated all driver?sutterance units of 195 dialogues.
The num-ber per utterance unit of fillers, hesitations andslips, are 0.34, 0.07, 0,04, respectively.
The factthat the frequencies are not less than those ofhuman-human conversations suggests the in-carspeech of the corpus to be spontaneous.2.2 Dependency Structure of SpokenLanguageIn order to characterize spontaneous dialoguespeeches from the viewpoint of dependency,we have constructed a spoken language cor-pus with dependency structures.
Dependencyanalyses have been provided by hand for alldriver?s utterance units in 81 spoken dialoguesof the in-car speech corpus.
The specificationsof part-of-speeches and dependency grammarsare in accordance with those of Kyoto Corpus(Kurohashi and Nagao, 1997), which is one ofJapanese text corpora.
We have provided thefollowing criteria for the linguistic phenomenapeculiar to spoken language:?
There is no bunsetsu on which fillers andhesitations depend.
They forms depen-dency structures independently.?
A bunsetsu whose head bunsetsu is omitteddoesn?t depend on any bunsetsu.?
The specification of part-of-speeches hasbeen provided for the phrases peculiar tospoken language by adding lexical entriesto the dictionary.?
We have defined one conversational turn asa unit of dependency parsing.
The depen-Table 1: Corpus data for dependency analysisDialogues 81Utterance units 7,781Conversational turns 6,078Bunsetsus 24,993Dependencies 11,789Dependencies per unit 1.52Dependencies per turn 1.94dencies might be over two utterance units,but be not hardly over two conversationalturns.The outline of the corpus with dependency anal-yses is shown in Table 1.
There exist 11,789dependencies for 24,993 bunsetsus 2.
The av-erage number of dependencies per turn is 1.94,and is exceedingly less than that of written lan-guage such as newspaper articles (about 10 de-pendencies).
This does not necessarily meanthat dependency parsing of spoken language iseasy than that of written language.
It is alsorequired to specify the bunsetsu with no headbunsetsu because every bunsetsu does not de-pend on another bunsetsu.
In fact, the bunset-sus which don?t have the head bunsetsu occupy52.8% of the whole.Next, we investigated inversion phenomenaand dependencies over two utterance units.
320inversions, 3.8% of all utterance turns andabout 0.04 times per turn, are in this data.
Thisfact means that the inversion phenomena cannot be ignored in spoken language processing.About 86.5% of inversions appear at the lastbunsetsu.
On the other hand, 73 dependen-cies, providing 5.4% of 1,362 turns consistingof more than two units, are over two utteranceunits.
Therefore, we can conclude that utter-ance units are not always sufficient as parsingunits of spoken language.3 Stochastic Dependency ParsingOur method provides the most plausible depen-dency analysis for each spoken language utter-ance unit by relaxing syntactic constraints andutilizing stochastic information acquired from alarge-scale spoken dialogue corpus.
In this pa-per, we define one turn as a parsing unit accord-2The frequency of filler bunsetsus is 3,049.010002000300040005000600070008000-4 -2 0 2 4 6 8Distance between bunsetsusNumber of dependencies-3 -1 1 3 5 7Figure 2: Distance between dependencies andits frequenciesing to the result of our investigation describedin Section 2.23.1 Dependency Structural ConstraintsAs Section 1 has already pointed out, mostconventional techniques for Japanese depen-dency parsing have assumed three syntacticconstraints.
Since the phenomena which are nothardly in written language appear frequently inspoken language, the actual dependency struc-ture does not satisfy such the constraints.
Ourmethod relaxes the constraints for the purposeof robust dependency parsing.
That is, ourmethod considers that the bunsetsus, whichdon?t have the head bunsetsu, such as fillersand hesitations, depend on themselves (relax-ing the constraint that each bunsetsu dependson another only one bunsetsu).
Moreover, wepermit that a bunsetsu depends on its left-sidebunsetsu to cope with the inversion phenomena(relaxing the constraint that dependencies aredirected from left to right) 3.3.2 Utilizing Stochastic InformationOur method calculates the plausibility of thedependency structure by utilizing the stochasticinformation.
The following attributes are usedfor that:?
Basic forms of independent words of a de-pendent bunsetsu biand a head bunsetsu3Since the phenomena that dependencies cross eachother is very few, the constraint is not relaxed.Table 2: Examples of the types of dependenciesDependent bunsetsu Type of dependencydenwa-ga (telephone) case particle ?ga?mise-de (at a store) case particle ?de?hayaku (early) continuous formookii (big) adnominal formkaeru (can buy) adnominal formchotto (briefly) adverbbj: hi, hj?
Part-of-speeches of independent words of adependent bunsetsu biand a head bunsetsubj: ti, tj?
Type of the dependency of a bunsetsu bi:ri?
Distance between bunsetsus biand bj: dij?
Number of pauses between bunsetsus biand bj: pij?
Location of a dependent bunsetsu bi: liHere, if a dependent bunsetsu bihas an ancillaryword, the type of the dependencies of a bunsetsubi, ri, is the lexicon, part-of-speech and conju-gated form of the word, and if not so, riis thepart-of-speech and the conjugated form of thelast morpheme.
Table 2 shows several exam-ples of the types of dependencies.
The locationof the dependent bunsetsu means whether it isthe last one of the turn or not.
As Section 2 in-dicates, the method uses the location attributefor calculating the probability of the inversion,because most inverse phenomena tend to appearat the last of the turn.The probability of the dependency betweenbunsetsus are calculated using these attributevalues as follows:P (i rel?
j|B)=C(i ?
j, hi, hj, ti, tj, ri)C(hi, hj, ti, tj, ri)(1)?C(i ?
j, ri, dij, pij, li)C(ri, dij, pij, li)Here, C is a cooccurrence frequency functionand B is a sequence of bunsetsus (b1b2?
?
?bn).In the formula (1), the first term of the righthand side expresses the probability of cooccur-rence between the independent words, and thesecond term does that of the distance betweenbunsetsus.
The problem of data sparseness is re-duced by considering these phenomena to be in-dependent each other and separating the prob-abilities into two terms.
The probability that abunsetsu which doesn?t have the head bunsetsucan also be calculated in formula (1) by con-sidering such the bunsetsu to depend on itself(i.e., i = j).
The probability that a dependencystructure for a sequence of bunsetsus B is S canbe calculated from the dependency probabilitiesbetween bunsetsus as follows.P (S|B) =n?i=1P (i rel?
j|B) (2)For a sequence of bunsetsus, B, the methodidentifies the dependency structure with?argmaxSP (S|B)?
satisfying the followingconditions:?
Dependencies do not cross each other.?
Each bunsetsu doesn?t no more than onehead bunsetsu.That is, our method considers the dependencystructure whose probability is maximum to bethe most plausible one.3.3 Parsing ExampleThe parsing example of a user?s utterancesentence including a filler ?eto?, a hesita-tion ?so?, a inversion between ?nai-ka-na?
and?chikaku-ni?, and a pause, ?Eto konbini nai-ka-na ?pause?
so sono chikaku-ni (Is there a conve-nience store near there?)?
is as follows:The sequence of bunsetsus of the sentence is?
[eto (well)],[konbini (convenience store)],[nai-ka-na (Is there?
)],?pause?, [so], [sono (there)],[chikaku-ni (near)]?.
The types of dependentof bunsetsus and the dependency probabilitiesbetween bunsetsus are shown in Table 2 and3, respectively.
Table 3 expresses that, for in-stance, the probability that ?konbini?
dependson ?nai-ka-na?
is 0.40.
Moreover, the probabil-ity of that ?eto?
depends on ?eto?
means thatthe probability of that ?eto?
does not dependon any bunsetsu.
Calculating the probabilityof every possible structure according to Table3, that of the dependency structure shown inFigure 3 becomes the maximum.Table 3: Dependency probabilities between bunsetsuseto konbini nai-ka-na so soko-no chikaku-nieto (well) 1.00 0.00 0.00 0.00 0.00 0.00konbini (convenience store) 0.00 0.01 0.40 0.00 0.00 0.00nai-ka-na (Is there?)
0.00 0.00 0.88 0.00 0.00 0.00so (hesitation) 0.00 0.00 0.00 1.00 0.00 0.00soko-no (there) 0.00 0.02 0.00 0.00 0.00 0.75chikaku-ni (near) 0.00 0.00 0.80 0.00 0.00 0.02eto        konbini          nai-kana                   so    soko-no  chikaku-ni<pose>Figure 3: Dependency structure of ?eto konbininai-kana ?pose?
so soko-no chikaku-ni?Table 4: Experimental result of dependencyparsingItem (a) (b) (a)+(b)Precision 82.0% 88.5% 85.5%Recall 64.3% 83.3% 73.8%(a): The result for 241 bunsetsus with a head(b): The result for 240 bunsetsus with no head(a)+(b): The result for 481 bunsetsus4 Parsing ExperimentIn order to evaluate the effectiveness of ourmethod, an experiment on dependency pars-ing has been made using a corpus of CIAIR(Kawaguchi et al, 2001).4.1 Outline of ExperimentWe used the same data as that for our investiga-tions in Section 2.2.
That is, among all driver?sutterance units of 81 dialogues, 100 turns wereused for the test data, and 5978 turns for thelearning data.
The test data, the average bun-setsus per turn is 4.81, consists of 481 depen-dencies.4.2 Experimental ResultThe results of the parsing experiment are shownpartially in Figure 4.
Table 4 shows the evalu-ation.
For the parsing accuracy, both precisionand recall are measured.
355 of 415 dependen-cies extracted by our method are correct depen-dencies, providing 85.5% for precision rate and73.8% for recall rate.
We have confirmed thatthe parsing accuracy of our method for spokenlanguage is as high as that of another meth-ods for written language (Fujio and Matsumoto,1998; Uchimoto et al, 1999).Our method correctly specified 200 of 240bunsetsus which don?t have the head bunsetsu.Most of them are fillers, hesitations and so on.It became clear that it is effective to utilize thedependency probabilities for identifying them.5 Concluding RemarksThis paper has proposed a method for depen-dency parsing of Japanese spoken language.The method can execute the robust analysis byrelaxing syntactic constraints of Japanese andutilizing stochastic information.
An experimenton CIAIR in-car spoken dialogue corpus hasshown our method to be effective for sponta-neous speech understanding.This experiment has been made on the as-sumption that the speech recognition systemhas a perfect performance.
Since the tran-script generated by a continuous speech recog-nition system, however, might include a lot ofrecognition errors, exceedingly robust parsingtechnologies are strongly required.
In order todemonstrate our method to be practical for au-tomatic speech transcription, an experiment us-ing a continuous speech recognition system willbe done.Acknowledgement: The authors would liketo thank all members of SLP Group in our lab-oratory for their contribution to the construc-tion of the Japanese spoken language corpuswith the dependency analysis.
This work is par-tially supported by the Grand-in-Aid for COEExample of correct parsing for inversione-to nedan-wa ryoho oshiete-morae-masu-ka daitai(Well, could you tell me both prices?
)Example of incorrect parsing (1)Hm.. chushajo-no aru aru-ka-naa(Is there a caf?
with a parking lot nearby ?
)chikaku-ni kissaten-teExample of incorrect parsing (2)Hm.. ramen-ga(Is there a caf?
with a parking lot nearby ?
)ikura-gurai-no arun-kacorrect resultincorrect resultright answerFigure 4: The results of parsing experiment (a part)Research of the Ministry of Education, Science,Sports and Culture, Japan and Aritificial Intel-ligence Research Promotion Foundation.ReferencesDen, Y.: A Unified Approach to Parsing SpokenNatural Language, Proceedings of 3rd Natu-ral Language Processing Pacific Rime Sympo-sium (NLPRS?95), pp.
574?579 (1995).Fujio, M. and Matsumoto, Y.: Japanese Depen-dency Structure Analysis based on Lexical-ized Statistics, Proceedings of 3rd Conferenceon Empirical Method for Natural LanguageProcessing (EMNLP?98), pp.
87?96 (1998).Kawaguchi, N., Matsubara, S., Takeda, K.,and Itakura, F.: Multi-Dimensional Data Ac-quisition for Integrated Acoustic InformationResearch, Proceedings of 3rd InternationalConference on Language Resources and Eval-uation (LREC2002), pp.
2043?2046 (2002).Kawaguchi, N., Matsubara, S., Takeda, K. andItakura, F.: Multimedia Data Collection ofIn-car Speech Communication, Proceedings of7th European Conference on Speech Commu-nication and Technology (Eurospeech2001),pp.
2027?2030 (2001).Kurohashi, S. and Nagao, M.: Kyoto Univer-sity Text Courpus Project, Proceedings of 3rdConference of Association for Natural Lan-guage Processing, pages:115?118 (1997).
(InJapanese)Kurohashi, S. and Nagao, M.: ?KN Parser:Japanese Dependency/Case Structure Ana-lyzer?
Proceedings of Workshop on SharableNatural Language Resources, pages:48?95(1994).Matsumoto, Y., Kitauchi, A., Yamashita, T.and Hirano, Y.: Japanese MorphologicalAnalysis System Chasen version 2.0 Man-ual, NAIST Techinical Report, NAIST-IS-TR99009 (1999).Uchimoto, K., Sekine, S. and Isahara, K.:Japanese Dependency Structure Analysisbased on Maximum Entropy Models, Pro-ceedings of 9th European Chapter of theAssociation for Computational Linguistics(EACL?99), pp.
196?203 (1999).
