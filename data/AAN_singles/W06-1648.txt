Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 408?414,Sydney, July 2006. c?2006 Association for Computational LinguisticsArabic OCR Error Correction Using Character Segment Correction,Language Modeling, and Shallow MorphologyWalid Magdy and Kareem DarwishIBM Technology Development CenterP.O.
Box 166 El-Ahram, Giza, Egypt{wmagdy,darwishk}@eg.ibm.comAbstractThis paper explores the use of a charactersegment based character correctionmodel, language modeling, and shallowmorphology for Arabic OCR error cor-rection.
Experimentation shows thatcharacter segment based correction is su-perior to single character correction andthat language modeling boosts correction,by improving the ranking of candidatecorrections, while shallow morphologyhad a small adverse effect.
Further,given sufficiently large corpus to extracta dictionary and to train a languagemodel, word based correction works wellfor a morphologically rich language suchas Arabic.1 IntroductionRecent advances in printed document digitizationand processing led to large scale digitization ef-forts of legacy printed documents producingdocument images.
To enable subsequent proc-essing and retrieval, the document images areoften transformed to character-coded text usingOptical Character Recognition (OCR).
AlthoughOCR is fast, OCR output typically contains er-rors.
The errors are even more pronounced inOCR?ed Arabic text due to Arabic?s orthographicand morphological properties.
The introducederrors adversely affect linguistic processing andretrieval of OCR?ed documents.
This paper ex-plores the effectiveness post-OCR error correc-tion.
The correction uses an improved charactersegment based noisy channel model, languagemodeling, and shallow morphological processingto correct OCR errors.
The paper will be organ-ized as follows:  Section 2 provides backgroundinformation on Arabic OCR and OCR error cor-rection; Section 3 presents the error correctionmethodology; Section 4 reports and discussesexperimental results; and Section 5 concludes thepaper and provides possible future directions.2 BackgroundThis section reviews prior work on Arabic OCRfor Arabic and OCR error correction.2.1 Arabic OCRThe goal of OCR is to transform a document im-age into character-coded text.
The usual processis to automatically segment a document imageinto character images in the proper reading orderusing image analysis heuristics, apply an auto-matic classifier to determine the character codesthat most likely correspond to each character im-age, and then exploit sequential context (e.g.,preceding and following characters and a list ofpossible words) to select the most likely charac-ter in each position.
The character error rate canbe influenced by reproduction quality (e.g.,original documents are typically better than pho-tocopies), the resolution at which a documentwas scanned, and any mismatch between the in-stances on which the character image classifierwas trained and the rendering of the characters inthe printed document.
Arabic OCR presents sev-eral challenges, including:?
Arabic?s cursive script in which most charac-ters are connected and their shape vary with posi-tion in the word.?
The optional use of word elongations and liga-tures, which are special forms of certain lettersequences.?
The presence of dots in 15 of the 28 letters todistinguish between different letters and the op-tional use of diacritic which can be confusedwith dirt, dust, and speckle (Darwish and Oard,2002).?
The morphological complexity of Arabic,which results in an estimated 60 billion possible408surface forms, complicates dictionary-based er-ror correction.
Arabic words are built from aclosed set of about 10,000 root forms that typi-cally contain 3 characters, although 4-characterroots are not uncommon, and some 5-characterroots do exist.
Arabic stems are derived fromthese root forms by fitting the root letters into asmall set of regular patterns, which sometimesincludes addition of ?infix?
characters betweentwo letters of the root (Ahmed, 2000).There is a number of commercial Arabic OCRsystems, with Sakhr?s Automatic Reader andShonut?s Omni Page being perhaps the mostwidely used.
Retrieval of OCR degraded textdocuments has been reported for many lan-guages, including English (Harding et al, 1997),Chinese (Tseng and Oard, 2001), and Arabic(Darwish and Oard, 2002).2.2 OCR Error CorrectionMuch research has been done to correctrecognition errors in OCR-degraded collections.There are two main categories of determininghow to correct these errors.
They are word-leveland passage-level post-OCR processing.
Some ofthe kinds of word level post-processing includethe use of dictionary lookup, probabilisticrelaxation, character and word n-gram frequencyanalysis (Hong, 1995), and morphologicalanalysis (Oflazer, 1996).
Passage-level post-processing techniques include the use of word n-grams, word collocations, grammar, conceptualcloseness, passage level word clustering,linguistic context, and visual context.
Thefollowing introduces some of the error correctiontechniques.?
Dictionary Lookup:  Dictionary Lookup, whichis the basis for the correction reported in thispaper, is used to compare recognized words withwords in a term list (Church and Gale, 1991;Hong, 1995; Jurafsky and Martin, 2000).
If aword is found in the dictionary, then it isconsidered correct.
Otherwise, a checkerattempts to find a dictionary word that might bethe correct spelling of the misrecognized word.Jurafsky and Martin (2000) illustrate the use of anoisy channel model to find the correct spellingof misspelled or misrecognized words.
Themodel assumes that text errors are due to editoperations namely insertions, deletions, andsubstitutions.
Given two words, the number ofedit operations required to transform one of thewords to the other is called the Levenshtein editdistance (Baeza-Yates and Navarro, 1996).
Tocapture the probabilities associated with differentedit operations, confusion matrices areemployed.
Another source of evidence is therelative probabilities that candidate wordcorrections would be observed.
Theseprobabilities can be obtained using wordfrequency in text corpus (Jurafsky and Martin,2000).
However, the dictionary lookup approachhas the following problems (Hong, 1995):a) A correctly recognized word might not be inthe dictionary.
This problem could surface if thedictionary is small, if the correct word is anacronym or a named entity that would notnormally appear in a dictionary, or if thelanguage being recognized is morphologicallycomplex.
In a morphological complex languagesuch as Arabic, German, and Turkish the numberof valid word surface forms is arbitrarily largewhich complicates building dictionaries for spellchecking.b) A word that is misrecognized is in thedictionary.
An example of that is the recognitionof the word ?tear?
instead of ?fear?.
Thisproblem is particularly acute in a language suchas Arabic where a large fraction of three letterssequences are valid words.?
Character N-Grams:  Character n-grams maybeused alone or in combination with dictionarylookup (Lu et al, 1999; Taghva et al, 1994).The premise for using n-grams is that some lettersequences are more common than others andother letter sequences are rare or impossible.
Forexample, the trigram ?xzx?
is rare in the Englishlanguage, while the trigram ?ies?
is common.Using this method, an unusual sequence of letterscan point to the position of an error in amisrecognized word.
This technique isemployed by BBN?s Arabic OCR system (Lu etal., 1999).?
Using Morphology:  Many morphologicallycomplex languages, such as Arabic, Swedish,Finnish, Turkish, and German, have enormousnumbers of possible words.
Accounting for andlisting all the possible words is not feasible forpurposes of error correction.
Domeij proposed amethod to build a spell checker that utilizes astem lists and orthographic rules, which governhow a word is written, and morphotactic rules,which govern how morphemes (building blocksof meanings) are allowed to combine, to acceptlegal combinations of stems (Domeij et al,1994).
By breaking up compound words,dictionary lookup can be applied to individualconstituent stems.
Similar work was done forTurkish in which an error tolerant finite state409recognizer was employed (Oflazer, 1996).
Thefinite state recognizer tolerated a maximumnumber of edit operations away from correctlyspelled candidate words.
This approach wasinitially developed to perform morphologicalanalysis for Turkish and was extended toperform spelling correction.
The techniquesused for Swedish and Turkish can potentially beapplied to Arabic.
Much work has been done onArabic morphology and can be potentiallyextended for spelling correction.?
Word Clustering:  Another approach tries tocluster different spellings of a word based on aweighted Levenshtein edit distance.
The insightis that an important word, specially acronymsand named-entities, are likely to appear morethan once in a passage.
Taghva described anEnglish recognizer that identifies acronyms andnamed-entities, clusters them, and then treats thewords in each cluster as one word (Taghva,1994).
Applying this technique for Arabicrequires accounting for morphology, becauseprefixes or suffixes might be affixed to instancesof named entities.
DeRoeck introduced aclustering technique tolerant of Arabic?scomplex morphology (De Roeck and Al-Fares,2000).
Perhaps the technique can be modified tomake it tolerant of errors.?
Using Grammar:  In this approach, a passagecontaining spelling errors is parsed based on alanguage specific grammar.
In a systemdescribed by Agirre (1998), an English grammarwas used to parse sentences with spellingmistakes.
Parsing such sentences gives clues tothe expected part of speech of the word thatshould replace the misspelled word.
Thuscandidates produced by the spell checker can befiltered.
Applying this technique to Arabic mightprove challenging because the work on Arabicparsing has been very limited (Moussa et al,2003).?
Word N-Grams (Language Modeling):  AWord n-gram is a sequence of n consecutivewords in text.
The word n-gram technique is aflexible method that can be used to calculate thelikelihood that a word sequence would appear(Tillenius, 1996).
Using this method, thecandidate correction of a misspelled word mightbe successfully picked.
For example, in thesentence ?I bought a peece of land,?
the possiblecorrections for the word peece might be ?piece?and ?peace?.
However, using the n-gram methodwill likely indicate that the word trigram ?pieceof land?
is much more likely than the trigram?peace of land.?
Thus the word ?piece?
is a morelikely correction than ?peace?.3 Error Correction MethodologyThis section describes the character level model-ing, the language modeling, and shallow mor-phological analysis.3.1 OCR Character Level ModelA noisy channel model was used to learn howOCR corrupts single characters or charactersegments, producing a character level confusionmodel.
To train the model, 6,000 OCR cor-rupted words were obtained from a modern print-ing of a medieval religious Arabic book (called?The Provisions of the Return?
or ?Provisions?for short by Ibn Al-Qayim).
The words werethen manually corrected, and the corrupted andmanually corrected versions were aligned.
TheProvisions book was scanned at 300x300 dotsper inch (dpi), and Sakhr?s Automatic Readerwas used to OCR the scanned pages.
From the6,000 words, 4,000 were used for training andthe remaining words were set aside for later test-ing.
The Word Error Rate (WER) for the 2,000testing words was 39%.
For all words (in train-ing and testing), the different forms of alef(hamza, alef, alef maad, alef with hamza on top,hamza on wa, alef with hamza on the bottom, andhamza on ya) were normalized to alef, and yaand alef maqsoura were normalized to ya.
Sub-sequently, the characters in the aligned wordscan aligned in two different ways, namely:  1:1(one-to-one) character alignment, where eachcharacter is mapped to no more than one charac-ter (Church and Gale, 1991); or using m:n align-ment, where a character segment of length m isaligned to a character segment of length n (Brilland Moore, 2000).
The second method is moregeneral and potentially more accurate especiallyfor Arabic where a character can be confusedwith as many as three or four characters.
Thefollowing example highlights the difference be-tween the 1:1 and the m:n alignment approaches.Given the training pair (rnacle, made):1:1 alignment :r     n     a     c     l     em    ?
a     d    ?
e410m:n alignment:For alignment, Levenstein dynamic program-ming minimum edit distance algorithm was usedto produce 1:1 alignments.
The algorithm com-putes the minimum number of edit operationsrequired to transform one string into another.Given the output alignments of the algorithm,properly aligned characters (such as a  a and e e) are used as anchors, ?
?s (null characters)are combined to misaligned adjacent charactersproducing m:n alignments, and ?
?s between cor-rectly aligned characters are counted as deletionsor insertions.To formalize the error model, given a clean word?
= #C1..Ck.. Cl..Cn# and the resulting OCR de-graded word ?
= #D1..Dx.. Dy..Dm#, where Dx.. Dyresulted from Ck.. Cl, ?
representing the nullcharacter, and # marking word boundaries, theprobability estimates for the three edit operationsfor the models are:Psubstitution (Ck..Cl ?> Dx.. Dy) =)..()....(lkyxlkCCcountDDCCcount ?Pdeletion (Ck..Cl ?> ?)
=)..()..(lklkCCcountCCcount ?
?Pinsertion (?
?>  Dx.. Dy) =)()..(CcountDDcount yx?
?When decoding a corrupted string ?
composed ofthe characters D1..Dx.. Dy..Dm, the goal is to finda string ?
composed of the characters C1..Ck..Cl..Cn such that P(?|?)?P(?)
is maximum.
P(?)
isthe prior probability of observing ?
in text andP(?|?)
is the probability of producing ?
from ?.P(?)
was computed from a web-mined collectionof religious text by Ibn Taymiya, the mainteacher of the medieval author of the ?Provi-sions?
book.
The collection contained approxi-mately 16 million words, with 278,877 uniquesurface forms.P(?|?)
is calculated using the trained model, asfollows:?=yx DDalllkyx CCDDPP..:)..|..()|( ?
?The segments Dx.. Dy are generated by finding allpossible 2n-1 segmentations of the word ?.
Forexample, given ?macle?
then all possible seg-mentations are (m,a,c,l,e), (ma,c,l,e), (m,ac,l,e),(mac,l,e), (m,a,cl,e), (ma,cl,e), (m,acl,e),(macl,e), (m,a,c,le), (ma,c,le), (m,ac,le), (mac,le),(m,a,cle), (ma,cle), (m,acle), (macle).All segment sequences Ck.. Cl known to produceDx.. Dy for each of the possible segmentations areproduced.
If a sequence of C1.. Cn segmentsgenerates a valid word ?
which exists in the web-mined collection, then argmax?
P(?|?)?P(?)
iscomputed, otherwise the sequence is discarded.Possible corrections are subsequently ranked.For all the experiments reported in this paper, thetop 10 corrections are generated.
Note that errorcorrection reported in this paper does not assumethat a word is correct because it exists in theweb-mined collection and assumes that all wordsare possibly incorrect.The effect of two modifications to the m:n char-acter model mentioned above were examined.The first modification involved making the char-acter model account for the position of letters ina word.
The intuition for this model is that sinceArabic letters change their shape based on theirpositions in words and would hence affect theletters with which they would be confused.Formally, given L denoting the positions of theletter at the boundaries of character segments,whether start, middle, end, or isolated, the char-acter model would be:Psubstitution (Ck..Cl ?> Dx.. Dy | L) =)|..()|....(LCCcountLDDCCcountlkyxlk ?Pdeletion (Ck..Cl ?> ?
| L) =)|..()|..(LCCcountLCCcountlklk ?
?Pinsertion (?
?>  Dx.. Dy) =)|()|..(LCcountLDDcount yx?
?The second modification involved giving a smalluniform probability to single character substiu-tions that are unseen in the training data.
Thiswas done in accordance to Lidstone?s law tosmooth probabilities.
The probability was set tobe 100 times smaller than the probability of thesmallest seen single character substitution*.
* Other uniform probability estimates were examined for thetraining data and the one reported here seemed to work bestr     n      a     c     l     em       a     d      e4113.2 Language ModelingFor language modeling, a trigram languagemodel was trained on the same web-mined col-lection that was mentioned in the previous sub-section without any kind of morphological proc-essing.
Like the text extracted from the ?Provi-sions?
book, alef and ya letter normalizationswere performed.
The language model was builtusing SRILM toolkit with Good-Turing smooth-ing and default backoff.Given a corrupted word sequence ?
= {?1 .. ?i ..?n} and ?
= {?1 .. ?i .. ?n}, where ?i ={?i0 .. ?im}are possible corrections of ?i (m = 10 for all theexperiments reported in the paper), the aim wasto find a sequence ?
= {?1 .. ?i .. ?n}, where?i ?
?i, that maximizes:( )4342144444 344444 21 odelCharacterMijidelLanguageMojijiijmjniPP )|(,| ,2,1..1,..1 ?????
???????
?
?
?==3.3 Language Modeling and Shallow Mor-phological AnalysisTwo paths were pursued to explore the combinedeffect of language modeling and shallow mor-phological analysis.In the first, a 6-gram language model was trainedon the same web-mined collection after each ofthe words in the collection was segmented intoits constituent prefix, stem, and suffix (in thisorder) using language model based stemmer (Leeet al, 2003).
For example, ?
?PQR?TU  ?
wktAbhm?was replaced by ?w# ktAb +hm?
where # and +were used to mark prefixes and suffixes respec-tively and to distinguish them from stems.
Likebefore, alef and ya letter normalizations wereperformed and the language model was built us-ing SRILM toolkit with the same parameters.Formally, the only difference between thismodel and the one before is that ?i ={?i0 .. ?im}are the {prefix, stem, suffix} tuples of the possi-ble corrections of ?i (a tuple is treated as a block).Otherwise everything else is identical.In the second, a trigram language model wastrained on the same collection after the languagemodeling based stemming was used on all thetokens in the collection (Lee et al, 2003).
Thetop n generated corrections were subsequentlystemmed and the stems were reranked using thelanguage model.
The top resulting stem wascompared to the condition in which languagemodeling was used without morphologicalanalysis (as in the previous subsection) and thenthe top resulting correction were stemmed.
Thispath was pursued to examine the effect of correc-tion on applications where stems are more usefulthan words such as Arabic information retrieval(Darwish et al, 2005; Larkey et al, 2002).3.4 Testing the ModelsThe 1:1 and m:n character mapping models weretested while enabling or disabling character posi-tion training (CP), smoothing by the assignmentof small probabilities to unseen single charactersubstitutions (UP), language modeling (LM), andshallow morphological processing (SM) usingthe 6-gram model.As mentioned earlier, all models were tested us-ing sentences containing 2,000 words in total.4 Experimental ResultsTable 1 reports on the percentage of words forwhich a proper correction was found in the top ngenerated corrections using different models.The percentage of words for which a proper cor-rection exists in the top 10 proposed correction isthe upper limit accuracy we can achieve giventhan we can rerank the correction using languagemodeling.
Table 2 reports the word error rate forthe 1:1 and m:n models with and without CP,UP, LM, and SM.
Further, the before and afterstemming error rates are reported for setups thatuse language modeling.
Table 3 reports on thestem error rate when using the stem trigram lan-guage model.The best model was able to find the proper cor-rection within the top 10 proposed correction for90% of the words.
The failure to find a propercorrection within the proposed corrections wasgenerally due to grossly misrecognized wordsand was rarely due to words that do not exist inweb-mined collection.
Perhaps, more trainingexamples for the character based models wouldimprove correction.Corrections 1 2 3 4 5 101:1 75.3 80.3 83.1 84.5 85 86.51:1 + CP 76.9 82.1 83.5 83.2 85 861:1 + UP 76 81 83.6 84.6 85.2 86.7m:n 78.3 83.5 85.4 86.7 87.1 88.5m:n + CP 79.9 83.9 84.0 85.5 85.9 86.8m:n + UP 78.4 83.7 85.6 84.1 87.0 90.0Table 1:  Percentage of words for which a proper cor-rection was found in the top n generated corrections412Model 1:1 m:nWord Stem Word StemNo Correction 39.0% - 39.0% -Base Model 24.7% - 21.8% -+ CP 23.1% - 21.5% -+ UP 24% - 21.6% -+ LM 15.8% 14.6% 13.3% 12.1%+ LM + CP 16.5% 15.1% 15.5% 14.7%+ LM + UP 15.4% 14.3% 11.7% 10.8%+ SM + UP 27.8% 26.5% 24.5% 23.0%Table 2:  Word/stem error rate for correction with thedifferent modelsModel 1:1 m:nStem 3-gram 16.1% 12.9%Table 3:  Stem error rate for top correction using stemtrigram language modelThe results indicate that the m:n character modelis better than the 1:1 model in two ways.
Thefirst is that the m:n model yielded a greater per-centage of proper corrections in the top 10 gen-erated corrections, and the second is that thescores of the top 10 corrections were betterwhich led to better results compared to the 1:1model when used in combination with languagemodeling.
For the m:n model with languagemodeling, the language model properly pickedthe proper correction from the proposed correc-tion 98% of the time (for the cases where aproper correction was within the proposed cor-rections).Also the use of smoothing, UP, produced bettercorrections, while accounting for character posi-tions had an adverse effect on correction.
Thismight be an indication that the character segmentcorrection training data was sparse.
Using the 6-gram language model on the segmented wordshad a severely negative impact on correction ac-curacy.
Perhaps is due to insufficient trainingdata for the model.
This situation lends itself tousing a factored language model using the sur-face form of words as well as other linguisticfeatures of the word such as part of speech tags,prefixes, and suffixes.As for training a language model on words ver-sus stems, the results suggest that word basedcorrection is slightly better than stem based cor-rection.
The authors?
intuition is that this re-sulted from having a sufficiently large corpus totrain the language model and that this might havebeen reversed if the training corpus for the lan-guage model was smaller.
Perhaps further inves-tigation would prove or disprove the authors?intuition.5 Conclusion and Future WorkThe paper examined the use of single characterand character segment models based correctionof Arabic OCR text combined with languagemodeling and shallow morphological analysis.Further, character position and smoothing issueswere also examined.
The results show the supe-riority of the character segment based modelcompared to the single character based model.Further, the use of language modeling yieldedimproved error correction particularly for thecharacter segment based model.
Accounting forcharacter position and shallow morphologicalanalysis had a negative impact on correction,while smoothing had a positive impact.
Lastly,given a large in-domain corpus to extract a cor-rection dictionary and to train a language modelis a sufficient strategy for correcting a morpho-logically rich language such as Arabic with a70% reduction in word error rate.For future work, a factor language modelmight prove beneficial to incorporate morpho-logical information and other factors such as partof speech tags while overcoming training datasparseness problems.
Also, determining the sizeof a sufficiently large corpus to generate a cor-rection dictionary and to train a language modelis desirable.
Finally, word prediction mightprove useful for cases where OCR grossly mis-recognized words.ReferenceAgirre, E., K. Gojenola, K. Sarasola, and A. Vouti-lainen.
Towards a Single Proposal in Spelling Cor-rection.
In COLING-ACL'98 (1998).Ahmed, M. A Large-Scale Computational Processorof Arabic Morphology and Applications.
MSc.
The-sis, in Faculty of Engineering Cairo University:Cairo, Egypt.
(2000).Baeza-Yates, R. and G. Navarro.
A Faster Algorithmfor Approximate String Matching.
In Combinato-rial Pattern Matching (CPM'96), Springer-VerlagLNCS (1996).Brill, E. and R. Moore.
An improved error model fornoisy channel spelling correction.
In the proceed-ings of the 38th Annual Meeting on Association forComputational Linguistics, pages 286 ?
293 (2000).Church, K. and W. Gale.
?Probability ScoringforSpelling Correction.?
Statistics and Computing, 1:93-103 (1991).Darwish, K. and D. Oard.
Term Selection for Search-ing Printed Arabic.
In SIGIR-2002 (2002).413Darwish, K., H. Hassan, and O. Emam.
Examiningthe Effect of Improved Context Sensitive Morphol-ogy on Arabic Information Retrieval.
In ACL Work-shop on Computation Approaches to Semitic Lan-guages, Ann Arbor, (2005).De Roeck, A. and W. Al-Fares.
A MorphologicallySensitive Clustering Algorithm for Identifying Ara-bic Roots.
In the 38th Annual Meeting of the ACL,Hong Kong, (2000).Domeij, R., J. Hollman, V. Kann.
Detection of spell-ing errors in Swedish not using a word list en clair.Journal of Quantitative Linguistics (1994) 195-201.Harding, S., W. Croft, and C. Weir.
Probabilistic Re-trieval of OCR-degraded Text Using N-Grams.
InEuropean Conference on Digital Libraries (1997).Hong, T. Degraded Text Recognition Using Visualand Linguistic Context.
Ph.D. Thesis, ComputerScience Department, SUNY Buffalo: Buffalo (1995).Jurafsky, D. and J. Martin.
Speech and LanguageProcessing.
Chapter 5: pages 141-163.
PrenticeHall (2000).Larkey, L., L. Ballesteros, and M. Connell.
Improvingstemming for Arabic information retrieval: lightstemming and cooccurrence analysis.
In proceed-ings of the 25th annual international ACM SIGIRconference, pages 275-282 (2002).Lee, Y., K. Papineni, S. Roukos, O. Emam, and H.Hassan.
Language Model Based Arabic Word Seg-mentation.
In the Proceedings of the 41st AnnualMeeting of the Association for Computational Lin-guistics, pages 399 - 406 (2003).Lu, Z., I. Bazzi, A. Kornai, J. Makhoul, P. Natarajan,and R. Schwartz.
A Robust, Language-IndependentOCR System.
In the 27th AIPR Workshop: Ad-vances in Computer Assisted Recognition, SPIE(1999).Moussa B., M. Maamouri, H. Jin, A. Bies, X. Ma.Arabic Treebank: Part 1 - 10Kword English Trans-lation.
Linguistic Data Consortium (2003).Oflazer, K. Error-Tolerant Finite State Recognitionwith Applications to Morphological Analysis andSpelling Correction.
Computational Linguistics22(1), 73-90 (1996).Taghva, K., J. Borsack, and A. Condit.
An ExpertSystem for Automatically Correcting OCR Output.In SPIE - Document Recognition (1994).Tillenius, M., Efficient generation and ranking ofspelling error corrections.
NADA (1996).Tseng, Y. and D. Oard.
Document Image RetrievalTechniques for Chinese.
In Symposium on Docu-ment Image Understanding Technology, Columbia,MD (2001).414
