A Cognitive Model of Coherence-Driven Story ComprehensionEl l io t  Smi thSchool of Computer Science, University of Birmingham,Edgbaston, Birmingham B15 2TT.
United Kingdom.email: e.smith@cs.bham.ac.ukAbst rac tCurrent models of story comprehension havethree major deficiencies: (1) lack of experimen-tal support for the inference processes they in-volve (e.g.
reliance on prediction); (2) indif-ference to 'kinds' of coherence (e.g.
local andglobal); and (3) inability to find interpretationsat variable depths.
I propose that comprehen-sion is driven by the need to find a representa-tion that reaches a 'coherence threshold'.
Vari-able inference processes are a reflection of differ-ent thresholds, and the skepticism of an individ-ual inference process determines how thresholdsare reached.1 In t roduct ionRecent research in psychology maintains thatcomprehension is 'explanation-driven' (Graesseret al, 1994) and guided by the 'need for coher-ence' (van den Broek et al, 1995).
The com-prehender's goal is construction of a more-or-less coherent representation which includes ex-planations for and relations between the story'seventualities.
This representation is generatedvia inferences, which enrich the representationuntil it reaches the threshold specified by thecomprehender's coherence need (van den Broeket al, 1995).By contrast, early models of comprehensionemphasised its expectation-driven nature: pre-diction of future eventualities, followed by sub-stantiation of these predictions (DeJong, 1979).The inference processes described in these earlymodels are still implemented in many contem-porary systems.One problem with these models is their fail-ure to account for experimental evidence aboutinferences: predictive inferences are not gener-ated at point x in the story, unless trongly sup-ported by the story up to point x (Trabasso andMagliano, 1996); in addition, predictive infer-ences not immediately confirmed by the storyafter point x are not incorporated into the rep-resentation (Murray et al, 1993).
While it isdifficult to define 'strong support' or 'confirma-tion', it is clear that an overly-assumptive modeldoes not reflect mundane comprehension.A second problem is the failure of these mod-els to account for differential establishment oflocal and global coherence.
Local coherenceholds between 'short sequences ofclauses', whileglobal coherence is measured in terms of 'over-arching themes' (Graesser et al, 1994).
McK-oon and Ratcliff (1992) maintain that only localcoherence is normally established uring com-prehension (the minimalist hypothesis).
Othersstate that readers 'attempt to construct a mean-ing representation that is coherent at both localand global levels' (the constructionist hypothe-sis) (Graesser et al, 1994).
Script-based mod-els allow globally-coherent structures to be con-structed automatically, contradicting the mini-malist hypothesis; the inclusion of promiscuouspredictive inferences also contradicts the con-structionist hypothesis.A third problem is that previous models denycomprehension's flexibility.
This issue is some-times side-stepped by assuming that compre-hension concludes with the instantiation of oneor more 'primitive' or 'top-level' patterns.
An-other approach is to apply lower-level patternswhich account for smaller subsets of the input,but the aim is still to connect a story's first even-tuality to its last (van den Broek et al, 1995).This paper describes a model which treatsinferences as coherence generators, where aninference's occurrence depends on its coher-ence contribution.
Unusual inference-making,establishment of local and global coherence,and variable-precision comprehension can be1499described within this framework.2 Coherence  and  Sat i s f i c ingA schema is any function which maps inputsonto mental representations.
It contains slotswhich can be instantiated using explicit in-put statements, or implicit statements derivedvia proof or assumption.
Instantiated schemasform the building blocks of the comprehender'srepresentation.
A comprehender has availableboth 'weak' schemas, which locally link smallamounts of input (e.g.
causal schemas); and'strong' schemas, which globally link larger sec-tions of input (e.g.
scripts).All schemas generate 'connections of intelligi-bility' which affect the coherence of a represen-tation (Harman, 1986).
Coherence is a common'currency' with which to measure the benefit ofapplying a schema.
Instead of requiring that atop-level structure be instantiated, the systeminstead applies schemas to produce a represen-tation of sufficient 'value'.
This process can benaturally described as abduction, or 'inferenceto the best explanation' (Ng and Mooney, 1990).Previous natural-language abduction systemscan form more-or-less coherent representations:for example, by halting comprehension whenassumptions start to reduce coherence (ibid.
).However, these systems till have a fixed 'cut-off' point: there is no way to change the criteriafor a good representation, for example, by re-quiring high coherence, ven if this means mak-ing poorly-supported assumptions.
By treatingcoherence as the currency of comprehension, theemphasis hifts from creating a 'complete' rep-resentation, to creating a satisficing one.
(Asatisficing representation is not necessarily op-timal, but one which satisfies ome minimal con-straint: in this case, a coherence threshold.
)3 Coherence-Dr iven  Comprehens ionIn this section, I outline some general princi-ples which may attenuate the performance of acomprehension system.
I begin with the generaldefinition of a schema:Cl ,  .
.
.
,  C.n --)' I.where cl, ..., c~ are the elements connected byI.
The left-hand side of a schema is its conditionset, and the right-hand side represents he inter-pretation of those conditions in terms of otherconcepts (e.g.
a temporal relation, or a corn-pound event sequence).
During each processingcycle, condition sets are matched against he setof observations.At present, I am developing a metric whichmeasures coherence contribution with respect oa schema nd a set of observations:C = (Y x U) - (P ?
S)where C = coherence contribution; V = Cov-erage; U--  Utility; P -- Completion; and S =Skepticism.
This metric is based on work incategorisation and diagnosis, and measures thesimilarity between the observations and a con-dition set (Tversky, 1977).3.1 Coverage and  Complet ionCoverage captures the principle of conflict res-olution in production systems.
The more ele-ments matched by a schema, the more coherencethat schema imparts on the representation, andthe higher the Coverage.
By contrast, Com-pletion represents the percentage of the schemathat is matched by the input (i.e.
the complete-ness of the match).
Coverage and Completionthus measure different aspects of the applica-bility of a schema.
A schema with high Cov-erage may match all of the observations; how-ever, there may be schema conditions that areunmatched.
In this case, a schema with lowerCoverage but higher Completion may generatemore coherence.3.2 UtilityThe more observations a schema can explain,the greater its coherence contribution.
Utilitymeasures this inherent usefulness: schemas withmany conditions are considered to contributemore coherence than schemas with few.
Util-ity is independent of the number of observa-tions matched, and reflects the structure of theknowledge base (KB).
In previous comprehen-sion models, the importance of schema size isoften ignored: for example, an explanation re-quiring a long chain of small steps may be lesscostly than a proof requiring a single large step.To alleviate this problem, I have made a com-mitment o schema 'size', in line with the no-tion of 'chunking' (Laird et al, 1987).
Chunkedschemas are more efficient as they require fewerprocessing cycles to arrive at explanations.15003.3 SkepticismThis parameter represents the unwillingness ofthe comprehender to 'jump to conclusions'.
Forexample, a credulous comprehender (with lowSkepticism) may make a thematic inference thata trip to a restaurant is being described, whenthe observations lend only scant support o thisinference.
By raising the Skepticism parameter,the system may be forced to prove that suchan inference is valid, as missing evidence nowdecreases coherence more drasticallyJ4 ExampleSkepticism can have a significant impact on thecoherence contribution of a schema.
Let the setof observations consist of two statements:enter(john, restaurant), order(john, burger)Let the KB consist of the schema (with Utilityof 1, as it is the longest schema in the KB):enter (Per, Rest), order(Per, Meal),leave(Per, Rest) --~restaurantvisit( Per, Meal, Rest).In this case, C = (V x U) - (P x S), where:Coverage(V) = Observat ionsCovered ~- 2N urnberO f Observat ionsUtility(U) = 1Completion(P) = Condi t ionsUnrnatched ~_.
1N urnberO / C andit ions1 Skepticism(S) =Therefore, C = ~, with leave(john, restau-rant) being the assumption.
If S is raised to1, C now equals 2 5, with the same assumption.Raising S makes the system more skeptical, andmay prevent hasty thematic inferences.5 Future  WorkPrevious models of comprehension have reliedon an 'all-or-nothing' approach which deniespartial representations.
I believe that chang-ing the goal of comprehension from top-level-pattern instantiation to coherence-need satis-faction may produce models capable of produc-ing partial representations.One issue to be addressed is how coherenceis incrementally derived.
The current metric,and many previous ones, derive coherence froma static set of observations.
This seems im-plausible, as interpretations are available at anypoint during comprehension.
A second issue is1Skepticism is a global parameter which 'weights' allschema applications.
Local weights could also be at-tached to individual conditions (see section 5).the cost of assuming various conditions.
Somemodels use weighted conditions, which differ-entially impact on the quality of the represen-tation (Hobbs et al, 1993).
A problem withthese schemes is the sometimes ad hoc charac-ter of weight assignment: as an antidote to this,I am currently constructing a method for de-riving weights from condition distributions overthe KB.
This moves the onus from subjectivedecisions to structural criteria.Re ferencesG.F.
DeJong.
1979.
Prediction and substanti-ation: A new approach to natural languageprocessing.
Cognitive Science, 3:251-273.A.C.
Graesser, M. Singer, and T. Trabasso.1994.
Constructing inferences during narra-tive text comprehension.
Psychological Re-view, 101(3):371-395.G.
Harman.
1986.
Change in View.
MIT Press,Cambridge, MA.J.R.
Hobbs, M.E.
Stickel, D.E.
Appelt, andP.
Martin.
1993.
Interpretation asabduction.Artificial Intelligence, 63(1-2):69-142.J.E.
Laird, A. Newell, and P.S.
Rosenbloom.1987.
Soar: An architecture for general in-telligence.
Artificial Intelligence, 33:1-64.G.
McKoon and R. Ratcliff.
1992.
Infer-ence during reading.
Psychological Review,99(3):440--466.J.D.
Murray, C.M.
Klin, and J.L.
Myers.
1993.Forward inferences in narrative text.
Journalof Memory and Language, 32:464-473.H.T.
Ng and R.J. Mooney.
1990.
On the roleof coherence in abductive explanation.
InProceedings of the 8th AAAI, pages 337-342,Boston, MA, July-August.T.
Trabasso and J.P. Magliano.
1996.
Con-scious understanding during comprehension.Discourse Processes, 21:255-287.A.
Tversky.
1977.
Features of similarity.
Psy-chological Review, 84:327-352.P.
van den Broek, K. Risden, and E. Husebye-Hartmann.
1995.
The role of readers' stan-dards for coherence in the generation of infer-ences during reading.
In R.F.
Lorch, Jr., andE.J.
O'Brien, editors, Sources of Coherence inReading, pages 353-373.
Lawrence Erlbaum,Hillsdale, NJ.1501Tree-based Analysis of Simple Recurrent Network LearningIvelin StoianovDept.
Alfa-Informatica, Faculty of Arts, Groningen University, POBox 716, 9700 AS Groningen,The Netherlands, Email:stoianov@let.rug.nl1 Simple recurrent networks for naturallanguage phonotacfics analysis.In searching for a cormectionist paradigm capable ofnatural anguage processing, many researchers haveexplored the Simple Recurrent Network (SRN) suchas Elman(1990), Cleermance(1993), Reilly(1995)and Lawrence(1996).
SRNs have a context layerthat keeps track of the past hidden neuronactivations and enables them to deal with sequentialdata.
The events in Natural Language span time soSRNs are needed to deal with them.Among the various levels of language proce-ssing, a phonological level can be distinguished.
ThePhonology deals with phonemes or graphemes - thelatter in the case when one works with orthographicword representations.
The principles governing thecombinations of these symbols is called phonotactics(Laver'1994).
It is a good starting point forconnectionist language analysis because there arenot too many basic entities.
The number of thesymbols varies between 26 (for the Latingraphemes) and 50 *(for the phonemes).Recently, some experiments consideringphonotactics modelling with SRNs have been cardedout by Stoianov(1997), Rodd(1997).
The neuralnetwork in Stoianov(1997) was trained to study thephonotactics of a large Dutch word corpus.
Thisproblem was implemented asan SRN learning task -to predict he symbol following the left context givento the input layer so far.
Words were applied to thenetwork, symbol by symbol, which in turn wereencoded orthogonally, that is, one node standing forone symbol (Fig.l).
An extra symbol ('#') was usedas a delimiter.
After the training, the networkresponded to the input with different neuronactivations at the output layer.
The more active agiven output neuron is, the higher the probability isthat it is a successor.
The authors used a so-calledoptimal threshold method for establishing thethreshold which determines the possible successors.This method was based on examining the network"for Dutch, and up to at most 100 in other languages.response to a test corpus of words belonging to thetrained language and a random corpus, built up fromrandom strings.
Two error functions dependent on athreshold were computed, for the test and therandom corpora, respectively.
The threshold atwhich both errors had minimal value was selected asan optimal threshold.
Using this approach, an SRN,trained to the phonotactics of a Dutch monosyllabiccorpus containing 4500 words, was reported todistinguish words from non-words with 7% error.Since the phonotactics of a given language isrepresented by the constraints allowing a givensequence to be a word or not, and the SRN managedto distinguish words from random strings withtolerable rror, the authors claim that SRNs are ableto learn the phonotactics of Dutch language.SRtFig.1.
SRN and mechanism of sequenceprocessing.
A character is provided to the inputand the next one is used for training.
In turn, ithas to be predicted uring the test phase.In the present report, alternative evaluationprocedures are proposed.
The network evaluationmethods introduced are based on examining thenetwork response to each left context, available inthe training corpus.
An effective way to representand use the complete set of context strings is a tree-based data structure.
Therefore, these methods aretermed tree-based analysis.
Two possibleapproaches are proposed for measuring the SRNresponse accuracy to each left context.
The fh-st usesthe idea mentioned above of searching a thresholdthat distinguishes permitted successors fromimpossible ones.
An error as a function of the1502threshold is computed.
Its minimum valuecorresponds to the SRN learning error rate.
Thesecond approach computes the local proximitybetween the network response and a vectorcontaining the empirical symbol probabilities that agiven symbol would follow the current left context.Two measures are used: 1,2 norm and normalisedvector multiplication.
The mean of these localproximities measures how close the networkresponses are to the desired responses.2 Tree-based corpus representation.There are diverse methods to represent a given set ofwords (corpus).
Lists is the simplest, but they arenot optimal with regard to the memory complexityand the time complexity of the operations workingwith the data.
A more effective method is the tree-based representation.
Each node in this tree has amaximum of 26 possible children (successors), if wework with orthographic word representations.
Theroot is empty, it does not represent a symbol.
It isthe beginning of a word.
The leaves do not havesuccessors and they always represent the end of aword.
A word can end somewhere between the rootand the leaves as well.
This manner of corpusrepresentation, termed trie, is one of the mostcompact representations and is very effective fordifferent operations with words from the corpus.In addition to the symbol at each node, we cankeep additional information, for example thefrequency of a word, if this node is the end of aword.
Another useful piece of information is thefrequency of each node C, that is, the frequency ofeach left context.
It is computed recursively as asum of the frequencies of all successors and thefrequency of the word ending at this node, providedthat such a word exists.
These frequencies give us aninstant evaluation of the empirical distribution foreach successor.
In order to compute the successors'empirical distribution vector 're(.
), we have tonormalise the successors' frequencies with respect otheir sum.3 Tree-based  eva luat ion  of  SRN learning.During the training of a word, only one outputneuron is forced to be active in response to thecontext presented so far.
But usually, in the entirecorpus there are several successors following a givencontext.
Therefore, the training should result inoutput neurons, reproducing the successors'probability distribution.
Following this reasoning,we can derive a test procedure that verifies whetherthe SRN output activations correspond to these localdistributions.
Another approach related to thepractical implementation of a trained SRN is tosearch for a cue, giving an answer to the questionwhether given symbol can follow the contextprovided to the input layer so far.
As in the optimalthreshold method we can search for a threshold thatdistinguishes these neurons.The tree-based learning examination methodsare recursive procedures that process each tree node,performing an in-order (or depth-first) treetraversal.
This kind of traversal algorithms startfrom the root and process each sub-tree completely.At each node, a comparison between the SRNsreaction to the input, and the empirical charactersdistribution is made.
Apart from this evaluation, theSRN state, that is, the context layer, has to be keptbefore moving to one of the sub-trees, in order for itto be reused after traversing this sub-tree.On the basis of above ideas, two methods fornetwork evaluation are performed at each tree nodeC.
The first one computes an error function P(t)dependent on a threshold t. This function gives theerror rate for each threshold t, that is, the ratio oferroneous predictions given t. The values of P(t) arehigh for close to zero and close to one thresholds,since almost all neurons would permit thecorrespondent symbols to be successors in the firstcase, and would not allow any successor in thesecond case.
The minimum will occur somewhere inthe middle, where only a few neurons would have anactivation higher than this threshold.
The trainingadjusts the weights of the network so that onlyneurons corresponding to actual successors areactive.
The SRN evaluation is  based on the meanF(t) of these local error functions (Fig.2a).The second evaluation method computes theproximity D c = \]NO(.)
,TO(.)
\[between the networkresponse N?(.)
and the local empirical distributionsvector To(.)
at each tree node.
The final evaluationof the SRN training is the n'r.an D of D c for all treenodes.
Two measures are used to compute D c. Thefirst one is 1,2 norm (1):(1) l N c(.)
,To(.)
I~ = \[M" r~.,.M (NC(x)-TC(x))" \],a1503The second is a vector multiplication, normali-sed with respect to the vector's length (cosine) (2):(2) \[ NC(.)
,TC(.)
I v =(INC(.
)l ITC(.
)l) "z ,V-~=I_M (NC(x)TC(x))where M is the vector size, that is, the number ofpossible successors (e.g.
27) (see Fig.
2b).4 Resu l ts .Well-trained SRNs were examined with both theoptimal threshold method and the tree-basedapproaches.
A network with 30 hidden neuronspredicted about 11% of the characters erroneously.The same network had mean 1,2 distance 0.056 andmean vector-multiplication proximity 0.851.
At thesame time, the optimal threshold method rated thelearning at 7% error.
Not surprisingly, the tree-based evaluations methods gave higher error rate -they do not examine the SRN response to non-existent left contexts, which in turn are used in theoptimal threshold method.Discuss ion  and  conc lus ions .Alternative valuation methods for SRN learning areproposed.
They examine the network response onlyto the training input data, which in turn isrepresented in a tree-based structure.
In contrast,previous methods examined trained SRNs with testand random corpora.
Both methods give a good ideaabout he learning attained.
Methods used previouslyestimate the SRN recognition capabilities, while themethods presented here evaluate how close thenetwork response is to the desired response - but forfamiliar input sequences.
The desired response isconsidered to be the successors' empiricalprobability distribution.
Hence, one of the methodsproposed compares the local empirical probabilities3o ~ ~ ~ M~E~<O.~>=o.~I  -.
.
.
.
: .
.
.
.
.
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.?
.20 .
.
- ;  .
.
.
.
.
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.
: .
.
.
.
: .
.
.
.
: .
.
.
.1510 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.500 2 4 6 8 Thrls~ld 12 14 1.6 18 20to the network response.
The other approachsearches for a threshold that minimises theprediction error function.
The proposed methodshave been employed in the evaluation ofphonotactics learning, but they can be used invarious other tasks as well, wherever the data can beorganised hierarchically.
I hope, that the proposedanalysis will contribute to our understanding oflearning carded out in SRNs.R e f e r e n c e s .Cleeremans, Axel (1993).
Mechanisms of ImplicitLearning.MIT Press.Elman, J.L.
(1990).
Finding structure in time.
CognitiveScience, 14, pp.179-211.Elman, J.L., et al (1996).
Rethinking Innates.
ABradford Book, The Mit Press.Haykin, Simon.
(1994).
Neural Networks, MacmillanCollege Publisher.Laver,John.
(1994).Principles of phonetics,Cambr.
Un Pr.Lawrence, S., et al(1996).NL Gramatical Inference AComparison of RNN and ML Methods.
Con-nectionist statistical and symbolic approaches tolearning for NLP, Springer-Verlag,pp.33-47Nerbonne, John, et al(1996).
Phonetic Distance betweenDutch Dialects.
In G.Dureux, W.Daelle-mans &S.Gillis(eds) Proc.of CLlN, pp.
185-202Reilly, Ronan G.(1995).Sandy Ideas and Coloured Days:Some Computational Implications of Embodiment.Art.
Intellig.
Review,9: 305-322.,Kluver Ac.
Publ.,NL.Rodd, Jenifer.
(1997).
Recurrent Neural-NetworkLearning of Phonological Regula-rities in Turkish,ACL'97 Workshop: Computational Natural languagelearning, pp.
97-106.Stoianov, I.P., John Nerbonne and Huub Bouma (1997).Modelling the phonotactic structure of naturallanguage words with Simple Recurrent Networks,Proc.
of 7-th CLIN'97 (in press)?
L2<~, t , r~,~- -0 .~ - -?
cOs i l le ( l te t  , t t~e ) ~ .~t .
~.
.
.
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.
: .
.
.
.
.
.
.
.
.0.3  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.
: .
.
.
.
.
.
.
.0.25  .
.
.
i  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
i .
.
.
.
.
!
.
.
.
.
.
i0.2 .
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.
: .
.
.
.
.O.L5  " .
.
.
.
.
: .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
.
.
.  "
.
.
.
.0 .0500.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9I \ ] i s t~ee0.450.40.35(b)Fig.2.
SRN evaluation by: (a.)
minimising the error function F(t).
(b.)
measuring the SRN matching to theempirical successor distributions.
The distributions of 1,2 distance and cosine are given (see the text).1504
