Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 212?217,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsMeasuring idiosyncratic interests in children with autismMasoud Rouhizadeh?, Emily Prud?hommeaux?, Jan van Santen?, Richard Sproat?
?Oregon Health & Science University?Rochester Institute of Technology?Google, Inc.{rouhizad,vansantj}@ohsu.edu, emilypx@rit.edu, rws@xoba.comAbstractA defining symptom of autism spectrumdisorder (ASD) is the presence of re-stricted and repetitive activities and inter-ests, which can surface in language as aperseverative focus on idiosyncratic top-ics.
In this paper, we use semantic sim-ilarity measures to identify such idiosyn-cratic topics in narratives produced bychildren with and without ASD.
We findthat neurotypical children tend to use thesame words and semantic concepts whenretelling the same narrative, while chil-dren with ASD, even when producing ac-curate retellings, use different words andconcepts relative not only to neurotypicalchildren but also to other children withASD.
Our results indicate that childrenwith ASD not only stray from the targettopic but do so in idiosyncratic ways ac-cording to their own restricted interests.1 IntroductionAutism spectrum disorder (ASD) is a neurode-velopmental disorder characterized by impairedcommunication and social behavior.
One of thecore symptoms is a preoccupation with specific re-stricted interests (American Psychiatric Associa-tion, 2013), and several commonly used diagnos-tic instruments for ASD instruct examiners to eval-uate the degree to which subjects display this char-acteristic (Lord et al, 2002; Rutter et al, 2003).In verbal individuals with ASD, such a preoccu-pation can be expressed as a tendency to fixate ona particular idiosyncratic topic.Previous research relying on expert annota-tion of spoken language in children with ASDhas found that their spoken narratives and con-versations include significantly more instancesof irrelevant content and more topic digressions(Loveland et al, 1990; Losh and Capps, 2003;Lam et al, 2012).
Similar results at the lexicallevel have been reported using automated anno-tations (Prud?hommeaux and Rouhizadeh, 2012;Rouhizadeh et al, 2013).
There has been littlework, however, in characterizing the precise direc-tion of the departure from a target topic, leavingopen the question of whether children with ASDare instigating similar, potentially reasonable topicchanges or whether they are introducing idiosyn-cratic topics consistent with their own restrictedinterests.In this paper, we attempt to automatically iden-tify topic digressions in the narrative retellingsof children with ASD and to determine whetherthese digressions are influenced by their idiosyn-cratic or restricted interests.
From a corpus ofspoken retellings of the same brief narrative, weextract several measures designed to capture dif-ferent facets of semantic similarity between a pairof retellings.
We find that the retellings of chil-dren with typical development (TD) semanticallyresemble one another much more than they resem-ble retellings by children with ASD.
This indicatesthat TD children are adhering to a common tar-get topic, while children with ASD are introduc-ing topic changes.
More strikingly, the similar-ity between pairs of ASD retellings is even lower,suggesting that children with ASD are strayingfrom the target topic in individual and idiosyn-cratic ways.
Although we do not yet have manualannotations to confirm that these topic shifts corre-spond to the particular restricted interests of eachstudy participant, our methods and results showthe potential of using automated analysis for re-vealing diagnostically relevant linguistic features.2 DataThirty-nine children with typical development(TD) and 21 high-functioning children with ASD,212ranging in age from 4 to 9 years, participatedin this study.
ASD was diagnosed via clinicalconsensus according to the DSM-IV-TR criteria(American Psychiatric Association, 2000) and theestablished thresholds on two widely-used diag-nostic instruments: the Autism Diagnostic Obser-vation Schedule (Lord et al, 2002) and the So-cial Communication Questionnaire (Rutter et al,2003).
No children met the criteria for a lan-guage impairment, and there were no significantbetween-group differences in age or full-scale IQ.To elicit retellings, we used the Narrative Mem-ory subtest of the NEPSY (Korkman et al, 1998),a large battery of tasks testing neurocognitivefunctioning in children.
In the NEPSY NarrativeMemory (NNM) subtest, the subject listens to abrief narrative about a boy and his dog and thenmust retell the narrative to the examiner.
Figure 1shows two sample retellings from our corpus.
TheNNM was administered by a trained clinicianto each study participant, and each participant?sretelling was recorded, transcribed, and evaluatedaccording to the published scoring guidelines.Under standard administration of the NNM, aretelling is scored according to how many storyelements from a predetermined list it contains.The guidelines for scoring do not require verba-tim recall for most elements and generally allowthe use of synonyms and paraphrases.
As is typ-ically reported when comparing matched groups(Diehl et al, 2006), we observed no significantdifference in the standard NNM free recall scorebetween the TD group (mean = 6.25, sd = 3.43)and the ASD group (mean = 4.90, sd = 3.72).
Itmight seem that a low similarity score betweentwo retellings simply indicates that one retellingincludes fewer story elements.
However, given theequivalent number of story elements recalled bythe two groups, we can assume that a low similar-ity score indicates a difference in the quality ratherthan the quantity of information in the retellings.3 Semantic similarity measuresWe expect that two different retellings of the samenarrative will lie in the same lexico-semantic spaceand will thus have high similarity scores.
In thiswork we use well-known similarity measures withtwo modifications.
Children with autism tend touse more off-topic and unexpected words.
Suchwords always have high inverse document fre-quency (IDF) scores since they are very specific toa particular retelling.
By including IDF weights,a similarity measure would be biased toward off-topic words rather than actual content words inthe story elements.
Conventional IDF weights aretherefore not useful for our particular purpose.
In-stead, we remove closed-class function words toavoid their bias in our similarity measures.
In ad-dition, we lemmatize our narrative corpus to re-duce the sparsity due to inflectional variation.3.1 Word overlap measures3.1.1 Jaccard similarity coefficientThe Jaccard similarity coefficient (SimJac) (Jac-card, 1912) is a simple word overlap measure be-tween a pair of narratives n and m defined as thesize of intersection of the words in narratives n andm, relative to the size of word union of n and m:SimJacc(n,m) =|n ?m||n ?m|(1)3.1.2 Cosine similarity scoreCosine similarity score SimCosis the similaritybetween two narratives by cosine of the angle be-tween their vector.
We use a non-weighted cosinesimilarity based on the following formula, wheretfw,nis the term frequency of word w in narra-tive n:SimCos(n,m)=?w?n?mtfw,n?
tfw,m??wi?n(tfwi,n)2?
?wj?m(tfwj,m)2(2)3.1.3 Relative frequency measureRelative frequency measure (SimRF) (Hoad andZobel, 2003) is an author identity measure foridentifying plagiarism at the document level.
Thismeasure normalizes the frequency of the wordsappearing in both narratives n and m by the over-all length of the two narratives, as well as the rel-ative frequency of the words common to the twonarratives.
We used a simplified variation of thismeasure, described by Metzler et al (2005) andformulated as follows:SimRF(n,m) =11 +max(|n|,|m|)min(|m|,|m|)?
?w?n?m11 + |tfw,n?
tfw,m|(3)213Jim went up a tree with a ladder.
He lost his shoe he got stuck he hung from a branch.
Pepper took his shoe.
Heshowed it to his sister and she helped him down.
Let me look at this picture with my trusty vision gadget.The boy got stuck and someone rescued him and pepper was a really smart dog.
Dogs have a great sense of smelltoo, like T-rex.
T-rex could smell things that were really far away.
T-rex could be over there and the meat could beway back there under the couch Well, that guy got stuck on the tree and then he, and then Pepper, his shoe fell outof the tree.
Anna rescued it.
Pepper brought his shoe back and Anna rescued them.Figure 1: Two topically different NNM retellings with similar free recall scores (6 and 5, respectively).3.1.4 BLEUBLEU (Papineni et al, 2002) is commonly usedmeasure of n-gram overlap for automatically eval-uating machine translation output.
Because it is aprecision metric, the BLEU score for any pair ofnarratives n and m will depend on which narrativeis considered the ?reference?.
To create a singleBLEU-based overlap score for each pair of narra-tives, we calculate SimBLEU(n,m)as the mean ofBLEU(m,n) and BLEU(n,m).3.2 Knowledge-based measuresIt is reasonable to expect people to use syn-onyms or semantically similar words in their nar-ratives retellings.
It is therefore possible that chil-dren with autism are discussing the appropriatetopic but choosing unusual words within that topicspace in their retellings.
We therefore use a set ofmeasures that consider the semantic overlap of twonarratives using WordNet (Fellbaum, 1998) sim-ilarities (Achananuparp et al, 2008), in order todistinguish instances of atypical but semanticallyappropriate language from true examples of poortopic maintenance.
Because WordNet-based simi-larity measures only consider word pairs with thesame part-of-speech, we POS-tagged the data us-ing a perceptron tagger (Yarmohammadi, 2014).3.2.1 WordNet-based vector similarityIn a modified version ofWordNet-based vectorsimilarity, SimWV), (Li et al, 2006), we first cre-ate vectors vnand vmfor each narrative n and m,where each element corresponds to a word in thetype union of n and m. We assign values to eachelement e in vnusing the following formulation:S(e, n) ={1 if e ?
nmaxwi?nLS(e, wi) otherwise(4)where LS is Lin?s universal similarity (Lin, 1998).In other words, if the element e is present in n,S(e, n) will be 1.
If not, the most similar wordto e will be chosen from words in n using Lin?suniversal similarity and S(e, n) will be that maxi-mum score.
The same procedure is applied to vm,and finally the similarity score between n and m isderived from the cosine score between vnand vm.3.2.2 WordNet-based mutual similarityIn a modified version of WordNet-based mutualsimilarity (SimWM) (Mihalcea et al, 2006), wefind the maximum similarity score S(wi,m) foreach word wiin narrative n with words in narra-tive m as described in Equation 4.
The same pro-cedure is applied to narrative m, and SimWMiscalculated as follows:SimWM(n,m)=12(?wi?nS(wi,m)|n|+?wj?mS(wj, n)|m|)(5)4 ResultsFor each of the semantic similarity measures, webuild a similarity matrix comparing every possi-ble pair of children.
Because this pairwise simi-larity matrix is diagonally symmetrical, we needonly consider the top right section of the matrixabove the diagonal in our analyses.
Table 1 showsthe mean semantic overlap scores between the nar-ratives for each of the three sub-matrices describedabove.
We see that for both the word-overlapand the knowledge-based semantic similarity mea-sures described in Section 3, TD children are mostsimilar to other TD children.
ASD children areless similar to TD children than TD children are toone another; and children with ASD are even lesssimilar to other ASD children than to TD children.Our goal is to explore the degree of similar-ity, as measured by the semantic overlap mea-sures, within and across diagnostic groups.
Withthis in mind, we consider the following threesub-matrices for each similarity matrix: one inwhich each TD child is compared with every other214TD.TD TD.ASD ASD.ASDSimJac0.19 0.14 0.11SimCos0.42 0.34 0.28SimRF2.07 1.52 1.08SimBLEU0.36 0.29 0.24SimWV0.54 0.47 0.42SimWM0.80 0.69 0.59Table 1: Average semantic overlap scores for each group.measure statisticp-valuesTD.TD vs ASD.ASD TD.TD vs TD.ASD TD.ASD vs ASD.ASDSimJact .014 .022 .022w .012 .002 .002SimCost .025 .043 .027w .025 .001 .001SimRFt .056 .072 .046w .012 .002 .002SimBLEUt .032 .039 .034w .036 .002 .002SimWVt .014 .008 .028w .01 .01 .01SimWMt .018 .007 .042w .018 .002 .002Table 2: Monte Carlo significance test p-values for each similarity measure.TD child (the TD.TD sub-matrix); one in whicheach ASD child is compared with every otherASD child (the ASD.ASD sub-matrix); and one inwhich each child is compared with the children inthe diagnostic group to which he does not belong(the TD.ASD sub-matrix).Note that we have no a priori reason to assumethat the similarity scores are from any particu-lar distribution.
In order to calculate the statis-tical significance of these between-group differ-ences, we therefore apply a Monte Carlo permu-tation method, a non-parametric procedure com-monly used in non-standard significance testingsituations.
For each pair of sub-matrices (e.g.,TD.TD vs ASD.ASD) we calculate two statisticsthat compare the cells in one sub-matrix with thecells in other sub-matrices: the t-statistic, usingthe Welch Two Sample t-test; and the w-statistic,using the Wilcoxon rank sum test.
We next takea large random sample with replacement from allpossible permutations of the data by shuffling thediagnosis labels of the children 1000 times.
Wethen calculate two above statistics for each shuffleand count the number of times the observed valuesexceed the values produced by the 1000 shuffles.Applying the Monte Carlo permutation method,we calculate the statistical significance of thefollowing comparisons: TD.TD vs ASD.ASD;TD.TD vs TD.ASD; and TD.ASD vs ASD.ASD.Table 2 summarizes the results of these signifi-cance tests.
In all cases, the differences are signif-icant at p < 0.05 except for the first two compar-isons in the t-test permutation of SimRF, whichnarrowly eluded significance.5 Conclusions and future workHigh-functioning children with ASD have longbeen described as ?little professors?, using pedan-tic or overly-adult language (Asperger, 1944).Low lexical overlap similarity measures by them-selves might indicate that children with ASD areusing semantically appropriate but infrequent orsophisticated words that were not used by otherchildren.
We note, however, that the knowledge-based overlap measures follow the same patternas the purely lexical overlap measures.
This sug-gests that it not the case that children with ASDare simply using rare synonyms of the more com-mon words used by TD children.
Instead, it seemsthat the children with ASD are moving away fromthe target topic and following their own individualand idiosyncratic semantic paths.
These findings215provide additional quantitative evidence not onlyfor the common qualitative observation that youngchildren with ASD have difficulty with topic main-tenance but also for the more general behavioralsymptom of idiosyncratic and restricted interests.The overlap measures presented in this papercould be used as features for machine learningclassification of ASD in combination with otherlinguistic features we have explored, including theuse of off-topic lexical items (Rouhizadeh et al,2013), features associated with poor pragmaticcompetence (Prud?hommeaux et al, 2014), andrepetitive language measures (van Santen et al,2013).
Recall, however, that a clinician must con-sider a wide range of social, communication, andbehavioral criteria when making a diagnosis ofASD, making it unlikely that language featuresalone could perfectly predict a diagnosis of ASD.The more significant potential in our approachesis more likely to lie in the area of language deficitdetection and remediation.A focus of our future work will be to manuallyannotate the data to determine the frequency andnature of the topic excursions.
It is our expecta-tion that children with ASD do not only veer fromthe target topic more frequently than typically de-veloping children but also pursue topics of theirown individual specific interests.
We also plan toapply our methods to ASR output rather than man-ual transcripts.
Despite the high word error ratestypically observed with this sort of audio data, weanticipate that our methods, which rely primarilyon content words, will be relatively robust.The work presented here demonstrates the util-ity of applying automated analysis methods to spo-ken language collected in a clinical settings fordiagnostic and remedial purposes.
Carefully de-signed tools using such methods could providehelpful information not only to clinicians and ther-apists working with children with ASD but alsoto researchers exploring the specific linguistic andbehavioral deficits associated with ASD.AcknowledgmentsThis work was supported in part by NSF grant#BCS-0826654, and NIH NIDCD grants #R01-DC007129 and #1R01DC012033-01.
Any opin-ions, findings, conclusions or recommendationsexpressed in this publication are those of the au-thors and do not necessarily reflect the views ofthe NSF or the NIH.ReferencesPalakorn Achananuparp, Xiaohua Hu, and XiajiongShen.
2008.
The evaluation of sentence similar-ity measures.
In Data Warehousing and KnowledgeDiscovery, pages 305?316.
Springer.American Psychiatric Association.
2000.
DSM-IV-TR:Diagnostic and Statistical Manual of Mental Disor-ders.
American Psychiatric Publishing, Washing-ton, DC.American Psychiatric Association.
2013.
Diagnosticand statistical manual of mental disorders (5th ed.
).American Psychiatric Publishing, Washington, DC.Hans Asperger.
1944.
Die ?autistischen psychopathe?im kindesalter.
Archiv fur Psychiatrie und Ner-venkrakheiten, 117:76?136.Joshua J. Diehl, Loisa Bennetto, and Edna CarterYoung.
2006.
Story recall and narrative coherenceof high-functioning children with autism spectrumdisorders.
Journal of Abnormal Child Psychology,34(1):87?102.Christian Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA.Timothy C Hoad and Justin Zobel.
2003.
Meth-ods for identifying versioned and plagiarized doc-uments.
Journal of the American society for infor-mation science and technology, 54(3):203?215.Paul Jaccard.
1912.
The distribution of the flora in thealpine zone.
1.
New phytologist, 11(2):37?50.Marit Korkman, Ursula Kirk, and Sally Kemp.
1998.NEPSY: A developmental neuropsychological as-sessment.
The Psychological Corporation, San An-tonio.Yan Grace Lam, Siu Sze, and Susanna Yeung.
2012.Towards a convergent account of pragmatic lan-guage deficits in children with high-functioningautism: Depicting the phenotype using the prag-matic rating scale.
Research in Autism SpectrumDisorders, 6(2):792?797.Yuhua Li, David McLean, Zuhair A Bandar, James DO?shea, and Keeley Crockett.
2006.
Sentence sim-ilarity based on semantic nets and corpus statistics.Knowledge and Data Engineering, IEEE Transac-tions on, 18(8):1138?1150.Dekang Lin.
1998.
An information-theoretic defini-tion of similarity.
In ICML, volume 98, pages 296?304.Catherine Lord, Michael Rutter, Pamela DiLavore, andSusan Risi.
2002.
Autism Diagnostic ObservationSchedule (ADOS).
Western Psychological Services,Los Angeles.Molly Losh and Lisa Capps.
2003.
Narrative ability inhigh-functioning children with autism or asperger?ssyndrome.
Journal of Autism and DevelopmentalDisorders, 33(3):239?251.216Katherine Loveland, Robin McEvoy, and Belgin Tu-nali.
1990.
Narrative story telling in autism anddown?s syndrome.
British Journal of Developmen-tal Psychology, 8(1):9?23.Donald Metzler, Yaniv Bernstein, W Bruce Croft, Alis-tair Moffat, and Justin Zobel.
2005.
Similarity mea-sures for tracking information flow.
In Proceedingsof the ACM International Conference on Informa-tion and Knowledge Management, pages 517?524.Rada Mihalcea, Courtney Corley, and Carlo Strappa-rava.
2006.
Corpus-based and knowledge-basedmeasures of text semantic similarity.
In AAAI, vol-ume 6, pages 775?780.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Compu-tational :inguistics, pages 311?318.Emily Prud?hommeaux and Masoud Rouhizadeh.2012.
Automatic detection of pragmatic deficitsin children with autism.
In Proceedings of the3rd Workshop on Child, Computer and Interaction(WOCCI), pages 1?6.Emily Prud?hommeaux, Eric Morley, MasoudRouhizadeh, Laura Silverman, Jan van Santen,Brian Roark, Richard Sproat, Sarah Kauper, andRachel DeLaHunta.
2014.
Computational analysisof trajectories of linguistic development in autism.In Proceedings of the IEEE Spoken LanguageTechnology Workshop (SLT), pages 266?271.Masoud Rouhizadeh, Emily Prud?hommeaux, BrianRoark, and Jan van Santen.
2013.
Distributionalsemantic models for the evaluation of disorderedlanguage.
In Proceedings of the Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies.Michael Rutter, Anthony Bailey, and Catherine Lord.2003.
Social Communication Questionnaire (SCQ).Western Psychological Services, Los Angeles.Jan van Santen, Richard Sproat, and Alison Pres-manes Hill.
2013.
Quantifying repetitive speechin autism spectrum disorders and language impair-ment.
Autism Research, 6(5):372?383.Mahsa Yarmohammadi.
2014.
Discriminative train-ing with perceptron algorithm for pos tagging task.Technical Report CSLU-2014-001, Center for Spo-ken Language Understanding, Oregon Health & Sci-ence University.217
