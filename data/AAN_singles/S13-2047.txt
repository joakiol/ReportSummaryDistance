Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 280?284, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSOFTCARDINALITY: Hierarchical Text Overlapfor Student Response AnalysisSergio Jimenez, Claudia BecerraUniversidad Nacional de ColombiaCiudad Universitaria,edificio 453, oficina 114Bogot?, Colombiasgjimenezv@unal.edu.cocjbecerrac@unal.edu.coAlexander GelbukhCIC-IPNAv.
Juan Dios B?tiz, Av.
Mendiz?bal,Col.
Nueva Industrial VallejoCP 07738, DF, M?xicogelbukh@gelbukh.comAbstractIn this paper we describe our system used toparticipate in the Student-Response-Analysistask-7 at SemEval 2013.
This system is basedon text overlap through the soft cardinality anda new mechanism for weight propagation.
Al-though there are several official performancemeasures, taking into account the overall ac-curacy throughout the two availabe data sets(Beetle and SciEntsBank), our system rankedfirst in the 2 way classification task and sec-ond in the others.
Furthermore, our sys-tem performs particularly well with ?unseen-domains?
instances, which was the more chal-lenging test set.
This paper also describes an-other system that integrates this method withthe lexical-overlap baseline provided by thetask organizers obtaining better results thanthe best official results.
We concluded that thesoft cardinality method is a very competitivebaseline for the automatic evaluation of stu-dent responses.1 IntroductionThe Student-Response-Analysis (SRA) task consistin provide assessments of the correctness of studentanswers (A), considering their corresponding ques-tions (Q) and reference answers (RA) (Dzikovskaet al 2012).
SRA is the task-7 in the SemEval2013 evaluation campaign (Dzikovska et al 2013).The method used in our participation was basicallytext overlap based on the soft cardinality (Jimenezet al 2010) plus a machine learning classifier.
Thismethod did not use any information external to thedata sets except for a stemmer and a list of stopwords.The soft cardinality is a general model for objectcomparison that has been tested at text applications.Particularly, this text overlap approach has providedstrong baselines for several applications, i.e.
entityresolution (Jimenez et al 2010), semantic textualsimilarity (Jimenez et al 2012a), cross-lingual tex-tual entailment (Jimenez et al 2012b), informationretrieval, textual entailment and paraphrase detec-tion (Jimenez and Gelbukh, 2012).
A brief descrip-tion of the soft cardinality is presented in the nextsection.The data for SRA consist of two data sets Bee-tle (5,199 instances) and SciEntsBank (10,804 in-stances) divided into training and test sets (76%-24% for Beetle and 46%-54% SciEntsBank).
In ad-dition, the test part of Beetle data set was dividedinto two test sets: ?unseen answers?
(35%) and ?un-seen questions?
(65%).
Similarity, SciEntsBank testpart is divided into ?unseen answers?
(9%), ?unseenquestions?
(13%) and ?unseen domains?
(78%).
Alltexts are in English.The challenge consists in predicting for each in-stance triple (Q, A, RA) an assessment of correct-ness for the student?s answer.
Three levels of detailare considered for this assessment: 2 way (correctand incorrect), 3 way (correct, contradictory and in-correct) and 5 way (correct, incomplete, contradic-tory, irrelevant and non-in-the-domain).Section 3 presents the method used for the extrac-tion of features from texts using the soft cardinal-ity to provide a vector representation.
In Section 4,the details of the system used to produce our predic-280tions are presented.
Besides, in that section a systemthat integrates our system with the lexical-overlapbaseline proposed by the task organizers is also pre-sented.
This combined system was motivated by theobservation that our system performed well in theSciEntsBank data set but poorly in Beetle in compar-ison with the lexical-overlap baseline.
The resultsobtained by both systems are also presented in thatsection.Finally in Section 5 the conclusions of our partic-ipation in this evaluation campaign are presented.2 Soft CardinalityThe soft cardinality (Jimenez et al 2010) of a col-lection of elements S is calculated with the follow-ing expression:|S|?
=n?i=1wi ??
?n?j=1sim(si, sj)p??
?1(1)Having S ={s1, s2, .
.
.
, sn}; wi ?
0; p ?
0;1 > sim(x, y) ?
0, x 6= y; and sim(x, x) = 1.The parameter p controls the degree of "softness"of the cardinality (the larger the ?harder?).
In fact,when p ?
?
the soft cardinality is equivalent toclassical set cardinality.
The default value for thisparameter is p = 1.
The coefficients wi are weightsassociated with each element, which can representthe importance or informative character of each ele-ment.
The function sim is a similarity function thatcompares pairs of elements in the collection S.3 Features from CardinalitiesIt is commonly accepted that it is possible to makea fair comparison of two objects if they are of thesame nature.
If the objects are instances of a com-positional hierarchy, they should belong to the sameclass to be comparable.
Clearly, a house is compa-rable with another house, a wall with another walland a brick with another brick, but walls and bricksare not comparable (at least not directly).
Similarly,in text applications documents should be comparedwith documents, sentences with sentences, wordswith words, and so on.However, a comparison measure between a sen-tence and a document can be obtained with differentapproaches.
First, using the information retrieval ap-proach, the document is considered like a very longsentence and the comparison is then straight for-ward.
Another approach is to make pairwise com-parisons between the sentence and each sentence inthe document.
Then, the similarity scores of thesecomparisons can be aggregated in a single scoreusing average, max or min functions.
These ap-proaches have issues, the former ignores the sen-tence subdivision of the document and the later ig-nores the similarities among the sentences in thedocument.In the task at hand, each instance is composed ofa question Q, a student answer A, which are sen-tences, and a collection of reference answers RA,which could be considered as a multi-sentence doc-ument.
The soft cardinality can be used to providevalues for |Q|?, |A|?, |RA|?, |Q?A|?, |A?RA|?
and|Q?RA|?.
The intersections that involve RA requirea special treatment to tackle the aforementioned is-sues.Let?s start defining a word-similarity function.Two words (or terms) t1 and t2 can be compared di-viding them into character q-grams (Kukich, 1992).The representation in q-grams of ti can be denotedas t[q]i .
Similarly, a combined representation us-ing a range of q-grams of different length can bedenoted as t[q1:q2]i .
For instance, if t1 =?home?then t[2:3]1 ={?ho?,?om?,?me?,?hom?,?ome?}.
Thus,t[q1:q2]1 and t[q1:q2]2 representations can be com-pared using the Dice?s coefficient to build a word-similarity function:simwords(t1, t2) =2 ???
?t[q1:q2]1 ?
t[q1:q2]2??????t[q1:q2]1???+???t[q1:q2]1???
(2)Note that in eq.
2 the classical set cardinality wasused, i.e |x| means classical cardinality and |x|?
softcardinality.The function simwords can be plugged in eq.1 toobtain the soft cardinality of a sentence S (using uni-tary weights wi = 1 and p = 1):|S|?
=|S|?i=1?
?|S|?j=1simword(ti, tj)??
?1(3)281|X| |Y | |X ?
Y |BF1: |Q|?
BF2: |A|?
BF3: |Q ?A|?BF2: |A|?
BF4: |RA|??
BF5: |RA ?A|?
?BF1: |Q|?
BF4: |RA|??
BF6: |RA ?Q|?
?Table 1: Basic feature setWhere ti are the words in the sentence S .The sentence-soft-cardinality function can beused to build a sentence-similarity function to com-pare two sentences S1 and S2 using again the Dice?scoefficient:simsent.
(S1, S2) =2 ?
(|S1|?
+ |S2|?
?
|S1 ?
S2|?
)|S1|+ |S2|(4)In this formulation S1?S2 is the concatenation ofboth sentences.The eq.
4 can be plugged again into eq.
1 to obtainthe soft cardinality of a ?document?
RA, which is acollection of sentences RA = {S1, S2.
.
.
.
, S|RA|}:|RA|??
=|RA|?i=1|Si|?
??
?|RA|?j=1sim(Si, Sj)??
?1(5)Note that the soft cardinalities of the sentences|Si|?
were re-used as importance weights wi in eq.1.
These weights are propagations of the unitaryweights assigned to the words, which in turn wereaggregated by the soft cardinality at sentence level(eq.
3).
This soft cardinality is denoted with doubleapostrophe because is a function recursively basedin the single-apostrophized soft cardinality.The proposed soft cardinality expressions areused to obtain the basic feature set presented in Ta-ble 1.
The soft cardinalities of |Q|?, |A|?
and |Q?A|?are calculated with eq.
3.
The soft cardinalities|RA|?
?, |RA?A|??
and |RA?Q|??
are calculated witheq.
5.
Recall that Q ?
A is the concatenation of thequestion and answer sentences.
Similarly, RA ?
Aand RA ?Q are the collection of reference answersadding A xor Q .Starting from the basic feature set, an extendedset, showed in Table 2, can be obtained from eachone of the three rows in Table 1.
Recall that |X ?Y | = |X|+ |Y |?|X?Y | and |X \Y | = |X|?|X?EF1: |X ?
Y | EF2: |X \ Y |EF3: |Y \X| EF4: |X?Y ||X|EF5:|X?Y ||Y | EF6:|X?Y ||X?Y |EF7:2?|X?Y ||X|+|Y | EF8:|X?Y |?|X|?|Y |EF9:|X?Y |min(|X|,|Y |) EF10:|X?Y |max(|X|,|Y |)EF11:|X?Y |?
(|X|+|Y |)2?|X|?|Y | EF12: |X ?
Y | ?
|X ?
Y |Table 2: Extended feature setY |.
Consequently, the total number of features is 6basic features plus 12 extended features multipliedby 3, i.e.
42 features.4 Systems Description4.1 Submitted SystemFirst, each text in the SRA data was preprocessed bytokenizing, lowercasing, stop-words1 removing andstemming with the Porter?s algorithm (Porter, 1980).Second, each stemmed word t was represented inq-grams: t[3:4] for Beetle and t[4] for SciEntsBank.These representations obtained the best accuraciesin the training data sets.Two vector data sets were obtained extracting the42 features?described in Section 3?for each instancein Beetle and SciEntsBank separately.
Then, threeclassification models (2 way, 3way and 5 way) werelearned from the training partitions on each vectordata set using a J48 graft tree (Webb, 1999).
All6 resulting classification models were boosted with15 iterations of bagging (Breiman, 1996).
The usedimplementation of this classifier was that includedin WEKA v.3.6.9 (Hall et al 2009).
The resultsobtained by this system are shown in Table 3 in therows labeled with ?Soft Cardinality-run1?.4.2 An Improved SystemAt the time when the official results were released,we observed that our submitted system performedpretty well in SciEntsBank but poorly in Beetle.Moreover, the lexical-overlap baseline outperformedour system in Beetle.
Firstly, we decided to includein our feature set the 8 features of the lexical over-lap baseline described by Dzikovska et al(2012)1those provided by nltk.org282Beetle SciEntsBankTask System UA1 UQ2 All UA1 UQ2 UD3 All All Rank2 waySoft Cardinality-unofficial 0.797 0.725 0.750 0.717 0.733 0.726 0.726 0.730 -Soft Cardinality-run1 0.781 0.667 0.707 0.724 0.745 0.711 0.716 0.715 1ETS-run1 0.811 0.741 0.765 0.722 0.711 0.698 0.702 0.713 2CU-run1 0.786 0.718 0.742 0.656 0.674 0.693 0.687 0.697 3Lexical overlap baseline 0.797 0.740 0.760 0.661 0.674 0.676 0.674 0.690 63 waySoft Cardinality-unofficial 0.608 0.532 0.559 0.656 0.671 0.646 0.650 0.634 -ETS-run1 0.633 0.551 0.580 0.626 0.663 0.632 0.635 0.625 1Soft Cardinality-run1 0.624 0.453 0.513 0.659 0.652 0.637 0.641 0.618 2CoMeT-run1 0.731 0.518 0.592 0.713 0.546 0.579 0.587 0.588 3Lexical overlap baseline 0.595 0.512 0.541 0.556 0.540 0.577 0.570 0.565 85waySoft Cardinality-unofficial 0.572 0.476 0.510 0.552 0.520 0.534 0.534 0.530 -ETS-run1 0.574 0.560 0.565 0.543 0.532 0.501 0.509 0.519 1Soft Cardinality-run1 0.576 0.451 0.495 0.544 0.525 0.512 0.517 0.513 2ETS-run2 0.715 0.621 0.654 0.631 0.401 0.476 0.481 0.512 3Lexical overlap baseline 0.519 0.480 0.494 0.437 0.413 0.415 0.417 0.430 11Total number of test instances 439 819 1,258 540 733 4,562 5,835 7,093TEST SETS: unseen answers1, unseen questions2, unseen domains3.Table 3: Official results for the top-3 performing systems (among 15), the lexical overlap baseline in the SRA taskSemEval 2013 and unofficial results of the soft cardinality system combined with the lexical overlap (in italics).Performance measure used: overall accuracy.
(see Text::Similarity::Overlaps2 package for moredetails).Secondly, the lexical overlap baseline aggregatesthe pairwise scores between each reference answerand the student answer by taking the maximumvalue of the pairwise scores.
So, we decided to usethis aggregation mechanism instead of the aggrega-tion proposed through eq.
3.Thirdly, only at that time we realized that, unlikeBeetle, in SciEntsBank all instances have only onereference answer.
Consequently, the only effect ofeq.
5 in SciEntsBank was in the calculation of |RA?A|??
(and |RA?Q|??)
by |X?Y |??
= |X|?+|Y |?1+simsent.
(X,Y ).As a result, this transformation induced a boostingeffect in X?Y making |X?Y |??
?
|X?Y |?
for anyX , Y .
We decided to use this intersection-boostingeffect not only in RA ?
A, RA ?
Q, but in Q ?A.
This intersecton boosting effect works similarlyto the Lesk?s measure (Lesk, 1986) included in thelexical overlap baseline.The individual effect in the performance of each2http://search.cpan.org/dist/Text-Similarity/lib/Text/Similarity/Overlaps.pmof the previous decisions was positive in all threecases.
The results obtained using an improvedsystem that implemented those three decisions areshown in Table 3?in italics.
This system would haveobtained the best general overall accuracy in the of-ficial ranking.5 ConclusionsWe participated in the Student-Response-Analysistask-7 in SemEval 2013 with a text overlap systembased on the soft cardinality.
This system obtainedplaces 1st (2 way task) and 2nd (3 way and 5 way)considering the overall accuracy across all data setsand test sets.
Particularly, our system was the bestin the largest and more challenging test set, namely?unseen domains?.
Moreover, we integrated the lex-ical overlap baseline to our system obtaining evenbetter results.As a conclusion, the text overlap method based onthe soft cardinality is very challenging base line forthe SRA task.283AcknowledgmentsThis research was funded in part by the Systemsand Industrial Engineering Department, the Officeof Student Welfare of the National University ofColombia, Bogot?, and through a grant from theColombian Department for Science, Technologyand Innovation, Colciencias, proj.
1101-521-28465with funding from ?El Patrimonio Aut?nomo FondoNacional de Financiamiento para la Ciencia, la Tec-nolog?a y la Innovaci?n, Francisco Jos?
de Caldas.
?The third author recognizes the support from Mexi-can Government (SNI, COFAA-IPN, SIP 20131702,CONACYT 50206-H) and CONACYT?DST India(proj.
122030 ?Answer Validation through TextualEntailment?
).ReferencesLeo Breiman.
1996.
Bagging predictors.
MachineLearning, 24(2):123?140.Myroslava O. Dzikovska, Rodney D. Nielsen, and ChrisBrew.
2012.
Towards effective tutorial feedback forexplanation questions: a dataset and baselines.
In Pro-ceedings of the 2012 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies, NAACLHLT ?12, page 200?210, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Myroslava O. Dzikovska, Rodney D. Nielsen, ChrisBrew, Claudia Leacock, Danilo Giampiccolo, LuisaBentivogli, Peter Clark, Ido Dagan, and Hoa TrangDang.
2013.
SemEval-2013 task 7: The joint stu-dent response analysis and 8th recognizing textual en-tailment challenge.
In Proceedings of the 7th Inter-national Workshop on Semantic Evaluation (SemEval2013), in conjunction with the Second Joint Confer-ence on Lexical and Computational Semantcis (*SEM2013), Atlanta, Georgia, USA, June.
Association forComputational Linguistics.Mark Hall, Frank Eibe, Geoffrey Holmes, and BernhardPfahringer.
2009.
The WEKA data mining software:An update.
SIGKDD Explorations, 11(1):10?18.Sergio Jimenez and Alexander Gelbukh.
2012.
Baselinesfor natural language processing tasks.
Appl.
Comput.Math., 11(2):180?199.Sergio Jimenez, Fabio Gonzalez, and Alexander Gel-bukh.
2010.
Text comparison using soft cardinality.In Edgar Chavez and Stefano Lonardi, editors, StringProcessing and Information Retrieval, volume 6393 ofLNCS, pages 297?302.
Springer, Berlin, Heidelberg.Sergio Jimenez, Claudia Becerra, and Alexander Gel-bukh.
2012a.
Soft cardinality: A parameterized simi-larity function for text comparison.
In Proceedings ofthe 6th International Workshop on Semantic Evalua-tion (SemEval, *SEM 2012), Montreal, Canada.Sergio Jimenez, Claudia Becerra, and Alexander Gel-bukh.
2012b.
Soft cardinality+ ML: learning adaptivesimilarity functions for cross-lingual textual entail-ment.
In Proceedings of the 6th International Work-shop on Semantic Evaluation (SemEval, *SEM 2012),Montreal, Canada.
ACL.Karen Kukich.
1992.
Techniques for automaticallycorrecting words in text.
ACM Computing Surveys,24:377?439, December.Michael Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In Proceedings of the5th annual international conference on Systems docu-mentation, SIGDOC ?86, page 24?26, New York, NY,USA.
ACM.Martin Porter.
1980.
An algorithm for suffix stripping.Program, 3(14):130?137, October.Geoffrey I. Webb.
1999.
Decision tree grafting from theall-tests-but-one partition.
In Proceedings of the 16thinternational joint conference on Artificial intelligence- Volume 2, IJCAI?99, pages 702?707, San Francisco,CA, USA.
Morgan Kaufmann Publishers Inc.284
