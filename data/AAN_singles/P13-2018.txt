Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 98?103,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsAn Empirical Examination of Challenges in Chinese ParsingJonathan K. Kummerfeld?Daniel Tse?James R. Curran?Dan Klein?
?Computer Science Division?School of Information TechnologyUniversity of California, Berkeley University of SydneyBerkeley, CA 94720, USA Sydney, NSW 2006, Australia{jkk,klein}@cs.berkeley.edu {dtse6695,james}@it.usyd.edu.auAbstractAspects of Chinese syntax result in a dis-tinctive mix of parsing challenges.
How-ever, the contribution of individual sourcesof error to overall difficulty is not well un-derstood.
We conduct  a  comprehensiveautomatic analysis of error types made byChinese parsers, covering a broad range oferror types for large sets of sentences, en-abling the first empirical ranking of Chi-nese error types by their performance im-pact.
We also investigate which error typesare resolved by using gold part-of-speechtags, showing that improving Chinese tag-ging  only  addresses  certain  error  types,leaving substantial outstanding challenges.1 IntroductionA decade of Chinese parsing research, enabledby the Penn Chinese Treebank (PCTB; Xue et al,2005), has seen Chinese parsing performance im-prove from 76.7 F1 (Bikel and Chiang, 2000) to84.1 F1 (Qian and Liu, 2012).
While recent ad-vances have focused on understanding and reduc-ing the errors that occur in segmentation and part-of-speech tagging (Qian and Liu, 2012; Jiang et al,2009; Forst and Fang, 2009), a range of substantialissues remain that are purely syntactic.Early work by Levy and Manning (2003) pre-sented modifications to a parser motivated by amanual investigation of parsing errors.
They notedsubstantial differences between Chinese and En-glish parsing, attributing some of the differences totreebank annotation decisions and others to mean-ingful differences in syntax.
Based on this analysisthey considered how to modify their parser to cap-ture the information necessary to model the syn-tax within the PCTB.
However, their manual ana-lysis was limited in scope, covering only part ofthe parser output, and was unable to characterizethe relative impact of the issues they uncovered.This paper presents a more comprehensive ana-lysis of errors in Chinese parsing, building on thetechnique presented in Kummerfeld et al (2012),which characterized the error behavior of Englishparsers by quantifying how often they make er-rors such as PP attachment and coordination scope.To accommodate error classes that are absent inEnglish, we  augment  the  system  to  recognizeChinese-specific parse errors.1We use the modi-fied system to show the relative impact of differenterror types across a range of Chinese parsers.To understand the impact of tagging errors ondifferent  error  types, we  performed  a  part-of-speech ablation experiment, in  which particularconfusions are introduced in isolation.
By analyz-ing the distribution of errors in the system outputwith and without gold part-of-speech tags, we areable to isolate and quantify the error types that canbe resolved by improvements in tagging accuracy.Our analysis shows that improvements in tag-ging accuracy can only address a subset of the chal-lenges of Chinese syntax.
Further improvement inChinese parsing performance will require researchaddressing other challenges, in particular, deter-mining coordination scope.2 BackgroundThe closest previous work is the detailed manualanalysis performed by Levy and Manning (2003).While their focus was on issues faced by their fac-tored PCFG parser (Klein and Manning, 2003b),the error types they identified are general issuespresented by Chinese syntax in the PCTB.
Theypresented several Chinese error types that are rareor absent in English, including noun/verb ambigu-ity, NP-internal structure and coordination ambi-guity due to pro-drop, suggesting that closing theEnglish-Chinese parsing gap demands techniques1The system described  in  this  paper  is  available  fromhttp://code.google.com/p/berkeley-parser-analyser/98beyond those currently used for English.
How-ever, as noted in their final section, their manualanalysis of parse errors in 100 sentences only cov-ered a portion of a single parser?s output, limitingthe conclusions they could reach regarding the dis-tribution of errors in Chinese parsing.2.1 Automatic Error AnalysisOur  analysis  builds  on  Kummerfeld  et al(2012), which presented a system that automati-cally classifies English parse errors using a twostage process.
First, the system finds the shortestpath from the system output to the gold annota-tions, where each step in the path is a tree transfor-mation, fixing at least one bracket error.
Second,each transformation step is classified into one ofseveral error types.When directly applied to Chinese parser output,the system placed over 27% of the errors in thecatch-all ?Other?
type.
Many of these errors clearlyfall into one of a small set of error types, motivat-ing an adaptation to Chinese syntax.3 Adapting error analysis to ChineseTo adapt the Kummerfeld et al (2012) system toChinese, we developed a new version of the secondstage of the system, which assigns an error cate-gory to each tree transformation step.To characterize the errors the original systemplaced in the ?Other?
category, we looked throughone  hundred  sentences, identifying  error  typesgenerated by Chinese syntax that the existing sys-tem did not account for.
With these observationswe were able to implement new rules to catch thepreviously missed cases, leading to the set shownin Table 1.
To ensure the accuracy of our classifica-tions, we alternated between refining the classifica-tion code and looking at affected classifications toidentify issues.
We also periodically changed thesentences from the development set we manuallychecked, to avoid over-fitting.Where necessary, we also expanded the infor-mation available during classification.
For exam-ple, we use the structure of the final gold standardtree when classifying errors that are a byproduct ofsense disambiguation errors.4 Chinese parsing errorsTable 1 presents the errors made by the Berkeleyparser.
Below we describe the error types that areError Type Brackets % of totalNP-internal* 6019 22.70%Coordination 2781 10.49%Verb taking wrong args* 2310 8.71%Unary 2262 8.53%Modifier Attachment 1900 7.17%One Word Span 1560 5.88%Different label 1418 5.35%Unary A-over-A 1208 4.56%Wrong sense/bad attach* 1018 3.84%Noun boundary error* 685 2.58%VP Attachment 626 2.36%Clause Attachment 542 2.04%PP Attachment 514 1.94%Split Verb Compound* 232 0.88%Scope error* 143 0.54%NP Attachment 109 0.41%Other 3186 12.02%Table 1: Errors made when parsing Chinese.
Values are thenumber of bracket errors attributed to that error type.
Thevalues shown are for the Berkeley parser, evaluated on thedevelopment set.
* indicates error types that were added orsubstantially changed as part of this work.either new in this analysis, have had their definitionaltered, or have an interesting distribution.2In all of our results we follow Kummerfeld et al(2012), presenting the number of bracket errors(missing or extra)  attributed to each error type.Bracket counts are more informative than a directcount of each error type, because the impact onEVALB F-score varies between errors, e.g.
a sin-gle attachment error can cause 20 bracket errors,while a unary error causes only one.NP-internal.
(Figure 1a).
Unlike  the  PennTreebank (Marcus et al, 1993), the PCTB anno-tates some NP-internal structure.
We assign thiserror type when a transformation involves wordswhose parts of speech in the gold tree are one of:CC, CD, DEG, ETC, JJ, NN, NR, NT and OD.We investigated the errors that fall into the NP-internal category and found that 49% of the errorsinvolved the creation or deletion of a single pre-termianl phrasal bracket.
These errors arise whena parser proposes a tree in which POS tags (for in-stance, JJ or NN) occur as siblings of phrasal tags(such as NP), a configuration used by the PCTBbracketing guidelines to indicate complementationas opposed to adjunction (Xue et al, 2005).2For an explanation of the English error types, see Kum-merfeld et al (2012).99Verb taking wrong args.
(Figure 1b).
Thiserror type arises when a verb (e.g.??
reverse)is  hypothesized  to  take  an  incorrect  argument(??
Bush instead of ??
position).
Note thatthis also covers some of the errors that Kummer-feld  et al (2012) classified  as  NP Attachment,changing the distribution for that type.Unary.
For mis-application of unary rules weseparate out instances in which the two brackets inthe production have the the same label (A-over-A).This cases is created when traces are eliminated, astandard step in evaluation.
More than a third ofunary errors made by the Berkeley parser are of theA-over-A type.
This can be attributed to two fac-tors: (i) the PCTB annotates non-local dependen-cies using traces, and (ii) Chinese syntax generatesmore traces than English syntax (Guo et al, 2007).However, for parsers that do not return traces theyare a benign error.Modifier attachment.
(Figure 1c).
Incorrectmodifier scope caused by modifier phrase attach-ment level.
This is less frequent in Chinese thanin English: while English VP modifiers occur inpre- and post-verbal positions, Chinese only al-lows pre-verbal modification.Wrong sense/bad attach.
(Figure 1d).
This ap-plies when the head word of a phrase receives thewrong POS, leading to an attachment error.
Thiserror type is common in Chinese because of POSfluidity, e.g.
the well-known Chinese verb/nounambiguity often causes mis-attachments that areclassified as this error type.In  Figure 1d, the  word ??
invest hasboth  noun  and  verb  senses.
While  the  goldstandard  interpretation  is  the  relative  clausefirms that Macau invests in, the parser returned anNP interpretation Macau investment firms.Noun boundary error.
In this error type, a spanis moved to a position where the POS tags of itsnew siblings all belong to the list of NP-internalstructure tags which we identified above, reflectingthe inclusion of additional material into an NP.Split  verb  compound.
The  PCTB annota-tions recognize several Chinese verb compound-ing strategies, such as  the serial  verb construc-tion (????
plan [and] build) and the resulta-tive construction (??
cook [until] done), whichjoin a bare verb to another lexical item.
We in-troduce an error type specific to Chinese, in whichsuch verb compounds are split, with the two halvesof the compound placed in different phrases...NP..NN .?
?coach..NN .?
?soccer..NN .?
?nat'l.NP..NP..NP.NN..NP.NN..NP.NN(a) NP-internal structure errors..VP..NP..NP .?
?position..DNP..DEG .
?..NP .?
?Bush..VV .?
?reverse.CP..IP..VP..VV..NP..DEC..NP(b) Verb taking wrong arguments..VP..VP .???
?win gold..QP..QP .??
?3rd time..ADVP .?
?in a row.VP..ADVP..QP..QP.VP(c) Modifier attachment ambiguity..CP..NP .?
?firm..IP..VP .?
?invest..NP .?
?Macau.NP..NP..NP..NP.NP(d) Sense confusionFigure 1: Prominent error types in Chinese parsing.
The lefttree is the gold structure; the right is the parser hypothesis.Scope error.
These are cases in which a newspan must be added to more closely bind a modifierphrase (ADVP, ADJP, and PP).PP attachment.
This error type is rare in Chi-nese, as adjunct PPs are pre-verbal.
It does oc-cur near coordinated VPs, where ambiguity arisesabout  which of  the conjuncts  the PP has scopeover.
Whether this particular case is PP attachmentor coordination is debatable; we follow Kummer-feld et al (2012) and label it PP attachment.4.1 Chinese-English comparisonIt is difficult to directly compare error analysisresults for Chinese and English parsing becauseof substantial changes in the classification method,and differences in treebank annotations.As described in the previous section, the set oferror categories considered for Chinese is very dif-ferent to the set of categories for English.
Evenfor some of the categories that were not substan-tially changed, errors may be classified differentlybecause of cross-over between categories between100NP Verb Mod.
1-Word Diff Wrong Noun VP Clause PPSystem F1 Int.
Coord Args Unary Attach Span Label Sense Edge Attach Attach Attach OtherBest 1.54 1.25 1.01 0.76 0.72 0.21 0.30 0.05 0.21 0.26 0.22 0.18 1.87Berk-G 86.8Berk-2 81.8Berk-1 81.1ZPAR 78.1Bikel 76.1Stan-F 76.0Stan-P 70.0Worst 3.94 1.75 1.73 1.48 1.68 1.06 1.02 0.88 0.55 0.50 0.44 0.44 4.11Table 2: Error breakdown for the development set of PCTB 6.
The area filled in for each bar indicates the average number ofbracket errors per sentence attributed to that error type, where an empty bar is no errors and a full bar has the value indicated inthe bottom row.
The parsers are: the Berkeley parser with gold POS tags as input (Berk-G), the Berkeley product parser withtwo grammars (Berk-2), the Berkeley parser (Berk-1), the parser of Zhang and Clark (2009) (ZPAR), the Bikel parser (Bikel),the Stanford Factored parser (Stan-F), and the Stanford Unlexicalized PCFG parser (Stan-P).two categories (e.g.
between Verb taking wrongargs and NP Attachment).Differences in treebank annotations also presenta challenge for cross-language error comparison.The  most  common  error  type  in  Chinese, NP-internal structure, is rare in the results of Kummer-feld et al (2012), but the datasets are not compara-ble because the PTB has very limited NP-internalstructure annotated.
Further characterization of theimpact of annotation differences on errors is be-yond the scope of this paper.Three conclusions that can be made are that (i)coordination is a major issue in both languages,(ii) PP attachment is a much greater problem inEnglish, and  (iii)  a  higher  frequency  of  trace-generating syntax in Chinese compared to Englishposes substantial challenges.5 Cross-parser analysisThe previous section described the error typesand their distribution for a single Chinese parser.Here we confirm that these are general trends, byshowing that the same pattern is observed for sev-eral  different  parsers  on  the  PCTB 6 dev  set.3We include results  for  a  transition-based parser(ZPAR; Zhang  and  Clark, 2009), a  split-mergePCFG parser (Petrov et al, 2006; Petrov and Klein,2007; Petrov, 2010), a lexicalized parser (Bikeland Chiang, 2000), and a factored PCFG and de-pendency parser (Levy and Manning, 2003; Kleinand Manning, 2003a,b).4Comparing the two Stanford parsers in Table 2,the factored model provides clear improvements3We use the standard data split suggested by the PCTB 6file manifest.
As a result, our results differ from those previ-ously reported on other splits.
All analysis is on the dev set,to avoid revealing specific information about the test set.4These parsers represent a variety of parsing methods,though exclude some recently developed parsers that are notpublicly available (Qian and Liu, 2012; Xiong et al, 2005).on  sense  disambiguation, but  performs  slightlyworse on coordination.The Berkeley product parser we include usesonly two grammars because we found, in contrastto the English results (Petrov, 2010), that furthergrammars provided limited benefits.
Comparingthe performance with the standard Berkeley parserit seems that the diversity in the grammars only as-sists certain error types, with most of the improve-ment  occurring in  four  of  the categories, whilethere is no improvement, or a slight decrease, infive categories.6 Tagging Error ImpactThe challenge of accurate POS tagging in Chi-nese has been a major part of several recent papers(Qian and Liu, 2012; Jiang et al, 2009; Forst andFang, 2009).
The Berk-G row of Table 2 showsthe performance of the Berkeley parser when givengold POS tags.5While the F1 improvement is un-surprising, for the first time we can clearly showthat the gains are only in a subset of the error types.In particular, tagging improvement will not helpfor two of the most significant challenges: coordi-nation scope errors, and verb argument selection.To see which tagging confusions contribute towhich error reductions, we adapt the POS ablationapproach of Tse and Curran (2012).
We considerthe POS tag pairs shown in Table 3.
To isolate theeffects of each confusion we start from the goldtags and introduce the output of the Stanford tag-ger whenever it returns one of the two tags beingconsidered.6We then feed these ?semi-gold?
tags5We used the Berkeley parser as it was the best of theparsers we considered.
Note that the Berkeley parser occa-sionally prunes all of the parses that use the gold POS tags,and so returns the best available alternative.
This leads to aPOS accuracy of 99.35%, which is still well above the parser?sstandard POS accuracy of 93.66%.6We introduce errors to gold tags, rather than removing er-101Confused tags Errors ?
F1VV NN 1055 -2.72DEC DEG 526 -1.72JJ NN 297 -0.57NR NN 320 -0.05Table 3: The most frequently confused POS tag pairs.
Each?
F1 is relative to Berk-G.to the Berkeley parser, and run the fine-grained er-ror analysis on its output.VV/NN.
This confusion has been consistentlyshown to be a major contributor to parsing errors(Levy and Manning, 2003; Tse and Curran, 2012;Qian and Liu, 2012), and we find a drop of over 2.7F1 when the output of the tagger is introduced.
Wefound that while most error types have contribu-tions from a range of POS confusions, verb/nounconfusion was responsible for virtually all of thenoun boundary errors corrected by using gold tags.DEG/DEC.
This confusion between the rela-tivizer and subordinator senses of the particle ?de is the primary source of improvements on mod-ifier attachment when using gold tags.NR/NN and JJ/NN.
Despite  their  frequency,these confusions have little effect on parsing per-formance.
Even within the NP-internal error typetheir impact is limited, and almost all of the errorsdo not change the logical form.7 ConclusionWe have  quantified  the  relative  impacts  of  acomprehensive set of error types in Chinese pars-ing.
Our analysis has also shown that while im-provements in Chinese POS tagging can make asubstantial difference for some error types, it willnot address two high-frequency error types: in-correct verb argument attachment and coordina-tion scope.
The frequency of these two error typesis also unimproved by the use of products of la-tent variable grammars.
These observations sug-gest that resolving the core challenges of Chineseparsing will require new developments that suit thedistinctive properties of Chinese syntax.AcknowledgmentsWe extend our thanks to Yue Zhang for helpingus train new ZPAR models.
We would also liketo thank the anonymous reviewers for their help-ful suggestions.
This research was supported bya General Sir John Monash Fellowship to the firstrors from automatic tags, isolating the effect of a single con-fusion by eliminating interaction between tagging decisions.author, the Capital Markets CRC under ARC Dis-covery grant DP1097291, and the NSF under grant0643742.ReferencesDaniel M. Bikel and David Chiang.
2000.
TwoStatistical Parsing Models Applied to the Chi-nese Treebank.
In Proceedings of the SecondChinese Language Processing Workshop, pages1?6.
Hong Kong, China.Martin Forst and Ji Fang.
2009.
TBL-improvednon-deterministic  segmentation  and  POS tag-ging for a Chinese parser.
In Proceedings of the12th Conference of the European Chapter of theACL, pages 264?272.
Athens, Greece.Yuqing Guo, Haifeng Wang, and Josef van Gen-abith.
2007.
Recovering Non-Local Dependen-cies for Chinese.
In Proceedings of the 2007Joint Conference on Empirical Methods in Nat-ural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL),pages 257?266.
Prague, Czech Republic.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.Automatic Adaptation of Annotation Standards:Chinese Word Segmentation and POS Tagging?
A Case Study.
In Proceedings of the JointConference of the 47th Annual Meeting of theACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP,volume 1, pages 522?530.
Suntec, Singapore.Dan Klein and Christopher D. Manning.
2003a.Accurate Unlexicalized Parsing.
In Proceedingsof the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 423?430.Sapporo, Japan.Dan Klein and Christopher D. Manning.
2003b.Fast Exact Inference with a Factored Model forNatural Language Parsing.
In Advances in Neu-ral Information Processing Systems 15, pages3?10.
MIT Press, Cambridge, MA.Jonathan K. Kummerfeld, David Hall, James R.Curran, and Dan Klein.
2012.
Parser Show-down at the Wall Street Corral: An EmpiricalInvestigation of Error Types in Parser Output.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Pro-cessing and Computational Natural LanguageLearning, pages 1048?1059.
Jeju Island, SouthKorea.102Roger Levy and Christopher Manning.
2003.
Isit harder to parse Chinese, or the Chinese Tree-bank?
In Proceedings of the 41st Annual Meet-ing on Association for Computational Linguis-tics, pages 439?446.
Sapporo, Japan.Mitchell P.  Marcus, Beatrice  Santorini, andMary Ann  Marcinkiewicz.
1993.
Buildinga  Large  Annotated  Corpus  of  English: ThePenn  Treebank.
Computational  Linguistics,19(2):313?330.Slav Petrov.
2010.
Products of Random LatentVariable Grammars.
In Human Language Tech-nologies: The 2010 Annual Conference of theNorth American Chapter of the Association forComputational  Linguistics, pages  19?27.
LosAngeles, California.Slav Petrov, Leon Barrett, Romain Thibaux, andDan Klein.
2006.
Learning  Accurate, Com-pact, and Interpretable Tree Annotation.
In Pro-ceedings of the 21st International Conference onComputational Linguistics and the 44th AnnualMeeting of the Association for ComputationalLinguistics, pages 433?440.
Sydney, Australia.Slav Petrov and Dan Klein.
2007.
Improved In-ference for Unlexicalized Parsing.
In HumanLanguage Technologies 2007: The Conferenceof the North American Chapter of the Associ-ation for Computational Linguistics; Proceed-ings of the Main Conference, pages 404?411.Rochester, New York, USA.Xian Qian and Yang Liu.
2012.
Joint Chineseword segmentation, POS tagging and parsing.In Proceedings of the 2012 Joint Conference onEmpirical Methods in Natural Language Pro-cessing and Computational Natural LanguageLearning, pages 501?511.
Jeju Island, Korea.Daniel  Tse  and  James R.  Curran.
2012.
TheChallenges of Parsing Chinese with Combina-tory Categorial Grammar.
In Proceedings of the2012 Conference of the North American Chap-ter of the Association for Computational Lin-guistics: Human Language Technologies, pages295?304.
Montre?al, Canada.Deyi Xiong, Shuanglong Li, Qun Liu, ShouxunLin, and Yueliang Qian.
2005.
Parsing the PennChinese Treebank with semantic knowledge.
InProceedings of  the Second international  jointconference  on  Natural  Language  Processing,pages 70?81.
Jeju Island, Korea.Nianwen  Xue, Fei  Xia, Fu-Dong  Chiou, andMartha  Palmer.
2005.
The  Penn  ChineseTreeBank: Phrase  structure  annotation  of  alarge corpus.
Natural Language Engineering,11(2):207?238.Yue Zhang and Stephen Clark.
2009.
Transition-Based Parsing of the Chinese Treebank using aGlobal Discriminative Model.
In Proceedingsof the 11th International Conference on ParsingTechnologies (IWPT?09), pages 162?171.
Paris,France.103
