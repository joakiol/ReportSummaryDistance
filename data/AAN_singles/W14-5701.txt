Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 1?10,Dublin, Ireland, August 24 2014.Modelling Regular Subcategorization Changes in German Particle VerbsStefan Bott Sabine Schulte im WaldeInstitut f?ur Maschinelle SprachverabeitungUniversit?at StuttgartPfaffenwaldring 5b, 70569 Stuttgart, Germany{stefan.bott,schulte}@ims.uni-stuttgart.deAbstractGerman particle verbs are a type of multi word expression which is often compositional withrespect to a base verb.
If they are compositional they tend to express the same types of semanticarguments, but they do not necessarily express them in the same syntactic subcategorizationframe: some arguments may be expressed by differing syntactic subcategorization slots and otherarguments may be only implicit in either the base or the particle verb.
In this paper we present amethod which predicts syntactic slot correspondences between syntactic slots of base and particleverb pairs.
We can show that this method can predict subcategorization slot correspondences witha fair degree of success.1 IntroductionIn German, particle verbs (PVs) are a very frequent and productive type of multi word expression.
Parti-cle verbs, such as anstarren (to stare at) in (1-a), are built from a base verb (BV) and a particle.
Similar toother multi word expressions, German PVs may show a varying degree of compositionality with respectto the BV and to the particle.
But German PVs also have another particularity: if they are compositional,the mapping from semantic arguments to syntactic subcategorization frames may be different betweenthe PV and its corresponding BV.
(1) a. DieTheKatzecat-N-nomstarrtstares(den(theVogelbird-N-acc||dietheWohnungst?ur)apartment door-N-acc)an.at-PRT.The cat stares at the (bird | apartment door).b.
DieTheKatzecat-N-nomstarrtstaresaufat-PdentheVogel.bird-acc.c.
DieTheKatzecat-N-nomstarrtstareszurat-P theWohnungst?ur.apartment door-dat.The events expressed with the PV anstarren in (1-a) can also be expressed with the BV starren in (1-b)and (1-c).
But while the argument Vogel or Wohnungst?ur is expressed as an accusative object in (1-a) itis expressed as a PP in both (1-b) and (1-c), headed by the preposition auf and zu, respectively.Related to this phenomenon, the change in the typical subcategorization frame from the BV to thePV can also lead to an incorporation or an addition of syntactic complements (Stiebels, 1996; L?udeling,2001), as illustrated by (2).
The BV bellen (to bark) is strictly intransitive, while the corresponding PVanbellen (to bark at) is transitive and takes an obligatory accusative object which expresses the personor entity being barked at.
This is a case of argument extensions in the PV with respect to its BV.
ThePV anschrauben (to screw onto) displays incorporation: it can nearly never select an argument whichexpresses the location onto which something is screwed, while its BV schrauben (to screw) requires theexpression of the location with a PP.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footer areadded by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1(2) a. DerTheHunddog-N-nombellt.barks.b.
DerTheHunddog-N-nombelltbarksdenthePostbotenpostman-N-accan.at-PRT.c.
DerTheMechanikermechanic-N-nomschraubtscrewsdietheAbdeckungcoveraufondiethe?Offnung.opening-N-acc.d.
DerTheMechanikermechanic-N-nomschraubtscrewsdietheAbdeckungcoveran.on-PRT.
(3) a. DerTheMetzgerbutcherbringtbringsseinerhisFrauwifeBlumen.flowers.The butcher brings his wife flowers.b.
DerTheMetzgerbutcherbringtbringsdastheL?ammchenlittle lambum.PRT.The butcher assassinates the little lamb.Finally, if the meaning of the PV is not compositional with respect to the BV, there are no se-mantic correspondences between subcategorization slots of the PV and the BV.
The problem of non-compositionality is illustrated by (3) which uses the PV umbringen (to assassinate), which has a totallydifferent meaning from its BV bringen (to bring).
A successful mapping between the subcategorizationslots of both can thus be expected to have a direct relation to the assessment of PV compositionality.The problem we address here can be called the syntactic transfer problem: the subcategorizationframe of a BV can be mapped onto a subcategorization frame of the PV, where semantic arguments arenot necessarily realized with the same syntactic positions in both of the verbs.
A good approximationto this problem is potentially very useful in computational lexicography and other NLP tasks, such asmachine translation and information extraction.
We also expect it to be helpful to assess other aspects ofGerman particle verbs, such as the prediction of compositionality levels.In order to tackle the problem of argument slot matching we use a vector space model to represent dis-tributional semantics.
We expect that high distributional similarity between two given subcategorizationslots taken from a verb pair signals a correspondence of these slots in a pair of subcategorization frames.On the contrary, we expect that low distributional similarity signals that no such correspondence can beestablished.
Further on, if for a given subcategorization slot, either from a BV or a PV, no matchingslot can be found in the complementary PV/BV automatically, this typically corresponds to a case ofargument incorporation or argument extension.In short, in this paper we make the following contributions: We present a method of automaticallymapping syntactic subcategorization slots of BVs and PVs which is based on distributional semanticsand we show that this method can outperform a random baseline with a high level of success.The rest of this paper is organized as follows: In section 2 we present related work.
Section 3 describesour experimental setup, including the method of correspondence prediction, the elicitation of humanjudgements and the evaluation.
Section 4 presents the results which are then discussed in section 5.Section 6 concludes the paper with some final remarks and outlook on future work.2 Related WorkParticle verbs have been studied from the theoretical perspective and, to a more limited extent, from theaspect of the computational identifiability, predictability of the degree of semantic compositionality (thetransparency of their meaning with respect to the meaning of the base verb and the particle) and thesemantic classifiabilty of PVs.For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicen-cio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy etal., 2003; Baldwin et al., 2003; Bannard, 2005).
To the best of our knowledge Aldinger (2004) is thefirst work that studies German PVs from a corpus based perspective, with an emphasis on the syntacticbehavior and syntactic change.
Schulte im Walde (2004; 2005; 2006) presents several preliminary distri-2butional studies to explore salient features at the syntax-semantics interface that determine the semanticnearest neighbours of German PVs.
Relying on the insights of those studies, Schulte im Walde (2006)and Hartmann (2008) present preliminary experiments on modelling the subcategorization transfer ofGerman PVs with respect to their BVs, in order to strengthen PV-BV distributional similarity.
The maingoal for them is to use transfer information in order to predict the degree of semantic compositionalityof PVs.
K?uhner and Schulte im Walde (2010) use unsupervised clustering to determine the degree ofcompositionality of German PVs, via common PV-BV cluster membership.
They are, again, mainlyinterested in the assessment of compositionality, which is done on the basis of lexical information.
Theyuse syntactic information, but only as a filter and for lexical heads as cooccurrence features in orderto limit the selected argument slots to certain syntactic functions.
They compare different feature con-figurations and conclude that the best results can be obtained with information stemming from directobjects and PP-objects.
The incorporation of syntactic information in the form of dependency arc labels(concatenated with the head nouns) does not yield satisfactory results, putting the syntactic transfer prob-lem in evidence, the problem which we address here.
They conclude that an incorporation of syntactictransfer information between BVs and PVs could possibly improve the results.
In Bott and Schulte imWalde (2014a) we present a method to assess PV compositionality without recurring to any syntacticfeatures, but we assume that the results of this method could be improved if additional syntactic transferinformation was incorporated.Based on a theoretical study (Springorum, 2011) which explains particle meanings in terms of Dis-course Representation Theory (Kamp and Reyle, 1993), Springorum et al.
(2012) show that four classesof PVs with the particle an can be classified automatically.
They take a supervised approach using de-cision trees.
The use of decision trees also allows them to manually inspect and analyze the decisionsmade by the classifier.
As predictive features they use the head nouns of objects, generalized classes ofthese nouns and PP types.
In Bott and Schulte im Walde (2014b) we present an experiment to classifysemantic classes of PVs, based on subcategorization information stemming from both the BV and theBV of each BV-PV pair.
In this work we use the same gold standard we use here.
This experiment is alsorelated to the one presented here in that we assume that the syntactic transfer patterns are quite stablewithin semantic classes.3 Experimental SetupIn order to test our hypothesis we selected a set of 32 PVs listed in Fleischer and Barz (2012), including14 PVs with the particle an and 18 with the particle auf.1We concentrated on two particles here in orderto have a small and controlled test bed which allows us to study the syntactic transfers.
We selectedverbs which we considered to be highly compositional in order to be able to study the correspondence ofsubcategorization slots.
The set contained verbs which have argument slots which are typically realizedas different syntactic subcategorizations.
The set also contained PVs which show argument incorporationor the introduction of an additional syntactic complement with respect to their BV.
We excluded verbswhich we could clearly perceive as being polysemous.
This set of verbs was processed automaticallyand presented to human raters, as described below.
The test set can be seen in table 1.
This test setwas already used in Bott and Schulte im Walde (2014b), where it was used as a gold standard for theautomatic classification of semantic classes of particle verbs, based on syntactic transfer patterns.
Thesubcategorization patterns listed here are the ones we expected to find, so the second and the third rowtogether represent the expected syntactic transfer pattern.
The values given in these two columns area lexicographic presentation of the transfer patterns we expected to find.
The task of the system wasdefined as to find matches between slots from both verbs automatically.
The verbs were grouped togetherin classes which are both semantically similar and also expected to have a similar syntactic behaviour.The labels in the column for the semantic class are taken from Fleischer and Barz (2012), but brokendown into more detailed classes, such as verbs of trying, gaze or sound.
The latter label extensions were1Fleischer and Barz list more than 100 PVs for both an and auf, but they embed this listing in a descriptive text.
Some ofthe verbs listed are very rare or highly ambiguous.
Since particle verbs in German are a highly productive paradigm and giverise to many neologisms, compiling a complete list of PVs is nearly impossible.3added by us.
In the present work we are not interested in the semantic classes as such, but we assumethat the transfer patterns are similar in each semantic class.3.1 Automatic ClassificationSince we wanted to test the predictability of syntactic slot correspondences, we first had to identifythe typical elements of the subcategorization frames for both BVs and PVs.
In order to do so, weextracted all observable subcategorization patterns from a parsed corpus.
Then we selected the 5 mostfrequent subcategorization patterns for each verb (either BV or PV).
These patterns were then brokendown into their individual elements.
The simple transitive pattern, for example, contained a subject andan accusative object.
Since some subordinate structures miss overt subjects and in German all verbs havea subject slot, we always included the subject in the representation of all verbs.
The rationale behind thismethod, which is based on the frequency of subcategorization patterns rather than the frequency of slots,was that we were not interested in subcategorization slots per se, but in subcategorization patterns as atypical representation structure in computational lexicography.Then we built a vector space model for all possible combinations of BV-complements and PV-complements of each BV-PV pair.
The dimensions of the vector were instantiated by the head nounsof the syntactic relation in question.
The extension in each dimension is equal to the frequency of thehead noun in the relevant position.
For this experiment no term weighting was applied.
Table 2 showsthe strongest dimensions for the vectors corresponding to the PP-argument headed by the verbs heften (toattach) and anheften (to attach to).
The two verbs can be used in quite similar contexts with very similararguments.
Accordingly, the two vectors are similar to each other.
Although the two vectors correspondto PP slots headed by the preposition an, it can be seen that there is a syntactic transfer from accusative todative case.
Both vectors include head nouns expressing typical places to which things can be attachedto, such as a pin board (Pinnwand), a wall (Wand) or a board (Brett).
The verb heften is frequentlyfound in the idiom sich an jemandes Ferse heften (to attach onseself to someone?s heels, which meansto follow someone closely), while this idiom cannot be formed with the PV anheften.
For this reason thedimension for Ferse is very strong.
This example, especially the vector for anheften also shows that thefeatures are often sparsely represented, which presents a problem for our approach.As a similarity measure we used the cosine distance between two vectors.
A variable threshold wasapplied on the cosine distance to, which serves to separate corresponding subcategorization slots fromnon-corresponding ones.
This is especially important for the detection of argument incorporation orargument extension (cf.
example (2)).
If, for example, for a given BV slot no PV slot can be foundwith a cosine value above the threshold, we interpret this as a case of argument extension.
On theother hand, a slot from a PV which cannot be match to a slot of its BV is taken to signal argumentincorporation.
Among the vectors compared to each target subcategorization slot only the one with thehighest cosine value was considered as a possible correspondence.
Finally, since we want to capture bothargument incorporation and argument extension, we computed correspondences for both BVs and PVsseparately.
Even if this means that most slot pairs are computed twice, this allowed zero-correspondencesfor slots from both verbs.
It theoretically also allows for one-to-many and many-to-one matches, evenif we did not exploit them here.
We excluded closed class dependencies of verbs, such as negations.We also excluded clausal complements, because they could not be properly represented by our vectorextraction method.
To get an idea of the lower bound of the outcome values, we used a select-1 baseline.This baseline was obtained by calculating the expected precision and recall for the case that for eachsubcategorization slot a matching slot from the corresponding other verb is assigned randomly.As training data we used a lemmatized and tagged version of the SDeWaC corpus (Faa?
and Eckart,2013), a corpus of nearly 885 million words.
The corpus was processed with the Mate dependency parser(Bohnet, 2010).
The output of this parser represents the syntactic complements of the verbs as labelledarcs.
In the case of nominal objects the nominal heads could be directly read of the dependent nodes andthe syntactic relation of the arc labels.
In the case of PP-complements we read the nominal heads of thenominal node which depends on the preposition which in turn depends on the verb.
For the extraction offeatures we could rely on the database compiled by (Scheible et al., 2013).4Particle Typical frames Typical frames Semantic Verbs in Classfor the BV for the PV ClassanNPnom+NPacc+PP-anNPnom+NPacc+PP-anlocative/relationaltyingan|binden to tie atan|ketten to chain atNPnom+PP-zu/in/nach/aufNPnom+NPacclocative/relationalgazean|blicken to glance atan|gucken to look atan|starren to stare atNPnom+NPacc+PP-mitNPnom+NPacc+PP-mitingressiveconsump-tionan|brechen start to breakan|rei?en start to tearan|schneiden start to cutNPnomNPnom+NPacclocative/relationalsoundan|br?ullen to roar atan|fauchen to hiss atan|meckern to bleat atNPnom+NPacc+PP-anNPnom+NPacclocative/relationalfixationan|heften to stick atan|kleben to glue atan|schrauben to screw ataufNPnom NPnomlocativeblaze-bubbleauf|brodeln to bubble upauf|flammen to light upauf|lodern to blaze upauf|spudeln to bubble upNPnom+PP-zu/in/nach/aufNPnomlocativegazeauf|blicken to glance upauf|schauen to look upauf|sehen to look upNPnom+NPaccNPnom+NPacclocative/dimensionalinstigateauf|hetzen to instigateauf|scheuchen to rouseNPnom+NPacc+PP-aufNPnom+NPacclocative/relationalfixationauf|heften to staple onauf|kleben to glue onauf|pressen to press onNPnom NPnomingressivesoundauf|br?ullen suddenly roarauf|heulen suddenly howlauf|klingen suddenly soundauf|kreischen suddenly screamauf|schluchzen suddenly sobauf|st?ohnen suddenly moanTable 1: The gold standard classes for the experiments, with subcategorization patterns.anheften-MO-an-dat count heften-MO-an-acc countOberfl?ache 3 Ferse 154Gerichtstafel 3 Brust 48Stelle 2 Revers 43Schluss 2 Kreuz 32Unterlage 1 Wand 30Kirchent?ure 1 Spur 12Brett 1 Tafel 11Pinnwand 1 Fahne 11K?orper 1 T?ur 11Wand 1 Pinnwand 9Bauchdecke 1 Kleid 6Baum 1 Brett 6Schleimhautzelle 1 Mastbaum 6Himmel 1 K?orper 5Spur 1 ihn 5Sph?are 1 Kleidung 5Wand 1 Oberfl?ache 5Spur 1 Stelle 4Engstelle 1 Baum 4Pflanze 1 Jacke 4Protein 1 Mantel 4Unterseite 1 Teil 3Zweig 1 Krebszelle 3Pin-Wand 1 schwarz 3Table 2: The strongest dimensions for two sample vectors representing subcategorization slots of theverbs heften and anheften.53.2 Human rating elicitationWe asked human raters to rate the same examples which the system classified automatically.
Each of thepairs of subcategorization slots described in section 3.1 was rated individually.
The pairs were alwayspresented in the order <BV-subcategorization-slot,PV-subcategorization-slot> and in visual blocks cor-responding to BV subcategorization slots.
So the raters could see the possible PV subcategorization slotsin direct comparison.
The order of blocks was randomized.
The raters were asked to judge every pairand rate whether or not they could correspond to a single semantic argument.
They were invited to inventexample sentences, but because of the length of the annotation session they were not asked to write themdown.
They were told that, as a criterion for semantic correspondence, each of the verbs in a pair shouldbe usable to describe at least one event or situation they could think of.
One annotation example, whichdid not stem from the set to be rated, was given.Four human raters were asked to rate examples.
All annotators were experts with either a linguisticor NLP background.
They were all German native speakers and none of them was otherwise involvedin the work presented in this paper.
Because of the large size of the data set to be annotated we hadto distribute the set over two annotation forms and each annotation form was annotated by two raters.Before the annotation started, one of the authors carried out the same annotation in order to estimate thetime needed for each annotation and the level of success which could be expected from the system.
Alsothis annotation was done blindly, without knowledge of the system output, but with a precise knowledgeof the task.The annotation turned out to be much more difficult that we had originally expected.
The annotatorsdescribed the annotation as being hard to perform.
This was also reflected by inter annotator agreement;we could only observe a fair agreement, with a Fleiss?
Kappa score of 0.31.
The agreement between theannotator ratings and the rating by the author was somewhat higher with a Fleiss?
Kappa score of 0.44.Some annotators gave detailed feedback, once they had completed the annotation.4 ResultsTable 3 shows the results we obtained.
The columns show precision, recall and the harmonic F-scoreobtained by comparing the system output to the human ratings.
We used a precision/recall schemabecause the task can be seen as the system selecting the most likely slot correspondences from a set of allpossible correspondences.
So a true positive is obtained if the system selects the same slot that a humanrater would select.
False positives correspond to a slot selected by the system, which was not chosen bythe annotator and a false negative instances are those which are marked by an annotator and not chosenby the system.2Since there was more than one annotators and the annotations differed, we took the sumof true and falls positives and false negatives from all annotators and calculated the scores over this sum.The last column shows the harmonic F-score values we obtained with the annotations produced by one ofthe authors.
The lines represent those threshold values for which the highest precision or F-score couldbe obtained.
The last line represents the baseline.
Since a variable threshold was applied there is a trade-off between precision and recall.
This is represented in figure 1, which displays the same information astable 3, but in a graphical way.As expected, the precision improves with higher thresholds, but this comes at the cost of a lower re-call.
The F-score stays relatively constant.
The baseline is quite low, especially the recall.
This can beexplained because the human raters were free to assign zero-correspondences (i.e.
argument incorpora-tions or argument extensions, as exemplified by the examples in (2)) or more than one correspondenceper target slot.5 DiscussionWe could observe that the system can predict the correspondences between syntactic subcategorizationslots to a fair degree of success and that our method can clearly outperform the baseline.
Our hypotheses2Precision was calculated as{true positives}{true positives}+{false positives}and recall as{true positives}{true positives}+{false negatives}.
The F-scorewas calculated as (precision + recall)/2.6Threshold Precision Recall F-score Author F-score0.15 0.48 0.38 0.43 0.680.6 0.69 0.21 0.45 0.630.85 0.75 0.14 0.44 0.59baseline 0.38 0.23 0.31 0.31Table 3: Results of the evaluation in precision, recall and harmonic F-score.
The last column representsthe pilot annotation carried out by one of the authors.Figure 1: Trade-off between precision and recall.
The F-Score remains relatively stable.that correspondence between subcategorization slots can be predicted to a large degree by distributionalsemantic similarity can thus be confirmed.
On the other hand, the success was not as high as we initiallyexpected.
It is surprising that the precision and recall values obtained with the annotations of the humanraters are much lower than the values obtained in the initial annotation produced by the author.
Theauthor annotation has to be seen as overly optimistic, since it was done with a deeper understanding of thecomputational task which was to be carried out by the system.
Still, this annotation was done blindly.
Sothe big difference we observed is surprising.
As already mentioned, the annotators all reported that theyfound the annotation task difficult to carry out and we attribute the low agreement to this difficulty.
Thefact that the agreement among different rather was also only fair (?
= 0.31) hints in the same direction.
Itmust be said that some annotators found the annotation task more difficult than others.
Two of the ratersreported less annotation difficulty than the remaining.
These two annotators were also the ones withmost annotation experience and they were both familiar with the topic of particle verbs from a theoreticalperspective.
When the system output was compared to the ratings of best annotator, a maximum F-scoreof 0.55 could be achieved, which is still lower than the values obtained in comparison to the authorannotation, but much higher than the average of all annotations.Since some of the annotators gave detailed comments after the annotation was completed, we coulddetect some problems, which made the annotation difficult, but also extends to the automatic matching.For example, some base verbs have a resultative reading which do not express an agent and match thepatient with the nominal subject position.
One such verb is kleben (to stick/glue) as exemplified in (4).Accordingly among the strongest dimensions of the vector that represents the subject slot of kleben,many nouns appear, which are typical things that stick, such as band aids (Pflaster), dough (Teig) andblood (Blut).
The closest vector to the vector for the accusative object vector of ankleben was alsothe accusative object vector of kleben (cosine=0.64), but the subject vector was still relatively strong(cosine=0.19).7(4) a. GerdaGerdaklebtsticksdentheZettelNoteanondietheT?ur.door.b.
DerTheZettelNoteklebtsticks-toanthederdoor.T?ur.The particle verb ankleben can be used to describe the same state of affairs as in (4-a), but not as in (4-b).This is evidently a problem which is hard to solve with our approach because the correspondence of slotsfrom BV and PV interferes with a slot correspondence among different uses of the BV.3Finally, we found that many of the feature vectors were sparsely instantiated.
This can be seen, forexample, in the vector that represents the dative PP modifier headed by an of the verb anheften shownin table 2.
The sparsity problem could be remedied by reducing the number of dimensions with theapplication of some kind of abstraction over the head nouns.
For example the concepts of T?ur (door) andKirchent?ur (church door) are strongly related and could be represented in one dimension of the featurevector.
The same holds for the concepts of Pinnwand (pin board), Wand (wall) and Tafel (blackboard)and other groups of concepts.
With a certain level of abstraction over such concepts, the distance betweenvectors would also be reduced in case they are sparse.
This abstraction is, however, not a trivial problemin itself.
The application of lexical ontologies like WordNet (as used by e.g.
Springorum et al.
(2012)),for example, has the danger of reducing the semantics of head nouns to level of abstraction which is toohigh, since WordNet has only few top-level categories and few levels of conceptual inheritance.6 Conclusion and OutlookWe started the work described in this paper out of an interest to approach the syntactic transfer problemof German particle verbs from a computational perspective.
We wanted to know in how far the subcat-egorization slots of a particle verb can be associated with subcategorization slots of a base verbs fromwhich it is derived.
The information we used for this matching is based on distributional semantics.
Wecould show that can be done with a good degree of success.
From the elicitation of human judgementswe learned that the task is also not an easy one for human raters.
This also sheds some light on thedifficulty of the problem as a computational task.The work we present here is relevant for computational lexicography.
Firstly it can help relate lexicalentries of such closely related lexical items as particle verbs and the base verbs they incorporate.
Thefindings we made here may be also applicable to other types of multi word expressions.In future work we would like to remedy the problem sparse vector representation with the use ofabstraction over the head-nouns which will reduce the dimensionality of the feature vector.
We alsoplan to see in how far an automatic clustering of particle verbs into semantic groups can strengthen theprediction of slot correspondences under the assumption that semantically similar verbs tend to undergothe same syntactic transfer.
Finally, the problem of syntactic transfer between two elements is alsorelated to the predictability of the degree of compositionality between BV-PV pairs.
We are especiallyinterested in this last problem and in future work we plan to investigate in which way subcategorizationslot matching can be used as a predictor for compositionality levels.AcknowledgementsThis work was funded by the DFG Research Project ?Distributional Approaches to Semantic Related-ness?
(Stefan Bott, Sabine Schulte im Walde), and the DFG Heisenberg Fellowship SCHU-2580/1-1(Sabine Schulte im Walde).
We would also like to thank the participants of the human rating experiment.ReferencesNadine Aldinger.
2004.
Towards a Dynamic Lexicon: Predicting the Syntactic Argument Structure of ComplexVerbs.
In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon,Portugal.3This problem is similar to the prediction of argument realizations in diathesis alternations, such as pairs found in pairs ofsentences like ?The boy rolled the ball down the hill?
vs ?the ball rolled down the hill?.8Timothy Baldwin and Aline Villavicencio.
2002.
Extracting the Unextractable: A Case Study on Verb Particles.In Proceedings of the Sixth Conference on Computational Natural Language Learning, pages 98?104, Taipei,Taiwan.Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows.
2003.
An Empirical Model of Mul-tiword Expression Decomposability.
In Proceedings of the ACL-2003 Workshop on Multiword Expressions:Analysis, Acquisition and Treatment, pages 89?96, Sapporo, Japan.Timothy Baldwin.
2005.
Deep Lexical Acquisition of Verb?Particle Constructions.
Computer Speech and Lan-guage, 19:398?414.Collin Bannard.
2005.
Learning about the Meaning of Verb?Particle Constructions from Corpora.
ComputerSpeech and Language, 19:467?478.Bernd Bohnet.
2010.
Top Accuracy and Fast Dependency Parsing is not a Contradiction.
In Proceedings of the23rd International Conference on Computational Linguistics, pages 89?97, Beijing, China.Stefan Bott and Sabine Schulte im Walde.
2014a.
Optimizing a Distributional Semantic Model for the Predictionof German Particle Verb Compositionality.
In Proceedings of the 9th International Conference on LanguageResources and Evaluation, pages 509?516, Reykjavik, Iceland.Stefan Bott and Sabine Schulte im Walde.
2014b.
Syntactic Transfer Patterns of German Particle Verbs and theirImpact on Lexical Semantics.
In Proceedings of the Third Joint Conference on Lexical and ComputationalSemantics, Dublin, Ireland.Gertrud Faa?
and Kerstin Eckart.
2013.
SdeWaC ?
a Corpus of Parsable Sentences from the Web.
In Proceedingsof the International Conference of the German Society for Computational Linguistics and Language Technology,Darmstadt, Germany.Wolfgang Fleischer and Irmhild Barz.
2012.
Wortbildung der deutschen Gegenwartssprache.
Walter de Gruyter,4th edition.Silvana Hartmann.
2008.
Einfluss syntaktischer und semantischer Subkategorisierung auf die Kompositionalit?atvon Partikelverben.
Studienarbeit.
Institut f?ur Maschinelle Sprachverarbeitung, Universit?at Stuttgart.
Supervi-sion: Sabine Schulte im Walde and Hans Kamp.Hans Kamp and Uwe Reyle.
1993.
From discourse to logic: Introduction to modeltheoretic semantics of naturallanguage, formal logic and discourse representation theory.
Number 42.
Springer.Natalie K?uhner and Sabine Schulte im Walde.
2010.
Determining the Degree of Compositionality of German Par-ticle Verbs by Clustering Approaches.
In Proceedings of the 10th Conference on Natural Language Processing,pages 47?56, Saarbr?ucken, Germany.Anke L?udeling.
2001.
On German Particle Verbs and Similar Constructions in German.
Dissertations in Linguis-tics.
CSLI Publications, Stanford, CA.Diana McCarthy, Bill Keller, and John Carroll.
2003.
Detecting a Continuum of Compositionality in PhrasalVerbs.
In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition andTreatment, Sapporo, Japan.Silke Scheible, Sabine Schulte im Walde, Marion Weller, and Max Kisselew.
2013.
A Compact but LinguisticallyDetailed Database for German Verb Subcategorisation relying on Dependency Parses from a Web Corpus: Tool,Guidelines and Resource.
In Proceedings of the 8th Web as Corpus Workshop, pages 63?72, Lancaster, UK.Sabine Schulte im Walde.
2004.
Identification, Quantitative Description, and Preliminary Distributional Analysisof German Particle Verbs.
In Proceedings of the COLING Workshop on Enhancing and Using ElectronicDictionaries, pages 85?88, Geneva, Switzerland.Sabine Schulte im Walde.
2005.
Exploring Features to Identify Semantic Nearest Neighbours: A Case Studyon German Particle Verbs.
In Proceedings of the International Conference on Recent Advances in NaturalLanguage Processing, pages 608?614, Borovets, Bulgaria.Sabine Schulte im Walde.
2006.
The Syntax-Semantics Interface of German Particle Verbs.
Panel discussionat the 3rd ACL-SIGSEM Workshop on Prepositions at the 11th Conference of the European Chapter of theAssociation for Computational Linguistics.9Sylvia Springorum, Sabine Schulte im Walde, and Antje Ro?deutscher.
2012.
Automatic Classification of Germanan Particle Verbs.
In Proceedings of the 8th International Conference on Language Resources and Evaluation,pages 73?80, Istanbul, Turkey.Sylvia Springorum.
2011.
DRT-based Analysis of the German Verb Particle ?an?.
Leuvense Bijdragen, 97:80?105.Barbara Stiebels.
1996.
Lexikalische Argumente und Adjunkte.
Zum semantischen Beitrag von verbalen Pr?afixenund Partikeln.
Akademie Verlag, Berlin.Aline Villavicencio.
2005.
The Availability of Verb-Particle Constructions in Lexical Resources: How much isenough?
Computer Speech & Language, 19(4):415?432.10
