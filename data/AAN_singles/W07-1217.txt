Proceedings of the 5th Workshop on Important Unresolved Matters, pages 128?135,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsPartial Parse Selection for Robust Deep ProcessingYi Zhang?
and Valia Kordoni?
and Erin Fitzgerald??
Dept of Computational Linguistics, Saarland University and DFKI GmbH, Germany?
Center for Language & Speech Processing,Dept of Electrical & Computer Engineering, Johns Hopkins University, USA{yzhang,kordoni}@coli.uni-sb.deerin@clsp.jhu.eduAbstractThis paper presents an approach to partialparse selection for robust deep processing.The work is based on a bottom-up chartparser for HPSG parsing.
Following the def-inition of partial parses in (Kasper et al,1999), different partial parse selection meth-ods are presented and evaluated on the basisof multiple metrics, from both the syntacticand semantic viewpoints.
The applicationof the partial parsing in spontaneous speechtexts processing shows promising compe-tence of the method.1 IntroductionLinguistically deep processing is of high theoret-ical and application interest because of its abilityto deliver fine-grained accurate analyses of natu-ral language sentences.
Unlike shallow methodswhich usually return analyses for any input, deepprocessing methods with precision grammars nor-mally make a clear grammaticality judgment on in-puts, therefore avoiding the generation of erroneousanalyses for less well-formed inputs.
This is a desir-able feature, for it allows for a more accurate mod-eling of language itself.However, this feature largely limits the robustnessof deep processing, for when a sentence is judgedto be ungrammatical, normally no analysis is gen-erated.
When faced with the noisy inputs in realapplications (e.g., input errors introduced by speechrecognizers or other pre-processors, mildly ungram-matical sentences with fragmental utterances, self-editing chunks or filler words in spoken texts, andso forth), lack of robustness means poor coverage,and makes deep processing less competitive as com-pared to shallow methods.Take the English Resource Grammar(ERG; Flickinger (2000)), a large-scale accu-rate HPSG for English, for example.
(Baldwin etal., 2004) reported coverage of 57% of the stringswith full lexical span from the British NationalCorpus (BNC).
Although recent extensions to thegrammar and lexicon have improved the coveragesignificantly, full coverage over unseen texts by thegrammar is still not anywhere in sight.Other domains are even more likely to not fitinto ERG?s universe, such as transcripts of sponta-neously produced speech where speaker errors anddisfluencies are common.
Using a recent version ofthe ERG, we are not able to parse 22.6% of a ran-dom sample of 500 utterances of conversational tele-phone speech data.
76.1% of the unparsed data wasindependently found to contain speaker errors anddisfluencies, and the remaining data either containedfilled pauses or other structures unaccounted for inthe grammar.
Correctly recognizing and interpretingthe substrings in the utterance which have coherentdeep syntax is useful both for semantic analysis andas building blocks for attempts to reconstruct the dis-fluent spontaneously produced utterances into well-formed sentences.For these reasons, it is preferable to exploit theintermediate syntactic and semantic analysis even ifthe full analysis is not available.
Various efforts havebeen made on the partiality of language processing.In bottom-up chart parsing, the passive parser edgeslicensed by the grammar can be taken as partial anal-yses.
However, as pointed out in (Kasper et al,1999), not all passive edges are good candidates, asnot all of them provide useful syntactic/semantic in-formation.
Moreover, the huge amount of passiveedges suggests the need for a technique of select-ing an optimal subset of them.
During recent devel-opment in statistical parse disambiguation, the useof log-linear models has been pretty much standard-ized.
However, it remains to be explored whether thetechniques can be adapted for partial parse selection.In this paper, we adopt the same definition forpartial parse as in (Kasper et al, 1999) and de-fine the task of partial parse selection.
Several dif-128ferent partial parse selection models are presentedand implemented for an efficient HPSG parser ?PET (Callmeier, 2001).One of the main difficulties in the research of par-tial analyses is the lack of good evaluation measure-ments.
Pure syntactic comparisons for parser eval-uation are not good as they are very much specificto the annotation guidelines.
Also, the deep gram-mars we are working with are not automatically ex-tracted from annotated corpora.
Therefore, unlessthere are partial treebanks built specifically for thedeep grammars, there is simply no ?gold?
standardfor non-golden partial analyses.Instead, in this paper, we evaluate the partial anal-yses results on the basis of multiple metrics, fromboth the syntactic and semantic point of views.
Em-pirical evaluation has been done with the ERG on asmall set of texts from the Wall Street Journal Sec-tion 22 of the Penn Treebank (Marcus et al, 1993).A pilot study of applying partial parsing in sponta-neous speech text processing is also carried out.The remainder of the paper is organized as fol-low.
Section 2 provides background knowledgeabout partial analysis.
Section 3 presents variouspartial parse selection models.
Section 4 describesthe evaluation setup and results.
Section 5 concludesthe paper.2 Partial Parsing2.1 HPSG ParsingOur work on partial parsing is done with theDELPH-IN HPSG grammars.
Many of these gram-mars can be used for both parsing and generation.In this paper, we only focus on the parsing task.
Forefficient parsing, we use PET.1 The parsing modulein PET is essentially a bottom-up chart parser.
Theparsing process is guided by the parsing tasks on anagenda.
A parsing task represents the combinationof a passive chart edge and an active chart edge ora rule.
When the combination succeeds, new tasksare generated and put on to the agenda.
The parserterminates either when the task agenda is empty orwhen a specific number of full analyses has beenfound (only in the no-packing best-first mode).HPSG grammars use typed feature structures (TF-Ses) as their background formalism.
The TFSes rep-resent various linguistic objects with a set of fea-1LKB (Copestake, 2002) has a similar chart-based parser,being less efficient mainly due to its implementation in Lisprather than C/C++.tures (attribute value pairs) and a type inheritancesystem.
Therefore, each passive edge on the parsingchart corresponds to a TFS.
A relatively small set ofhighly generalized rules are used to check the com-patibility among smaller TFSes and build up largerones.2.2 Partial ParsesBased on the bottom-up chart parsing, we use theterm Partial Parse to describe a set of intermediatepassive parsing edges whose spans (beginning andend positions) are non-overlapping between eachother, and together they cover the entire input se-quence (i.e., no skipped input tokens).In a graph view, the intermediate results of a chartparser can be described as a directed graph, whereall positions between input tokens/words are ver-tices, and all the passive edges derived during pars-ing are the directed graph arcs.
Obviously such agraph is acyclic and therefore topologically sorted.A partial parse is then a path from the source vertex(the beginning position of the input) to the terminalvertex (the end position of the input).Suppose in chart parsing, we derived the interme-diate results as in Figure 1.
There are in total 4 pos-sible partial parses: {a, b, c, d}, {a, b, f}, {a, e, d}and {a, g}.1w 2w 3w 4w0 1 2 3 4ba c degfFigure 1: Graph representation of intermediate chartparsing resultsNote that each passive edge is a sub-structure li-censed by the grammar.
A derivation tree or TFS canbe reconstructed for it if required.
This definition ofpartial parse is effectively the same to the view ofpartial analyses in (Kasper et al, 1999).2.3 Local Ambiguity PackingThere is one more complication concerning the par-tial parses when the local ambiguity packing is usedin the parser.Due to the inherent ambiguity of natural lan-guage, the same sequence of input may be ana-lyzed as the same linguistic object in different ways.Such intermediate analyses must be recorded dur-ing the processing and recovered in later stages.129Without any efficient processing technique, parsingbecomes computationally intractable with the com-binatory explosion of such local ambiguities.
InPET, the subsumption-based ambiguity packing al-gorithm proposed in (Oepen and Carroll, 2000) isused.
This separates the parsing into two phases:forest creation phase and read-out/unpacking phase.In relation to the work on partial parsing in thispaper, the local ambiguity packing poses an effi-ciency and accuracy challenge, as not all the inter-mediate parsing results are directly available as pas-sive edges on the chart.
Without unpacking the am-biguity readings, interesting partial analyses mightbe lost.2 But exhaustively unpacking all the readingswill pay back the efficiency gain by ambiguity pack-ing, and eventually lead to computational intractableresults.To efficiently recover the ambiguous readingsfrom packed representations, the selective unpack-ing algorithm has been recently implemented as anextension to the algorithm described in (Carroll andOepen, 2005).
It is able to recover the top-n bestreadings of a given passive parser edge based on thescore assigned by a maximum entropy parse rank-ing model.
This neat feature largely facilitates theefficient searching for best partial parses describedin later sections.3 Partial Parse SelectionA partial parse is a set of partial analyses licensedby the grammar which cover the entire input withoutoverlapping.
As shown in the previous section, thereare usually more than one possible partial parsesfor a given input.
For deep linguistic processing, ahigh level of local ambiguity means there are evenmore partial parses due to the combinatory explo-sion.
However, not all the possible partial parses areequally good.
Some partial parses partition the in-put into fragments that do not correspond to linguis-tic constituents.
Even if the bracketing is correct,the different edges with the same span represent sig-nificantly different linguistic objects, and their sub-structures can be completely different, as well.
Allthese indicate the need for methods that can appro-priately select the best partial parses from all thepossible ones.In this section, we review some of the previous2More informative analyses are subsumed by less informa-tive ones.
In subsumption-based packing, such analyses arepacked and are not directly accessible.approaches to partial parse selection, as well as newpartial parse ranking models.3.1 Longest EdgeOne of the simplest and most commonly used cri-terion in selecting the best partial parse is to preferthe partial parses which contain an edge that coversthe largest fragment of the input.
For example, un-der such a criterion, the best partial parse in Figure 1will be {a, g}, since edge g has the largest span.
Thelogic behind this criterion is that such largest frag-ments should preserve the most interesting linguisticanalysis of the input.
As an added incentive, findingthe longest edge does not involve much search.The limitations of such an approach are obvious.There is no guarantee that the longest edge will besignificantly better than shorter edges, or that it willeven correspond to a valid constituent.
Moreover,when there are multiple edges with the same length(which is often the case in parsing), the criteriondoes not suffice for the choice of the best partialparse.3.2 Shortest Path(Kasper et al, 1999) proposed an alternative solu-tion to the problem.
If the preference of each edgeas a part of the partial parse can be quantitatively de-cided as a weight of the edge (with smaller weightsassigned to better candidates), then the problem offinding the best partial parse is to find the shortestpath from the start vertex to the end vertex.
Sincethe graph is completely connected (by the lexicaledges spanning all the input tokens) and topolog-ically sorted, such a path always exists.
The dis-covery of such a path can be done in linear time(O(|V | + |E|)) with the DAG-shortest-path algo-rithm (Cormen et al, 1990).
Though not explic-itly pointed out by (Kasper et al, 1999), such analgorithm allows the weights of the edges to be ofany real value (no assumption of positive weights)as long as the graph is a Directed Acyclic Graph(DAG).
(Kasper et al, 1999) did point out that the weightsof the edges can be assigned by an estimation func-tion.
For example, the implementation of the al-gorithm in PET preferred phrasal edges over lexi-cal edges.
Other types of edges are not allowed inthe partial parse.
Suppose that we assign weight 1to phrasal edges, 2 to lexical edges, and inf to allother edges.
Then for the graph in 2, the best par-tial parses are {e, g} and {f, g}, both of which have130the path length of 2.
It should be noted that such anapproach does not always favor the paths with thelongest edges (i.e., path {h, d} is not preferred inthe given example).1w 2w 3w 4w0 1 2 3 4b ce ghdfa :2 :2 :2:2:1 :1:1i 8:1 :Figure 2: Shortest path partial parses with heuristi-cally assigned edge weightsHowever, (Kasper et al, 1999) did not pro-vide any sophisticated estimation functions basedon the shortest path approach.
Using the heuristicweight described above, usually thousands of differ-ent paths are found with the same weight.
(Kasperet al, 1999) rely on another scoring function in or-der to re-rank the partial parses.
Although differentrequirements for the scoring function are discussed,no further details have been defined.It should be noted that different variations of theshortest path approach are widely in use in many ro-bust deep parsing systems.
For instance, (Riezler etal., 2002) uses the fewest chunk method to choosethe best fragment analyses for sentences withoutfull analysis.
The well-formed chunks are preferredover token chunks.
With this partial parse selectionmethod, the grammar achieves 100% coverage onunseen data.
A similar approach is also used in (vanNoord et al, 1999).3.3 Alternative Estimation FunctionsGenerally speaking, the weights of the edges in theshortest path approach represent the quality of thelocal analyses and their likelihood of appearing inthe analysis of the entire input.This is an interesting parallel to the parse selec-tion models for the full analyses, where a goodnessscore is usually assigned to the full analysis.
Forexample, the parse disambiguation model describedin (Toutanova et al, 2002) uses a maximum entropyapproach to model the conditional probability of aparse for a given input sequence P (t|w).
A similarapproach has also been reported in (Johnson et al,1999; Riezler et al, 2002; Malouf and van Noord,2004).For a given partial parse ?
= {t1, .
.
.
, tk}, ?
={w1, .
.
.
, wk} is a segmentation of the input se-quence so that each local analysis ti ?
?
corre-sponds to a substring wi ?
?
of the input sequencew.
Therefore, the probability of the partial parse ?given an input sequence w is:P (?|w) = P (?|w) ?
P (?|?)
(1)With the bold assumption that P (ti|wi) are mutuallyindependent for different i, we can derive:P (?|w) ?
P (?|w) ?k?i=1P (ti|wi) (2)Therefore, the log-probability will belogP (?|w) ?
logP (?|w) +k?i=1logP (ti|wi) (3)Equation 3 indicates that the log-probability of apartial parse for a given input is the sum of the log-probability of local analyses for the sub-strings, withan additional component ?
log P (?|w) represent-ing the conditional log-probability of the segmen-tation.
If we use ?
logP (ti|wi) as the weight foreach local analysis, then the DAG shortest path al-gorithm will quickly find the partial parse that max-imizes log P (?|w) ?
logP (?|w).The probability P (ti|wi) can be modeled in a sim-ilar way to the maximum entropy based full parseselection models:P (ti|wi) =exp ?nj=1 ?jfj(ti, wi)?t?
?T exp?nj=1 ?jfj(t?, wi)(4)where T is the set of all possible structures thatcan be assigned to wi, f1 .
.
.
fn are the features and?1 .
.
.
?n are the parameters.
The parameters canbe efficiently estimated from a treebank, as shownby (Malouf, 2002).
The only difference from thefull parse selection model is that here intermediateresults are used to generate events for training themodel (i.e.
the intermediate nodes are used as posi-tive events if it occurs on one of the active tree, or asnegative events if not).
Since there is a huge numberof intermediate results availalbe, we only randomlyselect a part of them as training data.
This is es-sentially similar to the approach in (Osborne, 2000),where there is an infeasibly large number of trainingevents, only part of which is used in the estimationstep.
The exact features used in the log-linear modelcan significantly influence the disambiguation accu-racy.
In this experiment we used the same features131as those used in the PCFG-S model in (Toutanova etal., 2002) (i.e., depth-1 derivation trees).The estimation of P (?|w) is more difficult.
Ina sense it is similar to a segmentation or chunkingmodel, where the task is to segment the input intofragments.
However, it is difficult to collect train-ing data to directly train such a model for the deepgrammar we have.
Here we take a simple rough es-timation:P?
(?|w) = |Y (?
)||Z(w)| (5)where Y (?)
is the set of all partial parses that havethe segmentation ?
; Z(w) is the set of all partialparses for the input w.Unfortunately, the shortest path algorithm is notable to directly find the maximized P (?|w).
Fullysearching all the paths is not practical, since thereare usually tens of thousands of passive edges.
Inorder to achieve a balance between accuracy and ef-ficiency, two different approximation approaches aretaken.One way is to assume that the componentlog P (?|w) in Equation 3 has less significant ef-fect on the quality of the partial parse.
If this isvalid, then we can simply use ?
log P (ti|wi) as edgeweights, and use the shortest path algorithm to ob-tain the best ?.
This will be referred to as modelI.An alternative way is to first retrieve several?good?
?
with relatively high P (?|w), and then se-lect the best edges ti that maximize P (ti|wi) foreach wi in ?.
We call this approach the model II.How well these strategies work will be evaluatedin Section 4.
Other strategies or more sophisticatedsearching algorithms (e.g., genetic algorithm) canalso be used, but we will leave that to future re-search.3.4 Partial Semantic ConstructionFor each local analysis on the partial parse derived inthe above steps, a semantic fragment can be derived.The HPSG grammars we use take a compositionalapproach to semantic construction.
Minimal Re-cursion Semantics (MRS; Copestake et al (2006))is used for semantic representation.
MRS can beeasily converted to (Robust) MRS (RMRS; Copes-take (2006)), which allows further underspecifica-tion, and can be used for integration of deep and/orshallow processing tools.For robust deep processing, the ability to gener-ate partial semantics is very important.
Moreover, italso provides us with a way to evaluate the partialparses which is more or less independent from thesyntactic analysis.4 EvaluationThe evaluation of partial parses is not as easy as theevaluation of full parses.
For full parsers, there aregenerally two ways of evaluation.
For parsers thatare trained on a treebank using an automatically ex-tracted grammar, an unseen set of manually anno-tated data is used as the test set.
The parser out-put on the test set is compared to the gold standardannotation, either with the widely used PARSEVALmeasurement, or with more annotation-neutral de-pendency relations.
For parsers based on manuallycompiled grammars, more human judgment is in-volved in the evaluation.
With the evolution of thegrammar, the treebank as the output from the gram-mar changes over time (Oepen et al, 2002).
Thegrammar writer inspects the parses generated by thegrammar and either ?accepts?
or ?rejects?
the anal-ysis.In partial parsing for manually compiled gram-mars, the criterion for acceptable analyses is lessevident.
Most current treebanking tools are not de-signed for annotating partial analyses.
Large-scalemanually annotated treebanks do have the annota-tion for sentences that deep grammars are not ableto fully analyze.
And the annotation difference inother language resources makes the comparison lessstraightforward.
More complication is involved withthe platform and resources used in our experiment.Since the DELPH-IN grammars (ERG, JaCY, GG)use MRS for semantics representation, there is noreliable way of evaluating the output with traditionalmetrics, i.e., dependency relations.In this paper, we use both manual and automaticevaluation methods on the partial parsing results.Different processing resources are used to help theevaluation from the syntactic, as well as the seman-tic point of view.4.1 Syntactic EvaluationIn order to evaluate the quality of the syntactic struc-tures of the partial parses, we implemented the par-tial parse models described in the previous sectionin the PET parser.
The Nov-06 version of the ERGis used for the experiment.
As test set, we used a132subset of sentences from the Wall Street Journal Sec-tion 22 from the Penn Treebank.
The subset contains143 sentences which do not receive any full analysislicensed by the grammar, and do not contain lexi-cal gaps (input tokens for which the grammar can-not create any lexical edge).
The average sentencelength is 24 words.Due to the inconsistency of the tokenisation,bracketing and branching between the Penn Tree-bank annotation and the handling in ERG, we manu-ally checked the partial parse derivation trees.
Eachoutput is marked as one of the three cases: GBL ifboth the bracketing and the labeling of the partialparse derivation trees are good (with no more thantwo brackets crossing or four false labelings); GB ifthe bracketings of the derivation trees are good (withno more than two brackets crossing), but the label-ing is bad (with more than four false labelings); or Eif otherwise.The manual evaluation results are listed in Ta-ble 1.
The test set is processed with two modelspresented in Section 3.3 (M-I for model I, M-IIfor model II).
For comparison, we also evaluate forthe approach using the shortest path with heuristicweights (denoted by SP).
In case there are more thanone path found with the same weight, only the firstone is recorded and evaluated.GBL GB E# % # % # %SP 55 38.5% 64 44.8% 24 16.8%M-I 61 42.7% 46 32.2% 36 25.2%M-II 74 51.7% 50 35.0% 19 13.3%Table 1: Syntactic Evaluation ResultsThe results show that the na?
?ve shortest path ap-proach based on the heuristic weights works prettywell at predicting the bracketing (with 83.3% of thepartial parses having less than two brackets cross-ing).
But, when the labeling is also evaluated it isworse than model I, and even more significantly out-performed by model II.4.2 Semantic EvaluationEvaluation of the syntactic structure only reflects thepartial parse quality from some aspects.
In orderto get a more thorough comparison between differ-ent selection models, we look at the semantic outputgenerated from the partial parses.The same set of 143 sentences from the WallStreet Journal Section 22 of the Penn Treebank isused.
The RMRS semantic representations are gen-erated from the partial parses with different selectionmodels.
To compare with, we used RASP 2 (Briscoeet al, 2006), a domain-independent robust parsingsystem for English.
According to (Briscoe and Car-roll, 2006), the parser achieves fairly good accuracyaround 80%.
The reasons why we choose RASPfor the evaluation are: i) RASP has reasonable cov-erage and accuracy; ii) its output can be convertedinto RMRS representation with the LKB system.Since there is no large scale (R)MRS treebank withsentences not covered by the DELPH-IN precisiongrammars, we hope to use the RASP?s RMRS out-put as a standalone annotation to help the evaluationof the different partial parse selection models.To compare the RMRS from the RASP and thepartial parse selection models, we used the simi-larity measurement proposed in (Dridan and Bond,2006).
The comparison outputs a distance value be-tween two different RMRSes.
We normalized thedistance value to be between 0 and 1.
For each se-lection model, the average RMRS distance from theRASP output is listed in Table 2.RMRS Dist.(?
)SP 0.674M-I 0.330M-II 0.296Table 2: RMRS distance to RASP outputsAgain, we see that the outputs of model IIachieve the highest similarity when compared withthe RASP output.
With some manual validation,we do confirm that the different similarity does im-ply a significant difference in the quality of the out-put RMRS.
The shortest path with heuristic weightsyielded very poor semantic similarity.
The main rea-son is that not every edge with the same span gen-erates the same semantics.
Therefore, although theSP receives reasonable bracketing accuracy, it hasless idea of the goodness of different edges with thesame span.
By incorporating P (ti|wi) in the scoringmodel, the model I and II can produce RMRSes withmuch higher quality.4.3 Evaluating partial parses on spontaneousspeech textThe above evaluation shows in a comparative waythat model II outperforms other selection modelsfrom both syntactic and semantic points of view.
Inorder to show its competence in real applications,133we applied the best performing model II on sponta-neous speech transcripts, which have a high level ofinformality and irregularity not available in newspa-per texts such as the Wall Street Journal.To evaluate the accuracy and potential interpre-tational value of partial parsing on spontaneousspeech transcripts, we considered a 100-sentencerandom sample of the Fisher Conversational Tele-phone Speech 2004 development subcorpus (Cieriet al, 2004), used in the fall 2004 NIST Rich Tran-scription task.Of these 100 sentences, six utterances receivedneither full nor partial parses due to lexical gaps cre-ated by words not found in the grammar?s lexicon.375 utterances produced full HPSG parses.
For theremaining 19 utterances, the one best partial parse isfound for each using model II.According to manual evaluation of the output, se-mantically and syntactically cohesive partial analy-ses were successfully assigned to 9 of the 19 par-tially parsed utterances.
3 of the 19 received incom-plete semantics.
The remaining 7 were judged tobe poor due to false segmentation, the syntax andsemantics within those parsed fragments, or both.In one instance, the interpretation was plausible butviewed as far less likely by the evaluator than thepreferable interpretation (?.
.
.
[i think you know it it ?s][court]?4).
It is likely that n-best partial parsing couldhelp us in most cases.
This would only require astraightforward extension of the current partial pars-ing models.Current partial parsing models do not use any con-fidence thresholds.
Therefore, any input will receivesome full or partial analysis (ignoring the case ofunknown words), together with semantics.
Seman-tic completeness is not checked in partial parsing.
Infuture research, we may consider finding a sophisti-cated solution of assigning confidence scores to theoutput RMRS fragments.Overall though, we believe that the current 50%acceptability of segmentation is reasonable perfor-mance considering the types of noise in the speechtranscript input.As a further step to show the competence of par-tial parsing, we briefly investigated its applicationin capturing disfluent regions in speech texts.
Thestate of the art approach in identifying disfluent re-3Lexical prediction was not used here to avoid obfuscatingthe quality of partial parsing by introducing lexical type predic-tion errors.4The repetition error of ?it?
is interpreted as a topicalization.gions and potentially capturing meaningful text is ashallow parsing method described in (Johnson andCharniak, 2004), which searches the text string forapproximately repeated constituents.
We ran theirsystem on our random sample of the Fisher data, andcompared its results to the partial parse output of thenine well-segmented partial parses analyses (everyutterance of which contained some speaker-induceddisfluency) to see how well partial parsing could po-tentially fare as an approach for identifying disfluentregions of speech text.Often the (Johnson and Charniak, 2004) methodidentified disfluent regions overlapped with identi-fied fragments found in the partial parse, the removalof which would yield a fluent sentence.
As we hopeto learn confidence measures to determine whichfragments are contentless or repetitive in the fu-ture, we identified those partial parses where wholefragments could be deleted to obtain a fluent andmeaning-preserving sentence.In three cases, simple repeated phrases caught by(Johnson and Charniak, 2004) were also caught insome form by the partial parse partitioning.
In an-other case, the speaker interrupts one thought to sayanother, and both approaches identify in a singlefragment the final fluent statement.
Finally, of thenine well-segmented utterances, two partial parsespotentially catch deeper speaker errors that cannotbe caught by (Johnson and Charniak, 2004).5 Conclusion and Future WorkIn this paper, we have presented work on partialparse selection.
Different selection models havebeen presented and evaluated from syntactic andsemantic viewpoints.
In the application of spon-taneous speech text processing, the method showspromising competence, as well as a few problemsfor further study.One thing we did not do is a systematic compar-ison on the efficiency of different partial parse se-lection models.
Although it is clear that less search-ing is involved with the shortest path approach andmodel I comparing to model II, a scientific bench-marking of such difference will be helpful for thechoice between efficiency and accuracy.
Also, amore sophisticated estimation of P (?|w) can poten-tially help the accuracy of the selection models.Another alternative way of evaluation would beto generate an ungrammatical corpus by randomlyintroducing grammar errors.
The performance of the134partial parse selection models can be measured byevaluating how much of the parsing results can berecovered from original sentences.In the study with spontaneous speech text pro-cessing, we see a need for confidence measurementfor partial analyses.
We also see that the conditionalprobability P (ti|wi) does not serve as a good mea-surement, for it largely depends on the structuresthat can be licensed to wi by the grammar.
Thisshould be explored in future studies, as well.ReferencesTimothy Baldwin, Emily M. Bender, Dan Flickinger, Ara Kim,and Stephan Oepen.
2004.
Road-testing the English Re-source Grammar over the British National Corpus.
In Pro-ceedings of the Fourth International Conference on Lan-guage Resources and Evaluation (LREC 2004), Lisbon.Ted Briscoe and John Carroll.
2006.
Evaluating the accuracyof an unlexicalized statistical parser on the PARC DepBank.In Proceedings of the COLING/ACL 2006 Main ConferencePoster Sessions, pages 41?48, Sydney, Australia.Ted Briscoe, John Carroll, and Rebecca Watson.
2006.
Thesecond release of the RASP system.
In Proceedings of theCOLING/ACL 2006 Interactive Presentation Sessions, pages77?80, Sydney, Australia.Ulrich Callmeier.
2001.
Efficient parsing with large-scale uni-fication grammars.
Master?s thesis, Universita?t des Saarlan-des, Saarbru?cken, Germany.John Carroll and Stephan Oepen.
2005.
High efficiency realiza-tion for a wide-coverage unification grammar.
In Proceed-ings of the Second International Joint Conference on Natu-ral Language Processing (IJCNLP05), pages 165?176, JejuIsland, Korea.Christopher Cieri, Stephanie Strassel, Mohamed Maamouri,Shudong Huang, James Fiumara, David Graff, KevinWalker, and Mark L iberman.
2004.
Linguistic resourcecreation and distribution for EARS.
In Proceedings of theRich Transcription Fall Workshop (RT-04F).Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag.2006.
Minimal Recursion Semantics: an Introduction.
Re-search on Language and Computation, 3(4):281?332.Ann Copestake.
2002.
Implementing Typed Feature StructureGrammars.
CSLI, Stanford, CA.Ann Copestake.
2006.
Robust Minimal Recursion Se-mantics.
Working Paper, Unpublished Draft 2004/2006,http://www.cl.cam.ac.uk/ aac10/papers.html.Thomas H. Cormen, Charles E. Leiserson, and Ronald L.Rivest.
1990.
Introduction to Algorithms.
MIT Press, MA.Rebecca Dridan and Francis Bond.
2006.
Sentence compari-son using Robust Minimal Recursion Semantics and an on-tology.
In Proceedings of the ACL Workshop on LinguisticDistances, pages 35?42, Sydney, Australia.Dan Flickinger.
2000.
On building a more efficient grammar byexploiting types.
Natural Language Engineering, 6(1):15?28.Mark Johnson and Eugene Charniak.
2004.
A tag-based noisy-channel model of speech repairs.
In Proceedings of the 42ndMeeting of the Association for Computational Linguistics(ACL?04), Main Volume, pages 33?39, Barcelona, Spain.Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, andStefan Riezler.
1999.
Estimators for stochastic unifcation-based grammars.
In Proceedings of the 37th Annual Meetingof the ACL, pages 535?541, Maryland.Walter Kasper, Bernd Kiefer, Hans-Ulrich Krieger, C.J.
Rupp,and Karsten Worm.
1999.
Charting the depths of robustspeech processing.
In Proceedings of the 37th Meeting of theAssociation for Computational Linguistics (ACL?99), MainVolume, pages 405?412, Maryland, USA, June.Robert Malouf and Gertjan van Noord.
2004.
Wide cover-age parsing with stochastic attribute value grammars.
InIJCNLP-04 Workshop: Beyond shallow analyses - For-malisms and statistical modeling for deep analyses.Robert Malouf.
2002.
A comparison of algorithms for max-imum entropy parameter estimation.
In Proceedings of theSixth Conferencde on Natural Language Learning (CoNLL-2002), pages 49?55.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated corpusof English.
The Penn Treebank.
Computational Linguistics,19:313?330.Stephan Oepen and John Carroll.
2000.
Ambiguity packing inconstraint-based parsing ?
practical results.
In Proceedingsof the 1st Conference of the North American Chapter of theACL, pages 162?169, Seattle, WA.Stephan Oepen, Kristina Toutanova, Stuart Shieber, ChristopherManning, Dan Flickinger, and Thorsten Brants.
2002.
TheLinGO Redwoods treebank: Motivation and preliminary ap-plications.
In Proceedings of COLING 2002: The 17th Inter-national Conference on Computational Linguistics: ProjectNotes, Taipei.Miles Osborne.
2000.
Estimation of Stochastic Attribute-ValueGrammars using an Informative Sample.
In The 18th In-ternational Conference on Computational Linguistics (COL-ING 2000), volume 1, pages 586?592, Saarbru?cken.Stefan Riezler, Tracy H. King, Ronald M. Kaplan, RichardCrouch, John T. III Maxwell, and Mark Johnson.
2002.Parsing the Wall Street Journal using a Lexical-FunctionalGrammar and Discriminative Estimation Techniques.
InProceedings of the 40th Annual Meeting of the Associationfor Computational Linguistics, pages 271?278, Philadelphia.Kristina Toutanova, Christoper D. Manning, Stuart M. Shieber,Dan Flickinger, and Stephan Oepen.
2002.
Parse rank-ing for a rich HPSG grammar.
In Proceedings of the FirstWorkshop on Treebanks and Linguistic Theories (TLT2002),pages 253?263, Sozopol, Bulgaria.Gertjan van Noord, Gosse Bouma, Rob Koeling, and Mark-JanNederhof.
1999.
Robust grammatical analysis for spokendialogue systems.
Natural language engineering, 5(1):45?93.135
