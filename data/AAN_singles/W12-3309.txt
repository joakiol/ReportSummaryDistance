Proceedings of the 2012 Student Research Workshop, pages 49?54,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExtracting fine-grained durations for verbs from TwitterJennifer WilliamsDepartment of LinguisticsGeorgetown UniversityWashington, DC USAjaw97@georgetown.eduAbstractThis paper presents recent work on a  newmethod  to  automatically  extract fine-grained duration  information for  commonverbs using  a  large  corpus  of  Twittertweets.
Regular  expressions were  used toextract verbs and durations from each tweetin a corpus of more than 14 million tweetswith 90.38% precision  covering 486 verblemmas.
Descriptive statistics for each verblemma  were  found  as  well  as  the  mosttypical  fine-grained  duration  measure.Mean  durations  were compared  withprevious work by Gusev et al (2011) and itwas  found  that  there  is  a  small  positivecorrelation.1 IntroductionImplicit information about events is crucial to anynatural  language  processing  task  involvingtemporal  understanding  and  reasoning.
Thisinformation  comes  in  many  forms,  among  themknowledge about typical durations for events andknowledge about typical times at which an eventoccurs.
We know that  lunch lasts  for perhaps anhour and takes place around noon, and so when weinterpret a text such as ?After they ate lunch, theyplayed a game of chess and then went to the zoo?we can infer that the  chess game probably  lastedfor a few hours and not for several months.This  paper  describes  a  new  method forextracting information about typical durations forverbs from  tweets  posted  to  the  Twittermicroblogging site.
Twitter is a rich resource forinformation about  everyday events ?
people posttheir  'tweets'  to  Twitter  publicly  in  real-time  asthey  conduct  their  activities  throughout  the  day,resulting  in  a  significant  amount  of  informationabout common events.
Data from Twitter is morediverse  than the data  found in news articles  thathas  typically  been  used  for  looking  at  eventdurations (Pan et al, 2011).
For example, considerthat (1) was used find out that working can last foran hour and a half:(1) Had work for an hour and 30 mins nowgoing to disneyland with my cousins :)I extracted and analyzed a large number of suchtweets containing temporal duration  information.This  involved  identifying  relevant  tweets,extracting  the  temporal  phrases,  and  associatingthese with the verb they modified.
The processesare  described  below.
Two  objectives wereinvestigated in this paper: (1) how to automaticallyextract  duration  information  for  common  verbsfrom  Twitter,  and  (2)  to  discover  the  durationdistributions for common  verbs.
A wide range offactors  influence  typical  durations.
Among  theseare  the  character  of  a  verb's  arguments,  thepresence  of  negation  and  other  embeddingfeatures.
For example,  eating a snack is differentfrom  eating  a  meal since  these  events  havedifferent durations.
To simplify the task, I set asidetweets  wherein the  sentence-level verb  wasnegated,  or  in  the  conditional  or  future  tenses.Examining  the effect of verb arguments  was alsoset aside in this work.49The  problem  of  finding  typical  duration  forevents can be viewed as a coarse-grained task or afine-grained  task.
At  the  coarse-grained  level  itcould be determined whether or not a chess gamelasts for more or less than one day, whereas a fine-grained analysis would indicate that a chess gamelasts for minutes or hours.The results of this  work show that Twitter canbe  mined  for  duration  information  with  highaccuracy using regular expressions.
Likewise, thetypical durations for verbs can be summarized interms  of  the  most  frequent  duration-measure(seconds,  minutes,  hours,  days,  weeks,  months,years, decades) as well as by descriptive statistics.2 Prior WorkPast research on typical durations has made use ofstandard  corpora  with  texts  from  literatureexcerpts,  news  stories,  and  full-length  weblogs(Pan et al, 2011; Kozareva & Hovy, 2011; Gusevet al, 2011).
However, data from Twitter has beenuseful  for  other  NLP  tasks  such  as  detectingsarcasm (Gonz?lez-Ib?
?ez et al, 2011), as well assentiment  for  Twitter  events  (Thelwall  et  al.,2011).
The present  work used data  from Twitterbecause  it  is  readily  available  and diverse  in  itslinguistic nature.2.1 Hand-AnnotationThe first to examine typical durations of eventswas Pan et al (2011).
They  describe a  method toannotate events  with  duration  information.
Theyhand-annotated  a  portion  of  the  TIMEBANKcorpus  that  consisted  of  news  articles  and  non-financial  articles  from  the  Wall  Street  Journal.They  did  this  for  48  news  articles  (for  2,132events) and 10 Wall Street Journal articles (for 156events).
For each event, three annotators indicateda  lower-bound  duration  and  an  upper-boundduration  that  would  cover  80%  of  the  possiblecases  provided  that  durations  are  normallydistributed.
They converted  the  upper  and  lowerbounds into distributions.
They defined annotatoragreement  to  be the  average  overlap  of  all  thepairwise  overlapping  areas,  calculated  using  thekappa statistic.In their experiments, Pan et al (2011) examinedtheir  annotation  guidelines  and  found  thatannotator  agreement  was  significantly  improvedafter  annotators  were  instructed  to  use  theirguidelines.
These  guidelines  took  intoconsideration information about event classes.
Thefinal  guidelines addressed the following kinds ofclasses:  actions  vs.  states,  aspectual  events,reporting events (quoted and unquoted reporting),multiple  events,  events  involving  negation,appearance  events,  and  positive  infinitiveduration1.
Human  agreement  for  coarse-grainedanalysis  was  reported  to  be  87.7%  whereasagreement for fine-grained analysis was 79.8%.Hand-annotation  is  an expensive way  ofacquiring  typical  duration  and  human  annotatorsdo not always agree on how long events last.
Thispaper presents a  way  to  extract  durationinformation  automatically  and  at  a  fine-grainedscale  to  discover  the  kinds  of  distributions  ofdurations for different verbs as well as their typicaldurations.2.2 Web ExtractionTo compile temporal duration information for awider range of verbs, Gusev et al (2011) exploreda Web-based query method for harvesting typicaldurations of events.
They used five different kindsof  query  frames to  extract  events  and  theirdurations from the web  at  a coarse-grained leveland  at  a  fine-grained  level.
They  compiled  alexicon  of  10,000  events  and  their  durationdistributions.In  the  work of  Gusev  et  al.
(2011),  theycalculated the most likely duration for events at afine-grained  scale.
To  obtain  each  of  the fine-grained  duration  distributions,  they  first  binneddurations into  their  temporal  unit  measures(seconds,  minutes,  hours,  etc.).
Next,  theydiscarded  data  that  was  extracted  using  patternsthat  had  very  low ?hit-counts?
in  their  effort  tojudge  the  reliability  of  their  extraction  frames.Finally, they normalized the distributions based onhow  often  each pattern  occurs  in  general.
Theynote  that  many  verbs  have  a  two-peakeddistribution.
When  used  with  a  duration  marker,run,  for example, is used about 15% of the timewith hour-scale and 38% with year-scale durationmarkers.
In the case of the event say, Gusev et al(2011)  chose  to  normalize  their  durationdistributions  with a  heuristic  to  account  for  thepossibility that all of the year-scale durations could1 Positive infinitive durations describe states that will lastforever once they begin, such as being dead.50be attributed to the common phrase ?...
for years?.Kozareva  and  Hovy  (2011)  also  collectedtypical  durations  of  events  using  Web  querypatterns.
They proposed a six-way classification ofways  in  which  events  are  related  to  time,  butprovided  only  programmatic  analyses  of  a  fewverbs using Web-based query patterns.
They haveasked for a compilation of the 5,000 most commonverbs along with their typical temporal durations.In each of these efforts,  automatically collecting alarge amount of reliable data which covers a widerange of verbs has been noted as a difficulty.3 Methodology3.1 Data CollectionFor the present study, tweets were collected fromthe  Twitter web service API using an open-sourcePython  module called Tweetstream (Halvorsen &Schierkolk,  2010)2.
Specifically,  tweets  werecollected  that  contained  reference  to  a  temporalduration.
The data  collection  task  began  onFebruary  1,  2011  and  ended   on  September  28,2011.
The total number of tweets in  the collectedcorpus  was 14,801,607  and  the  total  number  ofwords in the corpus was 224,623,447.The following query terms (denoting temporalduration  measure)  were  used  to  extract  tweetscontaining  temporal  duration  from  the  Twitterstream:second, seconds, minute, minutes, hour, hours,day, days, week, weeks, month, months, year,years, decade, decades, century, centuries, sec,secs, min, mins, hr, hrs, wk, wks, yr, yrsTweets  were  normalized,  tokenized,  and  thentagged for POS, using the NLTK Treebank Tagger(Bird  &  Loper,  2004).
Each  tweet  came  with  aunique  tweet ID  number  provided by Twitter  andthis ID was used to inform  whether or not  therewere  duplicate  entries in  the dataset,  and  allduplicate entries were removed.
The twitter streamwas also filtered so that it did not include re-tweets(tweets that have been reposted to Twitter).3.2 Extraction FramesTo associate a temporal duration with each  verb,the  verbs and  durations  were  matched  and2 This Python module is available open-source at:https://bitbucket.org/runeh/tweetstream/src/extracted  using  four  types  of  regular  expressionextraction frames.
The patterns applied a heuristicto associate each verb with a temporal expression,similar to the extraction frames used  by Gusev etal.
(2011).
Unlike  Gusev  et  al.
(2011)  fourdifferent  extraction  frames  were  used (for,  in,spend, and  take)  with varied tense and aspect oneach frame,  in an effort to widen the coverage ofextractions  compared  with  that  of Gusev  et  al.(2011).
Each of  the  four  frames were associatedwith  a  set  of  regular  expressions  to match  andextract verbs for two tenses (past and present), andthree  different  aspects  (simple,  perfect,  andprogressive).
Durations  could  match  spelled  outnumbers (one hour), hyphenated numbers (twenty-one minutes), or digits (30 minutes).FOR: The  for-adverbial extraction  frame  wasdesigned to  match  two tenses  and three  aspects.The regular expressions accounted for variation inthe  word  ordering.
Consider  some  simplifiedpattern examples below, which show varied wordorder and tense-aspect combinations:?
John ran for 10 minutes?
for ten minutes Sally was runningIN: The in-adverbial extraction frame  is trickyfor extracting durations because the in-adverbial issometimes  used  to  describe  pending  events  orthings that are about to happen, such as, ?Sally isgoing  to  the  store  in  5  minutes?.
However,  Iwanted  to  avoid  collecting  durations  for  futureevents.
Therefore any verbs that  matched the in-adverbial extraction frame were restricted to matchthe perfect aspect  with any tense or the past tenseand with any aspect, to indicate that a given eventhas been completed.SPEND/TAKE: The tense and aspect were notrestricted and the tweets  were matched for tenseand aspect on  spend and  take.
In these cases thedurations were syntactically associated with spendand take whereas semantically, the durations wereassociated with the verb in the complement clause(read,  work, etc.).
Variations  in  word order,  likethat found in examples of the for extraction frame,were not  allowed for  tweets  matching  the  spendextraction frame.
We see in  the  examples belowthat  the  verb is  read and the tense and aspect ineach  of  the  examples  were  found  to  be  pastprogressive:?
Susie was spending 30 minutes reading51?
Susie was taking 5 minutes to read it3.3 Post-Processing Extracted TweetsThere were several steps to the post-processingof tweets.
First, I identified the verb lemmas usingNLTK  WordNet  (Bird  and  Loper,  2004).
Verblemmas that  occurred  less  than 100 times  wereremoved.Next,  all  of  the  durations-measures  wereconverted  into  seconds  using  a  separate  set  ofregular expressions.
Instances where the durationlasted  for  longer  than  1  billion  seconds  wereremoved.
There  were  6,389  tweets  that  met  thiscondition.
These  tweets  were  removed  in  anattempt to avoid figurative speech that  can  occuron Twitter.
So tweets such as the ones shown in (2)and (3) were removed:(2) I hate when I order food and it takes2009779732 years to come(3) I think my iTunes library is too big, it takes7987694564 years to openNot  all  of  the  temporal  durations  that  wereextracted were numerically  measured.
Tweets thatcontained  indefinite  determiners a or  an  weretreated as having a value of 1 temporal unit so thatthe noun phrase  ?an hour?
could be converted to3600  seconds.
There  were  51,806 such  tweets.Some of the tweets contained expressions such as:?some hours?, ?many hours?, and ?several hours?.In  cases  like  these, the  duration  was  treated  ashaving a value of based on its temporal unit so thatdurations like  ?many hours?
were treated as  onehour.
This  was  applied  to  all  of  the  temporaldurations that were not numerically measured3.In addition, tweets that matched more than oneextraction  frame  were  removed.
After  the  post-processing  stage  390,562 tweets  were  extractedthat covered 486 verb lemmas.3.4 Extraction Frame EvaluationExtraction frame precision was estimated for eachframe by  hand-annotating  a  randomly  selectedsample  and  labeling  each  extracted  tweet asrelevant if the duration, tense, aspect and verb wereidentified.
The extraction frames performed overallwith 90.38%  precision,  estimated  from  a  samplesize  determined  by  the  two-tailed  t-test  forproportions with 95% confidence (n=400, p=0.05).3There were 35,553 tweets matching this criteria.The extraction frame precision is reported below inTable 1.ExtractionFrame TypeEstimatedPrecision# Tweetsfor 91.25% 270,624in 72.25% 83,061spend 99.75% 2,593take 98.25% 34,284Overall 90.38% 390,562Table 1.
Number of extracted tweets4 Analysis of Durations4.1 Duration DistributionsTwitter is a lucrative resource for gathering typicaldurations associated with common verbs at a fine-grained level.
Some  verbs were found to have avery  short  mean  duration  (consider  rain  andsnooze)  while  some  had a  longer mean  duration(consider live and work), shown in Table 2.Short  durations Long durationsdoze 32,721 grow 197,921,586jog 405,550 smoke 246,557,468cough 4,756,427 live 247,274,960rain 4,994,776 marry 312,000,000meet 40,503,127 exist 341,174,881Table 2.
Mean durations (in seconds)for a sample of verb lemmasThe  following plots  (Figures  1-3)  show  thefrequency distribution for  three different  lemmas:wrestle, say, and boil.
Similar to the work done byPan  et  al.
(2011)  and  Gusev  et  al.
(2011),  thisresearch  also  shows that  some  of  the durationdistributions are bimodal.
Gusev et al (2011), Panet  al.
(2011),  and  recent  work  by  Williams  andKatz (2012) show that  some bimodal distributionscould  be  associated  with  iterative  events  orhabituality.52Figure 1.
Distribution for wrestle, typically takesminutes or yearsFigure 2.
Distribution for say, typically takesseconds or yearsThe  bimodal  distributions  for  wrestle and  saycould  possibly  indicate  that  there  are  twophenomena present  in the distributions: durationsfor events, and durations for habits.
Consider thatthe sentence ?John wrestled for half and hour withhis kids?
describes an event whereas the sentence?John wrestled for 30 years as a pro?
describes ahabit.
An  analysis  of  the  relationship  betweenbimodal  distributions  and  habituality  wouldprovide more information in future work.Not all of the distributions are bimodal, in factwe can see that is the case with the distribution forboil.
Users  of  Twitter  are  not  usually reportinglong durations for that verb, but they do in severalrare  cases.
This  could  be  due  to  the  effects  offigurative speech, as in ?John has been making byblood boil for decades?.Figure 3.
Distribution for boil, typically takesminutes4.2 Comparison of Previous WorkTo compare my work with Gusev et al, (2011),I  found  the overlap of verb lemmas.
There were356  verb  lemmas  in  common.
I  calculated  thelog10 of  each mean duration associated with eachverb lemma, for my data and theirs.
I plotted mymeans versus  their  means  and  I  used  linearregression  to  find  a  best  fit  line.
The  Pearsoncorrelation  value  was  0.46  (p  <  0.01),  whichsuggests a weak  positive  correlation.
Some of theoutliers  that we  see in Figure 4 correspond to thefollowing verb lemmas: freeze, judge, age, double,load, lock, revise, score, heat, remove, lose, meet,head, ring, skate, yell, and fall.Figure 4.
Mean durations vs. Gusev et al (2011) inlog10 seconds535 DiscussionThis  paper  has  presented  a  new  method  toautomatically  extract  duration  information  forverbs using data from Twitter.
The four extractionframes used  here  were 90.25%  accurate.
Thisindicates that regular expressions can be applied totweets  to  associate  an  event  with  its  duration.Comparison with previous work shows that there isa  positive  correlation,  and  this  indicates  that  themethod  presented  here  is  nearly  comparable.Corpora,  extracted  tweets,  durations,  and  othermaterials used in this study will be made publiclyavailable at the following website:https://sites.google.com/site/relinguistics/6 Future WorkThere were  several aspects of natural languagethat were put aside in this research.
Future workshould compare how the duration distributions areaffected  by  modality,  negation,  and  the  futuretense/aspect combinations.
And, although I brieflyaddressed the presence of figurative language, thiswork could  benefit  from  knowing  which  tweetswere  figurative,  since  this  may  affect  how  weexamine typical durations.Only four types of extraction frames were usedin this study.
More work is needed to find out ifthere are other extraction frames that can be usedfor  this  same task,  and  exactly  which  extractionframes  should  be  used  under  variouscircumstances.
Future work could also address thecombinatorial effects of modality, negation, futuretenses, and  verb arguments  with typical duration.Events  like  ?John might  finish writing his emailsoon?
and  ?John might finish writing his memoirsoon?
will  have  different  kinds  of durationsassociated with them.Looking at the distributions presented here, it isnot  clear  where  the  boundary  might  be betweensingle  episodes, iterative  events or  habits.
Thiskind of distinction between habits and events couldprove  to  be  important  because  an  event  such  asexist can go on for years, decades or centuries, andin  some cases  exist might  only  last  for  a  fewseconds ?
but  we  would  not  say  that  exist is  ahabit.
At the same time, the frequency distributionfor  wrestle in  Figure  1  indicates that  the  eventwrestle lasts  for  hours,  but the  fact  that  it  isreported to last  for  years  suggests  that  there  aresome habits in the collected data.ReferencesSteven  Bird  and Edward  Loper.
2004.
NLTK:  Thenatural  language  toolkit.
In Proceedings of  42ndAnnual  Meeting  of  the  Association  forComputational Linguistics (ACL-04).Roberto Gonz?lez-Ib?
?ez, Smaranda Muresan, and NinaWacholder.
2011.
?Identifying sarcasm in Twitter: acloser  look?.
In  Proceedings  of  the  49th  AnnualMeeting  of  the  Association  for  ComputationalLinguistics (pp.
581?586),  Portland,  Oregon,  June19-24.Andrey  Gusev,  Nathaniel  Chambers,  Pranav  Khaitan,Divye Khilnani, Steven Bethard, and Dan Jurafsky.2011.
?Using query patterns to learn the durations ofevents?.
IEEE  IWCS-2011,  9th  InternationalConference on Web Services.
Oxford, UK 2011.Rune  Halvorsen,  and Christopher  Schierkolk.
2010.Tweetstream:  Simple  Twitter  Streaming  API(Version  0.3.5)  [Software].
Available  fromhttps://bitbucket.org/runeh/tweetstream/src/Jerry Hobbs and James Pustejovsky.
2003.
?Annotatingand  reasoning  about  time  and  events?.
InProceedings  of  the  AAAI  Spring  Symposium  onLogical  Formulation  of  Commonsense  Reasoning.Stanford University, CA 2003.Zornitsa  Kozareva  and Eduard  Hovy.
2011.
?LearningTemporal  Information  for  States  and  Events?.
InProceedings  of  the  Workshop  on  SemanticAnnotation for Computational Linguistic  Resources(ICSC 2011), Stanford.Marc Moens  and  Mark Steedman.
1988.
?TemporalOntology and Temporal Reference?.
ComputationalLinguistics 14(2):15-28.Feng  Pan,  Rutu  Mulkar-Mehta,  and  Jerry  R.  Hobbs.2011.
"Annotating and Learning Event Durations inText."
Computational Linguistics.
37(4):727-752.Mike  Thelwall,  Kevan  Buckley,  and  GeorgiosPaltoglou.
2011.
?Sentiment  in  Twitter  events.
?Journal  of  the  American  Society  of  InformationScience  and  Technology,  62: 406?418.doi: 10.1002/asi.21462Jennifer Williams and Graham Katz.
2012.
?Extractingand modeling durations  for habits and events  fromTwitter?.
In  Proceedings  of  Association  forComputational Linguistics, ACL 2012.
Jeju, Republicof Korea.54
