Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 237?240,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPToward Smaller, Faster, and Better Hierarchical Phrase-based SMTMei YangDept.
of Electrical EngineeringUniversity of Washington, Seattle, WA, USAyangmei@u.washington.eduJing ZhengSRI InternationalMenlo Park, CA, USAzj@speech.sri.comAbstractWe investigate the use of Fisher?s exactsignificance test for pruning the transla-tion table of a hierarchical phrase-basedstatistical machine translation system.
Inaddition to the significance values com-puted by Fisher?s exact test, we introducecompositional properties to classify phrasepairs of same significance values.
We alsoexamine the impact of using significancevalues as a feature in translation mod-els.
Experimental results show that 1% to2% BLEU improvements can be achievedalong with substantial model size reduc-tion in an Iraqi/English two-way transla-tion task.1 IntroductionPhrase-based translation (Koehn et al, 2003)and hierarchical phrase-based translation (Chiang,2005) are the state of the art in statistical ma-chine translation (SMT) techniques.
Both ap-proaches typically employ very large translationtables extracted from word-aligned parallel data,with many entries in the tables never being usedin decoding.
The redundancy of translation ta-bles is not desirable in real-time applications,e.g., speech-to-speech translation, where speedand memory consumption are often critical con-cerns.
In addition, some translation pairs in a tableare generated from training data errors and wordalignment noise.
Removing those pairs could leadto improved translation quality.
(Johnson et al, 2007) has presented a tech-nique for pruning the phrase table in a phrase-based SMT system using Fisher?s exact test.
Theycompute the significance value of each phrasepair and prune the table by deleting phrase pairswith significance values smaller than a threshold.Their experimental results show that the size of thephrase table can be greatly reduced with no signif-icant loss in translation quality.In this paper, we extend the work in (Johnsonet al, 2007) to a hierarchical phrase-based transla-tion model, which is built on synchronous context-free grammars (SCFG).
We call an SCFG rule aphrase pair if its right-hand side does not contain anonterminal, and otherwise a rewrite rule.
Our ap-proach applies to both the phrase table and the ruletable.
To address the problem that many transla-tion pairs share the same significance value fromFisher?s exact test, we propose a refined methodthat combines significance values and composi-tional properties of surface strings for pruning thephrase table.
We also examine the effect of usingthe significance values as a feature in translationmodels.2 Fisher?s exact test for translation tablepruning2.1 Significance values by Fisher?s exact testWe briefly review the approach for computingthe significance value of a translation pair usingFisher?s exact test.
In Fisher?s exact test, the sig-nificance of the association of two items is mea-sured by the probability of seeing the number ofco-occurrences of the two items being the sameas or higher than the one observed in the sam-ple.
This probability is referred to as the p-value.Given a parallel corpus consisting of N sentencepairs, the probability of seeing a pair of phrases(or rules) (s?,?t) with the joint frequency C(s?,?t) isgiven by the hypergeometric distributionPh(C(s?,?t))=C(s?)!
(N ?
C(s?))!C(?t)!
(N ?
C(?t))!N !C(s?,?t)!C(s?,??t)!C(?s?,?t)!C(?s?,?
?t)!where C(s?)
and C(?t) are the marginal frequenciesof s?
and?t, respectively.
C(s?,?
?t) is the numberof sentence pairs that contain s?
on the source side237but do not contain?t on the target side, and similarfor the definition of C(?s?,?t) and C(?s?,??t).
Thep-value is therefore the sum of the probabilities ofseeing the two phrases (or rules) occur as oftenas or more often than C(s?,?t) but with the samemarginal frequenciesPv(C(s?,?t)) =?
?c=C(s?,?t)Ph(c)In practice, p-values can be very small, and thusnegative logarithm p-values are often used insteadas the measure of significance.
In the rest of thispaper, the negative logarithm p-value is referred toas the significance value.
Therefore, the larger thevalue, the greater the significance.2.2 Table pruning with significance valuesThe basic scheme to prune a translation table isto delete all translation pairs that have significancevalues smaller than a given threshold.However, in practice, this pruning scheme doesnot work well with phrase tables, as many phrasepairs receive the same significance values.
In par-ticular, many phrase pairs in the phrase table havejoint and both marginal frequencies all equal to1.
Such phrase pairs are referred to as triple-1pairs.
It can be shown that the significance valueof triple-1 phrase pairs is log(N).
Given a thresh-old, triple-1 phrase pairs either all remain in thephrase table or are discarded entirely.To look closer at the problem, Figure 1 showstwo example tables with their percentages ofphrase pairs that have higher, equal, or lower sig-nificance values than log(N).
When the thresh-old is smaller than log(N), as many as 35% ofthe phrase pairs can be deleted.
When the thresh-old is greater than log(N), at least 90% of thephrase pairs will be discarded.
There is no thresh-old that prunes the table in the range of 35% to90%.
One may think that it is right to delete alltriple-1 phrase pairs as they occur only once inthe parallel corpus.
However, it has been shownin (Moore, 2004) that when a large number ofsingleton-singleton pairs, such as triple-1 phrasepairs, are observed, most of them are not due tochance.
In other words, most triple-1 phrase pairsare significant and it is likely that the translationquality will decline if all of them are discarded.Therefore, using significance values alone can-not completely resolve the problem of phrase ta-ble pruning.
To further discriminate phrase pairs80%90%100% 50%60%70%80%90%100%>?log(N)30%40%50%60%70%80%90%100%>?log(N)=?log(N)<?log(N)0%10%20%30%40%50%60%70%80%90%100%>?log(N)=?log(N)<?log(N)0%10%20%30%40%50%60%70%80%90%100%Table1Table2>?log(N)=?log(N)<?log(N)0%10%20%30%40%50%60%70%80%90%100%Table1Table2>?log(N)=?log(N)<?log(N)Figure 1: Percentages of phrase pairs with higher,equal, and lower significance values than log(N).of the same significance values, particularly thetriple-1 phrase pairs, more information is needed.The Fisher?s exact test does not consider the sur-face string in phrase pairs.
Intuitively, some phrasepairs are less important if they can be constructedby other phrase pairs in the decoding phase, whileother phrase pairs that involve complex syntac-tic structures are usually difficult to construct andthus become more important.
This intuition in-spires us to explore the compositional property ofa phrase pair as an additional factor.
More for-mally, we define the compositional property of aphrase pair as the capability of decomposing intosubphrase pairs.
If a phrase pair (s?,?t) can be de-composed into K subphrase pairs (s?k,?tk) alreadyin the phrase table such thats?
= s?1s?2.
.
.
s?K?t =?t1?t2.
.
.
?tKthen this phrase pair is compositional; otherwiseit is noncompositional.
Our intuition suggests thatnoncompositional phrase pairs are more importantas they cannot be generated by concatenating otherphrase pairs in order in the decoding phase.
Thisleads to a refined scheme for pruning the phrase ta-ble, in which a phrase pair is discarded when it hasa significance value smaller than the threshold andit is not a noncompositional triple-1 phrase pair.The definition of the compositional property doesnot allow re-ordering.
If re-ordering is allowed,all phrase pairs will be compositional as they canalways be decomposed into pairs of single words.In the rule table, however, the percentage oftriple-1 pairs is much smaller, typically less than10%.
This is because rules are less sparse thanphrases in general, as they are extracted with ashorter length limit, and have nonterminals thatmatch any span of words.
Therefore, the basicpruning scheme works well with rule tables.2383 Experiment3.1 Hierarchical phrase-based SMT systemOur hierarchical phrase-based SMT system trans-lates from Iraqi Arabic (IA) to English (EN) andvice versa.
The training corpus consists of 722Kaligned Iraqi and English sentence pairs and has5.0M and 6.7M words on the Iraqi and Englishsides, respectively.
A held-out set with 18K Iraqiand 19K English words is used for parameter tun-ing and system comparison.
The test set is theTRANSTAC June08 offline evaluation data with7.4K Iraqi and 10K English words, and the transla-tion quality is evaluated by case-insensitive BLEUwith four references.3.2 Results on translation table pruningFor each of the two translation directions IA-to-EN and EN-to-IA, we pruned the translation ta-bles as below, where ?
represents the significancevalue of triple-1 pairs and ?
is a small positivenumber.
Phrase table PTABLE3 is obtained us-ing the refined pruning scheme, and others are ob-tained using the basic scheme.
Figure 2 shows thepercentages of translation pairs in these tables.?
PTABLE0: phrase table of full size withoutpruning.?
PTABLE1: pruned phrase table using thethreshold ?
?
?
and thus all triple-1 phrasepairs remain.?
PTABLE2: pruned phrase table using thethreshold ?
+ ?
and thus all triple-1 phrasepairs are discarded.?
PTABLE3: pruned phrase table using thethreshold ?
+ ?
and the refined pruningscheme.
All but noncompositional triple-1phrase pairs are discarded.?
RTABLE0: rule table of full size withoutpruning.?
RTABLE1: pruned rule table using the thresh-old ?+ ?.Since a hierarchical phrase-based SMT systemrequires a phrase table and a rule table at the sametime, performance of different combinations ofphrase and rule tables is evaluated.
The baselinesystem will be the one using the full-size tables ofPTABLE0 and RTABLE0.
Tables 2 and 3 show theBLEU scores for each combination in each direc-tion, with the best score in bold.708090100PTABLE05060708090100PTABLE0PTABLE130405060708090100PTABLE0PTABLE1PTABLE2PTABLE3RTABLE0102030405060708090100PTABLE0PTABLE1PTABLE2PTABLE3RTABLE0RTABLE10102030405060708090100IA?to?ENEN?to?IAPTABLE0PTABLE1PTABLE2PTABLE3RTABLE0RTABLE10102030405060708090100IA?to?ENEN?to?IAPTABLE0PTABLE1PTABLE2PTABLE3RTABLE0RTABLE1Figure 2: The percentages of translation pairs inphrase and rule tables.It can be seen that pruning leads to a substan-tial reduction in the number of translation pairs.As long phrases are more frequently pruned thanshort phrases, the actual memory saving is evenmore significant.
It is surprising to see that usingpruned tables improves the BLEU scores in manycases, probably because a smaller translation tablegeneralizes better on an unseen test set, and sometranslation pairs created by erroneous training dataare dropped.
Table 1 shows two examples of dis-carded phrase pairs and their frequencies.
Both ofthem are incorrect due to human translation errors.We note that using the pruned rule tableRTABLE1 is very effective and improved BLEUin most cases except when used with PTABLE0 inthe direction EN-to-IA.
Although using the prunedphrase tables had mixed effect, PTABLE3, whichis obtained through the refined pruning scheme,outperformed others in all cases.
This confirmsthe hypothesis that noncompositional phrase pairsare important and thus suggests that the proposedcompositional property is a useful measure ofphrase pair quality.
Overall, the best results areachieved by using the combination of PTABLE3and RTABLE1, which gave improvement of 1% to2% BLEU over the baseline systems.
Meanwhile,this combination is also twice faster than the base-line system in decoding.3.3 Results on using significance values as afeatureThe p-value of each translation pair can be usedas a feature in the log-linear translation model,to penalize those less significant phrase pairs andrewrite rules.
Since component feature values can-not be zero, a small positive number was added top-values to avoid infinite log value.
The resultsof using p-values as a feature with different com-binations of phrase and rule tables are shown in239Iraqi Arabic phrase English phrase in data Correct English phrase Frequenciesthere are four of us there are five of us 1, 29, 1young men three of four young men three or four 1, 1, 1Table 1: Examples of pruned phrase pairs and their frequencies C(s?,?t), C(s?
), and C(?t).RTABLE0 RTABLE1PTABLE0 47.38 48.40PTABLE1 47.05 48.45PTABLE2 47.50 48.70PTABLE3 47.81 49.43Table 2: BLEU scores of IA-to-EN systems usingdifferent combinations of phrase and rule tables.RTABLE0 RTABLE1PTABLE0 29.92 29.05PTABLE1 29.62 30.60PTABLE2 29.87 30.57PTABLE3 30.62 31.27Table 3: BLEU scores of EN-to-IA systems usingdifferent combinations of phrase and rule tables.Tables 4 and 5.
We can see that the results ob-tained by using the full rule table with the fea-ture of p-values (the columns of RTABLE0 in Ta-bles 4 and 5) are much worse than those obtainedby using the pruned rule table without the fea-ture of p-values (the columns of RTABLE1 in Ta-bles 2 and 3).
This suggests that the use of signif-icance values as a feature in translation models isnot as efficient as the use in translation table prun-ing.
Modest improvement was observed in the di-rection EN-to-IA when both pruning and the fea-ture of p-values are used (compare the columnsof RTABLE1 in Tables 3 and 5) but not in thedirection IA-to-EN.
Again, the best results areachieved by using the combination of PTABLE3and RTABLE1.4 ConclusionThe translation quality and speed of a hierarchi-cal phrase-based SMT system can be improvedby aggressive pruning of translation tables.
Ourproposed pruning scheme, which exploits bothsignificance values and compositional properties,achieved the best translation quality and gave im-provements of 1% to 2% on BLEU when com-pared to the baseline system with full-size tables.The use of significance values in translation tableRTABLE0 RTABLE1PTABLE0 47.72 47.96PTABLE1 46.69 48.75PTABLE2 47.90 48.48PTABLE3 47.59 49.50Table 4: BLEU scores of IA-to-EN systems usingthe feature of p-values in different combinations.RTABLE0 RTABLE1PTABLE0 29.33 30.44PTABLE1 30.28 30.99PTABLE2 30.38 31.44PTABLE3 30.74 31.64Table 5: BLEU scores of EN-to-IA systems usingthe feature of p-values in different combinations.pruning and in translation models as a feature hasa different effect: the former led to significant im-provement, while the latter achieved only modestor no improvement on translation quality.5 AcknowledgementsMany thanks to Kristin Precoda and AndreasKathol for valuable discussion.
This work is sup-ported by DARPA, under subcontract 55-000916to UW under prime contract NBCHD040058 toSRI International.ReferencesPhilipp Koehn, Franz J. Och and Daniel Marcu.
2003.Statistical phrase-based translation.
Proceedings ofHLT-NAACL, 48-54, Edmonton, Canada.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
Proceed-ings of ACL, 263-270, Ann Arbor, Michigan, USA.J Howard Johnson, Joel Martin, George Foster andRoland Kuhn.
2007.
Improving Translation Qualityby Discarding Most of the Phrasetable.
Proceed-ings of EMNLP-CoNLL, 967-975, Prague, CzechRepublic.Robert C. Moore.
2004.
On Log-Likelihood-Ratiosand the Significance of Rare Events.
Proceedings ofEMNLP, 333-340, Barcelona, Spain240
