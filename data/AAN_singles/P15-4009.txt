Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49?54,Beijing, China, July 26-31, 2015. c?2015 ACL and AFNLPA Dual-Layer Semantic Role Labeling SystemLun-Wei KuInstitute of Information ScienceAcademia Sinica, Taiwanlwku@iis.sinica.edu.twShafqat Mumtaz VirkInstitute of Information ScienceAcademia Sinica, Taiwanvirk.shafqat@gmail.comYann-Huei LeeInstitute of Information ScienceAcademia Sinica, Taiwanandycyrus.gmail.comAbstractWe describe a well-performed semantic rolelabeling system that further extracts concepts(smaller semantic expressions) from unstruc-tured natural language sentences language in-dependently.
A dual-layer semantic rolelabeling (SRL) system is built using ChineseTreebank and Propbank data.
Contextual in-formation is incorporated while labeling thepredicate arguments to achieve better perfor-mance.
Experimental results show that theproposed approach is superior to CoNLL 2009best systems and comparable to the state ofthe art with the advantage that it requires nofeature engineering process.
Concepts are fur-ther extracted according to templates formu-lated by the labeled semantic roles to serve asfeatures in other NLP tasks to provide seman-tically related cues and potentially help in re-lated research problems.
We also show that itis easy to generate a different language ver-sion of this system by actually building anEnglish system which performs satisfactory.1 IntroductionSemantic roles are utilized to find concepts au-tomatically and assure their meaningfulness.
Se-mantic role labeling is a research problem whichfinds in a given sentence the predicates and theirarguments (identification), and further labels thesemantic relationship between predicates and ar-guments, that is, their semantic roles (classifica-tion).
There are several labeling sets.
Researchershave widely adopted the semantic role labels de-fined in Propbank (Bonial et al., 2010) like predi-cate (PRED), numbered arguments 0 to 5 (ARG0,ARG1, ARG2, ARG3, ARG4, ARG5), or modifierarguments (ARGM-X); finer labels are those de-fined in Sinica Treebank (Huang et al., 2000) likeagent, theme, target, which are labeled on eachnode of the parse tree; those defined in FrameNet(Ruppenhofer et al., 2006) are the finest but mostexpressive.
Each set provides semantic information.As long as the semantic relationship between termsderives from their semantic role labels, we are ableto determine whether they should be extractedfrom the current sentence to construct a concept.The word concept usually refers to an abstract orgeneral idea inferred or derived from specific in-stances.
Therefore, the extraction of concepts fromtext is often defined as extracting terms that are insome way related to one another.
These termscould be predefined by people in resources such asontologies, or they could be typical words in texts.In this paper, we view concepts as the continuousor discontinuous meaningful units in a sentenceand hence they are tightly related to semantic roles.We propose a dual-layer semantic role labelingsystem which provides extracted concepts accord-ing to the reported labels, and then demonstrate thefunctions of this system.
Experimental results willshow the merit of the proposed framework.2 Related WorkPrevious studies related to this work can be dividedinto two groups: semantic role labeling and con-cept extraction.
Semantic role labeling (SRL) hassparked much interest in NLP (Shen and Lapata,2007; Liu and Gildea, 2010).
The first automaticSRL systems were reported by Gildea and Jurafskyin 2002 (Gildea and Jurafsky 2002); since then,their ideas have dominated the field.
In their ap-proach, they emphasize the selection of appropriatelexical and syntactical features for SRL, the use ofstatistical classifiers and their combinations, andways to handle data sparseness.
Many researchershave tried to build on their work by augmentingand/or altering the feature set (Xue 2004), by ex-perimenting with various classification approaches(Pradhan et al.
2004; Park and Rim 2005), and byattempting different ways to handle data sparseness49(Zapirain, Agirre, and M?rquez 2007).
Moreover,some researchers have tried to extend it in novelways.
For example, Ding and Chang (2008) used ahierarchical feature selection strategy, while Jiang,Li, and Ng (2005) proposed exploiting argumentinterdependence, that is, the fact that the semanticrole of one argument can depend on the semanticroles of other arguments.Many researchers have tried to extract conceptsfrom texts (Gelfand et al., 1998; Hovy et al., 2009;Villalon and Calvo, 2009; Dinh and Tamine, 2011;Torii et al., 2011).
Hovy narrowed the domain ofinterest into concepts ?below?
a given seed term.Villalon and Calvo extract concepts from studentessays for concept map mining, which generates adirected relational graph of the extracted conceptsin an essay.
For specific domains, biological ormedical concepts are of greatest interest to re-searchers (Jonnalagadda et al., 2011).
Two rela-tively new and related approaches are the Conceptparser (Rajagopal et al.
2013), a part of theSenticNet project (Cambria, Olsher, and Rajagopal2014) and ConceptNet (Liu and Singh 2004).
Theformer is a tool to decompose unrestricted naturallanguage text to a bag of concepts, which is similarto our work.
However, in the final phase a seman-tic knowledge base is used to express a concept inall its different forms and their concept-parser doesnot use any semantic knowledge during decompo-sition.
The latter is a semantic network based onthe Open Mind Common Sense (OMCS)knowledge base.
As it is a knowledge base, itsconstruction process is quite different from thework described here of automatically extractingconcepts from sentences.Figure 2: System Interface (Chinese example sentence: In 2010, Google company negotiated with the China gov-ernment on the issue of results censoring, and eventually shut down the web search service.
)Syntactic ParsingSemantic RoleLabelingConceptExtraction Concept TemplatesProp-BankOutput:ConceptsFigure 1:  System Framework.Input:Sentence503 SystemThe proposed system includes three major com-ponents: a syntactic parser, a semantic role la-beler, and a concept formulation component.
Theframework is shown in Figure 1.
The input sen-tence is first transformed into a syntactic parsetree through a syntactical analysis step that al-most all automatic semantic role labeling sys-tems require (Johansson and Nugues 2008).
Herethe Stanford parser (Klein and Manning 2003) isutilized.
Figure 2 shows the system interface.The left part is the English system and the rightpart is the Chinese system.
After users input asentence, the system will automatically parse,label semantic roles and report the related con-cepts for it.3.1 Semantic Role LabelingTo develop a SRL system, a total of 33 featuresincluding features related to the head word relat-ed features, target word related features, gram-mar related features, and semantic type relatedfeatures, are collected from related work (Xue,2008; Ding and Chang, 2008; Sun and Jurafsky2004; Gildea and Jurafsky 2002).
Then the base-line maximum entropy system is developed usingthese features (Manning and Schutze, 1999).Two sets of data ?
Chinese Treebank 5.0 togetherwith Propbank 1.0 and Chinese Treebank 6.0with Propbank 2.0 ?
are separated into the train-ing and testing sets, and are then used to buildmodels to identify and classify semantic labels,and also to evaluate the performance, respective-ly.
As Chinese data was selected for experiments,the hypernyms of words from E-Hownet1, a Chi-nese word ontology, are utilized as the semantictype of words.
When applying the whole systemon data in other languages, for major languages itis not difficult to find resources to obtain hyper-nyms.
For minor languages, it is fine to just ig-nore these features.
According to our experience,this will yield F-Score reductions of only 1% to2%.We further exploit argument interdependenceto enhance performance by the dual-layerframework shown in Figure 2.
Suppose for anygiven predicate P in a sentence, the system hasidentified the three potential arguments A1, A2,and A3 of the predicate.
Next, to predict the se-mantic role labels of those three arguments, acritical observation made by (Jiang, Li, and Ng1 http://ckip.iis.sinica.edu.tw/CKIP/conceptnet.htm2005) is that the semantic roles of argumentsmay depend on each other; this phenomenon isknown as argument interdependence.
A commonway to escape argument interdependence is toadopt sequence labeling, and use the featuresextracted from the arguments around the currentargument together with the features of the currentone to predict the label for the current argument.For example, while predicting the label of argu-ment A2, features extracted from arguments A1and A3 are also used.
Although window sizescan be used to set the scope of this interdepend-ence, the window-size strategy has some practi-cal limits: the typically large feature setnecessitates the use of smaller window sizes (awindow size of [-1,1] is common).
However,small window sizes can make it impossible tocapture long dependency phenomena.To overcome the limitations of the window-size strategy, we use all the surrounding argu-ments?
predicted labels ?
window size [-?,?
],as opposed to their features ?
to predict the labelof the current node.
This also conforms to therule that when a role is taken by the other argu-ment, it is less likely that the current argument isof the same role.
We implement this idea usingthe dual-layer classification framework shown inFigure 3.In layer 1 the baseline system is used to pre-dict the labels for identified nodes.
Then in layer2, these predicted labels of all surrounding argu-ments (in this example, A1 and A3) together withother features of the current node (A2) are usedLayer 1A1 A2 A3Features Features FeaturesLabelpredictionLabelpredictionLayer 2Features +predicted labelsPredicted labelFigure 3:  SRL classification framework.51to predict the label of the current node.
Note asthis approach is under no window size limitation,the labels of all arguments under the same predi-cate are taken into account.
Experimental resu ltsshow that this strategy works better than thewindow-size strategy.
Table 1 shows the systemaccuracies for the single- and dual-layer frame-works.
The predicted dual-layer framework uti-lized the SRL labels predicted in layer 1, whilethe gold dual-layer framework used as featuresthe gold SRL labels of the surrounding argu-ments.System AccuracyDing and Chang, 2008 (state of the art) 94.68Single-layer framework 94.60Dual-layer framework (predicted) 94.86Dual-layer framework (gold) 95.40Table 1.
Accuracy of SRL classification phase.To further evaluate the performance of theproposed system and offer comparisons, we ap-plied it on Chinese Treebank 6.0 with Propbank2.0 in the same way as in the CoNLL 2009 SRL-only task data according to the information pro-vided by the CoNLL organizers.
Table 2 showsthe results of the proposed system.
Table 3 fur-ther shows the performance of the best systemsin CoNLL 2009.Identification Classification SRLPrecision 94.3890.2286.89Recall 96.24 80.11F-Score 95.30 83.36Accuracy 97.92 96.25Table 2.
SRL results on Propbank 2.0.System name Type ScoreNugus (Bj?rkelundet al., 2009)Closed chal-lenge, SRL-only78.50(F-Score)Meza-Ruiz(Meza-Ruiz andRiedel, 2009)Closed chal-lenge, SRL-only82.66(Precision)T?ckstr?m(T?ckstr?m, 2009)Closed chal-lenge, SRL-only79.31(Recall)Che(Che et al., 2009)Open challenge,Joint Task76.42(F-Score)Table 3.
CoNLL 2009 SRL performance2.The CoNLL 2009 task builds dependency-based SRL systems, while the proposed systemworks on the constituent-based parsing trees.Also the settings of the proposed system are not2 http://ufal.mff.cuni.cz/conll2009-st/results/results.phpall the same as the CoNLL 2009 SRL systems.
InCoNLL 2009, as noted in Table 5, participantscan participate in open or closed challenges, andcan choose whether they want to attempt bothsyntactic and semantic labeling tasks (joint task)or only to attempt the SRL task.
The setting ofthe proposed system is open challenge, SRL-only,while researchers working on the Chinese dataselected only two other different settings: closedchallenge, SRL only and open challenge, jointtask.
However, Table 5 shows that the proposedsystem outperforms the CoNLL 2009 best sys-tems in terms of precision (86.89 vs. 82.66), re-call (80.11 vs. 79.31), and f-score (83.36 vs.78.50).
Moreover, lately, dependency-based SRLhas shown advantages over constituent-basedSRL (Johansson and Nugues, 2008); thus we ex-pect to show better results if working on depend-ency-based parsed data.
Therefore, we believethe proposed system is comparable or even supe-rior to other systems.3.2 Concept-FormulationsOnce the sentence has been annotated seman-tically, the concepts are formulated by concepttemplates designed according to Propbank SRLlabels.
Propbank provides semantic role labels oftwo types.
One type is numbered argumentsArg0, Arg1, and so on until Arg5; the other typeis modifiers with function tags, which give addi-tional information about when, where, or how theevent occurred.
Tables 4 and 5 list the descrip-tions of the Propbank arguments utilized for theconcept template generation.
Table 6 then liststhe generated concept templates.As shown in Table 6, the predicate and its ar-guments are placed in various orders to build alist of concepts according to their semantic roles.These role combinations serve as templateswhich can capture a complete and importantpiece of information described in one sentence toform a concept.
Additionally, the arguments (i.e.,the subjects and objects of the predicate) inthemselves can represent useful concepts, and forthis reason, the arguments alone are also includ-ed in extracted concepts.
For comparison, in Ta-ble 7 the extracted concepts are listed with thosefrom the SenticNet concept parser.52NumberedArgumentDescriptionArg0  agent, causer, experiencerArg1 theme, patientArg2 instrument, benefactive, attributeArg3  starting point, benefactive, attributeArg4  ending pointArg5 DirectionTable 4.
Propbank numbered arguments.Modifier Desc Modifier DescArgM-LOCLocation ArgM-COM ComitativeArgM-TMPTime ArgM-DIR DirectionArgM-GOLGoal ArgM-EXT ExtentArgM-MNRManner ArgM-NEG NegationArgM-CAUCause ArgM-PRP PurposeTable 5.
Propbank modifier auguments.# Concept Template1 ARG0_Pred2 Pred_ARG13 Pred_ARG1_ARG24 Pred_ARG1_ARG2_ARG35 Pred_ARG1_ARG2_ARG3_ARG46 Pred_ARG1_ARG2_ARG3_ARG4_ARG57 Pred_with_ARGM-COM8 Pred_in_ARGM-LOC9 Pred_in_order_to_ARGM-PRP10 Pred_in_the_direction_ARGM-DIR11 Pred_because_ARGM-CAU12 Pred_when_ARGM-TMP13 Pred_ARGM-GOL14 Pred_by_ARGM-EXT15 Pred_ARGM-MNR16 Pred_ARGM-NEG17 ARGX?s18 ARGM?sTable 6.
Concept templates.Proposed Systema_birthday_cake, bought_Super_Market,bought_a_birthday_cake, Super_Market, celebrat-ed_David?s_birthday, We_bought, David?s_birthday,We_celebratedSenticNet Concept Parserbirthday_cake, birthday_from_market,buy_birthday_cake, birthday_cake, birthday_david,buy_from_market, super_market, celebrate_davidTable 7.
Concepts generated by the proposed systemand the SenticNet Concept Parser.4 ConclusionWe have presented a system to decompose a sen-tence into a set of concepts through the proposedwell-performed semantic role labeling system(http://doraemon.iis.sinica.edu.tw/srl-concept/),which differs from previous related attempts.
Wedemonstrated that this dual-layer semantic rolelabeling framework that exploits argument inter-dependence performs slightly better than thestate of the art, and that it is relatively simple asno feature selection or engineering processes arerequired.
We easily generated another Englishsystem under the same framework, which show-cased the language independency of the system.In addition, it reached an F-Score 0.84, whichwas considered satisfactory.
In the future, weplan to investigate how to further represent andutilize these extracted concepts efficiently inmore NLP tasks which call for deep languageunderstanding.AcknowledgementResearch of this paper was partially supported byNational Science Council, Taiwan, under thecontract NSC101-2628-E-224-001-MY3.ReferencesBj?rkelund, A., Hafdell, L., & Nugues, P. 2009.
Mul-tilingual semantic role labeling.
In Proceedings ofthe Thirteenth Conference on Computational Natu-ral Language Learning: Shared Task, 43-48.Bonial, C.; Babko-Malaya, O.; Choi, J. D.; Hwang, J.;and Palmer, M. 2010.
Propbank annotation guide-lines.
Center for Computational Language andEdu-cation Research Institute of Cognitive ScienceUni-versity of Colorad at Boulder.Cambria, E.; Olsher, D.; and Rajagopal, D. 2014.Senticnet 3: A common and common-senseknowledge base for cognition-driven sentimentanal-ysis.
In Proceedings of AAAI, 1515?1521.Che, W., Li, Z., Li, Y., Guo, Y., Qin, B., & Liu, T.2009.
Multilingual dependency-based syntactic andsemantic parsing.
In Proceedings of the ThirteenthConference on Computational Natural LanguageLearning: Shared Task, 49-54.Dinh, D., & Tamine, L. 2011.
Biomedical conceptextraction based on combining the content-basedand word order similarities.
In Proceedings of the2011 ACM Symposium on Applied Computing,1159-1163.
ACM.Gelfand, B., Wulfekuler, M., & Punch, W. F. 1998.Automated concept extraction from plain text.53In AAAI 1998 Workshop on Text Categoriza-tion, 13-17.Gildea, D., and Jurafsky, D. 2002.
Automatic labelingof semantic roles.
Comput.
Linguist.
28(3):245?288.Hovy, E., Kozareva, Z., & Riloff, E. 2009.
Towardcompleteness in concept extraction and classifica-tion.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Pro-cessing: Volume 2-Volume 2, 948-957.Huang, C. R., Chen, F. Y., Chen, K. J., Gao, Z. M., &Chen, K. Y.
(2000, October).
Sinica Treebank: de-sign criteria, annotation guidelines, and on-line in-terface.
In Proceedings of the second workshop onChinese language processing: held in conjunctionwith the 38th Annual Meeting of the Associationfor Computational Linguistics-Volume 12, 29-37.Jiang, Z. P.; Li, J.; and Ng, H. T. 2005.
Semantic ar-gu-ment classification exploiting argument inter-depend-ence.
In Proceedings of the 19thInternational Joint Conference on Artificial Intelli-gence, IJCAI?05, 1067?1072.Johansson, R., & Nugues, P. 2008.
The effect of syn-tactic representation on semantic role labeling.
InProceedings of the 22nd International Conferenceon Computational Linguistics-Volume 1, 393-400.R.
Johansson and P. Nugues.
2008.
Dependency-based semantic role labeling of PropBank.
In Pro-ceedings of the 2008 Conference on EmpiricalMethods in Natural Language Processing.Jonnalagadda, S., Cohen, T., Wu, S., & Gonzalez, G.2012.
Enhancing clinical concept extraction withdistributional semantics.
Journal of biomedical in-formatics, 45(1), 129-140.Klein, D., and Manning, C. D. 2003.
Accurate unlexi-cal-ized parsing.
In Proceedings of the 41st AnnualMeeting on Association for Computational Lin-guis-tics - Volume 1, ACL ?03, 423?430.D.
Liu and D. Gildea.
2010.
Semantic role features formachine translation.
In Proceedings of the 23rd In-ternational Conference on Computational Linguis-tics.Liu, H., and Singh, P. 2004.
Conceptnet: A practicalcommonsense reasoning toolkit.
BTTECHNOLOGY JOURNAL 22:211?226.Manning, Christopher D. and Schutze, Hinrich.
1999.Foundations of statistical natural language pro-cessing, Cambridge, Mass.
: MIT Press.Meza-Ruiz, I., & Riedel, S. 2009.
Multilingual se-mantic role labelling with markov logic.In Proceedings of the Thirteenth Conference onComputational Natural Language Learning: SharedTask, 85-90.Park, K.-M., and Rim, H.-C. 2005.
Maximum entropybased semantic role labeling.
In Proceedings of theNinth Conference on Computational Natural Lan-guage Learning, CONLL ?05, 209?212.Pradhan, S.; Ward, W.; Hacioglu, K.; and Martin, J. H.2004.
Shallow semantic parsing using support vec-tor machines.
In Proceedings of the Conference onthe Human Language Technologies and NorthAmerican Association for Computational Linguis-tics (HLT-NAACL 2004), 233?240.Rajagopal, D.; Cambria, E.; Olsher, D.; and Kwok, K.2013.
A graph-based approach to commonsenseconcept extrac- tion and semantic similarity detec-tion.
In Proceedings of the 22Nd International Con-ference on World Wide Web Companion,WWW ?13 Companion, 565?570.Ruppenhofer, J., Ellsworth, M., Petruck, M. R., John-son, C. R., & Scheffczyk, J.
(2006).
FrameNet II:Extended theory and practice.D.
Shen and M. Lapata.
2007.
Using semantic roles toimprove question answering.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing and on Computational NaturalLanguage Learning.T?ckstr?m, O.
2009.
Multilingual semantic parsingwith a pipeline of linear classifiers.
In Proceedingsof the Thirteenth Conference on ComputationalNatural Language Learning: Shared Task, 103-108.Torii, M., Wagholikar, K., & Liu, H. 2011.
Usingmachine learning for concept extraction on clinicaldocuments from multiple data sources.
Journal ofthe American Medical Informatics Association,amiajnl-2011.Villalon, J., & Calvo, R. A.
2009.
Concept extractionfrom student essays, towards concept map mining.In Proceedings of Ninth IEEE International Con-ference on Advanced Learning Technologies, 221-225.Xue, N. 2004.
Calibrating features for semantic rolelabeling.
In Proceedings of EMNLP 2004, 88?94.Xue, N. 2008.
Labeling chinese predicates withseman-tic roles.
Comput.
Linguist.
34(2):225?255.Zapirain, B.; Agirre, E.; and M?rquez, L. 2007.
Ub-cupc: Sequential srl using selectional preferences:An approach with maximum entropy markov mod-els.
In Proceedings of the 4th International Work-shop on Semantic Evaluations, SemEval ?07, 354?357.54
