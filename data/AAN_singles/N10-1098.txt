Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 677?680,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEngaging learning groups using Social Interaction StrategiesRohit Kumar Carolyn P. Ros?Language Technologies InstituteCarnegie Mellon University, Pittsburgh, PA, 15213rohitk@cs.cmu.edu cprose@cs.cmu.eduAbstractConversational Agents have been shown to beeffective tutors in a wide range of educationaldomains.
However, these agents are often ig-nored and abused in collaborative learningscenarios involving multiple students.
In ourwork presented here, we design and evaluateinteraction strategies motivated from prior re-search in small group communication.
Wewill discuss how such strategies can be im-plemented in agents.
As a first step towardsevaluating agents that can interact socially, wereport results showing that human tutors em-ploying these strategies are able to cover moreconcepts with the students besides being ratedas better integrated, likeable and friendlier.1 IntroductionConversational Agents (CAs) are autonomous in-terfaces that interact with users via spoken or writ-ten conversation.
One of the applications of CAs istutoring.
Various research groups have developedtutoring agents in domains like reading, algebra,geometry, calculus, physics, computer literacy,programming, foreign languages, research methodsand thermodynamics.
Many of the evaluationsshow that CAs can be effective tutors (Arnott et.al., 2008; Kumar et.
al., 2007; Graesser et.
al.,2005).Most systems that use CAs as tutors have beenbuilt for learning scenarios involving one student.Evaluation of learning technologies involving stu-dents working in groups with interactive agents hasshown that learners are helped both by learning asa group and receiving tutorials from agents (Kumaret.
al., 2007).
However, some previous studieshave reported that students learning in groups ig-nore the tutor?s messages, unlike the case wherestudents are individually tutored.
Groups are morelikely to abuse tutors than individual students.We reason that the presence of other students incollaborative learning scenarios causes the agentsto compete for the attention of the students.
Sincethe agents are not adept at performing social inter-active behavior, which makes up the bulk of for-mative communication in a group, they are quicklypushed to the periphery of the group.Research on small group communication hasidentified twelve interaction categories that arecommonly observed in small groups (Bales, 1950).These categories are broadly classified into taskand social-emotional categories.
Content presentedby most current CAs mostly classifies under thetask categories.
In section 2, we will list the con-versational strategies motivated from the three pos-itive social-emotional interaction categories.Thereafter, the implementation and evaluation of aCA that interleaves these social interaction strate-gies while executing a task plan will be described.2 Social Interaction StrategiesBalesian methodology (Bales, 1950) identifiesthree positive social-emotional interaction catego-ries: showing solidarity, showing tension releaseand agreeing.
Participants contribute turns of thesecategories to address the problems of re-integration, tension release and decision respec-tively.
We have mapped these categories to practi-cally implementable conversational strategies.
Thismapping is shown in table 1 ahead.Each strategy is implemented as an instantiationof a conversational behavior.
Most of the strategieslisted in Table 1 are realized as prompts, triggeredby rules based on agent plan, discourse and contextfeatures.
For example, strategy 1e is triggered677when one or more students in the group are foundto be inactive for over 5 minutes.
In this event, thetutor chooses to raise the status of the inactive stu-dents by eliciting contributions from them througha prompt like: Do you have any suggestions Mike?More implementation details of these strategiesand triggers are discussed in the following section.1.
Showing SolidarityRaises other's status, gives help, reward1a.
Do IntroductionsIntroduce and ask names of all participants1b.
Be Protective & NurturingDiscourage teasing1c.
Give Re-assuranceWhen student is discontent, asking for help1d.
Complement / PraiseTo acknowledge student contributions1e.
EncourageWhen group or members are inactive1f.
Conclude Socially2.
Showing Tension ReleaseJokes, laughs, shows satisfaction2a.
Expression of feeling betterAfter periods of tension, work pressure2b.
Be cheerful2c.
Express enthusiasm, elation, satisfactionOn completing significant steps of the task3.
AgreeingShows passive acceptance, understands,concurs, complies3a.
Show attentionTo student ideas as encouragement3b.
Show comprehension / approvalTo student opinions and orientationsTable 1.
Social Interaction Strategies for threesocial-emotional interaction categories3 WrenchTalker: ImplementationWrenchTalker is a CA we have built to employ thesocial interaction strategies listed in section 2.
Ithelps teams of engineering students learn and ap-ply basic concepts of mechanical stress while theyparticipate in a freshmen lab project to design analuminum wrench.
Students can interact with thisagent using a text-based chat environment.The agent is built using the Basilica architecture(Kumar and Ros?, 2009).
Under this architecture,CAs are modeled as a network of behavioralcomponents.
There are three types of components:actors (actuators / performers), filters (perceptors /annotators / cordinators) and memories.
Figure 1below shows a simplified depiction of theWrenchTalker component network.Figure 1.
Component Network of WrenchTalkerThree of the actor and filter componentscorrespond to three observable behaviors of thetutor, i.e., Introducing (ai, fi), Prompting (ap, fp) andTutoring (at, ft).
Most of the other filtercomponents form a sub-network that annotatesturns with applicable semantic categories,accumulates them to identify inactive students andgenerates events that regulate the controllers.The plan controller (fplan) is responsible forexecuting the agent?s interaction plan, which iscomprised of 37 steps.
The plan is executed largelysequentially; however the plan controller canchoose to skip some steps in the interest of time.
Inthe experiment described in section 5, the sameplan controller is used in all three conditions.
Thesocial controller (fsocial) implements the 12strategies listed earlier.
The strategies are triggeredby rules based on combinations of threeconditions: the last executed plan step, semanticcategories associated with the most recent studentturns and the ratio of tutor turns generated by fsocialto fplan.
The first two conditions attempt to ensurethat social behavior is suitable in the currentconversational context and the third conditionregulates the amount of social behavior by the CA.The plan and social controllers are connected sothat they regulate each other.
For instance, whenthe plan controller is working, it blocks fsocial.
Uponcompletion of the blocking step, fsocial is givencontrol, which can then choose to perform astrategy by blocking fplan before it progresses to thenext step.
Reflex strategies like 1b are not blocked.Once the controllers determine a step or a strat-egy that is to be generated, the actors generate theirturns.
For example, strategy 1a is generated by ac-tor ai after it is triggered by the social controller.We note that Basilica provides the flexibility tobuild complicated pipelines, as demonstrated inthis case by the use of two controllers.6784 Related WorkTo contextualize our research with other work onCAs, we classify agents with the social interactionstrategies listed in Table 1 as social interfaces fol-lowing the taxonomy proposed by Isbister (2002).Within this class of CAs, researchers have investi-gated the technical challenges and effects of con-versational behavior that are similar in motivationto the ones we are exploring.
Bickmore et.
al.
(2009) report that users found agents with autobio-graphies, i.e., back stories in first person more en-joyable and they completed more conversationswith such agents.
Dybala et.
al.
(2009) found thatagents equipped with humor were evaluated asmore human-like, funny and likeable.
In a multi-party conversational scenario, Dohsaka et.
al.
(2009) found that an agent?s use of emphatic ex-pressions improved user satisfaction and user rat-ing of the agent.
We note that use of CAs as socialinterfaces has been found to have effects on bothperformance and perception metrics.5 Experimental DesignIn order to evaluate the effect of social interactionstrategies listed in Table 1, we designed an expe-riment with three conditions.
In the experimentalcondition (Social), students interacted with anagent that was equipped with our social interactionstrategies, unlike the control condition (Task).
Inthe third condition, a human tutor was allowed tointervene while the students interacted with a Taskagent.
In all three conditions, students go throughthe same task plan.
However, the degree of socialperformance is varied from minimal (Task) to ideal(Human).
We hypothesize that the human and so-cial agents will be rated better than the Task agent.We conducted a between subjects experimentduring a freshmen computer aided engineering lab.98 students participated in the experiment, whichwas held over six sessions spread evenly betweentwo days.
The two days of the experiment wereseparated by two weeks.
Students were groupedinto teams of three to four individuals.
Studentswere grouped so that no two members of the sameteam sat next to each other during the lab, to en-sure all communication was recorded.
The teamswere distributed between the three conditions.Each session started with a follow-along tutori-al of computer-aided analysis where the studentsanalyzed a wrench they had designed earlier.
Theexperimental manipulation happened during a col-laborative design competition after the tutorial.Students were asked to work as a team to design abetter wrench considering three aspects: ease ofuse, cost and safety.
Students were instructed tomake three new designs and calculate successmeasures of each of the three considerations.
Theywere also told that a tutor will help them with twodesigns so that they are well-prepared to do thefinal design.
No additional details about the tutorwere given.
The students communicated with eachother and with the tutors using ConcertChat, an on-line environment that provides text-based instantmessaging and workspace sharing facilities.After spending 30-35 minutes on the designcompetition, each student filled out a question-naire.
It was comprised of eighteen questions on aseven point Likert-scale ranging from StronglyDisagree (1) to Strongly Agree (7).
The questionswere designed to elicit four types of ratings.?
Ratings about the tutor?
Ratings about the other team members?
Ratings about the design task?
Ratings about the team functioningThe questions in the first two classes elicitedperceived liking and integration and checkedwhether the students noticed the tutor?s display ofthe social interaction strategies.
Task related ques-tions asked about satisfaction, perceived legitimacyand discussion quality.6 ResultsTable 2 below shows the mean values for ques-tionnaire categories apart from ratings about teammembers, since there were no significant effectsrelated to those questions.D1 D2  T S HIntegration 3.85 3.94 3.03 3.94 4.77Liking 3.68 3.63 2.78 3.53 4.73Friendly 5.13 5.43 4.47 5.56 5.83T.Releasing 4.49 4.63 3.84 4.61 5.27Agreeing 4.30 4.45 3.97 4.44 4.73Satisfaction 4.66 5.77 5.09 4.75 5.97Table 2.
Mean outcomes per condition ((T)ask,(S)ocial,(H)uman) and per day (Day1, and Day2)The means are highlighted appropriately(p<0.001, p<0.05, p<0.08) to indicate significant679differences from Day1 to Day2 and between theTask condition and each of the other two using apairwise Tukey comparison.First of all, we note that there is a significantdifference in task satisfaction between the twodays.
We fine-tuned the timing parameters of theplan controller after day 1 so that the students hadsufficient time to follow along with each of thesteps.
This was particularly useful for the task con-dition where the steps would be executed rapidlydue to lack of regulation by the social controller.On the right side of Table 2, we notice that thehuman tutors (H) were rated higher on being partof the team (Integration), being more liked, beingfriendlier and keeping the group more sociallycomfortable (T.Releasing).
On the other hand, thesocial tutors (S) were rated to be friendlier andwere only marginally better at being seen as part ofthe team.Strategy Social HumanIntroducing 1a 2.67 3.80Friendly 1b-1e 5.61 8.10Concluding 1f 0.97 1.80T.Releasing 2a-2c 5.81 1.77Agreeing 3a-3b 1.78 4.90Sum  16.83 22.17Table 3.
Mean counts of social turns by tutorNote that human tutors were restricted to exhi-bit only social behaviors, which were displayed inaddition to the same task related content given tostudents in the other two conditions.
Clearly, thehuman tutors were better at employing the socialinteraction strategies.
To further investigate this,we compare the number of turns corresponding tothe broad categories of strategies in Table 3.
Hu-man tutors performed significantly more (p<0.001)social turns than the automated tutors in all strate-gies except showing tension release.7 ConclusionsIn order to make CAs that can participate in multi-party conversational scenarios, the agents must beable to employ Social Interaction Strategies.
Herewe have shown that the human tutors that use thesestrategies are better integrated into the group, andare considered more likeable and friendlier.
Thesetutors also cover more steps and concepts and takeless time to tutor the concepts, suggesting that thestudents are more engaged and responsive to them.On the other hand, automated tutors that employthese strategies in our current implementation donot show significant differences compared to tasktutor.We note a contrast between the performance ofthe human and the automated tutors with respect tothe frequency with which they employ these strat-egies.
Besides the frequent use of these strategies,we believe human tutors were better at identifyingopportunities for employing these strategies, andthey are able to customize the prompt to better suitthe discourse context.AcknowledgmentsThe research was supported by NSF grant numberDUE 837661ReferencesElizabeth Arnott, Peter Hastings and David Allbritton,2008, Research Methods Tutor: Evaluation of a di-alogue-based tutoring system in the classroom, Beha-vior Research Methods, 40 (3), 694-698Robert F. Bales, 1950, Interaction process analysis: Amethod for the study of small groups, Addison-Wesley, Cambridge, MATimothy Bickmore, Daniel Schulman and LangxuanYin, Engagement vs. Deceit: Virtual Humans withHuman Autobiographies, 2009, IVA, AmsterdamKohji Dohsaka, Ryoto Asai, Ryichiro Higashinaka, Ya-suhiro Minami and Eisaku Maeda, Effects of Con-versational Agents on Human Communication inThough Evoking Multi-Party dialogues, 2009, 10thAnnual SigDial, London, UKPawel Dybala, Michal Ptaszynski, Rafal Rzepka andKenji Araki, Humoroids: Conversational Agents thatinduce positive emotions with humor, 2009, AAMAS,Budapest, HungaryArthur C. Graesser, Patrick Chipman, Brian C. Haynes,and Andrew Olney, 2005, AutoTutor: An IntelligentTutoring System with Mixed-initiative Dialogue,IEEE Transactions in Education, 48, 612-618Katherine Isbister and Patrick Doyle, Design and Evalu-ation of Embodied Conversational Agents: A Pro-posed Taxonomy, 2002, AAMAS Workshop:Embodied Conversational Agents, Bologna, ItalyRohit Kumar, Carolyn Ros?, Mahesh Joshi, Yi-ChiaWang, Yue Cui and Allen Robinson, Tutorial Dialo-gue as Adaptive Collaborative Learning Support,13th AIED 2007, Los Angeles, CaliforniaRohit Kumar, Carolyn Ros?, Building ConversationalAgents with Basilica, 2009, NAACL, Boulder, CO680
