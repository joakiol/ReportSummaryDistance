Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 130?134,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsSMT and SPE Machine Translation Systems for WMT?09Holger Schwenk and Sadaf Abdul-Rauf and Lo?
?c BarraultLIUM, University of Le Mans72085 Le Mans cedex 9, FRANCEschwenk,abdul,barrault@lium.univ-lemans.frJean SenellartSYSTRAN SA92044 Paris La De?fense cedex, FRANCEsenellart@systran.frAbstractThis paper describes the development ofseveral machine translation systems forthe 2009 WMT shared task evaluation.We only consider the translation betweenFrench and English.
We describe a sta-tistical system based on the Moses de-coder and a statistical post-editing sys-tem using SYSTRAN?s rule-based system.We also investigated techniques to auto-matically extract additional bilingual textsfrom comparable corpora.1 IntroductionThis paper describes the machine translation sys-tems developed by the Computer Science labo-ratory at the University of Le Mans (LIUM) forthe 2009 WMT shared task evaluation.
This workwas performed in cooperation with the companySYSTRAN.
We only consider the translation be-tween French and English (in both directions).The main differences to the previous year?s system(Schwenk et al, 2008) are as follows: better us-age of SYSTRAN?s bilingual dictionary in the sta-tistical system, less bilingual training data, addi-tional language model training data (news-train08as distributed by the organizers), usage of com-parable corpora to improve the translation model,and development of a statistical post-editing sys-tem (SPE).
These different components are de-scribed in the following.2 Used ResourcesIn the frame work of the 2009 WMT shared trans-lation task many resources were made available.The following sections describe how they wereused to train the translation and language modelsof the systems.2.1 Bilingual dataThe latest version of the French/English Europarland news-commentary corpus were used.
We re-alized that the first corpus contains parts with for-eign languages.
About 1200 such lines were ex-cluded.1 Additional bilingual corpora were avail-able, namely the Canadian Hansard corpus (about68M English words) and an UN corpus (about198M English words).
In several initial exper-iments, we found no evidence that adding thisdata improves the overall system and they werenot used in the final system, in order to keepthe phrase-table small.
We also performed ex-periments with the provided so-called bilingualFrench/English Gigaword corpus (575M Englishwords in release 3).
Again, we were not ableto achieve any improvement by adding this datato the training material of the translation model.These findings are somehow surprising since itwas eventually believed by the community thatadding large amounts of bitexts should improvethe translation model, as it is usually observed forthe language model (Brants et al, 2007).In addition to these human generated bitexts,we also integrated a high quality bilingual dictio-nary from SYSTRAN.
The entries of the dictio-nary were directly added to the bitexts.
This tech-nique has the potential advantage that the dictio-nary words could improve the alignments of thesewords when they also appear in the other bitexts.However, it is not guaranteed that multi-word ex-pressions will be correctly aligned by GIZA++and that only meaningful translations will actuallyappear in the phrase-table.
A typical example isfire engine ?
camion de pompiers, for which theindividual constituent words are not good trans-lations of each other.
The use of a dictionary toimprove an SMT system was also investigated by1Lines 580934?581316 and 599839?600662.130ENSMTFRused as queriesper day articlescandidate sentence pairs parallelsentences+?5 day articlesfrom English GigawordEnglishtranslations GigawordFrench174M words133M wordstailremovalsentences withextra words at ends+9.3M wordsparallelnumber / tablecomparisonlengthremovingWER10.3M wordsFigure 1: Architecture of the parallel sentence extraction system (Rauf and Schwenk, 2009).
(Brown et al, 1993).In comparison to our previous work (Schwenket al, 2008), we also included all verbs in theFrench subjonctif and passe?
simple tense.
In fact,those tenses seem to be frequently used in newsmaterial.
In total about 10,000 verbs, 1,500 adjec-tives/adverbs and more than 100,000 noun formswere added.2.2 Use of Comparable corporaAvailable human translated bitexts such as the UNand the Hansard corpus seem to be out-of domainfor this task, as mentioned above.
Therefore, weinvestigated a new method to automatically extractand align parallel sentences from comparable in-domain corpora.
In this work we used the AFPnews texts since there are available in the Frenchand English LDC Gigaword corpora.The general architecture of our parallel sentenceextraction system is shown in figure 1.
We firsttranslate 174M words from French into Englishusing an SMT system.
These English sentencesare then used to search for translations in the En-glish AFP texts of the Gigaword corpus using in-formation retrieval techniques.
The Lemur toolkit(Ogilvie and Callan, 2001) was used for this pur-pose.
Search was limited to a window of ?5 daysof the date of the French news text.
The retrievedcandidate sentences were then filtered using theword error rate with respect to the automatic trans-lations.
In this study, sentences with an error ratebelow 32% were kept.
Sentences with a largelength difference (French versus English) or con-taining a large fraction of numbers were also dis-carded.
By these means, about 9M words of ad-ditional bitexts were obtained.
An improved ver-sion of this algorithm using TER instead of theword error rate is described in detail in (Rauf andSchwenk, 2009).2.3 Monolingual dataThe French and English target language modelswere trained on all provided monolingual data.
Werealized that the news-train08 corpora containedsome foreign texts, in particular in German.
Wetried to filter those lines using simple regular ex-pressions.
We also discarded lines with a largefraction of numerical expressions.
In addition,LDC?s Gigaword collection, the Hansard corpusand the UN corpus were used for both languages.Finally, about 30M words crawled from the WEBwere used for the French LM.
All this data pre-dated the evaluation period.2.4 Development dataAll development was done on news-dev2009a andnews-dev2009b was used as internal test set.
Thedefault Moses tokenization was used.
All ourmodels are case sensitive and include punctuation.The BLEU scores reported in this paper were cal-culated with the NIST tool and are case sensitive.3 Language ModelingLanguage modeling plays an important role inSMT systems.
4-gram back-off language models(LM) were used in all our systems.
The word listcontains all the words of the bitext used to trainthe translation model and all words that appear atleast ten times in the news-train08 corpus.
Sep-arate LMs were build on each data source withthe SRI LM toolkit (Stolcke, 2002) and then lin-early interpolated, optimizing the coefficients withan EM procedure.
The perplexities of these LMs131Corpus # Fr words Dev09a Dev09b Test09SMT systemEparl+NC 46.5M 22.44 22.38 25.60Eparl+NC+dict 48.5M 22.60 22.55 26.01Eparl+NC+dict+AFP 57.8M 22.82 22.63?
26.18SPE systemSYSTRAN - 17.76 18.13 19.98Eparl+NC 45.5M 22.84 22.59# 25.59Eparl+NC+AFP 54.4M 22.72 21.96 25.40Table 1: Case sensitive NIST BLEU scores for the French-English systems.
?NC?
denotes the news-commentary bitexts, ?dict?
SYSTRAN?s bilingual dictionary and ?AFP?
the automatically aligned newstexts (?=primary, #=contrastive system)are given in Table 2.
Adding the new news-train08monolingual data had an important impact on thequality of the LM, even when the Gigaword datais already included.Data French EnglishVocabulary size 407k 299kEparl+news 248.8 416.7+ LDC Gigaword 142.2 194.9+ Hansard and UN 137.5 187.5news-train08 alone 165.0 245.9all 120.6 174.8Table 2: Perplexities on the development data ofvarious language models.4 Architecture of the SMT systemThe goal of statistical machine translation (SMT)is to produce a target sentence e from a sourcesentence f .
It is today common practice to usephrases as translation units (Koehn et al, 2003;Och and Ney, 2003) and a log linear framework inorder to introduce several models explaining thetranslation process:e?
= arg max p(e|f)= arg maxe{exp(?i?ihi(e, f))} (1)The feature functions hi are the system modelsand the ?i weights are typically optimized to max-imize a scoring function on a development set(Och and Ney, 2002).
In our system fourteenfeatures functions were used, namely phrase andlexical translation probabilities in both directions,seven features for the lexicalized distortion model,a word and a phrase penalty and a target languagemodel (LM).The system is based on the Moses SMT toolkit(Koehn et al, 2007) and constructed as follows.First, word alignments in both directions are cal-culated.
We used a multi-threaded version of theGIZA++ tool (Gao and Vogel, 2008).2 This speedsup the process and corrects an error of GIZA++that can appear with rare words.
This previouslycaused problems when adding the entries of thebilingual dictionary to the bitexts.Phrases and lexical reorderings are extracted us-ing the default settings of the Moses toolkit.
Theparameters of Moses are tuned on news-dev2009a,using the cmert tool.
The basic architecture ofthe system is identical to the one used in the2008 WMT evaluation (Schwenk et al, 2008),but we did not use two pass decoding and n-bestlist rescoring with a continuous space languagemodel.The results of the SMT systems are summarizedin the upper part of Table 1 and 3.
The dictionaryand the additional automatically produced AFP bi-texts achieved small improvements when translat-ing from French to English.
In the opposite trans-lation direction, the systems that include the addi-tional AFP texts exhibit a bad generalisation be-havior.
We provide also the performance of thedifferent systems on the official test set, calculatedafter the evaluation.
In most of the cases, the ob-served improvements carry over on the test set.5 Architecture of the SPE systemDuring the last years statistical post-editing sys-tems have shown to achieve very competitive per-formance (Simard et al, 2007; Dugast et al,2007).
The main idea of this techniques is to use2The source is available at http://www.cs.cmu.edu/?qing/132Corpus # En words Dev09a Dev09b Test09SMT systemEparl+NC 41.6M 21.89 21.78 23.80Eparl+NC+dict 44.0M 22.28 22.35# 24.13Eparl+NC+dict+AFP 51.7M 22.21 21.43 23.88SPE systemSYSTRAN - 18.68 18.84 20.29Eparl+NC 44.2M 23.03 23.15 24.36Eparl+NC+AFP 53.3M 22.95 23.15?
24.62Table 3: Case sensitive NIST BLEU scores for the English-French systems.
?NC?
denotes the news-commentary bitexts, ?dict?
denotes SYSTRAN?s bilingual dictionary and ?AFP?
the automaticallyaligned news texts (?=primary, #=contrastive system)an SMT system to correct the errors of a rule-based translation system.
In this work, SYSTRANserver version 6, followed by an SMT systembased on Moses were used.
The post-editing sys-tems uses exactly the same language models thanthe above described stand-alone SMT systems.The translation model was trained on the Europarl,the news-commentary and the extracted AFP bi-texts.
The results of these SPE systems are sum-marized in the lower part of Table 1 and 3.
SYS-TRAN?s rule-based system alone already achievesremarkable BLEU scores although it was not op-timized or adapted to this task.
This could be sig-nificantly improved using statistical post-editing.The additional AFP texts were not useful whentranslating form French to English, but helped toimprove the generalisation behavior for the En-glish/French systems.When translating from English to French (Ta-ble 3), the SPE system is clearly better than thecarefully optimized SMT system.
Consequently,it was submitted as primary system and the SMTsystem as contrastive one.6 Conclusion and discussionWe described the development of two comple-mentary machine translation systems for the 2009WMT shared translation task: an SMT and an SPEsystem.
The last one is based on SYSTRAN?srule-based system.
Interesting findings of this re-search include the fact that the SPE system out-performs the SMT system when translating intoFrench.
This system has also obtained the bestscores in the human evaluation.With respect to the SMT system, we werenot able to improve the translation model byadding large amounts of bitexts, although differentsources were available (Canadian Hansard, UNor WEB data).
Eventually these corpora are toonoisy or out-of-domain.
On the other hand, theintegration of a high quality bilingual dictionarywas helpful, as well as the automatic alignment ofnews texts from comparable corpora.Future work will concentrate on the integrationof previously successful techniques, in particu-lar continuous space language models and lightly-supervised training (Schwenk, 2008).
We also be-lieve that the tokenization could be improved, inparticular for the French sources texts.
Numbers,dates and other numerical expressions could betranslated by a rule-based system.System combination has recently shown to pro-vide important improvements of translation qual-ity.
We are currently working on a combination ofthe SMT and SPE system.
It may be also interest-ing to add a third (hierarchical) MT system.7 AcknowledgmentsThis work has been partially funded by the FrenchGovernment under the project INSTAR (ANRJCJC06 143038) and the by the Higher EducationCommission, Pakistan through the HEC OverseasScholarship 2005.133ReferencesThorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large language mod-els in machine translation.
In EMNLP, pages 858?867.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, Meredith J. Goldsmith, Jan Hajic,Robert L. Mercer, and Surya Mohanty.
1993.
Butdictionaries are data too.
In Proceedings of theworkshop on Human Language Technology, pages202?205, Princeton, New Jersey.Lo?
?c Dugast, Jean Senellart, and Philipp Koehn.
2007.Statistical post-editing on SYSTRAN?s rule-basedtranslation system.
In Second Workshop on SMT,pages 179?182.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for Natu-ral Language Processing, pages 49?57, Columbus,Ohio, June.
Association for Computational Linguis-tics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn et al 2007.
Moses: Open source toolkitfor statistical machine translation.
In ACL, demon-stration session.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for sta-tistical machine translation.
In ACL, pages 295?302.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignementmodels.
Computational Linguistics, 29(1):19?51.Paul Ogilvie and Jamie Callan.
2001.
Experimentsusing the Lemur toolkit.
In In Proceedings of theTenth Text Retrieval Conference (TREC-10), pages103?108.Sadaf Abdul Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In EACL, page to be published.Holger Schwenk, Jean-Baptiste Fouet, and Jean Senel-lart.
2008.
First steps towards a general purposeFrench/English statistical machine translation sys-tem.
In Third Workshop on SMT, pages 119?122.Holger Schwenk.
2008.
Investigations on large-scale lightly-supervised training for statistical ma-chine translation.
In IWSLT, pages 182?189.Michel Simard, Nicola Ueffing, Pierre Isabelle, andRoland Kuhn.
2007.
Rule-based translation withstatistical phrase-based post-editing.
In SecondWorkshop on SMT, pages 203?206.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In ICSLP, pages II: 901?904.134
