Session 10: Large Vocabulary CSRGeorge R. Doddington, chairmanSRI InternationalMenlo Park, CAOVERVIEWThis session comprised four papers on various topics inspeech recognition, followed by a general discussion.
Thefirst two papers covered computational search techniques,while the last two papers addressed phonetic modelingissues.The first paper, "Rapid Match Training for Large Vocabu-laries", was presented by Larry Gillick of Dragon Systems.This paper described an improved algorithm for buildingrapid match models for computational efficiency in contin-uous speech recognition.
The technique, designed toaccommodate variation in model parameters and phoneduration, was demonstrated to provide significant improve-ment in the miss rate for the correct word.
The miss rateremains relatively high however, about 5 percent for a listlength of 250 words and a vocabulary size of 5000 words.During the discussion on this paper, a question was raisedregarding the use of a language model in the rapid match.The answer was that, yes, a unigram word probability wasused.The second paper, "An A* Algorithm for Very LargeVocabulary Continuous Speech Recognition", was pre-sented by P. Kenny of INRS.
This paper described a newA* stack search algorithm that is only about en times morecomputationally expensive than isolated word recognition.Using a 60,000 word vocabulary, the CPU time required torun a perplexity 700 task was 120 times real time on an HP720 workstation.During the discussion on this paper, a question was raisedregarding the manner in which the search path is extended.The answer explained that he phone ndpoints were knownand were independent ofthe search path.The third paper, "Modeling Spontaneous Speech Effects inLarge Vocabulary Speech Recognition Applications", waspresented by John Butzberger of SRI.
This paper describedan analysis of speech recognition errors on spontaneousspeech and concluded that he increased error rate on spon-taneous peech is attributable todisfluencies and that fluentspontaneous speech exhibits the same recognition perfor-mance as read speech.
It was also concluded that he use ofspontaneous speech in training the recognition system isimportant for best performance.During the discussion on this paper, a question was raisedregarding how 70 percent of all errors could be labeled asdisfluencies.
The answer was that he notion of disfluencyalso comprehended natural phenomena such as vowel elon-gation and spontaneous speech grammatical constructs(low bigram probabilities).327The last paper, "Speaker-Independent Phone RecognitionUsing BREF", was presented by Jean-Luc Gauvain ofLIMSI.
This paper described a series of experiments onspeaker-independent phone recognition using the BREFcorpus of read speech as prompted using the French news-paper Le Monde.
Phone-level performance of31 percenterror was achieved, which is comparable with resultsachieved on the English TIMIT corpus.During the discussion on this paper, a question was raisedregarding the use of a grammar on this task.
The answerwas that a grammar was tried but that he error rate wasvery high.
(The perplexity of the grammar was about 500.
)D ISCUSSIONThe general discussion deviated from the topics covered bythe papers and addressed instead pitfalls and issues relatedto the idiosyncrasies ofspeech corpora nd their impact onspeech recognition results and technology.The SLS ATIS corpus was "attacked" by noting that resultswere a strong function of the identity of the site which sup-plied the data.
The question was raised multiple times ofwhat was the cause of these differences.
Various ourceswere suggested, including consistent differences in speak-ers, differences inthe acoustics and digitizing system, anddifferences inthe task.
Of these three, the last seems mostlikely, with even primitive measures ( uch as the number ofwords per sentence) showing striking differences from siteto site.A general complaint was lodged regarding the imbalanceof training data between sites for the MADCOW corpus,with MIT supplying an inordinate fraction of such data.
Ina mitigating reply to this complaint, itwas noted that heM1T sentences are significantly shorter than sentences fromother sites, and therefore the imbalance (in tenus of theamount of speech data) is not as great as is indicated by thesentence count.One astute comment categorized speech signal variabilityas being of two distinct ypes -- systematic (modelable) andnonsystematic (random).
It was further noted that he sys-tematic variability is not handled properly by HMM tech-nology and must be built into the system as a model of thespeech process.
Nonsystematic variability on the otherhand can only be modeled as noise and the only way tohandle such variation is through training with largeamounts of data.
A plea was made to isolate the systematiceffects and model them explicitly, so that we don't continueto need more and more data.
