Proceedings of the 8th International Natural Language Generation Conference, pages 64?73,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsAdapting Graph Summaries to the Users?
Reading LevelsPriscilla Moraes, Kathleen McCoy and Sandra CarberryDepartment of Computer and Information SciencesUniversity of Delaware, Newark, Delaware, USA[pmoraes | mccoy | carberry]@udel.eduAbstractDeciding on the complexity of a generated textin NLG systems is a contentious task.
Somesystems propose the generation of simple textfor low-skilled readers; some choose whatthey anticipate to be a ?good measure?
ofcomplexity by balancing sentence length andnumber of sentences (using scales such as theD-level sentence complexity) for the text;while others target high-skilled readers.
In thiswork, we discuss an approach that aims to lev-erage the experience of the reader when read-ing generated text by matching the syntacticcomplexity of the generated text to the readinglevel of the surrounding text.
We propose anapproach for sentence aggregation and lexicalchoice that allows generated summaries of linegraphs in multimodal articles available onlineto match the reading level of the text of the ar-ticle in which the graphs appear.
The tech-nique is developed in the context of theSIGHT (Summarizing Information GraphicsTextually) system.
This paper tackles the mi-cro planning phase of sentence generation dis-cussing additionally the steps of lexicalchoice, and pronominalization.1 IntroductionMultimodal documents from online popular me-dia often contain information graphics that aug-ment the information found in the text.
Thesegraphics, however, are inaccessible to blind us-ers.
The SIGHT system is an ongoing projectthat proposes methods of making this infor-mation accessible to visually impaired users bygenerating a textual summary capturing the high-level message of the graphic along with visuallydistinctive features.
Figure 1 shows an exampleof an information graphic found in popular me-dia.
This graphic ostensibly conveys that therewas a change in the trend of ocean levels, whichis first stable until about 1940 and then risingthrough 2003.
Earlier work on the system (Wu,Carberry, Elzer, & Chester, 2010) is able to inferthis high-level message given a representation ofthe graphic.Nevertheless, a generated summary shouldconvey more than just the intended message.
Itshould provide important visual features thatjump out at a person who views the graphic(such as the fluctuation in the data values as seenin the graph in Figure 1).
The set of remarkablefeatures is different for different graphics.
Previ-ous work of ours (Moraes, Carberry, & McCoy,2013) presents methods that capture these mostimportant features and allow the composition ofcustomized summaries for each graph.
Thus,given a graphic, our previous work has resultedin a system that can produce a set of propositionsto include in its summary.
In this paper, we turnto the subsequent phases of generation: given aset of propositions, how these propositionsshould be realized such that the resultant text isadapted to the user?s reading level and thus iscoherent and understandable.Therefore, this work presents novel strategiesthat have been deployed in the text generationphase of the SIGHT system applied to linegraphs.
It describes the micro planning phase,emphasizing sentence aggregation, lexical choiceand pronominalization.
The contribution of thiswork is the provision of coherent and concisetextual summaries that narrate line graphs?
high-level content to visually impaired users throughapproaches that rely on 1) making the rightwording choices and 2) making appropriate syn-tactical decisions in order to achieve a desiredreading level for the generated text.Previous work in generation assumes a partic-ular level of complexity for all texts created.
Ourhypothesis is that the graph?s summary shouldvary depending on the user?s reading level.
Alt-hough one could explicitly inquire about the us-er?s reading level, this would be intrusive and64would detract from the overall experience.
Thuswe hypothesize that the level of complexity ofthe article in which the graph appears roughlyequates with the user?s reading level --- that is,users generally choose articles that are at theirown reading comfort level.
Therefore, our ap-proach is to generate summaries that reflect thereading level of the accompanying article.
Notonly will such summaries be coherent and under-standable to the user, but also the summaryshould fit seamlessly into the user?s reading ofthe article.The decision to match the text complexity ofthe generated text to that of the article?s text wasinspired by results of an experiment performedwith college students aiming to evaluate the con-tent determination output.
In the experiment, sen-tences were generated for each proposition se-lected by the system.
Comments made by thesubjects revealed that the simplest possible textwas not easier to understand.
Rather, it causedthem confusion and discomfort when reading it.Based on these results, we decided to tackle theproblem of deciding on the text complexity ofautomatically generated text by following thesame syntactical complexity of the surroundingtext, by reading level.
In addition, we use wordfrequencies to select more common lexical itemsto compose summaries of lower reading levels.The next section presents the background andmotivation for our work.
Section 3 discussessome related work concerned with text genera-tion and simplification.
Section 4 presents ourproposed approach to text generation that adaptsthe output to the reading level of the surroundingtext.
Section 5 shows some examples of textgenerated in different grade level groups.
Section6 shows our preliminary evaluation and it is fol-lowed by some conclusions and ideas for futurework in Section 7 and 8, respectively.2 BackgroundThe approaches presented in this work are de-ployed in the context of the SIGHT system.
Thesystem is concerned with providing access toinformation graphics present in multimodal doc-uments from popular media such as the graphicin Figure 1.
For this graphic, the content selec-tion module1 (Moraes et al., 2013) chooses thefollowing propositions for inclusion in the initialsummary:?
graph type (line graph);1 The content selection module has been presented in a pre-vious paper and is outside the scope of this paper.?
entity being measured (annual differencefrom Seattle's 1899 sea level, in inches);?
the intended message of the graphic(changing trend: stable then rising);?
the high fluctuation of the data values;?
the description of the individual seg-ments of the graphic;?
the initial value (annotated end point);?
the ending value (annotated end point).Figure 1: Example of a graphic that has a Chang-ing Trend as its intended message and presentsout-standing visual features (volatility and anno-tations on end points).These propositions are not necessarily selectedin this listed order, nor in the order they will bementioned in the summary.
They are selectedbased on their overall importance in the contextof the graphic since the content selection frame-work is based on an adapted version of a cen-trality-based algorithm.
Once these propositionsare selected, an overarching organizational strat-egy must be chosen to decide on the most appro-priate ordering.
Our system gives most im-portance to the overall intended message of thegraphic and thus this will be mentioned first.Next, a description of the features of the individ-ual trend(s) will be provided.
Finally, summaryinformation about the whole graph will be given.The system must make further decisions whenthe graph conveys more than one trend (such asthe graph in Figure 1).
For such cases, the systemmust further decide whether to organize the de-scription of the trends (1) by the trends them-selves ?
e.g.
either in left to right order - when notrend is considered more important than the oth-ers; or (2) by importance ?
when a trend has a65greater set of features selected for the discourseor it composes a candidate intended message,which augments the intended message (Moraeset al., 2013).
In the latter case, if a piece of thegraphic (trend) has significantly more featuresselected, meaning that it possesses a higher num-ber of visually outstanding features, it will bedescribed first, then followed by the other trends.The organization of the sentences is a separatestep that happens prior to the realization phase,which is the focus here, and will not be discussedfurther in this paper.Having the set of ordered propositions select-ed, the question that arises is how to realize thisinformation to the user.
The most straightforwardway of realizing the summary would be to realizeeach proposition as a single sentence.
This strat-egy was applied in an evaluation experiment(briefly described next) that aimed to test thepreciseness of the content selection framework.The experiment presented the subjects with linegraphs and their correspondent generated initialsummaries (the propositions were properly or-dered for this experiment).
Subjects were askedwhether or not the most important informationabout the graphic was part of the summary andwhether the summary presented unnecessary orredundant information.
They were also offeredthe opportunity to provide additional comments.For the experiment, the initial summary for thegraphic in Figure 1 was the following:The image shows a linegraph.
The line graph ishighly volatile.
The linegraph presents the number ofannual difference from Seat-tle's 1899 sea level, ininches.
The line graph showsa trend that changes.
Thechanging trend consists of astable trend from 1900 to1928 followed by a risingtrend through 2003.
Thefirst segment is the stabletrend.
The stable trend hasa starting value of 1.97inches.
The second segmentis the rising trend.
Therising trend has an endingvalue of 8.9 inches.Although the experiment was intended to evalu-ate the content present in the summaries, variouscomments addressed the syntactical constructionof the text.
These comments highlighted the lackof aggregation and pronominalization.
For in-stance, a common theme of the comments wasthat some of the information could be ?com-bined?
and presented more succinctly.All the participants of the experiment weregraduate students.
These results showed thatmore sophisticated readers prefer text that ismore sophisticated.
This finding pointed to thenecessity of an aggregation step before the deliv-ery of the summaries.
However, questions aroseconcerning how much aggregation to do, how tomeasure aggregation to choose one strategy overanother, or to decide on a desired level of aggre-gation.To answer the above questions, we decided toexamine the text complexity of the text surround-ing the graphic --- that is, the text from the articlein which the graph appears.
We presume that thistext complexity equates with the user?s readinglevel and thus summaries at this level of com-plexity will be understandable and coherent tothe users.
This approach seemed to be the bestway of customizing the text complexity of thesummaries in order to tailor summaries to indi-vidual users.3 Related WorkResearch on generating text concerned with low-skilled users has been conducted by (Williams &Reiter, 2004, 2005a, 2005b, 2008; Williams,Reiter, & Osman, 2003).
As stated by (Williams& Reiter, 2005b), most NLG systems generatetext for readers with good reading ability.
Thus,they developed a system called SkillSum whichadapts its output for readers with poor literacyafter assessing their reading and numeracy skills.Their results show that, for these target readers,the micro planning choices made by SkillSumenhanced readability.
(Siddharthan, 2003) pro-poses a regeneration phase for syntactical textsimplification in order to preserve discoursestructure ?aiming to make the text easier to readfor some target group (like aphasics and peoplewith low reading ages) or easier to process bysome program (like a parser or machine transla-tion system).
(J. Carroll et al., 1999) presents atext simplification methodology to help lan-guage-impaired users.
(Rello & Baeza-Yates,2012) investigates dyslexic errors on the Weband (Rello, Baeza-Yates, Bott, & Saggion, 2013)propose a system that uses lexical simplificationto enhance readability and understandability oftext for people with dyslexia.
They help users tounderstand the text by offering as options thereplacement of more complicated lexical items66by simpler vocabulary.
They performed experi-ments with people with no visual impairmentsand with people with dyslexia and concluded thatthe system improved readability for the userswith dyslexia and improved comprehensibilityfor users with no visual impairments.
Experi-ments performed with blind users and the usabil-ity of a system that provides access to charts andgraphs is presented by (Ferres, Lindgaard,Sumegi, & Tsuji, 2013).Other NLG systems make decisions on textcomplexity based on available scales such as theD-level sentence complexity (Covington, He,Brown, Naci, & Brown, 2006).
One example ispresented in (Demir et al., 2010) where treestructures are built representing all the possibleways sentences can be aggregated and the choiceof the tree tries to balance the number of sen-tences, their D-level complexity, and the types ofrelative clauses.Although text simplification is crucial to targetlow-skilled readers and users with language dis-abilities, our experiment with college studentsshowed that the simplest text was rather unpleas-ant to read for them.
We therefore propose atechnique that focuses on adjusting the generatedtext to the reading level of the surrounding text.Thus, our system should satisfy both high-leveland low-level readers.4 Aggregation and Text ComplexityThe initial summaries generated by the systemare composed of individual sentences that wererealized from atomic concept units.
Since we usea bottom-up approach when selecting content, inorder to achieve different text complexity levels,a sentence aggregation step is needed.
The ag-gregation module is in charge of merging propo-sitions that describe an entity, creating a morecomplex sentence that will encompass the infor-mation selected that describes the referring ex-pression.The approach proposed by (Wilkinson, 1995)presents the aggregation process divided in twomajor steps: semantic grouping and sentencestructuring.
Although they are interdependent,both are needed in order to achieve aggregationin a text.
Initiatives on automatic aggregation (oronly semantic grouping) of text using learningtechniques also exist.
(Barzilay, 2006),(Bayyarapu, 2011), (Walker, Rambow, & Rogati,2001) are some examples of learning aggregationrules and grouping constrains in order to aggre-gate text.
(Demir, 2010) presents a mechanism inwhich each proposition is a single node treewhich can be realized as a sentence and attemptsto form more complex trees by combining treesin such a way so that the more complex tree(containing multiple propositions) can still berealized as a single sentence.
In order to decidewhich tree is the best one to be realized, Demir?swork applies the revised D-level sentence com-plexity scale, which measures the syntactic com-plexity of a sentence according to its syntacticstructure.Although learning methodologies are innova-tive, they strive to train the algorithms in order tochoose the best text plan based in a specific taskor environment (defined by the training data andthe decision of which plan is the ?best?
given thehuman subjects?
judgments).
Our contention isthat a given sentence plan can be perfectly suita-ble in one context and, at the same time, be inef-fective in another one, making the choice of thebest text plan a variable.
For this reason, we de-cided to take into consideration the article read-ing level when choosing the text plan that will beused to design the aggregation of summariesgenerated by our system.
This approach allowsthe summary of the line graph to fit coherentlywithin the article?s text.
Text plans, in the con-text of this work, refer to the different set of rulesthat are followed in order to aggregate proposi-tions before the realization phase.
Each text plandecides how propositions related to a given enti-ty should be combined in order to produce sen-tences.4.1 Reading Level AssessmentMuch effort has been devoted to developing au-tomated approaches for assessing text complexi-ty.
Some examples are the use of support vectormachines (Schwarm & Ostendorf, 2005) in orderto find topical texts at a given reading level.
An-other approach is the use of statistical languagemodels (Collins-Thompson & Callan, 2005;Collins-Thompson & Callan, 2004) for predict-ing reading difficulty.
The combination of vo-cabulary and grammatical features in order topredict reading difficulty for first and secondlanguage texts is the object of study in (Heilman,Collins-Thompson, Callan, & Eskenazi, 2007).
(Sheehan, Kostin, Futagi, & Flor, 2010) de-veloped a system called SourceRater (nownamed TextEvaluator), which considers featuresof text that go beyond syntactical features.
Theauthors list a set of dimensions of text that influ-ences in a text reading complexity.
These dimen-sions are: Spoken vs.
Written Language, Aca-67demic Orientation, Syntactic Complexity, Narra-tive Style, Overt Expression of Persuasion, Vo-cabulary Difficulty, and Negation.
They dividetexts into literary and informational in order toassess these features and their impact in readingdifficulty after finding that these styles have sub-stantial differences.
They evaluate their tech-nique by comparing their results with assess-ments done using Flesh-Kincaid reading levelassessment (Kincaid, Fishburne, Rogers, &Chissom, 1975) applied to text categorized intograde levels by the Common Core Standards("Common Core State Standards Initiative,"2014).Another tool, Coh-Metrix (Graesser et al.,2004), was designed to analyze text on measuresof cohesion, language and readability.
This eval-uator also categorizes the input text into one ofScientific, Narrative or Informational and it con-siders features such as cohesion relations, userworld knowledge, language, and discourse char-acteristics besides syntactical features such asword and sentence length when assessing the textcomplexity.To generate text that complies with a givenreading level, we consider that a common, well-know, widely-used metric such as Flesch-Kincaid or SMOG (Laughlin, 1969) will sufficefor providing input to the text planning phase ofour system.
To assure the usefulness of this met-ric in our context, we evaluated the similaritybetween assessments done by Flesch-Kincaidand SMOG and assessments made by TextEvalu-ator.
For this comparison, we used 55 articlesfrom our corpus2.
The results showed that foronly 20 percent of the articles was the readinglevel assessment provided by Flesch-Kincaid andSMOG different from the text complexity classi-fication done by TextEvaluator.
From these re-sults, we concluded that simple reading assess-ments such as Flesch-Kincaid and SMOG wouldsuffice for guiding the choice of syntactical textcomplexity in our generated summaries.4.2 Generating Summaries for DifferentReading LevelsWhen generating the initial summaries of linegraphs, our system creates different text plans foreach group of grade levels (each group compris-es two or more grade levels starting at the 5thgrade) and applies the appropriate one depending2 Our Digital Library contains multimodal articles collectedfrom popular media.
It is available athttp://ir.cis.udel.edu/~moraes/udgraphsupon the assessed reading level of the text in thearticle containing the graphic.Because the summary is not long enough to beexact when determining its reading level (sincelonger texts result in more accurate assessmentof their reading level), we decided not to createone text plan for each grade level.
Instead, wehave created five grade level groups and eachone comprises two or more grades.
For eachgroup of grade levels, we define a text plan thatincreases a sentence syntactic structure complex-ity as the grade gets higher.
We define a text planfor summaries that can range between grades 5(inclusive) and 7 (exclusive), another text planfor grades between 7 (inclusive) and 9 (excusive).A third text plan is defined for grades 9 inclusiveand 11 (exclusive), one for 11 (inclusive) and 13(exclusive) and, finally, another one for gradesgreater than or equal to 13 (college level).The content selection framework, as men-tioned earlier, defines the content of a givensummary dynamically.
Due to this fact, theamount of information (or the number of propo-sitions) selected for inclusion in a summary var-ies per graphic.
Our intention is to make sure thatthe reading level of the summaries generated byour system do not exceed the reading level oftheir respective article?s text.
It is admissible,however, for the summary to have a slightlylower reading level than the one from the text.The organization phase, which is a previousstep, divides the set of propositions produced bythe content selection module into three groups: 1)propositions that comprise an introduction con-taining the high-level message of the graphic, 2)propositions that detail the individual trends ofthe graph, and 3) propositions that convey com-putational information about the overall graph.Thus, from the set of selected propositions, thetext plan of a given group defines rules on NounPhrase (NP) density and lexical choice.
Whendescribing an entity, attributes of this entity canbe added to the NP as modifiers using either ad-jectives e.g.
?a steep rising trend?, conjunctionse.g., ?the rising trend is steep and volatile?
orrelative clauses e.g.
?a rising trend, which issteep?.
When the modifier of an NP is a VerbPhrase (VP), it is combined using a relativeclause e.g., ?the line graph, which presents thenumber of jackets sold in 2013...?
VPs can bemodified by adverbs e.g., ?the falling trend isvery steep?.
The text plans applies rules withinsets of propositions that are grouped hierarchical-ly.
Within these major groups, propositions canonly be aggregated if they belong to the same68entity.
The decision of using one syntactic struc-ture over the other is currently based on dis-course strategies.
The complexity added by arelative clause over the one added by an adjec-tive, for example, is the focus of current investi-gation (more details in Section 8) and will beconsidered when choosing one construction overanother.4.3 Lexical ChoiceMost of the work on text simplification and read-ability assessment considers lexicalization a cru-cial aspect for readability and comprehensibility.
(Rello, Baeza-Yates, Bott, & Saggion, 2013) pre-sents a system that increases the understandabil-ity and readability of text by helping users under-stand the text by replacing complex words withmore common ones in the lexicon.
(Laughlin,1969) states that longer and more precise wordsare usually harder to understand.This led us to use more common words atlower grade levels to increase the chance of thetext being easily understood by the reader.
Forthis, we use the Word Frequency Data from theCorpus of Contemporary American English(Davies, 2008).
Precise and specific words(which are less frequently used) that describevisual features of line graphs such as volatilityand steepness are replaced by other words or ex-pressions that are more commonly used but stillcarry the same meaning, such as ?peaks and val-leys?
or ?ups and downs?.
The experiment pre-sented in Section 6 corroborates this claim,showing that college level students were com-fortable with the use of such lexical items where-as fifth graders complained about them and as-serted they did not know their meanings.
Futurework concerns the use of lexical items catego-rized by reading levels (details in Section 8).4.4 PronominalizationAnother important feature is the pronominaliza-tion of referring expressions.
This techniqueavoids reintroduction of entities every time theyare mentioned.
The experiment mentioned inSection 2 showed that the reintroduction of enti-ties or the repetition of referring expressions(when a pronoun could be used) in fact jeopard-ized the understanding of some passages in thesummaries.
The participants would usually com-plain that a given summary was confusing be-cause it could be ?better presented?
and theywould additionally provide us with commentsregarding the reintroduction of the referring ex-pressions.
From these results, we concluded thatit would be valuable to include a pronominaliza-tion step in the aggregation phase so that eventhe summaries that are at a lower grade levelwould not repeat the referring expression whenusing multiple non aggregated sentences.The propositions chosen by the content selec-tion framework contain the information abouttheir memberships (features such as volatilityand steepness point to the segment of the graphicthey belong to).
This membership information isthe clue used to define discourse focus.
Our workfollows the approach applied in the TEXT sys-tem (McKeown, 1992), in which pronouns areused in order to refer to the entity being focusedin subsequent sentences.
Also inspired by thework presented by (McCoy & Strube, 1999) oursystem makes use of other anaphoric expressionsbesides pronouns, such as ?the trend?
or ?thegraph?.
These alternative anaphoric expressionsare used to reintroduce entities when the dis-course focus changes.
The following exampleshows the use of pronouns and the reintroductionof the entity in the last set of propositions.
Theentities that are in focus in each sentence are un-derlined and the referring expressions are bolded.The image shows a linegraph.
The line graph pre-sents the number of cumula-tive, global unredeemed fre-quent-flier miles.
It con-veys a rising trend from1999 to 2005.
It has astarting value of 5.5.
Ithas an ending value of 14.2.The graph shows an overallincrease of 8.7.The last sentence changes the focus back tothe overall graph.
Even though the entity linegraph was already mentioned, the focus hadchanged to the entity rising trend, so when thefocus returns to the entity line graph, the systemmakes use of a definite reference to reintroduceit.5 Examples of Summaries Generatedfor Different Reading LevelsBelow are examples of some of the summariesthat our system generates for the graph in Figure1 at different reading levels.
Their assessed read-ing levels provided by SMOG are also shown3.The summaries in these examples are also pro-3 These results were obtained from using a tool available inthe GNU project Style and Diction (FSF, 2005).69nominalized.
The pronominalization phase isdescribed in Section 4.4.Summary for Grades > 5 and <= 7The image shows a linegraph.
The line graph hasups and downs.
It presentsthe number of annual differ-ence from Seattle's 1899 sealevel, in inches.
It conveysa changing trend.
It con-sists of a stable trend from1900 to 1928 followed by arising trend through 2003.The first segment is thestable trend.
It has astarting value of 1.97 inch-es.
The second segment isthe rising trend.
It has anending value of 8.9 inches.
(SMOG 4.8)Summary for Grades > 11 and <= 13The image shows a highlyvolatile line graph, whichpresents the number of annu-al difference from Seattle's1899 sea level, in inches,in addition to conveying achanging trend that consistsof a stable trend from 1900to 1928 followed by a risingtrend through 2003.
Thefirst segment is the stabletrend that has starting val-ue of 1.97 inches.
The sec-ond segment is the risingtrend that has ending valueof 8.9 inches.
(SMOG 10.0)The assessed reading level of these passagesare below the maximum threshold due to the lim-ited number of propositions selected by the con-tent determination algorithm.6 EvaluationThis work on aggregation was motivated by theevaluation described in Section 2, which wasintended to evaluate the content selection phaseof the system.
Much to our surprise, many of thecomments indicated that the summaries weredifficult to read because they lacked aggregation!This result caused us to implement the work pre-sented here.
Our first evaluation therefore repli-cated our first experiment where, instead of usinga simple sentence for each proposition, sentenceswere aggregated to reflect a 7th ?
9th grade read-ing level (the level slightly lower than the medi-an of the articles collected for our corpus).Table 1 compares the results of these two ini-tial experiments.
The results4  show a dramaticdrop in the comments related to issues with ag-gregation.
From this preliminary experiment re-sults, we felt encouraged to pursue the generationof summaries suited to grade levels.NumberofSubjectsNumberofResponsesNumberofcomplaintsExperiment1 16 201 22Experiment2 29 331 4Table 1.
Comparison of results from preliminaryexperiment.Our second experiment targeted our genera-tion of grade-level appropriate text.
In this exper-iment, we wished to judge whether readers atdifferent reading levels would prefer texts gener-ated by our system aimed at their reading level.We therefore recruited two groups of partici-pants: (1) students from a fifth grade elementaryschool in the area and (2) undergraduate studentsin an introductory CS course at a university.Participants were presented with 2 summariesfrom each of 5 different graphs.
One of thesummaries was generated to be at a 5th ?
7thgrade reading level and the other at a 11th ?
13thgrade reading level.
The participants were askedto select the summary they liked the best and toprovide comments on what they did not like ineither summary.Table 2 shows the results of this experiment.Five students from 5th grade and thirty-fourfreshmen college students were recruited to par-ticipate.
From these results we can see that, infact, the majority in both groups preferred thegrade-level appropriate summary.
For the fresh-men college students, the fact that the subjectswere almost evenly split on their choices, eventhough they are at the same grade level, was ex-pected.
This shows that reading preferences mayvary even among people from same age/gradelevel.
Since there were subjects who preferredsimple to complex text, we can assume that read-ing skills can vary even within a grade levelgroup.
Our contention is that readers who prefersimple text would read venues that use simpletext structure and syntax.
That is where our ap-4 The number of complaints presented in Table 1 are con-cerned only with syntactical issues.70proach plays an even better role when lookinginto the surrounding text the user is reading.
Fol-lowing this approach, instead of assessing or ask-ing the user which level they are in, gives usmore chances of being successful at producingtext that will be more appropriate to each user.Analyzing the results on the choices of the op-posite summary to their target group, we noticedthat there was an agreement amongst subjectsregarding the type of the graph.
Kids whoshowed a preference for the complex text, forexample, did so only for graphics describing asimple trend, therefore having a small amount ofinformation an making it easy for them to follow.Some college students who chose the simplersummary provided comments that showed to beindependent of the reading level decisions of thesystem.
Some subjects pointed that a defaultconnective applied by the realizer (?in additionto?)
was making the summary complicated toread.
That can actually be the cause of the choicefor the simple summary, and not necessarily theamount of aggregation.
To address this, we con-sider that changing the connective to a morecommon one (e.g.
?and?)
would make the textmore fluid.From these results, we conclude that, indeed,adapting the generated text to the complexity oftext commonly read by a user is a promising pathto follow.
An experiment where we provide thesubjects with the article accompanying the graphand ask them to choose the summary that theybelieve fits the text complexity of the summary isintended and planned as future work.
We haveinitiated investigation in some automated waysof generating text within these different gradelevel groups and we discuss it further in Section8.Chose Sum-maries for 5th ?7th Grades (%)Chose Summar-ies for 11th - 13thGrades (%)5th grade 80 20Freshmenstudents 47 53Table 2.
Results from experiment measuringchoices of summaries in different reading levels.7 ConclusionMost NLG systems available today generatetext that focus on specific target readers.
Some ofthem focus on text generation for low-skilledreaders, while others generate text for high-skilled readers.
In this work, we presented anapproach that offers a solution that attends to theneeds of readers at different grade levels.Our system generates initial summaries of linegraphs available in popular media, so visuallyimpaired users can have access to the high-levelmessage these resources carry.
Our contention isthat users read articles from venues that they feelcomfortable with reading.
Therefore, we assertthat generating summaries that fit the text com-plexity of the overall article leverages the qualityof the generated text.
We showed an approachthat uses Flesch-Kincaid and SMOG reading as-sessments in order to determine the syntacticalcomplexity of the generated text.
From the ex-periments performed, we conclude that pursuingthe generation of natural language text that fitsthe reading level of the surrounding text is prom-ising.8 Path ForwardInvestigation on more automated ways of decid-ing on how to aggregate propositions is the nextstep to take.
Our current aggregation method re-lies on templates for each group.
We anticipatesome techniques to learn how different text con-structions can affect reading measures and thenusing them when choosing an adjective over arelative clause for increasing the NP density anduse of passive voice, for example.
This wouldallow the aggregation phase to be easily appliedto NLG systems in different contexts.Another important point is the choice of lexi-cal items by reading level or age.
We plan oninvestigating how the usage of word frequencyby age/grade level (Carroll, 1972) might helpachieving a more appropriate summary for a giv-en grade level.
Then, the lexical items that arelisted as common to the target grade reading lev-el would be applied in their respective context.Some comments provided on the second ex-periment described in Section 6 were that it wasnot so easy to understand long sentences onwhich values and dates were also present.
Thisaspect deserves investigation on acquiring nu-meracy skills along with reading skills as clues toassess the best text complexity to present.
Re-search that assess numeracy and literacy skills ofusers is presented by (Williams & Reiter, 2008).From the accessibility prospective, an experi-ment with blind users is anticipated.
We intendto evaluate the effect of generating text in differ-ent reading levels for people with visual and/orreading impairments.71ReferencesBarzilay, R. (2006).
Aggregation via set partitioningfor natural language generation.
Paperpresented at the In HLT-NAACL.Bayyarapu, H. S. (2011).
Efficient algorithm forContext Sensitive Aggregation in NaturalLanguage generation.
Paper presented at theRANLP.Carroll, J.
B.
(1972).
A New Word Frequency Book.Elementary English, 49(7), pp.
1070-1074.Collins-Thompson, K., & Callan, J.
(2005).
PredictingReading Difficulty with Statistical LanguageModels.
J.
Am.
Soc.
Inf.
Sci.
Technol.,56(13), 1448-1462.Collins-Thompson, K., & Callan, J. P. (2004).
ALanguage Modeling Approach to PredictingReading Difficulty.
Paper presented at theHLT-NAACL.Common Core State Standards Initiative.
(2014).Retrieved 2014-01-09, fromhttp://www.corestandards.org/Covington, M., He, C., Brown, C., Naci, L., &Brown, J.
(2006).
How Complex is thatSentence?
A Proposed Revision of theRosenberg and Abbeduto D-Level Scale.Paper presented at the Research Report,Artificial Intelligence Center, University ofGeorgia.Davies, M. (2008).
Word frequency data: Corpus ofContemporary American English.Demir, S. (2010).
Sight for visually impaired users:Summarizing information graphics textually.University of Delaware.Demir, S., Oliver, D., Schwartz, E., Elzer, S.,Carberry, S., McCoy, K. F., & Chester, D.(2010).
Interactive SIGHT: textual access tosimple bar charts.
New Rev.
HypermediaMultimedia, 16, 245-279.Ferres, L., Lindgaard, G., Sumegi, L., & Tsuji, B.(2013).
Evaluating a Tool for ImprovingAccessibility to Charts and Graphs.
ACMTrans.
Comput.-Hum.
Interact., 20(5), 28:21-28:32.FSF.
(2005).
Style and Diction GNU project.
fromwww.gnu.org/software/dictionGraesser, A. C., McNamara, D. S., Louwerse, M. M.,Cai, Z., Dempsey, K., Floyd, Y., .
.
.Correspondence, F. Y.
(2004).
Coh-Metrix:Analysis of text on cohesion and language.Paper presented at the M. Louwerse Topicsin Cognitive Science.Heilman, M., Collins-Thompson, K., Callan, J., &Eskenazi, M. (2007).
Combining Lexical andGrammatical Features to ImproveReadability Measures for First and SecondLanguage Texts.
Paper presented at the HLT-NAACL.Kincaid, J. P., Fishburne, R. P., Rogers, R. L., &Chissom, B. S. (1975).
Derivation of NewReadability Formulas (AutomatedReadability Index, Fog Count and FleschReading Ease Formula) for Navy EnlistedPersonnel.Laughlin, G. H. M. (1969).
SMOG Grading-a NewReadability Formula.
Journal of Reading,12(8), pp.
639-646.McCoy, K., & Strube, M. (1999).
GeneratingAnaphoric Expressions: Pronoun or DefiniteDescription?
Paper presented at the ACLWORKSHOP ON DISCOURSE ANDREFERENCE STRUCTURE.McKeown, K. (1992).
Text Generation: CambridgeUniversity Press.Moraes, P. S., Carberry, S., & McCoy, K. (2013).Providing access to the high-level content ofline graphs from online popular media.Paper presented at the Proceedings of the10th International Cross-DisciplinaryConference on Web Accessibility, Rio deJaneiro, Brazil.Rello, L., Baeza-Yates, R., Bott, S., & Saggion, H.(2013).
Simplify or Help?
: TextSimplification Strategies for People withDyslexia.
Paper presented at the Proceedingsof the 10th International Cross-DisciplinaryConference on Web Accessibility, NewYork, NY, USA.Rello, L., & Baeza-Yates, R. A.
(2012).
The presenceof English and Spanish dyslexia in the Web.The New Review of Hypermedia andMultimedia, 18(3), 131-158.Schwarm, S. E., & Ostendorf, M. (2005).
ReadingLevel Assessment Using Support VectorMachines and Statistical Language Models.Paper presented at the Proceedings of the43rd Annual Meeting on Association forComputational Linguistics, Stroudsburg, PA,USA.Sheehan, K. M., Kostin, I., Futagi, Y., & Flor, M.(2010).
Generating automated textcomplexity classifications that are alignedwith targeted text complexity standards.Walker, M. A., Rambow, O., & Rogati, M. (2001).SPoT: a trainable sentence planner.
Paperpresented at the Proceedings of the secondmeeting of the North American Chapter ofthe Association for ComputationalLinguistics on Language technologies,Stroudsburg, PA, USA.Wilkinson, J.
(1995).
Aggregation in NaturalLanguage Generation: Another Look.Williams, S., & Reiter, E. (2008).
Generating basicskills reports for low-skilled readers*.Natural Language Engineering, 14(4), 495-525.Wu, P., Carberry, S., Elzer, S., & Chester, D. (2010).Recognizing the intended message of linegraphs.
Paper presented at the Proceedingsof the 6th international conference on72Diagrammatic representation and inference,Berlin, Heidelberg.73
