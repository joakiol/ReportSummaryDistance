Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 198?207,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSyntax-based Simultaneous Translationthrough Prediction of Unseen Syntactic ConstituentsYusuke Oda Graham Neubig Sakriani Sakti Tomoki Toda Satoshi NakamuraGraduate School of Information ScienceNara Institute of Science and TechnologyTakayamacho, Ikoma, Nara 630-0192, Japan{oda.yusuke.on9, neubig, ssakti, tomoki, s-nakamura}@is.naist.jpAbstractSimultaneous translation is a method toreduce the latency of communicationthrough machine translation (MT) by di-viding the input into short segments be-fore performing translation.
However,short segments pose problems for syntax-based translation methods, as it is diffi-cult to generate accurate parse trees forsub-sentential segments.
In this paper,we perform the first experiments applyingsyntax-based SMT to simultaneous trans-lation, and propose two methods to pre-vent degradations in accuracy: a method topredict unseen syntactic constituents thathelp generate complete parse trees, and amethod that waits for more input when thecurrent utterance is not enough to gener-ate a fluent translation.
Experiments onEnglish-Japanese translation show that theproposed methods allow for improvementsin accuracy, particularly with regards toword order of the target sentences.1 IntroductionSpeech translation is an application of machinetranslation (MT) that converts utterances from thespeaker?s language into the listener?s language.One of the most identifying features of speechtranslation is the fact that it must be performedin real time while the speaker is speaking, andthus it is necessary to split a constant streamof words into translatable segments before start-ing the translation process.
Traditionally, speechtranslation assumes that each segment correspondsto a sentence, and thus performs sentence bound-ary detection before translation (Matusov et al,2006).
However, full sentences can be long, par-ticularly in formal speech such as lectures, andif translation does not start until explicit ends ofFigure 1: Simultaneous translation where thesource sentence is segmented after ?I think?
andtranslated according to (a) the standard method,(b) Grissom II et al (2014)?s method of final verbprediction, and (c) our method of predicting syn-tactic constituents.sentences, listeners may be forced to wait a con-siderable time until receiving the result of trans-lation.
For example, when the speaker continuesto talk for 10 seconds, listeners must wait at least10 seconds to obtain the result of translation.
Thisis the major factor limiting simultaneity in tradi-tional speech translation systems.Simultaneous translation (Section 2) avoids thisproblem by starting to translate before observingthe whole sentence, as shown in Figure 1 (a).However, as translation starts before the wholesentence is observed, translation units are oftennot syntactically or semantically complete, and theperformance may suffer accordingly.
The dele-terious effect of this missing information is lessworrying in largely monotonic language pairs (e.g.English-French), but cannot be discounted in syn-tactically distant language pairs (e.g.
English-Japanese) that often require long-distance reorder-ing beyond translation units.One way to avoid this problem of missing infor-mation is to explicitly predict information needed198Figure 2: Process of English-Japanese simultaneous translation with sentence segmentation.to translate the content accurately.
An ambitiousfirst step in this direction was recently proposedby Grissom II et al (2014), who describe a methodthat predicts sentence-final verbs using reinforce-ment learning (e.g.
Figure 1 (b)).
This approachhas the potential to greatly decrease the delayin translation from verb-final languages to verb-initial languages (such as German-English), but isalso limited to only this particular case.In this paper, we propose a more generalmethod that focuses on a different variety of in-formation: unseen syntactic constituents.
Thismethod is motivated by our desire to apply trans-lation models that use source-side parsing, suchas tree-to-string (T2S) translation (Huang et al,2006) or syntactic pre-ordering (Xia and McCord,2004), which have been shown to greatly improvetranslation accuracy over syntactically divergentlanguage pairs.
However, conventional methodsfor parsing are not directly applicable to the par-tial sentences that arise in simultaneous MT.
Thereason for this, as explained in detail in Section3, is that parsing methods generally assume thatthey are given input that forms a complete syntac-tic phrase.
Looking at the example in Figure 1,after the speaker has spoken the words ?I think?we have a partial sentence that will only be com-plete once we observe the following SBAR.
Ourmethod attempts to predict exactly this informa-tion, as shown in Figure 1 (c), guessing the re-maining syntactic constituents that will allow usto acquire a proper parse tree.Specifically the method consists of two parts:First, we propose a method that trains a statisti-cal model to predict future syntactic constituentsbased on features of the input segment (Section 4).Second, we demonstrate how to apply this syntac-tic prediction to MT, including the proposal of aheuristic method that examines whether a futureconstituent has the potential to cause a reorderingproblem during translation, and wait for more in-put in these cases (Section 5).Based on the proposed method, we perform ex-periments in simultaneous translation of English-Japanese talks (Section 6).
As this is the first workapplying T2S translation to simultaneous MT, wefirst compare T2S to more traditional phrase-basedtechniques.
We find that T2S translation is effec-tive with longer segments, but drops off quicklywith shorter segments, justifying the need for tech-niques to handle translation when full context isnot available.
We then compare the proposedmethod of predicting syntactic constituents, andfind that it improves translation results, particu-larly with respect to word ordering in the outputsentences.2 Simultaneous TranslationIn simultaneous translation, we assume that we aregiven an incoming stream of words f , which weare expected to translate.
As the f is long, wewould like to begin translating before we reach theend of the stream.
Previous methods to do so cangenerally be categorized into incremental decod-ing methods, and sentence segmentation methods.In incremental decoding, each incoming word isfed into the decoder one-by-one, and the decoderupdates the search graph with the new words anddecides whether it should begin translation.
Incre-mental decoding methods have been proposed forphrase-based (Sankaran et al, 2010; Yarmoham-madi et al, 2013; Finch et al, 2014) and hierar-chical phrase-based (Siahbani et al, 2014) SMT199models.1Incremental decoding has the advantageof using information about the decoding graph inthe choice of translation timing, but also requiressignificant changes to the internal workings of thedecoder, precluding the use of standard decodingtools or techniques.Sentence segmentation methods (Figure 2)provide a simpler alternative by first divid-ing f into subsequences of 1 or more words[f(1), .
.
.
,f(N)].
These segments are then trans-lated with a traditional decoder into output se-quences [e(1), .
.
.
, e(N)], which each are output assoon as translation finishes.
Many methods havebeen proposed to perform segmentation, includ-ing the use of prosodic boundaries (F?ugen et al,2007; Bangalore et al, 2012), predicting punc-tuation marks (Rangarajan Sridhar et al, 2013),reordering probabilities of phrases (Fujita et al,2013), or models to explicitly optimize translationaccuracy (Oda et al, 2014).
Previous work oftenassumes that f is a single sentence, and focus onsub-sentential segmentation, an approach we fol-low in this work.Sentence segmentation methods have the obvi-ous advantage of allowing for translation as soonas a segment is decided.
However, the use of theshorter segments also makes it necessary to trans-late while part of the utterance is still unknown.
Asa result, segmenting sentences more aggressivelyoften results in a decrease translation accuracy.This is a problem in phrase-based MT, the frame-work used in the majority of previous research onsimultaneous translation.
However, it is an evenlarger problem when performing translation thatrelies on parsing the input sentence.
We describethe problems caused by parsing a segment f(n),and solutions, in the following section.3 Parsing Incomplete Sentences3.1 Difficulties in Incomplete ParsingIn standard phrase structure parsing, the parser as-sumes that each input string is a complete sen-tence, or at least a complete phrase.
For example,Figure 3 (a) shows the phrase structure of the com-plete sentence ?this is a pen.?
However, in the caseof simultaneous translation, each translation unit1There is also one previous rule-based system that usessyntax in incremental translation, but it is language specificand limited domain (Ryu et al, 2006), and thus difficult tocompare with our SMT-based system.
It also does not predictunseen constituents, relying only on the observed segment.Figure 3: Phrase structures with surrounding syn-tactic constituents.is not necessarily segmented in a way that guar-antees that the translation unit is a complete sen-tence, so each translation unit should be treatednot as a whole, but as a part of a spoken sentence.As a result, the parser input may be an incompletesequence of words (e.g.
?this is,?
?is a?
), and astandard parser will generate an incorrect parse asshown in Figures 3(b) and 3(c).The proposed method solves this problem bysupplementing unseen syntactic constituents be-fore and after the translation unit.
For example,considering parse trees for the complete sentencein Figure 3(a), we see that a noun phrase (NP) canbe placed after the translation unit ?this is.?
If weappend the syntactic constituent NP as a ?blackbox?
before parsing, we can create a syntacticallydesirable parse tree as shown in Figure 3(d1) Wealso can construct another tree as shown in Fig-ure 3(d2) by appending two constituents DT andNN .
For the other example ?is a,?
we can createthe parse tree in Figure 3(e1) by appending NPbefore the unit and NN after the unit, or can cre-ate the tree in Figure 3(e2) by appending only NNafter the unit.3.2 Formulation of Incomplete ParsingA typical model for phrase structure parsing is theprobabilistic context-free grammar (PCFG).
Pars-ing is performed by finding the parse tree T that200maximizes the PCFG probability given a sequenceof words w ?
[w1, w2, ?
?
?
, wn] as shown by Eq.(2):T??
arg maxTPr(T |w) (1)?
arg maxT[?(X?[Y,???
])?Tlog Pr(X ?
[Y, ?
?
?])
+?
(X?wi)?Tlog Pr(X ?
wi) ], (2)where Pr(X ?
[Y, ?
?
?])
represents the genera-tive probabilities of the sequence of constituents[Y, ?
?
?]
given a parent constituentX , and Pr(X ?wi) represents the generative probabilities of eachword wi(1 ?
i ?
n) given a parent constituentX .To consider parsing of incomplete sentenceswith appended syntactic constituents, We defineL ?
[L|L|, ?
?
?
, L2, L1] as the sequence of pre-ceding syntactic constituents of the translation unitand R ?
[R1, R2, ?
?
?
, R|R|] as the sequence offollowing syntactic constituents of the translationunit.
For the example Figure 3(d1), we assumethat L = [ ] and R = [ NP ].We assume that both sequences of syntacticconstituents L and R are predicted based on thesequence of wordsw before the main parsing step.Thus, the whole process of parsing incompletesentences can be described as the combination ofpredicting both sequences of syntactic constituentsrepresented by Eq.
(3) and (4) and parsing withpredicted syntactic constituents represented by Eq.(5):L??
arg maxLPr(L|w), (3)R??
arg maxRPr(R|w), (4)T??
arg maxTPr(T |L?,w,R?).
(5)Algorithmically, parsing with predicted syntac-tic constituents can be achieved by simply treatingeach syntactic constituent as another word in theinput sequence and using a standard parsing algo-rithm such as the CKY algorithm.
In this process,the only difference between syntactic constituentsand normal words is the probability, which we de-fine as follows:Pr(X ?
Y ) ?
{1, if Y = X0, otherwise.
(6)It should be noted that here L refers to syntac-tic constituents that have already been seen in thepast.
Thus, it is theoretically possible to store pastparse trees as history and generate L based on thishistory, or condition Eq.
3 based on this infor-mation.
However, deciding which part of trees touse as L is not trivial, and applying this approachrequires that we predict L and R using differentmethods.
Thus, in this study, we use the samemethod to predict both sequences of constituentsfor simplicity.In the next section, we describe the actualmethod used to create a predictive model for thesestrings of syntactic constituents.4 Predicting Syntactic ConstituentsIn order to define which syntactic constituentsshould be predicted by our model, we assume thateach final parse tree generated by w, L and Rmust satisfy the following conditions:1.
The parse tree generated byw,L andRmustbe ?complete.?
Defining this formally, thismeans that the root node of the parse tree forthe segment must correspond to a node in theparse tree for the original complete sentence.2.
Each parse tree contains only L, w and R asterminal symbols.3.
The number of nodes is the minimum neces-sary to satisfy these conditions.As shown in the Figure 3, there is ambiguity re-garding syntactic constituents to be predicted (e.g.we can choose either [ NP ] or [ DT , NN ] asRfor w = [ ?this?, ?is?
]).
These conditions avoidambiguity of which syntactic constituents shouldpredicted for partial sentences in the training data.Looking at the example, Figures 3(d1) and 3(e1)satisfy these conditions, but 3(d2) and 3(e2) donot.Figure 4 shows the statistics of the lengths ofL and R sequences extracted according to thesecriteria for all substrings of the WSJ datasets 2 to23 of the Penn Treebank (Marcus et al, 1993), astandard training set for English syntactic parsers.From the figure we can see that lengths of up to 2constituents cover the majority of cases for bothLand R, but a significant number of cases requirelonger strings.
Thus methods that predict a fixednumber of constituents are not appropriate here.
InAlgorithm 1, we show the method we propose to201Figure 4: Statistics of numbers of syntactic con-stituents to be predicted.predictR for constituent sequences of an arbitrarylength.
Here ++ represents the concatenation oftwo sequences.First, our method forcibly parses the input se-quence w and retrieves a potentially incorrectparse tree T?, which is used to calculate featuresfor the prediction model.
The next syntactic con-stituent R+is then predicted using features ex-tracted from w, T?, and the predicted sequencehistoryR?.
This prediction is repeated recurrentlyuntil the end-of-sentence symbol (?nil?
in Algo-rithm 1) is predicted as the next symbol.In this study, we use a multi-label classifierbased on linear SVMs (Fan et al, 2008) to predictnew syntactic constituents with features shownin Table 1.
We treat the input sequence w andpredicted syntactic constituents R?as a concate-nated sequencew++R?.
For example, if we havew = [ this, is, a ] and R?= [ NN ], then theword features ?3 rightmost 1-grams?
will take thevalues ?is,?
?a,?
and NN .
Tags of semi-terminalnodes in T?are used as part-of-speech (POS) tagsfor corresponding words and the POS of each pre-dicted syntactic constituent is simply its tag.
?nil?is used when some information is not available.For example, if we have w = [ this, is ] andR?= [ ] then ?3 rightmost 1-grams?
will take thevalues ?nil,?
?this,?
and ?is.?
Algorithm 1 and Ta-ble 1 shows the method used to predictR?but L?can be predicted by performing the prediction pro-cess in the reverse order.5 Tree-to-string SMT with SyntacticConstituentsOnce we have created a tree from the sequenceL?++w++R?by performing PCFG parsing withpredicted syntactic constituents according to Eqs.
(2), (5), and (6), the next step is to use this tree intranslation.
In this section, we focus specificallyAlgorithm 1 Prediction algorithm for followingconstituents R?T??
arg maxTPr(T |w)R??
[ ]loopR+?
arg maxRPr(R|T?,R?
)if R+= nil thenreturnR?end ifR??
R?++[R+]end loopTable 1: Features used in predicting syntactic con-stituents.Type FeatureWords 3 leftmost 1,2-grams in w++R?3 rightmost 1,2-grams in w++R?Left/rightmost pair in w++R?POS Same as ?Words?Parse Tag of the root nodeTags of children of the root nodePairs of root and children nodesLength |w||R?|on T2S translation, which we use in our experi-ments, but it is likely that similar methods are ap-plicable to other uses of source-side syntax suchas pre-ordering as well.It should be noted that using these trees in T2Stranslation models is not trivial because each esti-mated syntactic constituent should be treated as anaggregated entity representing all possibilities ofsubtrees rooted in such a constituent.
Specifically,there are two problems: the possibility of reorder-ing an as-of-yet unseen syntactic constituent intothe middle of the translated sentence, and the cal-culation of language model probabilities consider-ing syntactic constituent tags.With regards to the first problem of reordering,consider the example of English-Japanese transla-tion in Figure 5(b), where a syntactic constituentPP is placed at the end of the English sequence(R?
), but the corresponding entity in the Japanesetranslation result should be placed in the middle ofthe sentence.
In this case, if we attempt to translateimmediately, we will have to omit the as-of-yetunknown PP from our translation and translate itlater, resulting in an unnatural word ordering in the202(a) (b)Figure 5: Waiting for the next translation unit.target sentence.2Thus, if any of the syntactic constituents in Rare placed anywhere other than the end of thetranslation result, we can assume that this is a hintthat the current segmentation boundary is not ap-propriate.
Based on this intuition, we propose aheuristic method that ignores segmentation bound-aries that result in a translation of this type, and in-stead wait for the next translation unit, helping toavoid problems due to inappropriate segmentationboundaries.
Algorithm 2 formally describes thiswaiting method.The second problem of language model proba-bilities arises because we are attempting to gener-ate a string of words, some of which are not actualwords but tags representing syntactic constituents.Creating a language model that contains probabil-ities for these tags in the appropriate places is nottrivial, so for simplicity, we simply assume that ev-ery syntactic constituent tag is an unknown word,and that the output of translation consists of bothtranslated normal words and non-translated tags asshown in Figure 5.
We relegate a more completehandling of these tags to future work.2It is also potentially possible to create a predictive modelfor the actual content of the PP as done for sentence-finalverbs by Grissom II et al (2014), but the space of potentialprepositional phrases is huge, and we leave this non-trivialtask for future work.Algorithm 2 Waiting algorithm for T2S SMTw ?
[ ]loopw ?
w++NextSegment()L??
arg maxLPr(L|w)R??
arg maxRPr(R|w)T??
arg maxTPr(T |L?,w,R?)e??
arg maxePr(e|T?
)if elements of R?are rightmost in e?thenOutput(e?
)w ?
[ ]end ifend loop6 Experiments6.1 Experiment SettingsWe perform 2 types of experiments to evaluate theeffectiveness of the proposed methods.6.1.1 Predicting Syntactic ConstituentsIn the first experiment, we evaluate prediction ac-curacies of unseen syntactic constituentsL andR.To do so, we train a predictive model as describedin Section 4 using an English treebank and evalu-ate its performance.
To create training and testingdata, we extract all substrings w s.t.
|w| ?
2 inthe Penn Treebank and calculate the correspond-ing syntactic constituents L and R by accordingto the original trees and substring w. We use the90% of the extracted data for training a classifierand the remaining 10% for testing estimation re-call, precision and F-measure.
We use the Ckylarkparser(Oda et al, 2015) to generate T?from w.6.1.2 Simultaneous TranslationNext, we evaluate the performance of T2S si-multaneous translation adopting the two proposedmethods.
We use data of TED talks from theEnglish-Japanese section of WIT3 (Cettolo et al,2012), and also append dictionary entries and ex-amples in Eijiro3to the training data to increasethe vocabulary of the translation model.
The totalnumber of sentences/entries is 2.49M (WIT3, Ei-jiro), 998 (WIT3), and 468 (WIT3) sentences fortraining, development, and testing respectively.We use the Stanford Tokenizer4for Englishtokenization, KyTea (Neubig et al, 2011) for3http://eijiro.jp/4http://nlp.stanford.edu/software/tokenizer.shtml203Japanese tokenization, GIZA++ (Och and Ney,2003) to construct word alignment, and KenLM(Heafield et al, 2013) to generate a 5-gram targetlanguage model.
We use the Ckylark parser, whichwe modified to implement the parsing method ofSection 3.2, to generate T?from L?, w and R?.We use Travatar (Neubig, 2013) to train the T2Stranslation model used in the proposed method,and also Moses (Koehn et al, 2007) to trainphrase-based translation models that serve as abaseline.
Each translation model is tuned us-ing MERT (Och, 2003) to maximize BLEU (Pa-pineni et al, 2002).
We evaluate translation ac-curacies by BLEU and also RIBES (Isozaki etal., 2010), a reordering-focused metric which hasachieved high correlation with human evaluationon English-Japanese translation tasks.We perform tests using two different sentencesegmentation methods.
The first is n-words seg-mentation (Rangarajan Sridhar et al, 2013), a sim-ple heuristic that simply segments the input ev-ery n words.
This method disregards syntacticand semantic units in the original sentence, al-lowing us to evaluate the robustness of translationagainst poor segmentation boundaries.
The secondmethod is the state-of-the-art segmentation strat-egy proposed by Oda et al (2014), which findssegmentation boundaries that optimize the accu-racy of the translation output.
We use BLEU+1(Lin and Och, 2004) as the objective of this seg-mentation strategy.We evaluate the following baseline and pro-posed methods:PBMT is a baseline using phrase-based SMT.T2S uses T2S SMT with parse trees generatedfrom only w.T2S-Tag further predicts unseen syntactic con-stituents according to Section 4.
Before eval-uation, all constituent tags are simply deletedfrom the output.T2S-Wait uses T2S-Tag and adds the waitingstrategy described in Section 5.We also show PBMT-Sent and T2S-Sent whichare full sentence-based PBMT and T2S systems.6.2 Results6.2.1 Predicting Syntactic ConstituentsTable 2 shows the recall, precision, and F-measureof the estimated L and R sequences.
The tableTable 2: Performance of syntactic constituent pre-diction.Target P % R % F %L (ordered) 31.93 7.27 11.85(unordered) 51.21 11.66 19.00R (ordered) 51.12 33.78 40.68(unordered) 52.77 34.87 42.00shows results of two evaluation settings, wherethe order of generated constituents is consideredor not.We can see that in each case recall is lower thanthe corresponding precision and the performanceof L differs between ordered and unordered re-sults.
These trends result from the fact that themodel generates fewer constituents than exist inthe test data.
However, this trend is not entirely un-expected because it is not possible to completelyaccurately guess syntactic constituents from everysubstring w. For example, parts of the sentence?in the next 18 minutes?
can generate the sequence?in the next CD NN ?
and ?
IN DT JJ 18 min-utes,?
but the constituents CD in the former caseand DT and JJ in the latter case are not neces-sary in all situations.
In contrast, NN and INwill probably be inserted most cases.
As a result,the appearance of such ambiguous constituents inthe training data is less consistent than that of nec-essary syntactic constituents, and thus the predic-tion model avoids generating such ambiguous con-stituents.6.2.2 Simultaneous TranslationNext, we evaluate the translation results achievedby the proposed method.
Figures 6 and 7 show therelationship between the mean number of words inthe translation segments and translation accuracyof BLEU and RIBES respectively.
Each horizon-tal axis of these graphs indicates the mean numberof words in translation units that are used to gen-erate the actual translation output, and these canbe assumed to be proportional to the mean waitingtime for listeners.
In cases except T2S-Wait, thesevalues are equal to the mean length of translationunit generated by the segmentation strategies, andin the case of T2S-Wait, this value shows the lengthof the translation units concatenated by the waitingstrategy.
First looking at the full sentence results(rightmost points in each graph), we can see thatT2S greatly outperforms PBMT on full sentences,204(a) n-words segmentation (b) optimized segmentationFigure 6: Mean #words and BLEU scores of each method.
(a) n-words segmentation (b) optimized segmentationFigure 7: Mean #words and RIBES scores of each method.underlining the importance of considering syntaxfor this language pair.Turning to simultaneous translation, we firstconsider the case of n-words segmentation, whichwill demonstrate robustness of each method topoorly formed translation segments.
When wecompare PBMT and T2S, we can see that T2S issuperior for longer segments, but on shorter seg-ments performance is greatly reduced, droppingbelow that of PBMT in BLEU at an average of 6words, and RIBES at an average of 4 words.
Thistrend is reasonable, considering that shorter trans-lation units will result in syntactically inconsistentunits and thus incorrect parse trees.
Next look-ing at the results for T2S-Tag, we can see that inthe case of the n-words segmentation, it is ableto maintain the same translation performance ofPBMT, even at the shorter settings.
Furthermore,T2S-Wait also maintains the same performanceof T2S-Tag in BLEU and achieves much higherperformance than any of the other methods inRIBES, particularly with regards to shorter trans-lation units.
This result shows that the method ofwaiting for more input in the face of potential re-ordering problems is highly effective in maintain-ing the correct ordering of the output.In the case of the optimized segmentation,all three T2S methods maintain approximatelythe same performance, consistently outperformingPBMT in RIBES, and crossing in BLEU around 5-6 words.
From this, we can hypothesize that theoptimized segmentation strategy learns featuresthat maintain some syntactic consistency, whichplays a similar role to the proposed method.
How-ever, RIBES scores for T2S-Wait is still generallyhigher than the other methods, demonstrating thatwaiting maintains its reordering advantage even inthe optimized segmentation case.7 Conclusion and Future WorkIn this paper, we proposed the first method toapply SMT using source syntax to simultaneoustranslation.
Especially, we proposed methods tomaintain the syntactic consistency of translationunits by predicting unseen syntactic constituents,and waiting until more input is available when it isnecessary to achieve good translation results.
Ex-205periments on an English-Japanese TED talk trans-lation task demonstrate that our methods are morerobust to short, inconsistent translation segments.As future work, we are planning to devisemore sophisticated methods for language model-ing using constituent tags, and ways to incorpo-rate previously translated segments into the esti-mation process for left-hand constituents.
Next,our method to predict additional constituents doesnot target the grammatically correct translationunits for which L = [ ] and R = [ ], althoughthere is still room for improvement in this assump-tion.
In addition, we hope to expand the meth-ods proposed here to a more incremental setting,where both parsing and decoding are performedincrementally, and the information from these pro-cesses can be reflected in the decision of segmen-tation boundaries.AcknowledgementPart of this work was supported by JSPS KAK-ENHI Grant Number 24240032, and Grant-in-Aidfor JSPS Fellows Grant Number 15J10649.ReferencesSrinivas Bangalore, Vivek Kumar Rangarajan Srid-har, Prakash Kolan, Ladan Golipour, and AuraJimenez.
2012.
Real-time incremental speech-to-speech translation of dialogs.
In Proc.
NAACL.Mauro Cettolo, Christian Girardi, and Marcello Fed-erico.
2012.
WIT3: Web inventory of transcribedand translated talks.
In Proc.
EAMT.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
The Journalof Machine Learning Research.Andrew Finch, Xiaolin Wang, and Eiichiro Sumita.2014.
An exploration of segmentation strategies instream decoding.
In Proc.
IWSLT.Christian F?ugen, Alex Waibel, and Muntsin Kolss.2007.
Simultaneous translation of lectures andspeeches.
Machine Translation, 21.Tomoki Fujita, Graham Neubig, Sakriani Sakti,Tomoki Toda, and Satoshi Nakamura.
2013.
Sim-ple, lexicalized choice of translation timing for si-multaneous speech translation.
In Proc.
Interspeech.Alvin Grissom II, He He, Jordan Boyd-Graber, JohnMorgan, and Hal Daum?e III.
2014.
Dont until thefinal verb wait: Reinforcement learning for simulta-neous machine translation.
In Proc.
EMNLP.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable modifiedKneser-Ney language model estimation.
In Proc.ACL.Liang Huang, Kevin Knight, and Aravind Joshi.
2006.Statistical syntax-directed translation with extendeddomain of locality.
In Proc.
AMTA.Hideki Isozaki, Tsutomu Hirao, Kevin Duh, KatsuhitoSudoh, and Hajime Tsukada.
2010.
Automaticevaluation of translation quality for distant languagepairs.
In Proc.
EMNLP.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ond?rej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProc.
ACL.Chin-Yew Lin and Franz Josef Och.
2004.
ORANGE:a method for evaluating automatic evaluation met-rics for machine translation.
In Proc.
COLING.Mitchell P Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The Penn treebank.
Com-putational linguistics, 19(2).Evgeny Matusov, Arne Mauser, and Hermann Ney.2006.
Automatic sentence segmentation and punc-tuation prediction for spoken language translation.In Proc.
IWSLT.Graham Neubig, Yosuke Nakata, and Shinsuke Mori.2011.
Pointwise prediction for robust, adaptablejapanese morphological analysis.
In Proc.
ACL-HLT.Graham Neubig.
2013.
Travatar: A forest-to-stringmachine translation engine based on tree transduc-ers.
In Proc.
ACL.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational linguistics.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proc.
ACL.Yusuke Oda, Graham Neubig, Sakriani Sakti, TomokiToda, and Satoshi Nakamura.
2014.
Optimiz-ing segmentation strategies for simultaneous speechtranslation.
In Proc.
ACL.Yusuke Oda, Graham Neubig, Sakriani Sakti, TomokiToda, and Satoshi Nakamura.
2015.
Ckylark: Amore robust PCFG-LA parser.
In Proc.
NAACL-HLT.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic eval-uation of machine translation.
In Proc.
ACL.206Vivek Kumar Rangarajan Sridhar, John Chen, SrinivasBangalore, Andrej Ljolje, and Rathinavelu Chengal-varayan.
2013.
Segmentation strategies for stream-ing speech translation.
In Proc.
NAACL-HLT.Koichiro Ryu, Shigeki Matsubara, and Yasuyoshi In-agaki.
2006.
Simultaneous english-japanese spo-ken language translation based on incremental de-pendency parsing and transfer.
In Proc.
COLING.Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar.2010.
Incremental decoding for phrase-based statis-tical machine translation.
In Proc.
WMT.Maryam Siahbani, Ramtin Mehdizadeh Seraj,Baskaran Sankaran, and Anoop Sarkar.
2014.Incremental translation using hierarchical phrase-based translation system.
In Proc.
SLT.Fei Xia and Michael McCord.
2004.
Improvinga statistical MT system with automatically learnedrewrite patterns.
In Proc.
COLING.Mahsa Yarmohammadi, Vivek Kumar Rangara-jan Sridhar, Srinivas Bangalore, and BaskaranSankaran.
2013.
Incremental segmentation anddecoding strategies for simultaneous translation.
InProc.
IJCNLP.207
