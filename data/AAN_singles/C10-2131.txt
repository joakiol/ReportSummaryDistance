Coling 2010: Poster Volume, pages 1140?1148,Beijing, August 2010A Method for Automatically Generating a MediatorySummary to Verify Credibility of Information on the WebHideyuki Shibuki and Takahiro Nagai and Masahiro NakanoRintaro Miyazaki and Madoka Ishioroshi and Tatsunori MoriGraduate School of Environment and Information Sciences,Yokohama National University{shib, nagadon, nakano, rintaro, ishioroshi, mori}@forest.eis.ynu.ac.jpAbstractIn this paper, we propose a method formediatory summarization, which is anovel technique for facilitating users?assessments of the credibility of infor-mation on the Web.
A mediatory sum-mary is generated by extracting a pas-sage from Web documents; this sum-mary is generated on the basis of itsrelevance to a given query, fairness,and density of keywords, which are fea-tures of the summaries constructed todetermine the credibility of informa-tion on the Web.
We demonstratethe effectiveness of the generated me-diatory summary in comparison withthe summaries of Web documents pro-duced by Web search engines.1 IntroductionMany pages on the Web contain incorrect orunverifiable information.
Therefore, there is agrowing demand for technologies that can en-able us to obtain reliable information.
How-ever, it would be almost impossible to auto-matically ascertain the accuracy of informa-tion presented on the Web.
Hence, the second-best approach is the development of a sup-porting method for judging the credibility ofinformation on the Web.Presently, when we wish to judge the credi-bility of information on the Web, we often readsome relevant Web documents retrieved viaWeb search engines.
However, Web search en-gines do not provide any suggestions in caseswhere the content of some documents conflictswith the content of other documents.
Further-more, the retrieved documents are too manyto read and may not be ranked according tothe credibility of the information they provide.In other words, information retrieval is notsufficient to support users?
assessments of thecredibility of information, and therefore, ad-ditional techniques are required for the same.Several previous researches have been con-ducted for developing such techniques.
Juffin-ger et al (2009) ranked blogs in terms oftheir concurrence with well-verified informa-tion from sources such as a news corpus.Miyazaki et al (2009) devised a method forextracting the description of the informationsender, namely, the person or organizationproviding texts in Web pages.
Ohshima etal.
(2009) proposed a method for rerankingWeb pages according to users?
regionality,which depends on two factors: uniformity andproximity.
While the abovementioned stud-ies mainly facilitate users?
assessments of thecredibility of individual Web pages, the fol-lowing studies deal with the issues of cred-ibility of information in multiple documentson the Web.
Murakami et al (2009) pro-posed a method to analyze semantic rela-tionships such as agreement, conflict, or ev-idence between texts on the Web.
Kawaharaet al (2009) reported a method for present-ing overviews of evaluative information suchas positive/negative opinions.Although the above techniques facilitateusers?
assessments of credibility of informationon the Web, there is still room for methodsthat support users?
judgment.
For example,when the truth of a statement1 ?Diesel en-gines are harmful to the environment?
is to1In this paper, a statement is defined as text suchas an opinion, evaluation, or objective fact.1140																			  !			"	!	#		$	!						$ 		$	!#$ !		%			!	"#		#%									 	!
"#!!$Figure 1: An example of the mediatory summary.be verified, the following two contradictorygroups of Web documents are obtained: onestating that ?Diesel engines are harmful tothe environment?
and the other stating that?Diesel engines are not harmful to the envi-ronment.?
How does one resolve this conflict?Are the contents of one group that containsa less reasonable description wrong?
On theother hand, if contents of both these groupsare correct, then why do they appear to becontradictory to each other?
A display ofonly the overview of statements in Web doc-uments and the relationships between thesestatements does not always provide sufficientinformation to answer these questions.In order to direct users to a reasonable in-terpretation written by one author, Kaneko etal.
(2009) proposed the notion of a mediatorysummary for pseudo conflicts, which are rela-tionships between statements that appear tocontradict each other at first glance but cancoexist under a certain situation.
However,Kaneko et aldid not describe any algorithms forautomatically generating the mediatory sum-mary.
Therefore, in this paper, we propose amethod for automatically generating the me-diatory summary and demonstrate the effec-tiveness of generated mediatory summaries.The rest of this paper is organized as fol-lows.
In Section 2, we describe the conceptof a mediatory summary and the features re-quired for automatically generating it.
In Sec-tion 3, we describe an algorithm for generationof the mediatory summary.
In Section 4, wepresent experimental results to demonstratethe effectiveness of the generated mediatorysummary.
Section 5 provides the conclusion.2 Mediatory SummaryThe generation of the mediatory summary isa type of informative summarization based onpassage extraction.
Figure 1 shows an exam-ple of the ideal mediatory summary for thequery ?Are diesel engines harmful to the en-vironment??
The text in boxes with thicklines is extracted from Web documents, andthe italicized text is generated through tem-plates.
The user is shown both positive andnegative responses to the query and appropri-ately guided on how to interpret them.
Oneof the most difficult issues in the automatedgeneration of the mediatory summary is theextraction of the most suitable passage that isused for interpretation.22Owing to space limitations, we have omitted thediscussion on generation through templetes.1141Nakano et al (2010) constructed a textsummarization corpus for determining thecredibility of information on the Web.
Theircorpus contains six query statements, the Webdocument collections retrieved for each query,and 24 summaries made by four persons perquery.
We analyzed these summaries from theviewpoint of mediatory summary generationand observed that mediatory summaries usu-ally display the following three features.The first feature is the high relevance to agiven query.
We can approximately determinewhether the text displays this feature by ex-amining whether or not it contains contentwords in the query such as ?diesel,?
as in Fig-ure 1.
The second feature is fairness, or inother words, evenly describing both positiveand negative opinions.
We can approximatelydetermine whether the text displays this fea-ture by examining whether or not it containswords for both opinions and having different,typically opposite meanings such as ?lot?
and?less,?
as in Figure 1.
It should be noted thatwords with opposite meanings are not lim-ited to antonyms.
In the case of the query?Are diesel engines harmful to the environ-ment?,?
?carbon dioxide?
and ?smog-formingpollutants?
should be also regarded as wordswith opposite meanings.
The third feature isthe high density of words of the above twotypes in a text.
In addition to appropriatenessof a text with high density as a summary, sucha text is likely to be a text contrasting bothsides of contents.3 Proposed Method3.1 OutlineWe propose a method for generating media-tory summaries by extracting passages thatdisplay the features described in the previoussection.
First, we define the content wordsrelated to the topic of a query as topic key-words.3 Next, we define the content words cor-3Although topic words are not restricted to wordsin the given query, we use only the words in the givenquery as topic words in this paper.
Inclusion of wordsother than those in the given query is a topic for futureresearch.			 	Figure 2: Outline of the proposed method.responding to the positive and negative opin-ions as positive keywords and negative key-words, respectively.
Although topic keywordsappear in the given query, positive/negativekeywords hardly appear in the given query.Therefore, positive/negative keywords have tobe extracted from other text.Figure 2 shows the outline of the proposedmethod.
First, in order to find contents op-posed to a given query, inverse queries aregenerated.
We define an inverse query as aquery generated by replacing a word in thegiven query with its antonym.
Next, the givenquery and the inverse queries are used to re-tain three sets of Web documents, which arelikely to contain more positive keywords, neg-ative keywords, and neither.
The topic, posi-tive, and negative keywords are then extractedfrom these sets.
Finally, the extracted key-words are used to extract passages from thethree sets of Web documents; these passagesare ranked in order of the score described inSection 3.5 as a mediatory summary.11423.2 Inverse Query GenerationInverse queries are generated by simply re-placing a word in the given query with anantonym of the word using a dictionary forantonyms.
For example, if the query is ?Issafety of LASIK operation high?,?
and if?risk?
and ?low?
are input into the dictionaryas antonyms of ?safety?
and ?high,?
respec-tively, then the two generated inverse queriesare ?Is risk of LASIK operation high??
and?Is safety of LASIK operation low??
Positivekeywords are words in the given query thatare to be replaced with their opposite wordsin the inverse queries.
On the other hand,the newly introduced opposite words in theinverse queries are regarded as negative key-words.
In the above example, ?safety?
and?high?
are positive keywords, whereas ?risk?and ?low?
are negative ones.
If there is no re-placeable word, the inverse query is not gen-erated.3.3 Web Document RetrievalUsing a given query and the correspondinginverse queries, Web documents are retrievedvia TSUBAKI (Shinzato et al, 2008); TSUB-AKI is an open-search engine with aninfras-tructure based on deep Japanese natural lan-guage processing, and it can accept a natural-language sentence as a query.
The number ofdocuments retrieved per query is tentativelyset to 100 in our experiment described in Sec-tion 4.The retrieved documents are classified intothe following three document sets: one con-taining documents retrieved by the givenquery but not retrieved by the inverse queries,one containing documents retrieved by the in-verse queries but not retrieved by the givenquery, and one containing documents re-trieved by both the given query and the in-verse queries.
These three document sets aretermed Dquery, Dinverse, and Dboth, respec-tively.
Words appearing frequently in Dqueryare likely to be positive keywords, and thoseappearing frequently in Dinverse, negative key-words.TSUBAKI has an optional function for au-Table 1: An example of extracted keywords.rank rank rankword tf POS NEG polarityLASIK 1 1 1 otheroperation 2 2 2 othereyesight 3 3 3 otherexamination 19 13 60 positiveglasses 47 58 75 otherblindness 61 5,045 20 negativeeffect 66 72 111 positivecomplications 77 206 58 negativetomatically expanding a submitted query byincluding the negative form of the main verbin the query.
For example, if ?Is safety ofLASIK operation high??
is the submittedquery, then the expanded query is ?Is safety ofLASIK operation not high??
The documentsretrieved for the expanded query derived fromthe given query are regarded as documentsretrieved for inverse queries.
Similarly, thedocuments retrieved for the expanded queryderived from the inverse queries are regardedas documents retrieved for the given query.Hence, even if there is no inverse query, pos-sibly conflicting documents can be retrieved.3.4 Keyword ExtractionPositive and negative keywords are extractedfrom the retrieved Web documents as follows.First, the positive score scPOS(w) and nega-tive score scNEG(w) of a word w are calculatedby Equations (1) and (2), respectively:scPOS(w) =df(w,Dquery) ?
tf (w)df(w,Dinverse) + 1(1)scNEG(w) =df(w,Dinverse) ?
tf (w)df(w,Dquery) + 1(2)where tf (w) is the frequency of w in all re-trieved documents, and df(w,D) is the num-ber of documents containing w in D. ThescPOS(w) is higher and scNEG(w) is lower ifthe word w appears more frequently in thedocuments retrieved by the given query andless frequently in the documents retrieved bythe inverse queries.
The frequency tf (w) is1143used to express these scores in order to con-sider the global importance of w in the entireretrieved document set.Because words such as ?LASIK?
in thequery ?Is safety of LASIK operation high?
?have high scores in terms of both scPOS(w)and scNEG(w), such words should not be ex-tracted as positive or negative keywords.
Be-cause the number of documents in Dqueryis different from that in Dinverse, scPOS(w)cannot be directly compared with scNEG(w).Hence, scPOS(w) and scNEG(w) are nor-malized, and rankPOS(w) and rankNEG(w)are compared.
The ranking functionsrankPOS(w) and rankNEG(w) are defined asthe nth place ranks when all words are rankedin the descending order of scPOS(w) andscNEG(w), respectively.
We consider the topCrank words on the tf () ranking as candi-dates for possible keywords.
If rankPOS(w)?rankNEG(w) or rankNEG(w)?rankPOS(w) isgreater than Cdif , then we regard w as a pos-itive or negative keyword, respectively.
Ta-ble 1 shows an example of the extracted key-words when the given query is ?Is safety ofLASIK operation high??
In this paper, Crankand Cdif are tentatively set to 100 and 20, re-spectively, in a preliminary experiment usingseveral queries except the ones described inSection 4.4 Finally, the positive/negative key-words, mentioned in Section 3.2, are respec-tively added to the positive/negative keywordsets described above.The topic keywords are the words in thegiven query excluding the positive/negativekeywords.3.5 Passage ExtractionPassages suitable for a mediatory summaryare extracted through the following fourstages.For all sentences in the document sets de-scribed in Section 3.3, the first stage involvesthe recognition of sentences that are uselessfor mediatory summary.
We regard insuffi-4The parameters used in this paper are set tenta-tively.
Determining the optimal parameters is a topicfor future research.cient or incomplete sentences as useless sen-tences.
We simply consider a sentence tobe sufficient when the sentence has, at least,one verb phrase and one noun phrase andwhen the sentence contains more than twoverb/noun phrases.
We simply consider a sen-tence to be insufficient if it is not a sufficientsentence.
When the expression ?...,?
whichindicates an omission, appears at the end ofa sentence, then we consider the sentence in-complete.
This recognition of sentences playsan important role in the calculation of scoresin subsequent stages.The second stage involves the calculationof the score of each sentence.
When KW isdefined as a set of all the topic, positive, andnegative keywords, the basic score scBAS(s) ofsentence s is calculated by Equation (3).scBAS(s) =?w?KW appear(w, s)|KW | (3)where appear(w, s) is a function whose valueis 1 if w appears in s and 0 otherwise.
If scontains many different keywords, scBAS(s)acquires a high value.
If s is recognized asa useless sentence, then scBAS(s) is multi-plied by Cuseless as a penalty.
In this pa-per, Cuseless is tentatively set to 0.5 in thecase of ungrammatical sentences and 0 in thecase that the end of the sentences is omitted.When the score of a sentence is calculated,the fairness described in Section 2 is deter-mined in the following manner.
If s containspositive/negative keywords besides topic key-words, the scBAS(s) is multiplied by Cbasic.The negative form of positive/negative key-words is considered, and Cbasic is tentativelyset to two if either a positive or negative ex-pression appears in s and to three if both pos-itive and negative expressions appear in s.The third stage involves the application ofa smoothing method to raw scores of a sen-tence in order to suppress over-fragmentationof passages.
As given in Equation (4), thesmoothed score scSMO(si) for the ith sentencesi in a document is calculated using the Hann1144function, whose window length is L.scSMO(si) =L2?j=?L2(scBAS(si+j) ?
hf(j)) (4)hf(k) = 0.5 + 0.5 cos 2?
kL (5)The value of L is tentatively set as 5 inthis study.
Insufficient sentences may con-vey useful information to readers when theyare embedded in an appropriate context.
Onthe other hand, incomplete sentences do not.Therefore, scSMO(s) of such omitted sen-tences is set as 0 even after smoothing.
If alltypes of keywords appear in the Hann win-dow, then scSMO(s) is multiplied by Csmoothbecause a passage containing s is likely to bea part of a mediatory summary.
The value ofCsmooth is tentatively set as 2 in this study.The fourth stage involves the extraction andranking of passages.
Every series of sentenceswith scSMO(s) greater than 1N of the maxi-mum score in the document is extracted asa passage.
N is tentatively set as 3.
Thescore scPAS(p) of passage p is the highest scorescSMO(s) of sentence s in the passage.
If alltypes of keywords appear in p, the scPAS(p)is multiplied by Cpassage, as in the third stage.Note that the length of the extracted passagesis not set to L sentences and that passagesthat contain sentences multiplied by Csmoothare not always multiplied by Cpassage.
Cpassageis tentatively set as 3 in this study.
Be-cause of summarization, the passages whoselengths are nearer to the ideal length Clengthare ranked higher.
The final score scFIN(p) iscalculated by Equation (6).scFIN(p) = exp (scPAS(p) ?
?
?
er(p)) (6)er(p) = |Clength ?
nc(p)| (7)where nc(p) is the number of characters in p,and ?
is a coefficient.
Clength and ?
are ten-tatively set to 300 and 0.02, respectively.4 Experiment4.1 ConditionsBecause the proposed method is the firstmethod for automated generation of media-tory summary, there is no existing method todirectly compare our proposed method with.Therefore, we compare the proposed methodwith the following three methods.
The firstmethod, KWtf , uses frequent words instead ofthe three types of keywords described in Sec-tion 3.4.
The second method, LinTSU , uses anexisting summarization module for summariz-ing the top documents in order of the score inwhich TSUBAKI retrieves them.
The thirdmethod, LinscF IN , uses the same existingsummarization module for summarizing docu-ments containing the top passages in order ofthe score scFIN () described in Section 3.5.
Weemploy Lingua::JA::Summarize::Extract5 as asummarization module, which extracts sen-tences containing more characteristic words;this extraction is based on the word frequencyand word bigram frequency in a given docu-ment.KWtf is compared with the proposedmethod in order to investigate the effective-ness of keywords in terms of polarity.
One ofthe functions of the proposed method is theclassification of the top Crank words on thetf () ranking into positive keywords, negativekeywords, and others in order to determinethe fairness described in Section 2.
KWtf issimply based on frequent words and does notclassify them.
In other words, all of the topCrank words on the tf () ranking are used askeywords without polarity.
It should be notedthat no rewards can be obtained using Cbasic,Csmooth, and Cpassage in the passage extrac-tion described in Section 3.5, although penal-ties can be obtained using Cuseless and Clength.LinTSU is compared with the proposedmethod in order to clarify the difference be-tween the summarization by our method andthat by a method used for general purposes.In other words, we investigate whether or notthe extraction of sentences containing morecharacteristic words is sufficient for generat-ing mediatory summaries.LinscF IN is compared with the proposedmethod in order to investigate the appropri-5http://search.cpan.org/?yappo/Lingua-JA-Summarize-Extract-0.02/1145Table 2: Average precision of appropriateness of summaries generated by each query.Top 3 Top 5 Top 10 Top 3 Top 5 Top 10Are diesel engines harmful to the environment?
Is safety of LASIK operation high?Proposed 100.0% 60.0% 36.7% Proposed 33.3% 20.0% 20.0%KWtf 0.0% 0.0% 0.0% KWtf 0.0% 0.0% 0.0%LinTSU 66.7% 40.0% 26.7% LinTSU 33.3% 20.0% 30.0%LinscFIN 0.0% 13.3% 16.7% LinscFIN 0.0% 0.0% 0.0%Are whales endangered species?
Does asbestos have toxics?Proposed 55.6% 33.3% 30.0% Proposed 33.3% 40.0% 56.7%KWtf 0.0% 0.0% 0.0% KWtf 33.3% 20.0% 30.0%LinTSU 11.1% 20.0% 13.3% LinTSU 33.3% 20.0% 30.0%LinscFIN 22.2% 13.3% 10.0% LinscFIN 0.0% 20.0% 30.0%Is catch and release a better way of fishing?
Does carbon dioxide cause global warming?Proposed 33.3% 26.7% 13.3% Proposed 0.0% 0.0% 6.7%KWtf 0.0% 0.0% 6.7% KWtf 0.0% 0.0% 0.0%LinTSU 66.7% 46.7% 26.7% LinTSU 11.1% 6.7% 3.3%LinscFIN 33.3% 26.7% 13.3% LinscFIN 0.0% 0.0% 13.3%ateness of the extracted passages.
Anotherfunction of the proposed method is the rerank-ing of passages regardless of the order of doc-uments containing the passages during docu-ment retrieval.
Therefore, a set of documentssummarized by the proposed method may bedifferent from the set of documents summa-rized by LinTSU .
Therefore, it is observed thatLinscF IN handles the same documents as theproposed method.Because the mediatory summary is a novelconcept, methods for evaluating it have notbeen developed yet.
Although ROUGE (Linand Hovy, 2003) is one of the most popularmethods for evaluation of summaries, it maynot be appropriate for the evaluation of themediatory summary because the scoring basedon N-gram in this method cannot be used toconsider the fairness described in Section 2.Therefore, we evaluate the methods throughthe binary judgment of three human asses-sors, If the top summaries produced by eachmethod are deemed to be appropriate by thethree human assessors, we will be able to fa-cilitate users?
assessments of the contradictoryopinions that are relevant to the given query.Because we consider that filling a passagewith all the information necessary to facili-tate users?
assessments is more important thanshortening the passage under conditions forgeneration of mediatory summary, we imposedno limitation on the length of passages but theresultant penalty is obtained using Equations(6) and (7).
The average length of all sum-maries generated by the proposed method andKWtf was 288.4 characters, and none of thesummaries exceeded 500 characters.
There-fore, we allowed LinTSU and LinscF IN to gen-erate summaries as long as 500 characters,which is about 200 characters longer thansummaries generated by the proposed methodand KWtf .
We instructed the assessors to notjudge the appropriateness of the summaries onthe basis of their length.For the experiment, we prepared the follow-ing six queries: ?Are diesel engines harmfulto the environment?,?
?Is safety of LASIKoperation high?,?
?Are whales endangeredspecies?,?
?Does asbestos have toxics?,?
?Iscatch and release a better way of fishing?,?and ?Does carbon dioxide cause global warm-ing??
We used the Japanese morphologicalanalyzer, MeCab.66http://mecab.sourceforge.net/ (in Japanese)1146Table 3: Average precision of assessors interms of appropriateness of overall summaries.Top 3 Top 5 Top 10Proposed 42.6% 30.0% 27.2%KWtf 5.6% 3.3% 6.1%LinTSU 37.0% 25.6% 21.7%LinscFIN 9.3% 12.2% 13.9%4.2 Result and ConsiderationThe kappa values between each pair of asses-sors?
judgments on the appropriateness of thesummaries were 0.79, 0.77, and 0.76, respec-tively; these values indicate a high level ofagreement among assessors?
judgments.Table 2 shows the average precision7 of theassessors in terms of appropriateness of sum-maries on the basis of responses to each query,and Table 3 shows the overall precision.
Thecolumns in Tables 2 and 3 show the precisionof appropriateness for the top 3, top 5, andtop 10 summaries produced by each method.It should be noted that there are only a fewpassages suitable for mediatory summary inall of the retrieved documents, and thereforea method for placing such suitable passages ata higher rank is more effective.
We confirmedthat the proposed method provided the bestoverall results among all the compared meth-ods.The difference between the proposedmethod and KWtf shows that classificationof frequent words into positive keywords, neg-ative ones, and others, in other words, the fair-ness described in Section 2 contributed to gen-eration of appropriate mediatory summaries.The difference between LinTSU andLinscF IN indicates that the order of thescore scFIN () described in Section 3.5 wasdifferent from that of the score of TSUB-AKI.
Lingua::JA::Summarize::Extract couldnot extract the appropriate passages from7We use precision, which represents #correct out-puts/#total outputs, as an evaluation measure becauseit is difficult to calculate the recall of the mediatorysummaries that are dynamically generated from Webdocuments and because users tend to read just a fewof the summaries generated by the system.document sets on the basis of scFIN(), eventhough the document sets contained the sameappropriate passages that were extracted bythe proposed method.
Therefore, summa-rization for a general purpose is insufficientfor generation of mediatory summaries, andthe proposed method can provide moreappropriate mediatory summaries.However, the results of the queries ?Is catchand release a better way of fishing??
and?Does carbon dioxide cause global warming?
?in Table 2 show that the proposed methodcould not extract all the appropriate passagesthat were extracted by LinTSU .
We aim to im-prove the proposed method in future research.5 ConclusionWe proposed a method for automated genera-tion of mediatory summaries in order to facil-itate users?
assessment of the credibility of in-formation on the Web.
A mediatory summaryis generated by extracting a passage from Webdocuments on the basis of their relevance toa given query, fairness, and density of key-words, which are features of the summariesconstructed to determine the credibility of in-formation on the Web.
We demonstrated theeffectiveness of the generated mediatory sum-mary in comparison with the summaries ofWeb documents produced by Web search en-gines.AcknowledgementThis research is partially supported by the Na-tional Institute of Information and Communi-cations Technology, Japan.ReferencesJuffinger, Andreas, Michael Granitzer, and Elisa-beth Lex.
2009.
Blog credibility ranking by ex-ploiting verified content.
In Proceedings of theSecond Workshop on Information Credibility onthe Web (WICOW 2009), pages 51?57.Kaneko, Koichi, Hideyuki Shibuki, MasahiroNakano, Rintaro Miyazaki, Madoka Ishioroshi,and Tatsunori Mori.
2009.
Mediatory summary1147generation: Summary-passage extraction for in-formation credibility on the web.
In Proceed-ings of the 23rd Pacific Asia Conference on Lan-guage, Information and Computation (PACLIC23), pages 240?249.Kawahara, Daisuke, Tetsuji Nakagawa, TakuyaKawada, Kentaro Inui, and Sadao Kurohashi.2009.
Summarizing evaluative information onthe web for information credibility analysis.
InProceedings of the 3rd International Univer-sal Communication Symposium (IUCS 2009),pages 187?192.Lin, Chin-Yew and Eduard Hovy.
2003.
Au-tomatic evaluation of summaries using n-gramco-occurrence statistics.
In Proceedings of theHuman Language Technology Conference 2003(HLT-NAACL-2003), pages 71?78.Miyazaki, Rintaro, Ryo Momose, HideyukiShibuki, and Tatsunori Mori.
2009.
Usingweb page layout for extraction of sender names.In Proceedings of the 3rd International Univer-sal Communication Symposium (IUCS 2009),pages 181?186.Murakami, Koji, Eric Nichols, Suguru Matsuyoshi,Asuka Sumida, Shouko Masuda, Kentaro Inui,and Yuji Matsumoto.
2009.
Statement map:Assisting information credibility analysis by vi-sualizing arguments.
In Proceedings of the Sec-ond Workshop on Information Credibility on theWeb (WICOW 2009), pages 43?50.Nakano, Masahiro, Hideyuki Shibuki, RintaroMiyazaki, Madoka Ishioroshi, Koichi Kaneko,and Tatsunori Mori.
2010.
Construction of textsummarization corpus for the credibility of in-formation from the web.
In Proceedings of the7th Language Resources and Evaluation Confer-ence (LREC 2010), pages 3125?3131.Ohshima, Hiroaki, Satoshi Oyama, HiroyukiKondo, and Katsumi Tanaka.
2009.
Web infor-mation credibility analysis by geographical so-cial support.
In Proceedings of the 3rd Inter-national Universal Communication Symposium(IUCS 2009), pages 193?196.Shinzato, Keiji, Tomohide Shibata, Daisuke Kawa-hara, Chikara Hashimoto, and Sadao Kuro-hashi.
2008.
Tsubaki: An open search en-gine inflastructure for developing new informa-tion access methodology.
In Proceedings of theThird International Joint Conference on Natu-ral Language Processing (IJCNLP 2008), pages189?196.1148
