INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 125?127,Utica, May 2012. c?2012 Association for Computational LinguisticsNatural Language Generation for a Smart Biology TextbookEva Banik1, Eric Kow1, Vinay Chaudhri2, Nikhil Dinesh2, and Umangi Oza31{ebanik,kowey}@comp-ling.co.uk, Computational Linguistics Ltd, London, UK2 {chaudhri,dinesh}@ai.sri.com, SRI International, Menlo Park, CA3umangi.oza@evalueserve.com, Evaluserve, New Delhi, India1 Application ContextIn this demo paper we describe the natural lan-guage generation component of an electronictextbook application, called Inquire1.
Inquireinteracts with a knowledge base which encodesinformation from a biology textbook.
Theapplication includes a question-understandingmodule which allows students to ask questionsabout the contents of the book, and a question-answering module which retrieves the corre-sponding answer from the knowledge base.
Thetask of the natural language generation mod-ule is to present specific parts of the answer inEnglish.
Our current generation pipeline han-dles inputs that describe the biological func-tions of entities, the steps of biological processes,and the spatial relations between parts of enti-ties.
Our ultimate goal is to generate paragraph-length texts from arbitrary paths in the knowl-edge base.
We describe here the natural lan-guage generation pipeline and demonstrate theinputs and generated texts.
In the demo pre-sentation we will show the textbook applicationand the knowledge base authoring environment,and provide an opportunity to interact with thesystem.2 The Knowledge BaseThe knowledge base contains information froma college-level biology textbook2, encoded by bi-1The work described in this paper and presented inthe demo is funded by Vulcan Inc.2 Reece et al 2010.
Campbell biology.
PearsonPublishing.ologists as part of project HALO at SRI3.
Thecore of the knowledge base is the CLIB ontol-ogy4, which is extended with biology-specific in-formation.
The knowledge base encodes entity-to-event relations (similar to thematic roles inlinguistics), event-to-event relations (discourserelations), various property values and relationsbetween properties, spatial relations, cardinalityconstraints, and roles that participants play inevents.
The input to the generation pipeline is aset of triples extracted from the biology knowl-edge base.
Currently our content selection in-cludes either an event and the entities that par-ticipate in the event, or a set of entities andspatial relations between them.3 Generation Grammar and LexiconOur generation grammar consists of a set of TreeAdjoining Grammar (TAG) elementary trees.Each tree is associated with either a single rela-tion, or a set of relations in the knowledge base.As an example, Fig 1 illustrates the mappingbetween elementary trees and event participantrelations in the KB for the above input.
Wecurrently associate up to three different elemen-tary trees with each event and the connectedset of participant relations: an active senten-tial tree, a passive sentential tree and a complexnoun phrase.The knowledge base provides concept-to-word3 Gunning Et al, 2010.
Project halo updateprogress toward digital aristotle.
AI Magazine Fall:33-58.
See also http://www.projecthalo.com/4http://www.cs.utexas.edu/users/mfkb/RKF/clib.html125Figure 1: The grammar of the surface realizermappings (a list of synonyms) for every concept,and the words are used in the generation lexi-con to anchor elementary TAG trees.
Our gen-eration grammar consists of a set of TAG treetemplates, which are defined as combinations oftree fragments and are compiled using the XMGmetgrammar toolkit5.These underspecified elementary trees are fur-ther specified in the generation lexicon, whichmaps concepts onto elementary tree templates,and associates a word (an anchor) with thetree, along with other idiosynchratic information(e.g., preposition choice).
We create a genera-tion lexicon dynamically at run-time, by map-ping tree templates onto concepts based on thenumber and types of participants, and the lexi-cal information associated with the event (e.g.,the preposition requirements of the verb).Concept names for entities are included inthe elementary trees as features on the corre-sponding NP nodes.
These features form partof the input to the referring expression genera-tion module, which looks up the concept name5https://sourcesup.renater.fr/xmg/in the concept-to-word mapping to obtain a listof possible noun phrases.4 RealizationOur natural language generation pipeline is cen-tered around the GenI surface realizer6,7.
Theset of triples yielded by content selection are firstaggregated and converted to GenI?s input for-mat, a set of flat semantic literals.
We then feedthis input to GenI to produce an underspecifiedsurface form in which referring expressions arestill underspecified:NP is detach from NP resulting in NP at NPNP detach from NP resulting in NP at NPDetachment of NP from NP resulting in NP at NPA post-processing module carries out refer-ring expression generation and morphological re-alization to produce the fully specified output.6 Kow, Eric.
2007.
Surface realisation: ambiguityand determinism.
Doctoral Dissertation, Universite deHenri Poincare - Nancy 1.7 Banik, Eva 2010.
A minimalist approach to gen-erating coherent texts.
Phd thesis, Department of Com-puting, The Open University126Question Answering & Reasoning AlgorithmsEvent InstanceContent SelectionSet of triplesInput aggregation and conversion +Stylistic controlKnowledge BaseRealization with GenIMorphology &referring expression generationSemantic literals +input parametersRankingUnderspecified realizationsLinguistic ResourcesGeneration LexiconGrammar: Description of TAG tree templatesConcept-to-WordmappingsMapping of KB relationsto TAG tree templatesMorphological lexiconVerb frames (preposition choice)NLG PipelineFigure 2: Linguistic resources and the generation pipelineOur referring expression realization algorithmperforms further semantic aggregation wherenecessary to produce cardinals (?two chromo-somes?
), and decides on a suitable determinerbased on previous mentions of instance namesand subclasses in the discourse context (def-inite/indefinite determiner, ?another?
or ?thesame?).
For the input shown in Fig 1, our sys-tem will produce the following three realizations:1.
A sister chromatid detaches from another sister chro-matid resulting in two chromosomes at a kinetochore.2.
A sister chromatid is detached from another sisterchromatid resulting in two chromosomes at a kinetochore.3.
Detachment of a sister chromatid from another sisterchromatid resulting in two chromosomes at a kinetochoreWe rank the generated outputs based on theirlinguistic properties using optimality theoreticconstraints (e.g., active sentences are rankedabove passive sentences), where each constraintcorresponds to a (set of) tree fragments thatcontributed to building the tree that appears inthe output.
Our system also allows for extra in-put parameters to be sent to GenI to restrict theset of generated outputs to fit a specific context(e.g., syntactic type or focused discourse entity).Our full natural language generation pipeline isillustrated in Fig 2.5 Future WorkWe are currently working on extending the sys-tem to handle more relations and other datatypes in the knowledge base.
This involves ex-tending the grammar to new sentence types andother linguistic constructions, and extending thecontent selection module to return more triplesfrom the knowledge base.
Our ultimate goal isto be able to generate arbitrary ?
but in somesense well-formed ?
paths from the knowledgebase as coherent paragraphs of text.127
