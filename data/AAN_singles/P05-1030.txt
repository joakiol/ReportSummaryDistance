Proceedings of the 43rd Annual Meeting of the ACL, pages 239?246,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsImplications for Generating Clarification Requests in Task-orientedDialoguesVerena RieserDepartment of Computational LinguisticsSaarland UniversitySaarbru?cken, D-66041vrieser@coli.uni-sb.deJohanna D. MooreSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9LW, GBJ.Moore@ed.ac.ukAbstractClarification requests (CRs) in conversa-tion ensure and maintain mutual under-standing and thus play a crucial role inrobust dialogue interaction.
In this pa-per, we describe a corpus study of CRsin task-oriented dialogue and compare ourfindings to those reported in two priorstudies.
We find that CR behavior intask-oriented dialogue differs significantlyfrom that in everyday conversation in anumber of ways.
Moreover, the dialoguetype, the modality and the channel qual-ity all influence the decision of when toclarify and at which level of the ground-ing process.
Finally we identify form-function correlations which can inform thegeneration of CRs.1 IntroductionClarification requests in conversation ensure andmaintain mutual understanding and thus play a sig-nificant role in robust and efficient dialogue interac-tion.
From a theoretical perspective, the model ofgrounding explains how mutual understanding is es-tablished.
According to Clark (1996), speakers andlisteners ground mutual understanding on four lev-els of coordination in an action ladder, as shown inTable 1.Several current research dialogue systems can de-tect errors on different levels of grounding (Paekand Horvitz, 2000; Larsson, 2002; Purver, 2004;Level Speaker S Listener LConvers.
S is proposing activity?L is considering pro-posal ?Intention S is signalling that p L is recognizing that pSignal S is presenting signal ?
L is identifying signal?Channel S is executing behavior?L is attending to behav-ior ?Table 1: Four levels of groundingSchlangen, 2004).
However, only the work ofPurver (2004) addresses the question of how thesource of the error affects the form the CR takes.In this paper, we investigate the use of form-function mappings derived from human-human di-alogues to inform the generation of CRs.
We iden-tify the factors that determine which function a CRshould take and identify function-form correlationsthat can be used to guide the automatic generationof CRs.In Section 2, we discuss the classificationschemes used in two recent corpus studies of CRsin human-human dialogue, and assess their applica-bility to the problem of generating CRs.
Section 3describes the results we obtained by applying theclassification scheme of Rodriguez and Schlangen(2004) to the Communicator Corpus (Bennett andRudnicky, 2002).
Section 4 draws general conclu-sions for generating CRs by comparing our resultsto those of (Purver et al, 2003) and (Rodriguez andSchlangen, 2004).
Section 5 describes the correla-tions between function and form features that arepresent in the corpus and their implications for gen-erating CRs.239Attr.
Value Category Exampleform non Non-Reprise ?What did you say?
?wot Conventional ?Sorry?
?frg Reprise Fragment ?Edinburgh?
?lit Literal Reprise ?You want a flight to Edinburgh?
?slu Reprise Sluice ?Where?
?sub Wh-substituted Reprise ?You want a flight where?
?gap Gap ?You want a flight to...?
?fil Gap Filler ?...Edinburgh?
?other Other xreadings cla Clausal ?Are you asking/asserting that X?
?con Constituent ?What do you mean by X?
?lex Lexical ?Did you utter X?
?corr Correction ?Did you intend to utter X instead?
?other Other xTable 2: CR classification scheme by PGH2 CR Classification SchemesWe now discuss two recently proposed classifica-tion schemes for CRs, and assess their usefulness forgenerating CRs in a spoken dialogue system (SDS).2.1 Purver, Ginzburg and Healey (PGH)Purver, Ginzburg and Healey (2003) investigatedCRs in the British National Corpus (BNC) (Burnard,2000).
In their annotation scheme, a CR can takeseven distinct surface forms and four readings, asshown in Table 2.
The examples for the form featureare possible CRs following the statement ?I want aflight to Edinburgh?.
The focus of this classificationscheme is to map semantic readings to syntactic sur-face forms.
The form feature is defined by its rela-tion to the problematic utterance, i.e., whether a CRreprises the antecedent utterance and to what extent.CRs may take the three different readings as definedby Ginzburg and Cooper (2001), as well as a fourthreading which indicates a correction.Although PGH report good coverage of thescheme on their subcorpus of the BNC (99%), wefound their classification scheme to to be too coarse-grained to prescribe the form that a CR should take.As shown in example 1, Reprise Fragments (RFs),which make up one third of the BNC, are ambigu-ous in their readings and may also take several sur-face forms.
(1) I would like to book a flight on Monday.
(a) Monday?frg, con/cla(b) Which Monday?frg, con(c) Monday the first?frg, con(d) The first of May?frg, con(e) Monday the first or Monday the eighth?frg, (exclusive) conRFs endorse literal repetitions of part of the prob-lematic utterance (1.a); repetitions with an addi-tional question word (1.b); repetition with furtherspecification (1.c); reformulations (1.d); and alter-native questions (1.e)1.In addition to being too general to describe suchdifferences, the classification scheme also fails todescribe similarities.
As noted by (Rodriguez andSchlangen, 2004), PGH provide no feature to de-scribe the extent to which an RF repeats the prob-lematic utterance.Finally, some phenomena cannot be described atall by the four readings.
For example, the readingsdo not account for non-understanding on the prag-matic level.
Furthermore the readings may have sev-eral problem sources: the clausal reading may beappropriate where the CR initiator failed to recog-nise the word acoustically as well as when he failedto resolve the reference.
Since we are interested ingenerating CRs that indicate the source of the error,we need a classification scheme that represents suchinformation.2.2 Rodriguez and Schlangen (R&S)Rodriguez and Schlangen (2004) devised a multi-dimensional classification scheme where form and1Alternative questions would be interpreted as asking a polarquestion with an exclusive reading.240function are meta-features taking sub-features as at-tributes.
The function feature breaks down intothe sub-features source, severity, extent, reply andsatisfaction.
The sources that might have causedthe problem map to the levels as defined by Clark(1996).
These sources can also be of differentseverity.
The severity can be interpreted as de-scribing the set of possible referents: asking forrepetition indicates that no interpretation is avail-able (cont-rep); asking for confirmation meansthat the CR initiator has some kind of hypothesis(cont-conf).
The extent of a problem describeswhether the CR points out a problematic element inthe problem utterance.
The reply represents the an-swer the addressee gives to the CR.
The satisfactionof the CR-initiator is indicated by whether he renewsthe request for clarification or not.The meta-feature form describes how the CR islingustically realised.
It describes the sentence?smood, whether it is grammatically complete, the re-lation to the antecedent, and the boundary tone.
Ac-cording to R&S?s classification scheme our illustra-tive example would be annotated as follows2:(2) I would like to book a flight on Monday.
(a) Monday?mood: declcompleteness: partialrel-antecedent: repetsource: acous/np-refseverity: cont-repetextent: yes(b) Which Monday?mood: wh-questioncompleteness: partialrel-antecedent: additionsource: np-refseverity: cont-repetextent: yes(c) Monday the first?mood: declcompleteness: partialrel-antecedent: additionsource: np-refseverity: cont-confextent: yes(d) The first of May?mood: declcompleteness: partial2The source features answer and satisfaction are ignored asthey depend on how the dialogue continues.
The interpretationof the source is dependent on the reply to the CR.
Therefore allpossible interpretations are listed.rel-antecedent: reformulsource: np-refseverity: cont-confextent: yes(d) Monday the first or Monday the eighth?mood: alt-qcompleteness: partialrel-antecedent: additionsource: np-refseverity: cont-repetextent: yesIn R&S?s classification scheme, ambiguitiesabout CRs having different sources cannot be re-solved entirely as example (2.a) shows.
However,in contrast to PGH, the overall approach is a differ-ent one: instead of explaining causes of CRs withina theoretic-semantic model (as the three differentreadings of Ginzburg and Cooper (2001) do), theyinfer the interpretation of the CR from the context.Ambiguities get resolved by the reply of the ad-dressee and the satisfaction of the CR initiator in-dicates the ?mutually agreed interpretation?
.R&S?s multi-dimensional CR description allowsthe fine-grained distinctions needed to generate nat-ural CRs to be made.
For example, PGH?s generalcategory of RFs can be made more specific via thevalues for the feature relation to antecedent.
In ad-dition, the form feature is not restricted to syntax; itincludes features such as intonation and coherence,which are useful for generating the surface form ofCRs.
Furthermore, the multi-dimensional functionfeature allows us to describe information relevant togenerating CRs that is typically available in dialoguesystems, such as the level of confidence in the hy-pothesis and the problem source.3 CRs in the Communicator Corpus3.1 Material and MethodMaterial: We annotated the human-human travelreservation dialogues available as part of theCarnegie Mellon Communicator Corpus (Bennettand Rudnicky, 2002) because we were interestedin studying naturally occurring CRs in task-orienteddialogue.
In these dialogues, an experienced travelagent is making reservations for trips that people inthe Carnegie Mellon Speech Group were taking inthe upcoming months.
The corpus comprises 31 di-alogues of transcribed telephone speech, with 2098dialogue turns and 19395 words.241??????????????????????form:??????
?distance-src:{1 | 2 | 3 | 4 | 5 | more}mood:{none | decl | polar-q | wh-q | alt-q | imp | other}form:{none | particle | partial | complete}relation-antecedent:{none | add | repet | repet-add | reformul | indep}boundary-tone:{none | rising | falling | no-appl}???????function:????????
?source:{none | acous | lex | parsing | np-ref | deitic-ref | act-ref |int+eval | relevance | belief | ambiguity | scr-several}extent:{none | fragment | whole}severity:{none | cont-conf | cont-rep | cont-disamb | no-react}answer:{none | ans-repet | ans-y/n | ans-reformul | ans-elab |ans-w-defin | no-react}satisfaction:{none | happy-yes | happy-no | happy-ambig}??????????????????????????????
?Figure 1: CR classification schemeAnnotation Scheme: Our annotation scheme,shown in Figure 1, is an extention of the R&Sscheme described in the previous section.
R&S?sscheme was devised for and tested on the BielefeldCorpus of German task-oriented dialogues aboutjoint problem solving.3 To annotate the Commu-nicator Corpus we extended the scheme in the fol-lowing ways.
First, we found the need to distin-guish CRs that consist only of newly added infor-mation, as in example 3, from those that add in-formation while also repeating part of the utteranceto be clarified, as in 4.
We augmented the schemeto allow two distinct values for the form featurerelation-antecedent, add for cases like 3and repet-add for cases like 4.
(3) Cust: What is the last flight I could come back on?Agent: On the 29th of March?
(4) Cust: I?ll be returning on Thursday the fifth.Agent: The fifth of February?To the function feature source we added the val-ues belief to cover CRs like 5 and ambiguityrefinement to cover CRs like 6.
(5) Agent: You need a visa.Cust: I do need one?Agent: Yes you do.
(6) Agent: Okay I have two options .
.
.
with Hertz .
.
.
if notthey do have a lower rate with Budget and that isfifty one dollars.Cust: Per day?Agent: Per day um mm.Finally, following Gabsdil (2003) we introducedan additional value for severity, cont-disamb, to3http://sfb360.uni-bielefeld.decover CRs that request disambiguation when morethan one interpretation is available.Method: We first identified turns containing CRs,and then annotated them with form and function fea-tures.
It is not always possible to identify CRs fromthe utterance alone.
Frequently, context (e.g., thereaction of the addressee) or intonation is requiredto distinguish a CR from other feedback strategies,such as positive feedback.
See (Rieser, 2004) for adetailed discussion.
The annotation was only per-formed once.
The coding scheme is a slight varia-tion of R&S, which has been shown relaiable withKappa of 0.7 for identifying source.3.2 Forms and Functions of CRs in theCommunicator CorpusThe human-human dialogues in the Communica-tor Corpus contain 98 CRs in 2098 dialogue turns(4.6%).Forms: The frequencies for the values of theindividual form features are shown in Table 3.The most frequent type of CRs were partialdeclarative questions, which combine the moodvalue declarative and the completeness valuepartial.4 These account for 53.1% of the CRsin the corpus.
Moreover, four of the five mostfrequent surface forms of CRs in the Communi-cator Corpus differ only in the value for the fea-ture relation-antecedent.
They are partialdeclaratives with rising boundary tone, that either re-formulate (7.1%) the problematic utterance, repeat4Declarative questions cover ?all cases of non-interrogativeword-order, i.e., both declarative sentences and fragments?
(Ro-driguez and Schlangen, 2004).242Feature Value Freq.
(%)Mood declarative 65polar 21wh-question 7other 7Completeness partial 58complete 38other 4Relation antecedent rep-add 27independent 21reformulation 19repetition 18addition 10other 5Boundary tone rising 74falling 22other 4Table 3: Distribution of values for the form featuresthe problematic constituent (11.2%), add only newinformation (7.1%), or repeat the problematic con-stituent and add new information (10.2%).
The fifthmost frequent type is conventional CRs (10.2%).5Functions: The distributions of the function fea-tures are given in Figure 4.
The most frequent sourceof problems was np-reference.
Next most frequentwere acoustic problems, possibly due to the poorchannel quality.
Third were CRs that enquire aboutintention.
As indicated by the feature extent, al-most 80% of CRs point out a specific element ofthe problematic utterance.
The features severity andanswer illustrate that most of the time CRs requestconfirmation of an hypothesis (73.5%) with a yes-no-answer (64.3%).
The majority of the providedanswers were satisfying, which means that the ad-dressee tends to interpret the CR correctly and an-swers collaboratively.
Only 6.1% of CRs failed toelicit a response.4 CRs in Task-oriented Dialogue4.1 ComparisonIn order to determine whether there are differencesas regards CRs between task-oriented dialogues andeveryday conversations, we compared our results tothose of PGH?s study on the BNC and those of R&S5Conventional forms are ?Excuse me?
?, ?Pardon?
?, etc.Feature Value Freq.
(%)Source np-reference 40acoustic 31intention 8belief 6ambiguity 4contact 4others 3relevance 2several 2Extent yes 80no 20Severity confirmation 73repetition 20other 7Answer y/n answer 64other 15elaboration 13no reaction 6Table 4: Distribution of values for the function fea-tureson the Bielefeld Corpus.
The BNC contains a 10million word sub-corpus of English dialogue tran-scriptions about topics of general interest.
PGHanalysed a portion consisting of ca.
10,600 turns,ca.
150,000 words.
R&S annotated 22 dialoguesfrom the Bielefeld Corpus, consisting of ca.
3962turns, ca.
36,000 words.The major differences in the feature distributionsare listed in Table 5.
We found that there are nosignificant differences between the feature distri-butions for the Communicator and Bielefeld cor-pora, but that the differences between Communica-tor and BNC, and Bielefeld and BNC are significantat the levels indicated in Table 5 using Pearson?s?2.
The differences between dialogues of differ-ent types suggest that there is a different groundingstrategy.
In task-oriented dialogues we see a trade-off between avoiding misunderstanding and keepingthe conversation as efficient as possible.
The hy-pothesis that grounding in task-oriented dialogues ismore cautious is supported by the following facts (asshown by the figures in Table 5):?
CRs are more frequent in task-oriented dia-logues.?
The overwhelming majority of CRs directlyfollow the problematic utterance.243CorpusFeature Communicator Bielefeld BNCCRs 98 230 418frequency 4.6% 5.8%*** 3.9%distance-src=1 92.8%* 94.8%*** 84.4%no-react 6.1%* 8.7%** 17.0%cont-conf 73.5%*** 61.7%*** 46.6%partial 58.2%** 76.5%*** 42.4%independent 21.4%*** 9.6%*** 44.2%cont-rep 19.8%*** 14.8%*** 39.5%y/n-answer 64.3% 44.8% n/aTable 5: Comparison of CR forms in everyday vs. task-oriented corpora (* denotes p < .05, ** is p < .01, *** isp < .005.)?
CRs in everyday conversation fail to elicit a re-sponse nearly three times as often.6?
Even though dialogue participants seem tohave strong hypotheses, they frequently con-firm them.Although grounding is more cautious in task-oriented dialogues, the dialogue participants try tokeep the dialogue as efficient as possible:?
Most CRs are partial in form.?
Most of the CRs point out one specific element(with only a minority being independent asshown in Table 5).
Therefore, in task-orienteddialogues, CRs locate the understanding prob-lem directly and give partial credit for what wasunderstood.?
In task-oriented dialogues, the CR-initiatorasks to confirm an hypothesis about what heunderstood rather than asking the other dia-logue participant to repeat her utterance.?
The addressee prefers to give a short y/n answerin most cases.Comparing error sources in the two task-orientedcorpora, we found a number of differences as shownin Table 6.
In particular:6Another factor that might account for these differences isthat the BNC contains multi-party conversations, and questionsin multi-party conversations may be less likely to receive re-sponses.
Furthermore, due to the poor recording quality of theBNC, many utterances are marked as ?not interpretable?, whichcould also lower the response rate.CorpusFeature Communicator Bielefeld Significancecontact 4.1% 0 inst n/aacoustic 30.6% 11.7% ***lexical 1 inst 1 inst n/aparsing 1 inst 0 inst n/anp-ref 39.8% 24.4% **deict-ref 1 inst 27.4% ***ambiguity 4.1% not eval.
n/abelief 6.1% not eval.
n/arelevance 2.1% not eval.
n/aintention 8.2% 22.2% **several 2.0% 14.3% ***Table 6: Comparison of CR problem sources in task-orientedcorpora?
Dialogue type: Belief and ambiguity refine-ment do not seem to be a source of problemsin joint problem solving dialogues, as R&S didnot include them in their annotation scheme.For CRs in information seeking these featuresneed to be added to explain quite frequent phe-nomena.
As shown in Table 6, 10.2% of CRswere in one of these two classes.?
Modality: Deictic reference resolution causesmany more understanding difficulties in dia-logues where people have a shared point ofview than in telephone communication (Biele-feld: most frequent problem source; Communi-cator: one instance detected).
Furthermore, inthe Bielefeld Corpus, people tend to formulatemore fragmentary sentences.
In environmentswhere people have a shared point of view, com-plete sentences can be avoided by using non-verbal communication channels.
Finally, wesee that establishing contact is more of a prob-lem when speech is the only modality available.?
Channel quality: Acoustic problems are muchmore likely in the Communicator Corpus.These results indicate that the decision process forgrounding needs to consider the modality, the do-main, and the communication channel.
Similar ex-tensions to the grounding model are suggested by(Traum, 1999).2444.2 Consequences for GenerationThe similarities and differences detected can beused to give recommendations for generating CRs.In terms of when to initiate a CR, we can statethat clarification should not be postponed, and im-mediate, local management of uncertainty is criti-cal.
This view is also supported by observations ofhow non-native speakers handle non-understanding(Paek, 2003).Furthermore, for task-oriented dialogues the sys-tem should present an hypothesis to be confirmed,rather than ask for repetition.
Our data suggests that,when they are confronted with uncertainty, humanstend to build up hypotheses from the dialogue his-tory and from their world knowledge.
For example,when the customer specified a date without a month,the travel agent would propose the most reasonablehypothesis instead of asking a wh-question.
It is in-teresting to note that Skantze (2003) found that usersare more satisfied if the system ?hides?
its recog-nition problem by asking a task-related question tohelp to confirm the hypothesis, rather than explicitlyindicating non-understanding.5 Correlations between Function andForm: How to say it?Once the dialogue system has decided on the func-tion features, it must find a corresponding surfaceform to be generated.
Many forms are indeed re-lated to the function as shown in Table 7, where wepresent a significance analysis using Pearson?s ?2(with Yates correction).Source: We found that the relation to the an-tecedent seems to distinguish fairly reliably be-tween CRs clarifying reference and those clarify-ing acoustic understanding.
In the CommunicatorCorpus, for acoustic problems the CR-initiator tendsto repeat the problematic part literally, while refer-ence problems trigger a reformulation or a repeti-tion with addition.
For both problem sources, par-tial declarative questions are preferred.
These find-ings are also supported by R&S.
For the first levelof non-understanding, the inability to establish con-tact, complete polar questions with no relation to theantecedent are formulated, e.g., ?Are you there?
?.Severity: The severity indicates how much wasunderstood, i.e., whether the CR initiator asks toconfirm an hypothesis or to repeat the antecedentutterance.
The severity of an error strongly cor-relates with the sentence mood.
Declarative andpolar questions, which take up material from theproblematic utterance, ask to confirm an hypothe-sis.
Wh-questions, which are independent, refor-mulations or repetitions with additions (e.g., wh-substituted reprises) of the problematic utteranceusually prompt for repetition, as do imperatives.
Al-ternative questions prompt the addressee to disam-biguate the hypothesis.Answer: By definition, certain types of questionprompt for certain answers.
Therefore, the featureanswer is closely linked to the sentence mood ofthe CR.
As polar questions and declarative ques-tions generally enquire about a proposition, i.e., anhypothesis or belief, they tend to receive yes/noanswers, but repetitions are also possible.
Wh-questions, alternative questions and imperatives tendto get answers providing additional information (i.e.,reformulations and elaborations).Extent: The function feature extent is logically in-dependent from the form feature completeness, al-though they are strongly correlated.
Extent is a bi-nary feature indicating whether the CR points outa specific element or concerns the whole utterance.Most fragmentary declarative questions and frag-mentary polar questions point out a specific element,especially when they are not independent but standin some relation to the antecedent utterance.
In-dependent complete imperatives address the wholeprevious utterance.The correlations found in the Communicator Cor-pus are fairly consistent with those found in theBielefeld Corpus, and thus we believe that the guide-lines for generating CRs in task-oriented dialoguesmay be language independent, at least for Germanand English.6 Summary and Future WorkIn this paper we presented the results of a corpusstudy of naturally occurring CRs in task-oriented di-alogue.
Comparing our results to two other stud-ies, one of a task-oriented corpus and one of a cor-245FunctionForm source severity extent answermood ?2(24) = 112.20p < 0.001?2(5) = 30.34p < 0.001?2(5) = 24.25df = p < 0.005?2(5) = 25.19p < 0.001bound-tone indep.
indep.
indep.
indep.rel-antec ?2(24) = 108.23p < 0.001?2(4) = 11.69p < 0.005?2(4) = 42.58p < 0.001indep.complete ?2(7) = 27.39p < 0.005indep.
?2(1) = 27.39p < 0.001indep.Table 7: Significance analysis for form/function correlations.pus of everyday conversation, we found no signif-icant differences in frequency of CRs and distribu-tion of forms in the two task-oriented corpora, butmany significant differences between CRs in task-oriented dialogue and everyday conversation.
Ourfindings suggest that in task-oriented dialogues, hu-mans use a cautious, but efficient strategy for clar-ification, preferring to present an hypothesis ratherthan ask the user to repeat or rephrase the problem-atic utterance.
We also identified correlations be-tween function and form features that can serve asa basis for generating more natural sounding CRs,which indicate a specific problem with understand-ing.
In current work, we are studying data collectedin a wizard-of-oz study in a multi-modal setting, inorder to study clarification behavior in multi-modaldialogue.AcknowledgementsThe authors would like thank Kepa Rodriguez, Oliver Lemon,and David Reitter for help and discussion.ReferencesChristina L. Bennett and Alexander I. Rudnicky.
2002.The Carnegie Mellon Communicator Corpus.
In Pro-ceedings of the International Conference of SpokenLanguage Processing (ICSLP02).Lou Burnard.
2000.
The British National Corpus UsersReference Guide.
Technical report, Oxford UniversiryComputing Services.Herbert Clark.
1996.
Using Language.
Cambridge Uni-versity Press.Malte Gabsdil.
2003.
Clarification in Spoken DialogueSystems.
Proceedings of the 2003 AAAI Spring Sym-posium.
Workshop on Natural Language Generation inSpoken and Written Dialogue.Jonathan Ginzburg and Robin Cooper.
2001.
ResolvingEllipsis in Clarification.
In Proceedings of the 39thmeeting of the Association for Computational Linguis-tics.Staffan Larsson.
2002.
Issue-based Dialogue Manage-ment.
Ph.D. thesis, Goteborg University.Tim Paek and Eric Horvitz.
2000.
Conversation as Ac-tion Under Uncertainty.
In Proceedings of the Six-teenth Conference on Uncertainty in Artificial Intelli-gence.Tim Paek.
2003.
Toward a Taxonomy of Communica-tion Errors.
In ISCA Tutorial and Research Workshopon Error Handling in Spoken Dialogue Systems.Matthew Purver, Jonathan Ginzburg, and Patrick Healey.2003.
On the Means for Clarification in Dialogue.
InR.
Smith and J. van Kuppevelt, editors, Current andNew Directions in Discourse and Dialogue.Matthew Purver.
2004.
CLARIE: The Clarification En-gine.
In Proceedings of the Eighth Workshop on For-mal Semantics and Dialogue.Verena Rieser.
2004.
Fragmentary Clarifications on Sev-eral Levels for Robust Dialogue Systems.
Master?sthesis, School of Informatics, University of Edinburgh.Kepa J. Rodriguez and David Schlangen.
2004.
Form,Intonation and Function of Clarification Requests inGerman Task-orientaded Spoken Dialogues.
In Pro-ceedings of the Eighth Workshop on Formal Semanticsand Dialogue.David Schlangen.
2004.
Causes and Strategies for Re-question Clarification in Dialogue.
Proceedings of the5th SIGdial Workshop on Discourse and Dialogue.Gabriel Skantze.
2003.
Exploring Human Error Han-dling Strategies: Implications for Spoken DialogueSystems.
In ISCA Tutorial and Research Workshopon Error Handling in Spoken Dialogue Systems.David R. Traum.
1999.
Computational Models ofGrounding in Collaborative Systems.
In Proceedingsof the AAAI Fall Symposium on Psychological Modelsof Communication.246
