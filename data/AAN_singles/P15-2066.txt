Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 402?407,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsPainless Labeling with Application to Text MiningSajib DasguptaChittagong Indepedent UniversityChittagong, Bangladeshsdgnew@gmail.comAbstractLabeled data is not readily available formany natural language domains, and ittypically requires expensive human effortwith considerable domain knowledge toproduce a set of labeled data.
In this paper,we propose a simple unsupervised systemthat helps us create a labeled resource forcategorical data (e.g., a document set) us-ing only fifteen minutes of human input.We utilize the labeled resources to dis-cover important insights about the data.The entire process is domain independent,and demands no prior annotation samples,or rules specific to an annotation.1 IntroductionConsider the following two scenarios:Scenario 1: We start processing a new languageand we want to get an initial idea of the languagebefore embarking on the expensive process of cre-ating hand annotated resources.
For instance, wemay want to know how people express opinion ina language of interest, what characterizes the sub-jective content of the language and how expres-sions of opinion differ along opinion types.
Thequestion is how to acquire such first-hand insightsof an unknown language in quick time and withminimal human effort?Scenario 2: We have a set of blog articles andwe are interested in learning how blogging differsacross gender.
In particular, we seek to learn thewriting styles or other indicative patterns ?
topicsof interest, word choices etc.
?
that can potentiallydistinguish writings across gender.
A traditionalNLP approach would be to collect a set of articlesthat are tagged with gender information, which wecan then input to a learning system to learn pat-terns that can differentiate gender.
What if no suchannotation is available, as the bloggers don?t re-veal their gender information?
Could we arrangea human annotation task to annotate the articlesalong gender?
Often the articles contain explicitpatterns (e.g., ?my boyfriend?, ?as a woman?
etc.
)which help the annotators to annotate the articles.Often there are no indicative patterns in the writ-ten text, and it becomes impossible to annotate thearticles reliably.The above scenarios depict the cases when weare resource constrained and creating a new re-source is nontrivial and time consuming.
Givensuch difficulties, it would be helpful if we coulddesign a system that requires less human input tocreate a labeled resource.
In this paper, we presenta simple unsupervised system that helps us cre-ate a labeled resource with minimal human effort.The key to our method is that instead of label-ing the entire set of unlabeled instances the sys-tem labels a subset of data instances for which itis confident to achieve high level of accuracy.
Weexperiment with several document labeling tasksand show that a high-quality labeled resource canbe produced by a clustering-based labeling systemthat requires a mere fifteen minutes of human in-put.
It achieves 85% and 78% accuracy for the taskof sentiment and gender classification, showing itseffectiveness on two nontrivial labeling tasks withdistinct characteristics (see Section 3).We also utilize the labeled resources created byour system to learn discriminative patterns thathelp us gain insights into a dataset.
For instance,we learn how users generally express opinion in alanguage of interest, and how writing varies acrossgender.
The next section describes the details ofour main algorithm.
We present experimental re-sults in Section 3 and 4.402The sound from my system did seem to be a little better(the CD?s were not skipping as much).But the bottom line is it didn?t fix the problem asthe CDs are still skipping noticeably,although not as bad as before.
..Table 1: Snippet of an ambiguous CD Player re-view.2 Problem FormulationWe consider a general classification framework.Let X = {x1, .
.
.
, xn} represents a categoricaldataset with n data points where xi?
?d.
Letcx?
{1,-1} is the true label of x1.
Our goal islabel a subset of the data, X ?
= {C1, C2} ?
X,where C1and C2comprise data points of positiveand negative class respectively.
Note that, X ?
rep-resents the subset of datapoints that are confidentlylabeled by the system.To illustrate, we show a snippet of a CD playerreview taken from Amazon in Table 1.
As you cansee this review is highly ambiguous, as it describesboth the positive and negative aspects of the prod-uct: while the phrases a little better, not skipping,and not as bad conveys a positive sentiment, thephrases didn?t fix and skipping noticeably are neg-ative sentiment-bearing.
Any automated systemwould find it hard to correctly label this review,as the review is highly ambiguous.
Our goal is toremove such ambiguous data points from the dataspace and label the remaining unambiguous datapoints.
The fact that unambiguous data instancesare easier to label allows us to use an automatedsystem to label them quickly with minimal humaneffort (see the next section).Now how could we set apart unambiguous datapoints from the ambiguous ones from a set of unla-beled data points?
Note that we desire the systemto be unsupervised.
We also desire the system tobe generic i.e., applicable to any application do-main.
Next we show how we extend spectral clus-tering to achieve this goal.2.1 Ambiguity Resolution with IterativeSpectral ClusteringIn spectral clustering, a set of n data points is rep-resented as an undirected graph, where each nodecorresponds to a data point and the edge weightbetween two nodes is their similarity as definedby S. The goal is to induce a clustering, or equiv-alently, a partitioning function f , which is typi-cally represented as a vector of length n such that1We present our system for binary classification task.
Itcan be extended fairly easily to multi-way classification tasks.f(i) ?
{1, ?1} indicates which of the two clustersdata point i should be assigned to.In spectral clustering, the normalized cut parti-tion of a similarity graph, S is derived from thesolution of the following constrained optimizationproblem: argminf?
?n?i,jSi,j(f(i)?di?f(j)?dj)2subject to fTDf = 1 and Df ?
1, whereD is a diagonal matrix with Di,i=?jSi,janddi= Di,i.
The closed form solution to this opti-mization problem is the eigenvector correspondingto the second smallest eigenvalue of the Laplacianmatrix, L = D?1/2(D ?
S)D?1/2 (Shi and Ma-lik (2000)).
Clustering using the second eigenvec-tor, is trivial: since we have a linearization of thepoints, all we need to do is to determine a thresh-old for partitioning the data points.Second eigenvector reveals useful informationregarding the ambiguity of the individual datapoints.
In the computation of eigenvectors eachdata point factors out orthogonal projections ofeach of the neighboring data points.
Ambigu-ous data points factor out orthogonal projectionsfrom both the positive and negative data instances,and hence they have near zero values in the pivoteigenvectors.
We exploit this important informa-tion.
The basic idea is that the data points withnear zero values in the second eigenvector aremore ambiguous than those with large absolutevalues.
Hence, to cluster only the unambiguousdatapoints, we can therefore sort the data pointsaccording to second eigenvector, and keep only thetop and bottom m(m < n) datapoints.
Finally, in-stead of removing (n?m) datapoints at once, weremove them in iteration.Here is our final algorithm:1.
Let s : X ?
X ?
?
be a similarity functiondefined over data X. Construct a similaritymatrix S such that Sij= s(xi, xj).2.
Construct the Laplacian matrix L =D?1/2(D ?
S)D?1/2, where D is a diago-nal matrix with Di,i=?jSi,j.3.
Find eigenvector e2corresponding to secondsmallest eigenvalue of L.4.
Sort X according to e2and remove ?
pointsindexed from (|X|/2?
?/2+1) to (|X|/2+?/2).5.
If |X| = m, goto Step 6; else goto Step 1.403Dataset System m = 15n m =25n m =35n m =45n m = n Fully SupervisedGender Kmeans++ 52.3% 51.6% 52.3% 51.7% 51.2% -TSVM 53.1% 53.6% 52.7% 52.6% 52.0% 80.4%OUR 78.5% 73.7% 69.3% 66.8% 64.4% -Spam Kmeans++ 67.6% 58.6% 54.9% 53.8% 52.4% -TSVM 87.8% 85.0% 82.7% 80.7% 78.9% 96.9%OUR 83.8% 82.9% 80.4% 79.8% 78.4% -Sentiment Kmeans++ 64.5% 61.4% 60.5% 57.8% 56.5% -TSVM 70.2% 65.1% 61.5% 61.8% 60.4% 86.4%OUR 90.3% 85.4% 79.9% 74.9% 71.2% -Table 2: Accuracy of automatically labeled data for each dataset.
We also report 5-fold supervisedclassification result for each dataset.6.
Sort X according to e2and put top m2datapoints in cluster C1and bottom m2data pointsin cluster C2.In the algorithm stated above, we start with aninitial clustering of all of the data points, and theniteratively remove the ?
most ambiguous pointsfrom the data space.
We iterate the process of re-moving ambiguous data points and re-clusteringuntil we have m data points remaining.
It shouldnot be difficult to see the advantage of removingthe data points in an iterative fashion (as opposedto removing them in a single iteration): the clus-ters produced in a given iteration are supposedto be better than those in the previous iterations,as subsequent clusterings are generated from lessambiguous points.
In all our experiments, we set?
to 100.
Finally, we label the clusters by inspect-ing 10 randomly sampled points from each cluster.We use the cluster labels to assign labels to the munambiguous data points.
Note that labeling theclusters is the only form of human input we re-quire in our system.3 ExperimentsWe use three text classification tasks for evalua-tion:Gender Classification: Here we classify blogarticles according to whether an article is writtenby a male or female.
We employ the blog datasetas introduced by Schler et al (2006) for this task.The dataset contains 19320 blog articles, out ofwhich we randomly selected 5000 blog articles asour dataset.Spam Classification: Here the goal is to deter-mine whether an email is Spam or Ham (i.e., notspam).
We use the Enron spam dataset as intro-duced by Metris et al (Metsis et al (2006)).
Wejoin together the BG section of Spam emails andkaminski section of Ham emails, and randomly se-lected 5000 emails as our dataset.Sentiment Classification: Here the goal is todetermine whether the sentiment expressed in aproduct review is positive or negative.
We usePang et al?s movie review dataset for this task(Pang et al (2002)).
The dataset contains 2000reviews annotated with the positive and negativesentiment label.To preprocess a document, we first tokenize anddowncase it, remove stop words, and represent itas a vector of unigrams, using frequency as pres-ence.
For spectral clustering, we use dot productas a measure of similarity between two documentsvectors.Dataset Data points Features Pos:NegGender 5000 75188 2751:2249Spam 5000 23760 2492:2508Sentiment 2000 24531 1000:1000Table 3: Description of the datasets.3.1 Accuracy of Automatically Labeled DataFor each dataset, given n unlabeled data points,we apply our system to label m(m <= n) leastambiguous data points.
We check the quality oflabeled data by comparing the assigned (cluster)labels of m datapoints against their true labels,and show the accuracy.
Table 2 shows the accu-racy of automatically labeled data for five differentvalues of m for each dataset.
For example, whenm = n/5, our system labels 1000 out of available5000 data points with 78.5% accuracy for the gen-der dataset.
These 1000 data points are the mostunambiguous out of the 5000 data points, as se-lected by the algorithm.
For m = n the systemlabels the entire dataset.As you can see, for all three datasets, the ac-curacy of labeling unambiguous data instances ismuch higher than the accuracy of labeling the en-tire dataset.
For instance, the accuracy of top n/5unambiguous labeled instances of the sentimentdataset is 90.3%, whereas the accuracy of labelingthe entire dataset is 71.2%.
The more unambigu-404ous the data instances are the higher is the qual-ity of labeled data (as shown by the fact that theaccuracy of labeled instances increases as we in-crease m).
Notice that our system labels 60% ofthe data points of the spam dataset with 80.4% ac-curacy; 40% of the data points of the sentimentdataset with 85.4% accuracy; and 20% of the datapoints of the gender dataset with 78.5% accuracy.We also report 5-fold supervised classificationresult for each dataset.
We used linear SVM forclassification with all parameters set to their de-fault values.
As you can see, when m = n/5 oursystem achieves near supervised labeling perfor-mance for the gender and sentiment dataset.
Oneof the reviewers asked how SVM performed whentrained with unambiguous data instances alone.We refer to Dasgupta and Ng (2009) where the au-thors report that training SVM with unambiguousdata alone produces rather inferior result.
They,however, work on a small data sample.
It wouldbe interesting to know whether large number ofunambiguous (or, semi-ambiguous) data instancescould offset the need for ambiguous data in a gen-eral classification setting.
Given that unlabeleddata are abundantly available in many NLP tasks,one can employ our method to create decent sizelabeled data quickly from unlabeled data, and uti-lize them later in the process to build an indepen-dent classifier or augment the performance of anexisting classifier (Fuxman et al (2009)).We employed two baseline algorithms, i.e.,kmeans++ and a semi-supervised learning system,Transductive SVM.
For kmeans++ we used thefollowing as a measure of ambiguity for each datapoint: 1?
(x??i)2?ki(x?
?i)2, where x is a data vector and?i, i = 1 : k are k mean vectors.
It ranges from0 to 1.
Ambiguity score near 0.5 suggests thatthe data point is ambiguous.
Following commonpractice in document clustering, we reduced thedimensions of the data to 100 using SVD beforewe apply kmeans++.
For transductive SVM, werandomly selected 20 labeled data points as seeds.Table 2 shows the result for each baseline.Notice that our system beat the baselines (oneof them is a semisupervised system) by a big mar-gin for the Gender and Sentiment dataset, whereasTransductive SVM performs the best for the Spamdataset.
Interesting to point that our method of re-moving ambiguous data instances to get a qualita-tively stronger clustering contrasts with the max-margin methods which use the ambiguous datainstances to acquire the margin.
Also impor-tant to mention that spectral clustering is a graph-based clustering algorithm, where similarity mea-sure employed to construct the graph plays a cru-cial role in performance (Maier et al (2013)).
Infact, ?right?
construction of the feature space and aright similarity measure can considerably changethe performance of a graph-based clustering algo-rithm.
We have not tried different similarity mea-sures in this initial study, but it provides us roomfor improvement for a dataset like Spam.Implementation Details: On a machine with3GHz of Intel Quad Core Processor and 4GB ofRAM, the iterative spectral clustering algorithmtakes less than 2 minutes in Matlab for a datasetcomprising 5000 data points and 75188 features.This along with the fact that human labelers takeon average 12 minutes to label the clusters sug-gests that the entire labeling process requires lessthan 15 minutes to complete.4 Mining Patterns and InsightsIn this section, we show that we can utilize thelabeled resources created by our system to learndiscriminative patterns that help us gain insightsinto a dataset (Don et al (2007), Larsen and Aone(1999), Cheng et al (2007), Maiya et al (2013)).We utilize the top n/5 unambiguous labeled in-stances for this task, where n is size of the dataset.Note that the quality of unambiguous labeled in-stances is much higher than the entire set of la-beled instances (see Section 3.1), so the statis-tics we collect from the unambiguous labeled in-stances to identify discriminative patterns are sup-posedly more reliable.We learn our first category of discriminativepatterns the following way: for each cluster,we rank all unigrams in the vocabulary by theirweighted log-likelihood ratio:P (wt| cj) ?
logP (wt| cj)P (wt| ?cj)where wtand cjdenote the t-th word in the vocab-ulary and the j-th cluster, respectively, and eachconditional probability is add one smoothed.
In-formally, a unigram w will have a high rank withrespect to a cluster c if it appears frequently inc and infrequently in ?c.
The higher the scorethe more discriminative the pattern is.
We alsolearn the discriminative bigrams similarly: foreach cluster, we rank all bigrams by their weighted405Dataset Class Top Discriminative UnigramsGender Female haha, wanna, sooo, lol, ppl, omg, hahaha, ur, yay, soo, cuz, bye, soooo, hehe, ate, hurts, sucks.Male provide, reported, policies, administration, companies, development, policy, services, nations.Spam Spam vicodin, goodbye, utf, rolex, watches, loading, promotion, reproductions, nepel, fw, fwd, click.Ham risk, securities, statements, exchange, terms, third, events, act, investing, objectives, assumptions.Sentiment Positive relationship, husband, effective, mother, strong, perfect, tale, novel, fascinating, outstanding.Negative stupid, worst, jokes, bunch, sequel, lame, guess, dumb, boring, maybe, guys, video, flick, oh.Table 4: Top discriminative unigram patterns identified by our system.Dataset Class Top Discriminative BigramsGender Female wanna go, im so, im gonna, at like, don?t wanna, was sooo, was gonna, soo much, so yeah.Male to provide, york times, the issue, understanding of, the political, bush admin, the democratic.Spam Spam promotional material, adobe photoshop, name it, choose from, you name, stop getting, office xp.Ham investment advice, this report, respect to, current price, risks and, information provided.Sentiment Positive story of, her husband, relationship with, begins to, love and, life of, the central, the perfect.Negative the worst, bad movie, bunch of, got to, too bad, action sequences, waste of, than this, the bad.Table 5: Top discriminative bigram patterns identified by our system.log-likelihood ratio score and select the top scor-ing bigrams as the most discriminative bigrams.Table 4 and 5 show the most discriminative un-igrams and bigrams learned by our system.
No-tice that the learned patterns are quite informa-tive.
For instance, in the case of blog dataset welearn that certain word usages (e.g., sooo, cuz etc.
)are more common in women?s writings, whereasmen?s writings often contain discussion of poli-tics, news and technology.
For sentiment data, thepatterns correspond well to the generic sentimentlexicon manually created by the sentiment experts.The ability of our system to learn top sentimentfeatures could be handy for a resource-scarce lan-guage, which may not have a general purpose sen-timent lexicon.
Note that the system is not lim-ited to unigram and bigram patterns only.
The la-beled instances can be utilized similarly to gatherstatistics for other form of usage patterns includ-ing syntactic and semantic patterns for documentcollections.5 Related WorkAutomatic extraction of labeled data has gainedmomentum in recent years (Durme and Pasca(2008), Nakov and Hearst (2005), Fuxman etal.
(2009)).
Traditionally, researchers use task-specific heuristics to generate labeled data, e.g.,searching for a specific pattern in the web to col-lect data instances of a particular category (Hearst(1992), Go et al (2009), Hu et al (2013)).
An-other line of research follows semi-supervised in-formation extraction task, where given a list ofseed instances of a particular category, a bootstrap-ping algorithm is applied to mine new instancesfrom large corpora (Riloff and Jones (1999), Et-zioni et al (2005), Durme and Pasca (2008)).There has also been a surge of interests in unsu-pervised approaches which primarily rely on clus-tering to induce psuedo labels from large amountof text (Clark (2000), Slonim and Tishby (2000),Sahoo et al (2006), Christodoulopoulos et al(2010)).
We differ from existing unsupervisedclustering algorithms in a way that we uncompli-cate spectral clustering by forcing it to cluster un-ambiguous data points only, which ensures that thesystem makes less mistakes during clustering andthe clustered data are qualitatively strong.6 ConclusionWe have presented a system that helps us createa labeled resource for a given dataset with mini-mal human effort.
We also utilize the labeledresources to discover important insights about thedata.
The ability of our system to learn and vi-sualize top discriminative patterns facilitates ex-ploratory data analysis for a dataset that might beunknown to us.
Even if we have some knowledgeof the data, the system may unveil additional char-acterisitcs that are unknown to us.
The top fea-tures induced for each classification task can alsobe interpreted as our system?s ability to discovernew feature spaces, which can be utilized inde-pendently or along with a simpler feature space(e.g., bag of words) to learn a better classificationmodel.
Additional research is needed to furtherexplore this idea.AcknowledgementsWe acknowledge three anonymous reviewers andVincent Ng for their valuable feedback on an ear-lier draft of the paper.406ReferencesH.
Cheng, X. Yan, J. Han, and C. Hsu.
2007.
Discrim-inative frequent pattern analysis for effective classi-fication.
In International Conference on Data Engi-neering (ICDE).C.
Christodoulopoulos, S. Goldwater, and M. Steed-man.
2010.
Two decades of unsupervised posinduction: How far have we come?
In Em-pirical Methods in Natural Language Processing(EMNLP).Alexander Clark.
2000.
Inducing syntactic categoriesby context distributional clustering.
In the Confer-ence on Natural Language Learning (CoNLL).S.
Dasgupta and V. Ng.
2009.
Mine the easy, clas-sify the hard: A semi-supervised approach to au-tomatic sentiment classification.
In ACL-IJCNLP2009: Proceedings of the Main Conference.A.
Don, E. Zheleva, M. Gregory, S. Tarkan, L. Auvil,T.
Clement, B. Shneiderman, and C. Plaisant.
2007.Discovering interesting usage patterns in text col-lections: integrating text mining with visualization.In Proceedings of the ACM International Confer-ence on Information and Knowledge Management(CIKM).Benjamin Van Durme and Marius Pasca.
2008.
Find-ing cars, goddesses and enzymes: Parametrizableacquisition of labeled instances for open-domain in-formation extraction.
In the AAAI Conference on Ar-tificial Intelligence (AAAI).O.
Etzioni, M. Cafarella, D. Downey, A. Popescu,T.
Shaked, S. Soderland, D. Weld, and A. Yates.2005.
Unsupervised named-entity extraction fromthe web: an experimental study.
In Artificial Intelli-gence.A.
Fuxman, A. Kannan, A. Goldberg, R. Agrawal,P.
Tsaparas, and J. Shafer.
2009.
Improving classifi-cation accuracy using automatically extracted train-ing data.
In 15th ACM Conference on KnowledgeDiscovery and Data Mining (SIGKDD).A Go, R Bhayani, and L Huang.
2009.
Twitter sen-timent classification using distant supervision.
InProject Report, Stanford University.M.
A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In the Inter-national Conference on Computational Linguistics(COLING).X.
Hu, J. Tang, H. Gao, and H. Liu.
2013.
Unsuper-vised sentiment analysis with emotional signals.
InIn the Proceedings of the International World WideWeb Conference (WWW).B.
Larsen and C. Aone.
1999.
Fast and effective textmining using linear-time document clustering.
Inthe Conference on Knowledge Discovery and DataMining (SIGKDD).M.
Maier, U. von Luxburg, and M. Hein.
2013.
Howthe result of graph clustering methods depends onthe construction of the graph.
In ESAIM: Probabil-ity and Statistics, vol.
17.A.
S. Maiya, J. P. Thompson, F. Loaiza-Lemos, andR.
M. Rolfe.
2013.
Exploratory analysis of highlyheterogeneous document collections.
In the Con-ference on Knowledge Discovery and Data Mining(SIGKDD).V.
Metsis, I. Androutsopoulos, and G. Paliouras.
2006.Spam filtering with naive bayes - which naive bayes?In 3rd Conference on Email and Anti-Spam (CEAS).Preslav Nakov and Marti Hearst.
2005.
Using the webas an implicit training set: Application to structuralambiguity resolution.
In Empirical Methods in Nat-ural Language Processing (EMNLP).Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification us-ing machine learning techniques.
In Proceedings ofEmpirical Methods in Natural Language Processing(EMNLP).E.
Riloff and R. Jones.
1999.
Learning dictionaries forinformation extraction by multi-level bootstrapping.In Proceedings of the ACM International Confer-ence on Information and Knowledge Management(CIKM).N.
Sahoo, J. Callan, R. Krishnan, G. Duncan, andR.
Padman.
2006.
Incremental hierarchical cluster-ing of text documents.
In the International Confer-ence on Information and Knowledge Management(CIKM).J.
Schler, M. Koppel, S. Argamon, and J. Pennebaker.2006.
Effects of age and gender in blogging.
InAAAI Symposium on Computational Approaches forAnalyzing Weblogs.Jianbo Shi and Jitendra Malik.
2000.
Normalized cutsand image segmentation.
IEEE Transactions on Pat-tern Analysis and Machine Intelligence.Noam Slonim and Naftali Tishby.
2000.
Documentclustering using word clusters via the informationbottleneck method.
In Proceedings of the ACM SI-GIR Conference on Research and Development inInformation Retrieval.407
