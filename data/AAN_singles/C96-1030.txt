Example-Based Machine Translation in the Pangloss SystemRalf  D. Brown(Jenter for Machine Translation(~arncgie Mellon \[lniversity5000 Fort)('s Aw;nucl'ittsburgll, PA 15213-',~890ra l f@cs ,  cmu.
eduAbst rac tThe Pangloss Example-Based MachineTranslation engine (I'anEI3MT) l is atranslation system reql,iring essentiallyno knowledge of the structure of a lan-guage, merely a large parallel corpus ofexample sentences atn\[ a bilingual dictio-nary.
Input texts are segmented into se-quences of words occurring in the corpus,for which translations are determined bysubsententia\[ alignment of the sentencepairs containing those sequences.
Thesepartial translations are then combinedwith the results of other translation engines to form the final translation pro-duced by the Pangloss system.
In aninternal evaluation, PanEBMT achieved70.2% coverage of unrestricted Spanishnews-wire text, despite a simplistic sub-sententia\[ alignment algorithm, a subopritual dictionary, and a corpus Dora a dif-ferent domain than the evalual, ion texts.1 In t roduct ionPangloss (Nirenburg el; al., 1995) is a multi-engine machine translation system, in which sev-eral translation engines are.
run in parallel to pro-pose translations of various portions of the input,Dora which the final translation is selected by astatistical anguage model.
Panl'3BMT is one ofthe translation engines used by Pangloss.EBMT is essentially translation-by-analogy:given a source-language passage S and a collec-tion of aligned source/target text pairs, lind the"best" match for S in the source-language half ofthe text collection, and accept he target-languagehalf of that match as the translation.
PanEBMT,like other example-based translation systems, usesessentially no knowledge about its source or targetlanguages; what little knowledge it does use is op-tional, and is supplied in a eonIiguration file.
Its1This work as part of the l'angloss project was sup-ported I)y tim U.S.
I)epartment of Defensethree main knowledge sources arc: a sententially-aligned parallel bilingual corpus; a bilingual dic-tionary; and a target-language root/synonym list,.The fourth (minor and optional) knowledge sourceis the hmguage-specific information provided inthe conliguration tile, which consists of n list oftokenizations equating words within classes suchas w0ekdays, a list of words which ntay be elidedduring alignment (such as artMes), and a list ofwords which may be inserted2 Para l le l  B i l ingua l  CorpusThe corpus used by PanEBMT consists of a set ofsource/target sentence, pairs, and is flflly indexedon t, he source-language s ntences.
The corpus isnot aligned at any granularity liner than the sen-tence pair; subsententia\] alignment is perfornledat run-time based on the sentence fragments e-let;ted and the other knowledge sources.The corpus index lists all occurrences of ev-ery word and punctuation mark in the source-language sentences contained in the corpus.
Theindex has been designed to permit incremental up-dates, allowing new sentence pairs to be added tothe corpus as they become awulable (for example,to implement a translation memory with the sys-tem's own output).
The text is tokenized priorto indexing, so that words in any of the equiva-lence classes detined in the EBMT contigurationtile (such as month names, countries, or measuringunits), as well as the predetined equiwdence class<nunt lmr>,  are indexed under the equivalenceclass rather than their own names.
For each dis-tinct token, the index contains a list of tile token'soccurrences, consisting of a sentence identifier andthe word number within the sentence.
At transla-tion time, f'anEI~MT back-substitutes tile appro-priate target-language word into any translationwhich involves any tokenized words.
'rile bilingual corpus used for the results re-ported here consists of 726,406 Spanish-Englishsentence pairs drawn primarily from the IIN Mul-tilingual (~'orpus available fl'om tile l,inguisticData (Jonsortium(Graff and Finch, 1992) (Figurel), with a small admixture of texts from the Pan-169Las fuentes de esos comentarios yrecomendaciones son las siguientes :The sources of these comments andrecommendations are :E1 informe de la Junta de Auditores a laAsamblea General que incluye lasobservaciones del Director Ejecutivodel UNICEF sobre los comentarios yrecomendaciones de la Junta deAuditores ;The report of the Board of Auditors tothe General Assembly which incorporatesthe observations of the ExecutiveDirector of UNICEF on the comments andrecommendations of the Board ofAuditors ;Figure 1: Corpus Sentence Pairs(ACADMICOS ACADEMICS ACADEMICALTITLES DEGREES)(ACAECIDO HAPPEN)(ACAECIDOS HAPPEN)(ACANTONADAS CANTON QUARTER TROOPS)(ACANTONAMIENTO CANTONMENT)(ACARREA CARRY CART HAUL TRANSPORTCAUSE OCCASION)(ACARREABA CARRY CART HAUL TRANSPORTCAUSE OCCASION)(ACARREARON CARRY CART HAUL TRANSPORTCAUSE OCCASION)(ACARREAR TRANSPORT HAUL CART CARRYLUG ALONG BRING DOWN CAUSE OCCASIONITS TRAIN RESULT GIVE RISE)Figure 2: Bilingual Dictionary EntriesAmerican Health Organization and prior projectevaluations 2, indexed as described above.Together, the bilingual dictionary and target-language list, of roots and synonyms (extractedfrom WordNet when translating into English)provide the necessary information to lind as-sociations between source-language and target-language words in the selected sentence pairs.These associations are used in performing subsen-tential alignment.
A source word is considered tobe associated with a target-language word when-ever either the target word itself or any of thewords in its root/synonym list appear in the listof possible translations for the source word givenby the dictionary.Not all words will be associated one-to-one;however, the current implementation requires thatat least one such unique association be found inorder to provide an anchor for the alignment pro-tess.3 ImplementationPanEBMT is implemented in C++, using theFramepaC library (Brown, 1996) for accessingLisp data structures stored in files or sent from themain Pangloss module via Unix pipes.
PanEBMTconsists of approximately 13,300 lines of code, in-cluding the code for a glossary mode which willnot be described here.PanEBMT uses a re-processed version of thebilingual dictionary used by Pangloss's dictionarytranslation engine (Figure 2).
The re-processingconsists of removing various high-frequency wordsand splitting all nmlti-word definitions into a listof single words, needed to find one-to-one associ-ations.210250 sentence pairs stern from the PAI{O corpusand 552 pairs from evaluations.4 EBMT's  P lace  in  Pang lossPanEBMT is merely one of the translation en-gines used by Pangloss; the others are trans-fer engines (dictionaries and glossaries) and aknowledge-based machine translation engine (Fig-ure 3).
Each of these produces a set of candi-date translations for various segments of the in-put, which are then combined into a chart (Figure3).
The chart is passed through a statistical lan-guage model to determine the best path throughthe chart, which is then output as the translationof the original input sentence.5 EBMT OperationThe EBMT engine produces translations in twophases:1. find chunks by searching the corpus index foroccurrences of consecutive words from the in-put text2.
perform subsentential ignment on each sen-tence pair found in the first phase to deter-mine the translation of the chunkIn constrast with other work on example-based translation, such as (Maruyama nd Watan-abe, 1992) or early Pangloss EBMT experiments(Nirenburg et al, 1993), PanEBMT does not findan optimal partitioning of the input.
Instead, itattempts to produce translations of every wordsequence in the input sentence which appears inits corpus.
The final selection of the "correct"cover for the input is left for the statistical an-guage model, as is the case for all of the othertranslation engines in Pangloss.
An advantage ofthis approach is that; it avoids discarding possiblechunks merely because they are not part of the"optimal" cover for the input, instead selectingthe input coverage by how well the translations fittogether to form a complete translation.170Transfer M ' I )(\]MAT l'ost-cdit )H A 'l'al'get TextSource Text \]1!T 5/< 5 /Figure 3: l'angloss Machine q'r;mslation SystemArchitecture3'0 lind chunks, the engine sequentially looks upeach word of tile input in the index.
The oc<:ur-rence list for each word is comp~tred ;tgainst theoccurrence list for the prior word and against thelist of chunks extending to the prior word.
Forc,~u;h occtlrrence which is adjacent to all occnr-l'elwe of the prior word, a new chunk is createdor an existing chunk is extended as appropriate.Alter processing all input words in this tmmner,the engine has determined all possible substringsof the input containing at least two words whichare; present in the corpus.
Since the more Dequentword sequences <:an o<:cur hundreds of times inthe eorl)uS , the list of chunks is culled to elimi-nate all but the last tlve (by default) occurrencesof any distinct word sequence.
By selecting thelast occurrences of each word sequence, one effec-tively gives the most recent additions to the cor-pus the highest weight, precisely what is neededfor a translation meanory.Next, the sentence pairs containing tile chunksretold in the lirst phase are read from disk, andalignment is performed on each in order to de-termine the translation of the chunk unless thematch is against he entire COl'pus entry, in whichcase the entire target-language s ntence is takenas the translation.
Alignment currently uses arather simplistic brnte-force approach very simi-lar to that of (Nirenburg et el., 1994) which iden-tifies the minimum and maximum possible seg-ments of the target-language s ntence which couldpossibly correspond to the chunk, and then ap-plies a scoring fimction to ew',ry possible substringof the maximum segment containing at least theluinimmn segment.
The suhstring with the bestscore is then selected as the aligned match for thechunk.The alignment scoring function is computedfl'om the weighted sum of a number of extremelysimple test flmctions.
The weights call be changedfor ditDring lengths of the source chunk in order toadapt to varying impacts of the tests with varyingnuml)ers of words in the chunk, as well as vary-it,g impacts as some or all of the.
raw test storeschange.
The test functions include (in approxi-mate order el' importance) such measures as a)the number o\[' source words without <:orrcspon-dences in the t.;trget, b) the number of targetwords without c.orrespondences in tile source, c)matching words in source/target without corre-spondences, d) nmnber of words with COl'respon-dence itt the fifll target but not the candidatechunk, e) common sentence boundaries, f)  eli(t-able source words, g) insertable target words, andIt) the difference in length between source and ta>get chunks.There is one exception to the above procedurefor retrieving and aligning chunks.
If any of thechunks covers the entire input string and the en-tire source-language half of a corpus sentence pair,then all other chunks are discarded and the target-language half of the pair is prodnced as the trans-lation.
This speeds up the system when opea'atingin tnmsl~tion memory mode, as would be the casein a system used to translate revisions of previoustexts.
Unlike a pure translation memory, however,Pan I'\]IIMT does not require all exact; match witha memorized translation.Figure 4 shows the set of translations gener-ated fi'om one sentence.
The output is shownin the format used R)r standalone testing, whichgenerates only the best translation for each dis-tinct clnmk; when integrated with the rest of Pan-gloss, Panl,;l/MT also includes information indi-cating which portion of tile input sentence andwhich pair fi'om the corpus were used, and canproduce multiple translations for each chunk.
The.number next to the source-language chunk in theoutput indicates the wdue of the scoring flnlction,where higher values are worse.
Very poor align-meats (scores greater than five times the sourcechunk length) have already been omitted from theoutput.6 Recent  EnhancementsThe EBMT engine described here is a completelynew implementation ill C++ replacing an earlierLisp version.
The previous version had performedvery poorly (to the point where its results were171E1 Banco de Santander habia sidoelegido el lunes per las autoridadesmonetarias espanolas para comprar elBanco Espanol de Credito (Banesto),cuarto banco espanol.
"El Banco de" (O)("the Bank of")"El Banco de Santander" (i)("the Bank of Santander")"Banco de" (0)("Bank of")"Banco de Santander" (I)("Bank of Santander")"de Santander" (0)("of Santander")"habia side" (0.5)("been")"elegido el" (0)("chosen the")"el lunes por" (0)("Monday by the")"por las" (O)("by the")"por las autoridades" (14.2)("by the health authorities")"por las autoridades monetarias" (0)("by the monetary authorities")"las autoridades monetarias" (0)("the monetary authorities")"comprar el" (0)("buying the")"Espanol de Credito" (13.2)("Spanish Institute of Credit for")"de Credito" (0)("of credit")"de Credito (" (i)("of credit (")"Credito (" (0)("credit (")", cuarto" (0)(", fourth")"banco espanol" (0)("Spanish bank")"espanol ."
(0)("Spanish .
")Figure 4: Sample 'DanslationsInput words 9169Matched against corpus 90.4% 8294Alignable 84.5% 7748Good alignments 70.2Z 6439Table 1: (\]overage and Sentence AlignabilityEngine Proposed SelectedName Arcs Words Arcs Words CoverDICT 27482 27482 3451 3451 9167EBMT 11005 34992 1527 4768 6439GLOSS 17663 19249 1567 1774 5780Overa l l :  46580 71998 5415 9169 9169Table 2: (\]onl, ributions of Pangloss l~hlginesessentially ignored when combining the outputsof the various translation engines), for two mainreasons: inadequate corpus size and incompleteindexing.The earlier incarnation had used a corpus ofconsiderably less than 40 megabytes of text, com-pared to the 270 megabytes used for the results de-scribed herein.
The seven-fold increase in corpussize produces a proportional increase in matches.Not only was the corpus fairly small, the textwhich was used was not flflly indexed.
To limitthe size of the index file, a long list of tile mostfrequent words were omitted from the index, aswere punctuation marks.
Although allowanceswere made for the words on the stop Fist, themissing punctuation marks always forced a breakin clmnks, fl'equently limiting the size of chunkswhich could be found.
Further, allowance wasmade for the ,m-indexed frequent words by per-mitring any sequence of frequent words betweentwo indexed words, producing many erroneousmatches.The newer implementation fully indexes thecorpus, anti thus examines only exact matcheswith the input, ensuring that only good matchesare actually processed.
Further, PanEBMT canindex certain word pairs to, in effect, precomputesome two-word chunks.
When applied to the fiveto ten most frequent words, this pairing can re-duce processing time during translation by dra-matically reducing the amount of data which mustbe read from the index file (for example, theremight be 10,000 occurrences of a word pair insteadof 1,000,000 occurrences of one of the words and100,000 of the other word), and thus the numberof adjacency comparisons which must be made.7 Per formance7.1 AccuracyPanEBMT was first put to the test during an172internM evaluation in August 1995, whi{:h w~tssimilar in design I,o l, he ARI'A MT ewdual, ions(White &, O'(kmnel l ,  1,{)94).
During this evMual.ion, i;weni;y newswire arl;icles (seleel, ed from thel(}O articles used in Lhe l>rior A\]{I)A evMu;tl, iol 0averaging M)(}ul, 450 wor(ls ea(:h were l}ro(:essed~md sul)se(luently ex~Lmine(t. For this i}a,l)er, an-ol;tmr eva\]u~tl;ion was I)erformed using a sul}set ofthe l}angloss system on ~he 25?, senl;{mces in thel;wenl,y ~l'ti{:les.
Talkie 2 shows the {,oDd nltln-bet of arcs prol)ose{l 1}y each {,ranslation engiueuse(I, the mm~l}er sele(:Led for out,l}Ut, 153, the st,>tisl, i(:M bmgm~ge model, ~m(I the ntu~d)er {}t" sourcewords represen{;ed I}y 1,hose ares.
The {inal e.olumnshows l;he {,o{;M nund}er of source wor(Is covercdI}y at; leasl, {}lie 15rOl)OSed ~r{'.
The vMue8 for in-{lividual engines {lo not sum t,(} the O~:cr.ll v;due1}eeause multit)le engines cml I)r(}{luce e(luiva\[enl,arcs, which are (:ombine(I in the {:ha rl,, wil, h bothengil~CS {:redited for the arc.
The engines lisl,e(I int, he l,ables ~re?
DICT iouary :  l'anl'31~MT's asso{:ia, l, iol~ die-Li(}It,a,l'y~ tl,'-;e{I here priumrily 1;{} I}rovi(le cov-el'ztge f'{}\]' words  It(){, ()l;herwise e{}vered?
EBMT:  Pm\]EI~MT?
GLOSSar ies :  haa\]{t-(:raf{,e(t wor{I/l)hrasebilinguM glossm'ies7.2 Sl)e(;dIn{lexing a 270 m{:gal}yi;c {:{}rl)US requircs al}l}r()xi-tn;tl;ely 45 ndmaes on a Sun SI)arcsl,;tti-n I,X whenall tiles are located on local ,lisks, an,l an{)lher ~{}lllilllll,eB I,{) lmck {,he.
index (n(}l, required, I}ul, iml}roves speed al, run time).
It~cret}~enl,al a{hlil,ionof new data.
1,o the {:orpllS l}l'o{:e{2{l:-; ;tl, ~t l'al,c (}\["roughly six megal}ytes l)er ndnute.A sample text (}f 15 sentences l;(}t;Mling 414Wol'ds ,~l, ll(l I}llll{:{41&{,iOll ll10,1'k8 c0,II I){'~ t}l'{.
}{:(':ss(':(Iin jus{, under three minul,es.
The 20 texts use{lin l;he evalu~d,ion (:~m he {:On~l}lel,ely i}r{)eesse(I inl,w{} hours, inchMing sel)~U';d,e i)asscs for (ti{:l, io-.
;try lool~ul}S ;m(l sl,~l;istieM \]~{,{leling I,y a se I}ar;d,e i}rogr~tm ((lescril}e{t in (Ih'owu m,{t I"re{lerk-inp;, 1!
}95)); I)m~EI~MT a(:c(}unl,s for a,I)oul, 8{} nfin-tiles (}f l ;hose l;wo ho l l r s .The above t;imings rel)reselll, ;1, v{LricLy of sl}ee(IOl}l, imizati(}ns which Imve been N}l}lied since theAugusl; 1.
{)95 ewdm~t;ion, r{',sulting in a {h}ul}lingof t;he in{lexiug spee{I and trit)ling {}f 1,r~mslal, ionspeed.8 St rengths  and  WeaknessesAs {:urrenl, y i~q}h.uenl,e(I, )m~EI~MT has I,()l,hsi, rengl,hs ~tnd wea, knesses, ll, s s{;renglhs are l, ha, l,l, he nfininmt knowledge req.ired all(}ws {luM( re-I,argcl, ing and flint, it,s {lesip;n l}rovi{les I'{}r gra.ee\['u\] degra{lal, i{}n. Its we~knesses are thai; ii, isumd}le t,o conq}let,ely e{}ver inlsul, s , Lh;t{, it, {l{}esnot per\['ornl well when the correspondences I)e-tween som'ce-ltutgu~ge mM l,~rgct-l~mguage words~re not one-to-.one, ~nd that~ (like statistically-based tr~mshrl, ion sysl,ems) i|, is sensitive to dif-I'ereltce,q 1)eLweel/ Lhe example corp l lS  811(I I;he Sell-1,ences l,o be I;ranslat,ed,The astul, e rca.
(ler wil l  have noticed that therehave been virl, ually no ment, ions of l, he sourceor t;arget, langmtges iP, this paper they ~r{~ notrelcva.
{; 1,15 discussions of the design ~md oper-al, i{m of l, he engine, since t;he only language--{telsen{len{, kn(,wledge consists of l, he e(luivMence{:lasses and the lists of insert;able ;m{l cli&d)lewor{ts, which are ln'ovided via the {:Ollligllra,t, iOlllile.
This l;mguage-indel}endent asl}e{:l; of EBMTmM<es I}~mEI~MT r~Lpidly retargetM)le {;o otherl~mguage l}Mrs, and in f~t{:l; thcre are ;dready ver-sions {}f I};mF, I~MT provi{ling Serhocro;Ll,ia.n-i:o-English and El\]glish-to-Serhocroati~m trmlslal;i(ms(m) exl)erimenl, M (t/-tl, a, i8 ,~ts yel, ~twuilM,le for SePho{:roa, Lia, ll I)e{::4118e t.he {:olnl)\]eLe {li(:ti{}n;~ry an(I{'{srpus are sl, itt heiug acquire(l).
(~iven thc 1,hreere{luire(I knowledge S(}llP{'es O\[" e{)rpllS, {li{:l, ionary,and word-root, list,, PanEI{MT can begin pro{h.>iug tr~mslat, ions for a new langtmgc pair in only a,few h{}urs.
I,'iue tuniug will require one {;o twoweeks 12o del;erlnine reasOllS,\])Ie word  (:\[a, sses \['()ri;okenizal;ion (along; with the required rc-indexingof the {:orlms) a.nd t{) adjusl; the scoring fllll(:l, iOllweighl,s.Nun~l}er ~m(l qualil,y of I;rmlsl;tl, ions {legra(lesgradually as the size and (lualil# {}\[ the I)ilin-gual diction&try aim synonym list (leerease.
An in-{:{mtl}tel,e (licl;i{mary or rool,/synonym list m{welycauses Pan EB M'\[' l;o miss son.2 potenl, ial tr;msla-t,i{}ns.
Similarly, a smMM' {:orpus t}r{}duces fewerl}otential m~d, ches, I}ut there i~ no t}oinl, 12}r ~my (51"l, he l, hree l?nowle{Ip#2 SOllrces ~tl, which the etlg~iltesu{hlenly {:eases 1;o \['tlllCLiOll.
()lie can I M(c ad-vantage of this gradual beh~wior l}y tmihting {heknowledgc sources incrcmenl;Mly and using I!
;I~MTfOP l, ra, llSlaJ, iOllS eve l l  I)el 'ore the kn{}wledge sourcestrove I)ecn eomplc(,e{I.
In I)ar{,icul~tr, 1}y a(htinp;l},}sl,-edil,ed oul, l}lll, Of the MT sysl,elll I}ack into1,11{': {:Ol ' l ) l lS } l ; \[ Ie sysL{ ' : l l l  c;I, ll I}{: 1}{}o{;s{,ra, i}l}e{I I'r{}nla rela.tively mo{lesl, inil, ial coPi)ll8 (precisely thei{tea, l}ehin{l ~ l;r;-msla,(;i{)n nlenlory).I)uring l)repa.r~l;ion of this l)a.1}er, severM ex-l,l'.~tlleOIlS lines were discovered in the eorlms files,w}lich ('all:-;(:(I lll(}l'C, l;ha, ll 2!
)/1110 8ell|,{:ll(:e p;Lil'S(over 4% o\[" Lhc eorl}lls ) l,o t}{~ corrul)l, ed.
I)11(21,{) t, he exl;r~l lines, the corrut)l,ed pairs consisl, ed ofthe English target senl;enee t'ronl one pair and l, heSpanish sotn'ec senl, en{',e t?
(}m the following I)air.
'l'his error had n(}t I}een diseovere{I earlier 1}e{:auseil, had n{} ol)vious effect ou I}anEl3MT's perfor-lnmt(:e ~t clear exa.ml}le of the sysl;enl}s graceful{ h~gra.
{Ial, i(sn i}r{q}erl:y.I,ack {)f (:~)mt)lel,e in\[)/ll, {:{}w, rage is a severe {)t}-s{,;i.cle l,O IlSill~ I'anl,',l~IMT as a sl,and-ahme I, rans17 3lation system.
The engine can not generate achunk for a word unless it both co-occurs with ei-ther the preceding or following word somewhere inthe corpus, and at least one occurrence can be suc-cessfiflly aligned.
Additionally, candidate chunksare omitted if the alignment was successfifl butthe scoring function indicates a poor match.
Un-less all of these conditions are met, a gap in outputoccurs for the particular input word.
In the con-text of the Pangloss system, such gaps are not aproblem, since one of the other engines can usuallysupply a translation covering each gap.As currently implemented, the EBMT engine isunable to properly deal with translations that donot involve one-for-one correspondences betweensource and target words (e.g.
Spanish "rail mil-liones" corresponding to English "billions").
Lackof a one-to-one correspondence between source-language and target:language expressions can of-ten cause the alignment o be incorrect or fail al-together under the current alignment algorithm.Since the corpus used in the experimentsdescribed here was based almost entirely onthe UN proceedings rather than newswire text,PanEBMT did not find many long chunks duringthe evaluation.
In fact, the average chunk was justover three words in length, and less than three per-cent of the chunks were more than six words long.This quite naturally affects the quality of the finaltranslation, since many short pieces must be as-sembled into a translation rather than one or twolong segments.Despite all these difficulties, PanEBMT wasable to cover 70.2% of the input it was presentedwith good chunks, and generate some translationfor more than 84ordinarily not outpnt at all).
In-tegrating the hand-crafted glossaries from Pan-gloss into the corpus, thus adding 148,600 effec-tively pre-aligned phrases to the corpus, improvedthe matches against the corpus from 90.4% to90.9% of the input, and the coverage with goodchunks to 73.3%.9 Future  EnhancementsSince PanEBMT is a fairly new implementation,there is still much that could be done to en-hance it.
Among the improvements being consid-ered are: improving the qnality of the dictionary(in progress); supporting one-to-many or many-to-one associations for alignment; optimizing thetest-function weights; other alignment algorithms;using linguistic information such as morphologi-cal variants and source-language synonymy to in-crease the number of matches against the cor-pus; using approximate matchings when no exactmatches exist in the corpus; and using of a clas-sifier algorithm to remove redundancy from thecorpus (suggested by C. Domashnev).Re ferencesRalf Brown (in preparation).
FramepaC User'sManual Carnegie Mellon University (\]enter:for Machine Translation technical memoran-dnm hUp:// ww, es.
cmu.
edu/afs/cs, emu.
edu/-user/ralf/pub/W  W/papers.
h tmlRalf Brown and Robert Frederking 1995.
Apply-ing Statistical English Language Modeling toSymbolic Machine ~lYanslation.
In Proceedingsof the Sixth International Conference on The-oretical and Methodoloqical Issues in MachineTranslation (TMI-95), pages 221-239.
Leuven,Belgium.David Graft and Rebecca Finch 1994.
Multilin-gum Text Resources at the Linguistic Data Con-sortium In Proceedings of the 1994 ARPA Hu-man Language Technology Workshop MorganKaufinann.H.
Maruyama nd H. Watanabe 1992.
Tree CoverSearch Algorithm for Example-Based 'lYansla-tion.
In Proceedings of the Fourth InternationalConference on Theoretical and MethodologicalIssues in Machine ~lYanslation (TMI-92), pages173-184.
Montreal.M.
Nagao 1984.
A Framework of a Mechani-cal ~IYanslation between Japanese and Englishby Analogy Principle.
In Artificial and HumanIntelligence, A. Elithorn and R. Banerji (eds).NATO PublicationsSergei Nirenburg, (ed.).
1995.
"The PanglossMark IIl Machine Translation System."
JointTechnical Report, Computing Research Labora-tory (New Mexico State University), Center forMachine Translation (Carnegie Mellon Univer:sity), Information Sciences Institute (Universityof Southern California).
Issued as CMU techni-cal report CMU-CMT-95-145.Sergei Nirenburg, Stephen Beale, and ConstantineDomashnev 1994.
A Full-Text Experiment inExample-Based Machine Translation.
In NewMethods in Language Processing Manchester,England.Sergei Nirenburg, Constantine Domashnev, andDean J. Grannes 1993.
Two Approaches toMatching in EBMT.
In Proceedings of theFifth International Conference on Theoreticaland Methodological Issues in Machine Transla-tion (TM\[-93).White, J.S.
and T. O'Connell.
1994.
"Evalu-ation in the ARPA Machine Translation Pro-gram: 1993 Methodology."
\[n Proceedings ofthe ARPA lILT Workshop.
Plainsboro, NJ.174
