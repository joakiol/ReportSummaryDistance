Treebank Conversion based Self-training Strategy for ParsingZhiguo Wang and Chengqing ZongNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences{zgwang, cqzong}@nlpr.ia.ac.cnAbstractIn this paper, we propose a novel self-training strategy for parsing which isbased on Treebank conversion (SSPTC).In SSPTC, we make full use of thestrong points of Treebank conversionand self-training, and offset theirweaknesses with each other.
To providegood parse selection strategies which areneeded in self-training, we score theautomatically generated parse trees withparse trees in source Treebank as areference.
To maintain the constituencybetween source Treebank and conversionTreebank which is needed in Treebankconversion, we get the conversion treeswith the help of self-training.
In ourexperiments, SSPTC strategy is utilizedto parse Tsinghua Chinese Treebankwith the help of Penn Chinese Treebank.The results significantly outperform thebaseline parser.1 IntroductionSyntax parsing is one of the most fundamentaltasks in natural language processing (NLP) andhas attracted extensive attention during the pastfew decades.
In statistical area, according to thetype of data used in training stage, the parsingapproaches can be classified into threecategories: supervised, semi-supervised andunsupervised.
In supervised parsing approach, ahigh-performance parser can be built when givensufficient labeled data (Charniak, 2000; Collins,2003; Henderson, 2004).
The semi-supervisedapproach utilizes some labeled data to annotateunlabeled data, then uses the annotated data toimprove original model, e.g., self-training(McClosky et al, 2006) and co-training (Hwa etal., 2003).
In unsupervised parsing, the labeleddata was not employed and all annotations andgrammars are discovered automatically fromunlabeled data.State-of-the-art supervised parsers (Charniak,2000; Collins, 2003; Henderson, 2004) requirelarge amounts of manually annotated trainingdata, such as the Penn Treebank (Marcus et al,1993), to achieve high performance.
However, itis quite costly and time-consuming to createhigh quality labeled data.
So it becomes a keybottleneck for supervised approach to acquiresufficient labeled training data.
Self-training isan effective strategy to overcome this shortage.It tries to enlarge the training set withautomatically annotated unlabeled data andtrains a parser with the enlarged training set.During the last few decades, many Treebanksannotated with different grammar formalismsare released (Zhou, 2004; Xue et al, 2005).Although they are annotated with differentschemes, they have some linguistic consistencyin some extent.
Intuitively, we can convertTreebank annotated with one grammarformalisms into another Treebank annotatedwith grammar formalism that we are interestedin.
For simplicity, we call the first sourceTreebank, and the second target Treebank.
Andwe call this strategy as Treebank conversion.Although both self-training and Treebankconversion can overcome the limitation oflabeled data shortage for supervised parsing insome extent, they all have drawbacks.
For self-training, the quality of automatically annotatedunlabeled data will affect the performance ofsemi-supervised parsers highly.
For example,McClosky et al (2006) shows that when theparser-best list is used for self-training, theparsing performance isn?t improved, but afterusing reranker-best list, the retrained parserachieves an absolute 1.1% improvement.
ForTreebank conversion, different types amongTreebanks make the converting procedure verycomplicated, and it is very hard to get aconversion Treebank constituent with targetTreebank.To overcome the limitations mentioned above,we propose a Treebank conversion based self-training strategy for parsing, which tries tocombine self-training and Treebank conversiontogether.Remainder of this paper is organized asfollows.
In Section 2, we introduce some relatedwork.
Section 3 describes details of our SSPTCstrategy.
In Section 4, we propose a head findingmethod for Task21 in CLP2010.
Theexperiments and analysis is given in Section 5.The last section draws conclusions and describesthe future work.2 Related WorkWith the development of statistical parsingapproaches, large scale corpus has become anindispensable resource.
Because of the limitedamount of existing labeled training data and thehardness of constructing corpus, many strategieshave been proposed and experimented toovercome the contradiction.Self-training is one of the most successfulstrategies.
McClosky et al (2006) shows thatself-training effectively improves the accuracyof English parsing.
First, they trained a two-stage reranking parser(Charniak and Johnson,2005) using Penn Treebank (PTB)(Marcus et al,1993) and parsed 1,750k unlabeled sentencesfrom North American News Text corpus(NANC).
Then they combined the labeledNANC sentences with PTB together as trainingset and retrained the first stage of the parser.
Thefinal result got a 1.1% improvement over theprevious best parser for section 23 of the PennTreebank.
Huang and Harper (2009) combinedself-training into a PCFG-LA based parser bothfor English and Chinese.
Experimental resultshowed that self-training contributed 0.83%absolute improvement using only 210kunlabeled sentences with a single generativeparser.
For the Chinese parsing, self-trainingcontributed 1.03% absolute improvement.Treebank Conversion is another potentialstrategy to reuse existing source Treebanks forthe study of target grammar parsing.
Wang et al(1994) proposed a Treebank conversionalgorithm for corpus sharing.
They employed aparser with target grammar formalism to get N-best parse list for each sentence in sourceTreebank, selected the best conversion tree fromthe list using their algorithm, then inserted theconversion trees into training set, and finallyretrained the parser with the enlarged training set.Experimental result shows their algorithm iseffective.
Collins et al (1999) performedstatistical constituency parsing of Czech on aTreebank that was converted from the PragueDependency Treebank under the guidance ofconversion rules and heuristic rules, and the finalperformance was also improved.
Xia and Palmer(2001) proposed three methods to convertdependency trees into phrase structure trees withsome hand-written heuristic rules.
Foracquisition of better conversion rules, Xia et al(2008) proposed a method to automaticallyextract conversion rules from a target Treebank.Niu et al (2009) tried to exploit heterogeneousTreebanks for parsing.
They proposed agrammar formalism conversion algorithm toconvert dependency formalism Treebank intophrase structure formalism, and did phrasestructure parsing with the conversion trees.
Theirexperiments are done in Chinese parsing, and thefinal performance is improved indeed.In summary, from the existing work we areconfident that the strategies of self-training andTreebank conversion are effective to improvethe performance of parser.3 Our Strategy3.1 Parsing AlgorithmAlthough self-training and Treebank Conversionare effective for training set enlarging, they allhave drawbacks.
Self-training needs some parseselection strategies to select higher qualityparsers.
Treebank Conversion needs us tomaintain the consistency between conversedTreebank and target Treebank.
On the otherhand, self-training strategy provides us a goodidea to get annotated trees consistent with targetgrammar formalism, and the parse trees insource side provide a reference for higherquality parsers selecting.
So we can combineself-training and Treebank Conversion together,use self-training strategy to get convertedcandidates for sentences in source Treebank, andselect higher quality parses according to trees insource Treebank.
We call this strategy TreebankConversion based Self-training, and show moredetails in Algorithm 1.In Algorithm 1, target Treebank tT  and sourceTreebank sT  are input first (line 1).
Then tT  issplit into two parts: training set trainT  anddevelopment set devT  (line 3).
And we train aninitial parser with trainT and devT  in line 4.
Fromline 6 to line 12, we train parsers with SSPTCstrategy Iter times iteratively.
Let is tT o be theautomatically converted Treebank from sourceTreebank to target Treebank grammar formalismduring the i-th iteration.
From line 8 to line 11,we try to get a conversion tree with targetgrammar for each of the N sentences in sourceTreebank.
We get N-best parse list kParseList  forsentence ks with 1iParser   (line 9), select theparse ?
kp  with the highest score from kParseList(line 10), and insert it into is tT o  (line 11).
Thisprocedure runs iteratively until all the trees insource Treebank have been converted, finally,we train a new parser iParser  with trainT , devT  andis tT o (line 12).3.2 Parse selectionIn line 10 of Algorithm 1, we select the highestquality parse ?
kp  from kParseList according tofunction ( , )s s tScore p p o , where sp denotes a treein source Treebank and s tp o denotes aconversion tree with target Treebank grammarformalism for sp .
( , )s s tScore p p o  comparess tp o  with sp  and computes a score for s tp otaken sp  as a reference.
According to the ideaproposed in Wang et al (1994), we use thenumber of aligned constituents in the source andtarget trees to construct ( , )s s tScore p p o .
Wepropose two types of ( , )s s tScore p p o as follows.
(1) Unlabeled aligned constituents F1 score(UAF)First, we define a constituent as tag[i,j], whichrepresents a non-terminal node labeled with tagand spanning words from positions i to j of theinput sentence.
A non-terminal node in s tp oaligns with a non-terminal node in sp  when theyspan the same words.
If two nodes are aligned,we call them an aligned constituent and denotethe aligned relationship as [ , ] [ , ]s ttag i j tag i j?
.For example in Figure 1, there are three alignedconstituents between the source Treebank treeand the conversion tree, and we can denote themas [0, 7] [0, 7]s tIP dj?
, [0, 2] [0, 2]s tNR sp?
and[2, 6] [2, 6]s tNR np?
, respectively.When given sp and s tp o , we can easilycollect all the aligned constituents.
So we defineUnlabeled aligned constituents Precision (UAP)and Unlabeled aligned constituents Recall (UAR)as follows.,,( [ , ] [ , ])( [ , ])s ti jti jCount tag i j tag i jUAPCount tag i j??
?,,( [ , ] [ , ])( [ , ])s ti jsi jCount tag i j tag i jUARCount tag i j??
?Algorithm 11: Input: tT and sT2:  initialize3: { , ( )}train dev tT T Split Tm4: 0 ( , )train devParser Train T Tm5:   Iter iterations6: for im 1?
Iter do7:    is tT Io m8:    for k m 1?
N do9:        1( , )k i kParseList Nbest Parser sm10:       ,?
arg max ( , )j kk s k jp ParseListp Score p p?11:       ?is t kT po m12:   ( , , )ii train dev s tParser Train T T T om13: return IterParserThen Unlabeled aligned constituents F1 score(UAF) is defined as:,,2( , )2 ( [ , ] [ , ])( ( [ , ]) ( [ , ]))s s ts ti js ti jUAP UARScore p pUAP UARCount tag i j tag i jCount tag i j Count tag i jou uu ???
(1)(2) Labeled aligned constituents F1 score(LAF)In the last subsection, we define ( , )s s tScore p p oaccording to UAF.
In fact, the tags ofconstituents bring us much information to scoreconversion trees.
So wedefine ( , )s s tScore p p o with Labeled alignedconstituents F1 score (LAF) in this subsection.Because the annotation schemes are different,constituent tags in source Treebank may bemuch more different from target Treebank.
Thenumber of such tags may be drastically differentand the mapping may not be one-to-one.
Toeliminate the contradiction, we assume that eachtag in source Treebank can be converted intoevery tag in target Treebank with variousprobabilities.
So there is a converting matrixrepresenting the converting probabilities, and wecan calculate the converting matrix throughsource Treebank and N-best conversion trees.Given the source Treebank and N-bestconversion trees, first we align all theconstituents, then collect all the aligned tags andcompute the converting probability as thefollowing equation.
( )( )( )s ts tsCount tag tagp tag tagCount tag?o(2)Finally, we modify UAF computed byequation (1) into LAF as below.,,( )2 (1 ( )) ( [ , ] [ , ])( ( [ , ]) ( [ , ])),s t s ti js ti js s tScorep tag tag Count tag i j tag i jCount tag i j Count tag i jp pJou  u o u ???
(3)In equation (3), J  is a tunable variable, whichis used to weight the converting probability.Especially, LAF will be transferred into UAFwhen J =0.3.3 Corpus weighting techniqueIn line 12 of Algorithm 1, we train a new parserwith target Treebank and conversion trees.However, the errors in automatically conversiontrees are unavoidable and they would limit theaccuracy of the self-trained model.
So we haveto take some measures to weight the gold targetTreebank and the automatically conversion trees.McClosky et al (2006) and Niu et al (2009)take the strategy that duplicates the goldTreebank data many times.
However, thisstrategy isn?t suitable for PCFG-LAparser 1 (Matsuzaki et al, 2005; Petrov et al,2006), because PCFG-LA employs an EMalgorithm in training stage, so duplicating goldTreebank would increase the training timetremendously.
Instead, according to Huang andHarper (2009), we weight the posteriorprobabilities computed for the gold andautomatically converted trees to balance theirimportance.Let ( | )count A tEo be the count of ruleA Eo  in a parse tree t .
tT  and s tT o  are the setsof target Treebank and automatically convertedtrees from source Treebank respectively.
Theposterior probability of rule A Eo  (withweighting parameterD ) can be expressed as:1 We will use BerkeleyParser as our baseline parser,which is a PCFG-LA based parser.??
??
??
?
??
??
?
?NR NR NN CC NN NN VV??
??
??
?
??
??
?
?nS nS vN cC n vN vNR [0,2] NR [2,6] VP [6,7]VP [0,6]IP [0,7]sp [0,2] np [4,6]np [2,6]vp [2,7]dj [0,7](a) parse tree in source Treebank(b) conversion tree with target Treebank grammarFigure 1: source tree and its conversiontree with target grammar formalism( )( | ) ( | )( ( | ) ( | ))t s tt s tt T t Tt T t Tp ACount A t Count A tCount A t Count A tEEE D EE D Eoo?
??
?oo  oo  o?
??
?
?
(4)4 Head FindingIn Task21 of CLP2010, we are required to findheads for each constituent.
Our method is tomake head finding as a post procedure afterparsing.We treat head finding problem as aclassification problem, which is to classify eachcontext-free production into categories labelledwith their heads.
For example, there are threetypes of heads: -0, -0-2 and -2 forvp vp wP vpo , so we try to classify thisproduction into categories labelled with -0, -0-2and -2.
First, we scan the train set and collect allthe heads for each context-free production.
Thenwe train a Maxent classifier to classify eachcontext-free production into categories.
We takethe same feature templates for the classificationas Chen et al (2009) did, which is described inTable 1.The head finding procedure proceeds in abottom-up fashion, so that we can make use ofheads of productions in lower layers as featuresfor classification of the higher layers.To evaluate the accuracy of our head findingmethod, we randomly select a development set,remove all head information and use our Maxentclassifier to retrieve the heads.
Experimentalresults show the accuracy has reached 98.28%.However, the final performance would dropmuch when the parse trees are generatedautomatically.
Because the automaticallygenerated parse trees would bring many errors,and the post procedure of head finding can?tcorrect the errors.5 Experiments and Analysis5.1 Data PreparationIn order to evaluate the effectiveness of ourapproach, we do experiments for Chineseparsing using Tsinghua Chinese Treebank(TCTB) on target side and Penn ChineseTreebank (PCTB) on source side.
We divide thetraining portion of the Tsinghua ChineseTreebank provided by CLP2010 into three partsas follows: 500 trees are randomly extracted asdevelopment set, another 500 as validating setand the rest trees are taken as training set.
Fortrees in PCTB, all the empty-node and functiontag information are removed.
All the ParseValmeasures reported in this paper are evaluated bythe EVALB tool2.5.2 ExperimentsIn order to get a good final accuracy, we chooseBerkeleyParser 3 , which is a state-of-the-artunlexicalized parser, and train a model with thetraining set as our baseline.
The F1 score ofvalidating set parsed by baseline parser is85.72%.
In the following of this subsection, wetry to combine our strategies into the baselineparser and evaluate the effectiveness.
Becausemult-time iterations can?t improve parsingperformance tremendously but cost much timeduring our experiments, we take Iter=1 here.
(1) Corpus weighting experimentTo evaluate the corpus weighting strategy, wetake sentences (ignore the tree structure) inPCTB as unlabeled data, and train a parser withself-training strategy.
F1 scores of validating setvarying with D in equation (4) are shown inFigure 2.
From Figure 2, we find that the F1score varies with D , and reaches 86.46%2 http://nlp.cs.nyu.edu/evalb/3 http://code.google.com/p/berkeleyparser/Feature templatesThe label of the current constituent;The label of the left most child, the middle child and the right most child;The head word of the left most child, the middle child and the right most child;The POS tag of the head word of the left most child, the middle child and the right most child;Bigram of label, head word and POS tag of head word of the children: L/M, M/R;Trigram of label, head word and POS tag of head word of the children: L/M/R;The number of children;Table 1: Feature Templates for Head Findingwhen D =1.
The 0.74 absolute improvementcomparing with the baseline certifies theeffectiveness of our corpus weighting strategy.
(2) Parse selection experimentsIn this subsection we evaluate our parseselection strategies with the help of PCTB.According to Algorithm 1, we train an initialparser with training set and development set.Then we generate 50-best parses list with theinitial parser for each sentence in PCTB, andselect a higher-score parse for each sentencethrough our parse selection strategies to build aconversion Treebank.
Finally, we retrain a parserwith training set and the conversion Treebankwith the help of corpus weighting strategy.Figure 3 shows F1 scores of validating setusing UAF to select higher quality parses.When D =0.3, F1 score reaches 86.92%.
Theimprovement over baseline is 1.2 percentagepoints.
Comparing with the highest F1 score ofself-training, we got 0.46 more improvement.
Soour parse selection strategy with UAF iseffective.Because the highest F1 score is at the pointD =0.3 in Figure 3, we choose D =0.3 toevaluating LAF strategy.
Figure 4 shows F1scores on validating set using LAF.
The highestF1 score is 87.44% at the pointJ =6, and it gets1.72 percentage points improvement overbaseline.
Comparing with UAF, LAF gets 0.52more improvement.
So we can conclude that theparse selection strategy with LAF is much moreeffective.5.3 DiscussionTable 2 reports the highest performances ofvarious strategies.
From the table we can easilyfind that all strategies outperform the baselineparser.
Corpus weighting experiment tells us thatbalancing the importance of gold targetTreebank and conversion trees is helpful for thefinal performance.
Using UAF to selectconversion trees can get more improvement thanself-training which just selects the best-first trees.This fact proves that our SSPTC strategy isreasonable and effective.
Making use of LAF,we get more improvement than UAF.
It tells usthat exploiting source Treebank deeply can bringus more useful knowledge which is helpful todevelop high-performance parser.6 Experiments for Task 2 of CLP2010Task 2 of CLP2010 includes two sub-tasks: sub-sentence parsing and complete sentence parsing.For each sub-task, there are two tracks: closedtrack and open track.
To accomplish tasks inclosed track, we make use of our baseline parsershown in section 5 and train it with differentparameters and data set.
For open track, wemake use of our SSPTC strategy and train it withdifferent parameters and data set.
We tuned theparameters on the development set and selectedStrategy F1 scoreBaseline 85.72%Corpus weighting 86.46%UAF 86.92%LAF 87.44%Table 2: F1 scores of various strategiesFigure 4: F1 score of LAF strategyFigure 2: F1 score of self-trainingFigure 3: F1 score of UAF strategysome configurations which achieve higherperformance on the development set(moredetails have been shown in section 5).
The finalparameters and training data of our systems areshown in Table 34.
We also make use of theapproach explained in section 4 for the headfinding procedure.The parsing results of our systems on the testset can be found on the official ranking report.Our systems training with SSPTC strategy bringus an amazing performance which outperformsother systems in both the two sub-tasks.7 Conclusion and Future workIn this paper, we propose a novel self-trainingstrategy for parsing which is based on Treebankconversion.
Benefiting from SSPTC strategy, wehave gotten higher quality parse trees with thehelp of source Treebank, and gotten conversionTreebank with target Treebank grammarformalism simply and consistently.
The parsingresults on validating set show SSPTC iseffective.
We apply SSPTC to the test set ofTask 2 in CLP2010, and get 1.275 percentagepoints improvement over baseline parser usingthe parameters tuned on validating set.4 The parsing result for system b in open track of sub-task1 has been submitted mistakenly, so the figures ofthis system on the official ranking report have noreference value.5 The F1 score of baseline parser is 75.24%, and itreaches 76.51% using TCBS strategy.All the delightful results tell us that SSPTC isa promoting strategy for parsing.
However, thereis much knowledge in source Treebank remainedto further exploit, e.g.
the POS tags in sourceTreebank is a good resource to improve the POStagging accuracy of target Treebank.
So, in thenext step we will exploit source Treebank deeplyand try to get more knowledge from it forparsing.AcknowledgementThe research work has been partially funded bythe Natural Science Foundation of China underGrant No.
6097 5053, 90820303 and 60736014,the National Key Technology R&D Programunder Grant No.
2006BAH03B02, the Hi-TechResearch and Development Program (?863?Program) of China under Grant No.2006AA010108-4, and also supported by theChina-Singapore Institute of Digital Media(CSIDM) project under grant No.
CSIDM-200804.ReferencesEugene Charniak, 2000.
A maximum-entropy-inspired parser.
In NAACL-2000Eugene Charniak and Mark Johnson, 2005.
Coarse-to-fine n-best parsing and MaxEnt discriminativereranking.
In ACL-05.Xiao Chen, Changning Huang, Mu Li and ChunyuKit, 2009.
Better Parser Combination.
In CIPS.Sub-task Track  ID Parser Parameters Train dataa  Berkeley -- TSClosedb  Berkeley -- TS && VSa SSPTC  0.3  5D J  TS && PTCBSub-task 1Openb SSPTC  0.3  5D J   TS && VS && PTCBa   Berkeley -- TSClosedb   Berkeley -- TS && VSa SSPTC  0.3  6D J  TS && PTCBb SSPTC  0.3  5D J   TS && VS && PTCBc SSPTC  0.3  5D J  TS && PTCBSub-task 2Opend SSPTC  0.3  3D J  TS && PTCBTable 3: The configurations of our systems.
The abbreviations in the last column meantraining set(TS) and validating set(VS) explaining in section 5.1.Michael Collins, 2003.
Head-driven statistical modelsfor natural language parsing.
ComputationalLinguistics, 29 (4).
pages 589-637.M Collins, J Hajic, L Ramshaw and C Tillman, 1999.A statistical parser for Czech.
In ACL-99.
JHenderson, 2004.
Discriminative training of aneural network statistical parser.Zhongqiang Huang and Mary Harper, 2009.
Self-Training PCFG grammars with latent annotationsacross languages.
ACL-09.R Hwa, M Osborne, A Sarkar and M Steedman, 2003.Corrected co-training for statistical parsers.Citeseer.MP Marcus, B Santorini and MA Marcinkiewicz,1993.
Building a large annotated corpus of English:The Penn Treebank.
Computational Linguistics, 19(2).
pages 313-330.Takuya Matsuzaki, Yusuke Miyao and Jun'ichi Tsujii,2005.
Probabilistic CFG with latent annotations.
InACL-05.David McClosky, Eugene Charniak and MarkJohnson, 2006.
Effective self-training for parsing.In ACL-06.Zheng-Yu Niu, Haifeng Wang and Hua Wu, 2009.Exploiting heterogeneous treebanks for parsing.
InACL-09, pages 46-54.Slav Petrov, Leon Barrett, Romain Thibaux and DanKlein, 2006.
Learning accurate, compact, andinterpretable tree annotation.
In ACL-06.Jong-Nae Wang, Jing-Shin Chang and Keh-Yih Su,1994.
An automatic treebank conversion algorithmfor corpus sharing.
In ACL-94.Fei Xia and Martha Palmer, 2001.
Convertingdependency structures to phrase structures.
In The1st Human Language Technology Conference(HLT-2001).Fei Xia, Owen Rambow, Rajesh Bhatt, MarthaPalmer and Dipti Misra Sharma, 2008.
Towards amulti-representational treebank.
Proc.
of the 7thInt'lWorkshop on Treebanks and LinguisticTheories (TLT-7).
pages 207-238.Qiang Zhou, 2004.
Annotation Scheme for ChineseTreebank.
Journal of Chinese InformationProcessing, 18 (004).
