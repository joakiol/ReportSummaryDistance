Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 960?967,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsLearning Synchronous Grammars for Semantic Parsing withLambda CalculusYuk Wah Wong and Raymond J. MooneyDepartment of Computer SciencesThe University of Texas at Austin{ywwong,mooney}@cs.utexas.eduAbstractThis paper presents the first empirical resultsto our knowledge on learning synchronousgrammars that generate logical forms.
Usingstatistical machine translation techniques, asemantic parser based on a synchronouscontext-free grammar augmented with ?-operators is learned given a set of trainingsentences and their correct logical forms.The resulting parser is shown to be the best-performing system so far in a database querydomain.1 IntroductionOriginally developed as a theory of compiling pro-gramming languages (Aho and Ullman, 1972), syn-chronous grammars have seen a surge of interest re-cently in the statistical machine translation (SMT)community as a way of formalizing syntax-basedtranslation models between natural languages (NL).In generating multiple parse trees in a single deriva-tion, synchronous grammars are ideal for model-ing syntax-based translation because they describenot only the hierarchical structures of a sentenceand its translation, but also the exact correspon-dence between their sub-parts.
Among the gram-mar formalisms successfully put into use in syntax-based SMT are synchronous context-free gram-mars (SCFG) (Wu, 1997) and synchronous tree-substitution grammars (STSG) (Yamada and Knight,2001).
Both formalisms have led to SMT sys-tems whose performance is state-of-the-art (Chiang,2005; Galley et al, 2006).Synchronous grammars have also been used inother NLP tasks, most notably semantic parsing,which is the construction of a complete, formalmeaning representation (MR) of an NL sentence.
Inour previous work (Wong and Mooney, 2006), se-mantic parsing is cast as a machine translation task,where an SCFG is used to model the translationof an NL into a formal meaning-representation lan-guage (MRL).
Our algorithm, WASP, uses statisticalmodels developed for syntax-based SMT for lexicallearning and parse disambiguation.
The result is arobust semantic parser that gives good performancein various domains.
More recently, we show thatour SCFG-based parser can be inverted to produce astate-of-the-art NL generator, where a formal MRLis translated into an NL (Wong and Mooney, 2007).Currently, the use of learned synchronous gram-mars in semantic parsing and NL generation is lim-ited to simple MRLs that are free of logical vari-ables.
This is because grammar formalisms such asSCFG do not have a principled mechanism for han-dling logical variables.
This is unfortunate becausemost existing work on computational semantics isbased on predicate logic, where logical variablesplay an important role (Blackburn and Bos, 2005).For some domains, this problem can be avoided bytransforming a logical language into a variable-free,functional language (e.g.
the GEOQUERY functionalquery language inWong andMooney (2006)).
How-ever, development of such a functional language isnon-trivial, and as we will see, logical languages canbe more appropriate for certain domains.On the other hand, most existing methods formapping NL sentences to logical forms involve sub-stantial hand-written components that are difficultto maintain (Joshi and Vijay-Shanker, 2001; Bayeret al, 2004; Bos, 2005).
Zettlemoyer and Collins(2005) present a statistical method that is consider-960ably more robust, but it still relies on hand-writtenrules for lexical acquisition, which can create a per-formance bottleneck.In this work, we show that methods developed forSMT can be brought to bear on tasks where logicalforms are involved, such as semantic parsing.
In par-ticular, we extend the WASP semantic parsing algo-rithm by adding variable-binding ?-operators to theunderlying SCFG.
The resulting synchronous gram-mar generates logical forms using ?-calculus (Mon-tague, 1970).
A semantic parser is learned given aset of sentences and their correct logical forms us-ing SMT methods.
The new algorithm is called ?-WASP, and is shown to be the best-performing sys-tem so far in the GEOQUERY domain.2 Test DomainIn this work, we mainly consider the GEOQUERYdomain, where a query language based on Prolog isused to query a database on U.S. geography (Zelleand Mooney, 1996).
The query language consistsof logical forms augmented with meta-predicatesfor concepts such as smallest and count.
Figure 1shows two sample logical forms and their Englishglosses.
Throughout this paper, we use the notationx1, x2, .
.
.
for logical variables.Although Prolog logical forms are the main focusof this paper, our algorithm makes minimal assump-tions about the target MRL.
The only restriction onthe MRL is that it be defined by an unambiguouscontext-free grammar (CFG) that divides a logicalform into subformulas (and terms into subterms).Figure 2(a) shows a sample parse tree of a logicalform, where each CFG production corresponds to asubformula.3 The Semantic Parsing AlgorithmOur work is based on the WASP semantic parsing al-gorithm (Wong andMooney, 2006), which translatesNL sentences into MRs using an SCFG.
In WASP,each SCFG production has the following form:A ?
?
?, ??
(1)where ?
is an NL phrase and ?
is the MR translationof ?.
Both ?
and ?
are strings of terminal and non-terminal symbols.
Each non-terminal in ?
appearsin ?
exactly once.
We use indices to show the cor-respondence between non-terminals in ?
and ?.
Allderivations start with a pair of co-indexed start sym-bols, ?S 1 , S 1 ?.
Each step of a derivation involvesthe rewriting of a pair of co-indexed non-terminalsby the same SCFG production.
The yield of a deriva-tion is a pair of terminal strings, ?e, f?, where e isan NL sentence and f is the MR translation of e.For convenience, we call an SCFG production a rulethroughout this paper.While WASP works well for target MRLs thatare free of logical variables such as CLANG (Wongand Mooney, 2006), it cannot easily handle variouskinds of logical forms used in computational seman-tics, such as predicate logic.
The problem is thatWASP lacks a principled mechanism for handlinglogical variables.
In this work, we extend the WASPalgorithm by adding a variable-binding mechanismbased on ?-calculus, which allows for compositionalsemantics for logical forms.This work is based on an extended version ofSCFG, which we call ?-SCFG, where each rule hasthe following form:A ?
?
?, ?x1 .
.
.
?xk.??
(2)where ?
is an NL phrase and ?
is the MR trans-lation of ?.
Unlike (1), ?
is a string of termi-nals, non-terminals, and logical variables.
Thevariable-binding operator ?
binds occurrences ofthe logical variables x1, .
.
.
, xk in ?, which makes?x1 .
.
.
?xk.?
a ?-function of arity k. When ap-plied to a list of arguments, (xi1 , .
.
.
, xik), the ?-function gives ?
?, where ?
is a substitution oper-ator, {x1/xi1 , .
.
.
, xk/xik}, that replaces all boundoccurrences of xj in ?
with xij .
If any of the ar-guments xij appear in ?
as a free variable (i.e.
notbound by any ?
), then those free variables in ?
mustbe renamed before function application takes place.Each non-terminal Aj in ?
is followed by a listof arguments, xj = (xj1 , .
.
.
, xjkj ).
During pars-ing, Aj must be rewritten by a ?-function fj of ar-ity kj .
Like SCFG, a derivation starts with a pairof co-indexed start symbols and ends when all non-terminals have been rewritten.
To compute the yieldof a derivation, each fj is applied to its correspond-ing arguments xj to obtain an MR string free of ?-operators with logical variables properly named.961(a) answer(x1,smallest(x2,(state(x1),area(x1,x2))))What is the smallest state by area?
(b) answer(x1,count(x2,(city(x2),major(x2),loc(x2,x3),next to(x3,x4),state(x3),equal(x4,stateid(texas)))))How many major cities are in states bordering Texas?Figure 1: Sample logical forms in the GEOQUERY domain and their English glosses.
(a)smallest(x2,(FORM,FORM))QUERYanswer(x1,FORM)area(x1,x2)state(x1)(b)?x1.smallest(x2,(FORM(x1),FORM(x1, x2)))QUERYanswer(x1,FORM(x1))?x1.state(x1) ?x1.
?x2.area(x1,x2)Figure 2: Parse trees of the logical form in Figure 1(a).As a concrete example, Figure 2(b) shows anMR parse tree that corresponds to the Englishparse, [What is the [smallest [state] [by area]]],based on the ?-SCFG rules in Figure 3.
Tocompute the yield of this MR parse tree, we startfrom the leaf nodes: apply ?x1.state(x1) tothe argument (x1), and ?x1.
?x2.area(x1,x2)to the arguments (x1, x2).
This results in twoMR strings: state(x1) and area(x1,x2).Substituting these MR strings for the FORM non-terminals in the parent node gives the ?-function?x1.smallest(x2,(state(x1),area(x1,x2))).Applying this ?-function to (x1) gives the MRstring smallest(x2,(state(x1),area(x1,x2))).Substituting this MR string for the FORM non-terminal in the grandparent node in turn gives thelogical form in Figure 1(a).
This is the yield of theMR parse tree, since the root node of the parse treeis reached.3.1 Lexical AcquisitionGiven a set of training sentences paired with theircorrect logical forms, {?ei, fi?
}, the main learningtask is to find a ?-SCFG, G, that covers the train-ing data.
Like most existing work on syntax-basedSMT (Chiang, 2005; Galley et al, 2006), we con-structG using rules extracted fromword alignments.We use the K = 5 most probable word alignmentsfor the training set given by GIZA++ (Och and Ney,2003), with variable names ignored to reduce spar-sity.
Rules are then extracted from each word align-ment as follows.To ground our discussion, we use the word align-ment in Figure 4 as an example.
To representthe logical form in Figure 4, we use its linearizedparse?a list of MRL productions that generate thelogical form, in top-down, left-most order (cf.
Fig-ure 2(a)).
Since the MRL grammar is unambiguous,every logical form has a unique linearized parse.
Weassume the alignment to be n-to-1, where each wordis linked to at most one MRL production.Rules are extracted in a bottom-up manner, start-ing with MRL productions at the leaves of theMR parse tree, e.g.
FORM ?
state(x1) in Fig-ure 2(a).
Given an MRL production, A ?
?, aruleA ?
?
?, ?xi1 .
.
.
?xik .??
is extracted such that:(1) ?
is the NL phrase linked to the MRL produc-tion; (2) xi1 , .
.
.
, xik are the logical variables thatappear in ?
and outside the current leaf node in theMR parse tree.
If xi1 , .
.
.
, xik were not bound by?, they would become free variables in ?, subject torenaming during function application (and therefore,invisible to the rest of the logical form).
For exam-ple, since x1 is an argument of the state predicateas well as answer and area, x1 must be bound(cf.
the corresponding tree node in Figure 2(b)).
Therule extracted for the state predicate is shown inFigure 3.The case for the internal nodes of the MR parsetree is similar.
Given an MRL production, A ?
?,where ?
contains non-terminals A1, .
.
.
, An, a ruleA ?
?
?, ?xi1 .
.
.
?xik .???
is extracted such that: (1)?
is the NL phrase linked to the MRL production,with non-terminals A1, .
.
.
, An showing the posi-tions of the argument strings; (2) ??
is ?
with eachnon-terminal Aj replaced with Aj(xj1 , .
.
.
, xjkj ),where xj1 , .
.
.
, xjkj are the bound variables in the?-function used to rewrite Aj ; (3) xi1 , .
.
.
, xik arethe logical variables that appear in ??
and outsidethe current MR sub-parse.
For example, see the rule962FORM ?
?state , ?x1.state(x1)?FORM ?
?by area , ?x1.
?x2.area(x1,x2)?FORM ?
?smallest FORM 1 FORM 2 , ?x1.smallest(x2,(FORM 1 (x1),FORM 2 (x1, x2)))?QUERY ?
?what is (1) FORM 1 , answer(x1,FORM 1 (x1))?Figure 3: ?-SCFG rules for parsing the English sentence in Figure 1(a).smallesttheiswhatstatebyareaQUERY ?
answer(x1,FORM)FORM ?
smallest(x2,(FORM,FORM))FORM ?
state(x1)FORM ?
area(x1,x2)Figure 4: Word alignment for the sentence pair in Figure 1(a).extracted for the smallest predicate in Figure 3,where x2 is an argument of smallest, but it doesnot appear outside the formula smallest(...),so x2 need not be bound by ?.
On the otherhand, x1 appears in ?
?, and it appears outsidesmallest(...) (as an argument of answer),so x1 must be bound.Rule extraction continues in this manner until theroot of the MR parse tree is reached.
Figure 3 showsall the rules extracted from Figure 4.13.2 Probabilistic Semantic Parsing ModelSince the learned ?-SCFG can be ambiguous, aprobabilistic model is needed for parse disambigua-tion.
We use the maximum-entropy model proposedin Wong and Mooney (2006), which defines a condi-tional probability distribution over derivations givenan observed NL sentence.
The output MR is theyield of the most probable derivation according tothis model.Parameter estimation involves maximizing theconditional log-likelihood of the training set.
Foreach rule, r, there is a feature that returns the num-ber of times r is used in a derivation.
More featureswill be introduced in Section 5.4 Promoting NL/MRL IsomorphismWe have described the ?-WASP algorithm whichgenerates logical forms based on ?-calculus.
Whilereasonably effective, it can be improved in severalways.
In this section, we focus on improving lexicalacquisition.1For details regarding non-isomorphic NL/MR parse trees,removal of bad links from alignments, and extraction of wordgaps (e.g.
the token (1) in the last rule of Figure 3), see Wongand Mooney (2006).To see why the current lexical acquisition algo-rithm can be problematic, consider the word align-ment in Figure 5 (for the sentence pair in Fig-ure 1(b)).
No rules can be extracted for the statepredicate, because the shortest NL substring thatcovers the word states and the argument stringTexas, i.e.
states bordering Texas, contains the wordbordering, which is linked to an MRL productionoutside the MR sub-parse rooted at state.
Ruleextraction is forbidden in this case because it woulddestroy the link between bordering and next to.In other words, the NL and MR parse trees are notisomorphic.This problem can be ameliorated by transformingthe logical form of each training sentence so thatthe NL and MR parse trees are maximally isomor-phic.
This is possible because some of the opera-tors used in the logical forms, notably the conjunc-tion operator (,), are both associative (a,(b,c)= (a,b),c = a,b,c) and commutative (a,b =b,a).
Hence, conjuncts can be reordered and re-grouped without changing the meaning of a conjunc-tion.
For example, rule extraction would be pos-sible if the positions of the next to and stateconjuncts were switched.
We present a method forregrouping conjuncts to promote isomorphism be-tween NL and MR parse trees.2 Given a conjunc-tion, it does the following: (See Figure 6 for thepseudocode, and Figure 5 for an illustration.
)Step 1.
Identify the MRL productions that corre-spond to the conjuncts and the meta-predicate thattakes the conjunction as an argument (count inFigure 5), and figure them as vertices in an undi-2This method also applies to any operators that are associa-tive and commutative, e.g.
disjunction.
For concreteness, how-ever, we use conjunction as an example.963QUERY ?
answer(x1,FORM)howmanymajorcitiesareinstatesborderingtexasFORM ?
count(x2,(CONJ),x1)CONJ ?
city(x2),CONJCONJ ?
major(x2),CONJCONJ ?
loc(x2,x3),CONJCONJ ?
next to(x3,x4),CONJCONJ ?
state(x3),FORMFORM ?
equal(x4,stateid(texas))OriginalMRparsex2x3x4how manycitiesinstatesborderingtexasmajorQUERYanswer(x1,FORM)count(x2,(CONJ),x1)major(x2),CONJcity(x2),CONJloc(x2,x3),CONJstate(x3),CONJnext to(x3,x4),FORMequal(x4,stateid(texas))QUERYanswer(x1,FORM)count(x2,(CONJ),x1)major(x2),CONJcity(x2),CONJloc(x2,x3),CONJequal(x4,stateid(texas))next to(x3,x4),CONJstate(x3),FORM(shownaboveasthickedges)Step5.FindMSTStep 4.
Assign edge weightsStep 6.Construct MR parseFormgraphSteps1?3.Figure 5: Transforming the logical form in Figure 1(b).
The step numbers correspond to those in Figure 6.Input: A conjunction, c, of n conjuncts; MRL productions, p1, .
.
.
, pn, that correspond to each conjunct; an MRL production,p0, that corresponds to the meta-predicate taking c as an argument; an NL sentence, e; a word alignment, a.Let v(p) be the set of logical variables that appear in p. Create an undirected graph, ?, with vertices V = {pi|i = 0, .
.
.
, n}1and edges E = {(pi, pj)|i < j,v(pi) ?
v(pj) 6= ?
}.Let e(p) be the set of words in e to which p is linked according to a.
Let span(pi, pj) be the shortest substring of e that2includes e(pi) ?
e(pj).
Subtract {(pi, pj)|i 6= 0, span(pi, pj) ?
e(p0) 6= ?}
from E.Add edges (p0, pi) to E if pi is not already connected to p0.3For each edge (pi, pj) in E, set edge weight to the minimum word distance between e(pi) and e(pj).4Find a minimum spanning tree, T , for ?
using Kruskal?s algorithm.5Using p0 as the root, construct a conjunction c?
based on T , and then replace c with c?.6Figure 6: Algorithm for regrouping conjuncts to promote isomorphism between NL and MR parse trees.rected graph, ?.
An edge (pi, pj) is in ?
if and onlyif pi and pj contain occurrences of the same logicalvariables.
Each edge in ?
indicates a possible edgein the transformed MR parse tree.
Intuitively, twoconcepts are closely related if they involve the samelogical variables, and therefore, should be placedclose together in the MR parse tree.
By keeping oc-currences of a logical variable in close proximity inthe MR parse tree, we also avoid unnecessary vari-able bindings in the extracted rules.Step 2.
Remove edges from ?
whose inclusion inthe MR parse tree would prevent the NL and MRparse trees from being isomorphic.Step 3.
Add edges to ?
to make sure that a spanningtree for ?
exists.Steps 4?6.
Assign edge weights based on word dis-tance, find a minimum spanning tree, T , for ?, thenregroup the conjuncts based on T .
The choice of Treflects the intuition that words that occur close to-gether in a sentence tend to be semantically related.This procedure is repeated for all conjunctionsthat appear in a logical form.
Rules are then ex-tracted from the same input alignment used to re-group conjuncts.
Of course, the regrouping of con-juncts requires a good alignment to begin with, andthat requires a reasonable ordering of conjuncts inthe training data, since the alignment model is sen-sitive to word order.
This suggests an iterative algo-rithm in which a better grouping of conjuncts leadsto a better alignment model, which guides further re-grouping until convergence.
We did not pursue this,as it is not needed in our experiments so far.964(a) answer(x1,largest(x2,(state(x1),major(x1),river(x1),traverse(x1,x2))))What is the entity that is a state and also a major river, that traverses something that is the largest?
(b) answer(x1,smallest(x2,(highest(x1,(point(x1),loc(x1,x3),state(x3))),density(x1,x2))))Among the highest points of all states, which one has the lowest population density?
(c) answer(x1,equal(x1,stateid(alaska)))Alaska?
(d) answer(x1,largest(x2,(largest(x1,(state(x1),next to(x1,x3),state(x3))),population(x1,x2))))Among the largest state that borders some other state, which is the one with the largest population?Figure 7: Typical errors made by the ?-WASP parser, along with their English interpretations, before anylanguage modeling for the target MRL was done.5 Modeling the Target MRLIn this section, we propose two methods for model-ing the target MRL.
This is motivated by the fact thatmany of the errors made by the ?-WASP parser canbe detected by inspecting the MR translations alone.Figure 7 shows some typical errors, which can beclassified into two broad categories:1.
Type mismatch errors.
For example, a state can-not possibly be a river (Figure 7(a)).
Also it isawkward to talk about the population density of astate?s highest point (Figure 7(b)).2.
Errors that do not involve type mismatch.
For ex-ample, a query can be overly trivial (Figure 7(c)),or involve aggregate functions on a known single-ton (Figure 7(d)).The first type of errors can be fixed by type check-ing.
Each m-place predicate is associated with a listofm-tuples showing all valid combinations of entitytypes that the m arguments can refer to:point( ): {(POINT)}density( , ):{(COUNTRY, NUM), (STATE, NUM), (CITY, NUM)}These m-tuples of entity types are given as do-main knowledge.
The parser maintains a set ofpossible entity types for each logical variable in-troduced in a partial derivation (except those thatare no longer visible).
If there is a logical vari-able that cannot refer to any types of entities(i.e.
the set of entity types is empty), then the par-tial derivation is considered invalid.
For exam-ple, based on the tuples shown above, point(x1)and density(x1, ) cannot be both true, because{POINT} ?
{COUNTRY, STATE, CITY} = ?.
Theuse of type checking is to exploit the fact that peo-ple tend not to ask questions that obviously have novalid answers (Grice, 1975).
It is also similar toSchuler?s (2003) use of model-theoretic interpreta-tions to guide syntactic parsing.Errors that do not involve type mismatch arehandled by adding new features to the maximum-entropy model (Section 3.2).
We only consider fea-tures that are based on the MR translations, andtherefore, these features can be seen as an implicitlanguage model of the target MRL (Papineni et al,1997).
Of the many features that we have tried,one feature set stands out as being the most effec-tive, the two-level rules in Collins and Koo (2005),which give the number of times a given rule is usedto expand a non-terminal in a given parent rule.We use only the MRL part of the rules.
For ex-ample, a negative weight for the combination ofQUERY ?
answer(x1,FORM(x1)) and FORM?
?x1.equal(x1, ) would discourage any parsethat yields Figure 7(c).
The two-level rules features,along with the features described in Section 3.2, areused in the final version of ?-WASP.6 ExperimentsWe evaluated the ?-WASP algorithm in the GEO-QUERY domain.
The larger GEOQUERY corpus con-sists of 880 English questions gathered from varioussources (Wong and Mooney, 2006).
The questionswere manually translated into Prolog logical forms.The average length of a sentence is 7.57 words.We performed a single run of 10-fold crossvalidation, and measured the performance of thelearned parsers using precision (percentage of trans-lations that were correct), recall (percentage of testsentences that were correctly translated), and F-measure (harmonic mean of precision and recall).A translation is considered correct if it retrieves thesame answer as the correct logical form.Figure 8 shows the learning curves for the ?-96501020304050607080901000  100  200  300  400  500  600  700  800  900Precision(%)Number of training exampleslambda-WASPWASPSCISSORZ&C(a) Precision01020304050607080901000  100  200  300  400  500  600  700  800  900Recall (%)Number of training exampleslambda-WASPWASPSCISSORZ&C(b) RecallFigure 8: Learning curves for various parsing algorithms on the larger GEOQUERY corpus.
(%) ?-WASP WASP SCISSOR Z&CPrecision 91.95 87.19 92.08 96.25Recall 86.59 74.77 72.27 79.29F-measure 89.19 80.50 80.98 86.95Table 1: Performance of various parsing algorithms on the larger GEOQUERY corpus.WASP algorithm compared to: (1) the originalWASP algorithm which uses a functional query lan-guage (FunQL); (2) SCISSOR (Ge and Mooney,2005), a fully-supervised, combined syntactic-semantic parsing algorithm which also uses FunQL;and (3) Zettlemoyer and Collins (2005) (Z&C), aCCG-based algorithm which uses Prolog logicalforms.
Table 1 summarizes the results at the endof the learning curves (792 training examples for ?-WASP, WASP and SCISSOR, 600 for Z&C).A few observations can be made.
First, algorithmsthat use Prolog logical forms as the target MRL gen-erally show better recall than those using FunQL.
Inparticular, ?-WASP has the best recall by far.
Onereason is that it allows lexical items to be combinedin ways not allowed by FunQL or the hand-writtentemplates in Z&C, e.g.
[smallest [state] [by area]]in Figure 3.
Second, Z&C has the best precision, al-though their results are based on 280 test examplesonly, whereas our results are based on 10-fold crossvalidation.
Third, ?-WASP has the best F-measure.To see the relative importance of each componentof the ?-WASP algorithm, we performed two abla-tion studies.
First, we compared the performanceof ?-WASP with and without conjunct regrouping(Section 4).
Second, we compared the performanceof ?-WASP with and without language modeling forthe MRL (Section 5).
Table 2 shows the results.It is found that conjunct regrouping improves recall(p < 0.01 based on the paired t-test), and the use oftwo-level rules in the maximum-entropy model im-proves precision and recall (p < 0.05).
Type check-ing also significantly improves precision and recall.A major advantage of ?-WASP over SCISSOR andZ&C is that it does not require any prior knowl-edge of the NL syntax.
Figure 9 shows the perfor-mance of ?-WASP on the multilingual GEOQUERYdata set.
The 250-example data set is a subset of thelarger GEOQUERY corpus.
All English questions inthis data set were manually translated into Spanish,Japanese and Turkish, while the corresponding Pro-log queries remain unchanged.
Figure 9 shows that?-WASP performed comparably for all NLs.
In con-trast, SCISSOR cannot be used directly on the non-English data, because syntactic annotations are onlyavailable in English.
Z&C cannot be used directlyeither, because it requires NL-specific templates forbuilding CCG grammars.7 ConclusionsWe have presented ?-WASP, a semantic parsing al-gorithm based on a ?-SCFG that generates logicalforms using ?-calculus.
A semantic parser is learnedgiven a set of training sentences and their correctlogical forms using standard SMT techniques.
Theresult is a robust semantic parser for predicate logic,and it is the best-performing system so far in theGEOQUERY domain.This work shows that it is possible to use standardSMT methods in tasks where logical forms are in-volved.
For example, it should be straightforwardto adapt ?-WASP to the NL generation task?allone needs is a decoder that can handle input logicalforms.
Other tasks that can potentially benefit from966(%) Precision Recall?-WASP 91.95 86.59w/o conj.
regrouping 90.73 83.07(%) Precision Recall?-WASP 91.95 86.59w/o two-level rules 88.46 84.32and w/o type checking 65.45 63.18Table 2: Performance of ?-WASP with certain components of the algorithm removed.0204060801000  50  100  150  200  250Precision(%)Number of training examplesEnglishSpanishJapaneseTurkish(a) Precision0204060801000  50  100  150  200  250Recall (%)Number of training examplesEnglishSpanishJapaneseTurkish(b) RecallFigure 9: Learning curves for ?-WASP on the multilingual GEOQUERY data set.this include question answering and interlingual MT.In future work, we plan to further generalize thesynchronous parsing framework to allow differentcombinations of grammar formalisms.
For exam-ple, to handle long-distance dependencies that occurin open-domain text, CCG and TAG would be moreappropriate than CFG.
Certain applications may re-quire different meaning representations, e.g.
framesemantics.Acknowledgments: We thank Rohit Kate, Raz-van Bunescu and the anonymous reviewers for theirvaluable comments.
This work was supported by agift from Google Inc.ReferencesA.
V. Aho and J. D. Ullman.
1972.
The Theory of Pars-ing, Translation, and Compiling.
Prentice Hall, EnglewoodCliffs, NJ.S.
Bayer, J. Burger, W. Greiff, and B. Wellner.
2004.The MITRE logical form generation system.
In Proc.
ofSenseval-3, Barcelona, Spain, July.P.
Blackburn and J. Bos.
2005.
Representation and Inferencefor Natural Language: A First Course in Computational Se-mantics.
CSLI Publications, Stanford, CA.J.
Bos.
2005.
Towards wide-coverage semantic interpretation.In Proc.
of IWCS-05, Tilburg, The Netherlands, January.D.
Chiang.
2005.
A hierarchical phrase-based model for sta-tistical machine translation.
In Proc.
of ACL-05, pages 263?270, Ann Arbor, MI, June.M.
Collins and T. Koo.
2005.
Discriminative rerankingfor natural language parsing.
Computational Linguistics,31(1):25?69.M.
Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,W.
Wang, and I. Thayer.
2006.
Scalable inference and train-ing of context-rich syntactic translation models.
In Proc.
ofCOLING/ACL-06, pages 961?968, Sydney, Australia, July.R.
Ge and R. J. Mooney.
2005.
A statistical semantic parserthat integrates syntax and semantics.
In Proc.
of CoNLL-05,pages 9?16, Ann Arbor, MI, July.H.
P. Grice.
1975.
Logic and conversation.
In P. Cole andJ.
Morgan, eds., Syntax and Semantics 3: Speech Acts, pages41?58.
Academic Press, New York.A.
K. Joshi and K. Vijay-Shanker.
2001.
Compositional se-mantics with lexicalized tree-adjoining grammar (LTAG):How much underspecification is necessary?
In H. Bunt etal., eds., Computing Meaning, volume 2, pages 147?163.Kluwer Academic Publishers, Dordrecht, The Netherlands.R.
Montague.
1970.
Universal grammar.
Theoria, 36:373?398.F.
J. Och and H. Ney.
2003.
A systematic comparison of vari-ous statistical alignment models.
Computational Linguistics,29(1):19?51.K.
A. Papineni, S. Roukos, and R. T. Ward.
1997.
Feature-based language understanding.
In Proc.
of EuroSpeech-97,pages 1435?1438, Rhodes, Greece.W.
Schuler.
2003.
Using model-theoretic semantic interpre-tation to guide statistical parsing and word recognition in aspoken language interface.
In Proc.
of ACL-03, pages 529?536.Y.
W. Wong and R. J. Mooney.
2006.
Learning for seman-tic parsing with statistical machine translation.
In Proc.
ofHLT/NAACL-06, pages 439?446, New York City, NY.Y.
W. Wong and R. J. Mooney.
2007.
Generation by invertinga semantic parser that uses statistical machine translation.
InProc.
of NAACL/HLT-07, Rochester, NY, to appear.D.
Wu.
1997.
Stochastic inversion transduction grammars andbilingual parsing of parallel corpora.
Computational Lin-guistics, 23(3):377?403.K.
Yamada and K. Knight.
2001.
A syntax-based statisti-cal translation model.
In Proc.
of ACL-01, pages 523?530,Toulouse, France.J.
M. Zelle and R. J. Mooney.
1996.
Learning to parse databasequeries using inductive logic programming.
In Proc.
ofAAAI-96, pages 1050?1055, Portland, OR, August.L.
S. Zettlemoyer and M. Collins.
2005.
Learning to map sen-tences to logical form: Structured classification with proba-bilistic categorial grammars.
In Proc.
of UAI-05, Edinburgh,Scotland, July.967
