Extracting Causal Knowledge from a Medical DatabaseUsing Graphical PatternsChristopher S.G. Khoo, Syin Chan and Yun NiuCentre for Advanced Information Systems, School of Computer EngineeringBlk N4, Rm2A-32, Nanyang AvenueNanyang Technological UniversitySingapore 639798assgkhoo@ntu.edu.sg; asschan@ntu.edu.sg; niuy n@hotmail.comAbstractThis paper reports the first part of a projectthat aims to develop a knowledge extrac-tion and knowledge discovery system thatextracts causal knowledge from textual da-tabases.
In this initial study, we develop amethod to identify and extract cause-effectinformation that is explicitly expressed inmedical abstracts in the Medline database.A set of graphical patterns were constructedthat indicate the presence of a causal rela-tion in sentences, and which part of thesentence represents the cause and whichpart represents the effect.
The patterns arematched with the syntactic parse trees ofsentences, and the parts of the parse treethat match with the slots in the patterns areextracted as the cause or the effect.1 IntroductionVast amounts of textual documents and data-bases are now accessible on the Internet and theWorld Wide Web.
However, it is very difficultto retrieve useful information from this hugedisorganized storehouse.
Programs that canidentify and extract useful information, and re-late and integrate information from multiplesources are increasingly needed.
The WorldWide Web presents tremendous opportunitiesfor developing knowledge extraction and knowl-edge discovery programs that automatically ex-tract and acquire knowledge about a domain byintegrating information from multiple sources.New knowledge can be discovered by relatingdisparate pieces of information and by infer-encing from the extracted knowledge.This paper reports the first phase of a projectto develop a knowledge extraction and knowl-edge discovery system that focuses on causalknowledge.
A system is being developed toidentify and extract cause-effect informationfrom the Medline database ?
a database of ab-stracts of medical journal articles and conferencepapers.
In this initial study, we focus on cause-effect information that is explicitly expressed(i.e.
indicated using some linguistic marker) insentences.
We have selected four medical areasfor this study ?
heart disease, AIDS, depressionan  schizophrenia.The medical domain was selected for tworeasons:1.
The causal relation is particular important inmedicine, which is concerned with devel-oping treatments and drugs that can effect acure for some disease2.
Because of the importance of the causal re-lation in medicine, the relation is more likelyto be explicitly indicated using linguisticmeans (i.e.
using words such as result, ef-fect, cause, etc.
).2 Previous StudiesThe goal of information extraction research is todevelop systems that can identify the passage(s)in a document that contains information that isrelevant to a prescribed task, extract the infor-mation and relate the pieces of information byfilling a structured template or a database record(Cardie, 1997; Cowie & Lehnert, 1996; Gai-zauskas & Wilks, 1998).Information extraction research has beeninfluenced tremendously by the series of Mes-sage Understanding Conferences (MUC-5,MUC-6, MUC-7), organized by the U.S. Ad-vanced Research Projects Agency (ARPA)(http://www.muc.saic.com/proceedings/proceedings_index.html).
Participants of the conferencesdevelop systems to perform common informa-tion extraction tasks, defined by the conferenceorganizers.For each task, a template is specified thatindicates the slots to be filled in and the type ofinformation to be extracted to fill each slot.
Theset of slots defines the various entities, aspectsand roles relevant to a prescribed task or topic ofinterest.
Information that has been extracted canbe used for populating a database of facts aboutentities or events, for automatic summarization,for information mining, and for acquiringknowledge to use in a knowledge-based system.Information extraction systems have been devel-oped for a wide range of tasks.
However, few ofthem have focused on extracting cause-effectinformation from texts.Previous studies that have attempted to ex-tract cause-effect information from text havemostly used knowledge-based inferences to inferthe causal relations.
Selfridge, Daniell & Sim-mons (1985) and Joskowsicz, Ksiezyk &Grishman (1989) developed prototype computerprograms that extracted causal knowledge fromshort explanatory messages entered into theknowledge acquisition component of an expertsystem.
When there was an ambiguity whether acausal relation was expressed in the text, thesystems used a domain model to check whethersuch a causal relation between the events waspossible.Kontos & Sidiropoulou (1991) and Kaplan& Berry-Rogghe (1991) used linguistic patternsto identify causal relations in scientific texts, butthe grammar, lexicon, and patterns for identify-ing causal relations were hand-coded and devel-oped just to handle the sample texts used in thestudies.
Knowledge-based inferences were alsoused.
The authors pointed out that substantialdomain knowledge was needed for the system toidentify causal relations in the sample texts ac-curately.More recently, Garcia (1997) developed acomputer program to extract cause-effect infor-mation from French technical texts without us-ing domain knowledge.
He focused on causativeverbs and reported a precision rate of 85%.Khoo, Kornfilt, Oddy & Myaeng (1998) devel-oped an automatic method for extracting cause-effect information from Wall Street Journal textsusing linguistic clues and pattern matching.Their system was able to extract about 68% ofthe causal relations with an error rate of about36%.The emphasis of the current study is on ex-tracting cause-effect information that is explic-itly expressed in the text without knowledge-based inferencing.
It is hoped that this will resultin a method that is more easily portable to othersubject areas and document collections.
We alsomake use of a parser (Conexor?s FDG parser) toconstruct syntactic parse trees for the sentences.Graphical extraction patterns are constructed toextract information from the parse trees.
As aresult, a much smaller number of patterns needbe constructed.
Khoo et al (1998) who usedonly part-of-speech tagging and phrase bracket-ing, but not full parsing, had to construct a largenumber of extraction patterns.3 Initial Analysis of the Medical Texts200 abstracts were downloaded from the Med-line database for use as our training sample oftexts.
They are from four medical areas: depres-sion, schizophrenia, heart disease and AIDs(fifty abstracts from each area).
The texts wereanalysed to identify:1. the different roles and attributes that are in-volved in a causal situation.
Causeand effectare, of course, the main roles, but other rolesalso exist including enabling conditions, sizeof the effect, and size of the cause (e.g.
dos-age).2. the various linguistic markers used by thewriters to explicitly signal the presence of acausal relation, e.g.
as a result, affect, re-duce, etc.3.1 Cause-effect templateThe various roles and attributes of causal situ-tions identified in the medical abstracts ares ructured in the form of a template.
There arethree levels in our cause-effect template, Level 1giving the high-level roles and Level 3 givingthe most specific sub-roles.
The first two levelsare given in Table 1.
A more detailed descriptioni  provided in Khoo, Chan & Niu (1999).The information extraction system devel-oped in this initial study attempts to fill only them in slots of cause, effect and modality, withoutattempting to divide the main slots into subslots.Table 1.
The cause-effect templateLevel 1 Level 2ObjectState/EventCauseSizeObjectState/EventEffectSizePolarity (e.g.
?Increase?, ?Decrease?,etc.
)ObjectState/EventSizeDurationConditionDegree of necessityModality (e.g.
?True?, ?False?,?Probable?, ?Possible?, etc.
)Research methodSample sizeSignificance levelInformation sourceEvidenceLocationType of causal relationTable 2.
Common causal expressions fordepression & schizophreniaExpression No.
ofOccurrencescausative verb  69effect (of) ?
(on)  51associate with  35treatment of  31have effect on  28treat with  26treatment with  22effective (for)  14related to  10Table 3.
Common causal expressions forAIDs & heart diseaseExpression  No.
ofOccurrencescausative verb  119have effect on  30effect (of)?
(on)  25due to  20associate with  19treat with  15causative noun (includingnominalized verbs)12effective for  103.2 Causal expressions in medical textsCausal relations are expressed in text in variousways.
Two common ways are by using causallinks and causative verbs.
Causal links are wordsused to link clauses or phrases, indicating acausal relation between them.
Altenburg (1984)provided a comprehensive typology of causallinks.
He classified them into four main types:the adverbial link (e.g.
hence, therefore), theprepositional link (e.g.
because of, on accountof), subordination (e.g.
because, as, since, for,so) and the clause-integrated line (e.g.
that?swhy, the result was).
Causative verbs are transi-tive action verbs that express a causal relationbetween the subject and object or prepositionalphrase of the verb.
For example, the transitiveverb break can be paraphrased as to cause tobreak, and the transitive verb kill can be para-phrased as to cause to die.We analyzed the 200 training abstracts toidentify the linguistic markers (such as causallinks and causative verbs) used to indicate causalrelations explicitly.
The most common linguisticexpressions of cause-effect found in the Depres-sion and Schizophrenia bstracts (occurring atleast 10 times in 100 abstracts) are listed in Ta-ble 2.
The common expressions found in theAIDs and Heart Disease abstracts (with at least10 occurrences) are listed in Table 3.
The ex-pressions listed in the two tables cover about70% of the explicit causal expressions found inthe sample abstracts.
Six expressions appear inboth tables, indicating a substantial overlap inthe two groups of medical areas.
The most fr-quent way of expressing cause and effect is byusing causative verbs.4 Automatic Extraction of Cause-Effect InformationThe information extraction process used in thisstudy makes use of pattern matching.
This issimilar to methods employed by other research-ers for information extraction.
Whereas moststudies focus on particular types of events ortopics, we are focusing on a particular type ofrelation.
Furthermore, the patterns used in thisstudy are graphical patterns that are matchedwith syntactic parse trees of sentences.
The pat-terns represent different words and sentencestructures that indicate the presence of a causalrelation and which parts of the sentence repr-sent which roles in the causal situation.
Any partof the sentence that matches a particular patternis considered to describe a causal situation, andthe words in the sentence that match slots in thepattern are extracted and used to fill the appro-priate slots in the cause-effect template.4.1 ParserThe sentences are parsed using Conexor?s Func-tional Dependency Grammar of English (FDG)parser (http://www.conexor.fi), which generatesa representation of the syntactic structure of thesentence (i.e.
the parse tree).
For the examplesentencePaclitaxel was well tolerated and resulted in asignificant clinical response in this patient.a graphical representation of the parser output isgiven in Fig.
1.
For easier processing, the syn-tactic structure is converted to the linear con-ceptual graph formalism (Sowa, 1984) given inFig.
2.A conceptual graph is a graph with thenodes representing concepts and the directedarcs representing relations between concepts.Although the conceptual graph formalism wasdeveloped primarily for semantic representation,we use it to represent the syntactic structure ofsentences.
In the linear conceptual graph nota-tion, concept labels are given within squarebrackets and relations between concepts areFig.
1.
Syntactic structure of a sentencegiven within parentheses.
Arrows indicate thedirection of the relations.4.2 Construction of causality patternsWe developed a set of graphical patterns thatspecifies the various ways a causal relation canbe explicitly expressed in a sentence.
We callthem causality patterns.
The initial set of pat-terns was constructed based on the training setof 200 abstracts mentioned earlier.
Each abstractwas analysed by two of the authors to identifythe sentences containing causal relations, and thep rts of the sentences representing the cause andthe effect.
For each sentence containing a causalrelation, the words (causality identifiers) thatwere used to signal the causal relation were alsoiden ified.
These are mostly causal links andcausative verbs described earlier.Example sentencePaclitaxel was well tolerated and resulted in asignificant clinical response in this patient.Syntactic structure in linear conceptualgr ph format[tolerate]-(vch)->[be]->(subj)->[paclitaxel](man)->[well](cc)->[and](cc)->[result]-(loc)->[in]->(pcomp)->[response]-(det)->[a](attr)->[clinical]->(attr)->[significant],(phr)->[in]->(pcomp)->[patient]->(det)->[this],,.Example causality pattern[*]-&(v-ch)->(subj)->[T:cause.object](cc|cnd)->[result]+-(loc)+->[in]+->(pcomp)->[T:effect.event](phr)->[in]->(pcomp)->[T:effect.object],,.Cause-effect templateCause: paclitaxelEffect: a significant clinical response in thispatientFig.
2.
Sentence structure and causalitypattern in conceptual graph formatmainroottoleratebev-chwell andman cc resultccin inloc phrresponsepcomppatientpcompclinicalattradetthisdetsignificantattrWe constructed the causality patterns foreach causality identifier, to express the differentsentence constructions that the causality identi-fier can be involved in, and to indicate whichparts of the sentence represent the cause and theeffect.
For each causality identifier, at least 20sentences containing the identifier were ana-lysed.
If the training sample abstracts did nothave 20 sentences containing the identifier, ad-ditional sentences were downloaded from theMedline database.
After the patterns were con-structed, they were applied to a new set of 20sentences from Medline containing the identi-fier.
Measures of precision and recall were cal-culated.
Each set of patterns are thus associatedwith a precision and a recall figure as a roughindication of how good the set of patterns is.The causality patterns are represented in lin-ear conceptual graph format with some exten-sions.
The symbols used in the patterns are asfollows:1.
Concept nodes take the following form:[concept_label] or [concept_label:role_indicator].
Concept_label can be:?
a character string in lower case, represent-ing a stemmed word?
a character string in uppercase, refering to aclass of synonymous words that can occupythat place in a sentence?
?
*?, a wildcard character that can matchany word?
?T?, a wildcard character that can matchwith any sub-tree.Role_indicator refers to a slot in the cause-effect template, and can take the form:?
role_label which is the name of a slot in thecause-effect template?
role_label = ?value?, where value is acharacter string that should be entered inthe slot in the cause-effect template (if?value?
is not specified, the part of thesentence that matches the conc pt_label isentered in the slot).2.
Relation nodes take the following form:(set_of_relations).
Set_of_relations can be:?
a relation_label, which is a character stringrepresenting a syntactic relation (these arethe relation tags used by Conexor?s FDGparser)?
relation_label | set of relations (?|?
indi-cates a logical ?or?)3.
&subpattern_label refers to a set of sub-graphs.Each node can also be followed by a ?+?indicating that the node is mandatory.
If themandatory nodes are not found in the sentence,then the pattern is rejected and no information isextracted from the sentence.
All other nodes areoptional.
An example of a causality pattern isgiven in Fig.
2.4.3 Pattern matchingThe information extraction process involvesmatching the causality patterns with the parsetrees of the sentences.
The parse trees and theca sality patterns are both represented in thelinear conceptual graph notation.
The patternmatching for each sentence follows the follow-ing procedure:1. the causality identifiers that match withkeywords in the sentence are identified,2.
the causality patterns associated with eachmatching causality identifier are shortlisted,3.
for each shortlisted pattern, a matching pro-cess is carried out on the sentence.The matching process involves a kind ofspreading activation in both the causality patterngraph and the sentence graph, starting from thenode representing the causality identifier.
If apattern node matches a sentence node, thematching node in the pattern and the sentenceare activated.
This activation spreads outwards,with the causality identifier node as the center.When a pattern node does not match a sentencenode, then the spreading activation stops for thatbranch of the pattern graph.
Procedures are at-tached to the nodes to check whether there is amatch and to extract words to fill in the slots inthe cause-effect template.
The pattern matchingprogram has been implemented in Java (JDK1.2.1).
An example of a sentence, matching pat-tern and filled template is given in Fig.
2.5 EvaluationA total of 68 patterns were constructed for the35 causality identifiers that occurred at leasttwice in the training abstracts.
The patterns wereappli d to two sets of new abstracts downloadedfrom Medline: 100 new abstracts from the origi-nal four medical areas (25 abstracts from eacharea), and 30 abstracts from two new domains(15 each) ?
digestive system diseases and respi-ratory tract diseases.
Each test abstract wasanalyzed by at least 2 of the authors to identify?medically relevant?
cause and effect.
A fairnumber of causal relations in the abstracts aretrivial and not medically relevant, and it was feltthat it would not be useful for the informationextraction system to extract these trivial causalrelations.Of the causal relations manually identifiedin the abstracts, about 7% are implicit (i.e.
haveto be inferred using knowledge-based inferenc-ing) or occur across sentences.
Since the focusof the study is on explicitly expressed cause andeffect within a sentence, only these are includedin the evaluation.
The evaluation results are pre-sented in Table 4.
Recall is the percentage of theslots filled by the human analysts that are cor-rectly filled by the computer program.
Precisionis the percentage of slots filled by the computerprogram that are correct (i.e.
the text entered inthe slot is the same as that entered by the humananalysts).
If the text entered by the computerprogram is partially correct, it is scored as 0.5(i.e.
half correct).
The F-measure given in Table4 is a combination of recall and precisionequally weighted, and is calculated using theformula (MUC-7):2*precision*recall / (precision + recall)Table 4.
Extraction resultsSlot RecallPreci-sionF-MeasureResults for 100 abstracts from theoriginal 4 medical areasCausalityIdentifier.759 .768 .763Cause .462 .565 .508Effect .549 .611 .578Modality .410 .811 .545Results for 30 abstracts from 2 newmedical areasCausalityIdentifier.618 .759 .681Cause .415 .619 .497Effect .441 .610 .512Modality .542 .765 .634For the 4 medical areas used for building theextraction patterns, the F-measure for the causeand effect slots are 0.508 and 0.578 respectively.If implicit causal relations are included in theevaluation, the recall measures for cause andeffect are 0.405 and 0.481 respectively, yieldingan F-measure of 0.47 for cause and 0.54 for ef-fect.
The results are not very good, but not verybad either for an information extraction task.For the 2 new medical areas, we can see inTable 4 that the precision is about the same asfor the original 4 medical areas, indicating thatthe current extraction patterns work equally wellin th  new areas.
The lower recall indicates thatn w causality identifiers and extraction patternsneed to be constructed.The sources of errors were analyzed for theset of 100 test abstracts and are summarized inTable 5.
Most of the spurious extractions (in-formation extracted by the program as cause oreffect but not identified by human analysts) wereactually causal relations that were not medicallyrelevant.
As mentioned earlier, the manual iden-tification of causal relations focused on medi-cally relevant causal relations.
In the caseswher  the program did not correctly extractcause and effect information identified by theanalysts, half were due to incorrect parser out-put, and in 20% of the cases, causality patternshave not been constructed for the causality iden-tifier found in the sentence.We also analyzed the instances of implicitcausal relations in sentences, and found thatmany of them can be identified using someamount of semantic analysis.
Some of them in-volve words like when, after and with that indi-cate a time sequence, for example:?
The results indicate that changes to 8-OH-DPAT and clonidine-induced responses oc-cur quicker with the combination treatmentthan with either reboxetine or sertralinetreatments alone.?
There are also no reports of serious adverseevents when lithium is added to a monoam-ine oxidase inhibitor.?
Four days after flupenthixol administration,the patient developed orolingual dyskineticmovements involving mainly tongue bitingand protrusion.Table 5.
Sources of Extraction ErrorsA.
Spurious errors (the program identifiedcause or effect not identified by the hu-man judges)A1.The relations extraced are not relevant to medi-cine or disease.
(84.1%)A2.Nominalized or adjectivized verbs are identifiedas causative verbs by the program because ofparser error.
(2.9%)A3.Some words and sentence constructions that areused to indicate cause-effect can be used to indi-cate other kinds of relations as well.
(13.0%)B.
Missing slots (cause or effect not ex-tracted by program), incorrect text ex-tracted, and partially correct extractionB1.Complex sentence structures that are not in-cluded in the pattern.
(18.8%)B2.The parser gave the wrong syntactic structure ofa sentence.
(49.2%)B3.Unexpected sentence structure resulting in theprogram extracting information that is actuallynot a cause or effect.
(1.5%)B4.Patterns for the causality identifier have not beenconstructed.
(19.6%)B5.Sub-tree error.
The program extracts the relevantsub-tree (of the parse tree) to fill in the cause oreffect slot.
However, because of the sentenceconstruction, the sub-tree includes both the causeand effect resulting in too much text being ex-tracted.
(9.5%)B6.Errors caused by pronouns that refer to a phraseor clause within the same sentence.
(1.3%)In these cases, a treatment or drug is associatedwith a treatment response or physiological event.If noun phrases and clauses in sentences can beclassified accurately into treatments and treat-ment responses (perhaps by using Medline?sMedical Subject Headings), then such implicitcausal relations can be identified automatically.Another group of words involved in implicitcausal relations are words like receive, get andtake, that indicate that the patient received adrug or treatment, for example:?
The nine subjects who received p24-VLPand zidovudine had an augmentation and/orbroadening of their CTL response comparedwith baseline (p = 0.004).Such causal relations can also be identified bysemantic analysis and classifying noun phrasesand clauses into treatments and treatment r-sponses.6.
ConclusionWe have described a method for performingautomatic extraction of cause-effect informationfrom textual documents.
We use Conexor?s FDGparser to construct a syntactic parse tree for eachtarget sentence.
The parse tree is matched with aset of graphical causality patterns that indicatethe presence of a causal relation.
When a matchis found, various attributes of the causal relation(e.g.
the cause, the effect, and the modality) canthen be extracted and entered in a cause-effecttemplate.The accuracy of our extraction system is notyet satisfactory, with an accuracy of about 0.51(F-measure) for extracting the cause and 0.58for extracting the effect that are explicitly ex-pressed.
If both implicit and explicit causal rela-tions are included, the accuracy is 0.41 for causeand 0.48 for effect.
We were heartened to findthat when the extraction patterns were applied to2 new medical areas, the extraction precisionwas the same as for the original 4 medical areas.Future work includes:1.
Constructing patterns to identify causal re-lations across sentences2.
Expanding the study to more medical areas3.
Incorporating semantic analysis to extractimplicit cause-effect information4.
Incorporating discourse processing, includ-ing anaphor and co-reference resolution5.
Developing a method for constructing ex-traction patterns automatically6.
Investigating whether the cause-effect in-formation extracted can be chained togetherto synthesize new knowledge.Two aspects of discourse processing is beingstudied: co-reference resolution and hypothesisconfirmation.
Co-reference resolution is impor-t nt for two reasons.
The first is the obvious rea-son that to extract complete cause-effect infor-mation, pronouns and references have to ber solved and replaced with the information thatthey refer to.
The second reason is that quite of-ten a causal relation between two events is ex-pressed more than once in a medical abstract,each time providing new information about thecausal situation.
The extraction system thusneeds to be able to recognize that the differentcausal expressions refer to the same causalsituation, and merge the information extractedfrom the different sentences.The second aspect of discourse processingbeing investigated is what we refer to as hy-pothesis confirmation.
Sometimes, a causal rela-tion is hypothesized by the author at the begin-ning of the abstract.
This hypothesis may beconfirmed or disconfirmed by another sentencelater in the abstract.
The information extractionsystem thus has to be able to link the initial hy-pothetical cause-effect expression with the con-firmation or disconfirmation expression later inthe abstract.Finally, we hope eventually to develop asystem that not only extracts cause-effect infor-mation from medical abstracts accurately, butalso synthesizes new knowledge by chaining theextracted causal relations.
In a series of studies,Swanson (1986) has demonstrated that logicalconnections between the published literature oftwo medical research areas can provide new anduseful hypotheses.
Suppose an article reportsthat A causes B, and another article reports thatB causes C, then there is an implicit logical linkbetween A and C (i.e.
A causes C).
This relationwould not become explicit unless work is doneto extract it.
Thus, new discoveries can be madeby analysing published literature automatically(Finn, 1998; Swanson & Smalheiser, 1997).ReferencesAltenberg, B.
(1984).
Causal linking in spoken andwritten English.
Studia Linguistica, 38(1), 20-69.Cardie, C. (1997).
Empirical methods in informationextraction.
AI Magazine, 18(4), 65-79.Cowie, J., & Lehnert, W. (1996).
Information extrac-tion.
Communications of the ACM, 39(1), 80-91.Finn, R. (1998).
Program Uncovers Hidden Connec-tions in the Literature.
Th  Scientist, 12( 0), 12-13.Gaizauskas, R., & Wilks, Y.
(1998).
Informationextraction beyond document retrieval.
Journ l ofDocumentation, 54(1), 70-105.Garcia, D. (1997).
COATIS, an NLP system to locateexpressions of actions connected by causality links.In Knowledge Acquisition, Modeling and Ma-agement, 10th European Workshop, EKAW ?97Proceedings (pp.
347-352).
Berlin: Springer-Verlag.Joskowsicz, L., Ksiezyk, T., & Grishman, R. (1989).Deep domain models for discourse analysis.
In TheAnnual AI Systems in Government Conference (pp.195-200).
Silver Spring, MD: IEEE Computer So-ciety.Kaplan, R. M., & Berry-Rogghe, G. (1991).
Knowl-edge-based acquisition of causal relationships intext.
Knowledge Acquisition, 3(3), 317-337.Khoo, C., Chan, S., Niu, Y., & Ang, A.
(1999).
Amethod for extracting causal knowledge from tex-tual databases.
Singapore Journal of Library &Information Management, 28, 48-63.Khoo, C.S.G., Kornfilt, J., Oddy, R.N., & Myaeng,S.H.
(1998).
Automatic extraction of cause-effectinformation from newspaper text without knowl-edge-based inferencing.
Literary and LinguisticComputing, 13(4), 177-186.Kontos, J., & Sidiropoulou, M. (1991).
On the acqui-sition of causal knowledge from scientific textswith attribute grammars.
Expert Systems for Infor-mation Management, 4(1), 31-48.MUC-5.
(1993).
Fifth Message Understanding Co-fer nce (MUC-5).
San Francisco: Morgan Kauf-mann.MUC-6.
(1995).
Sixth Message Understanding Con-ference (MUC-6).
San Francisco: Morgan Kauf-mann.MUC-7.
(2000).
Message Understanding Confer-e ce proceedings (MUC-7) [Online].
Available:http://www.muc.saic.com/proceedings/muc_7_toc.html.Selfri ge, M., Daniell, J., & Simmons, D. (1985).Learning causal models by understanding real-world natural language explanations.
In The Sec-ond Conference on Artificial Intelligence Applica-tions: The Engineering of Knowledge-Based Sys-tems (pp.
378-383).
Silver Spring, MD: IEEEComputer Society.Sowa, J.F.
(1984).
Conceptual structures: Informa-processing in man and machine.
Reading,MA: Addison-Wesley,.Swanson, D.R.
(1986).
Fish oil, Raynaud?s Syn-drome, and undiscovered public knowledge.
Per-spectives in Biology and Medicine, 30(1), 7-18.Swanson, D.R., & Smalheiser, N.R.
(1997).
An inter-active system for finding complementary litera-tures: A stimulus to scientific discovery.
ArtificialIntelligence, 91, 183-203.
