Proceedings of NAACL-HLT 2013, pages 691?696,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsAn opinion about opinions about opinions: subjectivity and the aggregatereaderAsad SayeedComputational Linguistics and Phonetics / M2CI Cluster of ExcellenceSaarland University66123 Saarbru?cken, Germanyasayeed@coli.uni-saarland.deAbstractThis opinion piece proposes that recent ad-vances in opinion detection are limited in theextent to which they can detect important cat-egories of opinion because they are not de-signed to capture some of the pragmatic as-pects of opinion.
A component of these is theperspective of the user of an opinion-miningsystem as to what an opinion really is, which isin itself a matter of opinion (metasubjectivity).We propose a way to define this component ofopinion and describe the challenges it posesfor corpus development and sentence-level de-tection technologies.
Finally, we suggest thatinvestment in techniques to handle metasub-jectivity will likely bear costs but bring bene-fits in the longer term.1 IntroductionOpinion mining, also known as sentiment analysis(Pang and Lee, 2008), is a relatively recent areaof research in natural language processing.
It hasgrown very quickly as a research area, developingaround a small number of basic approaches.
How-ever, these approaches are based on particular def-initions of opinion, assumptions about opinion ex-pressions, and evaluation practices that we believeneed to be expanded in order for sentiment analysisto reach new domains and applications.We are not the first to express concern over thedirection of sentiment analysis as a field.
This paperseeks to further expand upon the views expressedin Alm (2011) that prevailing evaluation concepts insentiment analysis limit the kinds of models we canbuild, particularly through the encouragement of afocus on ?high-performing?
systems.The central thread that connects our view of thefield is the idea that the basis of standard techniquesand evaluation in information retrieval and extrac-tion that underlie existing approaches needs to berethought for applications that are inherently subjec-tive and that the field needs to return to more theoret-ical groundwork.
This will entail sacrificing some ofthe performance gains made in recent times, as wellas potentially reducing the capacity for easily com-parable research that has been gained by the rapidadoption of corpora that are very easily produced,shared, and used.This problem is particularly relevant in the expan-sion of sentiment analysis techniques to areas suchas market prediction (Bollen et al 2010) and socialscience.
In these areas, it is not enough to detectopinions in predefined areas of text or even to minefor the locations of opinions in large corpora, but it isnecessary to be able to connect opinions across doc-uments and to reconstruct the social networks thatunderlie social trends.
Furthermore, it must be pos-sible to do this in text that can have an arbitrary num-ber of opinions intertwined in ways that go beyondthe base case of product review text.
This requiresboth additional consideration of the perspective ofthe user and attention to the finer-grained details ofsentiment expression.Do existing resources and techniques really re-flect the ultimate goals and end-uses of fine-grainedopinion-mining, particularly focusing on the senten-tial and sub-sentential levels?
Consider an ?idealcase?
of a marketing director or a political campaignmanager requesting a forecast of how a product orconcept will unfold in the media and market.
Howdo the present conceptions of opinion mining relateto this among other real-world problems of affect?691In the remainder of this position paper, we brieflydescribe three closely related issues in sentimentanalysis that pertain to expanding beyond the cur-rent limits of the field.2 Challenges2.1 Metasubjectivity and pragmatic opinionRecent efforts in opinion mining (Ruppenhoferet al 2008) technology have often tended to takethe position that opinion is an internal characteristicof the speaker, a ?private state?, and that the overallaim of the opinion mining field is to discover tech-niques that allow us to infer the that latent state fromthe evidence presented in text.
But this may not al-ways be appropriate to all circumstances.A very simple boundary example comes from So-masundaran and Wiebe (2009): The blackberry issomething like $150 and the iPhone is $500.
Thiscomes from a corpus of opinions on cell phone pref-erence, and this sentence is intended to be a negativeopinion about the iPhone.
According to Somasun-daran and Wiebe, this kind of opinion-expressionrequires a model of world-knowledge that is eithernot practical under current technologies, or it re-quires the development of techniques that can re-cruit a larger context in the text in order to make thecorrect inference.
They refer to this phenomenon as?pragmatic opinion?.One crucial piece of world-knowledge that pro-vides an opinion its polarity is that of the perspectiveof the reader or listener to the opinion; we can min-imally represent this as the ?application?
to whichthe opinion will be put.
We refer to variation in theapplication-specific interpretation of the concept ofopinion as ?metasubjectivity.?
Metasubjectivity isa serious problem in extending sentiment analysiswork to other domains, particularly for reasons thatwe describe in the next section.Metasubjectivity is closely related to the underly-ing relative nature of veridicality assessment.
Theveridicality of an utterance is the level to which thelistener may judge it as a factual statement about theworld.
de Marneffe et al(2012) note that this re-quires, in some cases, extensive pragmatic knowl-edge.
They present this sentence as an example:FBI agents alleged in court documents today thatZazi had admitted receiving weapons and explosivestraining from al-Qaeda operatives in Pakistan lastyear.
There is an interplay between the trustworthi-ness of the source of the sentence, the mentioned en-tities, and the veridicality of words alleged and ad-mitted, all of which are mediated by the perspectiveof the reader.
For example, if the reader is stronglyinclined to trust the FBI, then there may be a highlevel of veridicality in ?alleged?
than otherwise.
Butit could also be the case that the reader believes thatZazi is misleading the FBI.These distinctions operate directly in the contextof determining polarity in opinion mining.
Considerthe following example sentence from a major in-formation technology (IT) business journal: LloydHession, chief security officer at BT Radianz in NewYork, said that virtualization also opens up a slew ofpotential network access control issues.This sentence can be taken to represent an opinionor merely a factual statement.
A casual reader with-out experience in the domain of IT might be con-vinced that this sentence is simply a neutral state-ment of fact.
But from the perspective of an inter-ested reader such as an investor, this may actuallyrepresent a mildly negative statement about virtu-alization, or it may represent a negative statementabout network access control.
From the perspectiveof the manager of an IT support department, it maywell be very negative.
But from the perspective ofLloyd Hession, we have no idea outside of the prag-matic context.
Mr. Hession could be a developer ofIT solutions, in which case he would view this as apositive development for the market in new networkaccess control technologies, or, for that matter, hemay be invested in a set of technological approachesthat compete with virtualization.This extends to the vocabulary used to expressopinions.
The use of the word ?slew?, in this case,has negative connotations, but only if the wholestatement is construed by the perspective of thereader to represent an opinion.
However, if LloydHession is a provider of new network access controlsolutions, then the use of ?open?
may convert thisnegative context into a positive context.This is not merely a matter of the perspectivesof individual users and participants.
It is a matterof how providers of sentiment analysis applicationschoose to represent these choices to the user, whichis in turn reflected in the way in which they create692resources, models, and algorithms.
If, for example,our goal is to provide sentiment analysis for domain-specific market prediction or social science, then weneed to model the reactions not of the private stateof Mr. Hession or of the writer of the article, butof an ?aggregate reader?
with a presumed interest inthe text.
Here is a definition of this external stateaggregate reader model that might apply to the ITbusiness domain:Opinion source A expresses opinion about opiniontarget B if an interested third party C?s actions to-wards B may be affected by A?s textually recordedactions, in a context where actions have positive ornegative weight.This accounts for the cases in which the opinion ofinterest in the IT example happens to be held by aninvestor or a IT support manager or other interestedreaders, and it can be generalized to apply to otherdomains in which the world?s opinion matters.It is once again within the area of veridicality as-sessment that we suggest that a possible form ofsolution exists.
de Marneffe et al(2012) presenta model in which the uncertainty in veridicality isrepresented as a distribution rather than a discretelabelling problem.In the case of veridicality, there is generally anultimate ground truth in verifiable facts about theworld, apart from the relative veridical nature of astatement.
For sentiment, however, there is no suchfoundation: opinion presence and opinion polarityexist entirely relative to the perspective of the ag-gregate reader.
This requires a different process ofannotation, the challenges of which we describe inthe next section.2.2 Corpus development and evaluationConsidering the prevalence of machine learningtechniques in opinion mining research, addressingthe issue of metasubjectivity must mean addressingthe matter of the corpus development.Existing evaluation techniques depend on a no-tion of ?gold standard data?
that are produced byexpert judges or crowdsourced annotators (Wilson,2007; Kessler et al 2010; Hsueh et al 2009).
Thereare NLP areas in which popular notions of objec-tivity may partly apply, such as query relevance;due, among other things, to metasubjectivity, opin-ion mining is not entirely one of these.
However,gold standard data for opinion mining is typicallyproduced using procedures that are standard for in-formation retrieval research, and the quality mea-sures that are generally used happen to assume thepresence of an underlying objective truth.This assumption can be coerced to fit particularcases.
For example, a large proportion of opinionmining research is invested in predicting the rat-ings of product reviews and then aggregating resultsinto a single ratings summary, sometimes based ona lower-level breakdown of product features (de Al-bornoz et al 2011).
Implicit in this type of workis the assumption of the existence of an ideal raterwho uses language in a roughly predictable way toexpress his or her feelings about the text.The users of these types of systems can be as-sumed, to some degree of safety, to share some ofthe expectations of the builders of these systems,particularly since groups of users as product ratersare often the source of the information itself.But in environments where the users of the sys-tem may have various different perspectives on thenature of sentiment, it does not make sense to as-sume that there would ever be significant agree-ment among annotators, particularly for market-relevant applications where prediction of reader re-action is central to the task.
We attempted to an-notate IT business press articles for sentence-levelreader-perspective opinion occurrences and foundthat multiple trained annotators had very low inter-rater agreement by Cohen?s ?.
Multiple attemptsat further annotator training and error analysis re-vealed that the annotators simply found it very dif-ficult to agree on what the definition of an opinionwas.
Originally, we had two trained student anno-tators for this task, with repeated training and jointpractice annotations in order to achieve consensus asto what counts as an opinion mention instance andwhat does not.
Other groups of annotators and an-notation designs had no better success.However, we observed that this appears to be pri-marily a problem of conservativity where annotatorsdiffered in the quantity of sentences that they con-sidered to be opinionated, and had a large amount ofoverlap in those that they did consider to be opinion-ated.
Further discussion with the annotators foundthat some simply had a much lower threshold atwhich they would consider a sentence to contain an693opinion.
In other words, this form of annotation ismore affected by metasubjectivity than opinion an-notation focused on opinion source perspective.
Itshould be noted that this is a different task fromfinding opinion sources and labelling the textual ev-idence of their private states; we were attempting tomodel the ?ideal case?
we identified in section 1.We suggest that the answer to this problem isto deploy the concept of the aggregate reader men-tioned in the previous section and to pose the anno-tation question indirectly.
The former requires thecollection of data from a larger number of peopleand can be provided by existing crowdsourcing tech-niques (Snow et al 2008).
The latter, however, re-quires designing the annotation in such a way thatit avoids letting the annotator consider the question:?What is an opinion??
This is most likely done bya user interface that simulates the behaviour of theintended aggregate reader (Sayeed et al 2011).2.3 Grammatical expressionThere are a number of types of features with whichone can construct and train supervised sentence-level sentiment detection models.
Most recent tech-niques (Kim and Hovy, 2006; Choi et al 2006;Jakob and Gurevych, 2010) take into account thesyntactic context of the sentence but limit theamount of syntactic context thus used.
These re-strictions reduce the presence or absence of partic-ular structures to binary features in the model.
Weargue that we need techniques that take into accountmore syntactic context, particularly without makinguse of predefined structures.The latest techniques make use of larger syntac-tic contexts with potentially unlimited scope.
Oneexample is Nakagawa et al(2010), who use fac-tor graphs (McCallum et al 2009) to learn a modelthat traces paths through the dependency trees ofopinion-relevant sentences (de Marneffe and Man-ning, 2008).
However, this is in the service of polar-ity classification, as it assumes that the appropriatesentences have already been identified; then it is amatter of correctly processing negations and otherpolarity-changing items.
The challenge of metasub-jectivity is a barrier to opinion sentence detection it-self, well before polarity classification.Another example is Qiu et al(2011).
They aremore directly focused on detecting opinion-relevantlanguage.
However, they make use of a system ofhard-coded heuristics to find opinion words in de-pendency parses.
While these types of heuristicssupport longer-distance syntactic relations, they tendto focus on cases where some form of semantic com-positionality holds.
However, consider this sentencefrom the IT business press: The contract is consis-tent with the desktop computing Outsourcing dealsCitibank awarded EDS and Digital Equipment in1996.
.
.
In this case, an interested aggregate readermight note that ?awarded?
is a word that puts ?out-sourcing?
in a positive light.
However, the syntac-tic relationship between these two words does notdirectly imply or permit any semantic composition-ality, In order to find these relationships, we wouldneed to invest in techniques that can learn from ar-bitrary non-compositional structure, thereby poten-tially capturing patterns in grammar that actually re-flect some aspects of external pragmatic knowledge.3 ConclusionsThis paper has proposed a challenge for opinionmining, the challenge of metasubjectivity: where theanswer to the question ?What is an opinion??
is initself an opinion and an intrinsic part of the task.
Wefirst established the context of metasubjectivity rela-tive to existing characterizations of the opinion min-ing task, establishing the notion of an external aggre-gate reader as a way to extend from existing notionsof sentiment as an internal state.
Then we describedhow this affects the annotation process, given theas-yet-continuing dependence on supervised corpus-based detection techniques.
Finally, we describedhow this affects sentence-level fine-grained opiniondetection at the level of syntactic analysis.One of the risks for the field in proceeding toinvestigations of how to deal with the questionof metasubjectivity is one familiar in natural lan-guage processing as a whole: there is a strong riskthat these techniques will?initially and for a non-trivial quantity of time?cause the incremental per-formance gains in existing research to be lost ordamaged.
It will also require the creation of newtraining corpora and related resources, temporarilythreatening comparability.
Nevertheless, we believethat these risks need to be accepted in order to makeprogress in sentiment analysis.694ReferencesAlm, C. O.
(2011).
Subjective natural languageproblems: Motivations, applications, characteri-zations, and implications.
In ACL (Short Papers).Bollen, J., Mao, H., and Zeng, X.-J.
(2010).
Twit-ter mood predicts the stock market.
CoRR,abs/1010.3003.Choi, Y., Breck, E., and Cardie, C. (2006).
Joint ex-traction of entities and relations for opinion recog-nition.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP).de Albornoz, J., Plaza, L., Gerva?s, P., and D??az,A.
(2011).
A joint model of feature miningand sentiment analysis for product review rating.In Clough, P., Foley, C., Gurrin, C., Jones, G.,Kraaij, W., Lee, H., and Mudoch, V., editors, Ad-vances in information retrieval, volume 6611 ofLecture Notes in Computer Science, pages 55?66.Springer Berlin / Heidelberg.de Marneffe, M.-C. and Manning, C. D. (2008).The stanford typed dependencies representation.In CrossParser ?08: Coling 2008: Proceed-ings of the workshop on Cross-Framework andCross-Domain Parser Evaluation, Morristown,NJ, USA.
Association for Computational Linguis-tics.de Marneffe, M.-C., Manning, C. D., and Potts, C.(2012).
Did it happen?
the pragmatic complex-ity of veridicality assessment.
Computational lin-guistics, 35(1).Hsueh, P.-Y., Melville, P., and Sindhwani, V. (2009).Data quality from crowdsourcing: a study of an-notation selection criteria.
In Proceedings of theNAACL HLT 2009 Workshop on Active Learn-ing for Natural Language Processing, HLT ?09,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Jakob, N. and Gurevych, I.
(2010).
Extracting opin-ion targets in a single and cross-domain settingwith conditional random fields.
In EMNLP.Kessler, J. S., Eckert, M., Clark, L., and Nicolov, N.(2010).
The 2010 ICWSM JDPA sentment cor-pus for the automotive domain.
In 4th Int?l AAAIConference on Weblogs and Social Media DataWorkshop Challenge (ICWSM-DWC 2010).Kim, S.-M. and Hovy, E. (2006).
Extracting opin-ions, opinion holders, and topics expressed in on-line news media text.
In SST ?06: Proceedingsof the Workshop on Sentiment and Subjectivity inText, pages 1?8, Morristown, NJ, USA.
Associa-tion for Computational Linguistics.McCallum, A., Schultz, K., and Singh, S. (2009).Factorie: Probabilistic programming via impera-tively defined factor graphs.
In Neural Informa-tion Processing Systems (NIPS).Nakagawa, T., Inui, K., and Kurohashi, S. (2010).Dependency tree-based sentiment classificationusing crfs with hidden variables.
In HLT-NAACL.Pang, B. and Lee, L. (2008).
Opinion mining andsentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2).Qiu, G., Liu, B., Bu, J., and Chen, C. (2011).
Opin-ion word expansion and target extraction throughdouble propagation.
Computational linguistics,37(1):9?27.Ruppenhofer, J., Somasundaran, S., and Wiebe, J.(2008).
Finding the sources and targets of sub-jective expressions.
In Calzolari, N., Choukri, K.,Maegaard, B., Mariani, J., Odjik, J., Piperidis, S.,and Tapias, D., editors, Proceedings of the SixthInternational Language Resources and Evalua-tion (LREC?08), Marrakech, Morocco.
EuropeanLanguage Resources Association (ELRA).Sayeed, A.
B., Rusk, B., Petrov, M., Nguyen,H.
C., Meyer, T. J., and Weinberg, A.
(2011).Crowdsourcing syntactic relatedness judgementsfor opinion mining in the study of informationtechnology adoption.
In Proceedings of the Asso-ciation for Computational Linguistics 2011 work-shop on Language Technology for Cultural Her-itage, Social Sciences, and the Humanities (LaT-eCH).
Association for Computational Linguistics.Snow, R., O?Connor, B., Jurafsky, D., and Ng, A.
Y.(2008).
Cheap and fast?but is it good?
: evalu-ating non-expert annotations for natural languagetasks.
In EMNLP 2008.Somasundaran, S. and Wiebe, J.
(2009).
Recogniz-ing stances in online debates.
In Proceedings of695the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Con-ference on Natural Language Processing of theAFNLP: Volume 1, ACL ?09.Wilson, T. (2007).
Fine-grained Subjectivity andSentiment Analysis: Recognizing the Intensity,Polarity, and Attitudes of private states.
PhD the-sis, Intelligent Systems Program, University ofPittsburgh.696
