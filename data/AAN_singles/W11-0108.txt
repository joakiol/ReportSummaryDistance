Modular Graph Rewriting to Compute SemanticsGuillaume BonfanteNancy-Universite?
- LORIAbonfante@loria.frBruno GuillaumeINRIA - LORIAguillaum@loria.frMathieu MoreyNancy-Universite?
- LORIAmoreymat@loria.frGuy PerrierNancy-Universite?
- LORIAperrier@loria.frAbstractTaking an asynchronous perspective on the syntax-semantics interface, we propose to use modu-lar graph rewriting systems as the model of computation.
We formally define them and demonstratetheir use with a set of modules which produce underspecified semantic representations from a syn-tactic dependency graph.
We experimentally validate this approach on a set of sentences.
The resultsopen the way for the production of underspecified semantic dependency structures from corpora an-notated with syntactic dependencies and, more generally, for a broader use of modular rewritingsystems for computational linguistics.IntroductionThe aim of our work is to produce a semantic representation of sentences on a large scale using a formaland exact approach based on linguistic knowledge.
In this perspective, the design of the syntax-semanticsinterface is crucial.Based on the compositionality principle, most models of the syntax-semantics interface use a syn-chronous approach: the semantic representation of a sentence is built step by step in parallel with itssyntactic structure.
According to the choice of the syntactic formalism, this approach is implemented indifferent ways: in a Context-Free Grammars (CFG) style framework, every syntactic rule of a grammaris associated with a semantic composition rule, as in the classical textbook by Heim and Kratzer (1998);following the principles introduced by Montague, Categorial Grammars use an homomorphism from thesyntax to the semantics (Carpenter (1992)).
HPSG integrates the semantic and syntactic representationsin feature structures which combine by unification (Copestake et al (2005)).
LFG follows a similar prin-ciple (Dalrymple (2001)).
In a synchronous approach, the syntax-semantics interface closely depends onthe grammatical formalism.
Building such an interface can be very costly, especially if we aim at a largecoverage for the grammar.In our work, we have chosen an asynchronous approach in the sense that we start from a givensyntactic analysis of a sentence to produce a semantic representation.
With respect to the synchronousapproach, a drawback is that the reaction of the semantics on the syntax is delayed.
On the other hand,the computation of the semantics is made relatively independent from the syntactic formalism.
The onlyconstraint is the shape of the output of the syntactic analysis.In the formalisms mentioned above, the syntactic structure most often takes the form of a phrasestructure, but the choice of constituency for the syntax makes the relationship with the semantics morecomplicated.
We have chosen dependency graphs, because syntactic dependencies are closely relatedto predicate-argument relations.
Moreover, they can be enriched with relations derived from the syntax,which are usually ignored, such as the arguments of infinitives or the anaphora determined by the syntax.One may observe that our syntactic representation of sentences involves plain graphs and not trees.Indeed, these relations can give rise to multiple governors and dependency cycles.
On the semantic side,65we have also chosen graphs, which are widely used in different formalisms and theories, such as DMRS(Copestake (2009)) or MTT (Mel?c?uk (1988)) .The principles being fixed, our problem was then to choose a model of computation well suitedto transforming syntactic graphs into semantic graphs.
The ?-calculus, which is widely used in formalsemantics, is not a good candidate because it is appropriate for computing on trees but not on graphs.
Ourchoice naturally went to graph rewriting.
Graph rewriting is barely used in computational linguistics;it could be due to the difficulty to manage large sets of rules.
Among the pioneers in the use of graphrewriting, we mention Hyvo?nen (1984); Bohnet and Wanner (2001); Crouch (2005); Jijkoun and de Rijke(2007); Be?daride and Gardent (2009); Chaumartin and Kahane (2010).A graph rewriting system is defined as a set of graph rewrite rules and a computation is a sequenceof rewrite rule applications to a given graph.
The application of a rule is triggered via a mechanism ofpattern matching, hence a sub-graph is isolated from its context and the result is a local modification ofthe input.
This allows a linguistic phenomenon to be easily isolated for applying a transformation.Since each step of computation is fired by some local conditions in the whole graph, it is well knownthat one has no grip on the sequence of rewriting steps.
The more rules, the more interaction betweenrules, and the consistency of the whole rule system becomes difficult to maintain.
This bothers ourambition of a large coverage for the grammar.
To solve this problem, we propose to organize rules inmodules.
A module is a set of rules that is linguistically consistent and represents a particular step ofthe transformation.
For instance, in our proposal, there is a module transforming the syntactic argumentsof verbs, predicative nouns and adjectives into their semantic arguments.
Another module resolves theanaphoric links which are internal to the sentence and determined by the syntax.From a computational point of view, the grouping of a small number of rules inside a module allowssome optimizations in their application, thus leading to efficiency.
For instance, the confluence of rewrit-ing is a critical feature ?
one computes only one normal form, not all of them ?
for the performanceof the program.
Since the underlying relation from syntax to semantics is not functional but relational,the system cannot be globally confluent.
Then, it is particularly interesting to isolate subsets of conflu-ent rules.
Second point, with a small number of rules, one gets much more control on their output.
Inparticular, it is possible to automatically infer some invariant properties of graphs along the computationwithin a particular module.
Thus, it simplifies the writing of the rules for the next modules.
It is alsopossible to plan a strategy in the global evaluation process.It is well known that syntactic parsers produce outputs in various formats.
As a by-product of ourapproach, we show that the choice of the input format (that is the syntax) seems to be of low importanceoverall.
Indeed, as far as two formats contain the same linguistic information with different representa-tions, a system of rewrite rules can be designed to transform any graph from one format to another as apreliminary step.
The same remark holds for the output formats.To illustrate our proposal, we have chosen the Paris7 TreeBank (hereafter P7TB) dependency formatdefined by Candito et al (2010) as the syntactic input format and the Dependency MRS format (hereafterDMRS) defined by Copestake (2009) as the semantic output format.
We chose those two formats becausethe information they represent, if it is not complete, is relatively consensual and because both draw onlarge scale experiments: statistical dependency parsing for French1 on the one hand and the DELPH-INproject2 on the other hand.Actually, in our experiments, since we do not have an appropriate corpus annotated according to theP7TB standard, we used our syntactic parser LEOPAR3 whose outputs differ from this standard and wedesigned a rewriting system to go from one format to the other.The paper is organized as follows.
In section 1, we define our graph rewriting calculus, the ?-calculus.In Section 2, we describe the particular rewriting system that is used to transform graphs from the syn-tactic P7TB format into the DMRS semantic format.
In Section 3, we present experimental results on atest suite of sentences.1http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html2http://www.delph-in.net/3http://leopar.loria.fr661 The ?-calculus, a graph rewriting calculusTerm rewriting and tree rewriting can be defined in a straightforward and canonical way.
Graph rewritingis much more problematic and there is unfortunately no canonical definition of a graph rewriting system.Graph rewriting can be defined through a categorical approach like SPO or DPO (Rozenberg (1997)).But, in practice, it is much easier to use a more operational view of rewriting where modification ofthe graph (the ?right-hand side?
of a rule) is defined by means of a set of commands; the control of theway rules are applied (the ?left hand-side?)
still uses pattern matching as this is done in traditional graphrewriting.In this context, a rule is a pair of a pattern and a sequence of commands.
We give below the formalmaterials about graphs, patterns, matchings and commands.
We illustrate the section with examples ofrules and of rewriting.1.1 Graph definitionIn the following, we suppose given a finite set L of edge labels corresponding to the kind of dependenciesused to describe sentences.
They may correspond to syntax or to semantics.
For instance, we useL = {SUJ, OBJ, ARG1, ANT, .
.
.
}.To decorate vertices, we use the standard notion of feature structures.
Let N be a finite set offeature names and A be a finite set of atomic feature values.
In our example, N = {cat,mood, .
.
.}
andA = {passive, v, n, .
.
.}.
A feature is a pair made of a feature name and a set of atomic values.
Thefeature (cat, {v, aux}) means that the feature name cat is associated to either the value v or aux.
In thesequel, we use the notation cat = v|aux for this feature.
Two features f = v and f ?
= v?
are compatiblewhenever f = f ?
and v ?
v?
6= ?.A feature structure is a finite set of features such that each feature name occurs at most once.
F de-notes the set of feature structures.
Two feature structures are compatible if their respective features withthe same name are pairwise compatible.A graph G is then defined by a 6-tuple (V, fs, E , lab, ?, ?)
with:?
a finite set V of vertices;?
a labelling function fs from V to F ;?
a finite set E of edges;?
a labelling function lab from E to L;?
two functions ?
and ?
from E to V which give the source and the target of each edge.Moreover, we require that two edges between the same couple of nodes cannot have the same label.1.2 Patterns and matchingsFormally, a pattern is a graph and a matching ?
of a pattern P = (V ?, fs?, E ?, lab?, ?
?, ?
?)
into a graphG = (V, fs, E , lab, ?, ?)
is an injective graph morphism from P to G. More precisely, ?
is a couple ofinjective functions: ?V from V ?
to V and ?E from E ?
to E which:?
respects vertex labelling: fs(?V(v)) and fs?
(v) are compatible;?
respects edge labelling: lab(?E(e)) = lab?(e);?
respects edge sources: ?
(?E(e)) = ?V(??(e));?
respects edge targets: ?
(?E(e)) = ?V(?
?
(e)).671.3 CommandsCommands are low-level operations on graphs that are used to describe the rewriting of the graph withina rule application.
In the description below, we suppose to be given a pattern matching ?
: P ?
G. Wedescribe here the set of commands which we used in our experiment so far.
Naturally, this set could beextended.?
del edge(?, ?, `) removes the edge labelled ` between ?
and ?.
More formally, we suppose that?
?
VP , ?
?
VP andP contains an edge e from?
to ?
with label ` ?
L. Then, del edge(?, ?, `)(G)is the graph G without the edge ?(e).
In the following, we give only the intuitive definition of thecommand: thanks to injectivity of the matching ?, we implicitly forget the distinction between xand ?(x).?
add edge(?, ?, `) adds an edge labelled ` between ?
and ?.
Such an edge is supposed not to existin G.?
shift edge(?, ?)
modifies all edges that are incident to ?
: each edge starting from ?
is moved tostart from ?
; similarly each edge ending on ?
is moved to end on ?;?
del node(?)
removes the ?
node in G. If G contains edges starting from ?
or ending on ?, theyare silently removed.?
add node(?)
adds a new node with identifier ?
(a fresh name).?
add feat(?, f = v) adds the feature f = v to the node ?.
If ?
already contains a feature name f ,it is replaced by the new one.?
copy feat(?, ?, f) copies the value of the feature named f from the node ?
to the node ?.
If ?does not contain a feature named f , nothing is done.
If ?
already contains a feature named f , it isreplaced by the new value.Note that commands define a partial function on graphs: the action add edge(?, ?, `) is undefinedon a graph which already contains an edge labelled ` from ?
to ?.The action of a sequence of commands is the composition of actions of each command.
Sequencesof commands are supposed to be consistent with the pattern:?
del edge always refers to an edge described in the pattern and not previously modified by adel edge or a shift edge command;?
each command refers only to identifiers defined either in the pattern or in a previous add node;?
no command refers to a node previously deleted by a del node command.Finally, we define a rewrite rule to be a pair of a pattern and a consistent sequence of commands.A first example of a rule is given below with the pattern on the left and the sequence of commandson the right.
This rule called INIT PASSIVE is used to remove the node corresponding to the auxiliaryof the passive construction and to modify the features accordingly.INIT PASSIVE?cat = vvoice = active?cat = vvoice = unkAUX PASSc1 = copy feat(?, ?,mood)c2 = copy feat(?, ?, tense)c3 = add feat(?, voice = passive)c4 = del edge(?, ?, AUX PASS)c5 = shift edge(?, ?
)c6 = del node(?
)Our second example (PASSIVE ATS) illustrates the add node command.
It is used in a passiveconstruction where the semantic subject of the verb is not realized syntactically.68PASSIVE ATS?cat = vvoice = passive?
?SUJ ATS c1 = del edge(?, ?, SUJ)c2 = add edge(?, ?, OBJ)c3 = del edge(?, ?, ATS)c4 = add edge(?, ?, ATO)c5 = add feat(?, voice = active)c6 = add node(?
)c7 = add edge(?, SUJ, ?
)1.4 RewritingWe consider a graph G and a rewrite rule r = (P, [c1, .
.
.
, ck]).
We say that G?
is obtained from G by arewrite step with the r rule (written G ?
?r G?)
if there is a matching morphism ?
: P ?
G and G?
isobtained from G by applying the composition of commands ck ?
.
.
.
?
c1.Let us now illustrate two rewrite steps with the rules above.
Consider the first graph below which isa syntactic dependency structure for the French sentence ?Marie est conside?re?e comme brillante?
[Maryis considered as bright].
The second graph is obtained by application of the INIT PASSIVE rewrite ruleand the last one with the PASSIVE ATS rewrite rule.Mariecat = nplemma = MARIEestcat = vlemma = E?TREvoice = activetense = presentconside?re?ecat = vlemma = CONSIDE?RERvoice = unkcommecat = preplemma = COMMEbrillantecat = adjlemma = BRILLANTSUJAUX PASS ATS OBJMariecat = nplemma = MARIEest conside?re?ecat = vlemma = CONSIDE?RERvoice = passivetense = presentcommecat = preplemma = COMMEbrillantecat = adjlemma = BRILLANTSUJ ATS OBJ Mariecat = nplemma = MARIEest conside?re?ecat = vlemma = CONSIDE?RERvoice = activetense = presentcommecat = preplemma = COMMEbrillantecat = adjlemma = BRILLANTSUJOBJ ATO OBJ1.5 Modules and normal formsA module contains a set of rewrite rules but, in order to have a finer control on the output of thesemodules, it is useful to declare some forbidden patterns.
Hence a module is defined by a set R of rulesand a set P of forbidden patterns.For a given module M = (R,P), we say that G?
is an M-normal form of the graph G if there is asequence of rewriting steps with rules of R from G to G?
: G ?
?r1 G1 ?
?r2 G2 .
.
.
?
?rk G?, if no ruleof R can be applied to G?
and no pattern of P matches in G?.In our experiment, forbidden patterns are often used to control the subset of edges allowed in normalforms.
For instance, the NORMAL module contains the forbidden pattern: AUX PASS .
Hence, wecan then safely suppose that no graph contains any AUX PASS edge afterward.2 From syntactic dependency graphs to semantic graphsLinguistic theories diverge on many issues including the exact definition of the linguistic levels andthe relationships between them.
Our aim here is not to commit to any linguistic theory but rather to69demonstrate that graph rewriting is an adequate and realistic computational framework for the syntax-semantics interface.
Consequently, our approach is bound to neither the (syntactic and semantic) formatswe have chosen nor the transformation modules we have designed; both are mainly meant to exemplifyour proposal.2.1 Representational formatsOur syntactic and semantic formats both rely on the notion of linguistic dependency.
The syntacticformat is an enrichment of the one which was designed to annotate the French Treebank (Abeille?
andBarrier (2004)) with surface syntactic dependencies (Candito et al (2010)).
The enrichment is twofold:?
if they are present in the sentence, the deep arguments of infinitives and participles (from participialsubordinate clauses) are marked with the usual labels of syntactic functions,?
the anaphora relations that are predictable from the syntax (i.e.
the antecedents of relative, reflexiveand repeated pronouns) are marked with a special label ANT.This additional information can already be provided by many syntactic parsers and is particularly inter-esting to compute semantics.The semantic format is DependencyMinimal Recursion Semantics (DMRS) which was introduced byCopestake (2009) as a compact and easily readable equivalent to Robust Minimal Recursion Semantics(RMRS), which was defined by Copestake (2007).
This underspecified semantic formalism was designedfor large scale experiments without committing to fine-grained semantic choices.
DMRS graphs containthe predicate-argument relations, the restriction of generalized quantifiers and the mode of combinationbetween predicates.
Predicate-argument relations are labelled ARGi, where i is an integer following afixed order of obliqueness SUJ, OBJ, ATS, ATO, A-OBJ, DE-OBJ.
.
.
.
Naturally, the lexicon must be consistentwith this ordering.
The restrictions of generalized quantifiers are labelled RSTR ; their bodies are notovertly expressed but can be retrieved from the graph.
There are three ways of combining predicates:?
EQ when two predicates are elements of a same conjunction;?
H when a predicate is in the scope of another predicate; it is not necessarily one of its argumentsbecause quantifiers may occur between them;?
NEQ for all other cases.2.2 Modular rewriting systemGraph rewriting allows to proceed step by step to the transformation of a syntactic graph into a semanticone, by associating a rewrite rule to each linguistic rule.
While the effect of every rule is local, groupingrules in modules allows a better control on the global effect of all rules.We do not have the space here to propose a system of rules that covers the whole French grammar.We however propose six modules which cover a significative part of this grammar (cleft clauses, coor-dination, enumeration, comparatives and ellipses are left aside but they can be handled by other rewritemodules):?
NORMAL handles the regular syntactic transformations involving predicates: it computes tenseand transforms all redistributions of arguments (passive and middle voices, impersonal construc-tions and the combination of them) to the active canonical form.
This reduces the number of rulesrequired to produce the predicate-argument relations in the ARG module below.?
PREP removes affixes, prepositions and complementizers.?
ARG transforms the verbal, nominal and adjectival predicative phrases into predicate-argumentrelations.70?
DET translates the determiner dependencies (denoted DET) to generalized quantifiers.?
MOD interprets the various modifier dependencies (denoted MOD), according to their specificity:adjectives, adverbs, adjunct prepositional phrases, participial clauses, relative clauses, adjunctclauses.?
ANA interprets all anaphoric relations that are determined by the syntax (denoted ANT).Modules provide an easy way to control the order in which rules are fired.
In order to properly set up therules in modules, we first have to fix the global ordering of the modules.
Some ordering constraints areevident: for instance, NORMAL must precede PREP, which must precede ARG.
The rules we present inthe following are based on the order NORMAL, PREP, ARG, DET, MOD, ANA.2.2.1 Normalization of syntactic dependenciesThe NORMAL module has two effects: it merges tense and voice auxiliaries with their past participleand brings all the argument redistributions back to the canonical active form.
This module accountsfor the passive and middle voices and the impersonal construction for verbs that are not essentiallyimpersonal.
The combination of the two voices with the impersonal construction is naturally expressedby the composition of the corresponding rewrite rules.
The two rules given in section 1.4 are part of thismodule.
The first rule (INIT PASSIVE) merges the past participle of the verb with its passive auxiliary.The auxiliary brings its mood and tense to the verb, which is marked as being passive.
The second rule(PASSIVE ATS) transforms a passive verb with a subject and an attribute of the subject into its activeequivalent with a semantically undetermined subject, an object (which corresponds to the subject of thepassive form) and an attribute of the object (which corresponds to the attribute of the subject of thepassive form).2.2.2 Erasure of affixes, prepositions and complementizersThe PREP module removes affixes, prepositions and complementizers.
For example, the rule given heremerges prepositions with the attribute of the object that they introduce.
The value of the preposition iskept to compute the semantics.PREP ATO?voice = active?cat = prepprep = ?
?ATO OBJ c1 = copy feat(?, ?, prep)c2 = del edge(?, ?, OBJ)c3 = shift edge(?, ?
)c4 = del node(?
)2.2.3 From lexical predicative phrases to semantic predicatesThe ARG module transforms the syntactic arguments of a predicative word (a verb, a common noun oran adjective) into its semantic arguments.
Following DMRS, the predicate-argument relations are notlabelled with thematic roles but only numbered.
The numbering reflects the syntactic obliqueness.ARG OBJ?
?cat = n|np|proOBJc1 = del edge(?, ?, OBJ)c2 = add edge(?, ?, ARG2)c3 = add edge(?, ?, NEQ)2.2.4 From determiners to generalized quantifiersDET reverts the determiner dependencies (labelled DET) from common nouns to determiners into depen-dencies of type RSTR from the corresponding generalized quantifier to the nominal predicate which isthe core of their restriction.71DET?cat = det?cat = nDETc1 = del edge(?, ?, DET)c2 = add edge(?, ?, RSTR)c3 = add edge(?, ?, H)2.2.5 Interpretation of different kinds of modificationMOD deals with the modifier dependencies (labelled MOD, MOD REL and MOD LOC), providing rulesfor the different kinds of modifiers.
Adjectives and adverbs are translated as predicates whose firstargument is the modified entity.
The modifier and modified entities are in a conjunction (EQ), exceptfor scopal adverbs which take scope (H) over the modified predicate.
Because only lexical informationenables to differentiate scopal from non-scopal adverbs, we consider all adverbs to be systematicallyambiguous at the moment.
Adjunct prepositional phrases (resp.
clauses) have a similar rule except thattheir corresponding predicate is the translation of the preposition (resp.
complementizer), which hastwo arguments: the modified entity and the noun (resp.
verb) which heads the phrase (resp.
clause).Participial and relative clauses exhibit a relation labelled EQ or NEQ between the head of the clause andthe antecedent, depending on the restrictive or appositive type of the clause.2.2.6 Resolution of syntactic anaphoraANA deals with dependencies of type ANT and merges their source and their target.
We apply them toreflexive, relative and repeated pronouns.3 ExperimentsFor the experimentation, we are interested in a test suite which is at the same time small enough to bemanually validated and large enough to cover a rich variety of linguistic phenomena.
As said earlier, weuse the P7 surface dependency format as input, so the first attempt at building a test suite is to considerexamples in the guide which describes the format.
By nature, an annotation guide tries to cover a largerange of phenomena with a small set of examples.The latest version4 of this guide (Candito et al (2010)) contains 186 linguistic examples.
In our cur-rent implementation of the semantic constructions, we leave out clefts, coordinations and comparatives.We also leave out a small set of exotic sentences for which we are not able to give a sensible syntacticstructure.
Finally, our experiment runs on 116 French sentences.
Syntactic structures following P7 spec-ifications are obtained with some graph rewriting on the output of our parser.
Each syntactic structurewas manually checked and corrected when needed.
Then, graph rewriting with the modules described inthe previous section is performed.For all of these sentences, we produce at least one normal form.
Even if DMRS is underspecified, oursystem can output several semantic representations for one syntactic structure (for instance, for appositiveand restrictive relative clauses).
We sometimes overgenerate because we do not use lexical informationlike the difference between scopal and non-scopal adverbs.The result for three sentences is given below and the full set is available on a web page 5.4version 1.1, january 20105http://leopar.loria.fr/doku.php?id=iwcs201172[012] ?Le franc?ais se parle de moins en moins dans les confe?rences.?
[The French language is less andless spoken in conferences.
]lecat=detfran?aiscat=nsecat=proparlecat=vmood=indtense=presvoice=unkde moins en moinscat=advdanscat=prepprep=loclescat=detconf?rencescat=nDET AFF_MOYEN MOD DETSUJ MOD_LOC OBJ/la/ct=dea=/s?tritnR/ct=drS THPT/pt?la/ct=do?vvednre=arRadp?aRovncadtc=noamTEQ NAG//mTE1 NAG/eaf?vnrRfarf?vnrR/ct=dteomTE1 AG/etrR/ct=dp?app?apdlvcAG mTE1/cvrs2?arcaR/ct=drNAG mTEQ/laR/ct=dea=S THPT[057] ?J?encourage Marie a` venir.?
[I invite Mary to come.
]jecat=proencouragecat=vmood=indtense=presvoice=unkMariecat=np?cat=prepprep=?venircat=vmood=infvoice=unkSUJ OBJ OBJA-OBJSUJ/je/cat=pro/encourage/cat=vmood=indtense=presvoice=activeARG1 NEQ/Marie/cat=npARG2 NEQ/venir/cat=vmood=infprep=?voice=activeARG3 EQARG1 NEQ[106] ?La se?rie dont Pierre conna?
?t la fin?
[The story Peter knows the end of]lacat=dets?riecat=ndontcat=proPierrecat=npconna?tcat=vmood=indtense=presvoice=unklacat=detfincat=nDET ANT SUJ DETOBJMOD_RELDE-OBJ/la/cat=det/s?rie/cat=nRSTR H/Pierre/cat=np/conna?t/cat=vmood=indtense=presvoice=activeEQNEQ ARG1/fin/cat=nNEQ ARG2/la/cat=detRSTR HARG1 NEQ73ConclusionIn this paper, we have shown the relevance of modular graph rewriting to compute semantic representa-tions from graph-shaped syntactic structures.
The positive results of our experiments on a test suite ofvaried sentences make us confident that the method can apply to large corpora.The particular modular graph rewriting system presented in the paper was merely here to illustratethe method, which can be used for other input and output formats.
There is another aspect to the flexi-bility of the method: we may start from the same system of rules and enrich it with new rules to get afiner semantic analysis ?
if DMRS is considered as providing a minimal analysis ?
or integrate lexi-cal information.
The method allows the semantic ambiguity to remain unsolved within underspecifiedrepresentations or to be solved with a rule system aiming at computing models of underspecified rep-resentations.
Moreover, we believe that its flexibility makes graph rewriting a convenient framework todeal with idiomatic expressions.ReferencesAbeille?, A. and N. Barrier (2004).
Enriching a french treebank.
In Proceedings of LREC.Be?daride, P. and C. Gardent (2009).
Semantic Normalisation : a Framework and an Experiment.
InProceedings of IWCS, Tilburg Netherlands.Bohnet, B. and L. Wanner (2001).
On using a parallel graph rewriting formalism in generation.
InProceedings of EWNLG ?01, pp.
1?11.
Association for Computational Linguistics.Candito, M., B.
Crabbe?, and P. Denis (2010).
Statistical french dependency parsing: Treebank conversionand first results.
Proceedings of LREC2010.Candito, M., B.
Crabbe?, and M. Falco (2010).
De?pendances syntaxiques de surface pour le fran?cais.Carpenter, B.
(1992).
The logic of typed feature structures.
Cambridge: Cambridge University Press.Chaumartin, F.-R. and S. Kahane (2010).
Une approche paresseuse de l?analyse se?mantique ou commentconstruire une interface syntaxe-se?mantique a` partir d?exemples.
In TALN 2010, Montreal, Canada.Copestake, A.
(2007).
Semantic composition with (robust) minimal recursion semantics.
In Proceedingsof the Workshop on Deep Linguistic Processing, pp.
73?80.
Association for Computational Linguistics.Copestake, A.
(2009).
Invited Talk: Slacker semantics: Why superficiality, dependency and avoidanceof commitment can be the right way to go.
In Proceedings of EACL 2009, Athens, Greece, pp.
1?9.Copestake, A., D. Flickinger, C. Pollard, and I.
Sag (2005).
Minimal Recursion Semantics - an Introduc-tion.
Research on Language and Computation 3, 281?332.Crouch, D. (2005).
Packed Rewriting for Mapping Semantics to KR.
In Proceedings of IWCS.Dalrymple, M. (2001).
Lexical Functional Grammar.
New York: Academic Press.Heim, I. and A. Kratzer (1998).
Semantics in generative grammar.
Wiley-Blackwell.Hyvo?nen, E. (1984).
Semantic Parsing as Graph Language Transformation - a Multidimensional Ap-proach to Parsing Highly Inflectional Languages.
In COLING, pp.
517?520.Jijkoun, V. and M. de Rijke (2007).
Learning to transform linguistic graphs.
In Second Workshop onTextGraphs: Graph-Based Algorithms for Natural Language Processing, Rochester, NY, USA.Mel?c?uk, I.
(1988).
Dependency Syntax: Theory and Practice.
Albany: State Univ.
of New York Press.Rozenberg, G.
(Ed.)
(1997).
Handbook of Graph Grammars and Computing by Graph Transformations,Volume 1: Foundations.
World Scientific.74
