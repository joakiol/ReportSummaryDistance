Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 490?500,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsDocument Summarization via Guided Sentence CompressionChen Li1, Fei Liu2, Fuliang Weng2, Yang Liu11 Computer Science Department, The University of Texas at DallasRichardson, Texas 75080, USA2 Research and Technology Center, Robert Bosch LLCPalo Alto, California 94304, USA{chenli,yangl@hlt.utdallas.edu}{fei.liu, fuliang.weng@us.bosch.com}AbstractJoint compression and summarization hasbeen used recently to generate high qualitysummaries.
However, such word-based jointoptimization is computationally expensive.
Inthis paper we adopt the ?sentence compression+ sentence selection?
pipeline approach forcompressive summarization, but propose toperform summary guided compression, ratherthan generic sentence-based compression.
Tocreate an annotated corpus, the human anno-tators were asked to compress sentences whileexplicitly given the important summary wordsin the sentences.
Using this corpus, we traina supervised sentence compression model us-ing a set of word-, syntax-, and document-level features.
During summarization, we usemultiple compressed sentences in the inte-ger linear programming framework to selectsalient summary sentences.
Our results on theTAC 2008 and 2011 summarization data setsshow that by incorporating the guided sen-tence compression model, our summarizationsystem can yield significant performance gainas compared to the state-of-the-art.1 IntroductionAutomatic summarization can be broadly dividedinto two categories: extractive and abstractive sum-marization.
Extractive summarization focuses onselecting the salient sentences from the documentcollection and concatenating them to form a sum-mary; while abstractive summarization is generallyconsidered more difficult, involving sophisticatedtechniques for meaning representation, content plan-ning, surface realization, etc., and the ?true abstrac-tive summarization remains a researcher?s dream?
(Radev et al 2002).There has been a surge of interest in recentyears on generating compressed document sum-maries as a viable step towards abstractive sum-marization.
These compressive summaries oftencontain more information than sentence-based ex-tractive summaries since they can remove insignif-icant sentence constituents and make space for moresalient information that is otherwise dropped due tothe summary length constraint.
Two general strate-gies have been used for compressive summarization.One is a pipeline approach, where sentence-basedextractive summarization is followed or proceededby sentence compression (Knight and Marcu, 2000;Lin, 2003; Zajic et al 2007; Wang et al 2013).Another line of work uses joint compression andsummarization.
They have been shown to achievepromising performance (Daume?, 2006; Martins andSmith, 2009; Berg-Kirkpatrick et al 2011; Chaliand Hasan, 2012; Almeida and Martins, 2013; Qianand Liu, 2013).
One popular approach for such jointcompression and summarization is via integer lin-ear programming (ILP).
However, since words arethe units in the optimization framework, solving thisILP problem can be expensive.In this study, we use the pipeline compressionand summarization method because of its compu-tational efficiency.
Prior work using such pipelinemethods simply uses generic sentence-based com-pression for each sentence in the documents, no mat-ter whether compression is done before or after sum-mary sentence extraction.
We propose to use sum-490mary guided compression combined with ILP-basedsentence selection for summarization in this paper.We create a compression corpus for this purpose.Using human summaries for a set of documents, weidentify salient words in the sentences.
During anno-tation, the human annotators are given these salientwords and asked to generate compressed sentences.We expect such ?guided?
sentence compression isbeneficial for the pipeline compression and summa-rization task.
In addition, previous research on jointmodeling for compression and summarization sug-gested that the labeled extraction and compressiondata sets would be helpful for learning a better jointmodel (Daume?, 2006; Martins and Smith, 2009).We hope that our work on this guided compressionwill also be of benefit to the future joint modelingstudies.Using our created compression data, we traina supervised compression model using a varietyof word-, sentence-, and document-level features.During summarization, we generate multiple com-pression candidates for each sentence, and use theILP framework to select compressed summary sen-tences.
In addition, we also propose to apply a pre-selection step to select some important sentences,which can both speed up the summarization systemand improve performance.
We evaluate our pro-posed summarization approach on the TAC 2008and 2011 data sets using the standard ROUGE met-ric (Lin, 2004).
Our results show that by incorporat-ing a guided sentence compression model, our sum-marization system can yield significant performancegain as compared to the state-of-the-art reported re-sults.2 Related WorkSummarization research has seen great developmentover the last fifty years (Nenkova and McKeown,2011).
Compared to the abstractive counterpart, ex-tractive summarization has received considerable at-tention due to its clear problem formulation ?
to ex-tract a set of salient and non-redundant sentencesfrom the given document set.
Both unsupervised andsupervised approaches have been explored for sen-tence selection.
The supervised approaches includethe Bayesian classifier (Kupiec et al 1995), max-imum entropy (Osborne, 2002), skip-chain condi-tional random fields (CRF) (Galley, 2006), discrim-inative reranking (Aker et al 2010), among others.The extractive summary sentence selection prob-lem can also be formulated in an optimizationframework.
Previous approaches include the inte-ger linear programming (ILP) and submodular func-tions, which are used to solve the optimization prob-lem.
In particular, Gillick et al(2009) proposeda concept-based ILP approach for summarization.Li et al(2013) improved it by using supervisedstragety to estimate concept weight in ILP frame-work.
In (Lin and Bilmes, 2010), the authors modelthe sentence selection problem as maximizing a sub-modular function under a budget constraint.
Agreedy algorithm is proposed to efficiently approxi-mate the solution to this NP-hard problem.Compressive summarization receives increasingattention in recent years, since it offers a viablestep towards abstractive summarization.
The com-pressed summaries can be generated through a jointmodel of the sentence selection and compressionprocesses, or through a pipeline approach that in-tegrates a generic sentence compression model witha summary sentence pre-selection or post-selectionstep.Many studies explore the joint sentence compres-sion and selection setting.
Martins and Smith (2009)jointly perform sentence extraction and compressionby solving an ILP problem; Berg-Kirkpatrick et al(2011) propose an approach to score the candidatesummaries according to a combined linear modelof extractive sentence selection and compression.They train the model using a margin-based objec-tive whose loss captures the final summary qual-ity.
Woodsend and Lapata (2012) present a methodwhere the summary?s informativeness, succinctness,and grammaticality are learned separately from databut optimized jointly using an ILP setup; Yoshikawaet al(2012) incorporate semantic role informationin the ILP model; Chali and Hasan (2012) investi-gate three strategies in compressive summarization:compression before extraction, after extraction, orjoint compression and extraction in one global op-timization framework.
These joint models offer apromise for high quality summaries, but they oftenhave high computational cost.
Qian and Liu (2013)propose a graph-cut based method that improves thespeed of joint compression and summarization.491The pipeline approach, where sentence-based ex-tractive summarization is followed or proceeded bysentence compression, is also popular.
Knight andMarcu (2000) utilize the noisy channel and deci-sion tree method to perform sentence compression;Lin (2003) shows that pure syntactic-based com-pression may not improve the system performance;Zajic et al(2007) compare two sentence compres-sion approaches for multi-document summarization,including a ?parse-and-trim?
and a noisy-channel ap-proach; Galanis and Androutsopoulos (2010) usethe maximum entropy model to generate the candi-date compressions by removing the branches fromthe source sentences; Liu and Liu (2013) couplethe sentence compression and extraction approachesfor summarizing the spoken documents; Wang et al(2013) design a series of learning-based compres-sion models built on parse trees, and integrate themin query-focused multi-document summarization.Prior studies often rely heavily on the generic sen-tence compression approaches (McDonald, 2006;Nomoto, 2007; Clarke and Lapata, 2008; Thadaniand McKeown, 2013) for compressing the sentencesin the documents, yet a generic compression systemmay not be the best fit for the summarization pur-pose.In this paper, we adopt the pipeline-based com-pressive summarization framework, but propose anovel guided compression method that is catered tothe summarization task.
We expect this approachto take advantage of the efficient pipeline process-ing while producing satisfying results as the jointmodels.
We train a supervised guided compressionmodel to produce n-best compressions for each sen-tence, and use an ILP formulation to select the bestset of summary sentences.
In addition, we pro-pose to apply a sentence pre-selection step to fur-ther accelerate the processing and enhance the per-formance.3 Guided Compression CorpusThe goal of guided sentence compression is to createcompressed sentences that are grammatically cor-rect and contain the important information that wewould like to preserve in the final summary.
Fol-lowing the compression literature (Clarke and Lap-ata, 2008), the compression task is defined as a wordOriginal Sentence:The gas leak was contained Monday afternoon , nearly 18hours after it was reported , Statoil spokesman OeivindReinertsen said .Compression A:The gas leak was containedCompression B:The gas leak was contained Monday afternoonCompression C:The gas leak was contained nearly 18 hours after it wasreportedTable 1: Example sentence and three compressions.deletion problem, that is, the human annotators (andalso automatic compression systems) are allowed toonly remove words from the original sentence toform a compression.
The key difference betweenour proposed guided compression with generic sen-tence compression is that, we provide guidance tothe human compression process by specifying a setof ?important words?
that we wish to keep for eachsentence.
We expect this kind of summary orientedcompression would benefit the ultimate summariza-tion task.
Take the sentence shown in Table 1 as anexample.
For generic sentence compression, theremay be multiple ?good?
human compressions for thissentence, such as those listed in the table.
Withoutguidance, a human annotator (or automatic system)is likely to use option A or B; however, if ?18 hours?appears in the summary, then we want to provide thisguidance in the compression process, hence optionC may be the best compression choice.
This guidedcompression therefore avoids removing the salientwords that are important to the final summary.To generate the guided compression corpus, weuse the TAC 2010 data set1 that was used forthe multi-document summarization task.
There are46 topics.
Each has 10 news documents, andalso four human-created abstractive reference sum-maries.
Since annotating all the sentences in thisdata set is time consuming and some sentences arenot very important for the summarization task, wechoose a set of sentences that are highly related tothe human abstracts for annotation.
We compareeach sentence with the four human abstracts usingthe ROUGE-2 metric (Lin, 2004), and the sentences1http://www.nist.gov/tac/2010/492Original Sentence:He said Vietnam veterans are presumed to have been ex-posed to Agent Orange and veterans with any of the 10 dis-eases is presumed to have contracted it from the exposure ,without individual proof .Guided Compression:Vietnam veterans are presumed to have been exposed toAgent Orange.Original Sentence:The province has limited the number of trees to be choppeddown in the forest area in northwest Yunnan and has stoppedbuilding sugar factories in the Xishuangbanna region topreserve the only tropical rain forest in the country locatedthere .Guided Compression:province has stopped building sugar factories in theXishuangbanna region to preserve tropical rain forest.Table 2: Example original sentences and their guidedcompressions.
The ?guiding words?
are italicized andmarked in red.with the highest scores are selected.In annotation, human annotators are providedwith important ?guiding words?
(highlighted in theannotation interface) that we want to preserve in thesentences.
We calculate the word overlap between asentence and each of those sentences in the humanabstracts, and use a set of heuristic rules to deter-mine the ?guiding words?
in a sentence: the longestconsecutive word overlaps (greater than 2 words) ineach sentence pair are first selected; the rest overlapsthat contain 2 or more words (excluding the stop-words) are also selected.
We suggest the human an-notators to use their best judgment to keep the guid-ing words as many as possible while compressingthe sentence.We use the Amazon Mechanical Turk (AMT) fordata annotation2.
In total, we select 1,150 sentencesfrom the TAC news documents.
They are groupedinto about 230 human intelligence tasks (HITs) with5 sentences in each HIT.
A sentence was compressedby 3 human annotatorsand we select the shortestcandidate as the goldstandard compression for eachsentence.
In Table 2, we show two example sen-tences, their guiding words (bold), and the humancompressions.
The first example shows that givingup some guiding words is acceptable, since more2http://www.mturk.comunnecessary words will be included in order to ac-commodate all the guiding words; the second ex-ample shows that the guided compression can leadto more aggressive word deletions since the con-stituents that are not important to the summary willbe deleted even though they contain salient informa-tion by themselves.For our compression corpus, which contains1,150 sentences and their guided compressions, theaverage compression rate, as measured by the per-centage of dropped words, is about 50%.
This com-pression ratio is higher compared to other genericsentence compression corpora, in which the worddeletion rate ranges from 24% to 34% dependingon different text genres and annotation guidelines(Clarke and Lapata, 2008; Liu and Liu, 2009).
Thissuggests that the annotators can remove words moreaggressively when they are provided with a limitedset of guiding words.4 Summarization SystemOur summarization system consists of three keycomponents: we train a supervised guided compres-sion model using our created compression data, witha variety of features.then we use this model to gener-ate n-best compressions for each sentence; we feedthe multiple compressed sentences to the ILP frame-work to select the best summary sentences.
In ad-dition, we propose a sentence pre-selection step thatcan both speed up the summarization system and im-prove the performance.4.1 Guided Sentence CompressionSentence compression has been explored in previousstudies using both supervised and unsupervised ap-proaches, including the noisy-channel and decisiontree model (Knight and Marcu, 2000; Turner andCharniak, 2005), discriminative learning (McDon-ald, 2006), integer linear programming (Clarke andLapata, 2008; Thadani and McKeown, 2013), con-ditional random fields (CRF) (Nomoto, 2007; Liuand Liu, 2013), etc.
In this paper, we employ theCRF-based compression approach due to its provedperformance and its flexibility to integrate differ-ent levels of discriminative features.
Under thisframework, sentence compression is formulated asa sequence labeling problem, where each word is493labeled as either ?0?
(retained) or ?1?
(removed).We develop different levels of features to captureword-specific characteristics, sentence related infor-mation, and document level importance.
Most of thefeatures are extracted based only on the sentence tobe compressed.
However, we introduce a few doc-ument level features.
These are designed to cap-ture the word and sentence significance within thegiven document collection and are thus expected tobe more summary related.Word and sentence features:?
Word n-grams: identity of the current wordand two words before and after, as well as allthe bigrams and trigrams that can be formed bythe adjacent words and the current word.?
POS n-grams: same as the word n-grams, butuse the part-of-speech tags instead.?
Named entity tags: binary features represent-ing whether the current word is a person, loca-tion, or temporal expression.
We use the Stan-ford CoreNLP tools3 for named entity tagging.?
Stopwords: whether the current word is a stop-word or not.?
Conjunction features: (1) conjunction of thecurrent word with its relative position in thesentence; (2) conjunction of the NER tag withits relative position.?
Syntactic features: We obtain the syntacticparsing tree using the Berkeley Parser (Petrovand Klein, 2007), then obtain the following fea-tures: (1) the last sentence constituent tag inthe path from the root to the word; (2) depth:length of the path starting from the root nodeto the word; (3) normalized depth: depth di-vided by the longest path in the parsing tree;(4) whether the word is under an SBAR node;(5) depth and normalized depth of the SBARnode if the word is under an SBAR node;?
Dependency features: We employ thePenn2Malt toolkit 4 to convert the parse re-sult from the Berkeley parser to the depen-dency parsing tree, and use these dependency3http://nlp.stanford.edu/software/corenlp.shtml4http://stp.lingfil.uu.se/?nivre/research/Penn2Malt.htmlfeatures: (1) dependency relations such as?AMOD?
(adjective modifier), ?NMOD?
(nounmodifier), etc.
(2) whether the word has a child,left child, or right child in the dependency tree.Document-level features:?
Sentence salience score: We use a simple re-gression model to estimate a salience score foreach sentence (more details in Section 4.3),which represents the importance of the sen-tence in the document.
This score is discretizedinto four binary features according to the aver-age sentence salience.?
Unigram document frequency: this is thecurrent word?s document frequency based onthe 10 documents associated with each topic.?
Bigram document frequency: document fre-quency for the two bigrams, the current wordand its previous or next word.Some of the above features were employed in re-lated sentence compression studies (Nomoto, 2007;Liu and Liu, 2013).
In addition to these features, weexplored other related features, including the abso-lute position of the current word, whether the wordappears in the corresponding topic title and descrip-tions, conjunction of the syntactic tag with the treedepth, etc.
; however, these features did not lead toimproved performance.
We train the CRF modelwith the Pocket CRF toolkit5 using the guided com-pression corpus collected in Section 3.
During sum-marization, we apply the model to a given sentenceto generate its n-best guided compressions and usethem in the following summarization step.4.2 Summary Sentence SelectionThe sentence selection process is similar to the stan-dard sentence-based extractive summarization, ex-cept that the input to the selection module is a listof compressed sentences in our work.
Many extrac-tive summarization approaches can be applied forthis purpose.
In this work, we choose the integerlinear programming (ILP) method, specifically, theconcept-based ILP framework introduced in (Gillick5http://sourceforge.net/projects/pocket-crf-1/494et al 2009), mainly because it yields best perfor-mance in the TAC evaluation tasks.
This ILP ap-proach aims to extract sentences that can cover asmany important concepts as possible, while ensuringthe summary length is within a given constraint.
Wefollow the study in (Gillick et al 2009) to use wordbi-grams as concepts, and assign a weight to eachbi-gram using its document frequency in the givendocument collection for a test topic.
Two differencesare between our ILP setup and that in (Gillick et al2009).
First, since we use multiple compressionsfor one sentence, we need to introduce an additionalconstraint: for each sentence, only one of the n-bestcompressions may be included in the summary.
Sec-ond, we optimize a joint score of the concept cover-age and the sentence salience.
The formal ILP for-mulation is shown below:max?iwici +?jvj?ksjk (1)s.t.
?ksjk ?
1?j (2)sjkOcci jk ?
ci (3)?jksjkOcci jk ?
ci (4)?jkljksjk ?
L (5)ci ?
{0, 1} ?i (6)sjk ?
{0, 1} ?j, k (7)where ci and sjk are binary variables indicating thepresence of a concept and a sentence respectively;sjk denotes the kth candidate compression of thejth sentence; wi represents the weight of the con-cept; vj is the sentence salience score of the jthsentence, predicted using a regression model (Sec-tion 4.3), and all of its compressed candidates sharethis value.
(1) is the new objective function we usethat combines the coverage of the concepts and thesentence salience scores.
(2) represents our addi-tional constraint, which requires that for each sen-tence j, only one candidate compression will be cho-sen. Occi jk represents the occurrence of concept iin the sentence sjk.
Inequalities (3) and (4) associatethe sentences and the concepts.
Constraint (5) con-trols the summary length, as measured by the totalnumber of words in the summary.
We use an opensource ILP solver6.4.3 Sentence Pre-selectionThe above ILP method can offer an exact solutionto the defined objective function.
However, ILP iscomputationally expensive when the formulation in-volves large quantities of variables, i.e, when wehave many sentences and a large number of candi-date compressions for each sentence.
We thereforepropose to apply a sentence pre-selection step be-fore the compression.
This kind of selection stephas been used in previous ILP-based summarizationsystems (Berg-Kirkpatrick et al 2011; Gillick et al2009).
In this work, we propose to use a simple su-pervised support vector regression (SVR) model (Nget al 2012) to predict a salience score for each sen-tence and select the top ranked sentences for furtherprocessing (compression and summarization).To train the SVR model, the target value for eachsentence is the ROUGE-2 score between the sen-tence and the four human abstracts (this same valueis used for sentence selection in corpus annotation(Section 3)).
We employ three commonly used fea-tures: (1) sentence position in the document; (2) sen-tence length as indicated by a binary feature: it takesthe value of 0 if the number of words in the sentenceis greater than 50 or less than 10, otherwise the fea-ture value is 1; (3) interpolated n-gram documentfrequency as introduced in (Ng et al 2012), whichis a weighted linear combination of the documentfrequency of the unigrams and bigrams contained inthe sentence:f(s) =?
?wu?SDF (wu) + (1?
?
)?wb?SDF (wb)|S|where wu and wb represent the unigrams and bi-grams contained in the sentence S; ?
is a balancingfactor; |S| denotes the number of words in the sen-tence.The SVR model was trained using the SVMlighttoolkit7.
Using this model, we can predict a saliencescore (Vj in Eq 1) for each sentence and only selectthe top n sentences and supply them to the compres-sion and summarization steps.
In practice, using afixed n may not be a good choice since the number6http://www.gnu.org/software/glpk/7http://svmlight.joachims.org/495of sentences varies greatly for different topics.
Wetherefore set n heuristically based on the total num-ber of sentencesm for each topic: n=15 ifm > 150;n=10 if m < 100; n=0.1 ?m otherwise.5 Experimental Results5.1 Experimental SetupFor our experiments, we use the standard TAC datasets8, which have been used in the NIST competi-tions and in other summarization studies.
In par-ticular, we used the TAC 2010 data set for creatingthe guided compression corpus and training the SVRpre-selection model, the TAC 2009 data set as devel-opment set for parameter tuning, and the TAC 2008and 2011 data sets as the test set for reporting thefinal summarization results.We compare our pipeline summarization sys-tem against three recent studies, which have re-ported some of the highest published results on thistask.
Berg-Kirkpatrick et al(2011) introduce ajoint model for sentence extraction and compres-sion.
The model is trained using a margin-based ob-jective whose loss captures the end summary qual-ity; Woodsend and Lapata (2012) learn individ-ual summary aspects from data, e.g., informative-ness, succinctness, grammaticality, stylistic writ-ing conventions, and jointly optimize the outcomein an integer linear programming framework.
Nget al(2012) exploit category-specific informationfor multi-document summarization.
In addition tothe three previous studies, we also report the bestachieved results in the TAC competitions.5.2 Summarization ResultsIn Table 3 and Table 4, we present the results of oursystem and the aforementioned summarization stud-ies.
We use the ROUGE evaluation metrics (Lin,2004), with R-2 measuring the bigram overlap be-tween the system and reference summaries and R-SU4 measuring the skip-bigram with the maximumgap length of 4.
?Our System?
uses the pipelinesetting including the three components described inSection 4.
We use the SVR-based approach to pre-select a set of sentences from the document set; thesesentences are further fed to the guided compressionmodule that produces n-best compressions for each8http://www.nist.gov/tac/data/index.htmlSystem R-2 R-SU4 CompRTAC?08 Best System 11.03 13.96 n/a(Berg-Kirkpatrick et al 2011) 11.70 14.38 n/a(Woodsend et al 2012) 11.37 14.47 n/aOur System 12.35?
15.27?
43.06%Our System w/o Pre-selection 12.02 14.98 55.69%Our System w/ Generic Comp 10.88 13.79 30.90%Table 3: Results on the TAC 2008 data set.
?Our Sys-tem?
uses the SVR-based sentence pre-selection + guidedcompression + ILP-based summary sentence selection.
?Our System w/ Generic Comp?
uses the pre-selection +generic compression + ILP summary sentence selectionsetting.
?CompR?
represents the compression ratio, i.e.,percentage of dropped words.
?
represents our systemoutperforms the best previous result at the 95% signifi-cance level.System R-2 R-SU4 CompRTAC?11 Best System 13.44 16.51 n/a(Ng et al 2012) 13.93 16.83 n/aOur System 14.40 16.89 39.90%Our System w/o Pre-selection 13.74 16.5 53.81%Our System w/ Generic Comp 13.08 16.23 30.10%Table 4: Results on the TAC 2011 data set.
The systemsuse the same settings as for the TAC 2008 data set.sentence; the ILP-based framework is then used toselect the summary sentences from these compres-sions.We can see from the table that in general, our sys-tem achieves considerably better results compared tothe state-of-the-art on both the TAC 2008 and 2011data sets.
On the TAC 2008 data set, our system out-performs the best reported result at the 95% signifi-cance level; on the TAC 2011 data set, our systemalso yields considerable performance gain thoughnot exceed the 95% significance level.
In the fol-lowing, we show more detailed analysis to study theeffect of different system parameters.With or without sentence pre-selection.
Firstwe evaluate the impact of sentence pre-selectionstep.
In Table 3 and Table 4, we include theresults when this step is not used (?Our Systemw/o Pre-selection?).
That is, all of the sentencesin the documents (excluding those containing lessthan 5 words) are compressed and used in the ILP-496based summary sentence selection module.
We cansee that although sentence pre-selection removessome sentences from consideration in the later sum-marization step, it actually significantly improvessystem performance.
In the TAC 2008 data set,each topic contains averagely 210 sentences; whilethe pre-selection step chooses 13 sentences amongthem.
These numbers are 185 and 12 for the TAC2011 data set.
Table 5 shows the average runningtime of each topic in TAC 2011 data for the two sys-tems, with or without the pre-selection step.
Herewe fix the number of compressions to 100 in bothcases for fair comparison.
We can see the selec-tion step greatly accelerates the system processing.When applying the pre-selection step, fewer sen-tences are used in the compression and summariza-tion, this means we are able to use more compres-sion candidates for each sentence (considering thecomplexity of ILP module).
Using the TAC 2009as development set, we tuned the number of can-didate compressions generated for each sentence.Without pre-selection, we used the 100-best candi-dates generated from the compression model; withpre-selection, we are able to increase the numberto 200-best candidate compressions and still main-tain reasonable computational cost.
These are thenumbers used in the results in Table 3 and 4.
Us-ing more compressions helps improve summariza-tion performance.
We also notice that the compres-sion ratios are quite different when using sentencepre-selection vs. not.
This suggests that in the im-portant sentences (those are kept after pre-selection),there is more summary related information and thusthe compression model keeps more words in them(lower compression ratio).SystemCompressed Number of RunningSentences Compressions Time (sec)w/o Pre-selection 185 100 3.9w/ Pre-selection 12 100 0.85Table 5: Average running time of our system, w/ or w/othe sentence pre-selection step.
Experiments conductedon the TAC 2011 data set.
Running time refers only tothe execution time of the ILP module for each topic.Number of compression candidates.
This pa-rameter (denoted as n) also impacts system perfor-mance.
Figure 1 shows the R-2 scores of the twosystems (with and without the sentence pre-selectionstep) when using different number of compressionsfor each sentence.
In general, we find that the R-2scores do not change much when n is large enough.For example, the ?with pre-selection?
system canachieve relatively stable R-2 scores on the TAC 2008data set (ranging from 12.2 to 12.4) when m isgreater than 140; similarly, the R-2 scores on theTAC 2011 data is over 14.2 when m is greater than100.
Without the pre-selection step, the scores areless stable in regard to the changing of the m value,since the large amount of sentences plus a high vol-ume of the compression candidates may incur hugecomputational cost to the ILP solver.
This is also thereason that in Figure 1, for the system without pre-selection, we only vary n from 1 to 100.
In general,we also notice that given more compression candi-dates, the R-2 score is still improving, as indicatedby Figure 1.
The improved performance of ?withpre-selection?
over ?without pre-selection?
is partlybecause fewer sentences are used and thus we areable to increase the number of compression candi-dates for these sentences in the ILP sentence extrac-tion module.Quality of sentence compression training data.In order to illustrate the contribution of oursummary-guided sentence compression component,we train a generic sentence compression modeland use this in our compression and summariza-tion pipeline.
The generic compression model wastrained using the Edinburgh sentence compressioncorpus (Clarke and Lapata, 2008), which contains1370 sentences collected from news articles.
Thisdata set has been widely used in other summariza-tion studies (Martins and Smith, 2009).
Each sen-tence has 3 compressions and we choose the short-est compression as the reference.
The average com-pression rate of this corpus is about 28%, lower thanthat in our summary guided compression data.
Notethat in generic sentence compression, we only usethose word and sentence features described in Sec-tion 4.1, not the document-level features since theyare not available for the Edinburgh data set.
Resultsof our system using the generic compression model(with sentence pre-selection) are shown in the lastrow of Table 3 and Table 4.
We can see that the sys-tem with this generic compression model performs4971111.51212.51313.51414.5150  20  40  60  80  100ROUGE-2# Compression CandidatesTAC 2011TAC 20081111.51212.51313.51414.5150  50  100  150  200  250ROUGE-2# Compression CandidatesTAC 2011TAC 20081111.51212.51313.51414.5150  20  40  60  80  100ROUGE-2# Compression CandidatesTAC 2011TAC 20081111.51212.51313.51414.5150  50  100  150  200  250ROUGE-2# Compression CandidatesTAC 2011TAC 2008Figure 1: R-2 scores of the two systems (without andwith the sentence pre-selection step) when using differ-ent number of compressions for each sentence.worse than ours, and is also inferior to the TAC bestperforming system on both data sets, which signi-fies the importance of our proposed summary guidedsentence compression approach.
We can also seethere is a difference in the compression ratio in thesystem generated compressions when using differ-ent compression corpora to train the compressionmodels.
The resulting compression ratio patterns areconsistent with those in the training data, that is, us-ing our guided compression corpus our system com-pressed sentences more aggressively.Learning curve of guided compression.
Sincewe use a supervised compression model, we furtherconsider the relationship between the summarizationperformance and the number of sentence pairs usedfor training the guided compression model.
In to-tal, there are 1150 training sentence pairs in our cor-pus.
We incrementally add 100 sentence pairs eachtime and plot the learning curve in Figure 2.
Inthe compression step, we generate only the 1-bestcompression candidate in order to remove the im-pact caused by the downstream summary sentenceselection module.
As seen from Figure 2, increasingthe compression training data generally improvessummarization performance, although there are alsofluctuations.
When adding more training sentencepairs, the system performance is likely to further in-crease.10.51111.51212.5200  400  600  800 1000 1200ROUGE-2# Sentence Pairs in the Training SetTAC 2011TAC 2008Figure 2: ROUGE-2 scores when using different numberof sentences to train the guided compression model.6 Conclusion and Future WorkIn this paper, we propose a pipeline summariza-tion approach that combines a novel guided com-pression model with ILP-based summary sentenceselection.
We create a guided compression cor-pus, where the human annotators were explicitly in-formed about the important summary words duringthe compression annotation.
We then train a super-vised compression model to capture the guided com-pression process using a set of word-, sentence-, anddocument-level features.
We conduct experimentson the TAC 2008 and 2011 summarization data setsand show that by incorporating the guided sentencecompression model, our summarization system canyield significant performance gain as compared tothe state-of-the-art.
In future, we would like tofurther explore the reinforcement relationship be-tween keywords and summaries (Wan et al 2007),improve the readability of the sentences generatedfrom the guided compression system, and report re-sults using multiple evaluation metrics (Nenkova etal., 2007; Louis and Nenkova, 2012) as well as per-forming human evaluations.498AcknowledgmentsPart of this work was done during the first au-thor?s internship in Bosch Research and Technol-ogy Center.
The work is also partially supportedby NSF award IIS-0845484 and DARPA ContractNo.
FA8750-13-2-0041.
Any opinions, findings,and conclusions or recommendations expressed arethose of the author and do not necessarily reflect theviews of the funding agencies.ReferencesAhmet Aker, Trevor Cohn, and Robert Gaizauskas.
2010.Multi-document summarization using a* search anddiscriminative training.
In Proceedings of EMNLP.Miguel B. Almeida and Andre F. T. Martins.
2013.
Fastand robust compressive summarization with dual de-composition and multi-task learning.
In Proceedingsof ACL.Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.2011.
Jointly learning to extract and compress.
InProceedings of ACL.Yllias Chali and Sadid A. Hasan.
2012.
On the effective-ness of using sentence compression models for query-focused multi-document summarization.
In Proceed-ings of COLING.James Clarke and Mirella Lapata.
2008.
Global infer-ence for sentence compression an integer linear pro-gramming approach.
Journal of Artificial IntelligenceResearch.Hal Daume?.
2006.
Practical structured learning tech-niques for natural language processing.
Ph.D. thesis,University of Southern California.Dimitrios Galanis and Ion Androutsopoulos.
2010.
Anextractive supervised two-stage method for sentencecompression.
In Human Language Technologies: The2010 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics.Michel Galley.
2006.
A skip-chain conditional randomfield for ranking meeting utterances by importance.
InProceedings of EMNLP.Dan Gillick, Benoit Favre, Dilek Hakkani-Tur, BerndtBohnet, Yang Liu, and Shasha Xie.
2009.
The icsi/utdsummarization system at tac 2009.
In Proceedings ofTAC.Kevin Knight and Daniel Marcu.
2000.
Statistics-basedsummarization - step one: Sentence compression.Julian Kupiec, Jan Pedersen, and Francine Chen.
1995.A trainable document summarizer.
In Proceedings ofSIGIR.Chen Li, Xian Qian, and Yang Liu.
2013.
Using super-vised bigram-based ilp for extractive summarization.In Proceedings of ACL.Hui Lin and Jeff Bilmes.
2010.
Multi-document sum-marization via budgeted maximization of submodularfunctions.
In Proceedings of NAACL.Chin-Yew Lin.
2003.
Improving summarization perfor-mance by sentence compression - A pilot study.
InProceeding of the Sixth International Workshop on In-formation Retrieval with Asian Language.Chin-Yew Lin.
2004.
Rouge: a package for automaticevaluation of summaries.
In Proceedings of ACL.Fei Liu and Yang Liu.
2009.
From extractive to abstrac-tive meeting summaries: Can it be done by sentencecompression?
In Proceedings of ACL-IJCNLP.Fei Liu and Yang Liu.
2013.
Towards abstractive speechsummarization: Exploring unsupervised and super-vised approaches for spoken utterance compression.IEEE Transactions on Audio, Speech, and LanguageProcessing.Annie Louis and Ani Nenkova.
2012.
Automati-cally assessing machine summary content with a gold-standard.
Computational Linguistics.Andre F. T. Martins and Noah A. Smith.
2009.
Summa-rization with a joint model for sentence extraction andcompression.
In Proceedings of the ACL Workshopon Integer Linear Programming for Natural LanguageProcessing.Ryan McDonald.
2006.
Discriminative sentence com-pression with soft syntactic evidence.
In Proceedingsof EACL.Ani Nenkova and Kathleen McKeown.
2011.
Automaticsummarization.
Foundations and Trends in Informa-tion Retrieval.Ani Nenkova, Rebecca Passonneau, and Kathleen McK-eown.
2007.
The pyramid method: Incorporating hu-man content selection variation in summarization eval-uation.
ACM Transactions on Speech and LanguageProcessing.Jun-Ping Ng, Praveen Bysani, Ziheng Lin, Min-Yen Kan,and Chew-Lim Tan.
2012.
Exploiting category-specific information for multi-document summariza-tion.
In Proceedings of COLING.Tadashi Nomoto.
2007.
Discriminative sentence com-pression with conditional random fields.
InformationProcessing and Management.Miles Osborne.
2002.
Using maximum entropy for sen-tence extraction.
In Proceedings of the ACL-02 Work-shop on Automatic Summarization.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of HLT-NAACL.499Xian Qian and Yang Liu.
2013.
Fast joint compressionand summarization via graph cuts.
In Proceedings ofEMNLP.Dragomir R. Radev, Eduard Hovy, and Kathleen McKe-own.
2002.
Introduction to the special issue on sum-marization.
In Computational Linguistics.Kapil Thadani and Kathleen McKeown.
2013.
Sentencecompression with joint structural inference.
In Pro-ceedings of CoNLL.Jenine Turner and Eugene Charniak.
2005.
Supervisedand unsupervised learning for sentence compression.In Proceedings of ACL.Xiaojun Wan, Jianwu Yang, and Jianguo Xiao.
2007.
To-wards an iterative reinforcement approach for simulta-neous document summarization and keyword extrac-tion.
In Proceedings of ACL.Lu Wang, Hema Raghavan, Vittorio Castelli, Radu Flo-rian, and Claire Cardie.
2013.
A sentence com-pression based framework to query-focused multi-document summarization.
In Proceedings of ACL.Kristian Woodsend and Mirella Lapata.
2012.
Multipleaspect summarization using integer linear program-ming.
In Proceedings of EMNLP-CoNLL.Katsumasa Yoshikawa, Tsutomu Hirao, Ryu Iida, andManabu Okumura.
2012.
Sentence compression withsemantic role constraints.
In Proceedings of ACL.David Zajic, Bonnie J. Dorr, Jimmy Lin, and RichardSchwartz.
2007.
Multi-candidate reduction: Sentencecompression as a tool for document summarizationtasks.
In Information Processing and Management.500
