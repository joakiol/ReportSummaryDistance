A CENTERING APPROACH TO PRONOUNSSusan E. Brennan, Marilyn W. Friedman, Carl J. PollardHewlett-Packard Laboratories1501 Page Mill RoadPalo Alto, CA 94304, USAAbst ractIn this paper we present a formalization of the center-ing approach to modeling attentional structure in dis-course and use it as the basis for an algorithm to trackdiscourse context and bind pronouns.
As describedin \[GJW86\], the process of centering attention on en-tities in the discourse gives rise to the intersententialtransitional states of continuing, re~aining and shift-ing.
We propose an extension to these states whichhandles some additional cases of multiple ambiguouspronouns.
The algorithm has been implemented inan HPSG natural language system which serves asthe interface to a database query application.1 In t roduct ionIn the approach to discourse structure developed in\[Sid83\] and \[GJW86\], a discourse xhibits both globaland local coherence.
On this view, a key elementof local coherence is centering, a system of rulesand constraints that govern the relationship betweenwhat the discourse is about and some of the lin-guistic choices made by the discourse participants,e.g.
choice of grammatical function, syntactic struc-ture, and type of referring expression (proper noun,definite or indefinite description, reflexive or per-sonal pronoun, etc.).
Pronominalization i partic-ular serves to focus attention on what is being talkedabout; inappropriate use or failure to use pronounscauses communication to be less fluent.
For instance,it takes longer for hearers to process a pronominal-ized noun phrase that is no~ in focus than one that is,while it takes longer to process a non-pronominalizednoun phrase that is in focus than one that is not\[Gui85\].The \[GJW86\] centering model is based on the fol-lowing assumptions.
A discourse segment consists ofa sequence of utterances U1 .
.
.
.
.
U,~.
With each ut-terance Ua is associated a list of forward.looking cen-~ers, Cf(U,), consisting of those discourse entitiesthat are directly realized or realized I by linguistic ex-pressions in the utterance.
Ranking of an entity onthis list corresponds roughly to the likelihood that itwill be the primary focus of subsequent discourse; thefirst entity on this list is the preferred cen~er, Cp(U, O.U,~ actually centers, or is "about", only one entity ata time, the backward-looking cen~er, Cb(U=).
Thebackward center is a confirmation of an entity thathas already been introduced into the discourse; morespecifically, it must be realized in the immediatelypreceding utterance, Un-1.
There are several distincttypes of transitions from one utterance to the next.The typology of transitions is based on two factors:whether or not the center of attention, Cb, is the samefrom Un-1 to Un, and whether or not this entity co-incides with the preferred center of U,~.
Definitionsof these transition types appear in figure 1.These transitions describe how utterances arelinked together in a coherent local segment of dis-course.
If  a speaker has a number of propositions toexpress, one very simple way to do this coherentlyis to express all the propositions about a given en-tity (continuing) before introducing a related entity1U directly realizes c if U is an utterance (of some phrase,not necessarily a full clause) for which c is the semantic in-terpretation, and U realizes c if either c is an element of thesituation described by the utterance U or c is directly real-ized by some subpart of U.
Realizes is thus a generalization ofirectly realizes\[G JW86\].155cK~)= cM~)cKu.)
# cv(~.)Cb(U.)
= Cb(U._,) Cb(U.)
# Cb(U._,)CONTINUINGRETAININGSHIFTINGFigure 1 : Transition States(retaining) and then shifting the center to this newentity.
See figure 2.
Retaining may be a way to sig-nal an intention to shift.
While we do not claim thatspeakers really behave in such an orderly fashion, analgorithm that expects this kind of behavior is moresuccessful than those which depend solely on recencyor parallelism of grammatical function.
The inter-action of centering with global focusing mechanismsand with other factors such as intentional structure,semantic selectional restrictions, verb tense and as-pect, modality, intonation and pitch accent are topicsfor further esearch.Note that these transitions are more specific thanfocus movement as described in \[Sid83\].
The exten-sion we propose makes them more specific still.
Notealso that the Cb of \[GJW86\] corresponds roughly toSidner's discourse focus and the Cf to her potentialfoci.The formal system of constraints and rules for cen-tering, as we have interpreted them from \[GJW86\],are as follows.
For each \[7, in \[71,..., U,n:?
CONSTRAINTS1.
There is precisely one Cb.2.
Every element of Cf(Un) must be realizedin U,.3.
Cb(Un) is the highest-ranked element ofCf(U,-1) that is realized in U,.?
RULES1.
If some element of Cf(U,-1) is realized asa pronoun in U,, then so is Cb(U,).2.
Continuing is preferred over retainingwhich is preferred over shifting.As is evident in constraint 3, ranking of the itemson the forward center list, Cf, is crucial.
We rank theitems in Cf by obliqueness ofgrammatical relation ofthe subcategorized functions of the main verb: thatis, first the subject, object, and object2, followed byother subcategorized functions, and finally, adjuncts.This captures the idea in \[GJW86\] that subjecthoodcontributes strongly to the priority of an item on theC/list.CONTINUING...Un+l: Carl works at tIP on the Natural LanguageProject.Cb: \[POLLARD:Carl\]Of: (\[POLLARD:Carl\] \[HP:HP\]\[NATLANG:Natural Language Project\])CONTINUING...U,+2: He manages Lyn.Cb: \[POLLARD:Carl\]CI: (\[POLLARD:A1\] [FRIEDMAN:Lyn\])He = CarlCONTINUING...Un+3: He promised to get her a raise.Cb: \[POLLARD:A1\]el: (\[POLLARD:A2\] [FRIEDMAN:A3\]\[I~AISE:Xl\])He = Carl, her = LynRETAINING...\[/,+4: She doesn't believe him.Cb: \[POLLARD:A2\]Cf: (\[FRIEDMAN:A4\] \[POLLARD:AS\])She = Lyn, him = CarlFigure 2We are aware that this ranking usually coincideswith surface constituent order in English.
It wouldbe of interest o examine data from languages withrelatively freer constituent order (e.g.
German) to de-termine the influence of constituent order upon cen-tering when the grammatical functions are held con-stant.
In addition, languages that provide an identifi-able topic function (e.g.
Japanese) suggest that topictakes precedence over subject.The part of the HPSG system that uses the cen-tering algorithm for pronoun binding is called the156pragmatics processor.
It interacts with another mod-ule called the semantics processor, which computesrepresentations of intrasentential anaphoric relations,(among other things).
The semantics processor hasaccess to information such as the surface syntacticstructure of the utterance.
It provides the pragmat-ics processor with representations which include of aset of reference markers.
Each reference marker iscontraindexed ~ with expressions with which it can-not co-specify 3.
Reference markers also carry infor-mation about agreement and grammatical function.Each pronominal reference marker has a unique in-dex from Ax, .
.
.
,An  and is displayed in the figuresin the form \[POLLARD:A1 L where POLLARD isthe semantic representation f the co-specifier.
Fornon-pronominal reference markers the surface stringis used as the index.
Indices for indefinites are gen-erated from X I , .
.
.
,  X,~.2 Extens ionThe constraints proposed by \[GJW86\] fail in certainexamples like the following (read with pronouns de-stressed):Brennan drives an Alfa Romeo.She drives too fast.Friedman races her on weekends.She often beats her.This example is characterized by its multiple am-biguous pronouns and by the fact that the final ut-terance achieves a shift (see figure 4).
A shift is in-evitable because of constraint 3, which states thatthe Cb(U,~) must equal the Cp(U,-I) (since theCp(Un-x) is directly realized by the subject of Un,"Friedman").
However the constraints and rules from\[GJW86\] would fail to make a choice here between theco-specification possibilities for the pronouns in U,.Given that the transition is a shift, there seem to bemore and less coherent ways to shi~.
Note that thethree items being examined in order to characterizethe transition between each pair of anchors 4 are the= See \[BP80\] and \[Cho80\] for conditions on coreference3 See \[Sid83\] for definition and discussion of co-specification.Note that this use of co-specification is not the saxne as thatused in \[Se185\]4An anchor is a < Cb, Of > pair for an utteranceCb(U,,) = cpW.
)Cb(V,,) # cp(u.)CbW.)
= cb(~z._~) cbw.)
# CbW,,_,)CONTINUINGRETAININGSHIFTING-ISHIFTINGFigure 3 : Extended Transition StatesCb of U,,-1, the Cb of U,~, and the Cp of Un.
By\[GJW86\] a shift occurs whenever successive Cb's arenot the same.
This definition of shifting does notconsider whether the Cb of U, and the Cp of Un areequal.
It seems that the status of the Cp of Un shouldbe as important in this case as it is in determiningthe retaining/continuing distinction.Therefore, we propose the following extensionwhich handles ome additional cases containing mul-tiple ambiguous pronouns: we have extended rule 2so that there are two kinds of shifts.
A transitionfor Un is ranked more highly if Cb(Un) = Cp(U,);this state we call shifting-1 and it represents a morecoherent way to shift.
The preferred ranking iscontinuing >- retaining >- shifting-1 ~ shifting (seefigure 3).
This extension enables us to successfullybind the "she" in the final utterance of the examplein figure 4 to "Friedman."
The appendix illustratesthe application of the algorithm to figure 4.Kameyama \[Kam86\] has proposed another exten-sion to the \[G:JW86\] theory - a property-sharing con-straint which attempts to enforce a parallellism be-tween entities in successive utterances.
She considerstwo properties: SUBJ and IDENT.
With her exten-sion, subject pronouns prefer subject antecedents andnon-subject pronouns prefer non-subject antecedents.However, structural parallelism is a consequence ofour ordering the Cf  list by grammatical function andthe preference for continuing over retaining.
Further-more, the constraints uggested in \[GJW86\] succeedin many cases without invoking an independent s ruc-tural parallelism constraint, due to the distinctionbetween continuing and retaining, which Kameyamafails to consider.
Her example which we reproduce infigure 5 can also be accounted for using the contin-157CONTINUING...U,,+I: Brennan drives an Alfa Romeo.Cb: \[BRENNAN:Brennan\]C f: (\[BRENNAN:Brennan\] \[X2:Alfa Komeo\])CONTINUING...U,,+2: She drives too fast.Cb: \[BRENNAN:Brennan\]C f: (\[BRENNAN:AT\])She = BrennanRETAINING...U,~+s: Friedman races her on weekends.Cb: \[BRENNAN:A7\]C f: (\[FRIEDMAN:Friedman\] \[BI~ENNAN:A8\]\[WEEKEND:X3\])her = BrennanSHIFTING-l_.Un+4: She often beats her.Cb: \[FRIEDMAN:Friedman\]Of: (\[FRIEDMAN:A9\] \[BRENNAN:A10\])She = Friedman, her = BrennanFigure 4CONTINUING...U,~+I: Who is Max waiting for?Cb: \[PLANCK:Max\]Of :  (\[PLANCK:Max\])CONTINUING...Un+2: He is waiting for Fred.Cb: \[PLANCK:Max\]C.f: (\[PLANCK:A1\] \[FLINTSTONE:Fred\])He = MaxCONTINUING...U,~+3: He invited him to dinner.Cb: \[PLANCK:A1\]of:  (\[PLANCK:A2\] \[FLINTSTONE:A3\])He - Max, him = FredFigure 5uing/retaining distinction s. The third utterance inthis example has two interpretations which are bothconsistent with the centering rules and constraints.Because of rule 2, the interpretation i  figure 5 ispreferred over the one in figure 6.3 Algorithm for centering andpronoun bindingThere are three basic phases to this algorithm.First the proposed anchors are constructed, thenthey are filtered, and finally, they are classified andranked.
The proposed anchors represent all the co-specification relationships available for this utterance.Each step is discussed and illustrated in figure 7.It would be possible to classify and rank the pro-posed anchors before filtering them without any otherchanges to the algorithm.
In fact, using this strategy5It seems that  property shar ing of I 'DENT is still necessaryto account for logophoric use of pronouns in Japanese.CONTINUING...U,~+~: Who is Max waiting for?Cb: \[PLANCK:Max\]e l :  (\[PLANCK:Max\])CONTINUING...U,~+2: He is waiting for Fred.Cb: \[PLANCK:Max\]el :  (\[PLANCK:A1\] \[FLINTSTONE:Fred\])he = MaxRETAINING...Ur=+3: He invited him to dinner.Cb: \[PLANCK:A1\]el :  (\[FLINTSTONE:A3\] [PLANCK:A2\])He = Fred, him = MaxFigure 6158I.
CONSTRUCT THE PROPOSED ANCHORS for Un(a) Create set of referring expressions (RE's).
(b) Order KE's by grammatical relation.
(c) Create set of possible forward center (C f) lists.
Expandeach element of (b) according to whether it is a pronounor a proper name.
Expand pronouns into set with entryfor each discourse entity which matches its agreementfeatures and expand proper nouns into a set with anentry for each possible referent.
These expansions area way of encoding a disjunction of possibilities.
(d) Create list of possible backward centers (Cb's).
This istaken as the entities f~om Cf(U,-1) plus an additionalentry of NIL to allow the possibility that we will notfind a Cb for the current utterance.
(e) Create the proposed anchors.
(Cb-O.f combinationsfrom the cross-product of the previous two steps)2.
F ILTER THE PROPOSED ANCHORSFor each anchor in our list of proposed anchors we apply thefollowing three filters.
If it passes each filter then it is still apossible anchor for the current utterance.
(a) Filter by contraindices.
That is, if we have proposedthe same antecedent for two contraindexed pronounsor if we have proposed an antecedent for a pronounwhich it is contraindexed with, eliminate this anchorfrom consideration.
(b) Go through Cf(U,_,) keeping (in order) those whichappear in the proposed Cf list of the anchor.
If theproposed Cb of the anchor does not equal the first ele-ment of this constructed list then eliminate this anchor.This guarantees that the Cb will be the highest rankedelement of the Cf(U,-t) realized in the current utter-ance.
(This corresponds to constraint 3 given in sectiont)(c) If none of the entities realized as pronouns in the pro-posed C\[ list equals the proposed Cb then eliminatethis anchor.
This guarantees that if any element is re-alized as a pronoun then the Cb is realized as a pronoun.
(If there are no pronouns in the proposed C\[ list thenthe anchor passes this filter.
This corresponds' to rule1 in section 1).
This rule could be implemented as apreference strategy rather than a strict filter.3.
CLASS IFY  and BANKEXAMPLE:  She doesn't believe him.
(U,+4 from figure 2)= (\[A4\] \[AS\])=t, (\[A4\] \[AS\])=~ (\[FRIEDMAN:A4\] \[POLLARD:A5\])=> (\[POLLARD:A2\] [FKIEDMAN:A3\] \[KAISE:XI\] NIL).=~ There are four possible < Cb, Cf > pairs for this utterance.i.
<\[POLLARD:A2\], (\['FRIEDMAN:A4\] \[POLLARD:A5\])>ii.
<\[FRIEDMAN:A3\], (\[FRIEDMAN:A4\] [POLLARD:A5\])>iii.
<\[KAISE:X1\], (\[FRIEDMAN:A4\] [POLLARD:A$\])>iv.
<NIL, (\[FRIEDMAN:A4\] [POLLARD:A5\])>=~ This filter doesn't eliminate any of the proposed anchors inthis example.
Even though \[A4\] and \[A5\] are contraindexedwe have not proposed the same co-specifier due to agreement.=~ This filter eliminates proposed anchors ii, i i i ,  iv.=~ This filter doesn't eliminate any of the proposed anchors.The proposed Cb was realized as a pronoun.
(a) Classify each anchor on the list of proposed anchors by =~ Anchor i is classified as a retention based on tim transitionthe transitions as described in section 1 taking U,~-t to state definition.be the previous utterance and U, to be the one we arecurrently working on.
(b) Rank each proposed anchor using the extended rank- =~ Anchor i is the most highly ranked anchor (trivially).ing in section 2.
Set Cb(Un) to the proposed Cb andCf(Un) to proposed Cf of the most highly ranked an-chor.Figure 7 : A lgor i thm and Example159one could see if the highest ranked proposal passed allthe filters, or if the next highest did, etc.
The threefilters in the filtering phase may be done in parallel.The example we use to illustrate the algorithm is infigure 2.4 D iscuss ion4.1 Discussion of the algor i thmThe goal of the current algorithm design was concep-tual clarity rather than efficiency.
The hope is thatthe structure provided will allow easy addition of fur-ther constraints and preferences.
It would be simpleto change the control structure of the algorithm sothat it first proposed all the continuing or retaininganchors and then the shifting ones, thus avoiding aprecomputation f all possible anchors.\[GJW86\] states that a realization may contributemore than one entity to the Cf(U).
This is truein cases when a partially specified semantic descrip-tion is consistent with more than one interpreta-tion.
There is no need to enumerate xplicitly allthe possible interpretations when constructing pos-sible C f(U)'s 6, as long as the associated semantictheory allows partially specified interpretations.
Thisalso holds for entities not directly realized in an ut-terance.
On our view, after referring to "a house"in U,,, a reference to "the door" in U,~+I might begotten via inference from the representation for '%house" in Cf(Un).
Thus when the proposed anchorsare constructed there is no possibility of having aninfinite number of potential Cf's for an utterance offinite length.Another question is whether the preference order-ing of transitions in constraint 3 should always bethe same.
For some examples, particularly whereU,~ contains a single pronoun and U,~-I is a reten-tion, some informants eem to have a preference forshifting, whereas the centering algorithm chooses acontinuation (see figure 8).
Many of our informantshave no strong preference as to the co-specificationof the unstressed "She" in Un+4.
Speakers can avoidambiguity by stressing a pronoun with respect o itsphonological environment.
A computational system6 Barbara Grosz, personal communication, a d \[GJW86\]CONTINUING...Ur,+1: Brennan drives an Alfa P~omeo.Cb: \[BRENNAN:Brennan\]e l :  (\[BRENNAN:Brennan\] \[ALFA:X1\])CONTINUING...U,~+2: She drives too fast.Cb: \[B1LENNAN:Brennan\]C f: (\[BRENNAN:A7\])She - BrennanRETAINING...Un+3: Friedman races her on weekends.Cb: \[BB.ENNAN:A7\]C,f: (\[FRIEDMAN:Friedman\]\ [BRENNAN:A8\ ] )\ [WEEKEND:X3\ ] )her -- BrennanCONTINUING...U,~+4: She goes to Laguna Seca.Cb: \[BI~ENNAN:A8\]C f: (\[BRENNAN:A9\] \[LAG-SEC:LagunaSeca\])She - Brennan?
?Figure 8for understanding may need to explicitly acknowledgethis ambiguity.A computational system for generation would tryto plan a retention as a signal of an impending shift,so that after a retention, a shift would be preferredrather than a continuation.4.2 Future  ResearchOf course the local approach described here does notprovide all the necessary information for interpret-ing pronouns; constraints are also imposed by worldknowledge, pragmatics, emantics and phonology.There are other interesting questions concerningthe centering algorithm.
How should the centeringalgorithm interact with an inferencing mechanism?Should it make choices when there is more thanone proposed anchor with the same ranking?
In adatabase query system, how should answers be in-160corporated into the discourse model?
How does cen-tering interact with a treatment ofdefinite/indefiniteNP's and quantifiers?We are exploring ideas for these and other exten-sions to the centering approach for modeling referencein local discourse.5 AcknowledgementsWe would like to thank the following people fortheir help and insight: Hewlett Packard Lab's Natu-ral Language group, CSLI's DIA group, Candy Sid-net, Dan Flickinger, Mark Gawron, :John Nerbonne,Tom Wasow, Barry Arons, Martha Pollack, Aravind:Joshi, two anonymous referees, and especially Bar-bara Grosz.6 AppendixThis illustrates the extension in the same detail asthe example we used in the algorithm.
The number-ing here corresponds to the numbered steps in thealgorithm figure 7.
The example is the last utterancefrom figure 4.EXAMPLE:  She often beats her.I.
CONSTRUCT THE PROPOSED AN-CHORS(a) (\[Ag\] \[A10\])(b) (\[A9\] [A10\])(c) ((\[FRIEDMAN:A9\] [FRIEDMAN:A10\])(\[FRIEDMAN:A9\] \[BRENNAN:A10\])(\[BRENNAN:A9\] [BRENNAN:A10\])(\[BRENNAN:A9\] [FRIEDMAN:A10\]))(d) (\[FRIEDMAN:Friedman\] \[BRENNAN:A8\]\[WEEKEND:X3\] NIL)(e) There are 16 possible < Cb, C f  > pairs forthis utterance.i.
<\[FRIEDMAN:Friedman\],(\[FRIEDMAN:Ag\] [FRIEDMAN:A10\])>ii.
<\[FRIEDMAN:Friedman\],(\[FRIEDMAN:A9\] [BRENNAN:A10\])>iii.
<\[FRIEDMAN:Friedman\],(\[BRENNAN:A9\] \[FRIEDMAN:A10\]) >iv.
< \[FRiEDMAN:Friedmaa\],(\[BRENNAN:A9\] \[BRENNAN:A10\])>v.
<\[BRENNAN:A8\],(\[FRIEDMAN:Ag\] [FRIEDMAN:A10\])>vi.
<\[BRENNAN:A8\],(\[FRIEDMAN:Ag\] [BRENNAN:A10\])>vii.
<\[BRENNAN:A8\],(\[BRENNAN:A9\] \[FRIEDMAN:A10\])>viii.
<\[BRENNAN:A8\],(\[BRENNAN:A9\] \[BRENNAN:A10\])>ix.
<\[WEEKEND:X3\],(\[FRIEDMAN:Ag\] [FRIEDMAN:A10\])>x.
<\[WEEKEND:X3\],(\[FRIEDMAN:Ag\] [BRENNAN:A10\])>xi.
<\[WEEKEND:X3\],(\[BRENNAN:Ag\] \[FRIEDMAN:A10\])>xii.
<\[WEEKEND:X3\],(\[BRENNAN:A9\] \[BRENNAN:A10\])>xiii.
<NIL,(\[FRIEDMAN:Ag\] [FRIEDMAN:A10\])>xiv.
<NIL,(\[FRIEDMAN:A9\] [BRENNAN:A10\])>xv.
<NIL,(\[BRENNAN:Ag\] \[FRIEDMAN:A10\])>xvi.
<NIL,(\[BRENNAN:A9\] \[BRENNAN:A10\])>2.
F ILTER THE PROPOSED ANCHORS(a) Filter by contraindices.
Anchors i, iv, v,viii, iz, zii, ziii, zvi are eliminated since \[A9\]and \[A10\] are contraindexed.
(b) Constraint 3 filter eliminates proposed an-chors vii, ix through zvi.
(c) Rule 1 filter eliminates proposed anchors izthrough zvi.3.
CLASSIFY arid RANK(a) After filtering there are only two anchorsleft.ii: <\[FRIEDMAN:Friedman\],(\[FRIEDMAN:Ag\] [BRENNAN:A10\])>iii: <\[FRIEDMAN:Friedman\],(\[BRENNAN:A9\] \[FRIEDMAN:A10\])>Anchor ii is classified as shifting-1 whereasanchor iii is classified as shifting.
(b) Anchor ii is more highly ranked.161References\[BPS0\]\[Cho80\]\[GJW83\]\[GJw861\[Gs85\]\[Gui85\]\[Kam86\]\[Se185\]\[SH841\[Sid81\]E. Bach and B.H.
Partee.
Anaphora ndsemantic structure.
In J. Kreiman and A.Ojeda, editors, Papers from the Parases.sion on Pronouns and Anaphora, pages 1-28, CLS, Chicago, IL, 1980.N.
Chomsky.
On binding.
Linguistic In-quiry, 11:pp.
1-46, 1980.B.J.
Grosz, A.K.
Joshi, and S. Weinstein.Providing aunified account of definite nounphrases in discourse.
In Proc., Blst AnnualMeeting of the ACL, Association of Com-putational Linguistics, pages 44-50, Cam-bridge, MA, 1983.B.J.
Grosz, A.K.
Joshi, and S. Weinstein.Towards a computational theory of dis-course interpretation.
Preliminary draft,1986.B.J.
Gross and C.L.
Sidner.
The Strnc.ture of Discourse Structure.
Technical Re-port CSLI-85-39, Center for the Study ofLanguage and Information, Stanford, CA,1985.R.
Guindon.
Anaphora resolution: shortterm memory and focusing.
In Proc., 238tAnnual Meeting of the ACL, Association ofComputational Linguistics, pages pp.
218--227, Chicago, IL, 1985.M.
Kameyama.
A property-sharing con-straint in centering.
In Proc., 24st AnnualMeeting of the A CL, Association of Com-putational Linguistics, pages pp.
200-206,New York, NY, 1986.P.
Sells.
Coreference and bound anaphora:a restatement of the facts.
In ChoeBerman and McDonough, editors, Proceed-ings of \]gELS 16, GLSA, University of Mas-sachusetts, 1985.I.
Sag and J. Hankamer.
Towards a theoryof anaphoric processing.
Linguistics andPhilosophy, 7:pp.
325-345, 1984.C.L.
Sidner.
Focusing for interpretation fpronouns.
American Journal of Computa-tional Linguistics, 7(4):pp.
217-231, 1981.\[Sid83\] C.L.
Sidner.
Focusing in the comprehen-sion of definite anaphora.
In M. Bradyand R.C.
Berwick, editors, ComputationalModels of Discourse, MIT Press, 1983.162
