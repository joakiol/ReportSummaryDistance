Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 562?571,Honolulu, October 2008. c?2008 Association for Computational LinguisticsA Tale of Two Parsers: investigating and combining graph-based andtransition-based dependency parsing using beam-searchYue Zhang and Stephen ClarkOxford University Computing LaboratoryWolfson Building, Parks RoadOxford OX1 3QD, UK{yue.zhang,stephen.clark}@comlab.ox.ac.ukAbstractGraph-based and transition-based approachesto dependency parsing adopt very differentviews of the problem, each view having itsown strengths and limitations.
We study bothapproaches under the framework of beam-search.
By developing a graph-based and atransition-based dependency parser, we showthat a beam-search decoder is a competitivechoice for both methods.
More importantly,we propose a beam-search-based parser thatcombines both graph-based and transition-based parsing into a single system for train-ing and decoding, showing that it outper-forms both the pure graph-based and the puretransition-based parsers.
Testing on the En-glish and Chinese Penn Treebank data, thecombined system gave state-of-the-art accura-cies of 92.1% and 86.2%, respectively.1 IntroductionGraph-based (McDonald et al, 2005; McDon-ald and Pereira, 2006; Carreras et al, 2006) andtransition-based (Yamada and Matsumoto, 2003;Nivre et al, 2006) parsing algorithms offer two dif-ferent approaches to data-driven dependency pars-ing.
Given an input sentence, a graph-based algo-rithm finds the highest scoring parse tree from allpossible outputs, scoring each complete tree, whilea transition-based algorithm builds a parse by a se-quence of actions, scoring each action individually.The terms ?graph-based?
and ?transition-based?were used by McDonald and Nivre (2007) to de-scribe the difference between MSTParser (McDon-ald and Pereira, 2006), which is a graph-based parserwith an exhaustive search decoder, and MaltParser(Nivre et al, 2006), which is a transition-basedparser with a greedy search decoder.
In this paper,we do not differentiate graph-based and transition-based parsers by their search algorithms: a graph-based parser can use an approximate decoder whilea transition-based parser is not necessarily determin-istic.
To make the concepts clear, we classify the twotypes of parser by the following two criteria:1. whether or not the outputs are built by explicittransition-actions, such as ?Shift?
and ?Reduce?;2.
whether it is dependency graphs or transition-actions that the parsing model assigns scores to.By this classification, beam-search can be appliedto both graph-based and transition-based parsers.Representative of each method, MSTParser andMaltParser gave comparable accuracies in theCoNLL-X shared task (Buchholz and Marsi, 2006).However, they make different types of errors, whichcan be seen as a reflection of their theoretical differ-ences (McDonald and Nivre, 2007).
MSTParser hasthe strength of exact inference, but its choice of fea-tures is constrained by the requirement of efficientdynamic programming.
MaltParser is deterministic,yet its comparatively larger feature range is an ad-vantage.
By comparing the two, three interesting re-search questions arise: (1) how to increase the flex-ibility in defining features for graph-based parsing;(2) how to add search to transition-based parsing;and (3) how to combine the two parsing approachesso that the strengths of each are utilized.In this paper, we study these questions under oneframework: beam-search.
Beam-search has beensuccessful in many NLP tasks (Koehn et al, 2003;562Inputs: training examples (xi, yi)Initialization: set ~w = 0Algorithm:// R training iterations; N examplesfor t = 1..R, i = 1..N :zi = argmaxy?GEN(xi) ?
(y) ?
~wif zi 6= yi:~w = ~w + ?(yi)?
?
(zi)Outputs: ~wFigure 1: The perceptron learning algorithmCollins and Roark, 2004), and can achieve accuracythat is close to exact inference.
Moreover, a beam-search decoder does not impose restrictions on thesearch problem in the way that an exact inferencedecoder typically does, such as requiring the ?op-timal subproblem?
property for dynamic program-ming, and therefore enables a comparatively widerrange of features for a statistical system.We develop three parsers.
Firstly, using the samefeatures as MSTParser, we develop a graph-basedparser to examine the accuracy loss from beam-search compared to exact-search, and the accuracygain from extra features that are hard to encodefor exact inference.
Our conclusion is that beam-search is a competitive choice for graph-based pars-ing.
Secondly, using the transition actions fromMaltParser, we build a transition-based parser andshow that search has a positive effect on its accuracycompared to deterministic parsing.
Finally, we showthat by using a beam-search decoder, we are ableto combine graph-based and transition-based pars-ing into a single system, with the combined systemsignificantly outperforming each individual system.In experiments with the English and Chinese PennTreebank data, the combined parser gave 92.1% and86.2% accuracy, respectively, which are comparableto the best parsing results for these data sets, whilethe Chinese accuracy outperforms the previous bestreported by 1.8%.
In line with previous work on de-pendency parsing using the Penn Treebank, we fo-cus on projective dependency parsing.2 The graph-based parserFollowing MSTParser (McDonald et al, 2005; Mc-Donald and Pereira, 2006), we define the graph-Variables: agenda ?
the beam for state itemsitem ?
partial parse treeoutput ?
a set of output itemsindex, prev ?
word indexesInput: x ?
POS-tagged input sentence.Initialization: agenda = [??
]Algorithm:for index in 1..x.length():clear outputfor item in agenda:// for all prev words that can be linked with// the current word at indexprev = index ?
1while prev 6= 0: // while prev is valid// add link making prev parent of indexnewitem = item // duplicate itemnewitem.link(prev, index) // modifyoutput.append(newitem) // record// if prev does not have a parent word,// add link making index parent of previf item.parent(prev) == 0:item.link(index, prev) // modifyoutput.append(item) // recordprev = the index of the first word beforeprev whose parent does not existor is on its left; 0 if no matchclear agendaput the best items from output to agendaOutput: the best item in agendaFigure 2: A beam-search decoder for graph-based pars-ing, developed from the deterministic Covington algo-rithm for projective parsing (Covington, 2001).based parsing problem as finding the highest scoringtree y from all possible outputs given an input x:F (x) = argmaxy?GEN(x)Score(y)where GEN(x) denotes the set of possible parses forthe input x.
To repeat our earlier comments, in thispaper we do not consider the method of finding theargmax to be part of the definition of graph-basedparsing, only the fact that the dependency graph it-self is being scored, and factored into scores at-tached to the dependency links.The score of an output parse y is given by a linearmodel:Score(y) = ?
(y) ?
~w563where ?
(y) is the global feature vector from y and~w is the weight vector of the model.We use the discriminative perceptron learning al-gorithm (Collins, 2002; McDonald et al, 2005) totrain the values of ~w.
The algorithm is shown in Fig-ure 1.
Averaging parameters is a way to reduce over-fitting for perceptron training (Collins, 2002), and isapplied to all our experiments.While the MSTParser uses exact-inference (Eis-ner, 1996), we apply beam-search to decoding.
Thisis done by extending the deterministic Covingtonalgorithm for projective dependency parsing (Cov-ington, 2001).
As shown in Figure 2, the decoderworks incrementally, building a state item (i.e.
par-tial parse tree) word by word.
When each word isprocessed, links are added between the current wordand its predecessors.
Beam-search is applied bykeeping the B best items in the agenda at each pro-cessing stage, while partial candidates are comparedby scores from the graph-based model, according topartial graph up to the current word.Before decoding starts, the agenda contains anempty sentence.
At each processing stage, existingpartial candidates from the agenda are extended inall possible ways according to the Covington algo-rithm.
The top B newly generated candidates arethen put to the agenda.
After all input words are pro-cessed, the best candidate output from the agenda istaken as the final output.The projectivity of the output dependency treesis guaranteed by the incremental Covington process.The time complexity of this algorithm is O(n2),where n is the length of the input sentence.During training, the ?early update?
strategy ofCollins and Roark (2004) is used: when the correctstate item falls out of the beam at any stage, parsingis stopped immediately, and the model is updatedusing the current best partial item.
The intuition isto improve learning by avoiding irrelevant informa-tion: when all the items in the current agenda areincorrect, further parsing steps will be irrelevant be-cause the correct partial output no longer exists inthe candidate ranking.Table 1 shows the feature templates from theMSTParser (McDonald and Pereira, 2006), whichare defined in terms of the context of a word, itsparent and its sibling.
To give more templates, fea-tures from templates 1 ?
5 are also conjoined with1 Parent word (P) Pw; Pt; Pwt2 Child word (C) Cw; Ct; Cwt3 P and C PwtCwt; PwtCw;PwCwt; PwtCt;PtCwt; PwCw; PtCt4 A tag Bt PtBtCtbetween P, C5 Neighbour words PtPLtCtCLt;of P, C, PtPLtCtCRt;left (PL/CL) PtPRtCtCLt;and right (PR/CR) PtPRtCtCRt;PtPLtCLt; PtPLtCRt;PtPRtCLt; PtPRtCRt;PLtCtCLt; PLtCtCRt;PRtCtCLt; PRtCtCRt;PtCtCLt; PtCtCRt;PtPLtCt; PtPRtCt6 sibling (S) of C CwSw; CtSt;CwSt; CtSw;PtCtSt;Table 1: Feature templates from MSTParserw ?
word; t ?
POS-tag.1 leftmost (CLC) and PtCtCLCt;rightmost (CRC) PtCtCRCtchildren of C2 left (la) and right (ra) Ptla; Ptra;arity of P Pwtla; PwtraTable 2: Additional feature templates for the graph-basedparserthe link direction and distance, while features fromtemplate 6 are also conjoined with the direction anddistance between the child and its sibling.
Here?distance?
refers to the difference between word in-dexes.
We apply all these feature templates to thegraph-based parser.
In addition, we define two extrafeature templates (Table 2) that capture informationabout grandchildren and arity (i.e.
the number ofchildren to the left or right).
These features are notconjoined with information about direction and dis-tance.
They are difficult to include in an efficientdynamic programming decoder, but easy to includein a beam-search decoder.564Figure 3: Feature context for the transition-based algo-rithm3 The transition-based parserWe develop our transition-based parser using thetransition model of the MaltParser (Nivre et al,2006), which is characterized by the use of a stackand four transition actions: Shift, ArcRight, ArcLeftand Reduce.
An input sentence is processed fromleft to right, with an index maintained for the currentword.
Initially empty, the stack is used throughoutthe parsing process to store unfinished words, whichare the words before the current word that may stillbe linked with the current or a future word.The Shift action pushes the current word to thestack and moves the current index to the next word.The ArcRight action adds a dependency link fromthe stack top to the current word (i.e.
the stack topbecomes the parent of the current word), pushes thecurrent word on to the stack, and moves the currentindex to the next word.
The ArcLeft action adds adependency link from the current word to the stacktop, and pops the stack.
The Reduce action pops thestack.
Among the four transition actions, Shift andArcRight push a word on to the stack while ArcLeftand Reduce pop the stack; Shift and ArcRight readthe next input word while ArcLeft and ArcRight adda link to the output.
By repeated application of theseactions, the parser reads through the input and buildsa parse tree.The MaltParser works deterministically.
At eachstep, it makes a single decision and chooses one ofthe four transition actions according to the currentcontext, including the next input words, the stackand the existing links.
As illustrated in Figure 3, thecontextual information consists of the top of stack(ST), the parent (STP) of ST, the leftmost (STLC) andrightmost child (STRC) of ST, the current word (N0),the next three words from the input (N1, N2, N3) andthe leftmost child of N0 (N0LC).
Given the contexts, the next action T is decided as follows:T (s) = argmaxT?ACTIONScore(T, s)where ACTION = {Shift, ArcRight, ArcLeft,Reduce}.One drawback of deterministic parsing is errorpropagation, since once an incorrect action is made,the output parse will be incorrect regardless of thesubsequent actions.
To reduce such error propa-gation, a parser can keep track of multiple candi-date outputs and avoid making decisions too early.Suppose that the parser builds a set of candidatesGEN(x) for the input x, the best output F (x) canbe decided by considering all actions:F (x) = argmaxy?GEN(x)?T ?
?act(y) Score(T ?, sT ?
)Here T ?
represents one action in the sequence(act(y)) by which y is built, and sT ?
represents thecorresponding context when T ?
is taken.Our transition-based algorithm keeps B differentsequences of actions in the agenda, and chooses theone having the overall best score as the final parse.Pseudo code for the decoding algorithm is shownin Figure 4.
Here each state item contains a partialparse tree as well as a stack configuration, and stateitems are built incrementally by transition actions.Initially the stack is empty, and the agenda containsan empty sentence.
At each processing stage, onetransition action is applied to existing state items asa step to build the final parse.
Unlike the MaltParser,which makes a decision at each stage, our transition-based parser applies all possible actions to each ex-isting state item in the agenda to generate new items;then from all the newly generated items, it takes theB with the highest overall score and puts them ontothe agenda.
In this way, some ambiguity is retainedfor future resolution.Note that the number of transition actions neededto build different parse trees can vary.
For exam-ple, the three-word sentence ?A B C?
can be parsedby the sequence of three actions ?Shift ArcRightArcRight?
(B modifies A; C modifies B) or thesequence of four actions ?Shift ArcLeft Shift Ar-cRight?
(both A and C modifies B).
To ensure thatall final state items are built by the same numberof transition actions, we require that the final state565Variables: agenda ?
the beam for state itemsitem ?
(partial tree, stack config)output ?
a set of output itemsindex ?
iteration indexInput: x ?
POS-tagged input sentence.Initialization: agenda = [(?
?, [])]Algorithm:for index in 1 .. 2?
x.length() ?1:clear outputfor item in agenda:// when all input words have been read, the// parse tree has been built; only pop.if item.length() == x.length():if item.stacksize() > 1:item.Reduce()output.append(item)// when some input words have not been readelse:if item.lastaction() 6= Reduce:newitem = itemnewitem.Shift()output.append(newitem)if item.stacksize() > 0:newitem = itemnewitem.ArcRight()output.append(newitem)if (item.parent(item.stacktop())==0):newitem = itemnewitem.ArcLeft()output.append(newitem)else:newitem = itemnewitem.Reduce()output.append(newitem)clear agendatransfer the best items from output to agendaOutput: the best item in agendaFigure 4: A beam-search decoding algorithm fortransition-based parsingitems must 1) have fully-built parse trees; and 2)have only one root word left on the stack.
In thisway, popping actions should be made even after acomplete parse tree is built, if the stack still containsmore than one word.Now because each word excluding the root mustbe pushed to the stack once and popped off onceduring the parsing process, the number of actionsInputs: training examples (xi, yi)Initialization: set ~w = 0Algorithm:// R training iterations; N examplesfor t = 1..R, i = 1..N :zi = argmaxy?GEN(xi)?T ?
?act(yi) ?
(T?, c?)
?
~wif zi 6= yi:~w = ~w + ?T ?
?act(yi) ?
(T?, cT ?)?
?T ?
?act(zi) ?
(T?, cT ?
)Outputs: ~wFigure 5: the perceptron learning algorithm for thetransition-based parser1 stack top STwt; STw; STt2 current word N0wt; N0w; N0t3 next word N1wt; N1w; N1t4 ST and N0 STwtN0wt; STwtN0w;STwN0wt; STwtN0t;STtN0wt; STwN0w; STtN0t5 POS bigram N0tN1t6 POS trigrams N0tN1tN2t; STtN0tN1t;STPtSTtN0t; STtSTLCtN0t;STtSTRCtN0t; STtN0tN0LCt7 N0 word N0wN1tN2t; STtN0wN1t;STPtSTtN0w; STtSTLCtN0w;STtSTRCtN0w; STtN0wN0LCtTable 3: Feature templates for the transition-based parserw ?
word; t ?
POS-tag.needed to parse a sentence is always 2n ?
1, wheren is the length of the sentence.
Therefore, the de-coder has linear time complexity, given a fixed beamsize.
Because the same transition actions as theMaltParser are used to build each item, the projec-tivity of the output dependency tree is ensured.We use a linear model to score each transition ac-tion, given a context:Score(T, s) = ?
(T, s) ?
~w?
(T, s) is the feature vector extracted from the ac-tion T and the context s, and ~w is the weight vec-tor.
Features are extracted according to the templatesshown in Table 3, which are based on the context inFigure 3.
Note that our feature definitions are sim-ilar to those used by MaltParser, but rather than us-ing a kernel function with simple features (e.g.
STw,566N0t, but not STwt or STwN0w), we combine featuresmanually.As with the graph-based parser, we use the dis-criminative perceptron (Collins, 2002) to train thetransition-based model (see Figure 5).
It is worthnoticing that, in contrast to MaltParser, which trainseach action decision individually, our training algo-rithm globally optimizes all action decisions for aparse.
Again, ?early update?
and averaging parame-ters are applied to the training process.4 The combined parserThe graph-based and transition-based approachesadopt very different views of dependency parsing.McDonald and Nivre (2007) showed that the MST-Parser and MaltParser produce different errors.
Thisobservation suggests a combined approach: by usingboth graph-based information and transition-basedinformation, parsing accuracy can be improved.The beam-search framework we have developedfacilitates such a combination.
Our graph-basedand transition-based parsers share many similarities.Both build a parse tree incrementally, keeping anagenda of comparable state items.
Both rank stateitems by their current scores, and use the averagedperceptron with early update for training.
The keydifferences are the scoring models and incrementalparsing processes they use, which must be addressedwhen combining the parsers.Firstly, we combine the graph-based and thetransition-based score models simply by summation.This is possible because both models are global andlinear.
In particular, the transition-based model canbe written as:ScoreT(y) =?T ?
?act(y) Score(T ?, sT ?
)= ?T ?
?act(y) ?
(T ?, sT ?)
?
~wT= ~wT ?
?T ?
?act(y) ?
(T ?, sT ?
)If we take?T ?
?act(y) ?
(T ?, sT ?)
as the global fea-ture vector ?T(y), we have:ScoreT(y) = ?T(y) ?
~wTwhich has the same form as the graph-based model:ScoreG(y) = ?G(y) ?
~wGSections Sentences WordsTraining 2?21 39,832 950,028Dev 22 1,700 40,117Test 23 2,416 56,684Table 4: The training, development and test data fromPTBWe therefore combine the two models to give:ScoreC(y) = ScoreG(y) + ScoreT(y)= ?G(y) ?
~wG + ?T(y) ?
~wTConcatenating the feature vectors ?G(y) and ?T(y)to give a global feature vector ?C(y), and the weightvectors ~wG and ~wT to give a weight vector ~wC, thecombined model can be written as:ScoreC(y) = ?C(y) ?
~wCwhich is a linear model with exactly the same formas both sub-models, and can be trained with the per-ceptron algorithm in Figure 1.
Because the globalfeature vectors from the sub models are concate-nated, the feature set for the combined model is theunion of the sub model feature sets.Second, the transition-based decoder can be usedfor the combined system.
Both the graph-based de-coder in Figure 2 and the transition-based decoder inFigure 4 construct a parse tree incrementally.
How-ever, the graph-based decoder works on a per-wordbasis, adding links without using transition actions,and so is not appropriate for the combined model.The transition-based algorithm, on the other hand,uses state items which contain partial parse trees,and so provides all the information needed by thegraph-based parser (i.e.
dependency graphs), andhence the combined system.In summary, we build the combined parser byusing a global linear model, the union of featuretemplates and the decoder from the transition-basedparser.5 ExperimentsWe evaluate the parsers using the English and Chi-nese Penn Treebank corpora.
The English datais prepared by following McDonald et al (2005).Bracketed sentences from the Penn Treebank (PTB)3 are split into training, development and test sets567Figure 6: The influence of beam size on the transition-based parser, using the development dataX-axis: number of training iterationsY-axis: word precisionas shown in Table 4, and then translated into depen-dency structures using the head-finding rules fromYamada and Matsumoto (2003).Before parsing, POS tags are assigned to the in-put sentence using our reimplementation of the POS-tagger from Collins (2002).
Like McDonald et al(2005), we evaluate the parsing accuracy by theprecision of lexical heads (the percentage of inputwords, excluding punctuation, that have been as-signed the correct parent) and by the percentageof complete matches, in which all words excludingpunctuation have been assigned the correct parent.5.1 Development experimentsSince the beam size affects all three parsers, westudy its influence first; here we show the effect onthe transition-based parser.
Figure 6 shows differentaccuracy curves using the development data, eachwith a different beam size B.
The X-axis representsthe number of training iterations, and the Y-axis theprecision of lexical heads.The parsing accuracy generally increases as thebeam size increases, while the quantity of increasebecomes very small when B becomes large enough.The decoding times after the first training iterationare 10.2s, 27.3s, 45.5s, 79.0s, 145.4s, 261.3s and469.5s, respectively, when B = 1, 2, 4, 8, 16, 32, 64.Word CompleteMSTParser 1 90.7 36.7Graph [M] 91.2 40.8Transition 91.4 41.8Graph [MA] 91.4 42.5MSTParser 2 91.5 42.1Combined [TM] 92.0 45.0Combined [TMA] 92.1 45.4Table 5: Accuracy comparisons using PTB 3In the rest of the experiments, we set B = 64 inorder to obtain the highest possible accuracy.When B = 1, the transition-based parser be-comes a deterministic parser.
By comparing thecurves when B = 1 and B = 2, we can see that,while the use of search reduces the parsing speed, itimproves the quality of the output parses.
Therefore,beam-search is a reasonable choice for transition-based parsing.5.2 Accuracy comparisonsThe test accuracies are shown in Table 5, where eachrow represents a parsing model.
Rows ?MSTParser1/2?
show the first-order (using feature templates 1 ?5 from Table 1) (McDonald et al, 2005) and second-order (using all feature templates from Table 1)(McDonald and Pereira, 2006) MSTParsers, as re-ported by the corresponding papers.
Rows ?Graph[M]?
and ?Graph [MA]?
represent our graph-basedparser using features from Table 1 and Table 1 + Ta-ble 2, respectively; row ?Transition?
represents ourtransition-based parser; and rows ?Combined [TM]?and ?Combined [TMA]?
represent our combinedparser using features from Table 3 + Table 1 and Ta-ble 3 + Table 1 + Table 2, respectively.
Columns?Word?
and ?Complete?
show the precision of lexi-cal heads and complete matches, respectively.As can be seen from the table, beam-search re-duced the head word accuracy from 91.5%/42.1%(?MSTParser 2?)
to 91.2%/40.8% (?Graph [M]?
)with the same features as exact-inference.
How-ever, with only two extra feature templates fromTable 2, which are not conjoined with direction ordistance information, the accuracy is improved to91.4%/42.5% (?Graph [MA]?).
This improvementcan be seen as a benefit of beam-search, which al-lows the definition of more global features.568Sections Sentences WordsTraining 001?815; 16,118 437,8591001?1136Dev 886?931; 804 20,4531148?1151Test 816?885; 1,915 50,3191137?1147Table 6: Training, development and test data from CTBNon-root Root Comp.Graph [MA] 83.86 71.38 29.82Duan 2007 84.36 73.70 32.70Transition 84.69 76.73 32.79Combined [TM] 86.13 77.04 35.25Combined [TMA] 86.21 76.26 34.41Table 7: Test accuracies with CTB 5 dataThe combined parser is tested with various setsof features.
Using only graph-based features in Ta-ble 1, it gave 88.6% accuracy, which is much lowerthan 91.2% from the graph-based parser using thesame features (?Graph [M]?).
This can be explainedby the difference between the decoders.
In particu-lar, the graph-based model is unable to score the ac-tions ?Reduce?
and ?Shift?, since they do not mod-ify the parse tree.
Nevertheless, the score serves as areference for the effect of additional features in thecombined parser.Using both transition-based features and graph-based features from the MSTParser (?Combined[TM]?
), the combined parser achieved 92.0% per-word accuracy, which is significantly higher than thepure graph-based and transition-based parsers.
Ad-ditional graph-based features further improved theaccuracy to 92.1%/45.5%, which is the best amongall the parsers compared.15.3 Parsing ChineseWe use the Penn Chinese Treebank (CTB) 5 for ex-perimental data.
Following Duan et al (2007), we1A recent paper, Koo et al (2008) reported parent-predictionaccuracy of 92.0% using a graph-based parser with a different(larger) set of features (Carreras, 2007).
By applying separateword cluster information, Koo et al (2008) improved the accu-racy to 93.2%, which is the best known accuracy on the PTBdata.
We excluded these from Table 5 because our work is notconcerned with the use of such additional knowledge.split the corpus into training, development and testdata as shown in Table 6, and use the head-findingrules in Table 8 in the Appendix to turn the bracketedsentences into dependency structures.
Most of thehead-finding rules are from Sun and Jurafsky (2004),while we added rules to handle NN and FRAG, anda default rule to use the rightmost node as the headfor the constituent that are not listed.Like Duan et al (2007), we use gold-standardPOS-tags for the input.
The parsing accuracy is eval-uated by the percentage of non-root words that havebeen assigned the correct head, the percentage ofcorrectly identified root words, and the percentageof complete matches, all excluding punctuation.The accuracies are shown in Table 7.
Rows?Graph [MA]?, ?Transition?, ?Combined [TM]?
and?Combined [TMA]?
show our models in the sameway as for the English experiments from Section 5.2.Row ?Duan 2007?
represents the transition-basedmodel from Duan et al (2007), which applies beam-search to the deterministic model from Yamada andMatsumoto (2003), and achieved the previous bestaccuracy on the data.Our observations on parsing Chinese are essen-tially the same as for English.
Our combined parseroutperforms both the pure graph-based and the puretransition-based parsers.
It gave the best accuracywe are aware of for dependency parsing using CTB.6 Related workOur graph-based parser is derived from the workof McDonald and Pereira (2006).
Instead of per-forming exact inference by dynamic programming,we incorporated the linear model and feature tem-plates from McDonald and Pereira (2006) into ourbeam-search framework, while adding new globalfeatures.
Nakagawa (2007) and Hall (2007) alsoshowed the effectiveness of global features in im-proving the accuracy of graph-based parsing, us-ing the approximate Gibbs sampling method and areranking approach, respectively.Our transition-based parser is derived from thedeterministic parser of Nivre et al (2006).
Weincorporated the transition process into our beam-search framework, in order to study the influenceof search on this algorithm.
Existing efforts toadd search to deterministic parsing include Sagae569and Lavie (2006b), which applied best-first searchto constituent parsing, and Johansson and Nugues(2006) and Duan et al (2007), which applied beam-search to dependency parsing.
All three methods es-timate the probability of each transition action, andscore a state item by the product of the probabilitiesof all its corresponding actions.
But different fromour transition-based parser, which trains all transi-tions for a parse globally, these models train theprobability of each action separately.
Based on thework of Johansson and Nugues (2006), Johanssonand Nugues (2007) studied global training with anapproximated large-margin algorithm.
This modelis the most similar to our transition-based model,while the differences include the choice of learningand decoding algorithms, the definition of featuretemplates and our application of the ?early update?strategy.Our combined parser makes the biggest contribu-tion of this paper.
In contrast to the models above,it includes both graph-based and transition-basedcomponents.
An existing method to combine mul-tiple parsing algorithms is the ensemble approach(Sagae and Lavie, 2006a), which was reported tobe useful in improving dependency parsing (Hall etal., 2007).
A more recent approach (Nivre and Mc-Donald, 2008) combined MSTParser and MaltParserby using the output of one parser for features in theother.
Both Hall et al (2007) and Nivre and McDon-ald (2008) can be seen as methods to combine sep-arately defined models.
In contrast, our parser com-bines two components in a single model, in whichall parameters are trained consistently.7 Conclusion and future workWe developed a graph-based and a transition-basedprojective dependency parser using beam-search,demonstrating that beam-search is a competitivechoice for both parsing approaches.
We then com-bined the two parsers into a single system, using dis-criminative perceptron training and beam-search de-coding.
The appealing aspect of the combined parseris the incorporation of two largely different views ofthe parsing problem, thus increasing the informationavailable to a single statistical parser, and therebysignificantly increasing the accuracy.
When testedusing both English and Chinese dependency data,the combined parser was highly competitive com-pared to the best systems in the literature.The idea of combining different approaches tothe same problem using beam-search and a globalmodel could be applied to other parsing tasks, suchas constituent parsing, and possibly other NLP tasks.AcknowledgementsThis work is supported by the ORS and ClarendonFund.
We thank the anonymous reviewers for theirdetailed comments.AppendixConstituent RulesADJP r ADJP JJ AD; rADVP r ADVP AD CS JJ NP PP P VA VV; rCLP r CLP M NN NP; rCP r CP IP VP; rDNP r DEG DNP DEC QP; rDP r M; l DP DT OD; lDVP r DEV AD VP; rFRAG r VV NR NN NT; rIP r VP IP NP; rLCP r LCP LC; rLST r CD NP QP; rNP r NP NN IP NR NT; rNN r NP NN IP NR NT; rPP l P PP; lPRN l PU; lQP r QP CLP CD; rUCP l IP NP VP; lVCD l VV VA VE; lVP l VE VC VV VNV VPT VRD VSBVCD VP; lVPT l VA VV; lVRD l VVI VA; lVSB r VV VE; rdefault rTable 8: Head-finding rules to extract dependency datafrom CTB570ReferencesSabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of CoNLL, pages 149?164, New YorkCity, USA, June.Xavier Carreras, Mihai Surdeanu, and Lluis Marquez.2006.
Projective dependency parsing with perceptron.In Proceedings of CoNLL, New York City, USA, June.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of theCoNLL Shared Task Session of EMNLP/CoNLL, pages957?961, Prague, Czech Republic, June.Michael Collins and Brian Roark.
2004.
Incrementalparsing with the perceptron algorithm.
In Proceedingsof ACL, pages 111?118, Barcelona, Spain, July.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofEMNLP, pages 1?8, Philadelphia, USA, July.Michael A. Covington.
2001.
A fundamental algorithmfor dependency parsing.
In Proceedings of the ACMSoutheast Conference, Athens, Georgia, March.Xiangyu Duan, Jun Zhao, and Bo Xu.
2007.
Probabilis-tic models for action-based chinese dependency pars-ing.
In Proceedings of ECML/ECPPKDD, Warsaw,Poland, September.Jason Eisner.
1996.
Three new probabilistic models fordependency parsing: An exploration.
In Proceedingsof COLING, pages 340?345, Copenhagen, Denmark,August.Johan Hall, Jens Nilsson, Joakim Nivre, Gu?lsen Eryigit,Bea?ta Megyesi, Mattias Nilsson, and Markus Saers.2007.
Single malt or blended?
a study in multilingualparser optimization.
In Proceedings of the CoNLLShared Task Session of EMNLP/CoNLL, pages 933?939, Prague, Czech Republic, June.Keith Hall.
2007.
K-best spanning tree parsing.
In Pro-ceedings of ACL, Prague, Czech Republic, June.Richard Johansson and Pierre Nugues.
2006.
Investigat-ing multilingual dependency parsing.
In Proceedingsof CoNLL, pages 206?210, New York City, USA, June.Richard Johansson and Pierre Nugues.
2007.
Incremen-tal dependency parsing using online learning.
In Pro-ceedings of the CoNLL/EMNLP, pages 1134?1138,Prague, Czech Republic.Philip Koehn, Franz Och, and Daniel Marcu.
2003.
Sta-tistical phrase-based translation.
In Proceedings ofNAACL/HLT, Edmonton, Canada, May.Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Pro-ceedings of ACL/HLT, pages 595?603, Columbus,Ohio, June.Ryan McDonald and Joakim Nivre.
2007.
Characteriz-ing the errors of data-driven dependency parsing mod-els.
In Proceedings of EMNLP/CoNLL, pages 122?131, Prague, Czech Republic, June.R McDonald and F Pereira.
2006.
Online learning of ap-proximate dependency parsing algorithms.
In In Proc.of EACL, pages 81?88, Trento, Italy, April.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL, pages 91?98, AnnArbor, Michigan, June.Tetsuji Nakagawa.
2007.
Multilingual dependencyparsing using global features.
In Proceedings of theCoNLL Shared Task Session of EMNLP/CoNLL, pages952?956, Prague, Czech Republic, June.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL/HLT, pages 950?958, Colum-bus, Ohio, June.Joakim Nivre, Johan Hall, Jens Nilsson, Gu?ls?en Eryig?it,and Svetoslav Marinov.
2006.
Labeled pseudo-projective dependency parsing with support vector ma-chines.
In Proceedings of CoNLL, pages 221?225,New York City, USA, June.K Sagae and A Lavie.
2006a.
Parser combination byreparsing.
In In Proc.
HLT/NAACL, pages 129?132,New York City, USA, June.Kenji Sagae and Alon Lavie.
2006b.
A best-first prob-abilistic shift-reduce parser.
In Proceedings of COL-ING/ACL (poster), pages 691?698, Sydney, Australia,July.Honglin Sun and Daniel Jurafsky.
2004.
Shallowsemantic parsing of Chinese.
In Proceedings ofNAACL/HLT, Boston, USA, May.H Yamada and Y Matsumoto.
2003.
Statistical depen-dency analysis using support vector machines.
In Pro-ceedings of IWPT, Nancy, France, April.571
