Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 241?249, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUMCC_DLSI: Reinforcing a Ranking Algorithm with SenseFrequencies and Multidimensional Semantic Resources to solveMultilingual Word Sense DisambiguationYoan Guti?rrez, YenierCasta?eda, Andy Gonz?lez,Rainel Estrada, Dennys D. Piug,Jose I. Abreu, Roger P?rezAntonio Fern?ndez Orqu?n,Andr?s Montoyo, Rafael Mu?ozFranc CamaraDI, University of Matanzas DLSI, University of Alicante Independent ConsultantMatanzas, Cuba Alicante, Spain USA{yoan.gutierrez,yenier.castaneda,rainel.estrada,dennys.puig, jose.abreu,roger.perez}@umcc.cu,andy.gonzalez@infonet.umcc.cuantonybr@yahoo.com,{montoyo,rafael}@dlsi.ua.esinfo@franccamara.comAbstractThis work introduces a new unsupervisedapproach to multilingual word sensedisambiguation.
Its main purpose is toautomatically choose the intended sense(meaning) of a word in a particular context fordifferent languages.
It does so by selecting thecorrect Babel synset for the word and thevarious Wiki Page titles that mention theword.
BabelNet contains all the outputinformation that our system needs, in its Babelsynset.
Through Babel synset, we find all thepossible Synsets for the word in WordNet.Using these Synsets, we apply thedisambiguation method Ppr+Freq to find whatwe need.
To facilitate the work with WordNet,we use the ISR-WN which offers theintegration of different resources to WordNet.Our system, recognized as the best in thecompetition, obtains results around 69% ofRecall.1 IntroductionWord Sense Disambiguation (WSD) focuses onresolving the semantic ambiguity of a given word.This is an important task in Natural LanguageProcessing (NLP) because in many applications,such as Automatic Translation, it is essential toknow the exact meaning of a word in a givencontext.
In order to solve semantic ambiguity,different systems have been developed.
However,we can categorize them in two main groups:supervised and unsupervised systems.
Thesupervised ones need large quantity of hand-taggeddata in order to gather enough information to buildrules, train systems, and so on.
Unsupervisedsystems, on the other hand, do not need such alarge amount of hand-tagged datasets.
This meansthat, when there aren?t enough corpora to train thesystems, an unsupervised system is a good option.A sub-task of WSD is Multilingual Word SenseDisambiguation (MWSD) (Navigli et al 2013)that aims at resolving ambiguities in differentlanguages.In a language, there are words that have only onesense (or meaning), but in other languages, thesame words can have different senses.
Forexample, ?patient?
is a word that in English can beeither a noun or an adjective, but in German, itonly has one sense - ?viz?
(a person that needstreatment).
This shows that the informationobtained by combining two languages can be moreuseful for WSD because the word senses in eachlanguage can complement each other.
For it to beuseful, MWSD needs a multilingual resource thatcontains different languages, such as BabelNet(Navigli and Ponzetto, 2010; 2012) andEuroWordNet (Vossen, 1998).241As the preferred disambiguation method, wedecided to use the Ppr+Freq (Personalized PageRank combined with Frequencies of senses)(Guti?rrez, 2012) method because, amongunsupervised systems, graph-based methods haveobtained more promising results.It is worth mentioning the relevant approachesused by the scientific community to achievepromising results.
One approach used is structuralinterconnections, such as Structural SemanticInterconnections (SSI), which create structuralspecifications of the possible senses for each wordin a context (Navigli and Velardi, 2005).
The otherapproaches used are ?Exploring the integration ofWordNet?
(Miller et al 1990), FrameNet (Laparraet al 2010) and those using Page-Rank such as(Sinha and Mihalcea, 2007) and (Agirre and Soroa,2009).The aforementioned types of graph basedapproaches have achieved relevant results in boththe SensEval-2 and SensEval-3 competitions (seeTable 1).Algorithm RecallTexRank (Mihalcea, 2005)  54.2%(Sinha and Mihalcea, 2007) 56.4%(Tsatsaronis et al 2007) 49.2%Ppr (Agirre and Soroa, 2009) 58.6%Table 1.
Relevant WSD approaches.
Recall measure iscalculated recalls using SensEval-2 (English All Wordtask) guidelines over.Experiments using SensEval-2 and SensEval-3corpora suggest that Ppr+Freq (Guti?rrez, 2012)can lead to better results by obtaining over 64% ofRecall.
Therefore we selected Ppr+Freq as theWSD method for our system.The key proposal for this work is anunsupervised algorithm for MWSD, which uses anunsupervised method, Ppr+Freq, for semanticdisambiguation with resources like BabelNet (assense inventory only) (Navigli and Ponzetto, 2010)and ISR-WN (as knowledge base) (Guti?rrez et al2011a; 2010a).ISR-WN was selected as the default knowledgebase because of previous NLP research, whichincluded: (Fern?ndez et al 2012; Guti?rrez et al2010b; Guti?rrez et al 2012; 2011b; 2011c;2011d), which achieved relevant results using ISR-WN as their knowledge base.2 System architectureBy using one of BabelNet (BN) features, ourtechnique begins by looking for all the Babelsynsets (Bs) linked to the lemma of each word inthe sentence that we need to disambiguate.Through the Bs offsets, we can get itscorresponding WordNet Synset (WNS), whichwould be retrieved from WordNet (WN) using theISR-WN resource.
As a result, for each lemma, wehave a WordNet Synset List (WNSL) from whichour Word Sense Disambiguation method obtainsone WNS as the correct meaning.Our WSD method consists of applying amodification of the Personalizing PageRank (Ppr)algorithm (Agirre and Soroa, 2009), whichinvolves the senses frequency.
More specifically,the key proposal is known as Ppr+Freq (seeSection 2.3).Given a set of WNSLs of WNSL, as wordswindow, we applied the Synsets ranking method,Ppr+Freq, which ranks in a descending order, theSynsets of each lemma according to a calculatedfactor of relevance.
The first Synset (WNS) ofeach WNSL (the most relevant) is established asthe correct one and its associated Babel synset (Bs)is also tagged as correct.
To determine the WikiPage Titles (WK), we examine the WIKI(Wikipedia pages) and WIKIRED (Wikipediapages redirections) in the correct Babel synsetobtained.Figure 1 shows a general description of oursystem that is made up of the following steps:I.
Obtaining lemmasII.
Obtaing WN Synset of selected lemmasIII.
Applying Ppr+Freq methodIV.
Assigning Synset, Babel synset and Wikipage titleNote that ISR-WN contains WN as its nucleus.This allows linking both resources, BabelNet andISR-WN.242Figure 1.
General process description taking as instance a sentence provided by the trial dataset.2.1 Obtaining lemmasFor each input sentence, we extract the labeledlemmas.
As an example, for the sentence, ?Thestruggle against the drug lords in Colombia will bea near thing,?
the selected lemmas are: ?struggle,??drug_lord,?
?Colombia?, and ?near_thing.
?Figure 2.
Obtaining synset of lemmas.2.2 Obtaing WN Synset of selected lemmasFor each lemma obtained in the previous section,we look through BabelNet to recover the Bs thatcontains the lemma among its labels.
When BSsare mapped to WN, we use the ISR-WN resourceto find the corresponding Synset.
Since a lemmacan appear in a different Bs, it can be mapped withseveral WNS.
Thus, we get a Synset list for eachlemma in the sentence.
In case the lemma does nothave an associated Bs, its list would be empty.
Anexample of this step is shown on Figure 2.2.3 Applying Ppr+Freq methodIn the above case, Ppr+Freq modifies the ?classic?Page Rank approach instead of assigning the sameweight for each sense of WN in the disambiguationgraph (??
).The PageRank (Brin and Page, 1998)adaptation, Ppr , which was popularized by (AgirreIV .
Assigning Synset, Babel Synset and Wiki page title?
The struggle against the drug lords in Colombia will be a near thing .
?struggle drug_lord Colombia near_thingWikipedia WordNet BabelNetISR-WNWordNet(WN)SUMOWN-DomainWN-AffectSemanticClass eXtended WN3.0eXtended WN1.7struggle%1:04:01:: drug_lord%1:18:00:: colombia%1:15:00:: near_thing%1:04:00::bn:00009079n bn:00028876n bn:00020697n bn:00057109n-- Drug_Lord Colombia --I. Obtaing lemmasII.
Obtaining Synset of selected lemmasIII.
Applying Ppr+Freq methodWN keyBSWKstruggledrug_lord Colombianear_thingstrugglebn:00074762n wn:00587514nbn:00009079n wn:00739796nbn:00009080n wn:00901980ndrug_lord bn:00028876n wn:09394468ncolombiabn:00020697n wn:08196765nbn:02051949nbn:02530766nnear_thing bn:00057109n wn:00193543nSentence lemmasBabel synsetWordNet synset243and Soroa, 2009) in Word Sense Disambiguationthematic, and which has obtained relevant results,was an inspiration to us in our work.
The main ideabehind this algorithm is that, for each edgebetween ?i and ?j in graph ?, a vote is made from?i to ?j.
As a result, the relevance of ?j isincreased.On top of that, the vote strength from ?
to ?depends on ????
relevance.
The philosophy behindit is that, the more important the vertex is, the morestrength the voter would have.
Thus, PageRank isgenerated by applying a random walkthrough fromthe internal interconnection of ?, where the finalrelevance of ??
represents the random walkthroughprobability over ?, and ending on ?
?.Ppr+Freq includes the existent semantic andfrequency patterns of each sense of the word todisambiguate while finding a way to connect eachone of these words in a knowledge base.The new graph-based approach of WSDgenerates a graph of disambiguated words for eachinput sentence.
For that reason, it is necessary toclassify the word senses according to the otherwords that compose the context.
The generalmethod is shown in Figure 3.
This method isdivided into three steps:I.
Creation of a disambiguation graphII.
Application of Ppr+Freq in the generatedgraphIII.
Selection of the correct answerCreation of a disambiguation graph: In the firststep, a disambiguation graph is built by means of aBreath First Search (BFS) over the ?super?
graphcomposed by all the resources integrated into ISR-WN.
The components involved in this process are:WordNet, SUMO (Zouaq et al 2009) WordNetDomains (Magnini and Cavaglia, 2000) WordNetAffects (Strapparava and Valitutti, 2004) SemanticClasses (Izquierdo et al 2007) and eXtendedWordNet (XWN) relations (Moldovan and Rus,2001).
This search aims to recover all senses(nodes), domain labels (from WordNet Domainand WordNet Affects), SUMO categories, andSemantic Classes labels through the shortest pathbetween every pair of senses in the WNSL setassociated with the input sentence.
Using ISR-WNas the KB, through experimentation, we obtainedthe shortest paths with a length of five edges.
For abetter understanding of this process, see (Guti?rrez,2012).Application of Ppr+Freq in the generatedgraph: In the second step, we use the weightedPersonalized PageRank.
Here, all the vertices fromvector ?
in ??
are initialized with the value1?
;where ?
is the number of nodes in ??.
On theother hand, the vertices that represent word sensesin the analyzed sentence are not initialized withthis value.
Instead, they are initialized with valuesin the range [0?1], which are associated to theiroccurrence frequency in SemCor1 (Corpus andsense frequencies knowledge).
In the last step,after applying the Ppr+Freq algorithm over ?
?, weget a representative vector which contains ISR-WNnodes in ??
sorted in a descending order by aranking score computed by this algorithm.
For abetter description, see (Guti?rrez, 2012).Selection of the correct answer: As the correctsense, we take the highest ranked sense of eachtarget word involved in this vector.
Note thatdomain labels, SUMO categories, semantic classlabels, and affect labels are ranked too.
They couldbe used in the future to determine relevantconceptualizations that would be useful for textclassification and more.In our system, we assume the followingconfiguration: dumping factor ?
= 0.85 and like in(Agirre and Soroa, 2009) we used 30 iterations.
Adetailed explanation about PageRank algorithmcan be found in (Agirre and Soroa, 2009).Table 2 shows an example that analyzes theSynset for each word in the sentence and alsoshows how the higher ranked Synsets of the targetwords are selected as the correct ones.
For adetailed explanation of Ppr+Freq, see (Guti?rrez,2012).2.4 Assigning Synset, Babel synset and WikiPagesIn this step, English is handled differently fromother languages because WordNet Synsets areavailable only for English.
The following sectionsexplain how we proceed in each case.
Once theSynsets list is obtained for each lemma in section2.3, selecting the correct answer for the lemma isall that?s left to do.1 http://www.cse.unt.edu/~rada/downloads.html244Figure 3.
General process of WSD with Ppr+Freq.2.4.1 EnglishGiven a lemma, we go through its Synset list frombeginning to end looking for the first Synset thatcontains a key2 for the lemma.
If such Synsetexists, it is designated as the Synset for the lemma.Otherwise, no Synset is assigned.As already explained, each Synset in the list isconnected to a Bs.
Therefore, the lemma linkedwith the correct WNS selected in the previous step,is chosen as the correct lemma.
In case no Synsetswere designated as the correct ones, we take thefirst Bs in BN, which contains the lemma amongits labels.To determine the Wiki pages titles (WK) weexamine the WIKIRED and WIKI labels in thecorrect Bs selected in the preceding step.
Thissearch is restricted only to labels corresponding tothe analyzed language and discriminating upperand lower case letters.
Table 2 shows some sampleresults of the WSD process.Lemma struggle drug_lordWNS 00739796n 09394468nWN key struggle%1:04:01:: drug_lord%1:18:00::Bs bn:00009079n bn:00028876nWK - Drug_LordLemma colombia near_thingWNS 08196765n 00193543nWN key colombia%1:15:00:: near_thing%1:04:00::Bs bn:00020697n bn:00057109nWK Colombia -Table 2 : Example of English Language.2A sense_key is the best way to represent a sense insemantic tagging or other systems that refer to WordNetsenses.
sense_key?s are independent of WordNet sensenumbers and synset_offset?s, which vary between versions ofthe database.2.4.2 Other languagesFor this scenario, we introduce a change in the firststep discussed in the previous section.
The reasonis that the Synsets do not contain any keys in anyother language than English.
Thus, the correctSynset for the lemma is the first in the Synset listfor the lemma obtained, as described, in section2.3.3 ResultsWe tested three versions (runs) of the proposedapproach and evaluated them through a trialdataset provided by Task123 of Semeval-2013using babelnet-1.0.1.
Table 3 shows the result foreach run.
Note that the table results werecalculated with the traditional WSD recallmeasure, being this measure which has rankedWSD systems on mostly Semeval competitions.On the other hand, note that our precision andrecall results are different because the coverage isnot 100%.
See Table 5.English FrenchRuns WNS Bs WK Bs WKRun1 0.70 0.71 0.77 0.59 0.85Run2 0.70 0.71 0.78 0.60 0.85Run3 0.69 0.70 0.77 - -Table 3 : Results of runs with trial recall values.As can be noticed on Table 3, results of differentversions do not have big differences, but ingeneral, Run2 achieves the best results; it?s better3 http://www.cs.york.ac.uk/semeval-2013/task12ISR-WNfootballer#1 | cried#9 | winning#3footballer | cry | winningLemmas?The footballer cried when winning?DisambiguationGraph(0,9)Footballer#1(0,3)cry#7(0,4)cry#9(0,2)cry#10(0,2)cry#11(0,2)cry#12(0,2)winning#1(0,3)winning#3Creating GDPpr+FreqSelecting senses245than Run1 in the WK with a 78% in English andBs with 60% in French.
The best results are in theWK in French with a value of 85%.Since we can choose to include differentresources into ISR-WN, it is important to analyzehow doing so would affect the results.
Table 4shows comparative results for Run 2 of a trialdataset with BabelNet version 1.1.1.As can be observed in Table 4, the result does nothave a significant change even though we used theISR-WN with all resources.A better analysis of Ppr+Freq in, as it relates tothe influence of each resource involved in ISR-WN(similar to Table 4 description) assessingSensEval-2 and SensEval-3 dataset, is shown in(Guti?rrez, 2012).
There are different resourcecombinations showing that only XWN1.7 and allISR-WN resources obtain the highest performance.Other analysis found in (Guti?rrez, 2012) evaluatesthe influence of adding the sense frequency forPpr+Freq.By excluding the Factotum Domain, we obtainthe best result in Bs 54% for French (only 1%more than the version used in the competition).The other results are equal, with a 69% in WNS,66% in Bs, 64% in WK for English, and 69% inWK for French.English FrenchWN Domains Sumo Affect FactotumDomainSemanticClass XWN3.0 XWN1.7 WNS Bs WK Bs WKX X X X X X X X 0.69 0.66 0.64 0.53 0.69X X  X X X X X 0.69 0.66 0.64 0.53 0.69X    X X X X 0.68 0.65 0.64 0.52 0.69X X X X  X X X 0.69 0.66 0.64 0.54 0.69X X X X  X  X 0.68 0.65 0.65 0.53 0.69Table 4.
Influence of different resources that integrate ISR-WN in our technique.Wikipedia BabelNet WordNetSystem Language Precision Recall F-score Precision Recall F-score Precision Recall F-scoreMFS DE 0.836 0.827 0.831 0.676 0.673 0.686 - - -EN 0.86 0.753 0.803 0.665 0.665 0.656 0.63 0.63 0.63ES 0.83 0.819 0.824 0.645 0.645 0.644 - - -FR 0.698 0.691 0.694 0.455 0.452 0.501 - - -IT 0.833 0.813 0.823 0.576 0.574 0.572 - - -Run1 DE 0.758 0.46 0.572 0.619 0.617 0.618 - - -EN 0.619 0.484 0.543 0.677 0.677 0.677 0.639 0.635 0.637ES 0.773 0.493 0.602 0.708 0.703 0.705 - - -FR 0.817 0.48 0.605 0.608 0.603 0.605 - - -IT 0.785 0.458 0.578 0.659 0.656 0.657 - - -Run2 DE 0.769 0.467 0.581 0.622 0.62 0.621 - - -EN 0.62 0.487 0.546 0.685 0.685 0.685 0.649 0.645 0.647ES 0.778 0.502 0.61 0.713 0.708 0.71 - - -FR 0.815 0.478 0.603 0.608 0.603 0.605 - - -IT 0.787 0.463 0.583 0.659 0.657 0.658 - - -Run3 EN 0.622 0.489 0.548 0.68 0.68 0.68 0.642 0.639 0.64Table 5.
Results of Runs for Task12 of semeval-2013 using the test dataset.2463.1 Run1In this Run, WNSLs consist of all the target wordsinvolved in each sentence.
This run is applied atthe sentence level.
The results for the competitionare shown in Table 5.
For this Run, the best resultwas obtained for Spanish with a 70.3% in Bs and49.3% in WK of Recall.
As we can see, for Run1the precision is high for Wikipedia disambiguation,obtaining for French the best result of the ranking.
Thelow Recall in Wikipedia is due to the exact mismatchingof labels between our system output and the goldstandard.
This fact, affects the rest of our runs.3.2 Run2In this Run, WNSLs consist of all the target wordsinvolved in each domain.
We can obtain the targetwords because the training and test dataset containthe sentences grouped by topics.
For instance, forEnglish, 13 WNSLs are established.
This Run isapplied at the corpora level.
The results for thecompetition are shown in Table 5.
It is important toemphasize that our best results ranked ouralgorithm as first place among all proposedapproaches for the MWSD task.For this run, the best Recall was obtained forSpanish with a 70.8% in Bs and 50.2% in WK.This Run also has the best result of the three runs.For the English competition, it ended up with a64.5% in WNS, 68.5% in Bs, and 48.7% in WK.This Run obtained promising results, which tookfirst place in the competition.
It also had betterresults than that of the First Sense (Most FrequentSense) baseline in Bs results for all languages,except for German.
In Bs, it only obtained lowerresults in German with a 62% of Recall for oursystem and 67.3% for the First Sense baseline.3.3 Run3In this run, WNSLs consist of all the wordsincluded in each sentence.
This run uses targetwords and non-target words of each sentence, asthey are applied to the sentence level.
The resultsfor the competition are shown in Table 5.As we can see, the behavior of this run is similarto the previous runs.4 Conclusions and Future workThe above results suggest that our proposal is apromising approach.
It is also important to noticethat a richer knowledgebase can be built bycombining different resources such as BabelNetand ISR-WN, which can lead to an improvementof the results.
Notwithstanding, our system hasbeen recognized as the best in the competition,obtaining results around 70% of Recall.According to the Task12 results4, only thebaseline Most Frequent Sense (MFS) couldimprove our scores in order to achieve better WKand German (DE) disambiguation.
Therefore, weplan to review this point to figure out why weobtained better results in other categories, but notfor this one.
At the same time, further work willuse the internal Babel network to run the Ppr+Freqmethod in an attempt to find a way to enrich thesemantic network obtained for each target sentenceto disambiguate.
On top of that, we plan tocompare Ppr (Agirre and Soroa, 2009) withPpr+Freq using the Task12 dataset.Availability of our ResourceIn case researchers would like to use our resource,it is available at the GPLSI5 home page or bycontacting us via email.AcknowledgmentsThis research work has been partially funded bythe Spanish Government through the projectTEXT-MESS 2.0 (TIN2009-13391-C04), "An?lisisde Tendencias Mediante T?cnicas de Opini?nSem?ntica" (TIN2012-38536-C03-03) and?T?cnicas de Deconstrucci?n en la Tecnolog?as delLenguaje Humano?
(TIN2012-31224); and by theValencian Government through the projectPROMETEO (PROMETEO/2009/199).ReferencesAgirre, E. and A. Soroa.
Personalizing PageRank forWord Sense Disambiguation.
Proceedings of the 12thconference of the European chapter of theAssociation for Computational Linguistics (EACL-2009), Athens, Greece, 2009.4 http://www.cs.york.ac.uk/semeval-2013/task12/index.php?id=results5 http://gplsi.dlsi.ua.es/247Fern?ndez, A.; Y. Guti?rrez; H. D?vila; A. Ch?vez; A.Gonz?lez; R. Estrada; Y. Casta?eda; S. V?zquez; A.Montoyo and R. Mu?oz.
UMCC_DLSI:Multidimensional Lexical-Semantic TextualSimilarity.
{*SEM 2012}: The First Joint Conferenceon Lexical and Computational Semantics -- Volume1: Proceedings of the main conference and the sharedtask, and Volume 2: Proceedings of the SixthInternational Workshop on Semantic Evaluation{(SemEval 2012)}, Montreal, Canada, Associationfor Computational Linguistics, 2012.
608--616 p.Guti?rrez, Y.
An?lisis Sem?ntico Multidimensionalaplicado a la Desambiguaci?n del Lenguaje Natural.Departamento de Lenguajes y Sistemas Inform?ticos.Alicante, Alicante, 2012.
189. p.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez.
Integration of semantic resources based onWordNet.
XXVI Congreso de la Sociedad Espa?olapara el Procesamiento del Lenguaje Natural,Universidad Polit?cnica de Valencia, Valencia,SEPLN 2010, 2010a.
161-168 p. 1135-5948.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez.
UMCC-DLSI: Integrative resource fordisambiguation task.
Proceedings of the 5thInternational Workshop on Semantic Evaluation,Uppsala, Sweden, Association for ComputationalLinguistics, 2010b.
427-432 p.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez Enriching the Integration of SemanticResources based on WordNet Procesamiento delLenguaje Natural, 2011a, 47: 249-257.Guti?rrez, Y.; S. V?zquez and A. Montoyo.
ImprovingWSD using ISR-WN with Relevant Semantic Treesand SemCor Senses Frequency.
Proceedings of theInternational Conference Recent Advances in NaturalLanguage Processing 2011, Hissar, Bulgaria, RANLP2011 Organising Committee, 2011b.
233--239 p.Guti?rrez, Y.; S. V?zquez and A. Montoyo.
SentimentClassification Using Semantic Features Extractedfrom WordNet-based Resources.
Proceedings of the2nd Workshop on Computational Approaches toSubjectivity and Sentiment Analysis (WASSA2.011), Portland, Oregon., Association forComputational Linguistics, 2011c.
139--145 p.Guti?rrez, Y.; S. V?zquez and A. Montoyo.
Word SenseDisambiguation: A Graph-Based Approach Using N-Cliques Partitioning Technique.
en:  NaturalLanguage Processing and Information Systems.MU?OZ, R.;MONTOYO, A.et alSpringer Berlin /Heidelberg, 2011d.
6716: 112-124.p.Guti?rrez, Y.; S. V?zquez and A. Montoyo.
A graph-Based Approach to WSD Using Relevant SemanticTrees and N-Cliques Model.
CICLing 2012, NewDelhi, India, 2012.
225-237 p.Izquierdo, R.; A. Su?rez and G. Rigau A Proposal ofAutomatic Selection of Coarse-grained SemanticClasses for WSD Procesamiento del LenguajeNatural, 2007, 39: 189-196.Laparra, E.; G. Rigau and M. Cuadros.
Exploring theintegration of WordNet and FrameNet.
Proceedingsof the 5th Global WordNet Conference (GWC'10),Mumbai, India, 2010.Magnini, B. and G. Cavaglia.
Integrating Subject FieldCodes into WordNet.
Proceedings of ThirdInternational Conference on Language Resources andEvaluation (LREC-2000), 2000.
1413--1418 p.Mihalcea, R. Unsupervised large-vocabulary word sensedisambiguation with graph-based algorithms forsequence data labeling.
Proceedings of HLT05,Morristown, NJ, USA., 2005.Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross andK.
Miller.
Five papers on WordNet.
PrincentonUniversity, Cognositive Science Laboratory, 1990.Moldovan, D. I. and V. Rus Explaining Answers withExtended WordNet ACL, 2001.Navigli, R.; D. Jurgens and D. Vannella.
SemEval-2013Task 12: Multilingual Word Sense Disambiguation.
.Proceedings of the 7th International Workshop onSemantic Evaluation (SemEval 2013), in conjunctionwith the Second Joint Conference on Lexical andComputational Semantics (*SEM 2013), Atlanta,Georgia, 2013.Navigli, R. and S. P. Ponzetto.
BabelNet: Building aVery Large Multilingual Semantic Network.Proceedings of the 48th Annual Meeting of theAssociation for Computational Linguistics, Uppsala,Sweden, Association for Computational Linguistics,2010.
216--225 p.Navigli, R. and S. P. Ponzetto BabelNet: The automaticconstruction, evaluation and application of a wide-coverage multilingual semantic network Artif.
Intell.,2012, 193: 217-250.Navigli, R. and P. Velardi Structural SemanticInterconnections: A Knowledge-Based Approach toWord Sense Disambiguation IEEE Transactions onPattern Analysis and Machine Intelligence, 2005,27(7): 1075-1086.Sinha, R. and R. Mihalcea.
Unsupervised Graph-basedWord Sense Disambiguation Using Measures ofWord Semantic Similarity.
Proceedings of the IEEEInternational Conference on Semantic Computing(ICSC 2007), Irvine, CA, 2007.248Strapparava, C. and A. Valitutti.
WordNet-Affect: anaffective extension of WordNet.
Proceedings of the4th International Conference on Language Resourcesand Evaluation (LREC 2004), Lisbon, 2004.
1083-1086 p.Tsatsaronis, G.; M. Vazirgiannis and I.Androutsopoulos.
Word sense disambiguation withspreading activation networks generated fromthesauri.
IJCAI, 2007.Vossen, P. EuroWordNet: A Multilingual Database withLexical Semantic Networks.
Dordrecht, KluwerAcademic Publishers, 1998.Zouaq, A.; M. Gagnon and B. Ozell.
A SUMO-basedSemantic Analysis for Knowledge Extraction.Proceedings of the 4th Language & TechnologyConference, Pozna?, Poland, 2009.249
