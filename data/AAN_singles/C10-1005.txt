Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 37?45,Beijing, August 2010Plagiarism Detection across Distant Language PairsAlberto Barro?n-Ceden?o Paolo RossoNatural Language Engineering Lab.
- ELiRFUniversidad Polite?cnica de Valencia{lbarron, prosso}@dsic.upv.esEneko Agirre Gorka LabakaIXA NLP GroupBasque Country University{e.agirre, gorka.labaka}@ehu.esAbstractPlagiarism, the unacknowledged reuse oftext, does not end at language boundaries.Cross-language plagiarism occurs if a textis translated from a fragment written in adifferent language and no proper citationis provided.
Regardless of the change oflanguage, the contents and, in particular,the ideas remain the same.
Whereas dif-ferent methods for the detection of mono-lingual plagiarism have been developed,less attention has been paid to the cross-language case.In this paper we compare two recentlyproposed cross-language plagiarism de-tection methods (CL-CNG, based on char-acter n-grams and CL-ASA, based on sta-tistical translation), to a novel approachto this problem, based on machine trans-lation and monolingual similarity analy-sis (T+MA).
We explore the effectivenessof the three approaches for less relatedlanguages.
CL-CNG shows not be ap-propriate for this kind of language pairs,whereas T+MA performs better than thepreviously proposed models.1 IntroductionPlagiarism is a problem in many scientific and cul-tural fields.
Text plagiarism may imply differ-ent operations: from a simple cut-and-paste, tothe insertion, deletion and substitution of words,up to an entire process of paraphrasing.
Differ-ent models approach the detection of monolin-gual plagiarism (Shivakumar and Garc?
?a-Molina,1995; Hoad and Zobel, 2003; Maurer et al, 2006).Each of these models is appropriate only in thosecases where all the implied documents are writtenin the same language.Nevertheless, the problem does not end at lan-guage boundaries.
Plagiarism is also committed ifthe reused text is translated from a fragment writ-ten in a different language and no citation is pro-vided.
When plagiarism is generated by a transla-tion process, it is known as cross-language plagia-rism (CLP).Less attention has been paid to the detection ofthis kind of plagiarism due to its enhanced diffi-culty (Ceska et al, 2008; Barro?n-Ceden?o et al,2008; Potthast et al, 2010).
In fact, in the recentlyheld 1st International Competition on PlagiarismDetection (Potthast et al, 2009), no participantstried to approach it.In order to describe the prototypical process ofautomatic plagiarism detection, we establish thefollowing notation.
Let dq be a plagiarism suspectdocument.
Let D be a representative collectionof reference documents.
D presumably includesthe source of the potentially plagiarised fragmentsin dq .
Stein et al, (2007) divide the process intothree stages1:1. heuristic retrieval of potential source doc-uments: given dq, retrieving an appropri-ate number of its potential source documentsD?
?
D such that |D?|?
|D|;2. exhaustive comparison of texts: comparingthe text from dq and d ?
D?
in order toidentify reused fragments and their potential1This schema was formerly proposed for monolingualplagiarism detection.
Nevertheless, it can be applied with-out further modifications to the cross-language case.37sources; and3.
knowledge-based post-processing: those de-tected fragments with proper citation are dis-carded as they are not plagiarised.The result is offered to the human expert to takethe final decision.
In the case of cross-languageplagiarism detection (CLPD), the texts are writtenin different languages: dq ?
L and d?
?
L?.In this research we focus on step 2: cross-language exhaustive comparison of texts, ap-proaching it as an Information Retrieval problemof cross-language text similarity.
Step 1, heuristicretrieval, may be approached by different CLIRtechniques, such as those proposed by Dumais etal.
(1997) and Pouliquen et al (2003).Cross-language similarity between texts,?
(dq, d?
), has been previously estimated onthe basis of different models: multilingualthesauri (Steinberger et al, 2002; Ceska etal., 2008), comparable corpora ?CL-ExplicitSemantic Analysis CL-ESA?
(Potthast etal., 2008), machine translation techniques?CL-Alignment-based Similarity Analysis CL-ASA?
(Barro?n-Ceden?o et al, 2008; Pinto et al,2009) and n-grams comparison ?CL-Charactern-Grams CL-CNG?
(Mcnamee and Mayfield,2004).A comparison of CL-ASA, CL-ESA, and CL-CNG was carried out recently by Potthast etal.
(2010).
The authors report that in general,despite its simplicity, CL-CNG outperformed theother two models.
Additionally, CL-ESA showedgood results in the cross-language retrieval oftopic-related texts, whereas CL-ASA obtainedbetter results in exact (human) translations.However, most of the language pairs used in thereported experiments (English-{German, Span-ish, French, Dutch, Polish}) are related, whetherbecause they have common predecessors or be-cause a large proportion of their vocabulariesshare common roots.
In fact, the lower syntacticalrelation between the English-Polish pair causeda performance degradation for CL-CNG, and forCL-ASA to a lesser extent.
In order to confirmwhether the closeness among languages is an im-portant factor, this paper works with more dis-tant language pairs: English-Basque and Spanish-Basque.The rest of the paper is structured as follows.Section 2 describes the motivation for workingon this research topic, stressing the situation ofcross-language plagiarism among writers in lessresourced languages.
A brief overview of the fewworks on CLPD is included.
The three similar-ity estimation models compared in this researchwork are presented in Section 3.
The experimentalframework and the obtained results are includedin Section 4.
Finally, Section 5 draws conclusionsand discusses further work.2 MotivationCases of CLP are common nowadays because in-formation in multiple languages is available on theWeb, but people still write in their own language.This special kind of plagiarism occurs more oftenwhen the target language is a less resourced one2,as is the case of Basque.Basque is a pre-indoeuropean language withless than a million speakers in the world andno known relatives in the language families(Wikipedia, 2010a).
Still, Basque shares a portionof its vocabulary with its contact languages (Span-ish and French).
Therefore, we decided to workwith two language pairs: Basque with Spanish,its contact language, and with English, perhapsthe language with major influence over the rest oflanguages in the world.
Although the consideredpairs share most of their alphabet, the vocabularyand language typologies are very different.
Forinstance Basque is an agglutinative language.In order to illustrate the relations among theselanguages, Fig.
1 includes extracts from the En-glish (en), Spanish (es) and Basque (eu) versionsof the same Wikipedia article.
The fragments area sample of the lexical and syntactic distance be-tween Basque and the other two languages.
Infact, these sentences are completely co-derivedand the corresponding entire articles are a sampleof the typical imbalance in text available in the dif-ferent languages (around 2, 000, 1, 300, and only2Less resourced language is that with a low degree of rep-resentation on the Web (Alegria et al, 2009).
Whereas theavailable text for German, French or Spanish is less than forEnglish, the difference is more dramatic with other languagessuch as Basque.38The Party of European Socialists (PES) isa European political party comprising thirty-twosocialist, social democratic and labour partiesfrom each European Union member state andNorway.El Partido Socialista Europeo (PSE) es unpartido pol?
?tico pan-europeo cuyos miembrosson de partidos socialdemo?cratas, socialistas ylaboristas de estados miembros de la Unio?n Eu-ropea, as??
como de Noruega.Europako Alderdi Sozialista Europar Bata-suneko herrialdeetako eta Norvegiako hogeitahamahiru alderdi sozialista, sozialdemokrata etalaborista biltzen dituen alderdia da.Figure 1: First sentences from the Wikipedia arti-cles ?Party of European Socialists?
(en),?PartidoSocialista Europeo?
(es), and ?Europako AlderdiSozialista?
(eu) (Wikipedia, 2010b).100 words are contained in the en, es and eu arti-cles, respectively).Of high relevance is that the two corpora usedin this work were manually constructed by trans-lating English and Spanish text into Basque.
In theexperiments carried out by Potthast et al (2010),which inspired our work, texts from the JCR-Acquis corpus (Steinberger et al, 2006) andWikipedia were used.
The first one is a multilin-gual corpus with no clear definition of source andtarget languages, whereas in Wikipedia no spe-cific relationship exists between the different lan-guages in which a topic may be broached.
In somecases (cf.
Fig.
1) they are clearly co-derived, butin others they are completely independent.CLPD has been investigated just recently,mainly by adapting models formerly proposedfor cross-language information retrieval.
Thisis the case of cross-language explicit seman-tic analysis (CL-ESA), proposed by Potthast etal.
(2008).
In this case the comparison be-tween texts is not carried out directly.
Instead,a comparable corpus CL,L?
is required, contain-ing documents on multiple topics in the two im-plied languages.
One of the biggest corporaof this nature is Wikipedia.
The similarity be-tween dq ?
L and every document c ?
CLis computed based on the cosine measure.
Thesame process is made for L?.
This step gener-ates two vectors [cos(dq, c1), .
.
.
, cos(dq, c|CL|)]and [cos(d?, c?1), .
.
.
, cos(d?, c?|CL?
|)], where eachdimension is comparable between the two vectors.Therefore, the cosine between such vectors can beestimated in order to ?indirectly?
estimate howsimilar dq and d?
are.
The authors suggest that thismodel can be used for CLPD.Another recent model is MLPlag, proposed byCeska et al (2008).
It exploits the EuroWord-Net Thesaurus3, that includes sets of synonyms inmultiple European languages, with common iden-tifiers across languages.
The authors report ex-periments over a subset of documents of the En-glish and Czech sections of the JRC-Acquis cor-pus as well as a corpus of simplified vocabulary4 .The main difficulty they faced was the amount ofwords in the documents not included in the the-saurus (approximately 50% of the vocabulary).This is a very similar approach to that pro-posed by Pouliquen et al (2003) for the identi-fication of document translations.
In fact, bothapproaches have something in common: transla-tions are searched at document level.
It is assumedthat an entire document has been reused (trans-lated).
Nevertheless, a writer is free to plagiarisetext fragments from different sources, and com-pose a mixture of original and reused text.A third model is the cross-language alignment-based similarity analysis (CL-ASA), proposed byBarro?n-Ceden?o et al (2008), which is based onstatistical machine translation technology.
Thismodel was proposed to detect plagiarised textfragments (similar models have been proposed forextraction of parallel sentences from comparablecorpora (Munteanu et al, 2004)).
The authorsreport experiments over a short set of texts fromwhich simulated plagiarism was created from En-glish to Spanish.
Human as well as automatic ma-chine translations were included in the collection.Further descriptions of this model are included inSection 3, as it is one of those being assessed inthis research work.To the best of our knowledge, no work (in-cluding the three previously mentioned) has beendone considering less resourced languages.
In thisresearch work we approach the not uncommonproblem of CLPD in Basque, with source textswritten in Spanish (the co-official language of the3http://www.illc.uva.nl/EuroWordNet/4The authors do not mention the origin of the documents.39low tok pd bd sd lemT+MA   CL-ASA   CL-CNG    Table 1: Text preprocessing operations re-quired for the different models.
low=lowercasing,tok=tokenization, pd=punctuation marks deletion, bd=blankspace deletion, sd=symbols deletion, lem=lematization.Basque Country) and English (the language withmost available texts in the world).We compare three cross-language similarityanalysis methods: T+MA (translation followedby monolingual analysis), a novel method basedon machine translation followed by a monolin-gual similarity estimation; CL-CNG, a charactern-gram based comparison model; and CL-ASAa model that combines translation and similarityestimation in a single step.
Neither MLPlag norCL-ESA are included in the comparison.
On theone hand, we are interested in plagiarism at sen-tence level, and MLPlag is designed to compareentire documents.
On the other hand, in previousexperiments over exact translations, CL-ASA hasshown to outperform it on language pairs whosealphabet or syntax are unrelated (Potthast et al,2010).
This is precisely the case of en-eu andes-eu language pairs.
Additionally, the amountof Wikipedia articles in Basque available for theconstruction of the required comparable corpus isinsufficient for the CL-ESA data requirements.3 Definition of ModelsIn this section, we describe the three cross-language similarity models we compare.
For ex-perimental purposes (cf.
Section 4) we considerdq to be a suspicious sentence written in L andD?
to be a collection of potential source sentenceswritten in L?
(L 6= L?).
The text pre-processingrequired by the different models is summarisedin Table 1.
Examples illustrating how the modelswork are included in Section 4.3.3.1 Translation + Monolingual Analysisdq ?
L is translated into L?
on the basis ofthe Giza++ (Och and Ney, 2003), Moses (Koehnet al, 2007) and SRILM (Stolcke, 2002) tools,generating d?q .
The translation system uses alog-linear combination of state-of-the-art features,such as translation probabilities and lexical trans-lation models on both directions and a target lan-guage model.
After translation, d?q and d?
arelexically related, making possible a monolingualcomparison.Multiple translations from dq into d?q are pos-sible.
Therefore, performing a monolingual sim-ilarity analysis based on ?traditional?
techniques,such as those based on word n-grams compari-son (Broder, 1997) or hash collisions (Schleimeret al, 2003), is not an option.
Instead, we take theapproach of the bag-of-words, which has showngood results in the estimation of monolingual textsimilarity (Barro?n-Ceden?o et al, 2009).
Words ind?q and d?
are weighted by the standard tf -idf , andthe similarity between them is estimated by thecosine similarity measure.3.2 CL-Alignment-based Similarity AnalysisIn this model an estimation of how likely is that d?is a translation of dq is performed.
It is based onthe adaptation of the Bayes rule for MT:p(d?
| dq) = p(d?)
p(dq | d?)p(dq).
(1)As p(dq) does not depend on d?, it is neglected.From an MT point of view, the conditional prob-ability p(dq | d?)
is known as translation modelprobability and is computed on the basis of a sta-tistical bilingual dictionary.
p(d?)
is known as lan-guage model probability; it describes the targetlanguage L?
in order to obtain grammatically ac-ceptable translations (Brown et al, 1993).Translating dq into L?
is not the concern ofthis method, rather it focuses on retrieving textswritten in L?
which are potential translations ofdq .
Therefore, Barro?n-Ceden?o et al (2008) pro-posed replacing the language model (the one usedin T+MA) by that known as length model.
Thismodel depends on text?s character lengths insteadof language structures.Multiple translations from d into L?
are possi-ble, and it is uncommon to find a pair of translatedtexts d and d?
such that |d| = |d?|.
Nevertheless,the length of such translations is closely relatedto a translation length factor.
In accordance withPouliquen et al (2003), the length model is de-fined as:40?(d?)
= e?0.50B@|d?||dq| ??
?1CA2, (2)where ?
and ?
are the mean and the standard devi-ation of the character lengths between translationsof texts from L into L?.
If the length of d?
is not theexpected given dq, it receives a low qualification.The translation model probability is defined as:p(d | d?)
=Yx?dXy?d?p(x, y), (3)where p(x, y), a statistical bilingual dictionary,represents the likelihood that x is a valid transla-tion of y.
After estimating p(x, y) from a parallelcorpus, on the basis of the IBM statistical trans-lation models (Brown et al, 1993), we consider,for each word x, only the k best translations y(those with the highest probabilities) up to a min-imum probability mass of 0.4.
This threshold wasempirically selected as it eliminated noisy entrieswithout discarding an important amount of rele-vant pairs.The similarity estimation based on CL-ASA isfinally computed as:?
(dq, d?)
= ?(d?)
p(dq | d?).
(4)3.3 CL-Character n-Gram AnalysisThis model, the simplest of those compared in thisresearch, has been used in (monolingual) Author-ship Attribution (Keselj et al, 2003) as well ascross-language Information Retrieval (Mcnameeand Mayfield, 2004).
The simplified alphabet con-sidered is ?
= {a, .
.
.
, z, 0, .
.
.
, 9}; any othersymbol is discarded (cf.
Table 1).
The resultingtext strings are codified into character 3-grams,which are weighted by the standard tf -idf (con-sidering this n has previously shown to producethe best results).
The similarity between such rep-resentations of dq and d?
is estimated by the cosinesimilarity measure.4 ExperimentsThe objective of our experiments is to comparethe performance of the three similarity estimationmodels.
Section 4.1 introduces the corpora wehave exploited.
The experimental framework isdescribed in Section 4.2.
Section 4.3 illustrateshow the models work, and the obtained results arepresented and discussed in Section 4.4.4.1 CorporaIn other Information Retrieval tasks a plethora ofcorpora is available for experimental and compar-ison purposes.
However, plagiarism implies anethical infringement and, to the best of our knowl-edge, there is no corpora of actual cases available,other than some seminal efforts on creating cor-pora of text reuse (Clough et al, 2002), artificialplagiarism (Potthast et al, 2009), and simulatedplagiarism (Clough and Stevenson, 2010).
Theproblem is worse for cross-language plagiarism.Therefore, in our experiments we use twoparallel corpora: Software, an en-eu translationmemory of software manuals generously suppliedby Elhuyar Fundazioa5; and Consumer, a cor-pus extracted from a consumer oriented mag-azine that includes articles written in Spanishalong with their Basque, Catalan, and Galiciantranslations6 (Alca?zar, 2006).
Software includes288, 000 parallel sentences; 8.66 (6.83) words persentence in the English (Basque) section.
Con-sumer contains 58, 202 sentences; 19.77 (15.20)words per sentence in Spanish (Basque).
Thesecorpora also reflect the imbalance of text availablein the different languages.4.2 Experimental FrameworkWe consider Dq and D?
to be two entire docu-ments from which plagiarised sentences and theirsource are to be detected.
We work at this levelof granularity, and not entire documents, for twomain reasons: (i) we are focused on the exhaus-tive comparison stage of the plagiarism detectionprocess (cf.
Section 1); and (ii) even a single sen-tence could be considered a case of plagiarism,as it transmits a complete idea.
However, a pla-giarised sentence is usually not enough to auto-matically negate the validity of an entire docu-ment.
This decision is left to the human expert,which can examine the documents where severalplagiarised sentences occur.
Note that the task be-comes computationally more expensive as, for ev-ery sentence, we are looking through thousands5http://www.elhuyar.org6http://revista.consumer.es41es-eu en-eu?
?
?
?f1 1.1567 0.2346 1.0561 0.5497f2 1.1569 0.2349 1.0568 0.5510f3 1.1571 0.2349 1.0566 0.5433f4 1.1565 0.2363 1.0553 0.5352f5 1.1571 0.2348 1.0553 0.5467avg.
1.1569 0.2351 1.0560 0.5452Table 2: Length models estimated for each train-ing partition f1,...,5.
The values describe a normal distri-bution centred in ?
?
?, representing the expected length ofthe source text given the suspicious one.00.20.40.60.810 50 100 150 200 250ProbabilitydistributionLength of the sentenceseuesenFigure 2: Example length factor for a sentencewritten in Basque (eu) dq , such that |dq| = 90.The normal distributions represent the expected lengths forthe translation d?, either in Spanish (es) or English (en).of topically-related sentences that are potentialsources of dq, and not only those of a specific doc-ument.CLPD is considered a ranking problem.
Letdq ?
Dq be a plagiarism suspicious sentence andd?
?
D?
be its source sentence.
We consider thatthe result of the process is correct if, given dq, d?is properly retrieved.
A 5-fold cross validation forboth en-eu and es-eu was performed.
Bilingualdictionaries, language and length models were es-timated with the corresponding training partitions.The computed values for ?
and ?
are those in-cluded in Table 2.
The values for the differentpartitions are very similar, showing the low vari-ability in the translation lengths.
On the basis ofthese estimated parameters, an example of lengthfactor for a specific sentence is plotted in Fig.
2.In the test partitions, for each suspicious sen-tence dq , 11, 640 source candidate sentences existfor es-eu and 57, 290 for en-eu.
This results inmore than 135 million and 3 billion comparisonscarried out for es-eu and en-eu respectively.xeu yen p(x, y) xeu yen p(x, y)beste another 0.288 beste other 0.348dokumentu document 0.681 batzu some 0.422makro macro 0.558 ezin not 0.179ezin cannot 0.279 izan is 0.241izan the 0.162 atzi access 0.591. .
0.981Table 3: Entries in the bilingual dictionary for thewords in dq.
Relevant entries for the example are in bold.4.3 Illustration of ModelsIn order to clarify how the different models work,consider the following sentence pair, a suspicioussentence dq written in Basque and its source d?written in English (sentences are short for illustra-tive purposes):dq beste dokumentu batzuetako makroak ezin dira atzitu.d?
macros from other documents are not accessible.CL-CNG ExampleIn this case, symbols and spaces are discarded.Sentences become:dq bestedokumentubatzuetakomakroakezindiraatzitud?
macrosfromotherdocumentsarenotaccessibleOnly three 3-grams appear in both sentences(ume, men, ent).
In order to keep the example sim-ple, the 3-grams are weighted by tf only (in theactual experiments, tf -idf is used), resulting in adot product of 3.
The corresponding vectors mag-nitudes are |dq| = 6.70 and |d?| = 5.65.
There-fore, the estimated similarity is ?
(dq, d?)
= 0.079.CL-ASA ExampleIn this case, the text must be tokenised and lem-matised, resulting in the following string:dq beste dokumentu batzu makro ezin izan atzi .d?
macro from other document be not accessible .The sentences?
lengths are |dq| = 38 and |d?| =39.
Therefore, on the basis of Eq.
2, the lengthfactor between them is ?
(dq, d?)
= 0.998.The relevant entries of the previously estimateddictionary are included in Table 3.
Such entriesare substituted in Eq.
3, and the overall processresults in a similarity ?
(dq , d?)
= 2.74.
Whereasnot a stochastic value, this is a weight used whenranking all the potential source sentences in D?.T+MA ExampleIn this case, the same pre-processing thanin CL-ASA is performed.
In T+MA dq istranslated into L?, resulting in the new pair:d?q other document macro cannot be access .d?
macro from other document be not accessible .42Note that d?q is a valid translation of dq .
Never-theless, it has few syntactic relation to d?.
There-fore, applying more sophisticated codificationsthan the cosine measure over bag-of-words is notan option.
The example is again simplified byweighting the words based on tf .
Five words ap-pear in both sentences, resulting in a dot productof 5.
The vectors magnitudes are |d?q| = |d?| =?7.
The estimation by T+MA is ?
(dq, d?)
=0.71, a high similarity level.4.4 Results and DiscussionFor evaluation we consider a standard measure:Recall.
More specifically Recall after n texts havebeen retrieved (n = [1 .
.
.
, 50]).
Figure 3 plots theaverage Recall value obtained in the 5-folds withrespect to the rank position (n).In both language pairs, CL-CNG obtainedworse results than those reported for English-Polish by Potthast et al (2010): R@50 = 0.68vs.
R@50 = 0.53 for es-eu and 0.28 for en-eu.This is due to the fact that neither the vocabularynor its corresponding roots keep important rela-tions.
Therefore, when language pairs have a lowsyntactical relationship, CL-CNG is not an op-tion.
Still, CL-CNG performs better with es-euthan with en-eu because the first pair is composedof contact languages (cf.
Section 1).About CL-ASA, the results obtained with es-eu and en-eu are quite different: R@50 = 0.68for en-eu and R@50 = 0.53 for es-eu.
Whereasin the first case they are comparable to those ofCL-CNG, in the second one CL-ASA completelyoutperforms it.
The improvement of CL-ASA ob-tained for en-eu is due to the size of the trainingcorpus available in this case (approximately fivetimes the number of sentences available for es-eu).
This shows the sensitivity of the model withrespect to the size of the available resources.Lastly, although T+MA is a simple approachthat reduces the cross-language similarity estima-tion to a translation followed by a monolingualprocess, it obtained a good performance (R@50=0.77 for en-eu and R@50=0.89 for es-eu).
More-over, this method proved to be less sensitive thanCL-ASA to the lack of resources.
This couldbe due to the fact that it considers both direc-tions of the translation model (e[n|s]-eu and eu-00.20.40.60.811 2 3 4 5 10 20 50RecallrankCL-ASACL-CNGT+MA(a) es-eu00.20.40.60.811 2 3 4 5 10 20 50Recallrank(b) en-euFigure 3: Evaluation of the cross-language rank-ing.
Results plotted as rank versus Recall for the three eval-uated models and the two language pairs (R@[1, .
.
.
, 50]).e[n|s]).
Additionally, the language model, appliedin order to compose syntactically correct transla-tions, reduces the amount of wrong translationsand, indirectly, includes more syntactic informa-tion in the process.
On the contrary, CL-ASAonly considers one direction translation model eu-e[n|s] and completely disregards syntactical rela-tions between the texts.Note that the better results come at the costof higher computational demand.
CL-CNG onlyrequires easy to compute string comparisons.CL-ASA requires translation probabilities fromaligned corpora, but once the probabilities are es-timated, cross-language similarity can be com-puted very fast.
T+MA requires the previoustranslation of all the texts, which can be verycostly for large collections.5 Conclusions and Further WorkIn a society where information in multiple lan-guages is available on the Web, cross-language43plagiarism is occurring every day with increasingfrequency.
Still, cross-language plagiarism de-tection has not been approached sufficiently dueto its intrinsic complexity.
Though few attemptshave been made, even less work has been made totackle this problem for less resourced languages,and to explore distant language pairs.We investigated the case of Basque, a lan-guage where, due to the lack of resources, cross-language plagiarism is often committed from textsin Spanish and English.
Basque has no known rel-atives in the language family.
However, it sharessome of its vocabulary with Spanish.Two state-of-the-art methods based on trans-lation probabilities and n-gram overlapping, anda novel technique based on statistical machinetranslation were evaluated.
The novel techniqueobtains the best results in both language pairs,with the n-gram overlap technique performingworst.
In this sense, our results complement thoseof Potthast et al (2010), which includes closelyrelated language pairs as well.Our results also show that better results come atthe cost of more expensive processing time.
Forthe future, we would like to investigate such per-formance trade-offs in more demanding datasets.For future work we consider that exploring se-mantic text features across languages could im-prove the results.
It could be interesting to fur-ther analyse how the reordering of words throughtranslations might be relevant for this task.
Addi-tionally, working with languages even more dis-tant from each other, such as Arabic or Hindi,seems to be a challenging and interesting task.AcknowledgementsThe research work of the first two authors is partially fundedby CONACYT-Mexico and the MICINN project TEXT-ENTERPRISE 2.0 TIN2009-13391-C04-03 (Plan I+D+i).The research work of the last two authors is partially fundedby the MICINN projects OPENMT-2 TIN2009-14675-C03-01 and KNOW2 TIN2009-14715-C04-01.ReferencesAlca?zar, Asier.
2006.
Towards Linguistically Search-able Text.
In Proceedings of the BIDE 2005, Bilbao,Basque Country.Alegria, In?aki, Mikel L. Forcada, and Kepa Sara-sola, editors.
2009.
Proceedings of the SEPLN2009 Workshop on Information Retrieval and Infor-mation Extraction for Less Resourced Languages,Donostia, Basque Country.
University of the BasqueCountry.Barro?n-Ceden?o, Alberto, Paolo Rosso, David Pinto,and Alfons Juan.
2008.
On Cross-lingual Plagia-rism Analysis Using a Statistical Model.
In Stein,Stamatatos, and Koppel, editors, ECAI 2008 Work-shop on Uncovering Plagiarism, Authorship, andSocial Software Misuse (PAN 2008), pages 9?13,Patras, Greece.
CEUR-WS.org.Barro?n-Ceden?o, Alberto, Andreas Eiselt, and PaoloRosso.
2009.
Monolingual Text Similarity Mea-sures: A Comparison of Models over Wikipedia Ar-ticles Revisions.
In Sharma, Verma, and Sangal, ed-itors, ICON 2009, pages 29?38, Hyderabad, India.Macmillan Publishers.Broder, Andrei Z.
1997.
On the Resemblance andContainment of Documents.
In Compression andComplexity of Sequences (SEQUENCES?97), pages21?29.
IEEE Computer Society.Brown, Peter F., Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation: Pa-rameter Estimation.
Computational Linguistics,19(2):263?311.Ceska, Zdenek, Michal Toman, and Karel Jezek.
2008.Multilingual Plagiarism Detection.
In Proceedingsof the 13th International Conference on ArtificialIntelligence, pages 83?92.
Springer Verlag BerlinHeidelberg.Clough, Paul and Mark Stevenson.
2010.
Developinga Corpus of Plagiarised Short Answers.
LanguageResources and Evaluation: Special Issue on Plagia-rism and Authorship Analysis.Clough, Paul, Robert Gaizauskas, and Scott Piao.2002.
Building and Annotating a Corpus for theStudy of Journalistic Text Reuse.
In Proceedingsof the 3rd International Conference on LanguageResources and Evaluation (LREC 2002), volume V,pages 1678?1691, Las Palmas, Spain.Dumais, Susan T., Todd A. Letsche, Michael L.Littman, and Thomas K. Landauer.
1997.
Auto-matic Cross-Language Retrieval Using Latent Se-mantic Indexing.
In AAAI-97 Spring SymposiumSeries: Cross-Language Text and Speech Retrieval,pages 24?26.
Stanford University.Hoad, Timothy C. and Justin Zobel.
2003.
Meth-ods for Identifying Versioned and Plagiarized Doc-uments.
Journal of the American Society for Infor-mation Science and Technology, 54(3):203?215.44Keselj, Vlado, Fuchun Peng, Nick Cercone, and CalvinThomas.
2003.
N-gram-based Author Profilesfor Authorship Attribution.
In Proceedings of theConference Pacific Association for ComputationalLinguistics, PACLING?03, pages 255?264, Halifax,Canada.Koehn, Philipp, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical MachineTranslation.
In Annual Meeting of the Associationfor Computational Linguistics (ACL), demonstra-tion session, Prague, Czech Republic.Maurer, Hermann, Frank Kappe, and Bilal Zaka.
2006.Plagiarism - A Survey.
Journal of Universal Com-puter Science, 12(8):1050?1084.Mcnamee, Paul and James Mayfield.
2004.
CharacterN-Gram Tokenization for European Language TextRetrieval.
Information Retrieval, 7(1-2):73?97.Munteanu, Dragos S., Alexander Fraser, and DanielMarcu.
2004.
Improved Machine TranslationPerformace via Parallel Sentence Extraction fromComparable Corpora.
In Proceedings of the Hu-man Language Technology and North American As-sociation for Computational Linguistics Conference(HLT/NAACL 2004), Boston, MA.Och, Frank Josef and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19?51.See also http://www.fjoch.com/GIZA++.html.Pinto, David, Jorge Civera, Alberto Barro?n-Ceden?o,Alfons Juan, and Paolo Rosso.
2009.
A StatisticalApproach to Crosslingual Natural Language Tasks.Journal of Algorithms, 64(1):51?60.Potthast, Martin, Benno Stein, and Maik Anderka.2008.
A Wikipedia-Based Multilingual RetrievalModel.
In Macdonald, Ounis, Plachouras, Ruthven,and White, editors, 30th European Conference onIR Research, ECIR 2008, Glasgow, volume 4956LNCS of Lecture Notes in Computer Science, pages522?530, Berlin Heidelberg New York.
Springer.Potthast, Martin, Benno Stein, Andreas Eiselt, AlbertoBarro?n-Ceden?o, and Paolo Rosso.
2009.
Overviewof the 1st International Competition on PlagiarismDetection.
In Stein, Rosso, Stamatatos, Koppel, andAgirre, editors, SEPLN 2009 Workshop on Uncov-ering Plagiarism, Authorship, and Social SoftwareMisuse (PAN 09), pages 1?9, San Sebastian, Spain.CEUS-WS.org.Potthast, Martin, Alberto Barro?n-Ceden?o, BennoStein, and Paolo Rosso.
2010.
Cross-Language Pla-giarism Detection.
Language Resources and Eval-uation, Special Issue on Plagiarism and AuthorshipAnalysis.Pouliquen, Bruno, Ralf Steinberger, and Camelia Ig-nat.
2003.
Automatic Identification of Docu-ment Translations in Large Multilingual DocumentCollections.
In Proceedings of the InternationalConference on Recent Advances in Natural Lan-guage Processing (RANLP-2003), pages 401?408,Borovets, Bulgaria.Schleimer, Saul, Daniel S. Wilkerson, and Alex Aiken.2003.
Winnowing: Local Algorithms for DocumentFingerprinting.
In Proceedings of the 2003 ACMSIGMOD International Conference on Managementof Data, New York, NY.
ACM.Shivakumar, Narayanan and Hector Garc??a-Molina.1995.
SCAM: A Copy Detection Mechanism forDigital Documents.
In Proceedings of the 2nd An-nual Conference on the Theory and Practice of Dig-ital Libraries.Stein, Benno, Sven Meyer zu Eissen, and Martin Pot-thast.
2007.
Strategies for Retrieving PlagiarizedDocuments.
In Clarke, Fuhr, Kando, Kraaij, and deVries, editors, Proceedings of the 30th Annual Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 825?826, Amsterdam, The Netherlands.
ACM.Steinberger, Ralf, Bruno Pouliquen, and Johan Hag-man.
2002.
Cross-lingual Document SimilarityCalculation Using the Multilingual Thesaurus EU-ROVOC.
Computational Linguistics and IntelligentText Processing.
Proceedings of the CICLing 2002,2276:415?424.Steinberger, Ralf, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz Erjavec, Dan Tufis, andDa?niel Varga.
2006.
The JRC-Acquis: A multilin-gual aligned parallel corpus with 20+ languages.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC 2006),volume 9, Genoa, Italy.Stolcke, Andreas.
2002.
SRILM - An Extensible Lan-guage Modeling toolkit.
In Intl.
Conference on Spo-ken Language Processing, Denver, Colorado.Wikipedia.
2010a.
Basque language.
[Online; ac-cessed 5-February-2010].Wikipedia.
2010b.
Party of European Socialists | Par-tido Socialista Europeo | Europako Alderdi Sozial-ista .
[Online; accessed 10-February-2010].45
