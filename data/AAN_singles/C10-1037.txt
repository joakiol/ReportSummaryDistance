Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 322?330,Beijing, August 2010Multi-Sentence Compression: Finding Shortest Paths in Word GraphsKatja FilippovaGoogle Inc.katjaf@google.comAbstractWe consider the task of summarizing acluster of related sentences with a shortsentence which we call multi-sentencecompression and present a simple ap-proach based on shortest paths in wordgraphs.
The advantage and the novelty ofthe proposed method is that it is syntax-lean and requires little more than a tok-enizer and a tagger.
Despite its simplic-ity, it is capable of generating grammati-cal and informative summaries as our ex-periments with English and Spanish datademonstrate.1 IntroductionSentence compression (henceforth SC) is a taskwhere the goal is to produce a summary of a sin-gle sentence which would preserve the importantpart of the content and be grammatical.
Startingfrom the early work of Jing & McKeown (2000),in the last decade SC has received considerable at-tention in the NLP community.
Ubiquitous use ofmobile devices is an obvious example of whereSC could be applied?a longer text of an email,news or a Wikipedia article can be compressedsentence by sentence to fit into a limited display(Corston-Oliver, 2001).
Another reason why SC isso popular is its potential utility for extractive textsummarization, single or multi-document (Mani,2001).
There, a standard approach is to rank sen-tences by importance, cluster them by similarity,and select a sentence from the top ranked clusters.Selected sentences almost always require revisionand can be reformulated succinctly as it is oftenonly a part of the sentence which is of interest.It is this multi-document summarization scenariowhich motivates our work.Given a cluster of similar, or related, sentences,we aim at summarizing the most salient theme ofit in a short single sentence.
We refer to this taskas multi-sentence compression.
Defined this way,it comes close to sentence fusion which was orig-inally introduced as a text-to-text generation tech-nique of expressing content common to most ofthe input sentences in a single sentence (Barzi-lay & McKeown, 2005).
However, since then thetechnique has been extended so that now fusionalso stands for uniting complementary content ina single concise sentence (Filippova & Strube,2008b; Krahmer et al, 2008).
Since our methodis not designed for the ?union?
kind of fusion, wethink it is more appropriate to classify it as a sen-tence compression technique.Two challenges of SC as well as text summa-rization are (i) important content selection and (ii)its readable presentation.
Most existing systemsuse syntactic information to generate grammaticalcompressions.
Incidentally, syntax also providesclues to what is likely to be important?e.g., thesubject and the verb of the main clause are morelikely to be important than a prepositional phraseor a verb from a relative clause.
Of course, syn-tax is not the only way to gauge word or phraseimportance.
In the case of sentence compressionbeing used for text summarization, one disposesof a rich context to identify important words orphrases.
For example, recurring or semantically322similar words are likely to be relevant, and thisinformation has been used in earlier SC systems(Hori et al, 2003; Clarke & Lapata, 2007, interalia).
Still, syntactic parsers are assumed to be in-dispensable tools for both sentence compressionand fusion because syntactic constraints (hand-crafted or learned from the data) seem to be theonly way to control the grammaticality of the out-put.
In this paper we are going to question thiswell-established belief and argue that just like insome cases syntax helps to find important content(e.g., when the input is an isolated sentence), inthe multi-sentence case redundancy provides a re-liable way of generating grammatical sentences.In particular, the important and novel points of ourwork are as follows:?
We present a simple and robust word graph-based method of generating succinct com-pressions which requires as little as a part ofspeech tagger and a list of stopwords.?
To our knowledge, it is the first methodwhich requires neither a parser, nor hand-crafted rules, nor a language model to gen-erate reasonably grammatical output.?
In an extensive evaluation with native speak-ers we obtain encouraging results for Englishas well as for Spanish.In the following section we present our approachto sentence compression (Sec.
2); then we intro-duce the baseline (Sec.
3) and the data (Sec.
4).In Section 5 we report about our experiments anddiscuss the results.
Finally, Section 6 gives anoverview of related work.2 Multi-sentence CompressionA well-known challenge for extractive multi-document summarization systems is to producenon-redundant summaries.
There are two stan-dard ways of avoiding redundancy: either oneadds sentences to the summary one-by-one andeach time checks whether the sentence is signif-icantly different from what is already there (e.g.,using MMR), or one clusters related sentences andselects only one from each cluster.
In both casesa selected sentence may include irrelevant infor-mation, so one wishes to compress it, usually bytaking syntactic and lexical factors into account.However, we think this approach is suboptimal inthis case and explore a different way.
Instead ofcompressing a single sentence, we build a wordgraph from all the words of the related sentencesand compress this graph.A word graph is a directed graph where an edgefrom word A to word B represents an adjacencyrelation.
It also contains the start and end nodes.Word graphs have been widely used in natural lan-guage processing for building language models,paraphrasing, alignment, etc.
(see Sec.
6).
Com-pared with dependency graphs, their use for sen-tence generation has been left largely unexplored,presumably because it seems that almost all thegrammatical information is missing from this rep-resentation.
Indeed, a link between a finite verband an article does not correspond to any gram-matical relation between the two.
However, thepremise for our work is that redundancy should besufficient to identify not only important words butalso salient links between words.
In this sectionwe present our approach to word graph compres-sion.
We begin by explaining the graph construc-tion process and continue with the details of twocompression methods.2.1 Word Graph ConstructionGiven a set of related sentences S ={s1, s2, ...sn}, we build a word graph by it-eratively adding sentences to it.
As an illustration,consider the four sentences below and the graphin Figure 1 obtained from them.
Edge weightsare omitted and italicized fragments from thesentences are replaced with dots for clarity.
(1) The wife of a former U.S. president Bill Clin-ton Hillary Clinton visited China last Mon-day.
(2) Hillary Clinton wanted to visit China lastmonth but postponed her plans till Mondaylast week.
(3) Hillary Clinton paid a visit to the People Re-public of China on Monday.
(4) Last week the Secretary of State Ms. Clintonvisited Chinese officials.323wanted tomonthonlastofficialsvisitofClintonChinese(1)ESweeklast(4)(2)(3)tilltheMspaidHillaryClintonvisited ChinaMondayFigure 1: Word graph generated from sentences (1-4) and a possible compression path.After the first sentence is added the graph is sim-ply a string of word nodes (punctuation is ex-cluded) plus the start and the end symbols (S andE in Fig.
1).
A word from the following sentencesis mapped onto a node in the graph provided thatthey have the exact same lowercased word formand the same part of speech1 and that no wordfrom this sentence has already been mapped ontothis node.
Using part of speech information re-duces chances of merging verbs with nouns (e.g.,visit) and generating ungrammatical sequences.
Ifthere is no candidate in the graph a new node iscreated.Word mapping/creation is done in three stepsfor the following three groups of words: (1) non-stopwords2 for which no candidate exists in thegraph or for which an unambiguous mapping ispossible; (2) non-stopwords for which there areeither several possible candidates in the graph orwhich occur more than once in the sentence; (3)stopwords.This procedure is similar to the one used byBarzilay & Lee (2003) in that we also first iden-tify ?backbone nodes?
(unambiguous alignments)and then add mappings for which several possi-bilities exist.
However, they build lattices, i.e.,1We use the OpenNLP package for tagging: http://opennlp.sourceforge.net.2We generate a list of about 600 news-specific stopwordsfor English (including, e.g., said, seems) and took a publiclyavailable list of about 180 stopwords for Spanish from www.ranks.nl/stopwords/spanish.html.directed acyclic graphs, whereas our graphs maycontain cycles.
For the last two groups of wordswhere mapping is ambiguous we check the imme-diate context (the preceding and following wordsin the sentence and the neighboring nodes in thegraph) and select the candidate which has largeroverlap in the context, or the one with a greaterfrequency (i.e., the one which has more wordsmapped onto it).
For example, in Figure 1 whensentence (4) is to be added, there are two candi-date nodes for last.
The one pointing to week isselected as week is the word following last in (4).Stopwords are mapped only if there is some over-lap in non-stopword neighbors, otherwise a newnode is created.Once all the words from the sentence are inplace, we connect words adjacent in the sentencewith directed edges.
For newly created nodes,or nodes which were not connected before, weadd an edge with a default weight of one.
Edgeweights between already connected nodes are in-creased by one.
The same is done with the startand end nodes.
Nodes store id?s of the sentencestheir words come from as well as all their offsetpositions in those sentences.The described alignment method is fairly sim-ple and guarantees the following properties of theword graph: (i) every input sentence correspondsto a loopless path in the graph; (ii) words refer-ring to the same entities or actions are likely toend up in one node; (iii) stopwords are only joined324in one node if there is an overlap in context.
Thegraph may generate a potentially endless amountof incomprehensible sequences connecting startand end.
It is also likely to contain paths corre-sponding to good compressions, like the path con-necting the nodes highlighted with blue in Figure1.
In the following we describe two our methodsof finding the best path, that is, the best compres-sion for the input sentences.2.2 Shortest Path as CompressionWhat properties are characteristic of a good com-pression?
It should neither be too long, nor tooshort.
It should go through the nodes which rep-resent important concepts but should not pass thesame node several times.
It should correspond to alikely word sequence.
To satisfy these constraintswe invert edge weights, i.e., link frequencies, andsearch for the shortest path (i.e., lightest in termsof the edge weights) from start to end of a pre-defined minimum length.
This path is likely tomention salient words from the input and put to-gether words found next to each other in manysentences.
This is the first method we consider.We set a minimum path length (in words) to eightwhich appeared to be a reasonable threshold on adevelopment set?paths shorter than seven wordswere often incomplete sentences.Furthermore, to produce informative sum-maries which report about the main event of thesentence cluster, we filter paths which do not con-tain a verb node.
For example, Ozark?s ?Win-ter?s Bone?
at the 2010 Sundance Film Festivalmight be a good title indicating what the article isabout.
However, it is not as informative as ?Win-ter?s Bone?
earned the grand jury prize at Sun-dance which indeed conveys the gist of the event.Thus, we generate K shortest paths and filter allthose which are shorter than eight words or do notcontain a verb.
The path with the minimum totalweight is selected as the summary.2.3 Improved Scoring and RerankingThe second configuration of our system employsa more sophisticated weighting function.
The pur-pose of this function is two-fold: (i) to generate agrammatical compression, it favors strong links,i.e., links between words which appear signifi-cantly often in this order; (ii) to generate an in-formative compression, it promotes paths passingthrough salient nodes.Strong links: Intuitively, we want the compres-sion path to follow edges between words whichare strongly associated with each other.
Invertededge frequency is not sufficient for that becauseit ignores the overall frequency of the nodes theedge connects.
For example, edge frequency ofthree should count more if the edge connects twonodes with frequency of three rather than if theirfrequencies are much higher.
Thus, we redefineedge weight as follows:w(ei,j) =freq(i) + freq(j)freq(ei,j)(1)Furthermore, we also promote a connection be-tween two nodes if there are multiple paths be-tween them.
For example, if some sentencesspeak of president Barack Obama or president ofthe US Barack Obama, and some sentences areabout president Obama, we want to add some re-ward to the edge between president and Obama.However, longer paths between words are weaksignals of word association.
Therefore, the weightof an edge between the nodes i and j is reducedfor every possible path between them but reducedproportionally to its length:w?
(ei,j) =freq(i) + freq(j)Ps?S diff(s, i, j)?1(2)where the function diff(s, i, j) refers to the dis-tance between the offset positions (pos(s, i)) ofwords i and j in sentence s and is defined as fol-lows:diff(s, i, j) =(pos(s, i) ?
pos(s, j) if pos(s, i) < pos(s, j)0 otherwise(3)Salient words: The function above only indi-cates how strong the association between twowords is.
It assigns equal weights to edges con-necting words encountered in a single sentenceand words encountered next to each other in everysentence.
To generate a summary concerning themost salient events and entities, we force the path325to go through most frequent nodes by decreasingedge weight with respect to the frequency of thenodes it connects.
Thus, we further redefine edgeweight as follows:w??
(ei,j) = w?
(ei,j)freq(i) ?
freq(j) (4)We implement the K-shortest paths algorithmto find the fifty shortest paths from start to endusing the weighting function in (4).
We filter allthe paths which are shorter than eight words andwhich do not pass a verb node.
Finally, we rerankthe remaining paths by normalizing the total pathweight over its length.
This way we obtain thepath which has the lightest average edge weight.3 BaselineAs a first baseline we are searching for the mostprobable string with respect to the sentence clus-ter.
In particular, we use the Viterbi algorithm tofind the sequence of words of a predefined lengthn which maximizes the bigram probability (MLE-based):p(w1,n) = p(w1|s)p(w2|w1)...p(e|wn) (5)Similar to the shortest path implementation, wespecify compression length and set it also here toeight tokens.
However, the compressions obtainedwith this method are often unrelated to the maintheme.
The reason for that is that a token subse-quence encountered in a single sentence is likelyto get a high probability?all transition probabili-ties are equal to one?provided that the probabilityof entering this sequence is not too low.
To amendthis problem and to promote frequent words (i.e.,words which are likely to be related to the maintheme) we maximize the following baseline scorewhich takes into account both the bigram proba-bilities and the token likelihood, p(wi), which isalso estimated from the sentence cluster:b(w1,n) = p(w1|s)p(w2|w1)...p(e|wn)Yip(wi) (6)4 Data SourcesAs data for our experiments we use news arti-cles presented in clusters on Google News3.
Themain reason for why we decided to use this ser-vice is that it is freely available and does the jobof news classification and clustering with a pro-duction quality.
Apart from that, it is a rich sourceof multilingual data.We collected news clusters in English andSpanish, 10-30 articles each, 24 articles on aver-age.
To get sets of similar sentences we aggre-gated first sentences from every article in the clus-ter, removing duplicates.
The article-initial sen-tence is known to provide a good summary ofthe article and has become a standard competi-tive baseline in summarization4 .
Hence, given thatfirst sentences summarize the articles they belongto, which are in turn clustered as concerning thesame event, those sentences are likely althoughnot necessarily need to be similar.From the total of 150 English clusters we re-served 70 for development and 80 for testing.
ForSpanish we collected 40 clusters, all for testing.We stripped off bylines and dates from the begin-ning of every sentence with a handful of regularexpressions before feeding them to the baselineand our compression methods.The data we use has two interesting properties:(i) article-initial sentences are on average longerthan other sentences.
In our case average sentencelengths for English and Spanish (without bylines)are 28 and 35 tokens, respectively.
(ii) such sen-tence clusters are noisier than what one would ex-pect in a summarization pipeline.
Both propertiesmake the task realistically hard and pose a chal-lenge for the robustness of a compression method.If we show that reasonable compressions can begenerated even from noisy clusters acquired froma publicly available news service, then we have agood reason to believe that the method will per-form at least comparable on more carefully con-structed clusters of shorter sentences.3http://news.google.com4See DUC/TAC competitions: http://www.nist.gov/tac3265 Evaluation5.1 Experiment DesignThe performance of the systems was assessed inan experiment with human raters, all native speak-ers.
They were presented with a list of snippets ofthe articles from one cluster ?
first sentence andtitle linked to the original document.
The raterswere allowed to look up the articles if they needmore background on the matter but this was notobligatory.The first question concerned the quality of thesentence cluster.
The raters were asked whetherthe cluster contained a single prevailing event, orwhether it was too noisy and no theme stood out.Given how simple our sentence grouping proce-dure was, most clusters informed about more thanone event.
However, to answer the question posi-tively it would be enough to identify one prevail-ing theme.Below that, a summary and two further ques-tions concerning its quality were displayed.
Simi-lar to most preceding work, we were interested ingrammaticality and informativity of summaries.With respect to grammaticality, following Barzi-lay & McKeown (2005), we asked the raters togive one of the three possible ratings: perfect ifthe summary was a complete grammatical sen-tence (2 pts); almost if it required a minor edit-ing, e.g., one mistake in articles or agreement (1pt); ungrammatical if it was none of above (0 pts).We explicitly asked the raters to ignore lack orexcess of capitalization or punctuation.
Further-more, based on the feedback from a preliminaryevaluation, we provided an example in which wemade clear that summaries consisting of a fewphrases which cannot be reformulated as a com-plete sentence (e.g., Early Monday a U.S.
Navyship.)
should not count as grammatical.The final question, concerning informativity,had four possible options: n/a if the cluster is toonoisy and unsummarizable in the first place; per-fect if it conveys the gist of the main event and ismore or less like the summary the person wouldproduce himself (2 pts); related if it is related tothe the main theme but misses something impor-tant (1 pt); unrelated if the summary is not relatedto the main theme (0 pts).For each of the 80 sentence clusters (40 forSpanish) we generated three summaries with thethree systems.
Most summaries were rated by fourraters, a few got only three ratings; no rater sawthe same cluster twice.5.2 ResultsWe report average grammaticality and informativ-ity scores in Table 1.
However, averaging systemratings over all clusters and raters is not justifiedin our case.
It is important to remember that thescore assignments (i.e., 0, 1, 2) are arbitrary andthat the score of one with respect to grammatical-ity (i.e., a minor mistake) is in fact closer to twothan to zero.
One could set the scores differentlybut even then, strictly speaking, it is not correct toaverage the scores as ratings do not define a metricspace.System Gram InfoBaseline 0.70 / 0.61 0.62 / 0.53Shortest path 1.30 / 1.27 1.16 / 0.79Shortest path++ 1.44 / 1.25 1.30 / 1.25Table 1: Average ratings for English / Spanish.Therefore in Table 2 we present distributionsover the three scores for both grammaticalityand informativity together with average summarylengths in tokens.
For both grammaticality andinformativity, for every summary-cluster pair wedid majority voting and resolved ties by assign-ing the lower score.
For example, if a systemgot the ratings 1, 1, 2, 2 for a certain cluster, wecounted this as 1.
We dismissed cases where thetie was between the maximum and the minimumscore?this happened with some summaries whichgot just three scores (i.e., 0, 1, 2) and accountedfor < 4% of the cases.
To obtain the informativ-ity distribution we considered only clusters whichwere classified as containing a single prevailingevent by at least ten raters.
For English 75 outof 80 clusters qualified as such (37 out of 40 forSpanish).
Similar to above, we dismissed about3% tie cases where the ratings diverged signifi-cantly (e.g., 0, 1, 2).327System Gram-2 Gram-1 Gram-0 Info-2 Info-1 Info-0 Avg.
Len.Baseline (EN) 21% 15% 65% 18% 10% 73% 8Shortest path (EN) 52% 16% 32% 36% 33% 31% 10Shortest path++ (EN) 64% 13% 23% 52% 32% 16% 12Baseline (ES) 12% 15% 74% 9% 19% 72% 8Shortest path (ES) 58% 21% 21% 23% 26% 51% 10Shortest path++ (ES) 50% 21% 29% 40% 40% 20% 12Table 2: Distribution over possible ratings and average length for English and Spanish.5.3 DiscussionThe difference between the baseline and our short-est path systems is striking.
Although morethan 20% of the baseline summaries are perfectlygrammatical, the gap to the improved version ofshortest paths is significant, about 43%.
The sameholds for the percentage of informative summaries(18% vs. 52%).
Both numbers are likely to beunderstated as we chose to resolve all ties notin our favor.
84% of the summaries generatedby the improved method are related to the maintheme of the cluster, and more than 60% of those(52% of the total summaries) convey the very gistof it without missing any important information.Comparing the two configurations we have pro-posed, improved scoring function and rerankingwe added on top of the shortest path method wereboth rewarding.
Interestingly, even the straight-forward approach of choosing the shortest path ofa minimum length already guarantees a grammat-ical summary in more than half of the cases.An interesting difference in the performancefor Spanish and English is that shortest path gen-erates more grammatical sentences than the im-proved version of it.
However, the price for highergrammaticality scores is a huge drop in informa-tivity: half of such summaries are not related tothe main theme at all, whereas 40% of the sum-maries generated by the improved version got thehighest rating.
A possible reason for the poorerperformance for Spanish is that we used a muchsmaller list of stopwords which did not includenews-specific words like, e.g., dijo (said) whichresulted in denser graphs.
In the future, we wouldlike to apply the method to more languages andexperiment with longer lists of stopwords.One may notice that the summaries producedby the baseline are shorter than those generatedby the shortest paths which might look like a rea-son for its comparatively poor performance.
How-ever, the main source of errors for the baselinewas its inability to keep track of the words al-ready present in the summary, so it is unlikely thatlonger sequences would be of a much higher qual-ity.
The sentences generated by the baseline wereoften repetitive, e.g., The food tax on food tax onfood.
This is not an issue with the shortest pathapproaches as they never include loops when edgeweights are strictly positive.The reranking we added to the shortest pathmethod is the reason for why the summaries gen-erated by the improved version of the system areon average slightly longer than those producedby the simpler version.
The average lengths forboth systems are drastically shorter than the aver-age length of the sentences served as input (10/12vs.
28 tokens in English or 35 tokens for Span-ish).
This corresponds to the compression rate of36-43% (29-34% for Spanish) which is compar-atively ?aggressive?
as it usually varies between50-80% in other systems.6 Comparison with Related Work6.1 Sentence CompressionIn the last ten years a lot of research has beendevoted to sentence compression.
Most studiesshare two properties: (1) they rely on syntax, and(2) they are supervised.
The degree of syntax-dependence varies between methods.
Some uti-lize a parser to identify and later keep certain im-portant relations but do not require a completeparse (Clarke & Lapata, 2008), or use a syn-tactic representation to extract features (McDon-ald, 2006).
For other approaches correct syntac-328tic trees are crucial to obtain grammatical com-pressions (Galley & McKeown, 2007; Filippova& Strube, 2008a; Cohn & Lapata, 2009).
Hand-crafted rules (Dorr et al, 2003) as well as lan-guage models also have been utilized to generatefluent compressions (Hori et al, 2003; Clarke &Lapata, 2008).6.2 Sentence GenerationTo date the work on sentence fusion is com-pletely dependency syntax-based.
Input sentencesare parsed into trees, from those trees a new de-pendency structure is generated, and this struc-ture is finally converted into a sentence (Barzilay& McKeown, 2005; Filippova & Strube, 2008b;Wan et al, 2009).
Parser quality is of crucialimportance for such methods, and to our knowl-edge no attempt has been made to generate novelsentences without adhering to dependency repre-sentations.
In the future, it would be of interestto compare our method with a syntax-based fu-sion method.
Syntax-lean methods have been ex-plored for headline generation (Banko et al, 2000;Dorr et al, 2003; Jin & Hauptmann, 2003).
How-ever, they do not aim at generating complete sen-tences or informative summaries but rather to in-dicate what the news is about.6.3 Word Graphs and LatticesPerhaps the work of Barzilay & Lee (2003) whoalign comparable sentences to generate sentence-level paraphrases seems closest to ours in that weboth use word graphs for text generation.
How-ever, this is a fairly general similarity, as boththe goal and the implementation are different.While we search for an optimal weighting func-tion in noisy graphs to identify readable and in-formative compressions, they induce paraphrasepatterns from unweighted paths in much smallerDAGs obtained from highly similar sentences.Shen et al (2006) is another example of usingword lattices to find paraphrases.
Unlike Barzilay& Lee (2003), they propose to use syntax to obtainaccurate alignments.
Numerous examples of theutility of word lattices come from the field of finitestate automata, language modeling, speech recog-nition, parsing and machine translation (Mohri,1997, inter alia).7 ConclusionsWe considered the task of generating a short in-formative summary for a set of related sentences,called multi-sentence compression, which arisesnaturally in the context of multi-document textsummarization.
We presented a simple but ro-bust method which proceeds by finding shortestpaths in word graphs.
The novelty of our workis that we demonstrated that reasonable compres-sions can be obtained without any syntactic infor-mation if a good weighting function is defined.This distinguishes our work from earlier researchon sentence fusion and compression which re-lies on syntactic representations and/or languagemodels.
We provided the details of an extensiveevaluation on English and Spanish data and re-ported high grammaticality as well as informativ-ity scores.
In the future we would like to experi-ment with other languages and eschew using part-of-speech information.Acknowledgements: I am thankful to KeithHall for the discussions on this work and the veryhelpful feedback on an earlier draft of this paper.ReferencesBanko, M., V. O. Mittal & M. J. Witbrock (2000).Headline generation based on statistical trans-lation.
In Proc.
of ACL-00, pp.
318?325.Barzilay, R. & L. Lee (2003).
Learning to para-phrase: An unsupervized approach using multi-sequence alignment.
In Proc.
of HLT-NAACL-03, pp.
16?23.Barzilay, R. & K. R. McKeown (2005).
Sentencefusion for multidocument news summarization.Computational Linguistics, 31(3):297?327.Clarke, J.
& M. Lapata (2007).
Modelling com-pression with discourse constraints.
In Proc.
ofEMNLP-CoNLL-07, pp.
1?11.Clarke, J.
& M. Lapata (2008).
Global infer-ence for sentence compression: An integer lin-ear programming approach.
Journal of Artifi-cial Intelligence Research, 31:399?429.329Cohn, T. & M. Lapata (2009).
Sentence compres-sion as tree transduction.
Journal of ArtificialIntelligence Research, 34:637?674.Corston-Oliver, S. H. (2001).
Text compaction fordisplay on very small screens.
In Proceedingsof the NAACL Workshop on Automatic Summa-rization, Pittsburg, PA, 3 June 2001, pp.
89?98.Dorr, B., D. Zajic & R. Schwartz (2003).
Hedgetrimmer: A parse-and-trim approach to head-line generation.
In Proceedings of the Text Sum-marization Workshop at HLT-NAACL-03, Ed-monton, Alberta, Canada, 2003, pp.
1?8.Filippova, K. & M. Strube (2008a).
Dependencytree based sentence compression.
In Proc.
ofINLG-08, pp.
25?32.Filippova, K. & M. Strube (2008b).
Sentencefusion via dependency graph compression.
InProc.
of EMNLP-08, pp.
177?185.Galley, M. & K. R. McKeown (2007).
LexicalizedMarkov grammars for sentence compression.
InProc.
of NAACL-HLT-07, pp.
180?187.Hori, C., S. Furui, R. Malkin, H. Yu & A. Waibel(2003).
A statistical approach to automaticspeech summarization.
EURASIP Journal onApplied Signal Processing, 2:128?139.Jin, R. & A. G. Hauptmann (2003).
Automatictitle generation for spoken broadcast news.
InProc.
of HLT-01, pp.
1?3.Jing, H. & K. McKeown (2000).
Cut and pastebased text summarization.
In Proc.
of NAACL-00, pp.
178?185.Krahmer, E., E. Marsi & P. van Pelt (2008).Query-based sentence fusion is better definedand leads to more preferred results than genericsentence fusion.
In Proc.
of ACL-HLT-08, pp.193?196.Mani, I.
(2001).
Automatic Summarization.
Ams-terdam, Philadelphia: John Benjamins.McDonald, R. (2006).
Discriminative sentencecompression with soft syntactic evidence.
InProc.
of EACL-06, pp.
297?304.Mohri, M. (1997).
Finite-state transducers in lan-guage and speech processing.
ComputationalLinguistics, 23(2):269?311.Shen, S., D. Radev, A. Patel & G. Erkan (2006).Adding syntax to dynamic programming foraligning comparable texts for generation ofparaphrases.
In Proc.
of COLING-ACL-06, pp.747?754.Wan, S., M. Dras, R. Dale & C. Paris (2009).
Im-proving grammaticality in statistical sentencegeneration: Introducing a dependency spanningtree algorithm with an argument satisfactionmodel.
In Proc.
of EACL-09, pp.
852?860.330
