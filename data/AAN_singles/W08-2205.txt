Augmenting WordNet for DeepUnderstanding of TextPeter Clark1Christiane Fellbaum2Jerry R. Hobbs3Phil Harrison1William R. Murray1John Thompson11The Boeing Company (USA)2Princeton University (USA)3University of Southern California (USA)email: peter.e.clark@boeing.comAbstractOne of the big challenges in understanding text, i.e., constructing an over-all coherent representation of the text, is that much information neededin that representation is unstated (implicit).
Thus, in order to ?fill inthe gaps?
and create an overall representation, language processing sys-tems need a large amount of world knowledge, and creating those knowl-edge resources remains a fundamental challenge.
In our current work,we are seeking to augment WordNet as a knowledge resource for lan-guage understanding in several ways: adding in formal versions of itsword sense definitions (glosses); classifying the morphosemantic linksbetween nouns and verbs; encoding a small number of ?core theories?about WordNet?s most commonly used terms; and adding in simple rep-resentations of scripts.
Although this is still work in progress, we describeour experiences so far with what we hope will be a significantly improvedresource for the deep understanding of language.4546 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompson1 IntroductionMuch information that text is intended to convey is not explicitly stated.
Rather, thereader constructs a mental model of the scene described by the text, including many?obvious?
features that were not explicitly mentioned.
By one estimate, the ratio ofexplicit to implicit facts is 1:8 (Graesser, 1981), making the task of understandingtext, i.e., constructing a coherent representation of the scene that the author intendedto convey, very difficult, even given the generally reasonable quality of syntactic in-terpretation that today?s systems produce.
For example, given the sentence:A soldier was killed in a gun battle.a reader will infer that (probably):The soldier was shot; The soldier died; There was a fight; etc.even though none of these facts are explicitly stated.
A person is able to draw theseplausible conclusions because of the large amounts of world knowledge he/she has,and his/her ability to use them to construct an overall mental model of the scene beingdescribed.A key requirement for this task is access to a large body of world knowledge.
How-ever, machines are currently poorly equipped in this regard.
Although a few knowl-edge encoding projects are underway, e.g., Cyc (Lenat and Guha, 1989), developingsuch resources continues to be a major challenge, and any contribution to this taskhas significant potential benefit.
WordNet (Miller, 1995; Fellbaum, 1998) presents anunique avenue for making inroads into this problem: It already has broad coverage,multiple lexicosemantic connections, and significant knowledge encoded (albeit infor-mally) in its glosses.
It can thus be viewed as on the way to becoming an extensivelyleveragable, ?lightweight?
knowledge base for reasoning.
In fact, WordNet aleadyplays a central role in many question-answering systems e.g., 21 of the 26 teams inthe recent PASCAL RTE3 challenge used WordNet (Giampiccolo et al, 2007), andmost other large-scale resources already include mappings to it and thus can leverageit easily.
In our work we are developing several augmentations to WordNet to improveits utility further, and we report here on our experiences to date.Althoughwe are performing experimentswith recognizing textual entailment (RTE)(determining whether a hypothesis sentence H follows from some text T), it is impor-tant to note that RTE is not our end-goal.
Many existing RTE systems, e.g., (Adamset al, 2007; Chambers et al, 2007) largely work by statistically scoring the match be-tween T and H, but this to an extent sidesteps ?deep?
language understanding, namelybuilding a coherent, internal representation of the overall scenario the input text wasintended to convey.
RTE is one way of measuring success in this endeavor, but it isalso possible to do moderately well in RTE without the system even attempting to?understand?
the scenario the text is describing.
It is yet to be seen whether very highperformance in RTE can be obtained without some kind of deep language understand-ing of the entire scene that a text conveys.We are testing our work with BLUE, Boeing?s Language Understanding Engine,which we first describe.
We then present the WordNet augmentations that we are de-veloping, and our experience with these as well as with the DIRT paraphrase database.Augmenting WordNet for Deep Understanding of Text 47The contribution of this paper is some preliminary insight into avenues and challengesfor creating and leveraging more world knowledge, in the context of WordNet, fordeeper language understanding.2 Text Interpretation and Subsumption2.1 Text InterpretationFor text interpretation we are using BLUE, Boeing?s Language Understanding Engine(Clark and Harrison, 2008), comprising a parser, logical form (LF) generator, and fi-nal logic generator.
Parsing is performed using SAPIR, a mature, bottom-up, broadcoverage chart parser (Harrison and Maxwell, 1986).
The parser?s cost function isbiased by a database of manually and corpus-derived ?tuples?
(good parse fragments),as well as hand-coded preference rules.
During parsing, the system also generatesa logical form (LF), a semi-formal structure between a parse and full logic, looselybased on Schubert and Hwang (1993).
The LF is a simplified and normalized treestructure with logic-type elements, generated by rules parallel to the grammar rules,that contains variables for noun phrases and additional expressions for other sentenceconstituents.
Some disambiguation decisions are performed at this stage (e.g., struc-tural, part of speech), while others are deferred (e.g., word senses, semantic roles),and there is no explicit quantifier scoping.
A simple example of an LF is shown below(items starting with underscores _?A?I?
denote variables):;;; LF for "A soldier was killed in a gun battle.
"(DECL ((VAR _X1 "a" "soldier")(VAR _X2 "a" "battle" (NN "gun" "battle")))(S (PAST) NIL "kill" _X1 (PP "in" _X2)))The LF is then used to generate ground logical assertions of the form r(x,y), con-taining Skolem instances, by applying a set of syntactic rewrite rules recursively to it.Verbs are reified as individuals, Davidsonian-style.
An example of the output is:;;; logic for "A soldier was killed in a gun battle.
"object(kill01,soldier01)in(kill01,battle01)modifier(battle01,gun01)plus predicates associating each Skolem with its corresponding input word.
At thisstage of processing, the predicates are syntactic relations (subject(x,y), object(x,y),modifier(x,y), and all the prepositions, e.g., in(x,y)).
Definite coreference is computedby a special module which uses the (logic for the) referring noun phrase as a queryon the database of assertions.
Another module performs special structural transforma-tions, e.g., when a noun or verb should map to a predicate rather than an individual.Two additional modules perform (currently naive) word sense disambiguation (WSD)and semantic role labelling (SRL), described further in Clark and Harrison (2008).However, for our RTE experiments we have found it more effective to leave sensesand roles underspecified, effectively considering all valid senses and roles (for thegiven lexical features) during reasoning until instantiated by the rules that apply.48 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompson2.2 SubsumptionA basic operation for reasoning is determining if one set of clauses subsumes (is moregeneral than, is thus implied by) another, e.g., (the logic for) ?A person likes a person?subsumes ?A man loves a woman?.
This basic operation is used both to determine ifan axiom applies, and in RTE to determine if a text H subsumes (is implied by) a textT or its axiom-expanded elaboration.
A set S1 of clauses subsumes another S2 if eachclause in S1 subsumes some (different) member of S2.
A clause C1 subsumes anotherC2 if both (for binary predicates) of C1?s arguments subsume the corresponding argu-ments in C2, and C1 and C2?s predicates ?match?.
An argument A1 subsumes anotherA2 if some word sense for A1?s associated word is equal or more general (a hypernymof) some word sense of A2?s associated word (thus effectively considering all possibleword senses for A1 and A2)1.
We also consider adjectives related by WordNet?s ?sim-ilar?
link, e.g., ?clean?
and ?pristine?, to be equal.
Two syntactic predicates ?match?
(i.e., are considered to denote the same semantic relation) according to the followingrules:1. both are the same;2. either is the predicate ?of?
or ?modifier?;3.
the predicates ?subject?
and ?by?
match (for passives);4. the two predicates are in a small list of special cases that should match e.g., ?on?and ?onto?.These rules for matching syntactic roles are clearly an approximation to match-ing semantic roles, but have performed better in our experiments than attempting toexplicitly assign (with error) semantic roles early on and then matching on those.In addition, in language, ideas can be expressed using different parts of speech(POS) for the same basic notion, e.g., verb or noun as in ?The bomb destroyed theshrine?
or ?The destruction of the shrine by the bomb?
(Gurevich et al, 2006).
Tohandle these cross-POS variants, when finding the word senses of a word (above) oursystem considers all POS, independent of its POS in the original text.
Combined withthe above predicate-matching rules, this is a simple and powerful way of aligningexpressions using different POSs, e.g.:?
?The bomb destroyed the shrine?
and ?The destruction of the shrine by thebomb?
(but not ?The destruction of the bomb by the shrine?)
are recognized asequivalent.?
?A person attacks with a bomb?
and ?There is a bomb attack by a person?
arerecognized as equivalent.?
?There is a wrecked car?, ?The car was wrecked?, and ?The car is a wreck?
(adjective, verb, and noun forms) are recognized as equivalent.Although clearly these heuristics can go wrong, they provide a basic mechanismfor assessing simple equivalence and subsumption between texts.1Clearly this can go wrong, e.g., if the contexts of T and H are different so repeated/matching wordshave incompatible intended senses, although such discontinuities are unusual in natural text.Augmenting WordNet for Deep Understanding of Text 492.3 Experimental Test BedAs an experimental test bed we have developed a publically available RTE-style testsuite2 of 250 pairs (125 entailed, 125 not entailed).
As our goal is deeper semanticprocessing, the texts are syntactically simpler than the PASCAL RTE sets (at www.pascal-network.org) but semantically challenging to process.
We use examplesfrom this test suite (and others) in this paper.3 Exploiting Lexical & World Knowledge3.1 Use of WordNet?s GlossesTranslation to Logic WordNet?s word sense definitions (glosses) appear to containsubstantial amounts of world knowledge that could help with semantic interpretationof text, and we have been exploring leveraging these by translating them into first-order logic.
We have also experimented with Extended WordNet (XWN), a similardatabase constructed several years ago by Moldovan and Rus (2001).To do the translation, a different language interpreter, developed by ISI, was used(for historic reasons?
BLUE was not available at the time the translations were done,and has not been exercised or extended for definition processing).
ISI?s system worksas follows: First each gloss is converted into a sentence of the form ?word is gloss?and parsed using the Charniak parser.
Then the parse tree is then converted into a log-ical syntax by a system called LFToolkit, developed by Nishit Rathod.
In LFToolkit,lexical items are translated into logical fragments involving variables.
Finally, as syn-tactic relations are recognized, variables in the constituents are identified as equal.
Forexample, ?John works?
is translated into John(x1) & work(e,x2)& present(e), where eis a working event, and then a rule which recognizes ?John?
as the subject of ?works?sets x1 and x2 equal to each other.
Rules of this sort were developed for a largemajority of English syntactic constructions.
ISI?s system was then used to translatethe modified WordNet glosses into axioms.
For example (rewritten from the originaleventuality notation):;;; "ambition#n2: A strong drive for success"ambition(x1) -> a(x1) & strong(x1) & drive(x1) & for(x1,x6) & success(x6)Predicates are assigned word senses using the new-ly released WordNet sense-tagged gloss corpus3.
This process was applied to all ?
110,000 glosses, but withparticular focus on glosses for the 5,000 ?core?
(most frequently used) synsets.
Itresulted in good translations for 59.4% of the 5,000 core glosses, with lower qualityfor the entire gloss corpus.
Where there was a failure, it was generally the result of abad parse, with constructions for which no LFToolkit rules had been written.
In thesecases, the constituents are translated into logic, so that no information is lost; whatis lost is the equalities between variables that provides the connections between theconstituents.
For instance, in the ?John works?
example, we would know that therewas someone named John and that somebody works, but we would not know that theywere the same person.
Altogether 98.1% of the 5,000 core glosses were translatedinto correct axioms (59.4%) or axioms that had all the propositional content but were2http://www.cs.utexas.edu/~pclark/bpi-test-suite/3http://wordnet.princeton.edu/glosstag50 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompsondisconnected in this way (38.7%).
The remaining 1.9% of these glosses had bizarrelywrong parses due to noun-adjective ambiguities or to complex conjunction ambigui-ties.Using the Glosses We have used a combination of these logicalized glosses and thosefrom XWN to infer implicit information from text.
Although the quality of the logicis generally poor (for a variety of reasons, in particular that the glosses were neverintended for machine processing in the first place), our software was able to inferconclusions that help answer a few entailment problems, for example:T: Britain puts curbs on immigrant labor from Bulgaria and Romania.H: Britain restricted workers from Bulgaria.using the logic for the definition:restrict#v1: "restrict", "restrain": place limits on.plus WordNet?s knowledge that: ?put?
and ?place?
are synonyms; ?curb?
and ?limit?are synonyms; and a laborer is a worker.
In our experiments, the glosses were used toanswer 5 of the 250 entailment questions (4 correctly).
More commonly, the glossescame ?tantalizingly close?
to providing the needed knowledge.
For example, for:T: A Union Pacific freight train hit five people.H: A locomotive was pulling the train.it seems that the definition:train#n1: "train", "railroad train": public transport providedby a line of railway cars coupled together and drawn by a locomotive.is very close to providing the needed knowledge.
However, unfortunately it definesa train as ?public transport provided by cars pulled by a locomotive?
rather than just?cars pulled by a locomotive?
(the locomotive pulls the cars, not the train/public-transport), hence the hypothesis H is not concluded.
Similarly:T: The Philharmonic orchestra draws large crowds.H: Large crowds were drawn to listen to the orchestra.essentially requires knowledge that crowds (typically) listen to orchestras.
WordNet?sglosses come very close to providing this, with knowledge that:orchestra = collection of musiciansmusician = someone who plays musical instrumentmusic = sound produced by musical instrumentslisten = hear = perceive soundHowever, the connection that the playing results in sound production is missing,and hence again H cannot be inferred.
These experiences with the WordNet glosseswere very common.
In summary, our experience is the WordNet glosses providedsome value, being used 5 times (4 correctly) on the 250 examples in our test suite,Augmenting WordNet for Deep Understanding of Text 51with the short, simple definitions (e.g., bleed = lose blood) being the most reliable.The low quality of the logic was a problem (definitional text is notoriously difficult tointerpret automatically (Ide and Veronis, 1993)), although often the knowledge cameclose.
Finally, 110,000 rules (approx.
one per gloss) is actually quite a small number;typically only 10?s of rules fired per sentence, rarely containing the implications wewere looking for.3.2 Typed Morphosemantic LinksWordNet contains approximately 21,000 links connecting derivationally related verband noun senses, e.g., employ#v2-employee#n1; employ#v2-employment#n3.
Theselinks turn out to be essential for mapping between verbal and nominalized expressions(e.g.
using ?destroy?-?destruction?, as mentioned earlier).
However, the current linksdo not state the semantic type of the relation (e.g., that employee#n1 is the UNDER-GOER of an employ#v2 event; employment#n3 is the employ#v2 EVENT itself),which limits WordNet?s ability to help perform semantic role labeling.
In addition,not being able to distinguish the semantics of the relationships can cause errors inreasoning, for example distinguishing between H1 and H2 in:T: Detroit produces fast cars.H1: Detroit?s product is fast.H2?
: Detroit?s production is fast.
[NOT entailed]T: The Zoopraxiscope was invented by Mulbridge.H1: Mulbridge was the inventor of the Zoopraxiscope.H2?
: Mulbridge was the invention of the Zoopraxiscope.
[NOT entailed]To type these links, we have used a semi-automatic process: First, the computermakes a ?guess?
at the appropriate semantic relation based on the morphological re-lationship between the noun and the verb (e.g., ?A?IJ-er?A?I?
nouns usually refer to theagent), and the location of the two synsets in WordNet?s taxonomy.
Second, a humanvalidates and corrects these, a considerably faster progress than entering them fromscratch.
9 primary semantic relations (as well as 5 rarer ones) were used, namely:agent (e.g., employ#v2-employer#n1)undergoer/patient (e.g., employ#v2-employee#n1)instrument (e.g., shred#v1-shredder#n1)recipient (e.g., grant#v2-grantee#n1)result (e.g., produce#v2-product#n2)body-part (e.g., adduct#v1-adductor#n1)vehicle (e.g., cruise#v4-cruiser#n3)location (e.g., bank#v3-bank#n4)identity/equality (eg employ#v2-employment#n1)The resulting database of 21,000 typed links was recently completed, constitutinga major new addition to WordNet in support of deep language processing.
One of thesurprising side results of this effort was discovering how often the normal morpholog-ical defaults (e.g., ?-er?
nouns refer to agents) are violated, described in more detail inFellbaum et al (2007).
We are now in the process of incorporating the database intoour software.52 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompson3.3 Core TheoriesWhile WordNet?s glosses and links contain world knowledge about specific entitiesand relations, there is also more fundamental knowledge about language and the world?
e.g., about space, time, and causality ?
which is essential for understanding manytypes of text, yet is unlikely to be expressed in dictionary definitions or automaticallylearnable.
To address this need, we are also encoding by hand a number of theories tosupport deeper reasoning (in the style of lexical decomposition).
We have axiomatizeda number of abstract core theories that underlie the way we talk about events and eventstructure (Hobbs, 2008).
Among these are theories of composite entities (things madeof other things), scalar notions (of which space, time, and number are specializations),change of state, and causality.
For example, in the theory of change of state, thepredication change(e1,e2) says there is a change of state from state e1 to state e2.
Thepredication changeFrom(e1) says there is a change out of state e1.
The predicationchangeTo(e2) says there is a change into state e2.
An inference from changeFrom(e1)is that e1 no longer holds.
An inference from changeTo(e2) is that e2 now does hold.In the theory of causality (Hobbs, 2005), the predication cause(e1,e2), for e1 causese2, is explicated.
One associated inference is that if the causing happens, then theeffect e2 happens.
A defeasible inference is that not-cause-not often is the same ascause:not(cause(x,not(e)))?
cause(x,e)In the rightward direction this is of course sometimes wrong, but if we go to thetrouble of saying that the negation of something was not caused, then very often it isa legitimate conclusion that the causing did happen.We are connecting these theories with WordNet by mapping the core (5,000 mostcommon) WordNet synsets to the theory predicates.
For example, the core part ofWordNet contains 450 word senses having to do with events and event structure, andwe are in the process of encoding their meanings in terms of core theory predicates.For example, if x lets e happen (WordNet sense let#v1), then x does not cause e not tohappen:let#v1(x,e)?
not(cause(x,not(e)))One sense of ?go?
is ?changeTo?, as in ?I go crazy?go#v4(x,e)?
changeTo(e)(The entity x is the subject of the eventuality e.) If x frees y (the verb sense of ?free?
),then x causes a change to y being free (in the adjective sense of ?free?):free#v1(x,y)?
cause(x,changeTo(free#a1(y)))Given these mappings and the core theories themselves, this is enough to answerthe entailment pair:T: The captors freed the hostage.H: The captors let the hostage go free.Augmenting WordNet for Deep Understanding of Text 53via successive application of the above axioms:(part of) H interpretation?
let(x,go(y,free(y)))?
not(cause(x,not(changeTo(free#a1(y)))))?
cause(x,changeTo(free#a1(y)))?
free#v1(x,y)We are still in the early stages of developing this resource and have not yet evaluatedit, but we have already seen a number of examples of its potential utility in the textinference problem such as above.3.4 ScriptsSimple inference rules, such as in the above resources, provide a direct means ofdrawing conclusions from a few words in the input text.
However, they are largelycontext-independent, i.e., not sensitive to the bigger picture which the surroundingtext provides.
Consider the following example:T: A dawn bomb attack devastated a major shrine.H: The bomb exploded.In this case, it is hard to express the required knowledge (to conclude H followsfrom T) as simple rules (e.g., the rules ?bomb ?E??
bomb explode?
or ?bomb attack?
bomb explode?
are not adequate, as we do not want H to follow from ?The policedestroyed the bomb.?
or ?The bomb attack was thwarted?).
Rather, when a personreads T, he/she recognizes a complete scenario from multiple bits of evidence (possi-bly in multiple sentences), and integrates what is read with that scenario.
This kind oftop-down, expectation-driven process seems essential for creating an overall, coherentrepresentation of text.Although scripts are an old idea (e.g., (Schank and Abelson, 1977)) there are rea-sons their use may be more feasible today.
First, rapid advances in paraphrasing sug-gests that the matching problem ?
deciding if some text is expressing part of of ascript ?
may be substantially eased.
(Script work in the ?70s required stories tobe worded in exactly the right way to fire a script).
Second, two new approches foramassing knowledge are available today that were not available previously, namely au-tomated learning from corpora, and use of Web volunteers (e.g., (Chklovski, 2005)),and may be applicable to script acquisition (Script work in the ?70s typically workedwith tiny databases of scripts).
Finally, techniques for language processing have sub-stantially improved, making core tasks (e.g., parsing) less problematic, and openingthe possibility to easy authoring of scripts in English, followed by machine interpre-tation.
FrameNet (Baker et al, 1998) already provides a few small scripts, but doesnot currently encode the complex scenarios that we would like; a vastly expandedresource would be highly useful.We are in the early stages of exploring this avenue, encoding scripts as a list ofsimple English sentences, which are then automatically translated to WordNet-sensetagged logic using our software.
For example, a ?bombing?
script looks:A building is bombed by an attacker.The attacker plants the bomb in the building.54 Clark, Fellbaum, Hobbs, Harrison, Murray, and ThompsonThe bomb explodes.The explosion damages or destroys the building.The explosion injures or kills people in the building.In addition, some of these sentences are flagged as ?salient?.
If any salient sentencematches (subsumes) part of the text, then the script is triggered.
When triggered,a standard graph-matching algorithm searches for the maximal overlap between theclauses in the (interpreted) script and the clauses in the text, and then the script isunified with the text according to that maximal overlap, thus asserting the additionalfacts contained in the script to the text under consideration.
In the example earlier,the script is triggered by, and matched with, the text, thus aligning ?building?
with?shrine?, and asserting additional facts including (the logic representation of) ?Thebomb explodes?
and ?The bomb was planted in the building.
?.3.5 Using DIRT ParaphrasesLike others, we have also explored the use of the DIRT paraphrase database for rea-soning, and we report our experiences here for comparison.
The database contains12 million rules, discovered automatically from text, of form (X relation1 Y) ?
(Xrelation2 Y), where relation is a path in the dependency tree/parse between constitu-tents X and Y.
Although they are noisy (informally, about 50% seem reliable), theyprovided some leverage for us also, for example correctly answering:T: William Doyle works for an auction house in Manhattan.H?
: William Doyle never goes to Manhattan.
[NOT entailed]using the DIRT rule ?IF Y works in X THEN Y goes to X?
combined with negation,andT: The president visited Iraq in September.H: The president traveled to Iraq.using the (slightly strange but plausible) DIRT rule ?IF Y is visited by X THEN Xflocks to Y?
and that ?A?IJflock?A?I?
is a type (hyponym) of ?A?IJtravel?A?I?.
In ourexperiments, DIRT rules were used 47 times (27 correctly) on our 250 example testsuite.
The main cause of incorrect answers was questionable/incorrect rules in thedatabase, e.g.
:T: The US troops stayed in Iraq.H?
: The US troops left Iraq.
[NOT entailed]was found to be entailed using the DIRT rule ?IF Y stays in X THEN Y leaves X?.In addition, DIRT does not distinguish word senses (e.g., according to DIRT, shootinga person/basket implies killing the person/basket and scoring a person/basket), alsocontributing errors.Despite this, the DIRT rules were useful because they go beyond just the defini-tional knowledge in WordNet.
For example, according to DIRT ?X marries Y?
im-plies, among other things: Y marries X; X lives with Y; X kisses Y; X has a child withY; X loves Y ?
all examples of plausible world knowledge.
The main limitations weAugmenting WordNet for Deep Understanding of Text 55found were they were noisy, did not account for word senses, and only cover one rulepattern (X r1 Y?
X r2 Y).
So, for example, a rule like ?X buys Y?
X pays Money?is outside the expressive scope of DIRT.4 Preliminary EvaluationAlthough this is work in progress, we have evaluated some of these augmentationsusing our test suite.
As our ultimate goal is deeper understanding of text, we have de-liberately eschewed using statistical similarity measures between T and H, and insteadused abductive reasoning to create an axiom-elaborated representation of T, and thenseen if it is subsumed by H. Although not using statistical similarity clearly hurts ourscore, in particular assuming ?no entailment?
when the elaborated representation of Tis not subsumed by H, we believe this keeps us appropriately focused on our longer-term goal of deeper understanding of text.
The results on our 250 pairs currently are:H or ?H predicted by: Corrrect IncorrectSimple syntax manipulation 11 3WordNet taxonomy + morphosemantics 14 1WordNet logicalized glosses 4 1DIRT paraphrase rules 27 20H or ?H not predicted: Corrrect Incorrect(assumed not entailed) 97 72Thus our overall score on this test suite is 61.2%.
We have also run our software onthe PASCALRTE3 dataset (Giampiccolo et al, 2007), scoring 55.7% (excluding caseswhere no initial logical representation could be constructed due to parse/LF generationfailures).
In some cases, other known limitations of WordNet (eg.
hypernym errors,fine-grained senses) also caused errors in our tests (outside the scope of this paper).However, the most significant problem, at least for these tests, was lack of worldknowledge.5 ConclusionA big challenge for deep understanding of text ?
constructing a coherent represen-tation of the scene it is intended to convey ?
is the need for large amounts of worldknowledge.
We have described our work-in-progress to augment WordNet in vari-ous ways so it can better provide some of this knowledge, and described some initialexperiences with those augmentations, as well as with the DIRT database.
ExistingWordNet aleady provides extensive leverage for language processing, as evidencedby the large number of groups using it.
The contribution of this paper is some pre-liminary insight into avenues and challenges for further developing this resource.
Al-though somewhat anecdotal at this stage, our experience suggests the augmentationshave promise for further improving deep language processing, and we hope will resultin a significantly improved resource.Acknowledgements This work was performed under the DTO AQUAINT program,contract N61339-06-C-0160.56 Clark, Fellbaum, Hobbs, Harrison, Murray, and ThompsonReferencesAdams, R., G. Nicolae, C. Nicolae, and S. Harabagiu (2007).
Textual entailmentthrough extended lexical overlap and lexico-semantic matching.
In Proc.
ACL-PASCAL Workshop on Textual and Entailment and Paraphrasing, pp.
119?124.Baker, C. F., C. J. Fillmore, and J.
B. Lowe (1998).
The Berkeley FrameNet project.In C. Boitet and P. Whitelock (Eds.
), Proc 36th ACL Conf., CA, pp.
86?90.
Kauf-mann.Chambers, N., D. Cer, T. Grenager, D. Hall, C. K. MacCartney, M.-C. de Marneffe,D.
R. Yeh, and C. D. Manning (2007).
Learning alignments and leveraging naturallogic.
In Proc.
ACL-PASCAL Workshop on Textual and Entailment and Paraphras-ing, pp.
165?170.Chklovski, T. (2005).
Collecting paraphrase corpora from volunteer contributors.
InProc 3rd Int Conf on Knowledge Capture (KCap?05), NY, pp.
115?120.
ACM.Clark, P. and P. Harrison (2008, September).
Boeing?s NLP System and the Chal-lenges of Semantic Representation.
In J. Bos and R. Delmonte (Eds.
), Semanticsin Text Processing.
STEP 2008 Conference Proceedings, Venice, Italy.Fellbaum, C. (1998).
WordNet: An Electronic Lexical Database.
Cambridge, MA:MIT Press.Fellbaum, C., A. Osherson, and P. Clark (2007).
Putting semantics into wordnet?smorphosemantic links.
In Proc.
3rd Language and Technology Conference, Poz-nan, Poland.Giampiccolo, D., B. Magnini, I. Dagan, and B. Dolan (2007).
Textual entailmentthrough extended lexical overlap and lexico-semantic matching.
In Proc.
ACL-PASCAL Workshop on Textual and Entailment and Paraphrasing, pp.
1?9.Graesser, A. C. (1981).
Prose Comprehension Beyond the Word.
NY: Springer.Gurevich, O., R. Crouch, T. King, and V. de Paiva (2006).
Deverbal nouns in knowl-edge representation.
In Proc.
FLAIRS?06.Harrison, P. and M. Maxwell (1986).
A new implementation of GPSG.
In Proc.
6thCanadian Conf on AI (CSCSI-86), pp.
78?83.Hobbs, J.
(2005).
Toward a useful notion of causality for lexical semantics.
Journalof Semantics 22, 181?209.Hobbs, J.
(2008).
Encoding commonsense knowledge.
Technical report, USC/ISI.http://www.isi.edu/?hobbs/csk.html.Ide, N. and J. Veronis (1993).
Extracting knowledge-bases from machine-readabledictionaries: Have we wasted our time?
In Proc KB&KB?93 Workshop, pp.
257?266.Augmenting WordNet for Deep Understanding of Text 57Lenat, D. and R. Guha (1989).
Building Large Knowledge-Based Systems.
MA:Addison-Wesley.Miller, G. (1995).
WordNet: a lexical database for english.
Comm.
of theACM 38(11), 39?41.Moldovan, D. and V. Rus (2001).
Explaining answers with extended wordnet.
InProc.
ACL?01.Schank, R. and R. Abelson (1977).
Scripts, Plans, Goals and Understanding.
Hills-dale, NJ: Erlbaum.Schubert, L. and C. Hwang (1993).
Episodic logic: A situational logic for NLP.
InSituation Theory and Its Applications, pp.
303?337.
