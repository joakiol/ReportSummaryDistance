A Practical Evaluation of an Integrated Translation Tool duringa Large Scale Localisation ProjectReinhard SchKlerDepartment of Computer Science, University College Dublin,Belfield, Dublin 4, Irelandreinhard@nova, ucd.
ieAbstractThis paper reports on the assessment of computerassisted translation tools for a large localisation com-pany and the practical evaluation of one such tool.IntroductionOver the past two years, a number of integratedtranslation tools which include a translation edi-tor, an on-line terminology database and a transla-tion memory system became commercially available.Most of these tools were targeted at the software lo-calisation industry, where the ability to produce con-sistent translations of highly repetitive texts withintight deadlines determines valuable market shares inan increasingly competitive market.The level of sophistication these tools havereached is still quite embryonic.
Potential usershave, in most cases, no practical experience with theissues involved in the application of such tools.
Theyseek advice from experts who they feel can evaluatethe systems in question for them, but even the ex-perts have not yet agreed on a standard evaluationapproach.This paper reports on the assessment of computerassisted translation tools for a large localisation com-pany and the practical evaluation of one such toolduring a large scale localisation project which in-volved the translation of around 1 million words into9 languages at several different locations.The localisation of software and software docu-mentation, for a variety of reasons, is an idea\] ap-plication area for the new generation of electronictranslation tools (Translators' Workbenches), whichintegrate a translation editor, an electronic dictio-nary look-up system and a translation memory fea-ture (cf.
Ishida 1994):Text in software and the accompanying docu-mentation is highly repetitive (up to 30%).Translation often starts at a H-stage.
When thetranslation has to be updated to the final pro-duction version, Translators' Workbenches candetect modifications made to the original sourcefile and automatically insert text that has pre-viously been translated.New releases of the same product have to belocalised at ever decreasing intervals (every 9months approximately).In this paper, we report that even one of the mostsophisticated tools currently available still containsa considerable number of undesirable features manyof which cannot, realistically, be identified duringan initial test period.
We also note that there aremajor critical issues not connected to any particulartool which have up to now been overlooked by bothdevelopers and potential users.Project BackgroundIn 1992, we were approached by one of the major lo-calisation companies in Ireland to assist them withthe assessment of two Translators' Workbenches.Our initial brief was to recommend one of the twotranslation tools for use in the company's operation.There are no standard evaluation procedures forpotential buyers of translation memory systems andnone of the evaluation methods proposed for ma-chine translation systems (cf.
Machine Translation1993) is suitable because they are either too costly(translation memory systems cost a fraction of MTsystems) or they are simply inappropriate (becauseof the conceptual difference between MT and CATtools).Our assessment, herefore, had to rely on ourknowledge of the localisation industry and its re-quirements, and was limited by the resources atour disposal.
Our recommendation f the TRADOSTranslator's Workbench II (TWII)  was based largelyon practical issues of cost and portability.In autumn 1993, the company decided to use thetool for a large scale project (10 languages, roughlyone million words/language, 60 translators 10 coun-tries).
As far as we are aware, this was the first timethat TWII  (one of the market leaders in the area ofCAT) was put to a major practical test.In order to help with evaluation of the tool, thetranslators were asked to fill in a one page question-192naire.
Unfortunately, the response rate was very loweven after we had sent out a reminder (2 out of 10)*.Unsurprisingly, by far the best source of informationabout the performance of the tools under industrialconditions proved to be the queries and the Perfor-mance Reports forwarded to our support engineers.It is these reports, in addition to an, at times, over-whelming number of queries communicated bytele-phone and fax, on which the following practical eval-uation of the TRADOS Translators' Workbench IIis based.A Pract ical  Evaluat ionAll modules, the translation editor, the MultiTermterminology database, the translation memory mod-ule and the utility programs, revealed undesirablefeatures over the course of the project.
Of theseby far the most serious flaws were discovered in theTranslation Memory (TM) module which had beenexpected to be the most useful module.
Because ofthe impact his had on the overall performance ofthetool, we will concentrate on some of the unexpectedfeatures of the TM module.Segmentat ion of the source file: A number ofproblems were caused by the way in which TWIIsegments a file.
What TWII identifies as a segmentis rigidly defined by the program (TRADOS 1992).Apart from adding entries to a user definable abbre-viation list, there is no way to modify this definitionto cater for project specific circumstances.
Shoulda text not contain any formatting tags, TWII willsimply fail to segment i properly.
This is unaccept-able in view of the fact that translators often haveto deal with incorrectly or partially formatted text,and TWII should be capable of correctly segmentingplain ASCII files.Definit ion of  a 100% match:  The automaticsearch for and the "translation" ofpreviously trans-lated sentences i  generally seen as probably themost useful feature of this type of program (S. Bell1993).
Our experience showed that the definition ofa 100% match is not quite as clear as the developersand, admittedly, we ourselves had believed.
Indeed,the definition of a 100% match is one of the mostproblematic features.Storing Target Language Sentence Pairs: Nosafety mechanisms prevented translators and editorsform corrupting TM by storing target language sen-tence pairs in TM.The most frequent interference with the integrityof translation memories occured when a translatedsegment was edited outside TM mode.
This prob-lem had been explained to translators but under theThis was in line with the experience made during otherMT evaluation projects (Vasconcellos 1994) and con-firmed the view that questionnaires axe not an efficientway to gather information from users.pressure of deadlines and the need to produce trans-lations quickly, the warning was often overlooked.Once a segment had been edited outside TM mode,the automatic "translation" features of TWII be-came useless.Translat ion memory  at t r ibutes:  TWII can onlystore a single translation for any particular sourcesegment into TM, unless translators use differentTM attributes for their translations.
Sometimes,however, it proved necessary to translate the samesource segment occurring twice into two differenttarget segments.
This again made the automatic"translation" of source text impossible as TWII isnot able to switch between different attributes auto-matically.ConclusionsThe most interesting feedback we received was thecomment that translation memory based systems areprobably very useful for inexperienced translatorswho could draw on the knowledge and the examplessupplied by the translation memory.
Professionals,however, who translate up to 7,000 words a day usinga dictaphone and the services of two highly skilledtypists would almost certainly be slowed down bythe "cumbersome" translation process enforced bythe program.Without any doubt, the new generation of inte-grated translation tools are of great value to the lo-calisation industry.
They can speed up the transla-tion process, improve the quality of the translationby insuring a higher degree of consistency and bringdown translation costs significantly.However, our experience with the TRADOSTranslators' Workbench II, probably the best in-tegrated tool currently available, has shown that,while translators will have to acquire the necessarytechnical skills to work effectively with these tools,developers will have to work more closely with theircustomers inorder to produce tools which meet heirrequirements.REFERENCESS.
Bell (1993) 'q~ranslators' Workbench II", Lan-guage International 5(3), 5-7R.
Ishida (1994) "Future Translation Workbenches:Some Essential Requirements", The LocalisationIndustry Standards Association (LISA) ForumNewsletter (III) February, 3-12Machine Translation (1993), Special Issue on theEvaluation of MT Systems, (8)1-2TRADOS (1992) Translators' Workbench II, User'sGuide, Stuttgart.M.
Vasconcellos (1994) "The Current State of MTUsage", The Localisation Industry Standards Associ-ation (LISA) Forum Newsletter, (III) February, 21-29193
