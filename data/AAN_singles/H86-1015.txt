TAG's  as a Grammat ica lFormal i sm for Generat ionDavid D. McDonald and James D. PustejovskyMarch, 1985CPTM #sThis paper will be presented at and published in The Proceedings of the 23rd AnnualMeeting of the Association for Computational Linguistics, July 8-12, 1985, University ofChicago.146I ,  A lbst raetTree Adjolni-~ Grammars, or "rAG's", (Joshi, Levy & Takahashi 1975; Joshi 1983;Kroch & Joshi 1985) were developed as an alternative to the standard syntacticformalisms that are used in theoretical analyses of language.
They are att~=,~ctivebecause they may provide just the aspects of context sensitive expressive power thatactually appear in human languages while otherwise remaining context free.This paper describes how we have applied the thmry of Tree Adjoinln~ Grammarsto natural language generation.
We have been attracted to TAG's because theircentral operat ion-the extension of an "initial" phrase ~hucture tree through theinclusion, at very specifically constrained locations, of one or more "auxiliary"trees--corresponds directly to certain central operations of our own,performance-oriented theory.We begin by briefly describing TAG's as a formalism for phrase structure in acompetence theory, and summarize the points in the theory of TAG's that aregermaine to our own theory.
We then consider generally the position of a grammarwithin the generation process, introducing our use of TAG'S through a contrast withhow others have used systemic grammars.
This takes us to the core results of ourpaper: using examples from our research with weft-written texts from newspapers, wewalk through our TAG inspired treatments of raising and wh-movement, and show thecorrespondence of the TAG '%djunction" operation and our "attachment" process.In the final section we discuss extensions to the theory, motivated by the way weuse the operation corresponding to TAG'S" adjunction in performance.
This suggeststhat the competence theory of TAG's can be profitably projected to structures at themorphological level as well as the present syntactic level.2.
T ree  Ad junct ion  GrammarsThe theoretical apparatus of a TAG consists of a pr/mitively defined set of"elementary" phrase structure trees, a '~xking" relation that can be used to definedependency relations between two nodes within an elementary tree, and an "adjunction"operation that combines trees under specifiable constraints.
The elementary trees aredivided into two sets: init/a_l and auxiliary.
Initial trees have only terminals at theirleaves.
Auxiliary trees are distinguished by having one non-terminal among their leaves;the category of this node must be the same as the category of the root.
Allelemental trees are "minimal" in the sense that they do not recurse on anynon-terminal.A node N1 in an elementary tree may be linked (co-indexed) to a second nodeN2 in the same tree provided NI c-commands N2.
Linking is used to indicategrammatically defined dependencies between nodes inch as mbcategorization relationshipsor filler-gap dependencies.
Links are preserved (though "stretched out") when their treeis extended through adjunction; this is the mechanism TAG's use to representunbounded ependencies.147Sentence derivations tart with an initial tree, and continue via the adjunction o fan arbitrary number of auxiliary trees.
To adjoin an auxiliary tree A with rootcategory X to a initial (or derived) tree T, we f i rst  select mine node of category Xwithin T to be the point at which the ad~.mction is to occur.
Then (1) the subtree ofT dominated by that instance of X (call it X')  is removed from T, (2) the auxiliarytree A b knit into T at the position where X" had been located, and (3) the subtreedominated by X" b knit into A to replace the second occurence of the category X atT's frontier.
The two trees have now been merged by '%pricing" A into T, displacingthe subtree of T at the point of the adjunction to the frontier of A.For example we could take the initial tree:IS" Wh?i does IS John like e i \] \](the subscript "i" indicates that the "who" and the trace "e" are linked) and adjoin toit the auxiliary tree:\[S Bill befieves S \]to produce the derived tree:IS" Wh?i does IS Bill believe IS John likes e i \] \] \]Adjunction may be "constrained".
The grammar writer may specify which specifictrees may be adjoined to a given node in an elementary tree; if no specification isgiven the default is that there is no constraint and that any auxiliary tree may beadjoined to the node.2.1 Key features of the theory of TAG'sA TAG specifies surface structure.
There is no notion of derivation from deepstructure in the theory of TAG's- - the primitive trees are not transformed or otherwisechanged once they are introduced into a text, only combined with other primitive trees.As Kroch and Joshi point out, this means that a TAG is incomplete as an account ofthe structure of a natural language, e.g.
a TAG grammar will contain both an activeand a passive form of the same verbal subcategorizafion pattern, without antheory-mediated description of the very close relationship between them.To our minds this is by no means a deficit.
The procedural machinery thatgenerative grammars have traditionally carried with them to characterize relations likethat of active to passive has only gotten in the way of employing thosecharacterizations in processing models of generation.
This is because a generationmodel, like any theory of performance, has a procedural structure of its own andcannot coexist with an incompatible one, at least not while still operating efficiently orwhile retaining a simple mapping from its actual machine to the virtual machine thatits authors put forward as their account of psycholinguistic data.Our own generator uses surface siJucture as its only expficitly represented linguisticlevel.
Thus grammatical formalisms that dwell on the rules governing surface form aremore useful to us than those that hide those rules in a deep to surfacetransformational process.148?A TAG Involvw the tmmlpuladon of very small dementary structmrw.
This isbecause of the stip,,Indon that elementary trees may not induck recurtive nodes.
Itimpliea that the sentences one tee, in everyday usage, e.g.
newpaper texts, are theresult of many tucemive adjunctions.
This melds nicely with a move that we havemack in recent yeatt to view the conceptual representation from which generationproceeds as comiging of a heap of very small, reduadaatly related information unitsthat have been deliberatebj selected by a text planning process from the total state ofthe kaowledge base at the time of utterance; each satch unit will correspoad in thefinal text to a head lexical item plus selected thematic arguments--a linguistic entitythat is easily projected onto the elementary trees of a TAG.TAG theory ladmles only one operation, adJnnctlon, and otherwise makes nochanges to the elementary trees that go into ?
text, This comports well with theindefibility stipulation in our model of generation, dnce selected text fragments can beused directly as specified by the grammar without the need for any latertransformation.
The composition options delimited by the constraints on adjunctiongiven with a TAG define a space of alternative text forms which can corresponddirectly in generation to alternative conceptual relations among information units,alternatives in rhetorical intent, and alternatives in prose style.3.
Adapting TAG's to GenerationThe mapping from TAG's as a formalism for competence theories of language toour formalism for generation is strikingly direct.
Their adjuncti0n operation correspondsto our "attachment process"; their constraaints on adjunction correspond to our"attachment points"; their surface structure trees correspond to our surface structuretrees.
1 We further hypothesize that two quite strong correspondence claims can bemade, though considerably more experimentation and theorizing will have to be donewith both formalisms before these claims can be confirmed.1.
The primitive information units in realization specifications can be realizedexclusively as one or another elementary tree as defined by a suitable TAG,i.e.
linguistic criteria can be used in determining the proper modularity of theconceptual structure.
22.
Conversely, for any textual relationship which our generator would derive bythe attachment of multiple information units into a tingle package, there is acorresponding rule of adjunction.
Since we use attachment in the  realizationof nominal compouads like "o// tanker", this has the force of extending thedomain of TAG analyses into morphology.
(See section 7).1 Our model of generation does not employ the ample trees of labeled nodes that appear in mosttheoretical linguistic amtlytet Our turfa~ ttructurc incorporates the igmantic propertim of trees, butit also incJ,vt-,, rcifx=ttions of consdtmmt positions like "subject" or "acntem:e" and is bcttg~rcharacterized overall as an "executable aequence of labeled positions".
We discuss this further in::section 5.1.21f this iqq:x)tlm is mcemfui, it has very comequenfial ;mnlicadonl for thz "~.?"
of theinformation units that tbe text planner constructing tim realization specification can me, e.g.
they wouldnot be r~y.,~t at texts that include recmtiv, nodes.
We will discuss this and other implications in ?later ~ .
1494. l\[ e Place of Gramnmr in a Theory of GenerationTo understand why we are looking at TAG's  rather than some other formalism,one must first understand the role of grammar within our processing model.
Thefollowing is a brief summary of the model ;  a more complete description can be foundin McDonald & Pustejovsky \[1985b\].We have always had two complementary goals in our research: on the one handour generation program has had to be of practica~l utility to the knowedge based expertsystems that use it as part of a natural language interface.
This means thatarchitecturally our generator has always been designed to produce text from conceptualspecifications, ~plans", developed by another program and consequently has had to besensitive to the limitations and varying approaches of the present state of the art inconceptual representation.At  the same time, we want the architecture of the virtual machine that weabstract out of our program to be  effective as a source of psycholinguistic hypothesesabout the actual generation process that humans use; it should, for example, providethe basis for predictive accounts of human speech error behavior and apparent planninglimitations.
To achieve this, we have restricted ourselves to a highly constrained set ofrepresentations and operations, and have adopted strong and suggestive stipulations onour design such as high locality, information encapsulation, online quasi-realtime runtimeperformance, and indelibility) This restricts us as programmers, but disciplines us astheorists.We see the process of generation as involving three temporally intermingledactivities: (1) determining what goals the utterance is to achieve, (2) planning whatinformation content and rhetorical force will best meet those goals given the context,and (3) realiz/ng the specified information and rhetorical intent as a grammatical text.Our linguistic component (henceforth LC), the Zetalisp program MUMBLE, handles thethird of these activities, taking a "realiTztion specification "4 as input, and producing astream of morphologically specialiTed words 5 as output.As described in \[McDonald 1984\], our LC is a "description-directed" process: it usesthe structure of the realization specification it is given, plus the syntactic surfacestructure of the text in p ro~ss  (which it extends incrementally as the specification isrealized) to directly control its actions, interpreting them as though they were sequentialcomputer programs.
This technique imposes strong demands on the descriptiveformalima used for representing surface structure.
For example, nodes and categorylabeis now designate actions the generator is to take (e.g.
imposing scoping relationsor constraining embedded decisions) and dictate the inclusion of function words andmorphological specializations.3 "~ty"  in a computation requires that no action of a process (making decisions, constructingrepreseatations, chan8~ state, etc.)
can be tramparently undone once it has been performed.
Manynonbacktracking, nonfntra~ program designs have this property; it is our term for what Marcus \[1980\]referred to as the property of being "strictly determlnhtic'.4A  realization specification can informally be taken to correspond to what many researchers,partioti~iy p~hok~t .% lhink of Its the "me~tge love.J" g~Utt ion  of a text.5 Which is to say tb~t it presently produces written rath~ .hn ~ok~ U~UI.
We e~rp?~ tO workwith speech output shortly, howev~, sad the need to support the ~tat iona l  basis of anintonational contour is begi~n?
to influence our dcsigns for constituency patterns in surface structure.1504J Unb d s Gmm.nOf the egablished linguistic formalisms, systemic grammar \[Halliday 1976\] hasalways been the most important to AI researchers on generation.
Two of the mostimportant generation systems that have been developed, PROTEUS \[Davey 1974\] andNIGPJ- \[Mann & Matthieuen 1983\], use systemic grammar, and others, including ourown, have been strongly influenced by it.
The reasons for this enthusiamn are centralto the special concerns of generation.
Systemic grammars employ a functionalvocabulary: they emphasize the uses to which language can be put--how languagesachieve their speakers" goals-rather than its formal structure.
Since the generationprocess begins with goals, unlike the comprehem/on process which begins with structure,this orientation makes systemic grammars more immediately useful than, for example,transformational generative grammars or even procedurally oriented AI formalisms forlanguage such as A TN's.The generation researcher's primary question is why use one construction ratherthan another--active instead of passive, "the" instead of "a".
The principle device of asystemic grammar, the "choice sy~em", supports this question by highlighting how theconstructions of the language are grouped into sets of alternatives.
Choice systemsprovide an anchoring point for the rules of a theory of language use since it is naturalto a~ociate the various semantic, discourse, or rhetorical criteria that bear on theselection of a given construction or feature with the choice system to which theconstruction belongs, thus providing the basis of a decision-procedure for selecting fromits listed alternatives; the NIGEL system does precisely this in its "chooser" procedures.In our formalism we make use of the same information as  a systemic grammarcaptures, however we have choosen to bundle it quite differently.
The  underlying reasonfor this is that our concern for psycholinguistic modeling and efficient processing takesprecedence in our design decisions about how the facts of language and language useshould be represented in a generator.
It is thus instructive to look at the differentkinds of linguistic information that a network of choice systems carry.
In our systemwe distribute these to separate computational dev/ces.o Dependencies among structural features: A generator must respect theconstraints that dependencies impose and appreciate the impact they have on itsrealization options: for example that some subordinate clauses can not expresstense or modality while main clauses are required to; or that a pronominaldirect object forces particle movement while a lexical object leaves it optional.o Usage criteria.
The decision procedures amoc/ated with each choice system arenot a part of the grammar per se, although they are naturally associated with itand organized by it.
Also most systemic grammars include very abstractfeatur~ such as "generic reference" or "completed action", which cross-correlatethe language's urface features, and thus are more controllers of why a constructis used rather than conshucts themselves.o Coordinated structural alternatives.
A sentence may be either active or passive,either a question or a statement.
By groupin 8 these alternatives into systemsand using these systems exdusively when constructing a text, one is guaranteednot to combine inconsistent structural features.
"7o Efficient ordering of choices.
The network that connect, choice t~stems providesa natural path between decisiom, which if followed strictly guarentees that achoice will not be made un lm it is required, and that it will not be madebefore any of the choic_~___ that it it itself dependent upon, insuring that it can151be made indelibly.
~o Typology of sm'face structure.
Almost by accident (dnce its specification isdhgtributed throughout all of the systems impficitly), the grammar determines thepattern of dominance and comtituency relationshiln of the text.
While not aprinciple of the theozy, the trees of clanses, NP% etc.
in systemic grammars tendto be shallow and broad.We believe, but have not yet established, that equivalence transformations can bedefined that would take a systemic grammar as a q3ecification to construct thealternative devices that we use in our generator (or auement devices that derive fromother sources, e.g.
a TAG) by decomposing the information in the systemic grammaralong the lines just listed and redistributing it.5.
Example AnalysesOne of the task domains we are currently developing involves newspaper eports ofcurrent events.
We are "reverse engineering" leading paragraphs from actual newspaperarticles to produce narrow but complex conceptual representation, and then desiEningrealization specifications--plans--that will lead our LC to reconstruct the original text ormotivated variations on it.
We have adopted this domain because the news reportingtask, with its requirement of communicating what is new and si!,nificant in an event aswell as the event itself, appears to impose exceptionally rich constraints on the selectionof what conceptual information to report and on what syntactic constructions to use inreporting it (see discussion in Ciipplnger & McDonald \[1983 D. We expect to fred outhow much complexity a realization specification requires in order to motivate suchcarefully composed texts; this will later guide us in designing a text planner withsufficient capabilities to construct such specifications on its own.Our examples are drawn from the text fragment below (Associated Press, 12/23/84);the realization specification we use to reproduce the text follows.
"LONDON - Two oil tankers, the Norwegian-owned Thorshavet end aUben'en-registered v~__el, were reported to have been hit by missiles Friday in theGuff.The Thorshavet was ablaze end under tow to Bahrein, officiels in Oslo said.Uoyds reported that two crewmen were Injured on the Ubenan ship.
"(the-day" Hvents-~-the-GU~-tanker-war~1 as-ttHiource(mn~-ever4 #~me-ever~-~lpe_vnryk,o-om{em#<hlbby-rnbalm Thomhavel>#<~t-by-mbsaes Ubedan> >~nmual ~<nurrter-of-sP~ps-I~a 2>Jde y-the- ps )(partkxlars #<damage-r~xxt Thorahavet O~o-omc~s>#<da.~e-repo,t Uber~n Uoyds> ))*152This realization speOJicatiou represents the structured object which gives thetoplevel plan for this utterance.
Symbols preoeded by colons indicate particular featuresof the utterance.
The two expressions in parentheses are the content items of thespecification and are restricted to appear in the utterance in that order.
The firstsymbol in each expr~on is a label indicating the function of that item within theplan; embedded items appearing in angle brackets are information units from thecurrent-events knowledge base.Obviously this plan must be considerably refined before it could serve as aproximal source for the text; that is why we point out that it is a "toplever' plan.
Itis a specification for the general otltline of the utterance which must be fleshed out byrecursive planning once its reafization has begun and the LC can supply a linguisticcontext to further constrain the choices for the units and the rhetorical features.For present purposes, the key fact to appreciate about this realization specificationis how different it is in form from the surface structure.
One cannot produce thecited text simply by traversing and "reading out" the elements of the specification asthough one were doing direct production.
Structural rearrangements are required, andthese must be done under the oontrol of constraints which can only be stated inlinguistic vocabulary with terms like "subject" or "raising".The first unit in the spcc/fication, ~<same-event-t~e_>, is a relation over twoother units.
It indicates that  a commonality between the two has been noticed anddeemed significant in the underlying representation of the event.
The present LCalways realizes such relations by mergil~ the realizations of the two units.
If nothingelse occurred, this would give us the text "Two oil tankers were hit by missiles".As it happens, however, a pending rhetorical constraint from the realizationspecification, ~svents-r~ulre-?erUfk~on-u4o-source will force the addition of yet anotherinformation unit, 6 the reporting event by the news serv/ce that announced the aledgedevent (e.g.
a press release from Iraq, Reuters, etc.).
In this case the "coatent" of thereporting event is the two damage-repor~ which have already been planned for inclusionin the utterance as part of the '~trticulars" part of the specification.
Let us lookclosely at how that reportiing event unit is folded into surface structure.When not itself the focus of attention, a reporting event is typically realized as'~u3-and-so said X", that is, the content of the report is more important han the reportitself; whatever significance the report or its source has as news will be indicated subtlythrough "which of the alternative realizations below is selected for it.
76 We will not discuss the mechanism by which features in the specification i lluetg~ realization.Realization qgcifi~fions of the complexity of this emsmpiz are still very new in our research and wearc unsure whether the process is better organized at the mnceptual level directing ?
compositionprocess within the planning componeat (during one of the recursive invocations) or within the LC.. mediating a selection between anticipated alternatives.
At this point our design experiments are?
inconclusivc.7 These sentenees are s.rfificial; mea l  ones would be considerably longer.
Interestingly, o:rtainother syntactically permissable ~,~,~oes such ss "/t WaS ~oor ted  that" do not occur in say of thetexts we have examined.
Perhaps the "lead ~ position is too tmporUmt to waste on a proneun.153nedred cbmu er ae Rmdt  textde.empha~ report Two tankers were hit, Gulf shippin& sources said.source b 0yea  ebewhere Two tankers were reported hit.emiMmMxe report Iraq reported it hit two tankers.Figure 2 Possibilities for  expressing report(source, info) in newpaper proseIn our LC, these alternative "choices" are grouped together into a "realiTationclass" as shown in F'tgure 3.
Our  realiTafion classes have their historic orisin5 in thechoice t3nltem$ of systemic grammar, though they are very different in almost everyconcrete detail.
The most important difference of interest theoretically is that whilewstemic choice systems select among single alternative features (e.g.
p~ve,  gerundive),realization classes select among entire surface structure fxa~,ments at a time (whichmight be seen as prespecified realizations of bundles of features).
That is, ourapproach to generation calls for us to organize our decision procedures o as to selectthe values for a number of l inguhtic features simultaneously in one choice where asystemic grammar would make the selection incrementally.
88 The standard technique of using choicc systems to control ~ activc ~.Icction of utterancefeatures b employed by ~ most well-known applications of systa:nic grammars to ge.J,~ation (i.e.
thework of Davey \[1974\] and Mann and Matthiessen \[1983D.
Howover very reo~t work with systemicgrammars at Edinburgh by Patten \[1985\] depa~ from this technique.
Patten uses a semantic-levelplannin~ coml~lte~t to directly ~ grOUpl of features at the rightward, "output", rode of a systemicnetwork, and then works hackwarde through the network to determine what other, not semaficcaUyfeatures must be added to the text for it to be grammatical; control is thus outside thegrammar proper, with gramnunr rule, rckqptted to constraint specification only.
We are intrigued bythis technique and look forward to its further dcvelopmcnt.154beleve-vedm: parameters (aOent propomon ve, b): cholcem; e.g.
=L/oyds reports lraq hit two tankers.
"; encompasses variations with and without that, and; also tenseless complements like =John believes him: to be a foo l .
"( (raise-VERB-Into-PROP (passlvlze verb| prop)dame focus((aOe.t prop)) menUoned4sewtmm(aoent)); "Two tankers were reported to have been hit"( (It-VERB-PROP ve, b prop)dame ~erat~e(agent) ); e.g.
=it is reported that 2 tankers were hit.
"( Oeft,.dlslocated~ agent ved) prop)ciauu de-empemize(se~; "Two tankers were hit, Gulf sources saM.
"))Figure 3 Realization class assigned to report(l~J~t(_)Returning to our example, we are now faced now with the need to incorporate aunit denoting the report of the Iraqi attacks into the utterance to act as a certificationof the #<~-by-rmsaes> events.
This will be done using the realization classbe/ieve-vedm; the class is applicable to any information unit of the form report(source,info) (and others).
It determines the realization of such units l?oth when they appear inissolation and, as in  the present case, when they are to augment an utterancecorresponding to one of their arguments.From this realization class the choice raise-VERB-In, PROP will be selected since (1)the fact that two ships were hit is most ~gnificant, meaning that the focus will be onthe information and not the source (n.b.
when the class executes the source t'aq will bebound to the a0ent parameter and the information about the missile hits to theproposaM, n parameter); (2) there is no rhetorical motivation for us to occupy space inthe t int  sentence with the sources of the report since they have already been plannedto follow.
These conditions are sensed by attached pxocedures associated with thecharacteristics that annotate the choice (i.e.
focta and menti0md-elsewhem).Since the PROP is ah'cady in place in the mrface structure tree, the LC will beinterpreting ralse-VERB.Inlo-PROP as a q)eciflcation of how it may fold the auxiliary treefor reported into the tree for Two oil tankers were hit by missiles Friday in the Gulf.This corresponds to the TAG analym in F'tgure 4 \[Kroch & Joshi 1985\].155Initial Tree:c,JNP INFLtwo tankers /INFL VPbe h i t  by mi~ilesAuxiliary Tree:INFLINFL VPbe reported INFLFigure 4 In/tiaI and amdUlary trees for RalMng4e.eubjectThe initial tree for Two oil tankers were hit by missiles, I1, may be extended at i t sINFL" node as indicated by the constraint given in parenthesis by that node.
Figure 5shows the tree after the auxiliary tree A 2, named by that constraint, has been adjoincd.Notice that the original INFL" of Figure 4 is now in the complement position ofreport, giving us the sentence Two oil tankers were reported hit by missiles.NP j----._..two mi~eileeINFLINFL VPbe reported IIq'FLINFL VPbe hit by missilesFigure $ After embedding report5.I Path NotationAs readers of any of our earlier papers arc aware, we do not employ aconventional tree notation in our LC.
A generation model places its own kinds ofdemands on the representation of surface structure, and these lead to principleddepartures from the conventions adopted by theoretical inguists.
Figure 6 shows thesurface structure as our LC would actuary represent it just before the moment whenthe adjunction is made.156\ [SENTENCE\ ]  .
.
.
.
> .
.
.\[SUBJECTI(plural)\[qaent\] ~ \[heedlt,#o N\[l,r,moal \ [~ea\]oil tankerJ IPBE DICATE\]O At tach-o?
l t i t - l~y  -miss i les .
.
.
,  Ba ie i t~-Prect iceteFigure 6 Surfam structure in pathnotat ionWe call this representation path notat/on because it defines the path that our LCfollows.
Formally the structure is not a tree but a unidirectional linked list whoseformation rules obey the axioms of a tree (e.g.
any path "down" through a given nodemust eventually pass back "up" through that same node).
The path consists of astream of entities representing phrasal nodes, constituent positions (indicated by squarebrackets), instances of information units (in boldface), instances of words, and activatedattachment points (the labeled circle under the predicate; see next section).
Thevarious symbols in the figure (e.g.
sentence, predicate, etc.)
have attached proceduresthat are activated as the point of speech moves along the path, a process we call'~phrase ~iJucture execution".
Phrase ttlucture execution is the mean.~ by whichgrammatical constraints are imposed on embedded decisions and function words andgrammatical morphemes are produced.
(For discussion see McDonald \[1984\].
)Once one has begun to think of surface structure as a travenal path, it is a shortstep to ima~inln~ being able to cut the path and '~plice in" additional positionsequence.
9 This ~l ic ing  operat ion inherits a natural set of constraints on the ldnds ofdistortions that it can perform, since, by the indelibility stipulation, existing positionsequences can not be destroyed or rethreaded.
It is our impression that theseconstraints will turn out to be formally the same as those ~ of a TAG,  but we have notyet carried out the detailed analyses to confirm this.9The fem-ueity of cutting the mzrface structure and insetting new eequences that change the?
linguistic context of pmitiom akeady in place has been in our thmry of generation since 1978, whenwe used it to implement rat~Ing veto  whooe rhetorical fogee was the mine as "hedging" advedbs likepoax//dy.
Our pre~at, much more e~mtve  use of thia device as the core of a distim:t attachmentprocem dates from the summer of 1984.157$.2 Attaehm_m,t PeintsThe TAG formalism allows a grammar writer to define "constraints" by annotatingthe nodes of elementary trees with lists indicating what auxiliary trees may be adjoinedto them (including "any" or "none").
l?
In a similar manner the "choices" in ourrealization c l~which  by our hypothesis can be taken to always correspond to TAGelementary trees--include specifications of the attachment po/nts at which newinformation units can be incorporated into the surface structure path they defme.Rather than being constraints on an otherwise freely applying operation, as in a TAG,attachment points are actual ob~cts interposed in the path notation of the surfacestructure.
A list of the attachment points active at any moment is maintained by theattachment process and consulted whenever an information unit needs to be added.Most units could be attached at any of several points, with the decision being made onthe basis of what would be most consistent with the desired prose style (cf.
McDonaldand Pustejovsky \[1985aD.
When one of the points is selected it is instantiated, usuallysplicing in new surface structure in the process, and the new unit added at adesignated position within the new structure.
Figure 7 shows our present definition ofthe attachment point that ultimately leads to the addition of "was reported".
(define-attachment-point attach-raJs~ng.~'edcate reference-poinm( (~"~l~.~elot ?pr~.ate phrase)zttach-under )(vp-lrdinltlve-cong31emeot) ; specification of new phraseverb ; where the unit being attached goes~ int t Jve -cor~)  ; where the existing contents goe~ezt~-oew-peod~a~-po ln tscholcm-tl~-Introduc~ltx~oeee-~te~ ~et~t  "prececate))Figure 7 The attltchmeat-lpoint wed by was reported10 Constraints of this sort are an inovation introduced in Kroch & Joshi \[1985\].Previous versions of TAG theory allowed "context sensitive" constraint specificationsthat in fact were never exploited.
The present constraints are more attractive formallysince they must be stated locally to a single tree.158This attachment point goes with any choice (elementary tree) that includes aconstituent position labeled ia~dUkate.
It is placed in the position path immediatelyafter (or "under") that position (see Figure 6), where it is available to any new unitthat passes the indicated requirements.When this a.~chment is selected, it builds a new VP node that has the old VP asone of its comtituents, then spUces this new node into the path in its place as shownin F~u,~ 7.The unit being attached, e.g.
the report of the attack on the two oil tankers, ismade the verb of the new VP.
Later, once the phrase structure execution process haswalked into the new VP and reached that verb position, the unit's realization class(belief-verbs) will be consulted and a choice selected that is consistent with thegrammatical constraints of being a verb (i.e.
a conventional variant on theraise-VERB4nto-PROP choice), 8 iv i~ us "wos reported".\[SUBJECT\]NPt~,o oil tankers?
> \ [SENTENCE\ ]  ~ ..:S, \ [PREDICATE\]\ [verb\]  ---> \ [ |nf in iUve-rel~or t complement \ ]-<hit-by-mi--i le---->Figure 8 'nze path after" attachmentFrom this discussion one can see that our treatment of attachment uses twogructures, an attachment point and a choice, where a TAG would only use onestructure, an auxiliary tree.
~ is a consequence of the fact that we are workingwith a performance model of generation that must show explicitly how conceptualinformation units are  rendered into texts as part of a psycholinguisticaUy plausibleprocess, while a TAG b a formalism for competence theories that only hoe4 to specifythe syntactic itmcture of the grammatical strings of a language.
This is a significantdifference, but not one that should stand in our way in comparing what the twotheories have to offer each other.
Comequently in the rest of this paper we will omitthe d~ai l l  of the path notation and attachment point def'mitions to facilitate thecomparison of theoretical issues.1596.
Generating qua/ions m/ng a TAG version of wh-movementEarlier we illustrated the TAG concept of "linking" by showing how one wouldstart with an initial tree consisting of the /nnermost clause of a question plus thefronted wh-phrase and then build outward by successively adjoining the desired auxiliaryphrases to the S node that intervenes between the wh-phrase and the clause.Wh-questions are thus built from the bottom up, as in fact is any sentence involvingverbs taking sentential complements.analylis has the desirable property of allowing one to state the dependendesbetween the Wh-phrase and the gap as a local relation on a single elementary tree,eliminating the need to Include any machinery for movement in the theory.
Allunbounded ependendes now derive from adjunctions (which, as far as the grammar isconcerned, can be made without limit), rather than to the expficit migration of aconstituent acrms clauses.We also find this locality property to be desirable, and use an analogous procedurein our production of questiona and other kinds of Whquestions and unboundeddependency constructions.This "bottom-up" design has consequences for how the realization specifications forthese constructions must be organized.
In particular, the logician's usual representationof sentential complement verbs as higher operators is not tenable in that role.
Forexample we cannot have the source of, say, How many ships did Reuters report thatIraq had said it attacked?
be the expreuion:Lambda(quantlty-of-shlps) .
report(Reuters, ty(Lraq, attack(Iraq, quantity-of-ships)))Such an expression defines a natural sequence of exposure when used as realizationspecification, namely that one realize the Lmnlght operator first, the report operatorsecond, the sty third, and so on.
A local TAG analysis of Wh-movement requires usto have the Lambda and the expression containing its matrix trace, attach, be presentin a single "layer" of the specification, otherwise we would be forced to violate one ofthe strong principles of our theory of generation, namely that the characteristics in arealization class may "see" only the immediate arguments of the unit being realized;they may not' look "inside" those arguments to subsequent levels of conceptualstructure.This principle has served t~s well, and we are disinclined to give it up without avery compelling reason.
We elected instead to give up the internal representation ofsentential complement verb texts as tingle expressions.
This move was easy for us tomake since such  expreuions are awkward to manipulate in the "East Coast" style frameknowledge bases that we use in our own reasonin S programs, and we have preferred arepresentational style with redundant, smaller sized conceptual units for quite sometime.The representation~ we use instead amounts to breaking up the logical expressioninto individual units and allowing them to include references to each other.U I = lambda(quantity-of-shipa) .
ttack(Iraq,quantity-of-ships)U 2 = sty(Iraq, U1)u 3 : repo.
(Reuten, U2)160Given such a network as the realization specification, the LC must have someprinciple by which to judge where to start: which unit should form the basis of thesurface mucture to which the others are then attached?
A natural principle to adoptis to begin with the '?rash" unit, i~.
the one that does not mention any other units inits definition.
We are comiderin s adopting the policy that such units should beallowed only realizations as initial trees while units whose definition involves "pointingto" (naming) other units shouldbe allowed only rea!iza" tions as auxiliary trees.
Wehave not, however, worked through all of the ramifications uch a policy might haveon other parts of our generation model; without yet knowing whether it would improveor degrade the other parts of our theory, we are reluctant o assert it as one of ourhypotheses relating our generation model to TAG's.Given that three part source, the realization of the question is fairlystraightforward (See Figure 9).
The Lambda expression is assigned a realization classfor clausal Wh constructions, whereupon the ?xUscted argument quantlty.of.shlps iplaced in COMP, and the body of the expression is placed in the HEAD position.
Atthe same time, the two instances of qumd/ty-of-ehIp8 are specially marked.
The one inCOMP is ass/gned to the realization class for Wh phrases appropriate to quantity (e.g.it will have the choice how many X and possibly related choices such as <quantity> ofwhich and other variants appropriate to relative clauses or other positions where Whconstructions can be used).
Simultaneously the instance of quanflty-ef-eidps in theargument position of the head frame attack is assigned to the realization class forWh-trace.
These two specializations are the equivalent, in our model, of the TAGlinking relation.~ ~"  Reuters reports SIraq say S comp /WH(ships)?Fitmre 9 Qeesaea fermae\[oa with ~ ?emplement verbsThe two pending units, U 2 and U3, are then attached to this matrix, submergingfirst the attach unit and then U 2 into complement positions.1617.
Extensions to'the 'l\]~eory of TAGContext-free grammars are able to express the word formation processes that seemto exist for natural language, (cf.
Williams \[1981\], Selkirk \[1982\]).
A TAG analysis ofinch a grammar seems like a natural application to the current version of the theory(d. Puste~k-y (in preparation)).
To illustrate our point, consider compounding rulesin English.
We can say that for a context-free grammar for word formation, Gw, thereis a TAG, T w, that is equivalent o G w (d. Figur~ 10 and 11).
Consider a fragmentof G w below.
ItN ->N IA  I V I P HA ->NIA IP  AV ->PVFigure 10 CFG Fragment for Word FormationThe corresponding G w fragment would be:Ncomp NAcomp A P VAUXI LIARY TREESN N NI I Ioil tanker portINITIAL TREESFigure 11 TAG Fragment for Word FormationNow conmder the compound , =oil tanker terminal, taken from the newspaper eportingdomain, and its derivation in TAG theory, shown in Figure 12.11 Whether the word formation component should in fact have the power of a TAGor CFG is an open question.
Langendoen \[1981\] discusses the possibility that a f'mitestate grammar might be sufficient for the generative capacity of natural language wordformation components.162ogre(  ~N /~anker  ~k  ~e~inaloil tankerFigure 12 TAG Derivation of oil tanker terminalLet us compare this derivation to the process used by the LC.
The underlyinginformation units from which this compound is derived in our system are shown below.The planner has decided that the units below need to be communicated in order toadequately express the concept.
The top-level unit in this bundle is #<terminal>.U 1 = #<M~rn~u~>O 2 = #<aoekn-at U I th>u s = #<tank~>0 4 = #<~, ,~, ,  L h us>U s = #<o,>The first unit to be positioned in the mrface structure is U 1, and appears as the headof an NP.
There is an attachment point on this position, however, which allows for thepossibility of expressing U 2 prenominally.
One of the choices associated with this unit isa compound structuro--expre~ed in terms of an auxiliary tree.
A snapshot at this pointin the derivation shows the following structure.\[C~,.~ U2 \] Ol \]The next unit opened up in this structure is U 3, which also allows for attachmentprenominally.
Thus an auxiliary tree corresponding to U 4 is introduced, giving us thestructure below:~ ~.~ u4 \] u~ u 11The selectional constraints imposed by the structural positioning of information unitU 4 allows only a compounding choice.
Had there been no word-level compoundrealization option, we would have worked our way into a corner without expressing therelation between #<oi l> and #<tanker>.
Because of this it may be better to viewunits such as U 4 as being associated irectly with a lexical compounded form, i.e.
oiltanker.
This partial solution, however, would not speak to the problem of active wordformation in the language.
Furthermore, it would be interesting to compare thestrategic decisions made by a generation system with those planning mistakes made byhumans when speaking.
This is an aspect of generation that merits much furtherresearch.1638.
AcknowledgementsThis research as been mpterminaled in part by contract N0014-85-K4)017 from theDefense Advanced Research Projects Agency.
We would like to thank Marie Vaughanfor help in the preparation of this text.9.
ReferencesClippinger, & McDonald (1983) "Why Good Writing is Easier to Understand", Proc.IJCAI-83, pp.
730-732.Davey (1974) Dbcourse Production, Ph.D. Dissertation, Edinburgh University; publi~edin 1979 by Edinburgh University Press.Halliday (1976) System and Function in Language, Oxford University Press.Joshi (1983) "How Much Context-Sensitivity is Required to Provide ReasonableStructural Descriptions: Tree Adjoining Grammars", preprint to appear in Dowty,Karttunen, & Zwicky (ecls.)
Natural Language Processing: Psycholin=~2ulstlc ,Comimtatlonal, and Theoretical Perspectives, Cambridge University Press.Kroch, T. and A. Joshi (1985) "The Linguistic Relevance of Tree Adjoining Grammar",University of Penosylvania, Dept.
of Computer and Information Science.Langendoen, D.T.
(1981) 'q'he Generative Capacity of Word-Formation Components",Linguistic Inquiry, Volume 12.2Mann & Matthiessen (1983)Ni&el: A Systemic Grammar for Text Generation, in Freedle(ed.)
Systemic Perspectives on Discourse, Ablex.Marcus (1980) A Theory of Syntactic Recognition for Natural Language, MIT Press.McDonald (1984) "Description Directed Control: Its Implications for Natu~ral LanguageGeneration", in Cercone (ed.)
Cemlmtatlonal IAngulstlcs, Pergamon Press.McDonald & Pustejovsky (1985a) "SAMSON: a computational theory of prose style ingeneration", Proceedings of the 1985 meeting of the European Association forComputational Linguistics.
(1985b) "Description-Directed Natural Language Generation", Proceedingsof IJCAI-85, WXaufmann Inc., Los Altos CA.Patten T. (1985) "A Problem Solving Approach to Generating Text from SystemicGrammars", Proceedings of the 1985 meeting of the European Association forComputational Linguistics.Pustejovtky, J.
(In Preparation) "Word Formation in Tree Adjoining Grammars"Selkirk (1982) The Syntax of Words, MIT Press.Williams (1981) "Argument Structure and Morphology" The Linguistic Review, 1, 81-114.164
