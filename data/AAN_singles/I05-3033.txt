Towards a Hybrid Model for Chinese Word SegmentationXiaofei LuDepartment of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USAxflu@ling.osu.eduAbstractThis paper describes a hybrid Chineseword segmenter that is being developedas part of a larger Chinese unknownword resolution system.
The segmenterconsists of two components: a taggingcomponent that uses the transforma-tion-based learning algorithm to tageach character with its position in aword, and a merging component thattransforms a tagged character sequenceinto a word-segmented sentence.
In ad-dition to the position-of-character tagsassigned to the characters, the mergingcomponent makes use of a number ofheuristics to handle non-Chinese char-acters, numeric type compounds, andlong words.
The segmenter achieved a92.8% F-score and a 72.8% recall forOOV words in the closed track of thePeking University Corpus in the Sec-ond International Chinese Word Seg-mentation Bakeoff.1 IntroductionThis paper describes a hybrid Chinese wordsegmenter that participated in the closed track ofthe Peking University Corpus in the Second In-ternational Chinese Word Segmentation Bake-off.
This segmenter is still in its early stage ofdevelopment and is being developed as part of alarger Chinese unknown word resolution systemthat performs the identification, part of speechguessing, and sense guessing of Chinese un-known words (Lu, 2005).The segmenter consists of two major compo-nents.
First, a tagging component tags each indi-vidual character in a sentence with a position-of-character (POC) tag that indicates the position ofthe character in a word.
This could be one of thefollowing four possibilities, i.e., the character iseither a monosyllabic word or is in a word-initial, middle, or final position.
This componentis based on the transformation-based learning(TBL) algorithm (Brill, 1995), where a simplefirst-order HMM tagger (Charniak et al, 1993)is used to produce an initial tagging of a charac-ter sequence.
Second, a merging componenttransforms the output of the tagging component,i.e., a POC-tagged character sequence, into aword-segmented sentence.
Whereas this processrelies largely on the POC tags assigned to theindividual characters, it also takes advantage ofa number of heuristics generalized from thetraining data to handle non-Chinese characters,numeric type compounds, and long words.The approach adopted here is reminiscent ofthe line of research that employs the idea ofcharacter-based tagging for Chinese word seg-mentation and/or unknown word identification(Goh et al, 2003; Xue, 2003; Zhang et al,2002).
The notion of character-based taggingallows us to model the tendency for individualcharacters to combine with other characters toform words in different contexts.
This propertygives the model a good potential for improvingthe performance of Chinese unknown wordidentification, a major concern of the Chineseunknown word resolution system that the seg-menter is a part of.The rest of the paper is organized as follows.Section two describes the system architecture.Section three reports the results of the system inthe bakeoff.
Section four concludes the paper.1892 System DescriptionThe overall architecture of the segmenter is de-scribed in Figure 1.
An input sentence is firstsegmented into a character sequence, with aspace inserted after each character.
The seg-mented character sequence is then processed bythe tagging component, where it is initiallytagged by an HMM tagger, and then by a TBLtagger.
Finally, the tagged character sequence istransformed into a word-segmented sentence bythe merging component.Figure 1: System Architecture.2.1 The Tagging ComponentThe tagset used by the tagging component con-sists of the following four tags: L, M, R, and W,each of which indicates that the character is in aword-initial, word-middle, or word-final posi-tion or is a monosyllabic word respectively.
Thetransformation-based error-driven learning algo-rithm is adopted as the backbone of the taggingcomponent over other promising machine learn-ing algorithms because, as Brill (1995) argued, itcaptures linguistic knowledge in a more explicitand direct fashion without compromising per-formance.
This algorithm requires a gold stan-dard, some initial tagging of the training corpus,and a set of rule templates.
It then learns a set ofrules that are ranked in terms of the number oftagging error reductions they can achieve.A number of different initial tagging schemescan be used, e.g., tagging each character as amonosyllabic word or with its most probablePOC tag.
We used a simple first-order HMMtagger to produce an initial tagging.
Specifically,we calculate)|w)p(t|tp(t iiinii...tt n 111maxarg ?=?
(1)where ti denotes the ith tag in the tag sequenceand wi denotes the ith character in the charactersequence.
The transition probabilities and lexi-cal probabilities are estimated from the trainingdata.
The lexical probability for an unknowncharacter, i.e., a character that is not found in thetraining data, is by default uniformly distributedamong the four POC tags defined in the tagset.The Viterbi algorithm (Rabiner, 1989) is used totag new texts.The transformation-based tagger was imple-mented using fnTBL (Florian and Ngai, 2001).The rule templates used are the same as the con-textual rule templates Brill (1995) defined forthe POS tagging task.
These templates basicallytransform the current tag into some other tagbased on the current character/tag and the char-acter/tag one to three positions before/after thecurrent character.
An example rule template isgiven below:(1) Change tag a to tag b if the preceding char-acter is tagged z.The training process is iterative.
At each itera-tion, the algorithm picks the instantiation of arule template that achieves the greatest numberof tagging error reductions.
This rule is appliedto the text, and the learning process repeats untilno more rules reduce errors beyond a pre-defined threshold.
The learned rules can then beapplied to new texts that are tagged by the initialHMM tagger.2.2 The Merging ComponentThe merging component transforms a POC-tagged character sequence into a word-segmented sentence.
In general, the characters ina sequence are concatenated, and a space is in-serted after each character tagged R (word-finalposition) or W (monosyllabic word).UnsegmentedChinese sentenceSegmentedcharacter sequenceInitial POC-taggedcharacter sequenceFinal POC-taggedcharacter sequenceWord-segmentedsentenceCharactersegmenterHMMPOC taggerTBLPOC taggerMergingcomponent190In addition, two sets of heuristics are used inthis process.
One set (H1) is used to handle non-Chinese characters and numeric type compounds,e.g., numbers, time expressions, etc.
A few pat-terns of non-Chinese characters and numerictype compounds are generalized from the train-ing data.
If the merging algorithm detects such apattern in the character sequence, it groups thecharacters that are part of the pattern accord-ingly.The second set of heuristics (H2) is used tohandle words that three or more characters long.Our hypothesis is that long words tend to haveless fluidity than shorter words and their behav-ior is more predictable (Lu, 2005).
We extracteda wordlist from the training data.
Based on ourhypothesis, if the merging algorithm detects thata group of characters form a long word found inthe wordlist, it groups these characters into oneword.3 ResultsThe segmenter was evaluated on the closed trackof the Peking University Corpus in the bakeoff.In the development stage, we partitioned theofficial training data into two portions: the train-ing set consists of 90% of the data, and the de-velopment set consists of the other 10%.
ThePOC tagging accuracy on the development set issummarized in Table 1.
The results indicate thatthe TBL tagger significantly improves the initialtagging produced by the HMM tagger.AccuracyHMM tagger 0.814TBL tagger 0.936Table 1: Tagging Results on the Development Set.The performance of the merging algorithm onthe development set is summarized in Table 2.To understand whether and how much the heu-ristics contribute to improving segmentation, weevaluated four versions of the merging algo-rithm.
The set of heuristics used to handle non-Chinese characters and numeric type compoundsdid not seem to improve segmentation results onthe development set, suggesting that these char-acters are handled well by the tagging compo-nent.
However, the second set of heuristicsimproved segmentation accuracy significantly.This seems to confirm our hypothesis that longerwords tend to behave more stably.Resources used R P FPOC Tags only 0.928 0.926 0.927+ H1 0.929 0.925 0.927+ H2 0.938 0.959 0.948+ H1 & H2 0.940 0.960 0.950Table 2: Segmentation Results on the DevelopmentSet.
H1 stands for the set of heuristics used to handlenon-Chinese characters and numeric type com-pounds.
H2 stands for the set of heuristics used tohandle long words.Corpus R P F ROOV RIVPKU 0.922 0.934 0.928 0.728 0.934Table 3: Official Results in the Closed-Track of thePeking University Corpus.The official results of the segmenter in theclosed-track of the Peking University Corpus aresummarized in Table 3.
It is somewhat unex-pected that the results on the official test datadropped over 2% compared with the results ob-tained on the development set.
Compared withthe other systems, the segmenter performed rela-tively well on OOV words.Our preliminary error analysis indicates thatthis discrepancy in performance is partially at-tributable to two kinds of inconsistencies be-tween the training and test datasets.
One is thatthere are many ASCII numbers in the test set,but none in the training set.
These numbers be-came unknown characters to the tagger and af-fected tagging accuracy.
It is possible that thisinconsistency affected our system more thanother systems.
Second, there are also a numberof segmentation inconsistencies between thetraining and test sets, but these should have af-fected all systems more or less equally.
The er-ror analysis also indicates that the currentsegmenter performed poorly on transliterationsof foreign names.4 ConclusionsWe described a hybrid Chinese word segmenterthat combines the transformation-based learningalgorithm for character-based tagging and lin-guistic heuristics for transforming tagged char-acter sequences into word-segmented sentences.191As the segmenter is in its first stage of develop-ment and is far from mature, the bakeoff pro-vided an especially valuable opportunity forevaluating its performance.
The results suggestthat:1.
Despite the lack of a separate mecha-nism for unknown word recognition, thesegmenter performed relatively well onOOV words.
This confirms our hy-pothesis that character-based tagginghas a good potential for improving Chi-nese unknown word identification.2.
Using linguistic heuristics at the merg-ing stage can help improve segmenta-tion results.3.
There is much room for improvementfor both the tagging algorithm and themerging algorithm.
This is being under-taken.ReferencesEric Brill.
1995.
Transformation-based error-driven learning and natural language process-ing: A case study in part-of-speech tagging.Computational Linguistics, 21(4):543-565.Eugene Charniak, Curtis Hendrickson, Neil Ja-cobson, and Mike Perkowitz.
1993.
Equationsfor part-of-speech tagging.
In Proceedings ofAAAI-1993, pp.
784-789.Chooi Ling Goh, Masayuki Asahara, and YujiMatsumoto.
2003.
Chinese unknown wordidentification using character-based taggingand chunking.
In Proceedings of ACL-2003Interactive Posters and Demonstrations, pp.197-200.Xiaofei Lu.
2005.
Hybrid methods for POSguessing of Chinese unknown words.
In Pro-ceedings of ACL-2005 Student ResearchWorkshop, pp.
1-6.Grace Ngai and Radu Florian.
2001.
Transfor-mation-based learning in the fast lane.
In Pro-ceedings of NAACL-2001, pp.
40-47.Lawrence R. Rabiner.
1989.
A tutorial of hiddenMarkov models and selected applications inspeech recognition.
In Proceedings of IEEE-1989, pp.
257-286.Nianwen Xue.
2003.
Chinese word segmenta-tion as character tagging.
International Jour-nal of Computational Linguistics and ChineseLanguage Processing, 8(1):29-48.Kevin Zhang, Qin Liu, Hao Zhang, and Xue-QiCheng.
2002.
Automatic recognition of Chi-nese unknown words based on roles tagging.In Proceedings of the 1st SIGHAN Workshopon Chinese Language Processing, pp.
71-78.192
