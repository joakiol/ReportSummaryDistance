Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 49?56,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Finite-State Model of Human Sentence ProcessingJihyun Park and Chris BrewDepartment of LinguisitcsThe Ohio State UniversityColumbus, OH, USA{park|cbrew}@ling.ohio-state.eduAbstractIt has previously been assumed in thepsycholinguistic literature that finite-statemodels of language are crucially limitedin their explanatory power by the local-ity of the probability distribution and thenarrow scope of information used by themodel.
We show that a simple computa-tional model (a bigram part-of-speech tag-ger based on the design used by Corleyand Crocker (2000)) makes correct predic-tions on processing difficulty observed in awide range of empirical sentence process-ing data.
We use two modes of evaluation:one that relies on comparison with a con-trol sentence, paralleling practice in hu-man studies; another that measures prob-ability drop in the disambiguating regionof the sentence.
Both are surprisinglygood indicators of the processing difficultyof garden-path sentences.
The sentencestested are drawn from published sourcesand systematically explore five differenttypes of ambiguity: previous studies havebeen narrower in scope and smaller inscale.
We do not deny the limitations offinite-state models, but argue that our re-sults show that their usefulness has beenunderestimated.1 IntroductionThe main purpose of the current study is to inves-tigate the extent to which a probabilistic part-of-speech (POS) tagger can correctly model humansentence processing data.
Syntactically ambigu-ous sentences have been studied in great depth inpsycholinguistics because the pattern of ambigu-ity resolution provides a window onto the humansentence processing mechanism (HSPM).
Primafacie it seems unlikely that such a tagger will beadequate, because almost all previous researchershave assumed, following standard linguistic the-ory, that a formally adequate account of recur-sive syntactic structure is an essential componentof any model of the behaviour.
In this study, wetested a bigram POS tagger on different types ofstructural ambiguities and (as a sanity check) tothe well-known asymmetry of subject and objectrelative clause processing.Theoretically, the garden-path effect is definedas processing difficulty caused by reanalysis.
Em-pirically, it is attested as comparatively slowerreading time or longer eye fixation at a disam-biguating region in an ambiguous sentence com-pared to its control sentences (Frazier and Rayner,1982; Trueswell, 1996).
That is, the garden-patheffect detected in many human studies, in fact, ismeasured through a ?comparative?
method.This characteristic of the sentence processingresearch design is reconstructed in the currentstudy using a probabilistic POS tagging system.Under the assumption that larger probability de-crease indicates slower reading time, the test re-sults suggest that the probabilistic POS taggingsystem can predict reading time penalties at thedisambiguating region of garden-path sentencescompared to that of non-garden-path sentences(i.e.
control sentences).2 Previous WorkCorley and Crocker (2000) present a probabilisticmodel of lexical category disambiguation based ona bigram statistical POS tagger.
Kim et al (2002)suggest the feasibility of modeling human syntac-tic processing as lexical ambiguity resolution us-ing a syntactic tagging system called Super-Tagger49(Joshi and Srinivas, 1994; Bangalore and Joshi,1999).
Probabilistic parsing techniques also havebeen used for sentence processing modeling (Ju-rafsky, 1996; Narayanan and Jurafsky, 2002; Hale,2001; Crocker and Brants, 2000).
Jurafsky (1996)proposed a probabilistic model of HSPM usinga parallel beam-search parsing technique basedon the stochastic context-free grammar (SCFG)and subcategorization probabilities.
Crocker andBrants (2000) used broad coverage statistical pars-ing techniques in their modeling of human syn-tactic parsing.
Hale (2001) reported that a proba-bilistic Earley parser can make correct predictionsof garden-path effects and the subject/object rela-tive asymmetry.
These previous studies have usedsmall numbers of examples of, for example, theReduced-relative clause ambiguity and the Direct-Object/Sentential-Complement ambiguity.The current study is closest in spirit to a pre-vious attempt to use the technology of part-of-speech tagging (Corley and Crocker, 2000).Among the computational models of the HSPMmentioned above, theirs is the simplest.
Theytested a statistical bigram POS tagger on lexi-cally ambiguous sentences to investigate whetherthe POS tagger correctly predicted reading-timepenalty.
When a previously preferred POS se-quence is less favored later, the tagger makes a re-pair.
They claimed that the tagger?s reanalysis canmodel the processing difficulty in human?s disam-biguating lexical categories when there exists adiscrepancy between lexical bias and resolution.3 ExperimentsIn the current study, Corley and Crocker?s modelis further tested on a wider range of so-calledstructural ambiguity types.
A Hidden MarkovModel POS tagger based on bigrams was used.We made our own implementation to be sure ofgetting as close as possible to the design of Cor-ley and Crocker (2000).
Given a word string,w0, w1, ?
?
?
, wn, the tagger calculates the proba-bility of every possible tag path, t0, ?
?
?
, tn.
Un-der the Markov assumption, the joint probabilityof the given word sequence and each possible POSsequence can be approximated as a product of con-ditional probability and transition probability asshown in (1).
(1) P (w0, w1, ?
?
?
, wn, t0, t1, ?
?
?
, tn)?
?ni=1P (wi|ti) ?
P (ti|ti?1), where n ?
1.Using the Viterbi algorithm (Viterbi, 1967), thetagger finds the most likely POS sequence for agiven word string as shown in (2).
(2) argmaxP (t0, t1, ?
?
?
, tn|w0, w1, ?
?
?
, wn, ?
).This is known technology, see Manning andSchu?tze (1999), but the particular use we makeof it is unusual.
The tagger takes a word stringas an input, outputs the most likely POS sequenceand the final probability.
Additionally, it presentsaccumulated probability at each word break andprobability re-ranking, if any.
Note that the run-ning probability at the beginning of a sentence willbe 1, and will keep decreasing at each word breaksince it is a product of conditional probabilities.We tested the predictability of the model on em-pirical reading data with the probability decreaseand the presence or absence of probability re-ranking.
Adopting the standard experimental de-sign used in human sentence processing studies,where word-by-word reading time or eye-fixationtime is compared between an experimental sen-tence and its control sentence, this study comparesprobability at each word break between a pair ofsentences.
Comparatively faster or larger drop ofprobability is expected to be a good indicator ofcomparative processing difficulty.
Probability re-ranking, which is a simplified model of the reanal-ysis process assumed in many human studies, isalso tested as another indicator of garden-path ef-fect.
Given a word string, all the possible POSsequences compete with each other based on theirprobability.
Probability re-ranking occurs when aninitially dispreferred POS sub-sequence becomesthe preferred candidate later in the parse, becauseit fits in better with later words.The model parameters, P (wi|ti) andP (ti|ti?1), are estimated from a small sec-tion (970,995 tokens,47,831 distinct words) ofthe British National Corpus (BNC), which is a100 million-word collection of British English,both written and spoken, developed by OxfordUniversity Press (Burnard, 1995).
The BNC waschosen for training the model because it is aPOS-annotated corpus, which allows supervisedtraining.
In the implementation we use logprobabilities to avoid underflow, and we reportlog probabilities in the sequel.3.1 HypothesesIf the HSPM is affected by frequency information,we can assume that it will be easier to process50events with higher frequency or probability com-pared to those with lower frequency or probability.Under this general assumption, the overall diffi-culty of a sentence is expected to be measured orpredicted by the mean size of probability decrease.That is, probability will drop faster in garden-pathsentences than in control sentences (e.g.
unam-biguous sentences or ambiguous but non-garden-path sentences).More importantly, the probability decrease pat-tern at disambiguating regions will predict thetrends in the reading time data.
All other things be-ing equal, we might expect a reading time penaltywhen the size of the probability decrease at thedisambiguating region in garden-path sentences isgreater compared to the control sentences.
This isa simple and intuitive assumption that can be eas-ily tested.
We could have formed the sum overall possible POS sequences in association with theword strings, but for the present study we simplyused the Viterbi path: justifying this because thisis the best single-path approximation to the jointprobability.Lastly, re-ranking of POS sequences is expectedto predict reanalysis of lexical categories.
This isbecause re-ranking in the tagger is parallel to re-analysis in human subjects, which is known to becognitively costly.3.2 MaterialsIn this study, five different types of ambiguity weretested including Lexical Category ambiguity, Re-duced Relative ambiguity (RR ambiguity), Prepo-sitional Phrase Attachment ambiguity (PP ambi-guity), Direct-Object/Sentential-Complement am-biguity (DO/SC ambiguity), and Clausal Bound-ary ambiguity.
The following are example sen-tences for each ambiguity type, shown with theambiguous region italicized and the disambiguat-ing region bolded.
All of the example sentencesare garden-path sentneces.
(3) Lexical Category ambiguityThe foreman knows that the warehouseprices the beer very modestly.
(4) RR ambiguityThe horse raced past the barn fell.
(5) PP ambiguityKatie laid the dress on the floor onto the bed.
(6) DO/SC ambiguityHe forgot Pam needed a ride with him.
(7) Clausal Boundary ambiguityThough George kept on reading the story re-ally bothered him.There are two types of control sentences: unam-biguous sentences and ambiguous but non-garden-path sentences as shown in the examples below.Again, the ambiguous region is italicized and thedisambiguating region is bolded.
(8) Garden-Path SentenceThe horse raced past the barn fell.
(9) Ambiguous but Non-Garden-Path ControlThe horse raced past the barn and fell.
(10) Unambiguous ControlThe horse that was raced past the barn fell.Note that the garden-path sentence (8) and itsambiguous control sentence (9) share exactly thesame word sequence except for the disambiguat-ing region.
This allows direct comparison of prob-ability at the critical region (i.e.
disambiguatingregion) between the two sentences.
Test materi-als used in experimental studies are constructed inthis way in order to control extraneous variablessuch as word frequency.
We use these sentencesin the same form as the experimentalists so we in-herit their careful design.In this study, a total of 76 sentences were tested:10 for lexical category ambiguity, 12 for RR am-biguity, 20 for PP ambiguity, 16 for DO/SC am-biguity, and 18 for clausal boundary ambiguity.This set of materials is, to our knowledge, themost comprehensive yet subjected to this type ofstudy.
The sentences are directly adopted fromvarious psycholinguistic studies (Frazier, 1978;Trueswell, 1996; Frazier and Clifton, 1996; Fer-reira and Clifton, 1986; Ferreira and Henderson,1986).As a baseline test case of the tagger, thewell-established asymmetry between subject- andobject-relative clauses was tested as shown in (11).
(11) a.
The editor who kicked the writer firedthe entire staff.
(Subject-relative)b.
The editor who the writer kicked firedthe entire staff.
(Object-relative)The reading time advantage of subject-relativeclauses over object-relative clauses is robust in En-glish (Traxler et al, 2002) as well as other lan-guages (Mak et al, 2002; Homes et al, 1981).
Forthis test, materials from Traxler et al (2002) (96sentences) are used.514 Results4.1 The Probability Decrease per WordUnambiguous sentences are usually longer thangarden-path sentences.
To compare sentences ofdifferent lengths, the joint probability of the wholesentence and tags was divided by the number ofwords in the sentence.
The result showed thatthe average probability decrease was greater ingarden-path sentences compared to their unam-biguous control sentences.
This indicates thatgarden-path sentences are more difficult than un-ambiguous sentences, which is consistent withempirical findings.Probability decreased faster in object-relativesentences than in subject relatives as predicted.In the psycholinguistics literature, the comparativedifficulty of object-relative clauses has been ex-plained in terms of verbal working memory (Kingand Just, 1991), distance between the gap and thefiller (Bever and McElree, 1988), or perspectiveshifting (MacWhinney, 1982).
However, the testresults in this study provide a simpler account forthe effect.
That is, the comparative difficulty ofan object-relative clause might be attributed to itsless frequent POS sequence.
This account is par-ticularly convincing since each pair of sentences inthe experiment share the exactly same set of wordsexcept their order.4.2 Probability Decrease at theDisambiguating RegionA total of 30 pairs of a garden-path sentenceand its ambiguous, non-garden-path control weretested for a comparison of the probability decreaseat the disambiguating region.
In 80% of the cases,the probability drops more sharply in garden-pathsentences than in control sentences at the criticalword.
The test results are presented in (12) withthe number of test sets for each ambiguous typeand the number of cases where the model correctlypredicted reading-time penalty of garden-path sen-tences.
(12) Ambiguity Type (Correct Predictions/TestSets)a. Lexical Category Ambiguity (4/4)b. PP Ambiguity (10/10)c. RR Ambiguity (3/4)d. DO/SC Ambiguity (4/6)e. Clausal Boundary Ambiguity (3/6)?60?55?50?45?40?35LogProbability(a)     PP  Attachment  AmbiguityKatie put the dress on the floor  and / onto  the ...?35?30?25?20?15LogProbability(b)  DO / SC  Ambiguity  (DO Bias)He forgot Susan  but / remembered ...theandthefloortheontoSusanbutrememberedforgotFigure 1: Probability Transition (Garden-Path vs.Non Garden-Path)(a) ?
?
?
: Non-Garden-Path (Adjunct PP), ?
?
?
: Garden-Path (Complement PP)(b) ?
?
?
: Non-Garden-Path (DO-Biased, DO-Resolved),?
?
?
: Garden-Path (DO-Biased, SC-Resolved)The two graphs in Figure 1 illustrate the com-parison of probability decrease between a pair ofsentence.
The y-axis of both graphs in Figure 1is log probability.
The first graph compares theprobability drop for the prepositional phrase (PP)attachment ambiguity (Katie put the dress on thefloor and/onto the bed....) The empirical resultfor this type of ambiguity shows that reading timepenalty is observed when the second PP, onto thebed, is introduced, and there is no such effect forthe other sentence.
Indeed, the sharper probabilitydrop indicates that the additional PP is less likely,which makes a prediction of a comparative pro-cessing difficulty.
The second graph exhibits theprobability comparison for the DO/SC ambiguity.The verb forget is a DO-biased verb and thus pro-cessing difficulty is observed when it has a senten-tial complement.
Again, this effect was replicatedhere.The results showed that the disambiguatingword given the previous context is more difficultin garden-path sentences compared to control sen-tences.
There are two possible explanations forthe processing difficulty.
One is that the POS se-quence of a garden-path sentence is less probablethan that of its control sentence.
The other accountis that the disambiguating word in a garden-path52sentence is a lower frequency word compared tothat of its control sentence.For example, slower reading time was observedin (13a) and (14a) compared to (13b) and (14b) atthe disambiguating region that is bolded.
(13) Different POS at the Disambiguating Regiona.
Katie laid the dress on the floor onto(?57.80) the bed.b.
Katie laid the dress on the floor after(?55.77) her mother yelled at her.
(14) Same POS at the Disambiguating Regiona.
The umpire helped the child on (?42.77)third base.b.
The umpire helped the child to (?42.23)third base.The log probability for each disambiguating wordis given at the end of each sentence.
As ex-pected, the probability at the disambiguating re-gion in (13a) and (14a) is lower than in (13b) and(14b) respectively.
The disambiguating words in(13) have different POS?s; Preposition in (13a) andConjunction (13b).
This suggests that the prob-abilities of different POS sequences can accountfor different reading time at the region.
In (14),however, both disambiguating words are the samePOS (i.e.
Preposition) and the POS sequencesfor both sentences are identical.
Instead, ?on?and ?to?, have different frequencies and this in-formation is reflected in the conditional probabil-ity P (wordi|state).
Therefore, the slower read-ing time in (14b) might be attributable to the lowerfrequency of the disambiguating word, ?to?
com-pared to ?on?.4.3 Probability Re-rankingThe probability re-ranking reported in Corley andCrocker (2000) was replicated.
The tagger suc-cessfully resolved the ambiguity by reanalysiswhen the ambiguous word was immediately fol-lowed by the disambiguating word (e.g.
With-out her he was lost.).
If the disambiguating worddid not immediately follow the ambiguous region,(e.g.
Without her contributions would be very in-adequate.)
the ambiguity is sometimes incorrectlyresolved.When revision occurred, probability droppedmore sharply at the revision point and at the dis-ambiguation region compared to the control sen-?41?36?31?26?21(b)  " The woman told the joke did not ... "?30?25?20?15?10?5(a)    " The woman chased by ... "thewomanchased (MV)chased (PP)bythetoldthejokedidbutFigure 2: Probability Transition in the RR Ambi-guity(a) ?
?
?
: Non-Garden-Path (Past Tense Verb), ?
?
?
:Garden-Path (Past Participle)(b) ?
?
?
: Non-Garden-Path (Past Tense Verb), ?
?
?
:Garden-Path, (Past Participle)tences.
When the ambiguity was not correctly re-solved, the probability comparison correctly mod-eled the comparative difficulty of the garden-pathsentencesOf particular interest in this study is RR ambi-guity resolution.
The tagger predicted the process-ing difficulty of the RR ambiguity with probabil-ity re-ranking.
That is, the tagger initially favorsthe main-verb interpretation for the ambiguous -edform, and later it makes a repair when the ambigu-ity is resolved as a past-participle.In the first graph of Figure 2, ?chased?
is re-solved as a past participle also with a revisionsince the disambiguating word ?by?
is immedi-ately following.
When revision occurred, proba-bility dropped more sharply at the revision pointand at the disambiguation region compared to thecontrol sentences.
When the disambiguating wordis not immediately followed by the ambiguousword as in the second graph of Figure 2, the ambi-guity was not resolved correctly, but the probaba-biltiy decrease at the disambiguating regions cor-rectly predict that the garden-path sentence wouldbe harder.The RR ambiguity is often categorized as a syn-tactic ambiguity, but the results suggest that theambiguity can be resolved locally and its pro-cessing difficulty can be detected by a finite statemodel.
This suggests that we should be cautious53in assuming that a structural explanation is neededfor the RR ambiguity resolution, and it could bethat similar cautions are in order for other ambi-guities usually seen as syntactic.Although the probability re-ranking reported inthe previous studies (Corley and Crocker, 2000;Frazier, 1978) is correctly replicated, the taggersometimes made undesired revisions.
For exam-ple, the tagger did not make a repair for the sen-tence The friend accepted by the man was very im-pressed (Trueswell, 1996) because accepted is bi-ased as a past participle.
This result is compatiblewith the findings of Trueswell (1996).
However,the bias towards past-participle produces a repairin the control sentence, which is unexpected.
Forthe sentence, The friend accepted the man whowas very impressed, the tagger showed a repairsince it initially preferred a past-participle analy-sis for accepted and later it had to reanalyze.
Thisis a limitation of our model, and does not matchany previous empirical finding.5 DiscussionThe current study explores Corley and Crocker?smodel(2000) further on the model?s account of hu-man sentence processing data seen in empiricalstudies.
Although there have been studies on aPOS tagger evaluating it as a potential cognitivemodule of lexical category disambiguation, therehas been little work that tests it as a modeling toolof syntactically ambiguous sentence processing.The findings here suggest that a statistical POStagging system is more informative than Crockerand Corley demonstrated.
It has a predictivepower of processing delay not only for lexi-cally ambiguous sentences but also for structurallygarden-pathed sentences.
This model is attractivesince it is computationally simpler and requiresfew statistical parameters.
More importantly, it isclearly defined what predictions can be and can-not be made by this model.
This allows system-atic testability and refutability of the model un-like some other probabilistic frameworks.
Also,the model training and testing is transparent andobservable, and true probability rather than trans-formed weights are used, all of which makes iteasy to understand the mechanism of the proposedmodel.Although the model we used in the currentstudy is not a novelty, the current work largely dif-fers from the previous study in its scope of dataused and the interpretation of the model for humansentence processing.
Corley and Crocker clearlystate that their model is strictly limited to lexicalambiguity resolution, and their test of the modelwas bounded to the noun-verb ambiguity.
How-ever, the findings in the current study play out dif-ferently.
The experiments conducted in this studyare parallel to empirical studies with regard to thedesign of experimental method and the test mate-rial.
The garden-path sentences used in this studyare authentic, most of them are selected from thecited literature, not conveniently coined by theauthors.
The word-by-word probability compar-ison between garden-path sentences and their con-trols is parallel to the experimental design widelyadopted in empirical studies in the form of region-by-region reading or eye-gaze time comparison.In the word-by-word probability comparison, themodel is tested whether or not it correctly pre-dicts the comparative processing difficulty at thegarden-path region.
Contrary to the major claimmade in previous empirical studies, which is thatthe garden-path phenomena are either modeled bysyntactic principles or by structural frequency, thefindings here show that the same phenomena canbe predicted without such structural information.Therefore, the work is neither a mere extendedapplication of Corley and Crocker?s work to abroader range of data, nor does it simply con-firm earlier observations that finite state machinesmight accurately account for psycholinguistic re-sults to some degree.
The current study providesmore concrete answers to what finite state machineis relevant to what kinds of processing difficultyand to what extent.6 Future WorkEven though comparative analysis is a widelyadopted research design in experimental studies,a sound scientific model should be independentof this comparative nature and should be able tomake systematic predictions.
Currently, proba-bility re-ranking is one way to make systematicmodule-internal predictions about the garden-patheffect.
This brings up the issue of encoding moreinformation in lexical entries and increasing am-biguity so that other ambiguity types also can bedisambiguated in a similar way via lexical cate-gory disambiguation.
This idea has been exploredas one of the lexicalist approaches to sentence pro-cessing (Kim et al, 2002; Bangalore and Joshi,541999).Kim et al (2002) suggest the feasibility of mod-eling structural analysis as lexical ambiguity res-olution.
They developed a connectionist neuralnetwork model of word recognition, which takesorthographic information, semantic information,and the previous two words as its input and out-puts a SuperTag for the current word.
A Su-perTag is an elementary syntactic tree, or sim-ply a structural description composed of featureslike POS, the number of complements, categoryof each complement, and the position of comple-ments.
In their view, structural disambiguationis simply another type of lexical category disam-biguation, i.e.
SuperTag disambiguation.
Whenapplied to DO/SC ambiguous fragments, such as?The economist decided ...?, their model showeda general bias toward the NP-complement struc-ture.
This NP-complement bias was overcome bylexical information from high-frequency S-biasedverbs, meaning that if the S-biased verb was a highfrequency word, it was correctly tagged, but if theverb had low frequency, then it was more likely tobe tagged as NP-complement verb.
This result isalso reported in other constraint-based model stud-ies (e.g.
Juliano and Tanenhaus (1994)), but thedifference between the previous constraint-basedstudies and Kim et.
al is that the result of thelatter is based on training of the model on nois-ier data (sentences that were not tailored to thespecific research purpose).
The implementation ofSuperTag advances the formal specification of theconstraint-based lexicalist theory.
However, thescope of their sentence processing model is lim-ited to the DO/SC ambiguity, and the descriptionof their model is not clear.
In addition, their modelis far beyond a simple statistical model: the in-teraction of different sources of information is nottransparent.
Nevertheless, Kim et al (2002) pro-vides a future direction for the current study anda starting point for considering what informationshould be included in the lexicon.The fundamental goal of the current research isto explore a model that takes the most restrictiveposition on the size of parameters until additionalparameters are demanded by data.
Equally impor-tant, the quality of architectural simplicity shouldbe maintained.
Among the different sources ofinformation manipulated by Kim et.
al., the so-called elementary structural information is consid-ered as a reasonable and ideal parameter for ad-dition to the current model.
The implementationand the evaluation of the model will be exactly thesame as a statistical POS tagger provided with alarge parsed corpus from which elementary treescan be extracted.7 ConclusionOur studies show that, at least for the sample oftest materials that we culled from the standard lit-erature, a statistical POS tagging system can pre-dict processing difficulty in structurally ambigu-ous garden-path sentences.
The statistical POStagger was surprisingly effective in modeling sen-tence processing data, given the locality of theprobability distribution.
The findings in this studyprovide an alternative account for the garden-patheffect observed in empirical studies, specifically,that the slower processing times associated withgarden-path sentences are due in part to their rela-tively unlikely POS sequences in comparison withthose of non-garden-path sentences and in part todifferences in the emission probabilities that thetagger learns.
One attractive future direction is tocarry out simulations that compare the evolutionof probabilities in the tagger with that in a theo-retically more powerful model trained on the samedata, such as an incremental statistical parser (Kimet al, 2002; Roark, 2001).
In so doing we canfind the places where the prediction problem facedboth by the HSPM and the machines that aspireto emulate it actually warrants the greater powerof structurally sensitive models, using this knowl-edge to mine large corpora for future experimentswith human subjects.We have not necessarily cast doubt on the hy-pothesis that the HSPM makes crucial use of struc-tural information, but we have demonstrated thatmuch of the relevant behavior can be captured ina simple model.
The ?structural?
regularities thatwe observe are reasonably well encoded into thismodel.
For purposes of initial real-time process-ing it could be that the HSPM is using a similarencoding of structural regularities into convenientprobabilistic or neural form.
It is as yet unclearwhat the final form of a cognitively accurate modelalong these lines would be, but it is clear from ourstudy that it is worthwhile, for the sake of clarityand explicit testability, to consider models that aresimpler and more precisely specified than thoseassumed by dominant theories of human sentenceprocessing.55AcknowledgmentsThis project was supported by the Cognitive Sci-ence Summer 2004 Research Award at the OhioState University.
We acknowledge support fromNSF grant IIS 0347799.ReferencesS.
Bangalore and A. K. Joshi.
Supertagging: anapproach to almost parsing.
Computational Lin-guistics, 25(2):237?266, 1999.T.
G. Bever and B. McElree.
Empty categoriesaccess their antecedents during comprehension.Linguistic Inquiry, 19:35?43, 1988.L Burnard.
Users Guide for the British NationalCorpus.
British National Corpus Consortium,Oxford University Computing Service, 1995.S.
Corley and M. W Crocker.
The Modular Sta-tistical Hypothesis: Exploring Lexical CategoryAmbiguity.
Architectures and Mechanisms forLanguage Processing, M. Crocker, M. Picker-ing.
and C. Charles (Eds.)
Cambridge Univer-sity Press, 2000.W.
C. Crocker and T. Brants.
Wide-coverage prob-abilistic sentence processing, 2000.F.
Ferreira and C. Clifton.
The independence ofsyntactic processing.
Journal of Memory andLanguage, 25:348?368, 1986.F.
Ferreira and J. Henderson.
Use of verb infor-mation in syntactic parsing: Evidence from eyemovements and word-by-word self-paced read-ing.
Journal of Experimental Psychology, 16:555?568, 1986.L.
Frazier.
On comprehending sentences: Syntac-tic parsing strategies.
Ph.D. dissertation, Uni-versity of Massachusetts, Amherst, MA, 1978.L.
Frazier and C. Clifton.
Construal.
Cambridge,MA: MIT Press, 1996.L.
Frazier and K. Rayner.
Making and correct-ing errors during sentence comprehension: Eyemovements in the analysis of structurally am-biguous sentences.
Cognitive Psychology, 14:178?210, 1982.J.
Hale.
A probabilistic earley parser as a psy-cholinguistic model.
Proceedings of NAACL-2001, 2001.V.
M. Homes, J. O?Regan, and K.G.
Evensen.
Eyefixation patterns during the reading of relativeclause sentences.
Journal of Verbal Learningand Verbal Behavior, 20:417?430, 1981.A.
K. Joshi and B. Srinivas.
Disambiguation ofsuper parts of speech (or supertags): almostparsing.
The Proceedings of the 15th Inter-national Confer-ence on Computational Lin-gusitics (COLING ?94), pages 154?160, 1994.C.
Juliano and M.K.
Tanenhaus.
A constraint-based lexicalist account of the subject-object at-tachment preference.
Journal of Psycholinguis-tic Research, 23:459?471, 1994.D Jurafsky.
A probabilistic model of lexical andsyntactic access and disambiguation.
CognitiveScience, 20:137?194, 1996.A.
E. Kim, Bangalore S., and J. Trueswell.
A com-putational model of the grammatical aspects ofword recognition as supertagging.
paola merloand suzanne stevenson (eds.).
The Lexical Basisof Sentence Processing: Formal, computationaland experimental issues, University of GenevaUniversity of Toronto:109?135, 2002.J.
King and M. A.
Just.
Individual differences insyntactic processing: The role of working mem-ory.
Journal of Memory and Language, 30:580?602, 1991.B.
MacWhinney.
Basic syntactic processes.
Lan-guage acquisition; Syntax and semantics, S.Kuczaj (Ed.
), 1:73?136, 1982.W.
M. Mak, Vonk W., and H. Schriefers.
The influ-ence of animacy on relative clause processing.Journal of Memory and Language,, 47:50?68,2002.C.D.
Manning and H. Schu?tze.
Foundations ofStatistical Natural Language Processing.
TheMIT Press, Cambridge, Massachusetts, 1999.S.
Narayanan and D Jurafsky.
A bayesian modelpredicts human parse preference and readingtimes in sentence processing.
Proceedingsof Advances in Neural Information ProcessingSystems, 2002.B.
Roark.
Probabilistic top-down parsing and lan-guage modeling.
Computational Linguistics, 27(2):249?276, 2001.M.
J. Traxler, R. K. Morris, and R. E. Seely.
Pro-cessing subject and object relative clauses: evi-dence from eye movements.
Journal of Memoryand Language, 47:69?90, 2002.J.
C. Trueswell.
The role of lexical frequencyin syntactic ambiguity resolution.
Journal ofMemory and Language, 35:556?585, 1996.A.
Viterbi.
Error bounds for convolution codes andan asymptotically optimal decoding algorithm.IEEE Transactions of Information Theory, 13:260?269, 1967.56
