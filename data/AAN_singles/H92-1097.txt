ROBUST CONTINUOUS SPEECH RECOGNITIONPIs: John Makhoul and Richard Schwartzmakhoul@bbn.com, schwartz@bbn.comBBN Systems and Technologies, 10 Moulton St., Cambridge, MA 02138OBJECTIVESThe pnrnary objective of this basic researchprogram is to develop robust methods andmodels for speaker-independent acousticrecognition of spontaneously-produced,:ontinuous speech.
The work has focussedon developing accurate and detailed modelsof phonemes and their coarticulation for thepurpose of large-vocabulary continuousspeech recognition.
Important goals of thiswork are to achieve the highest possibleword recognition accuracy in continuousspeech and to develop methods for therapid adaptation of phonetic models to thevoice of a new speaker.RECENT RESULTS?
Ported our BYBLOS speechrecognition software to run on SiliconGraphics Inc. workstations, in addtionto Sun workstations.
In the process,we consolidated our programs andmodularized them to make them moreeasily portable to other sites andapplications.?
Developed methods for modelingspontaneous peech effects in theAirline Travel Information System(ATIS) domain.?
Developed a novel method for silencemodeling in spontaneous peech,especially to deal with the problem ofmissing silences in the transcriptions.The method works iteratively byhypothesizing silences everywhere inthe grammar, performing recognition,correcting the transcnptions based onthe recognition, and then retraining.?
Developed a trigram language model forthe ATIS domain.
This was possiblebecause of the availability of sufficienttraining data.
Because of the potentiallarge amount of computation associatedwith trigram grammars, we achievedlarge savings in computation by simplyrescoring an N-best list that wasproduced using a bigram grammar.In the most recent speech recognitiontest on the ATIS domain, using datacollected from five different sites, ourBYBLOS system achieve a 9.6%average word error rate over allutterances.
This performance was thebest among all sites tested.The N-best paradigm allows the simpleand modular integration of manyknowledge sources.
Recently, we havecombined our BYBLOS HMM systemto another system at Boston Universitybased on Stochastic Segment Models.The hybrid system improved speechrecognition performance over our state-of-the-art HMM system.A hybrid system consisting of ourBYBLOS system and another phoneticmodeling technique using neuralnetworks, called Segmental NeuralNetworks, has also succeeded inimproving performance over our HMMsystem by reducing the error rate by25%.PLANS FOR THE COMING YEARFor the coming year, we plan to continueour work on improving speech recognitionperformance on spontaneous speech in theATIS domain.
In addition, we plan to startwork on the new Wall Street Journalcontinuous speech recognition corpus.
Ourresearch into improved modeling willinclude the exploration of new acousticfeatures and methods for rapid speakeradaptation.464
