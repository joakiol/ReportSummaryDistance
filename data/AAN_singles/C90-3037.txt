Coordination in an A xlomatl  Grammar*Dav id  Mi lwa.rdUniversity of CambridgeComputer LaboratoryNew Museums Site, Pembroke Street, Cambridge, CB2 3QG, Englanddrml@cl.cam.ac.ukAbstractFor some time there has been interest in the idea ofparsing as deduction.
Here we present a grammati-cal tbrmalism, 'Axiomatic Grammar' ,  which is basedupon a small number of linguistically motivated ax--toms and deduction rules.
Each axiom or rule com-bines a 'category' with a string of words to form afurther category.
This contrasts with the usual 'tree-structure' approach to syntactic analysis where con-stituents are combined with each other to form afurther constituent.We describe a grammar for English which hasa good coverage of 'non-constituent' coordination.The grammar has been integrated with a toy se-mantics, and has been implemented in a left-to-right parser with incremental semantic interpreta-tion.
The parser does not suffer fi'om spurious am-biguity.I In t roduct ionCoordi:uation is a particularly troublesome phe-nomenon to account for in theories of syntax basedupon phrase structure rules.
Acceptable xamples of'non-constituent' coordination such as:(1) Jolhn gave Mary a book and Peter a paper(2) Ben likes and Fred admires Maryhave led some to abandon a single level of gram-matical description, and others to abandon phrasestructure rules.An example of the former approach is Modi-fier Structure Grammar (Dahl and McCord, 1983),which was justified as tbllows:... it appears that a proper and generaltreatment must recognise coordination asa "metagrmnmatieal'  construction, in thesense that metarules, general system oper-ations, or 'second-pass' operations uch astransformations, are needed for its formu-lation.Modifier Structure Grammar embeds its rules for co-ordination into the parsing algorithm (there are close*This research was supported by an SE\[IC resem'chstudentship.parallels with the SYSCONJ system (Woods, 1973)).In order to parse sentence (2), the state of the parserat the point immediately before 'Fred' is matched tothe state immediately before 'Ben'.
'Fred admires' isthen parsed, and the resulting state is merged withthe state after parsing 'lien likes'.The alternative approach to dealing with coordi-nation uses a single level of grammatical description,but uses a weaker notion of constituency than phrasestructure grammar.
It is presently exemplified byproposals to extend Categorial Grammar with For-ward Composition, the Product operator, SubjectType-Raising etc.Categorial Grammar,  just like phrase structuregrammar, is based upon the combination of oneor more constituents to form a further constituent.In order to deal with coordination, the category(X\X) /X  1 is assigned to the conjunction, or, n\ ]oreusually, a phrase structure rule is invoked of the form:X -~X conj XIn either case, each conjunct has to be assigned acategory.
Extensions to Categorial Grammar pro-vide a greater coverage of coordination phenomenaby allowing a greater number of strings to form cat-egories.
For example, to accept both (2) and (3),(3) Ben likes Mary and admires Janean extended grammar must allow 'Ben likes' to forma category which can combine with 'Mary'  to form asentence, and 'likes Mary' to form a category whichcan combine with 'Ben' to form a sentence.
Theconsequence of this is that the simple sentence 'Benlikes Mary' can be assigned at least two different syn-tactic structures: (Ben (likes Mary)) or ((Ben likes)Mary), which both correspond to the same readi,g(the sentence is spuriously ambiguous according tothe grammar).Axiomatic Grammar avoids the problem of spu-rious ambiguity by avoiding the need to assign cat-egories to conjuncts.
Although the formalism wasdeveloped uring research into extended CategorialGrammar,  the separation of grammatical informa-tion into axioms and rules makes its treatment ofcoordination look similar to that in a metalevel ap-proach such as Modifier Structure Grammar.
'\]'his1 Capita\] letters will be used to denote variables througl~outthis paper.l 207similarity is easiest o show if we introduce the cen-tral notion of 'category transition' through the ideaof state transition.Consider a left-to-right parse of the sentence 'aman sits' based upon a phrase structure grammarincluding the rules:s --~ np vp np --+ det nInitially we start in a state expecting a sentence(which we can encode as a list (s)).
After absorb-ing the determiner, 'a', we can move to a new statewhich expects a noun followed by a verb-phrase (en-coded as a list (n,vpl).
Following the absorption of'man', we can move to a state expecting just a verb-phrase, and following the absorption of 'sits' we havea successful parse since there is no more input andnothing more expected.
The transitions between theencodings of the states are as follows:(s) + "a" --* (n,vp) where a:det(n,vp} + "man"-+ (vp} where man:n(vp) + "sits" ~ 0 where sits:vp('a:det' means lhat the word "a' is a determiner)Instead of deriving these transitions from the phrasestructure rules, consider directly supplying axioms ofthe form:<s> + "w" --+ <n,vp) where W:det(n,vp> -{- :'W" ---+ (vp> where W:n<vp} + "W" --+ <> where W:vpIf constituent names are replaced by category speci-fications, generalisations become possible.
The threeaxioms:<s) + "W" --* <n,s\np) where W:np/n(n,s\np) + "W" --+ (s\np) where W:n(s\np) + "W" --* (> where W:s\np( 'np/n'  is an np requiring a noun on its right, and's\np' is a sentence requiring an up on its left)are instantiations of the axioms:<X) ?
R + "W" -+ <Z,X\Y) ?
R where W:Y/Z(X) ?
R + "W" --+ R where W:X('X' is the head and 'R', the tail of the list encodingthe state. '
. '
denotes concatenation, so '(n,s\np}' isequivalent o '(n) ?
<s\np>')The 'encoded states' will roughly correspond to'principal' categories in Axiomatic Grammar, andthe axioms above to the axioms of Prediction andComposition.The rule for coordination in Axiomatic Grammaris stated in terms of principal category transition.For example, the acceptability of sentence (2) is de-pendent upon a proof that the two strings "Ben likes"and "Fred admires" both take us from the initialcategory (corresponding to a parsing state expect-ing a sentence) to a second category (correspondingto a state expecting a noun-phrase).
The rule willbe stated formally after a general description of theformalism.2 The  Bas icsAxiomatic Grammar is mainly lexically based, withlexical entries containing both subcategorisation a dorder information.
An association of a word witha 'lexical' category is given by an expression of theform:word: LEX-CATEach lexical category is a feature valued structure.The features of interest are 'cat', which gives thebase type of the category ('s','np', or 'n'), and 'left'and 'right' which contain lists of 'arguments'.
Eachargument is itself a lexical category.
Categories arecomplete if the argument lists are empty.
As an ex-ample, consider the lexical entries for the determiner'the' and the transitive verb 'likes':\[ \[ cat  = np left = 0 the: right = ("ca% -- 8left = (likes:right = (\[ca% -~ n \] Ileft = 0 )righZ = 0\] cat  =np left = 0 )right = 0cat  = ~p \]left = 0 J )right = 0We can read the category for 'likes' as follows: givena complete noun-phrase on the left and a completenoun-phrase on the right, we can form a completesentence.
It is Worth comparing this category withthe category generally assigned to 'likes' by a Cate-gorial Grammar:(S \ NP)/  NPThe categories differ in two respects.
Firstly, theCategorial Grammar category not only provides in-formation as to what is on the left, and what is onthe right, but also determines the order in which eachargument is to be absorbed (in the above, the argu-ment on the right must be absorbed first, followedby the argument on the left).
Secondly, whereasthe Categorial Grammar category would be regardedas having the syntactic type 'np~-~(np--+s)', the Ax-iomatic Grammar category is regarded as having thebase type 's'.
This difference has a bearing on thetreatment of modifiers (discussed later).When a string of words is absorbed it causes atransition between principal categories.
A princi-pal category is again a feature structure, the featureof interest being the 'right' feature i.e.
the list ofargmnents 2 required on the right.
A parse of a sen-tence consists of a proof that, starting with a prin-cipal category which requires a sentence, we can end2 Arguments  are again lexical categories.208 2up with a complete principal category.
I'br example,Lo prove that 'Ben sits' is a sentence we prove thestatement 31 (} ) "Ben sits" r = 0 4r ()llenceforth, the convention is adopted that left orright argument lists which are not specified areempty.
This allows us to rewrite the statement aboverather more compactly as:A proof of a parse is performed using rules and ax-ioms.
An a?aom declares that a string of words per-{brms a transition between two principal categories.Axioms are either simple statements, or restricted~tatements of the form:Co String C1 where ....Three axiorns will be discussed here 5.
The first, Iden-i;ity, merely declares that an empty string performsthe identity transition i.e.Co ";; C0The other axioms, Prediction and C, omposition, workon strings consisting of a single word.
They have theformat:Co "W" C1 where W:LEX-CATrFhe flfll definitions, given in Figure 1, should becomeclearer as we work through an example.A deduction rule in Axiomatic Grammar declaresthat a string of words performs a transition betweent~vo principal categories provided that certain sub-st.rings perform certain transitions i.e.
rules have theformat6:Co String0 C1, ... ,C~ String, C,~+1Ca String C~(subscripted strings are substrings of'String')The consequent of a rule (the statement tinder theline) can be proved by proving all the antecedents(the staternents above the line).3Feature names  arc abbreviated in an obvious manner .Simple s ta tements  have the general form:Co String C1('Co'and 'C1' are principal categories, and 'String' is a string4 The corresponding state t rans i t ion would be:(s) + "Ben sits" -+ 05A four th  ax iom is used for topical isation.6This is actual ly the form of simple rules.
As with aximr~s,rules may be restr icted using a 'where' clause.3 An Example ProofIn order to prove that 'Ben sits' is a sentence, we needto use all the axioms, and two rules, Sequencing andOptional Reduction.
The relevant proof tree is givenin Figure 2 7.The Prediction Axiom is restricted in English tothe case where a category requires a sentence on theright, and the word encountered has a lexical cate-gory of base type noun-phrase.
Thus starting withthe principal category:we can absorb the proper-name 'BeeF, which hasthe lexical category, \[c = up l, to form a princi-pal category, 'c0', which requires first an optionalnoun-phrase modifier (e.g.
a non-restrictive r lativeclause), and then a sentence which requires a noun-phrase (a verb-phrase) i.e.= , ,p \ ] l  ' np \ ] /  I(the use of parenlheses around the base type of thenoun-phrase modifier denotes optionalily s)Writing this as a statement in the logic, we have aproof that:\ [ r  = (\[c = s \ ] ) \ ]  "Ben" cOThe Sequencing Rule 9 is used to combine the effectsof the absorption of two strings.
The rule declaresthat if one string defines a transition from Category0to Category1, and another defines a transition fromCategory1 to Category2, then the combined stringdefines a transition from Category0 to Category2 i.e.Co String0 Ca, CI String 1 C2Co String 0 ?
String 1 C~(here 'e' denotes concatenation of word strings e.g."Ben"?
"sits" is equivalent to "Ben sits")For this example, we can instantiate the Sequenc-ing Rule as follows:i j, \] " eo" cO, co \[ \]I t :  ,,B0o \[ \]7At this stage no restr ict ions have been imposed upon theordering of the rules, and more than  one proof  tree is possible.However, it is relatively trivial to prove the existence of anolwnal proof s t rategy which suppl ies a single proof tree for agiven sentence and a possible semant ics  (Milward, 1990).8Parentheses are used as a shor thand.
The lexical cate-gories ill a rgument  lists actual ly include a featm'e 'opt',  whichis set to an un ins tant ia ted  variable when the argument  is op.tional, to ' t rue'  if the a rgument  is compulsory.9The name 'Sequencing Rule'  is due to a loose correspon-dence between the grammar  and  the Floyd Iloare Ihlles forAxiomat ic  Semant ics of p rogramming  languages3 209COMPOSITION:r  = ( 1 L ) .
r = R ' , (r R"1 1c = (X) \ ] ) ,R" \ [  where J J !=x W: = L RoR'PREDICTION' 1 ( c = Y ) ) .R"( ' . '
denotes concatenation of lists.
Optional arguments have the value of the 'cat' feature in parentheses.X may be instantiated to the base types 's','np', or 'n'; L,I~,R' and R" lo lists of categories)Figure 1: Axioms.............. IDENTITY\[\]'"' \[1.................
COMPOSITION ..............
OPTIONAL REDN i - .1L d............................................................. SEQUENCINGc l"s i ts"  \ [ \ ]............................................
PREDICTION ...................
OPTIONAL REDN........................................................................................................... SEQUENCING( "cO','cl' and 'c2' are principal categories mentioned i'a the text)Figure 2: Proof Tree for 'Ben sits'We can thus obtain a proof of the whole sentence byproving the antecedents to the rule.
The first, hasalready been proved, so we are left to prove:cO "sits" \ [ \ ]The head of the argument list of cO is an optionalnoun-phrase modifier, Optional categories at thehead of the argument list of a principal category canbe deleted by the use of the Optional Reduction Rulewhich is as follows:\ [ r  = R"\ ]  String Cr = ( 1 = L )* String Cr = RWe instantiate the Optional Reduction Rule to:cl "sits" \ [ \ ]c0"s i t s " \ [ \ ]in which 'e l '  is cO without the optional modifier i.e.r=(  ( c=np)  )Tile proof now consists of proving the antecedent oftile Optional Reduction Rule i.e.r = ( (\[c : ,p \ ] /  )This can be proved using first the Composition Ax-iom, then tile Sequencing Rule followed by OptionalReduction, and finally the Identity Axiom.The Composition Axiom 1?
absorbs a word whichhas the same base category as the head of the a~r-gument list of a principal category.
Since the word'sits' has the following category:\ [ c_ -s  \]i = ( \ [ c :  npthe Composition Axiom can be used to absorb 'sits'and get us to the category 'c2"l ?The  name 'Composi t ion '  is due to the sinfi larity withthe rule of general ised I~rward  Composi t ion in a CatcgorialG r&mlll&r.210 4Using the Sequencing Rule once more, we can provethe whole given a proof ofr : l  i ( \ [~:~\ ] ) )  .
.
.
.which can be proved by first invoking the OptionalReduction Rule.
The optional sentcntial modifier isthen deleted, leaving ,is with a proof of\[\] .... \[\]which is true by the Identity Axiom.4 tgu l .es  and  Lex ica l  I temsSo tar we have introduced three axioms which areused by the grammar, and two rules.
Before consid-ering further rules it is worth discussing the grammaras it stands.The effect of the axioms, Prediction and Compo-sition, is to absorb a word and to predict an op-tional modifier for the base type.
For exarnple, inparsing 'the girl' a noun-phrase modifier is predictedafter parsing 'the' and a noun-modifier is predictedafter parsing 'girl'.
Thus, given a treatment of non-restrictive relatives, we could parse something like:(4) The girl outside, who has been waiting a longtime, looks frozenMoreover, alter parsing a noun modifier, anothernoun modifier is predicted (the base type of a nounmodifier is, after all, a noun).
Thus we could alsoparse(5) The girl outside in the red dress with the largeman ....Although the treatment of noun and noun-phrasemodification looks reasonably traditional, the treat-ment of verbal modification is less so.
Since the basetype of a verb is a sentence, a modifier for the verbhas the same type as a sentential modifier.
For ex-ample, in:(6) John hit the ball with a racketthe action of the Composition Axiom is to add anoptional sentential modifier onto tile end of the sub-categorisation list of the verb 'hit', and then to addthis list onto the list of expected arguments i.e.
afterabsorbing "hit" the principal category becomes:":= I ~ = np , i :  (\[~ = s\]lA successful proof of the sentence is achieved by giv-ing 'wit l f  a lexical entry:Sentences uch as ' John decided to sack Mary in se-cret?
are correctly treated as being structurally am-biguous, since 'in secret' may modify the 's' intro-duced by 'decided' or the %' introduced by 'sack'.The grammar which has been described so far ira=.poses a strict notion of word order.
This seems par-ticularly inappropriate fbr relative clauses which canbe extraposed from a position following the subjectnoun-phrase to after the verb-phrase.
Consider thesentence:(7) Children arrived who only spoke EnglishThe present grammar treats this case by allow-ing heavy noun and noun-phrase modifiers to swa.pplaces with categories having a base type ~s'.
Thusthe principal category created afLer absorbing "Chil-dren" :\[ \]\[can be transformed into:i <\[~ : .,~p\]> )r : / 1 / I t  : ' : /The possibility is being considered of replacing listsof arguments by sets of arguments associated withlinear precedence constraints (along the lines ofwork done on bounded discontinuous constituency(Rcape, 1989)).Finally, let us consider the particular restrictionwhich was made to the Prediction Rule  for English.The effect of the restriction is that the only accept-able lexical entries with left arguments are either ofthe form1 = ( c =np ) or 1 = ( c = X )r=  R r = Ri.e.
verbs (which require a noun-phrase subject ontheir left), or modifiers of the base types.5 The  Coord inat ion  Ru leThe Coordination Rule is as follows:Co String0 C1, Co String 1 C1Co String0 ?
"W" ?
String I C1where W 6 {and,or,but\]This contrasts with the phrase structure rule:X --, X conj Xwhich can be expressed in deduction rule format as:String 0 : X, String 1 : XString 0 g "W" ?
String I : Xwhere W 6 {and,or,but}Both rules allow nested and iterated conjunction,5 211however, whereas the phrase structure rule enforcesthat conjuncts are of the same category, the Coordi-nation Rule enforces that each conjunct defines thesame transition between principal categories.We can show the expressive power of the Coordi-nation Rule by considering some examples.
The firstis an example of 'unbounded' Right-Node Raising:(8) John admires, but Mary thinks he loves, the newteacherThis can be proved by separately proving that both"John admires" and "Mary thinks he loves" performa transition between the initial principal category,\[r = (\[c = s\]) \] and the category:r = ( ~ = np  , 1 ( \ [?
= s \ ] )  )The proof is completed by proving that "the teacher"defines a transition between this category and thecomplete principal category, \[\].The second example involves sharing on both theright and the !eft:(9) He lent John a book, and Mary a paper, aboutsubjacency .This example, which has been used to argue for theaddition of recta-rules to Categorial Grammar (Mor-rill, 1987), is of interest when the required reading iswhere the noun modifier 'about subjacency' appliesto both the book and the paper.
To prove the sen-tence we first prove that "He lent" performs a tran-sition between the initial principal category and thecategory:We then prove separately that "John a book", and"Mary a paper" perform a transition between thiscategory and the category:\[ 1\[ 1\] r : I / : n i l  = ' \ ]1  /Finally we prove that the string "about subjacency"takes us from this category to the complete category,\[\].The basic grammar does accept some sentenceswhich are generally regarded as unacceptable, andextra features are needed to constrain the rules.
Thesituation with the basic grammar is not, however,as bad as with many extended Categorial Gram-mars.
The Coordination Rule enforces a parallelismbetween conjuncts in a similar manner to the par-allelism enforced by the phrase structure rule men-tioned above.
This can be contrasted with assign-ing conj unctions the polymorphic category (X\X)/X,which allows sentences like:(10) John likes Mary and, or Peter likes Joan andAnneFurther parallelism is enforced by tile particulartreatment of wh-movement n which, for example,predicts the acceptability of (11) but not of (12):(11) The book arrived which John had shown Maryand given to Peter(12) *The book arrived which John had shownMary and to Peter6 Conclus ionThis paper has introduced Axiomatic Grammar, andhas given some justification for particular axioms andrules chosen for English.
The formalism itself hasbeen left very much underspecified, and further re-search is required both into its applicability to otherlanguages, and into its formal properties.A larger grammar for English has been imple-mented, including a treatment of wh-movement andverbal ellipsis (gapping).
The parser works word-by-word from left-to-right, and was designed so thatincorporation of the coordination rule does not slowdown parsing in general.Axiomatic Grammar fits in naturally with an in-cremental approach to semantic interpretation, orwith semantics based upon state change.
Thepresent, grammar is integrated with a toy semanticsbased upon the incremental (but non-monotonic) ac-cumulation of constraints.ReferencesDahl, Veronica and McCord, Michael C. (1983).Treating Coordination in Logic Grammars.Computational Linguistics, 9(2):69-91.Milward, David R. (1990).
Ph.D. Thesis.
Forthcom-ing.Morrill, Glyn (1987).
Meta-Categorial Grammar.In Haddock, Nicholas, Klein, Ewan, and Mor-rill, Glyn (eds.
), Categorial Grammar, Unifica-tion Grammar and Parsing, Centre for CognitiveScience, University of Edinburgh.Reape, Mike (1989).
A Logical Treatment of Semi-Free Word Order and Bounded DiscontinuousConstituency.
In European ACL, pages 103-110.Woods, W. (1973).
An Experimental Parsing Systemfor Transition Network Grammars.
In l%ustin, R.(ed.
), Natural Language Processing, AlgorithmicsPress.11 The rules for wh-movement  involve the use of a featm'eon pr inc ipal  categories which 'stacks'  ext racted  elements, andthe use of further  features to control  ext ract ion  sites.212 6
