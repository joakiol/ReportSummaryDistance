Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ?
AfLaT 2009, pages 38?45,Athens, Greece, 31 March 2009. c?2009 Association for Computational LinguisticsPart-of-Speech tagging of Northern Sotho:Disambiguating polysemous function wordsGertrud Faa???
Ulrich Heid?
Elsabe?
Taljard?
Danie Prinsloo??
Institut fu?r Maschinelle Sprachverarbeitung ?
University of PretoriaUniversita?t Stuttgart South AfricaGermanyfaaszgd@ims.uni-stuttgart.de elsabe.taljard@up.ac.zaheid@ims.uni-stuttgart.de danie.prinsloo@up.ac.zaAbstractA major obstacle to part-of-speech(=POS) tagging of Northern Sotho(Bantu, S 32) are ambiguous functionwords.
Many are highly polysemous andvery frequent in texts, and their localcontext is not always distinctive.With certain taggers, this issue leads tocomparatively poor results (between 88and 92 % accuracy), especially whensizeable tagsets (over 100 tags) are used.We use the RF-tagger (Schmid and Laws,2008), which is particularly designed forthe annotation of fine-grained tagsets (e.g.including agreement information), andwe restructure the 141 tags of the tagsetproposed by Taljard et al (2008) in a wayto fit the RF tagger.
This leads to over94 % accuracy.
Error analysis in additionshows which types of phenomena causetrouble in the POS-tagging of NorthernSotho.1 IntroductionIn this paper, we discuss issues of the part-of-speech (POS) tagging of Northern Sotho, one ofthe eleven official languages of South Africa, spo-ken in the North-east of the country.
NorthernSotho is a Bantu language belonging to the Sothofamily (Guthrie, 1967: S32).
It is written disjunc-tively (contrary to e.g.
Zulu), i.e.
certain mor-phemes appear as character strings separated byblank spaces.
It makes use of 18 noun classes (1,1a, 2, 2b, 3 to 10, 14, 15, and the locative classes16, 17, 18, N-, which may be summarized as LOCfor their identical syntactic features).
A concor-dial system helps to verify agreement or resolveambiguities.We address questions of the ambiguity of func-tion words, in the framework of an attempt to use?standard?
European-style statistical POS taggerson Northern Sotho texts.In the remainder of this section, we briefly dis-cuss our objectives (section 1.1) and situate ourwork within the state of the art (section 1.2).
Sec-tion 2 deals with the main issues at stake, the han-dling of unknown open class words, and the pol-ysemy of Northern Sotho function words.
In sec-tion 3, we discuss our methodology, summarizingthe tagset and the tagging technique used, and re-porting results from other taggers.
Section 4 isdevoted to details of our own results, the effectsof the size of training material (4.2), the effectsof polysemy and reading frequency (4.3), and itincludes a discussion of proposals for quality im-provement (Spoustova?
et al, 2007).
We concludein section 5.1.1 ObjectivesThe long term perspective of our work is to sup-port information extraction, lexicography, as wellas grammar development of Northern Sotho withPOS-tagged and possibly parsed corpus data.
Wecurrently use the 5.5 million word University ofPretoria Sepedi Corpus (PSC, cf.
de Schryverand Prinsloo (2000)), as well as a 45,000 wordstraining corpus.
We aim at high accuracy in thePOS-tagging, and at minimizing the amount of un-known word forms in arbitrary unseen corpora, byusing guessers for the open word classes.1.2 Recent workA few publications, so far, deal with POS-taggingof Northern Sotho; most prominently, de Schryverand de Pauw (2007) have presented the MaxTagmethod, a tagger based on Maximum Entropy38Learning (Berger et al, 1996) as implemented inthe machine learning package Maxent (Le, 2004).When trained on manually annotated text, it ex-tracts features such as the first and last letter ofeach word, or the first two and last two letters orthe first three and last three letters of each word;it takes the word and the tag preceding and fol-lowing the item to be tagged, etc., to decide aboutword/tag probabilities.
De Schryver and de Pauwreport an accuracy of 93.5 % on unseen data, usinga small training corpus of only ca.
10,000 wordforms.Other work is only partly engaged in POS-tagging, e.g.
Kotze?
?s (2008) finite state analysis ofthe verb complex of Northern Sotho.
This studydoes not cover all parts of speech and can thus notbe directly compared with our work.
Taljard et al(2008) and Van Rooy and Pretorius (2003) presenttagsets for Northern Sotho and the closely relatedlanguage Setswana, but they focus on the defini-tion of the tagsets without discussing their auto-matic application in detail.
In (Prinsloo and Heid,2005), POS-tagging is mentioned as a step in acorpus processing pipeline for Northern Sotho, butno experimental results are reported.2 Challenges in tagging Northern SothoPOS-tagging of Northern Sotho and of any dis-junctively written Bantu language has to deal es-pecially with two major issues which are con-sequences of their morphology and their syntax.One is the presence, in any unseen text, of a num-ber of lexical items which are not covered by thelexicon of the tagger (?unknown words?
), and theother is an extraordinarily high number of ambigu-ous function words.2.1 Unknown wordsIn Northern Sotho, nouns, verbs and adverbs areopen class items; all other categories are closedword classes: their items can be listed.
The openclasses are characterized in particular by a richmorphology: nouns can form derivations to ex-press diminutives and augmentatives, as well aslocative forms, to name just a few.
Adding thesuffix -ng to toropo ?town?, for example, formstoropong, ?in/at/to town?.
For verbs, tense, voice,mood and many other dimensions, as well as nom-inalization, lead to an even larger number of de-rived items.
Prinsloo (1994) distinguishes 18 clus-ters of verbal suffixes which give rise to over 260individual derivation types per verb.
Only a fewof these derivations are highly frequent in corpustext; however, due to productivity, a large numberof verbal derivation types can potentially appear inany unseen text.For tagging, noun and verb derivations show upas unknown items, and an attempt to cover themwithin a large lexicon will partly fail due to pro-ductivity and recursive applicability of certain af-fixes.
The impact of the unknown material ontagging quality is evident: de Schryver and dePauw (2007) report 95.1 % accuracy on knownitems, but only 78.9 % on unknowns; this leadsto a total accuracy of 93.5 % on their test corpus.We have carried out experiments with a versionof the memory-based tagger, MBT (Daelemans etal., 2007), which arrives at 90.67 % for the knownitems of our own test corpus (see section 3.2), asopposed to only 59.68 % for unknowns.To counterbalance the effect of unknown items,we use rule-based and partly heuristic guessers fornoun and verb forms (cf.
Prinsloo et al (2008) and(Heid et al, 2008)) and add their results to the tag-ger lexicon before applying the statistical tagger:the possible annotations for all words contained inthe text are thus part of the knowledge available tothe tagger.Adverbs are also an open word class in North-ern Sotho; so far, we have no tools for identifyingthem.
In high quality tagging, the suggestions ofour guessers are examined manually, before theyare added to the tagger lexicon.2.2 Polysemous function words andambiguityFunction words of Northern Sotho are highly am-biguous, and because of the disjunctive writingsystem of the language, a number of bound mor-phemes are written separately from other words.A single form can have several functions.
Forexample, the token -a- is nine-ways ambiguous:it can be a subject concord of noun class 1 or 6,an object concord of class 6, a possessive concordof class 6, a demonstrative of class 6, a hortativeor a question particle or a verbal morpheme in-dicating present tense or past tense (Appendix Aillustrates the ambiguity of -a- with example sen-tences).
Furthermore, the most polysemous func-tion words are also the most frequent word types incorpora.
The highly ambiguous item go1 alone ac-111 different functions of go may be distinguished: object39counts for over 5 % of all occurrences in our train-ing corpus, where 88 types of function words, withan average frequency of well over 200, make upfor about 40 % of all occurrences.The different readings of the function words arenot evenly distributed: some are highly frequent,others are rare.
Furthermore, many ambiguousfunction words appear in the context of other func-tion words; thus the local context does not nec-essarily disambiguate individual function words.This issue is particularly significant with ambigu-ities between concords which can have the samefunction (e.g.
object) in different noun classes.
Asmentioned, -a- can be a subject concord of eithernoun class 1 or 6: though there are some clearcutcases, like the appearance of a noun of class 6 (in-dicating class 6), or an auxiliary or the conjunctionge in the left context (both rather indicating class1) there still remain a number of occurrences of -a-in the corpora only where a broader context, some-times even information from preceding sentences,may help to disambiguate this item.Consequently, comparing tagging performanceacross different tagsets does not give very clear re-sults: if a tagset, like the one used by de Schryverand de Pauw (2007), does not distinguish nounclasses, obviously a large number of difficult dis-ambiguation cases does not appear at all (theirtagset distinguishes, for example, subject and ob-ject concord, but gives no information on nounclass numbers).
For the lexicographic applica-tion we are interested in, and more generally as apreparatory step to chunking or parsing of North-ern Sotho texts, an annotation providing informa-tion on noun classes is however highly desirable.3 Methodology3.1 TagsetThere are several proposals for tagsets to be usedfor Northern Sotho and related languages.
VanRooy and Pretorius (2003) propose a detailedtagset for Setswana, which is fully in line withthe guidelines stated by the EAGLES project, cf.Leech and Wilson (1999).
This tagset encodes aconsiderable number of semantic distinctions inits nominal and verbal tags.
In Kotze?
?s work onconcord of class 15, object concord of the locative classes,object concord of the 2nd person singular, subject concordof class 15, indefinite subject concord, subject concord ofthe locative classes, class prefix of class 15, locative particle,copulative indicating either an indefinite subject, or a subjectof class 15 or a locative subject.the Northern Sotho verb complex, (Kotze?, 2008),a number of POS tags are utilized to distinguishthe elements of the verb, however, due to Kotze?
?sobjectives, her classification does not cover otheritems.
De Schryver and de Pauw (2007) use atagset of only 56 different tags, whereas the pro-posal by Van Rooy and Pretorius leads to over 100tags.
Finally, Taljard et al (2008) propose a ratherdetailed tagset: contrary to the other authors men-tioned, they do encode noun classes in all relevanttags, which leads to a total of 141 tags.
Further-more, they encode a number of additional mor-phosyntactic distinctions on a second level of theirtagset, which leads to a total of 262 different clas-sifications of Northern Sotho morphemes.Our current tagset is inspired by Taljard et al(2008).
However, we disregard some of their sec-ond level information for the moment (which inmany cases encodes lexical properties of the items,e.g.
the subdivision of particles: hortative, ques-tion, instrumental, locative, connective, etc.).
Weuse the RF-tagger (Schmid and Laws, 2008) (cf.section 3.3), which is geared towards the annota-tion of structured tagsets, by separating informa-tion which partitions the inventory of forms (e.g.broad word classes) from feature-like informationpossibly shared by several classes, such as theSotho noun classes.
With this method, we are ableto account for Taljard et al?s (2008) 141 tags bymeans of only 25 toplevel tags, plus a number offeature-like labels of lower levels.
We summarizethe properties of the tagsets considered in table 1.3.2 Training corpusOur training corpus consists of ca.
45.000 manu-ally annotated word forms, from two text types.Over 20.000 word forms come from a novel ofthe South African author Oliver K. Matsepe (Mat-sepe, 1974); over 10.000 forms come from a Ph.D.dissertation by Raphehli M. Thobakgale (Thobak-gale, 2005), and another 10.000 from a secondPh.D.
dissertation, by Ramalau R. Maila (Maila,2006).
Obviously, this is not a balanced corpus; itwas indeed chosen because of its easy accessibil-ity.
We use this corpus to train our taggers and totest them; in a ten-fold cross validation, we splitthe text into ten slices of roughly equal size, trainon 9 of them and test on the tenth.
In this article,we give figures for the median of these results.40Authors No.
of tags ?
noun class tool?
(van Rooy and Pretorius, 2003) 106 - noun class no(De Schryver and De Pauw, 2007) 56 - noun class yes(Kotze?, 2008) partial N.R.
yes(Taljard et al, 2008) 141/262 + noun class noThis paper 25/141 + noun class yesTable 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools3.3 Tagging techniques: the RF-taggerWe opt for the RF-tagger (Schmid and Laws,2008), because it is a Hidden-Markov-Model(HMM) tagger which was developed especiallyfor POS tagsets with a large number of (fine-grained) tags.
Tests with our training corpus haveshown that this tagger outperforms the Tree-tagger((Schmid, 1994) and (Schmid, 1995)), as shown infigure 1.
An additional external lexicon may serveas input, too.
The development of the RF-taggerwas based on the widely shared opinion that forlanguages like German or Czech, agreement in-formation (e.g.
case, number or person) shouldpreferably appear as part of all appropriate partof speech tags.
However, as tagsets increase im-mensely in size when such information is part ofthe tags, the data are decomposed, i.e.
split intoseveral levels of processing.
The probability ofeach level is then calculated separately (the jointprobability of all levels is afterwards calculated astheir product).
With such methodology, a tag ofthe German determiner das may contain five levelsof information, e.g.
ART.Def.Nom.Sg.Neut to de-fine a definite, nominative singular, neutral deter-miner (article) that appears in the nominative case.This approach makes sense for the Bantu-languages as well, since information on noun classnumbers should be part of the noun tags, too, as inTaljard et als (2008) tagset.
A noun here is notonly tagged ?N?, but Nclass, e.g.
mohumagadi?
(married) woman?
as N01.
All concords, pro-nouns or other types that concordially agree withnouns are also labelled with a class number, e.g.o, the subject concord of class 1, is labelled CS01.This approach makes sense, especially in the viewof chunking/parsing and reference resolution, be-cause any of those elements can acquire a pronom-inal function when the noun that they refer to isdeleted (Louwrens, 1991).To utilize the RF-tagger, we split all tags con-taining noun class numbers into several levels (e.g.the tag N01 becomes N.01).
Emphatic and posses-sive pronouns are represented on three levels (e.g.PROPOSSPERS becomes PRO.POSS.PERS)2.4 ResultsIn a preliminary experiment, we compared severaltaggers3 on our manually annotated data.
Apartfrom the RF-tagger (Schmid and Laws, 2008),we also used the Tree-Tagger (Schmid, 1994), theTnT tagger (Brants, 2000) and MBT (Daelemanset al, 2007).4.1 Comparing taggersThe results give a relatively homogenous picture,with the RF-tagger achieving a median of 94.16 %when utilising a lexicon containing several thou-sand nouns and verbs.
It leads to 91 % accuracywithout this lexicon (to simulate similar condi-tions as for TnT or MBT where no external lex-icon was offered).
TnT achieves 91.01 %, andMBT 87.68 %.
Data from the Tree-Tagger werenot comparable for they had been obtained at anearlier stage using the lexicon (92.46 %).4.2 Effects of the size of the training corpuson the tagging resultsAll probabilistic taggers are in need of trainingdata the size of which depends on the size of thetagset and on the frequencies of occurrence ofeach context.
De Schryver and de Pauw (2007)demonstrated that when utilizing a tagset that con-tains only about a third of the tags (56) containedin Taljard et al?s (2008) tagset (141), their Max-Tag POS-tagger reaches a 93.5 % accuracy with atraining corpus of only about 10,000 tokens.Figure 1 depicts the effects of the size of thetraining corpus on the accuracy figures of the Tree-tagger and the RF-tagger.
Tests with training cor-pora of the sizes 15,000, 30,000 and 45,000 tokens2Tests have shown that the quantitative pronouns shouldbe treated separately, their tags are thus only split into twolevels.3Check the References section for the availability of thesetaggers.41Figure 1: Effects of the size of the training corpuson tagger results.showed that the results might not improve much ifmore data is added.
The RF-tagger already reachesmore than 94 % correctness when utilizing the cur-rent 45,000 token training corpus.4.3 Effects of the highly polysemous functionwords of Northern SothoThe less frequently a token-label pair appears inthe corpus, the lower is its probability (leading tothe sparse data problem, when probability guessesbecome unreliable because of low numbers of oc-currences).
This issue poses a problem for North-ern Sotho function words: if they occur very fre-quently with a certain label, the chances of thembeing detected with another label are fairly low.This effect is demonstrated in table 2, which de-scribes the detection of the parts of speech of thehighly ambiguous function word -a-.
The word -a- as PART(icle) occurs only 45 times while -a-as CS.01 occurs 1,182 times.
More than 50 % ofthe particle occurrences (23) are wrongly labelledCS.01 by the tagger.
In table 2, we list the cor-rect tags of all occurrences of -a-, as well as theassigned tags to each of them by our tagger.
Eachblock of table 2 is ordered by decreasing numbersof occurrence of each tag in the output of the RF-tagger.
For easier reference, the correct tags as-signed by the RF-tagger are printed in bold.
Table2 also clearly shows the effect of ambiguous localcontext on the tagging result: the accuracy of theCS.06-annotation (subject concord of class 6) isconsiderably lower than that of the more frequentCS.01 (96.45 % vs. 63.08 %), and CS.01 is themost frequent error in the CS.06 assignment pro-a as freq RF-tagger sums %CS.01 1182 CS.01 1140 96.4CS.06 19 1.6MORPH 14 1.2CDEM.06 3 0.3PART 2 0.2CPOSS.06 2 0.2CO.06 2 0.2CS.06 176 CS.06 111 63.1CS.01 43 24.4CPOSS.06 10 5.7CDEM.06 5 2.8MORPH 3 1.7PART 3 1.7CO.06 1 0.6CO.06 18 MORPH 7 38.9CS.01 6 33.3CO.06 3 16.7CS.06 2 11.11PART 45 CS.01 23 51.1MORPH 11 24.4CDEM.06 5 11.1PART 5 11.1CPOSS.06 1 2.2CDEM.06 97 CDEM.06 89 91.8CPOSS.06 4 4.1CS.06 2 2.1CS.01 1 1.0PART 1 1.0CPOSS.06 209 CPOSS.06 186 89.0CDEM.06 12 5.7CS.06 6 2.9PART 4 1.9CS.01 1 0.5MORPH 89 MORPH 44 49.4CO.06 26 29.2CS.01 15 16.9CPOSS.06 4 4.5sums 1816 1816Table 2: RF-tagger results for -a-cess.4.4 Suggestions for increasing correctnesspercentagesSpoustova?
et al (2007) describe a significant in-crease of accuracy in statistical tagging when uti-lizing rule-based macros as a preprocessing, forCzech.
We have contemplated, in an earlier stageof our work (Prinsloo and Heid, 2005) to adopt a42similar strategy, i.e.
to design rule-based macrosfor the (partial) disambiguation of high-frequencyfunction words.
However, the fact that the localcontext of many function words is similar (i.e.
theambiguity of this local context (see above)), is amajor obstacle to a disambiguation of single func-tion words by means of rules.
Rules would interactin many ways, be dependent on the application or-der, or disambiguate only partially (i.e.
leave sev-eral tag options).
An alternative would be to de-sign rules for the disambiguation of word or mor-pheme sequences.
This would however amount topartial parsing.
The status of such rules within atagging architecture would then be unclear.4.5 Effects of tagset size and structureWhile a preprocessing with rule-based disam-biguation does not seem to be promising, thereare other methods of improving accuracy, such as,e.g., the adaptation of the tagset.
Obviously, typesappearing in different contexts should have differ-ent labels.
For example, in the tagset of Taljard etal.
(2008), auxiliary verbs are a sub-class of verbs(V aux).
In typical Northern Sotho contexts, how-ever, auxiliaries are surrounded by subject con-cords, while verbs are only preceded by them.When ?promoting?
the auxiliaries to the first levelby labelling them VAUX, the RF-tagger result in-creases by 0.13 % to 94.16 % accuracy.
We stillsee room for further improvement here.
For exam-ple, ga as PART (either locative particle PART locor hortative particle PART hort) is identified cor-rectly in only 29.2 % of all cases at the moment.The hortative particle usually appears at the be-ginning of a verbal segment, while the locative inmost cases follows the segment.
Results may in-crease to an even higher accuracy when ?promot-ing?
these second level annotations, hort(ative) andloc(ative) to the first annotation level.5 Conclusions and future workThis article gives an overview of work on POS-tagging for Northern Sotho.
Depending on theplace of tagging in an overall NLP chain for thislanguage, different choices with respect to thetagset and to the tagging technology may proveadequate.In our work, which is part of a detailed lin-guistic annotation of Northern Sotho corpora forlinguistic exploration with a view to lexicons andgrammars, it is vital to provide a solid basis forchunking and/or parsing, by including informa-tion on noun class numbers in the annotation.We found that the RF-tagger (Schmid and Laws,2008) performs well on this task, partly becauseit allows us to structure the tagset into layers, andto deal with noun class information in the sameway as with agreement features for European lan-guages.
We reach over 94 % correctness, whichindicates that at least a first attempt at covering thePSC corpus may now be in order.Our error analysis, however, also highlights afew more general aspects of the POS annotationof Northern Sotho and related languages: obvi-ously, frequent items and items in distinctive lo-cal contexts are tagged quite well.
When nounclass information is part of the distinctions under-lying the tagset, function words usable for morethan one noun class tend however, to appear innon-distinctive local contexts and thus to lead toa considerable error rate.
Furthermore, we found afew cases of uses of, e.g., subject concords that areanaphoric, with antecedents far away and thus notaccessible to tagging procedures based on the lo-cal context.
These facts raise the question whether,to achieve the highest quality of lexical classifica-tion of the words and morphemes of a text, chunk-ing/parsing might be required altogether, ratherthan tagging.Our experiments also showed that several pa-rameters are involved in fine-tuning a Sotho tag-ger.
The size and structure of the tagset is onesuch a prominent parameter.
Tendencies towardssimpler and smaller tagsets obviously conflict withthe needs of advanced processing of the texts andof linguistically demanding applications.
It seemsthat tagset design and tool development go hand inhand.We intend to apply the current version of theRF-tagger to the PSC corpus and to evaluate theresults carefully.
We expect a substantial gainfrom the use of the guessers for nouns and verbs,cf.
(Prinsloo et.
al, 2008) and (Heid et al, 2008).Detailed error analysis should allow us to alsodesign specific rules to correct the output of thetagger.
Instead of preprocessing (as proposed bySpoustova?
et al (2007)), a partial postprocess-ing may contribute to further improving the overallquality.
Rules would then probably have to be ap-plied to particular sequences of words and/or mor-phemes which cause difficulties in the statisticalprocess.43ReferencesAdam L. Berger, Stephen Della Peitra, and VincentJ.
Della Pietra.
1996.
A Maximum Entropy Ap-proach to Natural Language Processing.
Computa-tional Linguistics 22(1): pp.
39 ?
71.Thorsten Brants.
2000.
TnT - A Statistical Part-of-Speech Tagger.
In Proceedings of the Sixth AppliedNatural Language Processing Conference ANLP-2000, Seattle, WA.Walter Daelemans, Jakub Zavrel, Antal van den Bosch.2007.
MBT: Memory-Base Tagger, version 3.1.
Ref-erence Guide.
ILK Technical Report Series 07?08[online].
Available : http://ilk.uvt.nl/mbt (10th Jan, 2009).Gilles-Maurice de Schryver and Guy de Pauw.
2007.Dictionary Writing System (DWS) + Corpus QueryPackage (CQP): The Case of TshwaneLex.
Lexikos17 AFRILEX-reeks/series 17:2007: pp.
226 ?246.
[Online tagger:] http://aflat.org/?q=node/177.
(10th Feb, 2009)Gilles-Maurice de Schryver and Daan J. Prinsloo.2000.
The compilation of electronic corpora withspecial reference to the African languages.
South-ern African Linguistics and Applied Language Stud-ies 18(1-4): pp.
89 ?
106.Malcolm Guthrie.
1971.
Comparative Bantu: an in-troduction to the comparative linguistics and prehis-tory of the Bantu languages, vol 2, Farnborough:Gregg International.Ulrich Heid, Daan J. Prinsloo, Gertrud Faa?, andElsabe?
Taljard.
2008 Designing a noun guesser forpart of speech tagging in Northern Sotho (33 pp).ms: University of Pretoria.Petronella M. Kotze?.
2008.
Northern Sotho grammat-ical descriptions: the design of a tokeniser for theverbal segment.
Southern African Linguistics andApplied Language Studies 26(2): pp.
197 ?
208.Zhang Le.
2004.
Maximum Entropy Modeling Toolkitfor Python and C++ (Technical Report) [online].Available: http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html(10th Jan, 2009).Geoffrey Leech, Andrew Wilson.
1999.
Standards forTagsets.
in van Halteren (Ed.)
Syntactic world-classtagging: pp.
55 ?
80 Dordrecht/Boston/London:Kluwer Academic Publishers.Louis J. Louwrens.
1991.
Aspects of the NorthernSotho Grammar p. 154.
Pretoria:Via Afrika.Ramalau A. Maila.
2006.
Kgolo ya tiragatso ya Se-pedi.
[=?Development of the Sepedi Drama?].
Doc-toral thesis.
University of Pretoria, South Africa.Oliver K. Matsepe.
1974.
Ts?a Ka Mafuri.
[=?From thehomestead?].
Pretoria: Van Schaik.Daan J. Prinsloo.
1994.
Lemmatization of verbs inNorthern Sotho.
SA Journal of African Languages14(2): pp.
93 ?
102.Daan J. Prinsloo and Ulrich Heid.
2005.
Creatingword class tagged corpora for Northern Sotho by lin-guistically informed bootstrapping.
in: Isabella Ties(Ed.
): LULCL, Lesser used languages and compu-tational linguistics, 27/28-10-2005, Bozen/Bolzano,(Bozen: Eurac) 2006: pp.
97 ?
113.Daan J. Prinsloo, Gertrud Faa?, Elsabe?
Taljard, andUlrich Heid.
2008.
Designing a verb guesser forpart of speech tagging in Northern Sotho.
SouthernAfrican Linguistics and Applied Languages Studies(SALALS) 26(2).Helmut Schmid and Florian Laws.
2008.
Es-timation of Conditional Probabilities withDecision Trees and an Application to Fine-Grained POS Tagging [online].
COLING2008.
Manchester, Great Britain.
Available:http://www.ims.uni-stuttgart.de/projekte/corplex/RFTagger/ (10th Jan,2009).Helmut Schmid.
September 1994.
ProbabilisticPart-of-Speech Tagging Using Decision Trees.
Pro-ceedings of the International Conference on NewMethods in Language Processing[online].
Avail-able: http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/(10th Jan, 2009).Helmut Schmid.
March 1995.
Improvements in Part-of-Speech Tagging with an Application to German.Proceedings of the ACL SIGDAT-Workshop.Drahom?
?ra ?johanka?
Spoustova?, Jan Hajic?, JanVotrubec, Pavel Krbec, and Pavel Kve?ton?.
Jun29, 2007.
The best of two worlds: Coop-eration of Statistical and Rule-based Taggersfor Czech.
Balto-Slavonic Natural LanguageProcessing: pp.
67 ?
74 [online].
Available:http://langtech.jrc.it/BSNLP2007/m/BSNLP-2007-proceedings.pdf (10thJan, 2009).Elsabe?
Taljard, Gertrud Faa?, Ulrich Heid and Daan J.Prinsloo.
2008.
On the development of a tagset forNorthern Sotho with special reference to standardi-sation.
Literator 29(1) 2008.
Potchefstroom, SouthAfrica.Raphehli M. Thobakgale.
Khuets?o ya OK Matsepe gobangwadi ba Sepedi [=?Influence of OK Matsepeon the writers of Sepedi?].
Doctoral thesis.
Univer-sity of Pretoria, South Africa.Bertus van Rooy and Rigardt Pretorius.
2003.
A word-class tagset for Setswana.
Southern African Linguis-tics and Applied Language Studies 21(4): pp.
203 ?222.44Appendix A.
The polysemy of -a-Description Example1 Subject ge monna a fihlaconcord of conjunctive + noun cl.
1 + subject concord cl.
1 + verb stemif/when + man + subj-cl1 + arrive?when the man arrives?2 Subject masogana a thus?a basadiconcord of noun cl.
6 + subject concord cl.
6 + verb stem + noun cl.2nominal cl.
6 young men + subj-cl6 + help women?the young men help the women?3 Possessive maoto a gagweconcord of noun cl.
6 + possessive concord cl.
6 + possessive pronoun cl.
1nominal cl.
6 feet + of + his?his feet?4 Present tense morutis?i o a bits?amorpheme noun cl.
1 + subject concord cl.1 + present tense marker + verb stemteacher + subj-cl1 + pres + call?the teacher is calling?5 Past tense morutis?i ga o a bits?a masoganamorpheme noun cl.
1 + negation morpheme + subject concord cl.1 +past tense marker + verb stem + noun cl.
6teacher + neg + subj-cl1 + past + call + young men?the teacher did not call the young men?6 Demonstrative ba nyaka masogana aconcord of subject concord cl.
2 + verb stem + noun cl.
6 + demonstrative concordnominal cl.
6 they + look for + young men + these?they are looking for these young men?7 Hortative a ba tseneparticle hortative particle + subject concord cl.
2 + verb stemlet + subj-cl2 + come in?let them come in?8 Interrogative a o tseba Sepediparticle interrogative particle + subject concord 2nd pers sg.
+ verb stem + noun cl.
7ques + subj-2nd-pers-sg + know + Sepedi?do you know Sepedi?9 Object moruti o a bidits?econcord of noun cl.
1 + subject concord cl.
1 + object concord cl.
6 + verb stemteacher + subj-cl1 + obj-cl6 + called?the teacher called them?45
