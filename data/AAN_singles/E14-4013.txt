Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 64?68,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsPredicting Romanian Stress AssignmentAlina Maria Ciobanu1,2, Anca Dinu1,3, Liviu P. Dinu1,21Center for Computational Linguistics, University of Bucharest2Faculty of Mathematics and Computer Science, University of Bucharest3Faculty of Foreign Languages and Literatures, University of Bucharestalina.ciobanu@my.fmi.unibuc.ro, anca_d_dinu@yahoo.com, ldinu@fmi.unibuc.roAbstractWe train and evaluate two models for Ro-manian stress prediction: a baseline modelwhich employs the consonant-vowel struc-ture of the words and a cascaded modelwith averaged perceptron training con-sisting of two sequential models ?
one forpredicting syllable boundaries and anotherone for predicting stress placement.
Weshow in this paper that Romanian stress ispredictable, though not deterministic, byusing data-driven machine learning tech-niques.1 IntroductionRomanian is a highly inflected language with arich morphology.
As dictionaries usually fail tocover the pronunciation aspects for all word formsin languages with such a rich and irregular mor-phology (Sef et al., 2002), we believe that adata-driven approach is very suitable for syllabi-cation and stress prediction for Romanian words.Moreover, such a system proves extremely usefulfor inferring syllabication and stress placement forout-of-vocabulary words, for instance neologismsor words which recently entered the language.Even if they are closely related, Romanianstress and syllabication were unevenly studied inthe computational linguistic literature, i.e., theRomanian syllable received much more attentionthan the Romanian stress (Dinu and Dinu, 2005;Dinu, 2003; Dinu et al., 2013; Toma et al., 2009).One possible explanation for the fact that Roma-nian syllabication was more intensively studiedthan Romanian stress is the immediate applicationof syllabication to text editors which need reliablehyphenation.
Another explanation could be thatmost linguists (most recently Dindelegan (2013))insisted that Romanian stress is not predictable,thus discouraging attempts to investigate any sys-tematic patterns.Romanian is indeed a challenging case study,because of the obvious complexities of the datawith respect to stress assignment.
At first sight, noobvious patterns emerge for learning stress place-ment (Dindelegan, 2013), other than as part of in-dividual lexical items.
The first author who chal-lenges this view is Chitoran (2002), who argues infavor of the predictability of the Romanian stresssystem.
She states that stress placement stronglydepends on the morphology of the language, moreprecisely on the distribution of the lexical itemsbased on their part of speech (Chitoran, 1996).Thus, considering this type of information, lexicalitems can be clustered in a limited number of re-gular subpatterns and the unpredictability of stressplacement is significantly reduced.
A rule-basedmethod for lexical stress prediction on Romanianwas introduced by Oancea and Badulescu (2002).Dou et al.
(2009) address lexical stress predic-tion as a sequence tagging problem, which provesto be an accurate approach for this task.
Theeffectiveness of using conditional random fieldsfor orthographic syllabication is investigated byTrogkanis and Elkan (2010), who employ themfor determining syllable boundaries and show thatthey outperform previous methods.
Bartlett etal.
(2008) use a discriminative tagger for auto-matic orthographic syllabication and present seve-ral approaches for assigning labels, including thelanguage-independent Numbered NB tag scheme,which labels each letter with a value equal to thedistance between the letter and the last syllableboundary.
According to Damper et al.
(1999), syl-lable structure and stress pattern are very useful intext-to-speech synthesis, as they provide valuableknowledge regarding the pronunciation modeling.Besides converting the letters to the correspondingphonemes, information about syllable boundariesand stress placement is also needed for the correctsynthesizing of a word in grapheme-to-phonemeconversion (Demberg et al., 2007).64In this paper, we rely on the assumption that thestress system of Romanian is predictable.
We pro-pose a system for automatic prediction of stressplacement and we investigate its performance byaccounting for several fine-grained characteristicsof Romanian words: part of speech, number ofsyllables and consecutive vowels.
We investigatethe consonant-vowel structure of the words (C/Vstructure) and we detect a high number of stresspatterns.
This calls for the need of machine learn-ing techniques, in order to automatically learnsuch a wide range of variational patterns.2 ApproachWe address the task of stress prediction for Roma-nian words (out-of-context) as a sequence taggingproblem.
In this paper, we account only for the pri-mary stress, but this approach allows further deve-lopment in order to account for secondary stressas well.
We propose a cascaded model consist-ing of two sequential models trained separately,the output of the first being used as input for thesecond.
We use averaged perceptron for parame-ter estimation and three types of features which aredescribed in detail further in this section: n-gramsof characters, n-grams marking the C/V structureof the word and binary positional indicators of thecurrent character with respect to the syllable struc-ture of the word.
We use one sequential modelto predict syllable boundaries and another one topredict stress placement.
Previous work on or-thographic syllabication for Romanian (Dinu etal., 2013) shows that, although a rule-based algo-rithm models complex interactions between fea-tures, its practicality is limited.
The authors re-port experiments on a Romanian dataset, wherethe rule-based algorithm is outperformed by anSVM classifier and a CRF system with charactern-gram features.We use a simple tagging structure for mar-king primary stress.
The stressed vowel re-ceives the positive tag 1, while all previous cha-racters are tagged 0 and all subsequent ones2.
This structure helps enforce the uniquenessof the positive tag.
The main features usedare character n-grams up to n = W in a win-dow of radius W around the current position.For example, if W = 2, the feature templateconsists of c[-2], c[-1], c[0], c[1], c[2],c[-2:-1], c[-1:0], c[0:1], c[1:2].
If thecurrent letter is the fourth of the word dinosaur,o, the feature values would be i, n, o, s, a, in, no,os, sa.
We use two additional types of features:?
features regarding the C/V structure of theword: n-grams using, instead of characters,markers for consonants (C) and vowels (V);?
binary indicators of the following positionalstatements about the current character, re-lated to the statistics reported in Table 1:?
exactly before/after a split;?
in the first/second/third/fourth syllableof the word, counting from left to right;?
in the first/second/third/fourth syllableof the word, counting from right to leftThe syllabication prediction is performed withanother sequential model of length n?
1, whereeach node corresponds to a position between twocharacters.
Based on experimenting and previ-ous work, we adopted the Numbered NB labeling.Each position is labeled with an integer denotingthe distance from the previous boundary.
For ex-ample, for the word diamond, the syllable (above)and stress annotations (below) are as follows:d i a m o n d1 0 0 1 2 30 1 2 2 2 2 2The features used for syllabication are based onthe same principle, but because the positions arein-between characters, the window of radius Whas length 2W instead of 2W + 1.
For this modelwe used only character n-grams as features.3 DataWe run our experiments for Romanian using theRoSyllabiDict (Barbu, 2008) dictionary, which isa dataset of annotated words comprising 525,528inflected forms for approximately 65,000 lemmas.This is, to our best knowledge, the largest experi-ment conducted and reported for Romanian so far.For each entry, the syllabication and the stressedvowel (and, in case of ambiguities, also grammat-ical information or type of syllabication) are pro-vided.
For example, the word copii (children) hasthe following representation:<form w="copii" obs="s."> co-p?i</form>We investigate stress placement with regard tothe syllable structure and we provide in Table 1the percentages of words having the stress placedon different positions, counting syllables from thebeginning and from the end of the words as well.For our experiments, we discard words whichdo not have the stressed vowel marked, compound65Syllable %words1st5.592nd18.913rd39.234th23.685th8.52(a) counting syllables fromthe beginning of the wordSyllable %words1st28.162nd43.933rd24.144th3.085th0.24(b) counting syllables fromthe end of the wordTable 1: Stress placement for RoSyllabiDictwords having more than one stressed vowel andambiguous words (either regarding their part ofspeech or type of syllabication).We investigate the C/V structure of the words inRoSyllabiDict using raw data, i.e., a, a?, ?, e, i, ?, o,u are always considered vowels and the rest of theletters in the Romanian alphabet are consideredconsonants.
Thus, we identify a very large numberof C/V structures, most of which are not determin-istic with regard to stress assignment, having morethen one choice for placing the stress1.4 Experiments and ResultsIn this section we present the main results drawnfrom our research on Romanian stress assignment.4.1 ExperimentsWe train and evaluate a cascaded model consist-ing of two sequential models trained separately,the output of the first being used as input to thesecond.
We split the dataset in two subsets: trainset (on which we perform cross-validation to se-lect optimal parameters for our model) and testset (with unseen words, on which we evaluate theperformance of our system).
We use the sametrain/test sets for the two sequential models, butthey are trained independently.
The output of thefirst model (used for predicting syllabication) isused for determining feature values for the secondone (used for predicting stress placement) for thetest set.
The second model is trained using goldsyllabication (provided in the dataset) and we re-port results on the test set in both versions: us-ing gold syllabication to determine feature values1For example, for CCV-CVC structure (1,390 occurrencesin our dataset) there are 2 associated stress patterns: CCV-CVC (1,017 occurrences) and CCV-CVC (373 occurrences).Words with 6 syllables cover the highest number of distinctC/V structures (5,749).
There are 31 C/V structures (rang-ing from 4 to 7 syllables) reaching the maximum number ofdistinct associated stress patterns (6).and using predicted syllabication to determine fea-ture values.
The results with gold syllabicationare reported only for providing an upper bound forlearning and for comparison.We use averaged perceptron training (Collins,2002) from CRFsuite (Okazaki, 2007).
For thestress prediction model we optimize hyperparam-eters using grid search to maximize the 3-foldcross-validation F1score of class 1, which marksthe stressed vowels.
We searched over {2,3,4}for W and over {1,5,10,25,50} for the maximumnumber of iterations.
The values which optimizethe system are 4 for W and 50 for the maximumnumber of iterations.
We investigate, during gridsearch, whether employing C/V markers and bi-nary positional indicators improve our system?sperformance.
It turns out that in most cases theydo.
For the syllabication model, the optimal hy-perparameters are 4 for the window radius and 50for the maximum number of iterations.
We evalu-ate the cross-validation F1score of class 0, whichmarks the position of a hyphen.
The system ob-tains 0.995 instance accuracy for predicting sylla-ble boundaries.We use a "majority class" type of baselinewhich employs the C/V structures described inSection 3 and assigns, for a word in the test set,the stress pattern which is most common in thetraining set for the C/V structure of the word, orplaces the stress randomly on a vowel if the C/Vstructure is not found in the training set2.
The per-formance of both models on RoSyllabiDict datasetis reported in Table 2.
We report word-level ac-curacy, that is, we account for words for whichthe stress pattern was correctly assigned.
As ex-pected, the cascaded model performs significantlybetter than the baseline.Model AccuracyBaseline 0.637Cascaded model (gold) 0.975Cascaded model (predicted) 0.973Table 2: Accuracy for stress predictionFurther, we perform an in-depth analysis of thesequential model?s performance by accounting for2For example, the word copii (meaning children) has thefollowing C/V structure: CV-CVV.
In our training set, thereare 659 words with this structure and the three stress patternswhich occur in the training set are as follows: CV-CVV (309occurrences), CV-CVV (283 occurrences) and CV-CVV (67occurrences).
Therefore, the most common stress pattern CV-CVV is correctly assigned, in this case, for the word copii.66several fine-grained characteristics of the wordsin RoSyllabiDict.
We divide words in categoriesbased on the following criteria:?
part of speech: verbs, nouns, adjectives?
number of syllables: 2-8, 9+?
number of consecutive vowels: with at least2 consecutive vowels, without consecutivevowelsCategory Subcategory ] wordsAccuracyG PPOSVerbs 167,193 0.995 0.991Nouns 266,987 0.979 0.979Adjectives 97,169 0.992 0.992Syllables2 syllables 34,810 0.921 0.9203 syllables 111,330 0.944 0.9414 syllables 154,341 0.966 0.9645 syllables 120,288 0.981 0.9696 syllables 54,918 0.985 0.9857 syllables 17,852 0.981 0.9898 syllables 5,278 0.992 0.9849+ syllables 1,468 0.979 0.980VowelsWith VV 134,895 0.972 0.972Without VV 365,412 0.976 0.974Table 3: Accuracy for cascaded model withgold (G) and predicted (P) syllabicationWe train and test the cascaded model indepen-dently for each subcategory in the same manner aswe did for the entire dataset.
We decided to usecross-validation for parameter selection instead ofsplitting the data in train/dev/test subsets in or-der to have consistency across all models, becausesome of these word categories do not compriseenough words for splitting in three subsets (wordswith more than 8 syllables, for example, have only1,468 instances).
The evaluation of the system?sperformance and the number of words in each cat-egory are presented in Table 3.4.2 Results AnalysisThe overall accuracy is 0.975 for the cascadedmodel with gold syllabication and 0.973 for thecascaded model with predicted syllabication.
Theformer system outperforms the latter by only verylittle.
With regard to the part of speech, the high-est accuracy when gold syllabication is used wasobtained for verbs (0.995), followed by adjectives(0.992) and by nouns (0.979).
When dividing thedataset with respect to the words?
part of speech,the cascaded model with predicted syllabicationis outperformed only for verbs.
With only a fewexceptions, the accuracy steadily increases withthe number of syllables.
The peak is reached forwords with 6 syllables when using the gold syllab-ication and for words with 7 syllables when usingthe predicted syllabication.
Although, intuitively,the accuracy should be inversely proportional tothe number of syllables, because the number ofpotential positions for stress placement increases,there are numerous stress patterns for words with6, 7 or more syllables, which never occur in thedataset3.
It is interesting to notice that stress pre-diction accuracy is almost equal for words con-taining two or more consecutive vowels and forwords without consecutive vowels.
As expected,when words are divided in categories based ontheir characteristics the system is able to predictstress placement with higher accuracy.5 Conclusion and Future WorkIn this paper we showed that Romanian stressis predictable, though not deterministic, by usingdata-driven machine learning techniques.
Syllablestructure is important and helps the task of stressprediction.
The cascaded sequential model usinggold syllabication outperforms systems with pre-dicted syllabication by only very little.In our future work we intend to experiment withother features as well, such as syllable n-gramsinstead of character n-grams, for the sequentialmodel.
We plan to conduct a thorough error analy-sis and to investigate the words for which the sys-tems did not correctly predict the position of thestressed vowels.
We intend to further investigatethe C/V structures identified in this paper and toanalyze the possibility to reduce the number ofpatterns by considering details of word structure(for example, instead of using raw data, to aug-ment the model with annotations about which let-ters are actually vowels) and to adapt the learningmodel to finer-grained linguistic analysis.AcknowledgementsThe authors thank the anonymous reviewers fortheir helpful comments.
The contribution of theauthors to this paper is equal.
Research supportedby a grant of ANRCS, CNCS UEFISCDI, projectnumber PN-II-ID-PCE-2011-3-0959.3For example, for the stress pattern CV-CV-CV-CV-CV-CVCV, which matches 777 words in our dataset, the stress isnever placed on the first three syllables.67ReferencesAna-Maria Barbu.
2008.
Romanian Lexical DataBases: Inflected and Syllabic Forms Dictionaries.
InProceedings of the 6th International Conference onLanguage Resources and Evaluation, LREC 2008,pages 1937?1941.Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.2008.
Automatic Syllabification with StructuredSVMs for Letter-to-Phoneme Conversion.
In Pro-ceedings of the 46th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies, ACL-HLT 2008, pages 568?576.Ioana Chitoran.
1996.
Prominence vs. rhythm: Thepredictability of stress in Romanian.
In Grammat-ical theory and Romance languages, pages 47?58.Karen Zagona.Ioana Chitoran.
2002.
The phonology of Romanian.
Aconstraint-based approach.
Mouton de Gruyter.Michael Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and Exper-iments with Perceptron Algorithms.
In Proceedingsof the ACL-02 Conference on Empirical Methods inNatural Language Processing - Volume 10, EMNLP2002, pages 1?8.Robert I. Damper, Yannick Marchand, M. J. Adam-son, and K. Gustafson.
1999.
Evaluating thepronunciation component of text-to-speech systemsfor English: a performance comparison of differ-ent approaches.
Computer Speech & Language,13(2):155?176.Vera Demberg, Helmut Schmid, and Gregor M?hler.2007.
Phonological Constraints and Morphologi-cal Preprocessing for Grapheme-to-Phoneme Con-version.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics, ACL 2007, pages 96?103.Gabriela Pan?a Dindelegan.
2013.
The Grammar ofRomanian.
Oxford University Press.Liviu P. Dinu and Anca Dinu.
2005.
A Parallel Ap-proach to Syllabification.
In Proceedings of the6th International Conference on Computational Lin-guistics and Intelligent Text Processing, CICLing2005, pages 83?87.Liviu P. Dinu, Vlad Niculae, and Octavia-Maria S,ulea.2013.
Romanian Syllabication Using MachineLearning.
In Proceedings of the 16th InternationalConference on Text, Speech and Dialogue, TSD2013, pages 450?456.Liviu Petrisor Dinu.
2003.
An Approach to Syllablesvia some Extensions of Marcus Contextual Gram-mars.
Grammars, 6(1):1?12.Qing Dou, Shane Bergsma, Sittichai Jiampojamarn,and Grzegorz Kondrak.
2009.
A Ranking Approachto Stress Prediction for Letter-to-Phoneme Conver-sion.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th IJCNLPof the AFNLP, ACL 2009, pages 118?126.Eugeniu Oancea and Adriana Badulescu.
2002.Stressed Syllable Determination for RomanianWords within Speech Synthesis Applications.
Inter-national Journal of Speech Technology, 5(3):237?246.Naoaki Okazaki.
2007.
CRFsuite: a fast implementa-tion of Conditional Random Fields (CRFs).Tomaz Sef, Maja Skrjanc, and Matjaz Gams.
2002.Automatic Lexical Stress Assignment of UnknownWords for Highly Inflected Slovenian Language.
InProceedings of the 5th International Conference onText, Speech and Dialogue, TSD 2002, pages 165?172.S.-A.
Toma, E. Oancea, and D. Munteanu.
2009.Automatic rule-based syllabication for Romanian.In Proceedings of the 5th Conference on SpeechTechnology and Human-Computer Dialogue, SPeD2009, pages 1?6.Nikolaos Trogkanis and Charles Elkan.
2010.
Con-ditional Random Fields for Word Hyphenation.
InProceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, ACL 2010,pages 366?374.68
