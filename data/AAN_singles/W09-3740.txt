Proceedings of the 8th International Conference on Computational Semantics, pages 342?345,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsA novel approach to mappingFrameNet lexical units to WordNet synsetsSara Tonelli, Emanuele PiantaAbstractIn this paper we present a novel approach to mapping FrameNetlexical units to WordNet synsets in order to automatically enrich thelexical unit set of a given frame.
While the mapping approaches pro-posed in the past mainly rely on the semantic similarity between lexicalunits in a frame and lemmas in a synset, we exploit the definition ofthe lexical entries in FrameNet and the WordNet glosses to find thebest candidate synset(s) for the mapping.
Evaluation results are alsoreported and discussed.1 FrameNet and the existing mapping approachesThe FrameNet database [1] is a lexical resource of English describing someprototypical situations, the frames, and the frame-evoking words or expres-sions associated with them, the lexical units (LU).
Every frame correspondsto a scenario involving a set of participants, the frame elements, that are typ-ically the syntactic dependents of the lexical units.
The FrameNet resourceis corpus-based, i.e.
every lexical unit should be instantiated by at leastone example sentence, even if at the moment the definition and annotationstep is still incomplete for several LUs.
FrameNet has proved to be usefulin a number of NLP tasks, from textual entailment to question answering,but its coverage is still a major problem.
In order to expand the resource,it would be a good solution to acquire lexical knowledge encoded in otherexisting resources and import it into the FrameNet database.
WordNet [4],for instance, covers the majority of nouns, verbs, adjectives and adverbs inthe English language, organized in synonym sets called synsets.
MappingFrameNet LUs to WordNet synsets would automatically increase the num-ber of LUs per frame by importing all synonyms from the mapped synset,and would allow to exploit the semantic and lexical relations in WordNet toenrich the information encoded in FrameNet.342Several experiments have been carried out in this direction.
Johansson andNugues [5] created a feature representation for every WordNet lemma andused it to train an SVM classifier for each frame that tells whether a lemmabelongs to the frame or not.
Crespo and Buitelaar [3] carried out an au-tomatic mapping of medical-oriented frames to WordNet synsets, trying toselect synsets attached to a LU that were statistically significant in a givenreference corpus.
De Cao et al [2] proposed a method to detect the setof suitable WordNet senses able to evoke the same frame by exploiting thehypernym hierarchies that capture the largest number of LUs in the frame.For all above mentioned approaches, a real evaluation on randomly selectedframes is missing, and accuracy was mainly computed over the new lexicalunits obtained for a frame, not on a gold standard where one or more synsetsare assigned to every lexical unit in a frame.
Besides, it seems that the mostcommon approach to carry out the mapping relies on some similarity mea-sures that perform better on richer sets of lexical units.2 The mapping algorithm2.1 MotivationWe propose a mapping algorithm that is independent of the number of LUsin a frame and from the example sentences available.
In fact, we believethat under real-usage conditions, the automatic expansion of LUs is typi-cally required for frames with a smaller LU set, especially for those withonly one element.
In the FrameNet database (v. 1.3), 33 frames out of 720are described only by one lexical unit, and 63 are described by two.
Further-more, almost 3000 lexical units are characterized only by the lexicographicdefinition and are not provided with example sentences.
For this reason, wesuggest an alternative approach that makes use of usually unexploited infor-mation collected in the FrameNet database, namely the definition associatedwith every lexical unit.Since both WordNet glosses and FrameNet definitions are manually writ-ten by lexicographers, they usually show a high degree of similarity, andsometimes are even identical.
For example, the definition of thicken in theChange of consistency frame is ?become thick or thicker?, which is identicalto the WordNet gloss of synset n. v#00300319.
The thicken lemma occursin three WordNet synsets, and in each of them it is the only lemma available,so no synonymy information could be exploited for the sense disambiguation.3432.2 The algorithmWe tried to devise a simple method to map a FrameNet Lexical Unit (LU)into one or more WordNet synsets.
Given a LU L from a frame F, we firstfind the set of all synsets containing L (L candidate set, LCandSet).
If LCan-dSet contains only one synset, this is assigned to L. Otherwise, we look forthe synsets in LCandSet whose WN gloss has the highest similarity with theFrameNet definition of L. We tried two baseline similarity algorithms basedrespectively on stem overlap and on a modified version of the Levenshteinalgorithm taking stems as comparison unit instead of characters.
Stem over-lap turned out to perform definitely better than Levehnstein.
Then we triedto improve on simple stem overlap baseline by considering also the otherLUs in F. To this extent, we calculate the set of all synsets linked to anyLU in F (FCandSet).
This is exploited in two ways.
First, we boost thesimilarity score of the synsets in LCandSet with the largest number of linksto other LUs in F (according to FCandSet).
Secondly we assign to F themost common WordNet Domain in FCandSet, and then boost the similarityscore of LCandSet synsets belonging to the most frequent WordNet-Domainin F. We discard any candidate synset with a similarity score below a MINthreshold; on the other side, we accept more than one candidate synset ifthey have a similarity score higher than a MAX threshold.3 EvaluationWe created a gold standard by manually mapping 380 LUs belonging toas many frames to the corresponding WordNet synsets.
Then, we dividedour dataset into a development set of 100 LUs and a testset of 280 LUs.We tested the Levenshtein algorithm and the Stem Overlap algorithm (SO),then we evaluated the improvement in performance of the latter taking intoaccount information about the most frequent domain (D) and the mostfrequent synsets (Syn).
Results are reported in Table 1.Table 1: Mapping evaluationPrecision Recall F-measureLevenshtein 0.50 0.49 0.49Stem Overlap (SO) 0.66 0.56 0.61SO+Domain (D) 0.66 0.57 0.61SO+D+Syn 0.71 0.62 0.66344We carried out several tests to set the MIN and MAX threshold in orderto get the best F-measure, reported in Table 1.
As for precision, the bestperformance obtained with SO+D+Syn and a stricter MIN/MAX thresholdscored 0.78 (recall 0.36, f-measure 0.49).4 ConclusionsWe proposed a new method to map FrameNet LUs to WordNet synsetsby computing a similarity measure between LU definitions and WordNetglosses.
To our knowledge, this is the only approach to the task based onthis kind of similarity.
The only comparable evaluation available is reportedin [5], and shows that our results are promising.
De Cao at al.
[2] reported abetter performance, particularly for recall, but evaluation of their mappingalgorithm relied on a gold standard of 4 selected frames having at least 10LUs and a given number of corpus instantiations.In the future, we plan to improve the algorithm by shallow parsing theLU definitions and the WordNet glosses.
Besides, we will exploit informa-tion extracted from the WordNet hierarchy.
We also want to evaluate theeffectiveness of the approach focusing on the new LUs to be included in theexisting frames.References[1] Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
The BerkeleyFrameNet Project.
In Proceedings of the 36th ACL Meeting and 17thICCL Conference.
Morgan Kaufmann, 1998.
[2] Diego De Cao, Danilo Croce, Marco Pennacchiotti, and Roberto Basili.Combining Word Sense and Usage for modeling Frame Semantics.
InProceedings of STEP 2008, Venice, Italy, 2008.
[3] Mario Crespo and Paul Buitelaar.
Domain-specific English-to-SpanishTranslation of FrameNet.
In Proc.
of LREC 2008, Marrakech, 2008.
[4] Christiane Fellbaum, editor.
WordNet: An Electronic Lexical Database.MIT Press, 1998.
[5] R. Johansson and P. Nugues.
Using WordNet to extend FrameNet cov-erage.
In Proc.
of the Workshop on Building Frame-semantic Resourcesfor Scandinavian and Baltic Languages, at NODALIDA, Tartu, 2007.345
