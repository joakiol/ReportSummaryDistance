From Predicting PredominantSenses to Local Context forWord Sense DisambiguationRob KoelingDiana McCarthyUniversity of Sussex (UK)email: robk@sussex.ac.ukAbstractRecent work on automatically predicting the predominant sense of a wordhas proven to be promising (McCarthy et al, 2004).
It can be applied (as afirst sense heuristic) to Word Sense Disambiguation (WSD) tasks, withoutneeding expensive hand-annotated data sets.
Due to the big skew in thesense distribution of many words (Yarowsky and Florian, 2002), the FirstSense heuristic for WSD is often hard to beat.
However, the local contextof an ambiguous word can give important clues to which of its senses wasintended.
The sense ranking method proposed by McCarthy et al (2004)uses a distributional similarity thesaurus.
The k nearest neighbours in thethesaurus are used to establish the predominant sense of a word.
In thispaper we report on a first investigation on how to use the grammaticalrelations the target word is involved with, in order to select a subset ofthe neighbours from the automatically created thesaurus, to take the localcontext into account.
This unsupervised method is quantitatively evalu-ated on SemCor.
We found a slight improvement in precision over usingthe predicted first sense.
Finally, we discuss strengths and weaknesses ofthe method and suggest ways to improve the results in the future.129130 Koeling and McCarthy1 IntroductionIn recent years, a lot of research was done on establishing the predominant sense ofambiguous words automatically using untagged texts (McCarthy et al, 2004, 2007).The motivation for that work is twofold: on the one hand it builds on the strengthof the first sense heuristic in Word Sense Disambiguation (WSD) (i.e.
the heuristic ofchoosing themost commonly used sense of a word, irrespective of the context in whichthe word occurs) and on the other hand it recognizes that manually created resourcesfor establishing word sense distributions are expensive to create and therefore hardto find.
The one resource that is used most widely, SemCor (Miller et al, 1993), isonly available for English and only representative for ?general?
(non domain specific)text.
McCarthy et als method was successfully applied to a corpus of modern Englishtext (the BNC (Leech, 1992)) and the predicted predominant senses compared wellwith the gold standard given by SemCor.
Other experiments showed that the methodcan successfully be adapted to domain specific text (Koeling et al, 2005) and otherlanguages (for example, Japanese (Iida et al, 2008)).Even though the first sense heuristic is powerful, it would be preferable to onlyuse it for WSD, when either the sense distribution is so skewed that the most com-monly used sense is by far the most dominant, or as a back-off when few other cluesare available to decide otherwise.
The use of local context is ultimately necessary tofind evidence for the intended sense of an ambiguous word.
In this paper we inves-tigate how we can exploit results from intermediate steps taken when calculating thepredominant senses to this end.The work on automatically finding predominant senses1 was partly inspired by theobservation that you can identify word senses by looking at the nearest neighbours of atarget word in a distributional thesaurus.
For example, consider the following (simpli-fied) entry for the word plant in such a thesaurus (omitting the scores for distributionalsimilarity):(9) plant : factory, industry, facility, business, company, species, tree, crop, en-gine, flower, farm, leaf, market, garden, field, seed, shrub...Just by looking at the neighbours you can identify two main groups of neighbours,each pointing at separate senses of the word.
First there is the set of words consist-ing of factory, industry, facility, business, company, engine that hint at the ?industrialplant?
sense of the word and then there is the set consisting of tree, crop, flower, leaf,species, garden, field, seed, shrub that are more closely related to the ?flora?
sense ofthe word.
A few words, like farm and possibly market could be associated equallystrongly with either sense.
The idea behind ?sense ranking?
is, that the right mix of1.
number of neighbours with a strong associations with one or more of the senses,2.
the strength of the association (semantic similarity) between neighbour andsense and1McCarthy et al (2004) concentrates on evaluating the predominant sense, but the method does in factrank all the senses in order of frequency of use.From Predicting Predominant Senses to Local Context for WSD 1313. the strength of the distributional similarity of the contributing neighbour and thetarget word, will allow us to estimate the relative importance (i.e.
frequency ofuse) of each sense.What we want to explore here, is how we can use the local context of an occurrenceof the target word, to select a subset of these neighbours.
This subset should consistof words that are related more strongly to the sense of the word in the target sentence.For example, consider the word plant in a sentence like:(10) The gardener grows plants from vegetable seeds.Plant is used in this sentence as the ?subject of grow?.
A simple way of zoomingin on potentially relevant neighbours is by using the most informative contexts sharedbetween neighbours and the word in the target sentence.
This is implemented byselecting just those words that occur in the same grammatical context (i.e.
as subjectof the verb ?grow?)
in a reference corpus2.
If we apply that to the example in 9, weend up with the following subset: business, industry, species, tree, crop, flower, seed,shrub.
Even though the first two words are still associated with the ?industrial plant?sense, we can see that the majority of the words in this subset is strongly associatedwith the intended sense.In the next section we first give a quick introduction to the sense ranking algorithmintroduced in McCarthy et al (2004).
Then we explain howwe can use the database ofgrammatical relations that we used for creating the thesaurus, for selecting a subset ofneighbours in the thesaurus.
The following section describes an evaluation performedon the SemCor data.
In the last two sections we discuss the results and especiallywhy both recall and precision are lower than we had hoped and what can be done toimprove the results.2 Predominant Senses and Local ContextFor a full review of McCarthy et als ranking method, we refer to McCarthy et al(2004) or McCarthy et al (2007).
Here we give a short description of the method.Since we need the grammatical relations used for building the thesaurus, for selectinga subset of the neighbours, we explain the procedure for building the thesaurus in 2.2.In the last part of this section we explain how we exploit local context for SD.2.1 Finding Predominant SensesWe use the method described inMcCarthy et al (2004) for finding predominant sensesfrom raw text.
It can be applied to all parts of speech, but the experiments in this pa-per all focus on nouns only.
The method uses a thesaurus obtained from the text byparsing, extracting grammatical relations and then listing each word (w) with its top knearest neighbours, where k is a constant.
Like McCarthy et al (2004) we use k = 50and obtain our thesaurus using the distributional similarity metric described by Lin(1998).
We use WordNet (WN) as our sense inventory.
The senses of a word w areeach assigned a ranking score which sums over the distributional similarity scores of2We use the same corpus used for generating the thesaurus as for the reference corpus (in all ourexperiments).132 Koeling and McCarthythe neighbours and weights each neighbour?s score by a WN Similarity score (Pat-wardhan and Pedersen, 2003) between the sense of w and the sense of the neighbourthat maximises the WN Similarity score.
This weight is normalised by the sum ofsuch WN similarity scores between all senses of w and and the senses of the neigh-bour that maximises this score.
We use the WN Similarity jcn score on nouns (Jiangand Conrath, 1997) since this gave reasonable results for McCarthy et al and it isefficient at run time given precompilation of frequency information.
The jcn measureneeds word frequency information, which we obtained from the British National Cor-pus (BNC) (Leech, 1992).
The distributional thesaurus was constructed using subject,direct object adjective modifier and noun modifier relations.Thus we rank each sense wsi ?WSw using Prevalence Score wsi =(11) ?n j?Nwdssn j ?wnss(wsi,n j)?wsi?
?WSw wnss(wsi?
,n j)where the WordNet similarity score (wnss) is defined as:wnss(wsi,n j) = maxnsx?NSn j(wnss(wsi,nsx))2.2 Building the ThesaurusThe thesaurus was acquired using the method described by Lin (1998).
For input weused grammatical relation data extracted using an automatic parser (Briscoe and Car-roll, 2002).
For the experiments in this paper we used the 90 million words of writtenEnglish from the BNC.
For each noun we considered the co-occurring verbs in thedirect object and subject relation, the modifying nouns in noun-noun relations and themodifying adjectives in adjective-noun relations.
This limited set of grammatical rela-tions was chosen since accuracy of the parser is particularly high for these 4 relations.We could easily extend the set of relations to more in the future.
A noun,w, is thus de-scribed by a set of co-occurrence triples < w,r,x > and associated frequencies, wherer is a grammatical relation and x is a possible co-occurrence with w in that relation.For every pair of nouns, where each noun had a total frequency in the triple data of 10or more, we computed their distributional similarity using the measure given by Lin(1998).
If T (w) is the set of co-occurrence types (r,x) such that I(w,r,x) is positivethen the similarity between two nouns, w and n, can be computed as:(12)?
(r,x)?T(w)?T (n) (I(w,r,x)+ I(n,r,x))?
(r,x)?T (w) I(w,r,x)+ ?
(r,x)?T(n) I(n,r,x)where I(w,r,x) = log P(x|w?r)P(x|r)A thesaurus entry of size k for a target nounw can then be defined as the k most similarnouns to noun w.2.3 Local ContextThe basis for building the distributional similarity thesaurus, is the set of grammaticalrelations that the target word shares with other words.
For example, if we look atthe thesaurus entry for the noun bike, then we see that the closest neighbours are (thesynonym) bicycle and the closely related motorbike (and motorcycle).
The next 10closest neighbours are all other vehicles (car, van, boat, bus, etc.).
This is somethingFrom Predicting Predominant Senses to Local Context for WSD 133we would expect to see, since all these words do occur in similar grammatical contexts.We travel by bike, as well as by motorcycle, car and bus.
We park them, drive_offwith them, hire them, abandon them and repair them.
Many of these relations can beapplied to a wide range of vehicles (or even a wider range of objects).
However, somerelations are more specific to two-wheeled vehicles.
For example, it is quite commonto mount a bike or a motorbike, whereas it is less common to mount a car or a van.
(Motor)bikes are chained to stop people from stealing them and it is probably morecommon to ride a (motor)bike as opposed to driving a car or truck.
Of course thereare many other more general things you can do with these vehicles: buy, sell, stealthem; there are yellow bikes, cars and boats, just like other objects.
Therefore, we cansee many other types of objects lower in the list of neighbours that share these moregeneral grammatical relations, but not those that are specific to, say, vehicles or eventhe sub-category of two-wheeled vehicles.Consider the following sentence containing the ambiguous noun body:(13) ?Regular exercise keeps the body healthy.?
(14) ?The funding body approved the final report.
?We would like our algorithm to be able to recognize that Wordnet?s first sense ofthe word body (the entire physical structure of an organism (especially an animal orhuman being)) is the most appropriate for sentence 13 and the third sense (a groupof persons associated by some common tie or occupation and regarded as an entity)for sentence 14.
If we calculate the most likely sense using all of the first 50 nearestneighbours in the thesaurus, we predict that sense 4 is the most frequently used sense(the body excluding the head and neck and limbs).However, the two uses of the target word in 13 and 14 appear each in a very spe-cific grammatical context.
How can we exploit this local context to single out a certainsubset of the 50 nearest neighbours, containing those words that are particularly rel-evant for (or more closely related to) the grammatical relation that the target word isinvolved in this particular sentence.
The idea we pursue here is to look at those neigh-bours in the thesaurus that occur in the same grammatical relation as our target wordand share a high mutual information (i.e.
word and grammatical relation do not onlyoccur frequently together, but also when you see one, there is a high probability thatyou see the other).While creating the thesaurus we consider all the words that co-occur with a certaintarget word (where co-occur means that it appears in the same grammatical relation).We also calculate the mutual information of both the target word and the co-occurringword and the grammatical relation.
Instead of throwing this information away afterfinishing an entry in the thesaurus, we now store this information in the grammaticalrelation database.Since this database grows to enormous proportions (in the order of 200GB for theone built up while processing the BNC), we need to reduce its size to be able towork with it.
If we only keep those entries in the database that involve the wordsin the thesaurus and their 50 neighbours, we can reduce the database to manageableproportions.
We experimented with reducing the number of entries in the databaseeven further by limiting the number of entries per grammatical relations to the ones134 Koeling and McCarthywith the highest mutual information scores, but this only had a negative effect on therecall, without improving the precision.
As we will see later, data sparseness is aserious issue and it is therefore not advisable to cut-out any usable information thatwe have at our disposal.
The word sense disambiguation procedure that uses the localcontext is then straightforward:1.
Parse the sentence with the target word (the word to be disambiguated).2.
If the target word is not involved with any of the 4 grammatical relations weconsidered for building up the thesaurus, local context can not be used.3.
Otherwise, consult the database to retrieve the co-occurring words:?
Let GR be the set of triples < w,r,x > from equation 12 in Section 2.2 fortarget word w.?
Let NGR be the set of triples < n j,r,x > from equation 12 for any neigh-bour n j ?
Nw?
For all w ?
T and all top 50 n ?
Nw, keep entries with < ?,r,x > indatabase.?
Let SGR be the set of relations < r,x > in the target sentence, where I <w,r,x > and I < n,r,x > are both positive (i.e.
r,x are both in the targetsentence and have high MI in BNC for both w and n.)4.
Compute the ranking score for each sense by applying to a modified version ofthe ranking equation (15) (compared to the original given in (11)), where the knearest neighbours are replaced by the subset found in the step 3.
(15) Prevalence Score ws_lci = ?n j?Nw MI?dssn j ?wnss(wsi,n j)?wsi?
?WSw wnss(wsi?
,n j)where the WordNet similarity score (wnss) is defined as before and let MI be I <n,r,x >, i.e.
the Mutual Information given by the events of seeing the grammaticalrelation in question and seeing the neighbour.2.4 An exampleThe fact that a subset of the neighbours in the thesaurus share some specific relationswith the target word in a particular sentence is something that we wish to exploit forWord Sense Disambiguation.
Let us have a closer look at the two example sentences13 and 14 that we introduced in the previous section.The grammatical relations that our target word body is involved with are (fromsentences 13 and 14 respectively):3(16) ?body?
object of ?keep?
for sentence 13 and(17) ?body?
subject of ?approved?
and ?body?
modified by the noun ?funding?
forsentence 143At the moment we only take 4 grammatical relations into account: Verb-Subject, Verb-Object, Adj-Noun and Noun-Noun modifier.From Predicting Predominant Senses to Local Context for WSD 135Table 1: Results of evaluation on the nouns in SemCorMethod Attempted Correct Wrong Precision RecallLocal Context 23,235 11,904 11,331 0.512 0.161First sense 23,235 11,795 11,440 0.508 ?Since keep is a fairly general verb, it is not surprising that quite a few of the neighboursoccur as object of keep.
As a matter of fact, 28 of the first 50 neighbours share thisrelation.
However, the good news is, that pretty much all the words associated withbody-parts (such as arm, hand, leg, face and head) are among them.The two grammatical relations that body is involved with in sentence 14, are morespecific.
There are just 6 neighbours that share the ?subject of approve?
relation withbody and another 5 that are used to modify the noun body.
Among these words are thehighly relevant words organisation, institution and board.3 Evaluation on SemCorThe example in the last section shows that in certain cases the method performs theway we envisaged.
However, we need a quantitative evaluation to get a proper pictureof the method?s usefulness.
We performed a full evaluation on SemCor.
In this experi-ment we limited our attention to nouns only.
We further eliminated Proper Names andmulti-word units from the test set.
Since the nouns in both these categories are mostlymonosemous, they are less interesting as test material and apart from that, they intro-duce problems (mostly parser related) that have little to do with the proposed method.A total of 73,918 words were left to evaluate.
Table 1 summarizes the results.
The fig-ure for recall for the ?First Sense?
method is not given, because we want to contrast thelocal context method with the first sense method.
Whilst the first sense method willreturn an answer in most cases, the local context method proposed in this paper willnot.
Here we want to focus on how we can improve on using the first sense heuristicby taking local context into account, rather than give complete results for a WSD task.There are several things to say about these results.
First of all, even though theresults for ?local context?
are slightly better than for ?first sense?, we expected morefrom it.
We had identified quite a few cases like 13 and 14 above, where the localcontext seemed to be able to help to identify the right neigbours in order to makethe difference.
Below, we will discuss a few cases where the grammatical relationsinvolved are so general, that the subset of neighbours is large and most importantly,not discriminative enough.
It seems to be reasonable to expect that the latter cases willnot influence the precision too much (i.e.
a smaller group of neighbourswill often givea different result, but some better, some worse).The recall is also lower than expected.
The first thought was that data sparsenesswas the main problem here, but additional experiments showed us that that is unlike tobe the case.
In one experiment we took a part of the GigaWord corpus (Graff, 2003),similar in size to the written part of the BNC (used in our original experiment) andbuilt our grammatical relation database using the combined corpus.
The recall wentup a little, but at the price of a slightly lower precision.136 Koeling and McCarthy4 DiscussionThe main problem causing the low recall seems to be the small number of grammaticalrelations that we use for building the thesaurus.
The four relations used (verb-subject,verb-object, noun-noun-modifier and adjective-noun-modifier) were chosen becauseof the parsers?
high accuracy for these.
For building the thesaurus, these grammaticalrelations suffice, since every word will occur in one of these relations sooner or later.However, whenever in a sentence the target word occurs outside these four relations,we are not able to look it up in our database.
Nouns within prepositional phrases seemto be a major victim here.
It should be straightforward to experiment with includingprepositional phrase related grammatical relations.
We will have to evaluate the influ-ence of the introduced noise on creating the thesaurus.
Alternatively, it is possible touse the four relations as before for creating the thesaurus and store the extra relationsin our database just for look-up.A second cause for missing target words is parser errors.
Even though RASP willproduce partial parses whenever a full parse of a sentence is not available, some lossis inevitable.
This is a harder problem to solve.
One way of solving this problemmight be by using a proximity thesaurus instead of a thesaurus build using grammat-ical relatons.
McCarthy et al (2007) reported promising results for using proximitybased thesaurus for predicting predominant senses, with accuracy figures closely be-hind those achieved with a dependency based thesaurus.One plausible reason why the method is not working in many cases, is the fact thatthe word to be disambiguated in the target sentence often occurs in a very generalgrammatical relation.
For example, ?subject of?
or ?direct object of?
a verb like have.In these cases, most of the neighbors in the thesaurus will be selected.
Even though itis clear that that would minimize the positive effect, it is not immediately obvious thatthis would have a negative effect.
It might therefore be the case that the number ofcases where the grammatical relation is a good selection criterion, is just lower thanwe thought (although this is not the impression that you get when you look at thedata).
We will need to establish a way of quantitatively evaluating this.The Mutual Information score gives us a measure of the dependence between thegrammatical relation and the word (neighbour of the target word) we are interestedit.
It gives us a handle on ?generality?
of the combination of seeing both events.
Thismeans that for a very common grammatical relation, many words will be expected toco-occur with a frequency comparable to their general frequency in texts.
The contrastwith relation/word combinations for which this is not the case might be usable foridentifying the cases that we want to exclude here.5 ConclusionsIn this paper we propose a completely unsupervised method for Word Sense Disam-biguation that takes the local context of the target word into account.
The startingpoint for this method is a method for automatically predicting the predominant sensesof words.
The grammatical relations that were used to create the distributional simi-larity thesaurus is exploited to select a subset of the k neighbours in the thesaurus, tofocus on those neighbours that are used in the same grammatical context as the wordwe want to disambiguate in the target sentence.From Predicting Predominant Senses to Local Context for WSD 137Even though the precision of our proposed method is slightly higher than for thepredominant sense method, we are disappointed by the current results.
We do believethat there is moremileage to be had from the methodwe suggest.
Improvement of bothrecall and precision is on the agenda for future research.
As we stated in the previoussection, we believe that the lower than expected recall can be addressed fairly easily,by considering more grammatical relations.
This is straightforward to implement andresults can be expected in the near future.A second approach, involving a thesaurus built on proximity, rather than grammat-ical relations will also be investigated.
Considering the expected lower precision forthis approach, we plan to use the proximity-based thesaurus as a ?back off?
solutionin case we fail to produce an answer with the dependency-based thesaurus.
Whenthe proximity-based thesaurus is in place, we plan to perform a full evaluation of thedependency versus the proximity approach.Before we can deal with improving the local context method?s precision, we needto have a better idea of the circumstances in which the method gets it wrong.
We haveidentified a large group of examples, where it is unlikely that the method will be suc-cessful.
A first step will be to develop a method to identify these cases automaticallyand eliminate those from the targets that we are attempting to try.
In the previoussection, we sketched how we think that we can achieve this by applying a PointwiseMutual Information threshold.
If we are successful, this will at least give us the op-portunity to focus on the strengths and weaknesses of the method.
At the moment, thevirtues of the method seem to be obscured too much by dealing with cases that shouldnot be considered.More insight in the method can also be gained from trying to identify in whichsituations the method is more likely to get it right.
At the moment we haven?t brokendown the results yet in terms of the target word?s polysemy and/or frequency of use.Some grammatical relations might be more useful for identifying the intended sensethan other.
A detailed analysis could give us these insights.We do believe there is a strong case to be made for using unsupervised methodsfor Word Sense Disambiguation (apart from McCarthy et al (2004)?s predominantsense method, other approaches include e.g.
Basili et al (2006)).
The predominantsense method has proven to be successful.
However, applying the first sense heuristicshould be limited to certain cases.
We can think of the cases where the dominanceof the predominant sense is so strong, that there is little to gain from doing a properattempt to disambiguation or to the cases where ?everything else fails?.
Ultimately,our goal is to find a balance between the dominance of the predominant sense and thestrength of the evidence from the supporting context.
If we are able to recognize thecorrect clues from the local context and use these clues to focus on those words witha high distributional similarity to the target word in the context in which the word isactually used, we can build on work on predicting predominant senses, to rely less onthe first sense heuristic.
This would be a good step forward for unsupervised WSD.Acknowledgments This workwas funded byUK EPSRC project EP/C537262 ?Rank-ing Word Senses for Disambiguation: Models and Applications?, and by a UK RoyalSociety Dorothy Hodgkin Fellowship to the second author.
We would like to thankSiddharth Patwardhan and Ted Pedersen for making the WN Similarity package avail-able and Julie Weeds for the thesaurus software.138 Koeling and McCarthyReferencesBasili, R., M. Cammisa, and A. Gliozzo (2006).
Integrating domain and paradig-matic similarity for unsupervised sense tagging.
In Proceedings of 7th EuropeanConference on Artificial Intelligence (ECAI06).Briscoe, E. and J. Carroll (2002).
Robust accurate statistical annotation of generaltext.
In Proceedings of the Third International Conference on Language Resourcesand Evaluation (LREC), Las Palmas, Canary Islands, Spain, pp.
1499?1504.Graff, D. (2003).
English gigaword.
Linguistic Data Consortium, Philadelphia.Iida, R., D. McCarthy, and R. Koeling (2008).
Gloss-based semantic similarity met-rics for predominant sense acquisition.
In Proceedings of the Third InternationalJoint Conference on Natural Language Processing, Hyderabad, India, pp.
561?568.Jiang, J. and D. Conrath (1997).
Semantic similarity based on corpus statistics andlexical taxonomy.
In 10th International Conference on Research in ComputationalLinguistics, Taiwan, pp.
19?33.Koeling, R., D. McCarthy, , and J. Carroll (2005).
Domain-specific sense distribu-tions and predominant sense acquisition.
In Proceedings of the Human LanguageTechnology Conference and EMNLP, Vancouver, Canada, pp.
419?426.Leech, G. (1992).
100 million words of English: the British National Corpus.
Lan-guage Research 28(1), 1?13.Lin, D. (1998).
Automatic retrieval and clustering of similar words.
In Proceedingsof COLING-ACL?98, Montreal, Canada, pp.
768?774.McCarthy, D., R. Koeling, J. Weeds, and J. Carroll (2004).
Finding predominantsenses in untagged text.
In Proceedings of the 42nd Annual Meeting of the Associ-ation for Computational Linguistics, Barcelona, Spain, pp.
280?287.McCarthy, D., R. Koeling, J. Weeds, and J. Carroll (2007).
Unsupervised acquisitionof predominant word senses.
Computational Linguistics 33(4), 553?590.Miller, G. A., C. Leacock, R. Tengi, and R. T. Bunker (1993).
A semantic concor-dance.
In Proceedings of the ARPA Workshop on Human Language Technology,pp.
303?308.
Morgan Kaufman.Patwardhan, S. and T. Pedersen (2003).
The CPAN WordNet::Similarity Package.http://search.cpan.org/?sid/WordNet-Similarity-0.05/.Yarowsky, D. and R. Florian (2002).
Evaluating sense disambiguation performanceacross diverse parameter spaces.
Natural Language Engineering 8(4), 293?310.
