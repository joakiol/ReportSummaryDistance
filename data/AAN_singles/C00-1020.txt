A Client/Server Architecture for Word Sense DisambiguationCaroline BrunXerox Research Centre Europe6, chemin de Maupertuis38240 Meylan FranceCaroline.Brun @ xrce.xerox.comAbstractThis paper presents a robust client/server implemen-tation of a word sense disambiguator for English.This system associates a word with its meaning ina given context using dictionaries as tagged corporain order to extract semantic disambiguation rules.Semantic rules are used as input of a semantic appli-cation program which encodes a linguistic strategyin order to select he best disambiguation rule forthe word to be disambiguated.
The semantic dis-ambiguation rule application program is part of theclient/server a chitecture enabling the processing oflarge corpora.1 IntroductionThis paper describes the implementation f an on-line lexical semantic disambiguation system for En-glish within a client/server linguistic application.This system allows to select he meaning of a wordgiven its context of appearance in a text segment,and addresses the general problem of Word SenseDisambiguation (WSD), (Ide et a190), (Gale et al92), (Gale et al 93), (Leacock et al93), (Yarowsky95), (Ng et al 96), (Resnik et al 97), (Vdronis et al98) and (Wilks et al 98).The basic idea of the semantic disambiguationsystem described here is to use a dictionary, inour case, the Oxford-Hachette bilingual dictionary(OHFD), (Oxford 94), a bilingual English/FrenchFrench/English dictionary designed initially for hu-mans but stored in SGML format, in order to extracta semantic disambiguation rule database.
The dic-tionary is in effect used as a semantically taggedcorpus.Once the semantic disambiguation database is avail-able, it becomes, as well as a dictionary and an on-tology, a resoume used by the server to performWSD on new input.
A linguistic strategy was im-plemented in order to select he best matching dis-ambiguation rule in a given context.This implementation is a follow-up of the Seman-tic Dictionary Lookup (SDL) aheady implementedin this client/server system (Aimelet 98) and o1' themethods proposed in (Dini et al 98) and (Diniet al 99).
The originality of our implementationlies in the rule selection strategy for application aswell as in the use of the client/server characteristicsto perform WSD.
After a brief presentation of theclient/server characteristics, we examine the imple-mentation of the WSD system.
Then we describethe results obtained after evaluation of the system,and finally we conclude with the description of itsapplications and perspectives.2 Architecture of the system2.1 XeLDa" a linguistic client/serverapplicationXeLDa addresses the problem of a generic de-veloplnent l'ramework for linguistic-based andlinguistics-enriched applications, based on avail-able, as well as future research results.
Potentialapplications include: translation aids over a net-work, on a desktop or a portable PC, syntax check-ing, terminology extraction, and authoring tools ingeneral.
This system provides developers and re-searchers with a common development architecturefor the open and seamless integration of linguis-tic services.
XeLDa offers different services uchas dictionary lookup, tokenization, tagging, shallowparsing, etc.Dictionary lookup and shallow parsing are ex-tensively used in the semantic rule extrac-tion/application processes described in this paper.2.2 Dictionary LookupThe OHFD dictionary is accessible via the XeLDaserver, which allows a fast and easy lookup ofwords.
Each entry in the OHFD dictionary (cf.Figl, entry of seize in SGML format) is organized indifferent levels (Akroyd 92), corresponding to syn-tactic ategories ( <S 1 >... </S 1 >, S 1 =part of speech132distinction J), which are themselves divided into se-nmntic categories (<$2> ... </$2>, the senses we areinterested in), themselves divided into several trans-lations (<TR> ... </TR>).<SE><HW>seize</HW><HG><PR><PH>si:z</PH></PR></HG><SI><OI><PS>vtr</PS></OI><S2><02><LA>Iit</LA><IC>take hold of</IC></02><TR>saisir<CO>person,object</CO></TR><TR><LE>to seize sb around thewaist</LE>saisir qn parla taille</TR><TR><LI>to seize hold of</Ll>se saisir de<CO>person</CO></TR><TR>s'emparer de<CO>object</CO></TR><TR>sauter  sur<CO>idea</CO></TR></$2><$2><02><LA>f ig</LA><lC>grasp</ IC></02><TR>sa is i r<CO>oppor tun i ty ,moment</CO></TR><TR>prendre<CO>in i t ia t ive</CO></TR><TR><LI>to be seized by</LI>@tre pris de<CO>emotion,pain, fit</CO></TR></$2><S2><02><LA>Mil</LA><LA>Pol</LA><IC>capture</ iC></O2><TR>s 'emparer  de<CO>power,territory, hostage, prisoner,installation</CO></TR><TR>prendre<CO>control</CO></TR></$2><S2><O2<LA>Jur</LA></02><TR>saisir<CO>arms, drugs,property</CO></TR><TR>apprdhender<CO>person</CO></TR></$2></SI><SI><OI><PS>vi</PS></OI><TR><CO>engine, mechanism</CO>se gripper</TR></SI></SE>Figl : SGML entry of seiee\]S l are a bit l'llOl*~ informative tlmn simple part of speechsince they distinguish also t,ansilivc, imransilivc rellexiveverbs, past participles, as well as some plural/singular nouns.Fine-grained SGML tags mark up different kinds ofinfornmtion related to semantic categories (<$2>)and translations, in particular:?
<C()> ... </CO> mark collocates (typical sub-jeers, objects, modiliers,...);?
<LC> ... </LC> mark compound exalnples as-sociated with the headword ;?
<LI~,> ... </LE> mark general examples used forillustration of a word or a phrase;?
<I,I> ... </I,I> mark idiomatic examples;?
<I~O> ... </LO> mark examples illustrating anobligatory syntactic structure of an entry;?
<I.U> ... </LU> mark examples of usage;?
<I,V> ... </IN> mark examples of phrasal verbl)attem.The recta-semantic information encoded into these(\]iffClCtlt SGMI.
tags is used to acquire semantic dis-,mfl~\]guation rules from the dictionary and guidesthe semantic rule application process, kS explainedlater.2.3 Shallow ParserThe "shanow parsing" technology is based on acascade of finite state transducers which allowsus to extracl from a sentence its shallow syntacticstructure (chunks) and its ftmctional relationships(AYt ct al.
97).The following example illustrates the kind ofanalysis provided by the shallow parser:A i~voh,er attd two shotguns wefw sei~ed atthepart3~\[SC \[NP A revolver  NP \ ] /SUBJ  and\[NP two shotguns NP\ ] /SUBJ  :v werese ized SC\] \[PP at the par ty  PP\].SUBJPASS(revolver ,  seize)SUBJPASS(shotgun,  seize)VMODOBJ (se ize ,a t ,par ty )Shallow parser transducers al'C accessible via theXcLI)a server enabling fast and robust execution(Roux98).The syntactic relations used in the disambiguationsystem arc subject-verb, verb-object and modifier.Subject-verb relations include cases such as pas-sives, rellexive and relative constructions.
Modilier133relations includes nominal, prepositional, adjecti-val, and adverbial phrases as well as relative clauses.2.4 Rule extractorTo perform semantic tag assignment using theOHFD dictionary, a sense number (Si) is assignedto each semantic category (<$2>) of each entry.These sense numbers act as semantic tags in theprocess of disambiguation rule application, becausethey directly point to a particular meaning of anentry.In the context of our OHFD-based implementation,sense numbering consists in concatenating thehomograph number (which is 0 if there are nohomographs of the entry, or 1, 2, 3 ..... for eachhomograph otherwise), the S1 number, and the $2number.
For example, the entry seize is composedof five distinct senses, respectively numbered 0.I.1,0.I.2, 0.I.3, 0.I.4 (for the transitive verb), 0.II.l (forthe intransitive verb).
Such sense numbers allow adeterministic retrieval of the semantic ategories ofa word.As in GINGER I (Dini et al 98) and GINGER II(Dini et al 99) the acquired rules are of two types:word level and/or ambiguity class level.The database is built according to the followingstrategy: for each sense number Si of the entry,examples are parsed with the shallow parseh andfunctional dependencies are extracted from theseexamples: if a dependency involves the entrylemma (headword), a semantic disambiguation ruleis built.
It can be paraphrased as:If the lemma X, which is ambiguous between $1,$2, ..., S~, appears in the dependency DEP(X,Y)or DEp(Y,X) then it can be disambiguated byassigning the sense Si.Such roles ate word level roles, because theymatch the lexical context.For each sense number again, collocates am usedto build semantic rules.
The type of dependencyillustrated by a collocate of an entry is SGML-taggedin the OHFD 2, and is directly exploited to buildrules in the same way.Then, for each rnle already built, semantic lassesfrom an ontology (in our case, WordNet 3, (Fell-2For example, a collocate in a verb entry describes either aSUBJ or an OBJ dependency depending on its SGML tag3Since WordNet classes are relatively poor for adjectivesand adverbs, additional infommtion about adjectival and adver-bial classes is extracted fi'om a general thesaurus, the Roget.baum 98)) are used to generalize the scope of therules: the non-headword argument of functionaldependencies is replaced in the rule by its selnan-tic classes.
The resulting rule can be paraphrased as:If the lemma X, which is ambiguous betweenSt, $2, ..., Sn, appears in the dependency DEP(X,ambiguityclass(Y)) or DEl'(mnbiguity_class(Y),X) then it can be disambiguated by assigning thesense Si.Such rules are class level rules, because theymatch the semantic context rather than lexicalitems.
In both cases, the type of the role (<LC>,<LE>, <LI>, <LO>, <LU>, <LV>, <CO>) is kept andencoded into the rules.Fox" example, from the last semantic category ofseize, 0.I.l, the system built the following wordlevel rules:SUBJ(engine,seize) ~ 0.l.1 <CO>;SUBJ(mechanism,seize) =~ 0.I.1 <CO>;Since engine belongs to the classes number6 (noun.artifact) and 19 (noun.phenomenon),whereas mechanism belongs to the classes num-ber 6, 4 (noun.act), 17 (noun.object), and 22(noun.process), corresponding class level rules are:SUB J(6/19,seize) =~ 0.I.
1 <CO>;SUB.I(4/6/17/22,seize) ~ 0.l.l <CO>;All dictionary entries are processed, which allowto automatically build a semantic disambiguationrule database available to be used by the semanticapplication program to disambiguate unseen texts.2.5 Rule application programThe rule application program matches rules of thesemantic database against new unseen input text us-ing a preference strategy in order to disambiguatewords on the fly.
In cases where the system is notable to find any matching rules, it gives as fall backresult he first meaning corresponding tothe syntac-tic part of speech of the word in the sentence.
Sincethe OHFD has been built using corpora frequencies,the most frequent senses of a word appear first inthe entry.
Therefore, even if there are no matchingrules, the system gives as result the most probablemeaning of the word to disambiguate.The linguistic strategy used in the application pro-gram is shown on several examples.1342.5.1 Simple rule matchingSttppose one wants to disambiguate ile woM seizein the sentence:Only cg'ter oranges had been served did ,ledseize the initiative, a scrmmnage pick-zq) e/fort byRonme Kirkl)atriek cancelling out Moore's score.The rule application l)rograul lirst extracts thefunctional dependencies by means of the shallowparser.
The word to be disambiguated has to bemember of one or more dependencies, ill this case:DOBJ(seize,initiative)The next step tries to match these dependen-cies with one or more rules in the semanticdisambiguation database.If one aud only one role matches the lexical contextof the dependencies directly, the system uses it todisambiguate he word, i.e.
to assign the sensenumber Si 4 to it; otherwise, if several rules matchdirectly at word level, the selection process usesthe meta-semantic information encoded in SGMI,tags within the dictionary (and kept in the rules oilpurpose) with the following preference strategy:rule built fl'om collocate (<C()>), from compoundsexamples (<LC>), from idiomatic examples (<IA>),t'rom structure xamples (<L()>), from phrasal verbpattern examples (<IN>), t'rom usage examples(<LU>), and finally from general examples (<I,E>).As far its implementation is concerned, rules areweighted flom 1 to 7 according to their types.This strategy relies on the linguistic choices lexi-cographers made to build the dictionary and takesinto account the accuracy of the linguistic typeel' the examples: it ranges from collocates, whichencode very typical arguments of prcdicatcs, tow'~ry general examples, as such the resulting rulesare linguistically-based.In these particular exmnple, only one lexical rulematches the dependency extracted:seize: l)OBJ(scize,iuitiative) => 0.I.2 <C()>meaning that the sense nmnber alTected toseize is 0.1.2.
This rule has been built using thetypical collocate of seize in its 0.I.2 sense, namelyinitiative.
The translation associated to this sensenmnber of seize in the dictionary is prendre, which4possibly translation, depending on the applicationis the desired one in this context.2.5.2 Rule competitionIn some casts, many rules may apply to a givenwoM in the same context, therefore we need a ruleselection strategy.Suppose one wants now to disambiguate lhe wordseize, in the sentence:77w police seized a man employed by the Krttgetw-dorp branch of the United Building Society onapproximately 18 May 1985.The dependencies extracted by the shallowparser which might lead to a disambiguation, i.e.which involve seize, are:SUBJ(police,seize)DO13J(seize,man)VMODOBJ(seize,about, 1985)VMODOBJ(seize,of, Society)VMODOBJ(seize,by,branch)In the case of our example, none of Ihe rulesof the database lnatch directly the lexical contextof the dependencies.
Therefore, the system triesto match the selnantic ontext of the dependency.To perform this task, the distance between thelist of semantic lasses o1' a potential rule (El)and the list o1' semantic lasses associaled with tilenon-headword o1' the dependency (L2) is calculated:d = (UAI?
I ) (UNION(L1,L2) ) - ( ;A IU) ( INT ' I ,g I , : ( I , I , L2) ) )U AI~I)( U N IO N ( I A ,L2) )"lb enable fast execution in terms of distancecalculation, a transducer which associate:~ a wordwith its WoMNet top classes has been built andis loaded on the server.
The distance calculatedhere ranges from 0 to 1, 0 meaning a fttll matchof classes, 1 no match at all, the "best" rulesbeing the ones with the smallest distance.
Ill thisparticular example, the list of classes atlached toman in WordNet is used to calculate the distancewith the potential matching rules.
Several rulesnow match the semantic ontext of the dependencyDOBJ(seize,man).After removing rules matching with a distanceabove some threshold, it appears that two potentialmatching rules still compete:?
one is built using the collocate \[prise,let\]:DOBJ(seizc,prisoner) => 0.I.3 <CO>;135at class level DOBJ(seize, l 8) => 0.I.3 <CO>;?
the other is built using the example to seizesomebody around the waist:DOBJ(seize,somebody) :=>0.I.l <LE>;at class level DOBJ(seize,l 8) => 0.I.1 <LE>;Indeed, prisoner and somebody sham the same se-mantic WordNet class (18, noun.animate) which isa member of the list of classes attached to man aswell.
The following preference strategy is appliedS:first, prefer ules from collocate (<CO>), then fromcompounds examples (<LC>), then from structureexamples (<LO>), then from phrasal verb pattern ex-amples (<LV>), then from usage examples (<LU>),and then fiom general examples (<LE>).
This strat-egy allows the selection of the role to apply, here theone built with the collocate \[prisoner\].
The sensenumber attached by the system to seize is 0.i.3,the general meaning being capture, and the Frenchtranslation s'emparer de.In cases where two competing rules are exactly ofthe same type, the system chooses the first one (firstsense appearing in the entry), relying on the fact thatthe OHFD was built using corpora: by default, se-mantic ategories of the entries are ordered accord-ing to frequency in corpora.2.5.3 Rule cooperationThe previous example showed how rules cancompete between each other.
But in some casesthey can cooperate as well.
Let's disambiguateseize in the following example sentence:United Slates federal agents seized a smface-to-air rocket launche~; a rocket motto; range-findersand a variety of milim O, manuals.Since the sentence contains a coordinated irectobject of seize, one gets the following dependenciesfiom the shallow parse,:DOBJ(seize,launcher)DOBJ(seize,motor)DOBJ(seize,range-finder)DOBJ(seize,manuals)Many roles are matching at class level, with agiven distance d, namely:DOBJ(seize,4/6/1 l) =;, 0.I.3 <CO>; d=0.75DOBJ(seize,7/24/4/9/26/6/18/10) =5 0.I.3 <CO>; d=0.9DOBJ(seize,8/6/14) => 0.I.4 <CO> ;d=0.75DOBJ(seize,21/7/15/9/6) :::>0.I.4 <CO> ;d=0.83Two rules point out the sense number 0.I.3,the two others, the sense number 0.1.4.
The strategyof role selection takes tiffs fact into account, givinginore importance to sense numbers matching manytimes.
As far as implementation is concerned,the distances associated with roles pointing onthe same sense number are multiplied together.Since distances range from 0 to 1, multiplyingthem decreases the resulting value of the distance.Since the lowest one is chosen, the system put theemphasis on semantic redundancy.
In the example,the distance finally associated with sense nmnber0.I.4 is 0.6625, which is smaller than the oneassociated with sense number 0.I.3 (0.675).
Thesense number selected by the system is therefore0.1.4, the translation being saisir, which is thedesired one.
The stone strategy is implementedfor word level rules cooperation, in this case, ruleweights are added.2.6 hnplementationThe different modules of the system presented hereare ilnplemented in C++ in the XeLDa client/serverarchitecture:- As aheady mentioned, the rule learner is a silnpleXeLDa client that performs rule extraction once ;- The rule application program is implemented asaspecific dictionary lookup service: when a word issemantically disalnbiguated with a rule, the applica-tion program reorders the dictionary entry accord-lug to the semantic ategory assigned to the word.The best matching part of the entry is then presentedfirst.
This application is built on top of Locolex(Bauer et al 95), an intelligent dictionary lookupwhich achieves ome word sense disambiguationusing word context (part-of speech and nmltiwordexpressions (MWEs) 6 recognition).
However, Lo-colex choices remain purely syntactic.
Using theOHFD information about examples, collocates andsubcategorization as well as semantic lasses froman ontology, the system presented here goes fnrthertowm'ds emantic disambiguation.5At class level, idiomatic examples are not used, becausethe idiomatic expressions given in the dictionary are fully lexi-calizede'Multiword expressions range flom compounds (salle debain) and fixed phrases (a priori) to idiomatic expressions (tosweep something t, nder the rug).1363 EvaluationWe ewfluated the system for English on the 34words used in the SENSEVAL competition (Kilgar-tiff 98; Kilgarriff 99), as well as on the SENSE-VAL corpus (HECTOR).
This provkled a test set ofaround 8500 sentences.
The SENSEVAL words arcall polysemous which means that the results givenbelow reflect real polysemy.We use the SENSEVAL test set for this in vitro ewfl-uation in order to give us a mean of comparison, es-pecially with the results obtained in tiffs competitionwith GINGER i1 (Dini el al.
99).
Still, it is impeltant to keep in mind that this comparison is difficultsince the dictionaries used are different.
We usedthe OHF1) bilingual dictionary while in SENSE-VAL the Oxford monolingual dictionary fl'om HEC-TOR was used.The evaluation given below is l)efformed it' and onlyif the semantic disambiguator has found a matchingrule, which means that tim results focus only on ourmethodology: recall and precision would have beenbetter if we had ewduated all outputs (even whenthe resul!
is just the first meaning corresponding tothe syntactic part el' speech of the word in the sen-tence) because the OHFI) gives by default he mostfrequent meaning of a word.The results obtained with the system arc given onthe following table:POS Precision RccallN 83.7 % 27.4 %A 81.3 % 55.8 %v 75 % 37.6 %Global 79.5 % 37.4 %Polysemy5.45.76.25.8Numbers show that the recall is equivalent to theone we obtained with GINGER 1I (37.6 %) in SEN-SF, VAL (tiffs just means that dictionaries content isabout the same) but precision is dramatically im-proved (46% for GINGER 1I for 79.5% with thissystem).
Increase in precision is due to the fact thatwe used more fine-grained ictionary information.Moreover, the evaluation shows that the distribu-tion of the precision results follows the preferencestrategy employed to select rtfles: collocate rulesam more precise than examples rules, compoundsor idiom rules am themselves more precise than us-agle exalnples, etc.Another ewfluation of smaller coverage has beenperformed on "all polysemous words" of about 400sentences extracted flom the T/me,s' newspaper; andshows similar results according to part of speechdistribution.POS Precision Recall Polyscm)N 81% 28.3 % 5.5A 79 % 64 % 5.8V 74% 34.5 % 9.8Global 78% 36.1% 6.2These results confirm that dictionary information isvery reliable for senmntic disambiguation tasks.4 Conclusion and Future  expectat ionsThis paper describes a client/server implementationel' a word sense disambiguator.
The method uses adictionary as a tagged corpus in order to extract asemantic disalnbiguation rule database.
Si rice thereis no need for a tagged training corpus, tim methodwe describe, which performs "all words" semanticdisambiguation, is unsupervised and avoide; the dataacquisition bottleneck observed in WS1).
Rules areavailable to be used by a semantic application pro-gram which uses a specilic linguistic strategy to se-lect the best matching rule to apply: the rule selec-l ion is based on an SGML typed-based preferencestrategy and takes into account rules competitionand rule cooperation.l~mphasis put on the advantage of the client/serverimplementation i  tin'ms o1' robustness as well kS onthe good results provided by the strategy in terms ofrecall and precision.
The client/server implementa-lion provides robustness, modularity and l'a~t execu-tion.The disambiguation strategy provides hig, h preci-sion results, because senses and examples have beendelined by lexicographers and therel'ore provide areliable linguistic source for constructing a databaseof semantic disambiguation rules.
Recall re.suits aregood as well, meaning that the coverage of the dic-tionary is iml)ortant.These results could be improved by learning moredisambiguation rules, for example using the co lrespondences between functional dependencies:when a dependency DOBJ(X,Y) is extracted, a rulefor SUBJPASS(Y,X) can be built (and vice-wzrsa).They could be improved as well by integrating moreline-grained semantic inl'ormation l'or adverbs andac!iective, WordNet being relatively poor \['or theseparts of speech.Since the architecture is modular, the sy~;tem ini-tially provided for F, nglish can be quickly adaptedfor any other language as soon as the requi:red com-ponents are available.
We already started to build a137semantic disambiguator for French, but we need tointegrate a French semantic ontology into the sys-tem.
At the moment, it is planned to extract suchan ontology from the dictionary itself, using the se-mantic labels which am associated with semanticcategories.
The expectation is to obtain more con-sistency between semantic tags (dictionary) and se-mantic lasses (ontology).Because we used a bilingual dictionary we inte-grated the disambiguation module into a generalsystem architecture d dicated to the comprehensionof electronic texts written in a foreign language.This technique coupled with other natural languageprocessing teclmiques such as shallow parsing canalso be used to extract general semantic networksfrom dictionaries or encyclopedia.Acknowledgments: Many thanks to FrdddriqueSegond for help, support and advices.
Thanks toE.
Aimelet, S. Aft-Mokhtal; J.R Chanod, M.H.
Cor-rdard, G. Grefenstette, C. Roux, and N. Tarbouriechfor helpful discussions.ReferencesElisabeth Aimelet.
1998.
XeLDa Dictiona~TLookup hnprovement XRCE ATS XeLDa Techni-cal Report.S.
Ait-Mokhtar, J-R Chanod.
1997.
Subject andObject Dependency Extraction Using Finite-StateTransducers.
In Proceedings of the Workshop onatttomatic Information E:mztctiotz arid the Build-ing of Lexical Semantic Resourees,, ACL, p71-77,Madrid, Spain.R.
Akroyd.
September 1992.
Markup for theOxford-Hachette French Dictionary, English toFrench.
Technical report Oxford University Press.D.
Bauel; E Segond, A. Zaenen.
1995.
LOCOLEX:the translation rolls off your tongue.
In Proceedingsof ACH-ALLC, Santa-Barbara, USA.L.
Dini, V. Di Tomaso, E Segond.
1998.
ErrorDriven Word Sense I)isambiguation I Proceedingsof COLING/ACL, p320-324, Montreal, Canada.L.
Dini, V. Di Tomaso, E Segond.
1999.
GINGERII: an example-driven word sense disambiguator.
InComputer and the Humanities, to appear.C.
Fellbaum.
1998.
WordNet: An Electronic Lexi-cal Database, MIT Press, Cambridge (MA).W.A.
Gale, K.W.
Church, D. Yarowsky.
1992.Work on statistical methods for word sense disam-biguation in Probabilistic Approaches to NaturalLanguage: Papers from the 1992 AAAI Fall Sym-posium, p54-60, Cambridge, MA, October.W.A.
Gale, K.W.
Church, I3.
Yarowsky.
1993.
Amethod for dismbiguating word senses in a largecorpus, in C()ml)uter and the Humanities, 26:415-439.N.
Ide.
Vdronis.
1990.
Very lalge neural networksfor word sense disambiguation, in Proceedil~gs ofthe 9th european conference oIz artificial intelli-gence, ECAI'90, p. 366-368, Stockhohn.A.
Kilganiff.
1998.
SENSEVAL: An Exercise inEvaluating Word Sense Disambiguation Programs.In Proceeding of the First International Col~\['erenceon lxmguage Ressources and Evaluation, Granada,Spain.A.
Kilgarriff.
1999.
Gold standard atasets forevaluating word sense disambiguation programs.
InComputer and the Humanities, to appear.C.
Leaeock, G. Towell.
1993.
Corpus-based statis-tical sense resolution, in Proceedings of the ARPAHuman Langttage technology workshop, San Fran-cisco, Morgan Kaufman.H.T.
Ng, H.B.
Lee.
1996.
Integrating MultipleKnowledge Sources to Disambiguate Word Sense:an Examplar-based Approach.
In Proceedings ofthe ACL, p.40-47.Oxford-Hachette.
1994.
The Oxford HachetteFrench Dictionao~.
Edited by M.-H. Corrdard andV.
Grundy, Oxford University Press-Hachette.R Resnik and D. Yarowsky.
1997.
A perspectiveon word sense disambiguation methods and theirevaluation.
In Proceedings ().\['ACL SIGLEX Work-sho 1) on Tagging Text with Lexical Semantics: Why,What, and How?, Washington D.C., USA.Claude Roux.
1998.
XeLDa Shallow Parser XRCEATS XeLDa Technical Report.J.
Vdronis, N. Ide.
1998.
Introduction tothe SpecialIssue on Word Sense Disambiguation: The State ofthe Art.
in Computational Liltguistics 24/1.J.
Vdronis, N. lde.
1990.
Word sense disambigua-tion with very large neural networks extracted fiomvery large corpora In Proceedings of the 13th inter-national cotzference on computatimzal linguistics,COLING'90, volmne 2, p.389-394, Helsinki, Fin-land.D.
Yarowsky.
1995.
Unsupervised word sense dis-ambiguation method rivalizing supervised methods.In Proceedings o\['the ACL, p189-196.Y.
Wilks, M. Stevenson.
1998.
Word Sense Disam-biguation using Optimised Combinations of Knowl-edge Sources.
In Proceedings o\[ COLING/ACL,Montreal, Canada.138
