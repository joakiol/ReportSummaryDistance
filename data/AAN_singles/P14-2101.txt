Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 618?624,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsAutomatic Labelling of Topic Models Learned from Twitter bySummarisationAmparo Elizabeth Cano Basave?Yulan He?Ruifeng Xu?
?Knowledge Media Institute, Open University, UK?School of Engineering and Applied Science, Aston University, UK?Key Laboratory of Network Oriented Intelligent ComputationShenzhen Graduate School, Harbin Institute of Technology, Chinaamparo.cano@open.ac.uk, y.he@cantab.net, xuruifeng@hitsz.edu.cnAbstractLatent topics derived by topic models suchas Latent Dirichlet Allocation (LDA) arethe result of hidden thematic structureswhich provide further insights into thedata.
The automatic labelling of suchtopics derived from social media poseshowever new challenges since topics maycharacterise novel events happening in thereal world.
Existing automatic topic la-belling approaches which depend on exter-nal knowledge sources become less appli-cable here since relevant articles/conceptsof the extracted topics may not exist in ex-ternal sources.
In this paper we proposeto address the problem of automatic la-belling of latent topics learned from Twit-ter as a summarisation problem.
We in-troduce a framework which apply sum-marisation algorithms to generate topic la-bels.
These algorithms are independentof external sources and only rely on theidentification of dominant terms in doc-uments related to the latent topic.
Wecompare the efficiency of existing stateof the art summarisation algorithms.
Ourresults suggest that summarisation algo-rithms generate better topic labels whichcapture event-related context compared tothe top-n terms returned by LDA.1 IntroductionTopic model based algorithms applied to socialmedia data have become a mainstream techniquein performing various tasks including sentimentanalysis (He, 2012) and event detection (Zhao etal., 2012; Diao et al, 2012).
However, one ofthe main challenges is the task of understandingthe semantics of a topic.
This task has been ap-proached by investigating methodologies for iden-tifying meaningful topics through semantic coher-ence (Aletras and Stevenson, 2013; Mimno et al,2011; Newman et al, 2010) and for characterisingthe semantic content of a topic through automaticlabelling techniques (Hulpus et al, 2013; Lau etal., 2011; Mei et al, 2007).
In this paper we focuson the latter.Our research task of automatic labelling a topicconsists on selecting a set of words that best de-scribes the semantics of the terms involved in thistopic.
The most generic approach to automatic la-belling has been to use as primitive labels the top-n words in a topic distribution learned by a topicmodel such as LDA (Griffiths and Steyvers, 2004;Blei et al, 2003).
Such top words are usuallyranked using the marginal probabilities P (wi|tj)associated with each word wifor a given topic tj.This task can be illustrated by considering the fol-lowing topic derived from social media related toEducation:school protest student fee choic motherlodtuition teacher anger policwhere the top 10 words ranked by P (wi|tj) forthis topic are listed.
Therefore the task is to findthe top-n terms which are more representative ofthe given topic.
In this example, the topic certainlyrelates to a student protest as revealed by the top3 terms which can be used as a good label for thistopic.However previous work has shown that topterms are not enough for interpreting the coherentmeaning of a topic (Mei et al, 2007).
More re-cent approaches have explored the use of externalsources (e.g.
Wikipedia, WordNet) for supportingthe automatic labelling of topics by deriving can-didate labels by means of lexical (Lau et al, 2011;Magatti et al, 2009; Mei et al, 2007) or graph-based (Hulpus et al, 2013) algorithms applied onthese sources.Mei et al (2007) proposed an unsupervisedprobabilistic methodology to automatically assigna label to a topic model.
Their proposed approach618was defined as an optimisation problem involvingthe minimisation of the KL divergence between agiven topic and the candidate labels while max-imising the mutual information between these twoword distributions.
Lau et al (2010) proposed tolabel topics by selecting top-n terms to label theoverall topic based on different ranking mecha-nisms including pointwise mutual information andconditional probabilities.Methods relying on external sources for auto-matic labelling of topics include the work by Ma-gatti et al (2009) which derived candidate topiclabels for topics induced by LDA using the hi-erarchy obtained from the Google Directory ser-vice and expanded through the use of the OpenOf-fice English Thesaurus.
Lau et al (2011) gen-erated label candidates for a topic based on top-ranking topic terms and titles of Wikipedia arti-cles.
They then built a Support Vector Regres-sion (SVR) model for ranking the label candidates.More recently, Hulpus et al (2013) proposed tomake use of a structured data source (DBpedia)and employed graph centrality measures to gener-ate semantic concept labels which can characterisethe content of a topic.Most previous topic labelling approaches focuson topics derived from well formatted and staticdocuments.
However in contrast to this type ofcontent, the labelling of topics derived from tweetspresents different challenges.
In nature microp-ost content is sparse and present ill-formed words.Moreover, the use of Twitter as the ?what?s-happening-right now?
tool, introduces new event-dependent relations between words which mightnot have a counter part in existing knowledgesources (e.g.
Wikipedia).
Our original interest inlabelling topics stems from work in topic modelbased event extraction from social media, in par-ticular from tweets (Shen et al, 2013; Diao etal., 2012).
As opposed to previous approaches,the research presented in this paper addresses thelabelling of topics exposing event-related contentthat might not have a counter part on existing ex-ternal sources.
Based on the observation that ashort summary of a collection of documents canserve as a label characterising the collection, wepropose to generate topic label candidates basedon the summarisation of a topic?s relevant docu-ments.
Our contributions are two-fold:- We propose a novel approach for topics la-belling that relies on term relevance of documentsrelating to a topic; and- We show that summarisation algorithms,which are independent of extenal sources, can beused with success to label topics, presenting ahigher perfomance than the top-n terms baseline.2 MethodologyWe propose to approach the topic labelling prob-lem as a multi-document summarisation task.
Thefollowing describes our proposed framework tocharacterise documents relevant to a topic.2.1 PreliminariesGiven a set of documents the problem to be solvedby topic modelling is the posterior inference of thevariables, which determine the hidden thematicstructures that best explain an observed set of doc-uments.
Focusing on the Latent Dirichlet Alloca-tion (LDA) model (Blei et al, 2003; Griffiths andSteyvers, 2004), let D be a corpus of documentsdenoted as D = {d1,d2, ..,dD}; where each doc-ument consists of a sequence ofNdwords denotedby d = (w1, w2, .., wNd); and each word in adocument is an item from a vocabulary index ofV different terms denoted by {1, 2, .., V }.
GivenD documents containing K topics expressed overV unique words, LDA generative process is de-scribed as follows:- For each topic k ?
{1, ...K} draw ?k?Dirichlet(?
),- For each document d ?
{1..D}:?
draw ?d?
Dirichlet(?);?
For each word n ?
{1..Nd} in document d:?
draw a topic zd,n?
Multinomial(?d);?
draw a word wd,n?
Multinomial(?zd,n).where ?kis the word distribution for topic k,and ?dis the distribution of topics in documentd.
Topics are interpreted using the top N termsranked based on the marginal probability p(wi|tj).2.2 Automatic Labelling of Topic ModelsGiven K topics over the document collection D,the topic labelling task consists on discovering asequence of words for each topic k ?
K. We pro-pose to generate topic label candidates by sum-marising topic relevant documents.
Such docu-ments can be derived using both the observed datafrom the corpus D and the inferred topic modelvariables.
In particular, the prominent topic of adocument d can be found bykd= argmaxk?Kp(k|d) (1)619Therefore given a topic k, a set of C documentsrelated to this topic can be obtained via equation1.Given the set of documents C relevant to topic k,we proposed to generate a label of a desired lengthx from the summarisation of C.2.3 Topic Labelling by SummarisationWe compare different summarisation algorithmsbased on their ability to provide a good label to agiven topic.
In particular we investigate the use oflexical features by comparing three different well-known multi-document summarisation algorithmsagainst the top-n topic terms baseline.
These al-gorithms include:Sum Basic (SB) This is a frequency based sum-marisation algorithm (Nenkova and Vanderwende,2005), which computes initial word probabilitiesfor words in a text.
It then weights each sen-tence in the text (in our case a micropost) bycomputing the average probability of the words inthe sentence.
In each iteration it picks the high-est weighted document and from it the highestweighted word.
It uses an update function whichpenalises words which have already been picked.Hybrid TFIDF (TFIDF) It is similar to SB,however rather than computing the initial wordprobabilities based on word frequencies it weightsterms based on TFIDF.
In this case the documentfrequency is computed as the number of times aword appears in a micropost from the collectionC.
Following the same procedure as SB it returnsthe top x weighted terms.Maximal Marginal Relevance (MMR) This is arelevance based ranking algorithm (Carbonell andGoldstein, 1998), which avoids redundancy in thedocuments used for generating a summary.
It mea-sures the degree of dissimilarity between the docu-ments considered and previously selected ones al-ready in the ranked list.Text Rank (TR) This is a graph-based sum-mariser method (Mihalcea and Tarau, 2004) whereeach word is a vertex.
The relevance of a vertex(term) to the graph is computed based on globalinformation recursively drawn from the wholegraph.
It uses the PageRank algorithm (Brin andPage, 1998) to recursively change the weight ofthe vertices.
The final score of a word is there-fore not only dependent on the terms immediatelyconnected to it but also on how these terms con-nect to others.
To assign the weight of an edgebetween two terms, TextRank computes word co-occurrence in windows of N words (in our caseN = 10).
Once a final score is calculated for eachvertex of the graph, TextRank sorts the terms ina reverse order and provided the top T vertices inthe ranking.
Each of these algorithms produces alabel of a desired length x for a given topic k.3 Experimental Setup3.1 DatasetOur Twitter Corpus (TW) was collected betweenNovember 2010 and January 2011.
TW comprisesover 1 million tweets.
We used the OpenCalais?document categorisation service1to generate cate-gorical sets.
In particular, we considered four dif-ferent categories which contain many real-worldevents, namely: War and Conflict (War), Disasterand Accident (DisAc), Education (Edu) and Lawand Crime (LawCri).
The final TW dataset afterremoving retweets and short microposts (less than5 words after removing stopwords) contains 7000tweets in each category.We preprocessed TW by first removing: punc-tuation, numbers, non-alphabet characters, stopwords, user mentions, and URL links.
We thenperformed Porter stemming (Porter, 1980) in orderto reduce the vocabulary size.
Finally to addressthe issue of data sparseness in the TW dataset, weremoved words with a frequency lower than 5.3.2 Generating the Gold StandardEvaluation of automatic topic labelling often re-lied on human assessment which requires heavymanual effort (Lau et al, 2011; Hulpus et al,2013).
However performing human evaluations ofSocial Media test sets comprising thousands of in-puts become a difficult task.
This is due to boththe corpus size, the diversity of event-related top-ics and the limited availability of domain experts.To alleviate this issue here, we followed the distri-bution similarity approach, which has been widelyapplied in the automatic generation of gold stan-dards (GSs) for summary evaluations (Donaway etal., 2000; Lin et al, 2006; Louis and Nenkova,2009; Louis and Nenkova, 2013).
This approachcompares two corpora, one for which no GS labelsexist, against a reference corpus for which a GSexists.
In our case these corpora correspond to theTW and a Newswire dataset (NW).
Since previous1OpenCalais service, http://www.opencalais.com620research has shown that headlines are good indi-cators of the main focus of a text, both in struc-ture and content, and that they can act as a humanproduced abstract (Nenkova, 2005), we used head-lines as the GS labels of NW.The News Corpus (NW) was collected duringthe same period of time as the TW corpus.
NWconsists of a collection of news articles crawledfrom traditional news media (BBC, CNN, andNew York Times) comprising over 77,000 articleswhich include supplemental metadata (e.g.
head-line, author, publishing date).
We also used theOpenCalais?
document categorisation service toautomatically label news articles and consideredthe same four topical categories, (War, DisAc,Edu and LawCri).
The same preprocessing stepswere performed on NW.Therefore, following a similarity alignment ap-proach we performed the steps oulined in Algo-rithm 1 for generating the GS topic labels of a topicin TW.Algorithm 1 GS for Topic LabelsInput: LDA topics for TW, and the LDA topics for NW forcategory c.Output: Gold standard topic label for each of the LDA top-ics for TW.1: for each topic i ?
{1, 2, ..., 100} from TW do2: for each topic j ?
{1, 2..., 100} from NW do3: Compute the Cosine similarity between word dis-tributions of topic tiand topic tj.4: end for5: Select topic j which has the highest similarity to i andwhose similarity measure is greater than a threshold(in this case 0.7)6: end for7: for each of the extracted topic pairs (ti?
tj) do8: Collect relevant news articles CjNWof topic tjfromthe NW set.9: Extract the headlines of news articles from CjNWandselect the top x most frequent words as the gold stan-dard label for topic tiin the TW set10: end forThese steps can be outlined as follows:1) Weran LDA on TW and NW separately for each cate-gory with the number of topics set to 100; 2) Wethen aligned the Twitter topics and Newswire top-ics by the similarity measurement of word distri-butions of these topics (Ercan and Cicekli, 2008;Haghighi and Vanderwende, 2009; Wang et al,2009; Delort and Alfonseca, 2012); 3) Finally togenerate the GS label for each aligned topic pair(ti?
tj), we extracted the headlines of the newsarticles relevant to tjand selected the top x mostfrequent words (after stop word removal and stem-ming).
The generated label was used as the goldstandard label for the corresponding Twitter topictiin the topic pair.4 Experimental ResultsWe compared the results of the summarisationtechniques with the top terms (TT) of a topic asour baseline.
These TT set corresponds to thetop x terms ranked based on the probability ofthe word given the topic (p(w|k)) from the topicmodel.
We evaluated these summarisation ap-proaches with the ROUGE-1 method (Lin, 2004),a widely used summarisation evaluation metricthat correlates well with human evaluation (Liuand Liu, 2008).
This method measures the over-lap of words between the generated summary anda reference, in our case the GS generated from theNW dataset.The evaluation was performed at x ={1, .., 10}.
Figure 1 presents the ROUGE-1 per-formance of the summarisation approaches as thelengthx of the generated topic label increases.
Wecan see in all four categories that the SB andTFIDF approaches provide a better summarisa-tion coverage as the length of the topic label in-creases.
In particular, in both the Educationand Law & Crime categories, both SB andTFIDF outperforms TT and TR by a large margin.The obtained ROUGE-1 performance is within thesame range of performance previously reported onSocial Media summarisation (Inouye and Kalita,2011; Nichols et al, 2012; Ren et al, 2013).Table 1 presents average results for ROUGE-1 in the four categories.
Particularly the SBand TFIDF summarisation techniques consis-tently outperform the TT baseline across all fourcategories.
SB gives the best results in three cate-gories except War.ROUGE-1TT SB TFIDF MMR TRWar 0.162 0.184 0.192 0.154 0.141DisAc 0.134 0.194 0.160 0.132 0.124Edu 0.106 0.240 0.187 0.104 0.023LawCri 0.035 0.159 0.149 0.034 0.115Table 1: Average ROUGE-1 for topic labels at x ={1..10}, generated from the TW dataset.The generated labels with summarisation at x =5 are presented in Table 2, where GS represents thelabel generated from the Newswire headlines.Different summarisation techniques revealwords which do not appear in the top terms but6210.050.100.150.200.252.5 5.0 7.5 10.0xRougeWar_Conflict0.100.150.200.252.5 5.0 7.5 10.0xRougeDisaster_Accident0.10.22.5 5.0 7.5 10.0xRougeEducation0.000.050.100.150.202.5 5.0 7.5 10.0xRougeLaw_CrimeTwitter TopicsvariableTTSBTFIDFTRMMRFigure 1: Performance in ROUGE for Twitter-derived topic labels, where x is the number of terms in thegenerated labelwhich are relevant to the information clusteredby the topic.
In this way, the labels generated fortopics belonging to different categories generallyextend the information provided by the top terms.For example in Table 2, the DisAc headline ischaracteristic of the New Zealand?s Pike River?scoal mine blast accident, which is an eventoccurred in November 2010.Although the top 5 terms set from the LDA topicextracted from TW (listed under TT) does capturerelevant information related to the event, it doesnot provide information regarding the blast.
In thissense the topic label generated by SB more accu-rately describes this event.We can also notice that the GS labels generatedfrom Newswire media presented in Table 2 appearon their own, to be good labels for the TW topics.However as we described in the introduction wewant to avoid relaying on external sources for thederivation of topic labels.This experiment shows that frequency basedsummarisation techniques outperform graph-based and relevance based summarisationtechniques for generating topic labels that im-prove upon the top-terms baseline, without relyingon external sources.
This is an attractive propertyfor automatically generating topic labels fortweets where their event-related content might nothave a counter part on existing external sources.5 Conclusions and Future WorkIn this paper we proposed a novel alternative totopic labelling which do not rely on external datasources.
To the best of out knowledge no existingwork has been formally studied for automatic la-belling through summarisation.
This experimentshows that existing summarisation techniques canbe exploited to provide a better label of a topic,extending in this way a topic?s information by pro-War DisAcGS protest brief policafghanistan attack worldleader bomb obamapakistanmine zealand rescu minercoal fire blast kill man dis-astTT polic offic milit recentmosqumine coal pike riverzealandSB terror war polic arrest offic mine coal explos river pikeTFIDF polic war arrest offic terror mine coal pike safetizealandMMR recent milit arrest attacktargettrap zealand coal mine ex-plosTR war world peac terror hope mine zealand plan fire fdaEdu LawCriGS school protest student feechoic motherlod tuitionteacher anger policman charg murder arrestpolic brief woman attackinquiri foundTT student univers protest oc-cupi planman law child deal jailSB student univers schoolprotest educman arrest law kill judgTFIDF student univers protestplan collegman arrest law judg killMMR nation colleg protest stu-dent occupifound kid wife student jailTR student tuition fee grouphitman law child deal jailTable 2: Labelling examples for topics generatedfrom the TW Dataset.
GS represents the gold-standard generated from the relevant Newswiredataset.
All terms are Porter stemmed as describedin subsection 3.1viding a richer context than top-terms.
These re-sults show that there is room to further improveupon existing summarisation techniques to caterfor generating candidate labels.AcknowledgmentsThis work was supported by the EPRSC grantEP/J020427/1, the EU-FP7 project SENSE4US(grant no.
611242), and the Shenzhen Interna-tional Cooperation Research Funding (grant num-ber GJHZ20120613110641217).622ReferencesNikolaos Aletras and Mark Stevenson.
2013.
Evaluat-ing topic coherence using distributional semantics.In Proceedings of the 10th International Conferenceon Computational Semantics (IWCS 2013) ?
LongPapers, pages 13?22, Potsdam, Germany, March.Association for Computational Linguistics.David Meir Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
In J. Mach.
Learn.Res.
3, pages 993?1022.Sergey Brin and Lawrence Page.
1998.
The anatomyof a large-scale hypertextual web search engine*1.
In Computer networks and ISDN systems, vol-ume 30, pages 107?117.Jaime Carbonell and Jade Goldstein.
1998.
The use ofmmr, diversity-based reranking for reordering docu-ments and producing summaries.
In Proceedings ofthe 21st Annual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, SIGIR ?98, pages 335?336, New York,NY, USA.
ACM.Jean-Yves Delort and Enrique Alfonseca.
2012.
Dual-sum: A topic-model based approach for update sum-marization.
In Proceedings of the 13th Conferenceof the European Chapter of the Association for Com-putational Linguistics, EACL ?12, pages 214?223,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Qiming Diao, Jing Jiang, Feida Zhu, and Ee-Peng Lim.2012.
Finding bursty topics from microblogs.
InProceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 536?544, Jeju Island, Korea,July.
Association for Computational Linguistics.Robert L. Donaway, Kevin W. Drummey, and Laura A.Mather.
2000.
A comparison of rankings producedby summarization evaluation measures.
In Proceed-ings of the 2000 NAACL-ANLP Workshop on Au-tomatic Summarization, NAACL-ANLP-AutoSum?00, pages 69?78, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Gonenc Ercan and Ilyas Cicekli.
2008.
Lexical co-hesion based topic modeling for summarization.
InProceedings of the 9th International Conference onComputational Linguistics and Intelligent Text Pro-cessing, CICLing?08, pages 582?592, Berlin, Hei-delberg.
Springer-Verlag.Thomas L. Griffiths and Mark Steyvers.
2004.
Findingscientific topics.
PNAS, 101(suppl.
1):5228?5235.Aria Haghighi and Lucy Vanderwende.
2009.
Ex-ploring content models for multi-document summa-rization.
In Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of the NorthAmerican Chapter of the Association for Compu-tational Linguistics, NAACL ?09, pages 362?370,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Yulan He.
2012.
Incorporating sentiment priorknowledge for weakly supervised sentiment analy-sis.
ACM Transactions on Asian Language Infor-mation Processing, 11(2):4:1?4:19, June.Ioana Hulpus, Conor Hayes, Marcel Karnstedt, andDerek Greene.
2013.
Unsupervised graph-basedtopic labelling using dbpedia.
In Proceedings of thesixth ACM international conference on Web searchand data mining, WSDM ?13, pages 465?474, NewYork, NY, USA.
ACM.David Inouye and Jugal K. Kalita.
2011.
Comparingtwitter summarization algorithms for multiple postsummaries.
In SocialCom/PASSAT, pages 298?306.IEEE.Jey Han Lau, David Newman, Karimi Sarvnaz, andTimothy Baldwin.
2010.
Best Topic Word Selec-tion for Topic Labelling.
CoLing.Jey Han Lau, Karl Grieser, David Newman, and Tim-othy Baldwin.
2011.
Automatic labelling of topicmodels.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies - Volume 1,HLT ?11, pages 1536?1545, Stroudsburg, PA, USA.Association for Computational Linguistics.Chin-Yew Lin, Guihong Cao, Jianfeng Gao, andJian-Yun Nie.
2006.
An information-theoreticapproach to automatic evaluation of summaries.In Proceedings of the Main Conference on Hu-man Language Technology Conference of the NorthAmerican Chapter of the Association of Computa-tional Linguistics, HLT-NAACL ?06, pages 463?470, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Chin-Yew Lin.
2004.
Rouge: A package for auto-matic evaluation of summaries.
In Stan SzpakowiczMarie-Francine Moens, editor, Text SummarizationBranches Out: Proceedings of the ACL-04 Work-shop, pages 74?81, Barcelona, Spain, July.
Associa-tion for Computational Linguistics.Feifan Liu and Yang Liu.
2008.
Correlation betweenrouge and human evaluation of extractive meetingsummaries.
In Proceedings of the 46th AnnualMeeting of the Association for Computational Lin-guistics on Human Language Technologies: ShortPapers, HLT-Short ?08, pages 201?204, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Annie Louis and Ani Nenkova.
2009.
Automaticallyevaluating content selection in summarization with-out human models.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 1 - Volume 1, EMNLP?09, pages 306?314, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Annie Louis and Ani Nenkova.
2013.
Automaticallyassessing machine summary content without a gold623standard.
Computational Linguistics, 39(2):267?300.Davide Magatti, Silvia Calegari, Davide Ciucci, andFabio Stella.
2009.
Automatic labeling of top-ics.
In Proceedings of the 2009 Ninth InternationalConference on Intelligent Systems Design and Appli-cations, ISDA ?09, pages 1227?1232, Washington,DC, USA.
IEEE Computer Society.Qiaozhu Mei, Xuehua Shen, and ChengXiang Zhai.2007.
Automatic labeling of multinomial topicmodels.
In Proceedings of the 13th ACM SIGKDDinternational conference on Knowledge discoveryand data mining, KDD ?07, pages 490?499, NewYork, NY, USA.
ACM.Rada Mihalcea and Paul Tarau.
2004.
TextRank:Bringing Order into Texts.
In Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?04, pages 404?411, Barcelona, Spain.
As-sociation for Computational Linguistics.David Mimno, Hanna M. Wallach, Edmund Talley,Miriam Leenders, and Andrew McCallum.
2011.Optimizing semantic coherence in topic models.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?11,pages 262?272, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Ani Nenkova and Lucy Vanderwende.
2005.
The im-pact of frequency on summarization.
Microsoft Re-search, Redmond, Washington, Tech.
Rep. MSR-TR-2005-101.Ani Nenkova.
2005.
Automatic text summarization ofnewswire: Lessons learned from the document un-derstanding conference.
In Proceedings of the 20thNational Conference on Artificial Intelligence - Vol-ume 3, AAAI?05, pages 1436?1441.
AAAI Press.David Newman, Jey Han Lau, Karl Grieser, and Tim-othy Baldwin.
2010.
Automatic evaluation oftopic coherence.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, HLT ?10, pages 100?108, Stroudsburg, PA,USA.
Association for Computational Linguistics.Jeffrey Nichols, Jalal Mahmud, and Clemens Drews.2012.
Summarizing sporting events using twitter.
InProceedings of the 2012 ACM International Confer-ence on Intelligent User Interfaces, IUI ?12, pages189?198, New York, NY, USA.
ACM.Martin Porter.
1980.
An algorithm for suffix stripping.Program, 14(3):130?137.Zhaochun Ren, Shangsong Liang, Edgar Meij, andMaarten de Rijke.
2013.
Personalized time-awaretweets summarization.
In Proceedings of the 36thInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, SIGIR?13, pages 513?522, New York, NY, USA.
ACM.Chao Shen, Fei Liu, Fuliang Weng, and Tao Li.
2013.A participant-based approach for event summariza-tion using twitter streams.
In Proceedings of the49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies - Volume 1, HLT ?13, Stroudsburg, PA, USA.Association for Computational Linguistics.Dingding Wang, Shenghuo Zhu, Tao Li, and YihongGong.
2009.
Multi-document summarization us-ing sentence-based topic models.
In Proceedingsof the ACL-IJCNLP 2009 Conference Short Papers,ACLShort ?09, pages 297?300, Stroudsburg, PA,USA.
Association for Computational Linguistics.Xin Zhao, Baihan Shu, Jing Jiang, Yang Song, HongfeiYan, and Xiaoming Li.
2012.
Identifying event-related bursts via social media activities.
In Pro-ceedings of the 2012 Joint Conference on Empiri-cal Methods in Natural Language Processing andComputational Natural Language Learning, pages1466?1477, Jeju Island, Korea, July.
Association forComputational Linguistics.624
