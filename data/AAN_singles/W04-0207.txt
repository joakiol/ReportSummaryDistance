Text Type Structure and Logical Document StructureHagen LangerJustus-Liebig-Universita?t/Universita?t Osnabru?ckhagen.langer@web.deHarald Lu?ngenJustus-Liebig-Universita?tGie?en, Germanyluengen@uni-giessen.dePetra Saskia BayerlJustus-Liebig-Universita?tGie?en, Germanybayerl@uni-giessen.deAbstractMost research on automated categorization of doc-uments has concentrated on the assignment of oneor many categories to a whole text.
However, newapplications, e.g.
in the area of the Semantic Web,require a richer and more fine-grained annotationof documents, such as detailed thematic informa-tion about the parts of a document.
Hence we in-vestigate the automatic categorization of text seg-ments of scientific articles with XML markup into16 topic types from a text type structure schema.
Acorpus of 47 linguistic articles was provided withXML markup on different annotation layers repre-senting text type structure, logical document struc-ture, and grammatical categories.
Six different fea-ture extraction strategies were applied to this corpusand combined in various parametrizations in differ-ent classifiers.
The aim was to explore the contribu-tion of each type of information, in particular thelogical structure features, to the classification ac-curacy.
The results suggest that some of the topictypes of our hierarchy are successfully learnable,while the features from the logical structure layerhad no particular impact on the results.1 IntroductionOur project Semantics of Generic Document Struc-tures is concerned with the text type structure of sci-entific articles and its relations to document gram-mars and markup.
One of its goals is to explorethe feasibility of an automatic categorization oftext segments of scientific articles which are an-notated with logical structure tags (e.g.
section,paragraph, appendix) into topic types such asbackground, researchTopic, method, and results de-fined in a hierarchical text type schema.
The schemarepresenting the text type structure (or, thematicstructure) of scientific articles is shown in Figure1 (explained more fully in section 2).
It is as-sumed that authors to some degree adhere to sucha schema when creating a logical structure for theirdocuments for instance by XML markup, and thattherefore such markup bears clues as to the thematicstructure of scientific articles.contentevidencebackground framework method_evdproblem answerstheory_frmconceptsframework_Rmethod_evd_Rdata dataCollectiondataAnalysisresults interpretationconclusionstextualresearchTopicrationaleothersWorkbackground_RresourceFigure 1: Text type schemaAutomatic document classification is an ad-vanced field within computational linguistics withmany practical applications and has yielded awealth of standard methods and tools over the past10 years.
Many systems have been developed onthe Reuters-21578 corpus containing 21578 Englishnewpaper articles manually categorized into 135topic categories, e.g.
(Zu et al, 2003).
Besidesnewspaper articles, some approaches have treatedthe automatic categorization of (HTML) hypertextsavailable on the W3 into universal text topic setssuch as the ones used in the LookSmart and Yahooweb directories (Dumais and Chen, 2000).
An ap-proach that focuses solely on research papers isCiteSeer (Giles et al, 1998), the online digital li-brary of scientific articles that can be navigated viacitation indices.
Though the focus of CiteSeer ison the citation indices, it also provides a classifica-tion of articles from computer science into the hi-erarchically ordered topic set of its computer sci-ence directory.
The bag-of-words model of docu-ment representation still prevails in automatic textcategorization, but the advent of XML calls for ex-tending this model to include logical structure fea-tures in the vector space.
Yi and Sundaresan (2000)have developed a so-called semi-structured classi-fier for semi-structured documents (e.g.
XML doc-uments) based on a document representation thatcombines terms with path expressions.
This clas-sifier was shown to reduce classification error ratesconsiderably in comparison with a purely term-based classifier when run on US patent documentsprovided with XML markup and re?sume?
documentsin HTML.
Our aim is to explore similar methods toclassify thematic segments of scientific articles inXML.2 Text type ontology for scientific articlesPrevious approaches to the text type structure of sci-entific articles have been developed in the context ofautomatic text summarization.
In Teufel and Moens(2002), a categorization scheme of seven ?rhetori-cal zones?
including background, other, own, aim,textual, contrast, basis is used for the classificationof the sentences of a scientific article according totheir rhetorical status and subsequently finding themost suitable ones for a summary.
The schema weemploy (see below) is more fine-grained, consist-ing of 16 categories that are hierarchically ordered(although in the present experiments we did notmake use of this hierarchical order).
These 16 cat-egories refer to the dimension that is discussed un-der problem structure in (Teufel and Moens, 2002),rather than to exclusively rhetorical zones and areviewed as types of topics.
A topic ?is the semantic-pragmatic function that selects which concept of thecontextual information will be extended with newinformation?
(van Dijk, 1980, p.97).
Thus whilethe concept The daily newspaper Neue Zu?rcherZeitung is the topic of several sentences in the ar-ticle Bu?hlmann (2002), it is an instance of the topictype ?data?
which in turn is part of the text typestructure of many scientific articles.
This text typestructure is captured in our text type schema with16 bottom-level topic types (Figure 1) that were ob-tained by evaluating articles from the disciplines oflinguistics and psychology.
Kando (1997) presenteda similar hierarchical schema with 51 bottom-levelcategories, which were employed for manually an-notating sentences in Japanese scientific articles.Her ?text constituents?
resemble our topic types, butwe have aimed at sorting out functional categoriessuch as ?Reason for...?, including only purely the-matic categories and keeping the number of cate-gories lower for the experiments described in thispaper.In Figure 1, the arcs represent the part-of rela-tion such that a type lower in the hierarchy is a partof the immediately dominating, more general typein terms of text type structure.
The schema is sup-posed to represent the typical thematic structure ofresearch papers.
The order of the categories repre-sents a canonical, expected order of topic types in ascientific article.
The text type schema was initiallyencoded as an XML Schema grammar where topictypes are represented by elements that are nestedsuch that the XML structure reflects the structureof the text type structure tree (Figure 2).<xs:element name="problem"><xs:complexType><xs:sequence><xs:element name="background" minOccurs="0"><xs:complexType><xs:sequence><xs:element name="othersWork"type="xs:string"minOccurs="0"/><xs:element name="background_R"type="xs:string"minOccurs="0"/></xs:sequence></xs:complexType></xs:element>...Figure 2: XML Schema grammar (extract) for thetext type schema3 Data and annotation levelsWe carried out the experiments on a corpus of 47linguistic research articles, taken from the Germanonline journal ?Linguistik Online?,1 from the vol-umes 2000-2003.
The selected articles came withHTML markup and have an average length of 8639word forms, dealing with subjects as diverse asthe syntax of adverbs, chat analysis, and languagelearning.Taking a text-technological approach, this cor-pus was prepared such that all required types of in-formation, including the target classification cate-gories and the classification features to be extracted,are realized as XML annotations of the raw text.Thus, XML markup was provided for the thematiclevel, a logical structure level, and a grammaticallevel.
As described in Bayerl et al (2003), anno-tation levels are distinguished from annotation lay-ers.
An annotation level is an abstract level of infor-mation (such as the morphology and syntax levelsin linguistics), originally independent of any anno-tation scheme.
The term annotation layer, in con-trast, refers to the realization of an annotation levelas e.g.
XML markup.
There need not be a 1:1-correspondence between annotation levels and lay-ers.
As for the three annotation levels in our setting,1http://www.linguistik-online.de/one (the structural level) was realized as an inde-pendent layer, and two (thematic and grammatical)were realized in one single annotation layer.
Eachannotation layer of an article is stored in a separatefile, while it is ensured that the PCDATA of eachlayer are identical.3.1 Annotation of text type structureThe order of topic types in a specific scientific ar-ticle may deviate from the canonical order repre-sented in the XML schema grammar of the text typestructure shown in Figure 2.
Thus a flat version ofthe hierarchical XML schema was derived by meansof an XSLT style sheet, exploiting the fact that XMLschema grammars, unlike DTDs, are XML docu-ments themselves.
In the derived flat XML schema,topic types are represented as attribute values of el-ements called <group> and <segment>, insteadof names of nested elements.
Empty <group> el-ements represent topic types that corresponded tothe nodes in the original tree of topic types, while<segment> elements correspond to leaves (termi-nal categories).
The original hierarchical structureis still represented via the ID/IDREF attributes idand parent, similar to O?Donnell?s (2000) repre-sentation of rhetorical structure trees.For the annotation, the raw text of each arti-cle was automatically partitioned into text segmentscorresponding to sentences, but the annotators wereallowed to modify (join or split) segments to yieldproper thematic units.
The problem of finding the-matic boundaries other than sentence boundariesautomatically (e.g.
Utiyama and Isahara (2001)) isthus not addressed in this work.
The annotator thenprovided the values of the attribute topic usingthe XML spy editor, choosing exactly one of the16 terminal topic types for each segment, or alter-natively the category void meta for metadata suchas acknowledgements.
If more than one topic typecould in principle be assigned, the annotators wereinstructed to choose the one that was most central tothe argumentation.
An extract from a THM annota-tion layer is shown in Figure 3.2The two annotators were experienced in that theyhad received intense training as well as annotateda corpus of psychological articles according to anextended version of the schema in Figure 1 earlier(Bayerl et al, 2003).
We assessed inter-rater reli-ability on three articles from the present linguisticscorpus, which were annotated by both annotators in-dependently according to the topic type set shownin Figure 1.
(Prior to the analysis the articles were2The extract, which is also shown in Figure 4, is taken fromBu?hlmann (2002).<segment id="s75a" parent="g19"topic="dataAnalysis">Die obige Reihenfolge vera?ndert sich etwas,wenn nicht die gesamte Anzahl derPersonenbezeichnungen ausschlaggebend ist,sondern die Anzahl unterschiedlicherPersonenbezeichnungen (das heisst, einePersonenbezeichnung wie z.B.
Jugendliche,die acht Mal verwendet wurde, wird trotzdemnur einmal geza?hlt):</segment><segment id="s76" parent="g4" topic="results">Im ganzen kommen in den untersuchten Artikel261 verschiedene Personenbezeichnungen vor.Davon sind u?ber 46,7% generische Maskulina,und nur 31% sind Institutions- undKollektivbezeichnungen.
Es folgen diegeschlechtsneutralen und -abstraktenBezeichnungen mit 18,4%, und nach wie vorstehen die Doppelformen mit 3,8% Bezeichnungenam Schluss.</segment>Figure 3: THM annotation (extract)resegmented manually so that segment boundarieswere completely identical.)
An average agreementof Kappa = 0.73 was reached (min: .63, max: .78),which can be interpreted as ?substantial?
agreement(Landis and Koch, 1977).
In order to test for anno-tation biases we also performed a Stuart-MaxwellTest (Stuart, 1955; Maxwell, 1970), leading to theconclusion that marginal homogeneity must be re-jected on the 1% level (?2 = 61.24; df = 14).
TheMcNemar Tests (McNemar, 1947) revealed that thetopic types textual, results, interpretation, others-Work, and conclusions were the problematic cate-gories.
Subsequent log-linear analyses revealed thatannotator1 systematically had assigned backgroundwhere annotator2 had assigned framework.
Alsointerpretation was regularly confused with conclu-sions, and concepts with either background or oth-ersWork (model-fit: ?2 = 173.14, df = 155, p =.15).3.2 Annotation of syntax and morphologyFor an annotation of grammatical categories to wordform tokens in our corpus, the commercial taggerMachinese Syntax by Connexor Oy was employed.This tagger is a rule-based, robust syntactic parseravailable for several languages and based on Con-straint Grammar and Functional Dependency Gram-mar (Tapanainen and Ja?rvinen, 1997).
It providesmorphological, surface syntactic, and functionaltags for each word form and a dependency struc-ture for sentences, and besides is able to processand output ?simple?
XML (that is, XML withoutattributes).
No conflicts in terms of element over-laps can arise between our THM annotation layerand the grammatical tagging, because all tags pro-vided by Machinese Syntax pertain to word forms.The grammatical annotations could therefore be in-tegrated with the THM annotations, forming theXML annotation layer that we call THMCNX.
AnXSLT stylesheet is applied to convert the THMannotations into attribute-free XML by integratingthe information from attribute-value specificationsinto the names of their respective elements.
Af-ter the grammatical tagging, a second stylesheetre-converts the resulting attribute-free XML repre-sentations into the original complex XML enrichedby the grammatical tags.
Besides, we re-formattedthe original Machinese Syntax tags by omitting,merging, and renaming some of them, again usingXSLT.
The <cmp-head-lemma> tag (containingthe lemma of the head of the present word form), forexample, was derived from the original <lemma>tag, the value of which contains compound segmen-tation information.
On the THMCNX layer, a sub-set of 15 grammatical tags may appear at each wordform, including <pos> (part of speech), <aux>(auxiliary verb), and <num> (number feature fornominal categories).3.3 Logical document structure annotationSince HTML is a hybrid markup language includinga mixture of structural and layout information, wechose to convert the original HTML of the corpusinto XML based on the DocBook standard (Walshand Muellner, 1999).
DocBook was originally de-signed for technical documentation and represents apurely logical document structure, relying on stylesheets to interpret the logical elements to produce adesired layout.
We did not employ the whole, verylarge official DocBook DTD, but designed a newXML schema that defines a subset with 45 Doc-Book elements plus 13 additional logical elementssuch as tablefootnote and numexample, whichappear in the annotations after the namespace pre-fix log.3 The annotations were obtained using aperl script that provided raw DocBook annotationsfrom the HTML markup, and the XML spy editorfor validation and manually filling in elements thathave no correspondences in HTML.
Figure 4 showsthe DocBook annotation of the extract that was alsogiven in Figure 3.Moreover, structural position attributes wereadded to each element by means of an XSLT stylesheet.
These ?POSINFO?
attributes make explicit theposition of the element in the XML DOM tree of3This XML schema was designed in collaborationwith the HyTex project at the University of Dortmund,http://www.hytex.info<sect2>...<log:figure><log:mediaobject><xhtml:img src="buehlmann20.gif"/></log:mediaobject></log:figure><para>Die obige Reihenfolge vera?ndert sichetwas, wenn nicht die gesamte Anzahl derPersonenbezeichnungen ausschlaggebend ist,sondern die Anzahl unterschiedlicherPersonenbezeichnungen (das heisst, einePersonenbezeichnung wie z.B.
Jugendliche, dieacht Mal verwendet wurde, wird trotzdem nureinmal geza?hlt): Im ganzen kommen in denuntersuchten Artikel 261 verschiedenePersonenbezeichnungen vor.
Davon sind u?ber46,7% generische Maskulina, und nur 31% sindInstitutions- und Kollektivbezeichnungen.
Esfolgen die geschlechtsneutralen und-abstrakten Bezeichnungen mit 18,4%, undnach wie vor stehen die Doppelformen mit3,8% Bezeichnungen am Schluss....</para>...</sect2>Figure 4: Annotation according to DocBook (ex-tract)the document instance in an XPATH-expression asshown in Figure 5.<para POSINFO1="/article[1]/sect1[4]/sect2[1]/para[10]">Die obige Reihenfolge vera?ndert sich etwas,...</para>Figure 5: Structural position path on the doc layerAs pointed out above, XML document structurehas been exploited formerly in the automatic classi-fication of complete documents, e.g.
in (Yi and Sun-daresan, 2000; Denoyer and Gallinari, 2003).
How-ever, we want to use XML document structure in theclassification of thematic segments of documents,where the thematic segments are XML elements inthe THM annotation layer.
The THM and DOClayers cannot necessarily be combined in a singlelayer, as we had refrained from imposing the con-straint that they always should be compatible, i.e.not contain overlaps.
Still we had to relate elementinstances on the DOC layer to element instances onthe THM layer.For this purpose, we resorted to the Prolog querytool seit.pl developed at the University of Biele-feld in the project Sekimo4 for the inference of re-4see (Goecke et al, 2003; Bayerl et al, 2003) andhttp://www.text-technology.de/lations between two annotation layers of the sametext.
seit.pl infers 13 mutually exclusive rela-tions between instances of element types on sep-arate annotation layers on account of their sharedPCDATA.
In view of the application we envisaged,we defined four general relations, one of which wasIdentity and three of which were defined by theunion of several more specific seit.pl relations:Identity: The original identity relation fromseit.pl.Included: Holds if a thematic segment is prop-erly included in a DocBook element in terms ofthe ranges of the respective PCDATA, i.e.
is de-fined as the union of the original seit.pl-relationsincluded A in B, starting point B and end point B.This relation was considered to be significant be-cause we would for example expect THM segmentsannotated with the topic type interpretation to ap-pear within /article[1]/sect1[5] rather than/article[1]/sect1[1] elements (i.e.
the fifthrather than the first sect1 element).Includes: Holds if a thematic segment prop-erly includes a DocBook element in terms of theranges of the respective PCDATA, i.e.
is definedas the union of the original seit.pl relations in-cluded B in A, starting point A, end point A. Thisrelation was considered to be significant because wewould for example expect logical elements such asnumexample to be included preferably in segmentslabelled with the topic type data.Overlap: Holds if a thematic segment prop-erly overlaps with a DocBook element in terms ofthe ranges of the respective PCDATA.
This relationwas considered less significant because the overlap-ping portion of PCDATA might be very small andseit.pl so far does not allow for querying howlarge the overlapping portion actually is.The Prolog code of seit.pl was modified suchthat it outputs XML files that contain the THM an-notation layer including structural positions fromthe DOC layer within each segment as values of el-ements that indicate the relation found, cf.
Figure6.4 Automatic text segment classificationexperimentsWe applied different classification models, namely aKNN classifier (cf.
section 4.1) and, for purposes ofcomparison, a simplified Rocchio classifier to textsegments, in order to evaluate the feasibility of anautomatic annotation of scientific articles accordingto our THM annotation layer.
One important moti-vation for these experiments was to find out whichkind of data representation yields the best classifi-cation accuracy, and particularly, if the combinationof complementary information sources, such as bag-of-words representations of text, on the one hand,and the structural information provided by the Doc-Book path annotations, on the other hand, producesadditional synergetic effects.4.1 KNN classificationThe basic idea of the K nearest neighbor (KNN)classification algorithm is to use already categorizedexamples from a training set in order to assign a cat-egory to a new object.
The first step is to choose theK nearest neighbors (i.e.
the K most similar objectsaccording to some similarity metric, such as cosine)from the trainings set.
In a second step the cate-gorial information of the nearest neighbors is com-bined, in the simplest case, by determining the ma-jority class.The version of KNN classification, adoptedhere, uses the Jensen-Shannon divergence (alsoknown as information radius or iRad) as a(dis-)similarity metric:iRad(q, r) = 12 [D(q?q+r2 ) + D(r?q+r2 )]D(x?y) is the Kullback-Leibler divergence (KLdivergence) of probability distributions x and y:D(x?y) =n?i=1x(i)(log(x(i)) ?
log(y(i)))iRad ranges from 0 (identity) to 2log2 (no simi-larity) and requires that the compared objects areprobability distributions.Let NO,C = {n1, .
.
.
, nm} (0 ?
m ?
K) bethe set of those objects among the K nearestneighbors of some new object O that belong to aparticular category C. Then the score assigned tothe classification O ?
C isscore(O,C) =m?j=1iRad(O,nj)E .Depending on the choice of E, one yields eithera simple majority decision (if E = 0), a linearweighting of the iRad similarity (if E = 1), or astronger emphasis on closer training examples (ifE > 1).
Actually, it turned out that very high valuesof E improved the classification accuracy.
Finally,the KNN scores for each segment were normalizedto probability distributions, in order to get compa-rable results for different K and E, when the KNNclassifications get combined with the bigram model.<segment id="s75a" topic="dataCollection"><included>/article[1]</included><included>/article[1]/sect1[4]</included><included>/article[1]/sect1[4]/sect2[1]</included><includes>/article[1]/sect1[4]/sect2[1]/log:figure[5]</includes><includes>/article[1]/sect1[4]/sect2[1]/log:figure[5]/log:mediaobject[1]</includes><includes>/article[1]/sect1[4]/sect2[1]/log:figure[5]/log:mediaobject[1]/xhtml:img[1]</includes><included>/article[1]/sect1[4]/sect2[1]/para[10]</included><text>Die obige Reihenfolge vera?ndert sich etwas, wenn nicht die gesamte Anzahlder Personenbezeichnungen...</text></segment><segment id="s76" topic="results"><included>/article[1]</included><included>/article[1]/sect1[4]</included><included>/article[1]/sect1[4]/sect2[1]</included><included>/article[1]/sect1[4]/sect2[1]/para[10]</included><text>Im ganzen kommen in den untersuchten Artikel 261 verschiedene Personenbezeichnungen vor.Davon sind ...</text></segment>Figure 6: Generated THMDOC layer4.2 Bigram modelThe bigram model gives the conditional probabilityof a topic type Tn+1, given its predecessor Tn.For a sequence of segments s1 .
.
.
sm the totalscore ?
(T, si) for the assignment of a topic type T tosi is the product of bigram probability, given the pu-tative predecessor topic type (i.e.
the topic type T ?with the highest ?
(T ?, si?1) computed in the pre-vious step), and the normalized score of the KNNclassifier.
The total score of the topic type sequenceis the product of its ?
scores.4.3 Information sourcesIn our classification experiments we used six differ-ent representations which can be viewed as differentfeature extraction strategies or different levels of ab-straction:?
word forms (wf): a bag-of-words represen-tation of the segment without morphologi-cal analysis; special characters (punctuation,braces, etc.)
are treated as words.?
compound heads (ch): stems; in case of com-pounds, the head is used instead of the wholecompound.
These features were extracted fromthe THMCNX layer (cf.
section 3.2).?
size (sz): number of words per segment (calcu-lation based on the THM annotation layer, cf.section 3.1).?
DocBook paths (dbp): the segment is repre-sented as the set of the DocBook paths whichinclude it (the segment stand in the the In-cluded relation to it as explained in section3.3).?
selected DocBook features (df): a set of 6 Doc-Book features which indicate occurrences ofblock quotes, itemized lists, numbered exam-ples, ordered lists, tables, and references tofootnotes standing in any of the four relationslisted in section 3.2.?
POS tags (pos): the distribution of part-of-speech tags of the segment taken from theTHMCNX layer (cf.
section 3.2).4.4 Training and EvaluationFor each test document the bigram model and theclassifier were trained with all other documents.The overall size of the data collection was 47 docu-ments.
Thus, each classifier and each bigram modelhas been trained on the basis of 46 documents, re-spectively.
The total number of segments was 7330.4.5 ResultsWe performed several hundred classification testswith different combinations of data representation,classification algorithm, and classifier parametersetting.
Table 1 summarizes some results of theseexperiments.
The baseline (a ?classifier?
guessingalways the most frequent topic type) had an accu-racy of 22%.The best combination of data representation andclassifier setting achieved about 47% accuracy.
Inthis configuration we used a mixture of the com-pound head representation (40%), the POS tag dis-tribution (40%), the segment size (10%), and theselected DocBook features (10%).
However, thecombination of compound heads (50%) and part-of-speech tags (50%) and a similar combination in-classifier feature K E accuracy accuracyweights classifier classifier+ bigrammostfrequent - - - 22.4147 -KNN* ch 40%pos 40%sz 10%df 10% 20 40 56.9785 -Rocchio ch - - 39.0267 -KNN ch 30%pos 30%dbp 40% 20 40 41.1278 41.6294KNN wf 20 40 38.9725 41.6429KNN pos 20 40 40.5314 41.9005KNN ch 25 40 40.4094 42.8765KNN ch 50%pos 50% 50 40 44.8556 45.8859KNN ch 50%pos 50% 13 40 44.3270 46.6179KNN ch 49%pos 49%dbp 2% 20 40 44.8150 46.9296KNN ch 40%pos 40%sz 10%df 10% 20 40 45.5063 47.0788Table 1: Resultscluding a 2% portion of DocBook path structurefeatures had similar results.
In all experiments theKNN algorithm performed better than the simplifiedRocchio algorithm.
For illustrative purpose, we alsoincluded a configuration, where all other segments(i.e.
including those from the same document) wereavailable as training segments (?KNN*?
in the sec-ond line of table 1).The variation of classification accuracy was veryhigh both across the topic types and across the doc-uments.
In the best configuration of our classifica-tion experiments the average segment classificationaccuracy per document had a range from 22% to77%, reflecting the fact that the document collec-tion was very heterogeneous in many respects.
Thetopic type resource had an average recall of 97.56%and an average precision of 91.86%, while severalother topic types, e.g.
rationale and dataAnalysiswere near to zero both w.r.t.
precision and recall.The most frequent error was the incorrect assign-ment of topic type othersWork to segments of topictypes framework, concepts, and background.4.6 DiscussionThe task of classifying small text segments, as op-posed to whole documents, is a rather new ap-plication field for general domain-independent textcategorization methods.
Thus, we lack data fromprevious experiments to compare our own resultswith.
Nevertheless, there are some conclusions tobe drawn from our experiments.Although the results probably suffer from limita-tions of our data collection (small sample size, re-stricted thematic domain), our main conclusion isthat at least some of the topic types of our hierarchyare successfully learnable.
It is, however, question-able if an overall accuracy of less than 50% is suffi-cient for applications that require a high reliability.Moreover, it should be emphasized that our classifi-cation experiments were carried out on the basis ofmanually segmented input.The usage of structural information improved theaccuracy results slightly, but the impact of this infor-mation source was clearly below our expectations.The effect of adding this kind of information waswithin the range of improvements which can also beachieved by fine-tuning a classifier parameter, suchas K.A somewhat surprising result was that a purepart-of-speech tag representation achieved nearly42% accuracy in combination with the bigrammodel.The usage of a bigram model improved the resultsin almost all configurations.5 ConclusionThe best combination of data representation andclassifier configuration included ch (40%), pos(40%), sz (10%) and df (10%), combined with atopic type bigram model, which yielded an accu-racy of 47%.
However, almost the same accuracycould be achieved by selecting ch and pos featuresonly.
Other test runs showed that the dbp featurescould not improve the results in any combination,although these features are the ones that indicatewhere a segment is situated in an article.
An in-spection of data representations revealed that, for aparticular test document (i.e.
text segment), the ma-jority of training documents with an identical dpbrepresentation are often assigned the desired topictype, but this majority is so small that many othertest documents with identical dbp representation aremis-classified.
An accuracy improvement mighttherefore be achieved by running different (local)KNN classifiers trained on different feature sets andcombine their results afterwards.More future work will focus on the inspection ofcategories that have a very low precision and recall(such as rationale) with a possible review of the texttype ontology.
Furthermore, we aim at testing al-ternative algorithms (e.g.
support vector machines),feature selection methods and at enlarging our train-ing set.
Besides, we will investigate the question,inhowfar our results are generalizable to scientificarticles from other disciplines and languages.ReferencesPetra S. Bayerl, H. Lu?ngen, D. Goecke, A. Witt, andD.
Naber.
2003.
Methods for the semantic anal-ysis of document markup.
In Proceedings of theACM Symposium on Document Engineering (Do-cEng 2003).Regula Bu?hlmann.
2002.
Ehefrau Vrenihaucht ihm ins Ohr... Untersuchungenzur geschlechtergerechten Sprache und zurDarstellung von Frauen in DeutschschweizerTageszeitungen.
Linguistik Online, 11.http://www.linguistik-online.de.Ludovic Denoyer and Patrick Gallinari.
2003.
Us-ing belief networks and fisher kernels for struc-tured document classification.
In Proceedings ofthe 7th European Conference on Principles andPractices of Knowledge Discovery in Databases,Cavtat-Dubrovnik, Croatia.Susan T. Dumais and Hao Chen.
2000.
Hierarchi-cal classification of web content.
In Proceedingsof SIGIR-00, 23rd ACM International Conferenceon Research and Development in Information Re-trieval, pages 256?263, Athens, Greece.
ACMpress, New York.C.
Lee Giles, Kurt Bollacker, and Steve Lawrence.1998.
CiteSeer: An automatic citation index-ing system.
In Ian Witten, Rob Akscyn, andFrank M. Shipman III, editors, Digital Libraries98 - The Third ACM Conference on DigitalLibraries, pages 89?98, Pittsburgh, PA. ACMPress.Daniela Goecke, Daniel Naber, and Andreas Witt.2003.
Query von Multiebenen-annotierten XML-Dokumenten mit Prolog.
In Uta Seewald-Heeg,editor, Sprachtechnologie fu?r die multilin-guale Kommunikation.
Beitra?ge der GLDV-Fru?hjahrstagung, Ko?then 2003, volume 5 ofSprachwissenschaft Computerlinguistik NeueMedien, pages 391?405, Sankt Augustin.gardez!-Verlag.Noriko Kando.
1997.
Text-level structure of re-search papers: Implications for text-based infor-mation processing systems.
In Proceedings of theBritish Computer Society Annual Colloquium ofInformation Retrieval Research, pages 68?81.J.R.
Landis and G. G. Koch.
1977.
The measure-ment of observer agreement for categorical data.Biometrics, 33:159?174.A.
Maxwell.
1970.
Comparing the classification ofsubjects by two independent judges.
British Jour-nal of Psychiatry, 116:651 ?
655.Q.
McNemar.
1947.
Note on the sampling error ofthe difference between correlated proportions orpercentages.
Psychometrika, 12:153 ?
157.A Stuart.
1955.
A test for homogeneity of themarginal distributions in a two-way classifica-tion.
Biometrika, 42:412 ?
416.Pasi Tapanainen and Timo Ja?rvinen.
1997.
A non-projective dependency parser.
In Proceedings ofthe 5th Conference on Applied Natural LanguageProcessing, pages 64?71, Washington D.C. As-sociation for Computational Linguistics.Simone Teufel and Marc Moens.
2002.
Summariz-ing scientfic articles: Experiments with relevanceand rhetorical status.
Computational Linguistics,28(4):409?445.Masao Utiyama and Hitoshi Isahara.
2001.
A sta-tistical model for domain-independent text seg-mentation.
In Meeting of the Association forComputational Linguistics, pages 491?498.Teun A. van Dijk.
1980.
Macrostructures: An in-terdisciplinary study of global structures in dis-course, interaction, and cognition.
LawrenceErlbaum Associates, Hillsdale, New Jersey.Norman Walsh and Leonard Muellner.
1999.
Doc-Book: The Definitive Guide.
O?Reilly.Jeonghee Yi and Neel Sundaresan.
2000.
A classi-fier for semi-structured documents.
In Proceed-ings of the Conference on Knowledge Discoveryin Data, pages 190?197.Guowei Zu, Wataru Ohyama, Tetsushi Wak-abayashi, and Fumitaka Kimura.
2003.
Accu-racy improvement of automatic text classifica-tion based on feature transformation.
In ChristineVanoirbeek, C. Roisin, and Ethan Munson, edi-tors, Proceedings of the 2003 ACM Symposiumon Document Engineering - DocEng03, pages118?120, Grenoble, France.
