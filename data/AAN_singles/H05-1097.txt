Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 771?778, Vancouver, October 2005. c?2005 Association for Computational LinguisticsWord-Sense Disambiguation for Machine TranslationDavid Vickrey Luke Biewald Marc Teyssier Daphne KollerDepartment of Computer ScienceStanford UniversityStanford, CA 94305-9010{dvickrey,lukeb,teyssier,koller}@cs.stanford.eduAbstractIn word sense disambiguation, a system attempts todetermine the sense of a word from contextual fea-tures.
Major barriers to building a high-performingword sense disambiguation system include the dif-ficulty of labeling data for this task and of pre-dicting fine-grained sense distinctions.
These is-sues stem partly from the fact that the task is be-ing treated in isolation from possible uses of au-tomatically disambiguated data.
In this paper, weconsider the related task of word translation, wherewe wish to determine the correct translation of aword from context.
We can use parallel languagecorpora as a large supply of partially labeled datafor this task.
We present algorithms for solving theword translation problem and demonstrate a signif-icant improvement over a baseline system.
We thenshow that the word-translation system can be usedto improve performance on a simplified machine-translation task and can effectively and accuratelyprune the set of candidate translations for a word.1 IntroductionThe problem of distinguishing between multiplepossible senses of a word is an important subtask inmany NLP applications.
However, despite its con-ceptual simplicity, and its obvious formulation as astandard classification problem, achieving high lev-els of performance on this task has been a remark-ably elusive goal.In its standard formulation, the disambiguationtask is specified via an ontology defining the dif-ferent senses of ambiguous words.
In the Sense-val competition, for example, WordNet (Fellbaum,1998) is used to define this ontology.
However, on-tologies such as WordNet are not ideally suited tothe task of word-sense disambiguation.
In manycases, WordNet is overly ?specific?, defining senseswhich are very similar and hard to distinguish.
Forexample, there are seven definitions of ?respect?as a noun (including closely related senses such as?an attitude of admiration or esteem?
and ?a feel-ing of friendship and esteem?
); there are even morewhen the verb definitions are included as well.
Suchclosely related senses pose a challenge both for auto-matic disambiguation and hand labeling.
Moreover,the use of a very fine-grained set of senses, most ofwhich are quite rare in practice, makes it very diffi-cult to obtain sufficient amounts of training data.These issues are clearly reflected in the perfor-mance of current word-sense disambiguation sys-tems.
When given a large amount of training datafor a particular word with reasonably clear sensedistinctions, existing systems perform fairly well.However, for the ?all-words?
task, where all am-biguous words from a test corpus must be disam-biguated, it has so far proved difficult to perform sig-nificantly better than the baseline heuristic of choos-ing the most common sense for each word.1In this paper, we address a different formulationof the word-sense disambiguation task.
Rather thanconsidering this task on its own, we consider a taskof disambiguating words for the purpose of somelarger goal.
Perhaps the most direct and compellingapplication of a word-sense disambiguator is to ma-chine translation.
If we knew the correct seman-tic meaning of each word in the source language,we could more accurately determine the appropriatewords in the target language.
Importantly, for thisapplication, subtle shades of meaning will often beirrelevant in choosing the most appropriate words inthe target language, as closely related senses of asingle word in one language are often encoded by asingle word in another.
In the context of this largergoal, we can focus only on sense distinctions that ahuman would consider when choosing the transla-tion of a word in the source language.We therefore consider the task of word-sense dis-ambiguation for the purpose of machine translation.Rather than predicting the sense of a particular worda, we predict the possible translations of a into the1See, for example, results of Senseval-3, available athttp://www.senseval.org/senseval3771target language.
We both train and evaluate the sys-tem on this task.
This formulation of the word-sensedisambiguation task, which we refer to as wordtranslation, has multiple advantages.
First, a verylarge amount of ?partially-labeled?
data is availablefor this task in the form of bilingual corpora (whichexist for a wide range of languages).
Second, the?labeling?
of these corpora (that is, translation fromone language to another), is a task at which humansare quite proficient and which does not generally re-quire the labeler (translator) to make difficult dis-tinctions between fine shades of meaning.In the remainder of this paper, we first discusshow training data for this task can be acquired au-tomatically from bilingual corpora.
We apply astandard learning algorithm for word-sense disam-biguation to the word translation task, with severalmodifications which proved useful for this task.Wepresent the results of our algorithm on word trans-lation, showing that it significantly improves perfor-mance on this task.
We also consider two simplemethods for incorporating word translation into ma-chine translation.
First, we can use the output ofour model to help a translation model choose betterwords; since general translation is a very noisy pro-cess, we present results on a simplified translationtask.
Second, we show that the output of our modelcan be used to prune candidate word sets for trans-lation; this could be used to significantly speed upcurrent translation systems.2 Machine TranslationIn machine translation, we wish to translate a sen-tence s in our source language into t in our targetlanguage.
The standard approach to statistical ma-chine translation uses the source-channel model ,argmaxtP (t|s) = argmaxtP (t)P (s|t),where P (t) is the language model for the target lan-guage, and P (s|t) is an alignment model from thetarget language to the source language.
Togetherthey define a generative model for the source/targetpair (s, t): first t is generated according to the lan-guage model P (t); then s is generated from t ac-cording to P (s|t).2Typically, strong independence assumptions arethen made about the distribution P (s|t).
For ex-ample, in the IBM Models (Brown et al, 1993),each word ti independently generates 0, 1, or more2Note that we refer to t as the target sentence, even though inthe source-channel model, t is the source sentence which goesthrough the channel model P (s|t) to produce the observed sen-tence s.words in the source language.
Thus, the words gen-erated by ti are independent of the words generatedby tj for each j 6= i.
This means that correla-tions between words in the source sentence are notcaptured by P (s|t), and so the context we will usein our word translation models to predict ti givensi is not available to a system making these inde-pendence assumptions.
In this type of system, se-mantic and syntactic relationships between wordsare only modeled in the target language; most orall of the semantic and syntactic information con-tained in the source sentence is ignored.
The lan-guage model P (t) does introduce some context-dependencies, but the standard n-gram model usedin machine translation is too weak to provide a rea-sonable solution to the strong independence assump-tions made by the alignment model.3 Task FormulationWe define the word translation task as finding, foran individual word a in the source language S , thecorrect translation, either a word or phrase, in thetarget language T .
Clearly, there are cases wherea is part of a multi-word phrase that needs to betranslated as a unit.
Our approach could be extendedby preprocessing the data in S to find phrases, andthen executing the entire algorithm treating phrasesas atomic units.
We do not explore this extension inthis paper, instead focusing on the word-to-phrasetranslation problem.As we discussed, a key advantage of the wordtranslation vs. word sense disambiguation is theavailability of large amounts of training data.
Thisdata is in the form of bilingual corpora, such asthe European Parliament proceedings3 .
Such doc-uments provide many training instances, where aword in one language is translated into another.However, the data is only partially labeled in thatwe are not given a word-to-word alignment betweenthe two languages, and thus we do not know whatevery word in the source language S translates to inthe target language T .
While sentence-to-sentencealignment is a fairly easy task, word-to-word align-ment is considerably more difficult.
To obtain word-to-word alignments, we used GIZA++4, an imple-mentation of the IBM Models (specifically, we usedthe output of IBM Model 4).
We did not performstemming on either language, so as to preserve suf-fix information for our word translation system andthe machine translation language model.Let DS be the set of sentences in the source lan-3Available at http://www.isi.edu/ koehn/4Available at http://www.isi.edu/ och/GIZA++.html772French (frequency) Translationmonte?e(51) going uple`ve(10), lever(17) standing uphausse(58), augmenter(37), increase(number)augmentation(150)interviens(53) to rise to speaknaissance(21), source(10) to be created, arisesouleve?
(10) raising an issueTable 1: Aligned translations for ?rise?
occurring atleast 10 times in the corpusguage and DT the set of target language sentences.The alignment algorithm can be run in either di-rection.
When run in the S ?
T direction, the al-gorithm aligns each word in t to at most one wordin s. Consider some source sentence s that containsthe word a, and let Ua,s?t = b1, .
.
.
, bk be the setof words that align to a in the aligned sentence t. Ingeneral, we can consider Ua = {Ua,s?t}s?Da to bethe candidate set of translations for a in T , whereDa is the set of source language sentences contain-ing a.
However, this definition is quite noisy: a wordbi might have been aligned with a arbitrarily; or, bimight be a word that itself corresponds to a multi-word translation in S .
Thus, we also align the sen-tences in the T ?
S direction, and require that eachbi in the phrase aligns either with a or with nothing.As this process is still fairly noisy, we only considera word or phrase b ?
Ua to be a candidate translationfor a if it occurs some minimum number of times inthe data.For example, Table 1 shows a possible candidateset for the English word ?rise?, with French as thetarget language.
Note that this set can contain notonly target words corresponding to different mean-ings of ?rise?
(the rows in the table) but also wordswhich correspond to different grammatical forms inthe target language corresponding to different partsof speech, verb tenses, etc.
So, disambiguation inthis case is both over senses and grammatical forms.The final result of our processing of the corpus is,for each source word a, a set of target words/phrasesUa; and a set of sentences Da where, in each sen-tence, a is aligned to some b ?
Ua.
For any sen-tence s ?
Da, aligned to some target sentence t,let ua,s ?
Ua be the word or phrase in t alignedwith a.
We can now treat this set of sentences asa fully-labeled corpus, which can be split into a setused for learning the word-translation model and atest set used for evaluating its performance.We note, however, that there is a limitation to us-ing accuracy on the test set for evaluating the perfor-mance of the algorithm.
A source word a in a givencontext may have two equally good, interchangeabletranslations into the target language.
Our evaluationmetric only rewards the algorithm for selecting thetarget word/phrase that happened to be used in theactual translation.
Thus, accuracies measured us-ing this metric may be artificially low.
This is acommon problem with evaluating machine transla-tion systems.Another issue is that we take as ground truth thealignments produced by GIZA++.
This has two im-plications: first, our training data may be noisy sincesome alignments may be incorrect; and second, ourtest data may not be completely accurate.
As men-tioned above, we only consider possible translationswhich occur some minimum number of times; thisremoves many of the mistakes made by GIZA++.Even if the test set is not 100% reliable, though, im-provement over baseline performance is indicativeof the potential of a method.4 Word Translation AlgorithmsThe word translation task and the word-sense dis-ambiguation task have the same form: each word ais associated with a set of possible labels Ua; givena sentence s containing word a, we must determinewhich of the possible labels in Ua to assign to a inthe context s. The only difference in the two tasks isthe set Ua: for word translation it is the set of pos-sible translations of a, while for word sense disam-biguation it is the set of possible senses of a in someontology.
Thus, we may use any word sense disam-biguation algorithm as a word translation algorithmby appropriately defining the senses (assuming thatthe WSD algorithm does not assume that a particularontology is used to choose the senses).Our main focus in this paper is to show that ma-chine learning techniques are effective for the wordtranslation task, and to demonstrate that we can usethe output of our word translation system to im-prove performance on two machine-translation re-lated tasks.
We will therefore restrict our atten-tion to a relatively simple model, logistic regres-sion (Minka, 2000).
There are several motivationsfor using this discriminative, probabilistic model.First, it is known both theoretically and empirically(e.g., (Ng and Jordan, 2002)) that discriminativemodels achieve higher accuracies than generativemodels if enough data is available.
For the tradi-tional word-sense disambiguation task, data must behand-labeled, and is therefore often too scarce to al-low for discriminative training.
In our setting, how-ever, training data is acquired automatically frombilingual corpora, which are widely available andquite large.
Thus, discriminative training is a viableoption for the word translation problem.
A second773consideration is that, to effectively incorporate oursystem into a statistical machine translation system,we would like to produce not just a single prediction,but a list of confidence-rated possibilities.
The op-timization procedure of logistic regression attemptsto produce a distribution over possible translationswhich accurately represents the confidence of themodel for each translation.
By contrast, a classicalNaive Bayes model often assigns very low proba-bilities to all but the most likely translation.
Otherword-sense disambiguation models may not produceconfidence measures at all.Features.
Our word translation model for a worda in a sentence s = w1, .
.
.
, wk is based on featuresconstructed from the word and its context within thesentence.
Our basic logistic regression model usesthe following features, which correspond to the fea-ture space for a standard Naive Bayes model:?
the part of speech of a (generated using theBrill tagger)5;?
a binary ?occurs?
variable for each word whichis 1 if that word is in a fixed context centeredat a (cr words to the right and cl words to theleft), and 0 otherwise.We also consider an extension to this model, whereinstead of the fixed context features above, we use:?
for each direction d ?
{l, r} and each possi-ble context size cd ?
{1, ..., Cd}, an ?occurs?variable for each word.This is a true generalization of the previous con-text features, since it contains features for all pos-sible context sizes, not just one particular fixed size.This feature set is equivalent to having one featurefor each word in each context position, except thatit will have a different prior over parameters understandard L2 regularization.
This feature set alowsour model to distinguish between very local (oftensyntactic) features and somewhat longer range fea-tures whose exact position is not as important.Let ?a,s be the set of features for word a to betranslated, with sentence context s (the descriptionof the model does not depend on the particular fea-ture set selected).Model.
The logistic regression model encodes theconditional distribution (P (ua,s = b | a, s) : b ?Ua).
Such a model is parameterized by a set of vec-tors ?ab , one for each word a and each possible targetb ?
Ua, where each vector contains a weight ?ab,j foreach feature ?a,sj .
We can now define our conditionaldistribution:5Available at http://www.cs.jhu.edu/ brill/P?a(b | a, s) =1Za,se?ab?a,swith partition function Za,s =?b?
?Ua exp(?ab??a,s).Training.
We train the logistic regression model tomaximize the conditional likelihood of the observedlabels given the features in our training set.
Thus,our goal in training the model for a is to maximize?s?DaP?a(ua,s | a, s).We maximize this objective by maximizing its log-arithm (the log-conditional-likelihood) using conju-gate gradient ascent (Shewchuk, 1994).One important consideration when training usingmaximum likelihood is regularization of the param-eters.
In the case of logistic regression, the mostcommon type of regularization is L2 regularization;we then maximize?b,jexp(?
(?ab,j)22?2)?s?DaP?a(ua,s | a, s).This penalizes the likelihood for the distance of eachparameter ?ab,j from 0; it corresponds to a Gaussianprior on each parameter with variance ?2.5 Word Translation ResultsFor our word translation experiments we used theEuropean Parliament proceedings corpus, whichcontains approximately 27 million words in each ofEnglish and French (as well as a number of otherlanguages).
We tested on a set of 1859 ambigu-ous words ?
specifically, all ambiguous words con-tained in the first document of the corpus.
For eachof these words, we found all instances of the word inthe corpus and split these instances into training andtest sets.We tested four different models.
The first, Base-line, always chooses the most common translationfor the word; the second, Baseline with Part ofSpeech, uses tagger-generated parts of speech tochoose the most common translation for the ob-served word/part-of-speech pair.
The third model,Simple Logistic, is the logistic regression modelwith the simpler feature set, a context window of afixed size.
We selected the window size by eval-uating accuracy for a variety of window sizes on20 of the 1859 ambiguous words using a randomtrain-test split.
The window size which performedbest on average extended one word to the left and774Model Macro MicroBaseline 0.511 0.526Baseline with Part of Speech 0.519 0.532Simple Logistic 0.581 0.605Logistic 0.596 0.620Table 2: Average Word Translation Accuracytwo words to the right (larger windows generally re-sulted in overfitting).
The fourth model, Logistic, isthe logistic regression model with overlapping con-text windows; the maximum window size for thismodel was four words to the left and four words tothe right.
We selected the standard deviation ?2 forthe logistic models by trying different values on thesame small subset of the ambiguous words.
For theSimple Logistic model, the best value was ?2 = 1;for the Logistic model, it was 0.35.Table 2 shows results of these four models.
Thefirst column is macro-averaged over the 1859 words,that is, the accuracy for each word counts equallytowards the average.
The second column shows themicro-averaged accuracy, where each test examplecounts equally.
We will focus on the micro-averagedresults, since they correspond to overall accuracy.The less accurate of our two models, Simple Lo-gistic, improves around 8% over the simple baselineand 7% over the part-of-speech baseline on aver-age.
Our more complex logistic model, which is ableto handle larger context sizes without significantlyoverfitting, improves accuracy by another 1.5%.There was a great deal of variance from wordto word in the performance of our models relativeto baseline.
For a few words, we achieved verylarge increases in accuracy.
For instance, the noun?agenda?
showed a 31.2% increase over both base-lines.
Similarly, the word ?rise?
(either a nounor a verb) had part-of-speech baseline accuracy of27.9%.
Our model increased the accuracy to 57.0%.It is worth repeating that accuracies on this taskare artificially low since in many cases a single wordcan be translated to many different words with thesame meaning.
At the same time, accuracies are ar-tificially inflated by the fact that we only considerexamples where we can find an aligned word inthe French corpus, so translations where a word isdropped or translated as part of a compound wordare not counted.One disadvantage of the EuroParl corpus is that itis not ?balanced?
in terms of semantic content.
It isnot clear how this affects our results.6 Blank-Filling TaskOne of the most difficult parts of machine translationis decoding ?
finding the most likely translation ac-cording to some probability model.
The difficultyarises from the enormous number of possible trans-lated sentences.
Existing decoders generally use ei-ther highly pruned search or greedy heuristic search.In either case, the quality of a translation can varygreatly from sentence to sentence.
This variationis much higher than the improvement in ?seman-tic?
accuracy our model is attempting to achieve.Moreover, currently available decoders do not pro-vide a natural way to incorporate the results of aword translation system.
For example, Carpuat andWu (2005) obtain negative results for two methodsof incorporating the output of a word-sense disam-biguation system into a machine translation system.Thus, we instead used our word translation modelfor a simplified translation problem.
We prepared adataset as follows: for each occurrence of an am-biguous words in an English sentence in the firstdocument of the Europarl corpus, we tried to de-termine what the correct translation for that wordwas in the corresponding French sentence.
If wefound one and exactly one possible translation forthat word in the French sentence, we replaced thatword with a ?blank?, and linked the English wordto that blank.
The final result was a set of 655 sen-tences with a total of 3018 blanks.For example, the following English-French sen-tence pair contains the two ambiguous words ad-dress and issue and one possible translation for each,examiner and question:?
Therefore, the commission should address theissue once and for all.?
Par conse?quent, la commission devra enfin ex-aminer cette question particulie`re.We replace the translations of the ambiguous wordswith blanks; we would like a decoder to replace theblanks with the correct translations:?
Par conse?quent, la commission devra enfin [ad-dress] cette [issue] particulie`re.An advantage of this task is that, for a given distri-bution P (t|s), we can easily write a decoder whichexhaustively searches the entire solution space forthe best answer (provided that there are not too manyblanks and that P (t|s) is sufficiently ?local?
with re-spect to t).
Thus, we can be sure that it is the prob-ability model, and not the decoder, which is deter-mining the quality of the output.
Also, we have re-moved most or all syntactic variability from the task,775Model ?lm ?ga ?da ?wt AccLanguage Model only 1 0 0 0 0.749Source-Channel 1 1 0 0 0.821LM + GA + DA 1 0.6?
0.6?
0 0.833LM + GA + DA + WT 1 0.6?
0?
1.2?
0.846Table 3: Blank-filling results.
Weights marked with* have been optimized.allowing us to better gauge whether we are choosingsemantically correct translations.Let (ai, bi) be the pairs of words corresponding tothe blanks in sentence t. Then the alignment modeldecomposes as a product of terms over these pairs,e.g.
P (s|t) ?
?
(ai,bi) P (ai|bi).
Analogously, weextend the word translation model as Pwt(t|s) ??
(ai,bi) Pwt(bi|s, ai).The source-channel model can be used directlyto solve the blank filling task; the language modelmakes use of the French words surrounding eachblank, while the alignment model guesses the ap-propriate translation based on the aligned Englishword.
As we have mentioned, this model does nottake full advantage of the context in the English sen-tence.
Thus, we hope that incorporating the wordtranslation model into the decoder will improve per-formance on this task.Conversely, simply using the word translationmodel alone for the blank-filling task would not takeadvantage of the available French context.
Thereare four probability distributions we might considerusing: the language model Plm(t); the ?genera-tive?
alignment model Pga(s|t), which we calcu-late using the training samples from the previoussection; the analogous ?discriminative?
alignmentmodel Pda(t|s), which corresponds to the Base-line system we compared to on the word translationtask; and our overlapping context logistic model,Pwt(t|s), which also goes in the ?discriminative?
di-rection, but uses the context features in the sourcelanguage for determining the distribution over eachword?s possible translations.We combine these models by simply taking a log-linear combination:log P (t|s) ?
?lm logPlm(t) + ?ga log Pga(s|t)+ ?da logPda(t|s) + ?wt logPwt(t|s).The case of ?lm = ?ga = 1 and ?da = ?wt = 0 re-duces to the source-channel model; other settings in-corporate discriminative models to varying degrees.We evaluated this combined translation model onthe blank-filling task for various settings of the mix-ture coefficients ?.
For our language model we used0 0.5 1 1.500.20.40.60.811.21.41.61.82Generative CoefficientWordTranslationCoefficient0.770.790.810.830.830.840.840.8450.845Figure 1: Accuracy on blank-filling task with ?lm = 1 and?disc = 0 as a function of ?gen and ?wt.the CMU-Cambridge toolkit.6 The word translationmodel for each ambiguous word was trained on alldocuments except the first.Table 3 shows results for several sets of weights.A * denotes entries which we optimized (see be-low); other entries were fixed.
For example, the thirdmodel was obtained by fixing the coefficient of thelanguage model to 1 and the word-translation to 0,and optimizing the weights for the generative anddiscriminative alignment models.The language model alone is able to achieve rea-sonable results; adding the alignment models im-proves performance further.
By adding the word-translation model, we are able to improve perfor-mance by approximately 2.5% over the source-channel model, a relative error reduction of 14%,and 1.3% over the optimized model using thelanguage model and generative and discriminativealignment models, a relative error reduction of 7.8%.We chose optimal coefficients for the combinedprobability models by exhaustively trying all possi-ble settings of the weights, at a resolution of 0.1,evaluating accuracy for each one on the test set.
Fig-ure 1 shows the performance on the blank-fillingtask as a function of the weights of the generativealignment model and the word-translation model(the optimum value of the discriminative alignmentmodel P (t|s) is always 0 when we include theword-translation model).
As we can see, the per-formance of this model is robust with respect tothe exact value of the coefficients.
The ?obvious?setting of 1.0 for the generative model and 1.0 forthe word translation model performs nearly as well6Available at http://mi.eng.cam.ac.uk/ prc14/toolkit.html.776as the optimized setting.
In the optimal region,the word-translation model receives twice as muchweight as the generative alignment model, indicat-ing that word-translation model is more informativethan the generative alignment model.
Incorporatingthe discriminative alignment model into the source-channel model also improves performance, but notnearly as much as using the word-translation model.An alternate way to optimize weights over trans-lation features is described in Och and Ney (2002).They consider a number of translation features, in-cluding the language model and generative and dis-criminative alignment models.7 Search Space PruningAs we have mentioned, one of the main difficultiesin translation is that there are an enormous numberof possible translations to consider.
Decoding al-gorithms must therefore use some kind of search-space pruning in order to be efficient.
A key partof pruning the search space is deciding on the setof words to consider in possible translations (Ger-mann et al, 2001).
One standard method is to con-sider only target words which have high probabil-ity according to the discriminative alignment model.But we have already shown that the word translationmodel achieves much better performance on wordtranslation than this baseline model; thus, we wouldexpect the word translation model to improve accu-racy when used to pick sets of candidate translations.Given a probability distribution over possibletranslations of a word, P (b|a, s), there are severalways to choose a reduced set of possible transla-tions.
Two commonly used methods are to onlyconsider the top n scoring words from this distribu-tion (best-n); and to only consider words b such thatP (b|a, s) is above some fixed threshold (cut-off ).We use the same data set as for the blank-fillingtask.
We evaluate the accuracy of a pruning strategyby evaluating whether the correct translation is inthe candidate set selected by the pruning strategy.To compare results for different pruning strategies,we plot performance as a function of average sizeof the candidate translation set.
Figure 2 shows theaccuracy vs. average candidate set size for the word-translation model, discriminative alignment model,and generative alignment model.The generative alignment model has the worstperformance of the three.
This is not surprising as itdoes not take into account the prior probability of thetarget word P (b).
More interestingly, we see that theword-translation model outperforms the discrimina-tive translation model by a significant amount.
For0 2 4 6 8 10 120.50.550.60.650.70.750.80.850.90.951Average number of possible translationsAccuracyFigure 2: Accuracy of best-n strategy (dotted lines) and cut-off strategy (solid lines).
o = generative alignment, + = discrim-inative alignment, * = word translation.instance, to achieve 95% recall (that is, for 95% ofthe ambiguous words, we retain the correct transla-tion), we only need candidate sets of average size 4.2for the cut-off strategy using the word-translationmodel, whereas for the same strategy on the discrim-inative alignment model we require an average setsize of 6.7 words.As the size of the solution space grows exponen-tially with the size of the candidate sets, the word-translation model could potentially greatly reducethe search space while maintaining good accuracy.It would be interesting to use similar techniques tolearn null fertility (i.e., when a word a has no trans-lation in the target sentence t).8 Related WorkBerger et al (1996) apply maximum entropy meth-ods (equivalent to logistic regression) to, amongother tasks, the word-translation task.
However, noquantitative results are presented.
In this paper wedemonstrate that the method can improve perfor-mance on a large data set and show how it mightbe used to improve machine translation.Diab and Resnik (2002) suggest using large bilin-gual corpora to improve performance on word sensedisambiguation.
The main idea is that knowing aFrench word may help determine the meaning of thecorresponding English word.
They apply this intu-ition to the Senseval word disambiguation task byrunning off-the-shelf translators to produce transla-tions which they then use for disambiguation.Ng et al (2003) address word sense disambigua-tion by manually annotating WordNet senses withtheir translation in the target language (Chinese),and then automatically extracting labeled examplesfor word sense disambiguation by applying the IBM777Models to a bilingual corpus.
They achieve compa-rable results to training on hand-labeled examples.Koehn and Knight (2003) focus on the task ofnoun-phrase translation.
They improve performanceon the noun-phrase translation task, and show thatthey can use this to improve full translations.
A keydifference is that, in predicting noun-phrase trans-lations, they do not consider the context of nouns.They present results which indicate that humans canaccurately translate noun phrases without lookingat the surrounding context.
However, as we havedemonstrated in this paper, context can be very use-ful for a (sub-human-level) machine translator.A similar argument applies to phrase-based trans-lation methods (e.g., Koehn et al (2003)).
Whilephrase-based systems do take into account contextwithin phrases, they are not able to use contextacross phrase boundaries.
This is especially impor-tant when ambiguous words do not occur as part ofa phrase ?
verbs in particular often appear alone.9 ConclusionsIn this paper, we focus on the word-translation prob-lem.
By viewing word-sense disambiguation in thecontext of a larger task, we were able to obtain largeamounts of training data and directly evaluate theusefulness of our system for a real-world task.
Ourresults improve over a baseline which is difficult tooutperform in the word sense disambiguation task.The word translation model could be improved ina variety of ways, drawing upon the large body ofwork on word-sense disambiguation.
In particular,there are many types of context features which couldbe used to improve word translation performance,but which are not available to standard machine-translation systems.
Also, the model could be ex-tended to handle phrases.To evaluate word translation in the context of amachine translation task, we introduce the novelblank-filling task, which decouples the impact ofword translation from a variety of other factors, suchas syntactic correctness.
For this task, increasedword-translation accuracy leads to improved ma-chine translation.
We also show that the word trans-lation model is effective at choosing sets of candi-date translations, suggesting that a word translationcomponent would be immediately useful to currentmachine translations systems.There are several ways in which the results ofword translation could be integrated into a full trans-lation system.
Most naturally, the word translationmodel can be used directly to modify the score ofdifferent translations.
Alternatively, a decoder canproduce several candidate translations, which can bereranked using the word translation model.
Unfortu-nately, we were unable to try these approaches, dueto the lack of an appropriate publicly available de-coder.
Carpuat and Wu (2005) recently observedthat simpler integration approaches, such as forcingthe machine translation system to use the word trans-lation model?s first choice, do not improve transla-tion results.
Together, these results suggest that oneshould incorporate the results of word translation ina ?soft?
way, allowing the word translation, align-ment, and language models to work together to pro-duce coherent translations.
Given an appropriate de-coder, trying such a unified approach is straightfor-ward, and would provide insight about the value ofword translation.ReferencesA.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1).P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisti-cal machine translation.
Computational Linguistics,19(2).M.
Carpuat and D. Wu.
2005.
Word sense disambigua-tion vs. statistical machine translation.
Proc.
ACL.M.
Diab and P. Resnik.
2002.
An unsupervised methodfor word sense tagging using parallel corpora.
Proc.ACL.C.
Fellbaum, editor.
1998.
WordNet: An Electronic Lex-ical Database.
MIT Press.U.
Germann, M. Jahr, K. Knight, D. Marcu, and K. Ya-mada.
2001.
Fast decoding and optimal decoding formachine translation.
Proc.
ACL.P.
Koehn and K. Knight.
2003.
Feature-rich statisticaltranslation of noun phrases.
Proc.
ACL.P.
Koehn, F. Och, and D. Marcu.
2003.
Statistical phrase-based translation.
HLT/NAACL.T.
Minka.
2000.
Algorithms formaximum-likelihood logistic regression.http://lib.stat.cmu.edu/ minka/papers/logreg.html.A.
Ng and M. Jordan.
2002.
On discriminative vs. gen-erative classifiers: A comparison of logistic regressionand naive bayes.
Proc.
NIPS.H.
T. Ng, B. Wang, and Y. S. Chan.
2003.
Exploitingparallel texts for word sense disambiguation: An em-pirical study.
Proc.
ACL.F.
Och and H. Ney.
2002.
Discriminative trainingand maximum entropy models for statistical machinetranslation.
Proc.
ACL.J.
Shewchuk.
1994.
An introduction to the conjugate gra-dient method without the agonizing pain.
http://www-2.cs.cmu.edu/ jrs/jrspapers.html.778
