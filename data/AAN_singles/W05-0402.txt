Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in NLP, pages 9?16,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsFeature Engineering and Post-Processing for Temporal ExpressionRecognition Using Conditional Random FieldsSisay Fissaha Adafre Maarten de RijkeInformatics Institute, University of AmsterdamKruislaan 403, 1098 SJ Amsterdam, The Netherlandssfissaha,mdr@science.uva.nlAbstractWe present the results of feature engineer-ing and post-processing experiments con-ducted on a temporal expression recogni-tion task.
The former explores the use ofdifferent kinds of tagging schemes and ofexploiting a list of core temporal expres-sions during training.
The latter is con-cerned with the use of this list for post-processing the output of a system based onconditional random fields.We find that the incorporation of knowl-edge sources both for training and post-processing improves recall, while the useof extended tagging schemes may helpto offset the (mildly) negative impact onprecision.
Each of these approaches ad-dresses a different aspect of the over-all recognition performance.
Taken sep-arately, the impact on the overall perfor-mance is low, but by combining the ap-proaches we achieve both high precisionand high recall scores.1 IntroductionTemporal expressions (timexes) are natural languagephrases that refer directly to time points or intervals.They not only convey temporal information on theirown but also serve as anchors for locating events re-ferred to in a text.
Timex recognition is a namedentity recognition (NER) task to which a variety ofnatural language processing and machine learningtechniques have been applied.
As with other NERtasks, timex recognition is naturally viewed as a se-quence labeling task, easily lending itself to ma-chine learning techniques such as conditional ran-dom fields (CRFs) (Lafferty et al, 2001).A preliminary experiment showed that, usingCRFs, a respectable recognition performance caneasily be achieved with a straightforward baselinesystem that is based on a simple tagging scheme andrequires very little tuning, yielding F-scores around0.78 (exact match) or even 0.90 (partial match).Interestingly, these high scores are mainly due tohigh or even very high precision scores, while recallleaves much to be improved.The main focus of this paper is on boosting re-call while maintaining precision at an acceptable(i.e., high) level.
We report on two types of ex-periments aimed at achieving this goal.
One typeconcerns feature engineering and the other concernspost-processing the output of a machine learner.While we do exploit the special nature of timexes,for portability reasons we avoid using task-specificand richer linguistic features (POS, chunks, etc.).
In-stead, we focus on features and techniques that canreadily be applied to other NER tasks.Specifically, our feature engineering experimentshave two facets.
The first concerns identification ofa set of simple features that results in high general-ization ability (accuracy).
Here, particular emphasiswill be placed on the use of a list of core timexes asa feature.
The assumption is that the performance ofdata-driven approaches for timex recognition can beimproved by taking into account the peculiar prop-erties of timexes.
Timexes exhibit various patterns,ranging from regular patterns that can easily be cap-tured using simple regular expressions to complexlinguistic forms (phrases).
While timexes are real-9ized in different phrase types, the core lexical itemsof timexes are restricted.
This suggests that a listof core timexes can easily be compiled and used inmachine learning-based timex recognition.
One ap-proach of integrating such a list is using them to gen-erate features, but the availability of such a list alsoopens up other possibilities in feature design that wepresent in later sections.The second aspect concerns the tagging scheme.As in most NER experiments, the task of recogniz-ing timexes is reduced to tagging.
Commonly usedtagging schemes are Inside-Outside (IO) and Begin-Continue-End-Unique-Negative (BCEUN) (Borth-wick et al, 1998).
The IO tagging scheme, which weuse as a baseline, assigns the tag I to a token if it ispart of a timex and O otherwise.
The richer BCEUNscheme assigns the five tags B, C, E, U, and N to to-kens depending on whether the token is single-tokentimex (U), a non-timex (N), appears at the beginning(B), at the end (E) or inside a timex boundary (C).
Inthis paper, we compare the IO, BCEUN and an ex-tended form of the BCEUN tagging scheme.
Theextended scheme adds two tags, PRE and POST, tothe BCEUN scheme, which correspond to tokens ap-pearing to the left and to the right of a timex.In contrast, our post-processing experiments in-vestigate the application of the list of core timexesfor filtering the output of a machine learner.
The in-corporation into the recognition process of explicitknowledge in the form of a list for post-processingrequires a carefully designed strategy to ensure thatthe important properties of the trained model arekept intact as much as possible while at the same-time improving overall results.
We present an ap-proach for using a list for post-processing that ex-ploits the knowledge embodied in the trained model.The paper is organized as follows.
In Section 2we provide background material, both on the timexextraction task (?2.1) and on the machine learningtechniques on which we build in this paper, condi-tional random fields (?2.2).
Our ideas on engineer-ing feature sets and tagging schemes are presentedin Section 3, while we describe our method for ex-ploiting the explicit knowledge contained in a list inSection 4.
In Section 5, we describe the experimen-tal setup and present the results of our experiments.Related work is briefly reviewed in Section 6, andwe conclude in Section 7.2 Background2.1 Task DescriptionIn recent years, temporal aspects of information ac-cess have received increasing amounts of attention,especially as it relates to news documents.
In addi-tion to factual content, news documents have a tem-poral context, reporting events that happened, arehappening, or will happen in relation to the publi-cation date.
Temporal document retrieval concernsthe inclusion of both the document publication dateand the in-text temporal expressions in the retrievalmodel (Kalczynski and Chou, 2005).
The task inwhich we are interested in this paper is identifyingthe latter type of expressions, i.e., extraction of tem-poral expressions.
TERN, the Temporal ExpressionRecognition and Normalization Evaluation, is orga-nized under the auspices of the Automatic ContentExtraction program (ACE, http://www.nist.gov/speech/tests/ace/).
The TERN evalu-ation provides specific guidelines for the identifica-tion and normalization of timexes, as well as taggedcorpora for training and testing and evaluation soft-ware.
These guidelines and resources were used forthe experiments described below.The TERN evaluation consisted of two distincttasks: recognition and normalization.
Timex recog-nition involves correctly detecting and delimitingtimexes in text.
Normalization involves assigningrecognized timexes a fully qualified temporal value.Our focus in this paper is on the recognition task;it is defined, for human annotators, in the TIDESTIMEX2 annotation guidelines (Ferro et al, 2004).The recognition task is performed with respect tocorpora of transcribed broadcast news speech andnews wire texts from ACE 2002, ACE 2003, andACE 2004, marked up in SGML format and, forthe training set, hand-annotated for TIMEX2s.
Anofficial scorer that evaluates the recognition perfor-mance is provided as part of the TERN evaluation.
Itcomputes precision, recall, and F-measure both forTIMEX2 tags (i.e., for overlap with a gold standardTIMEX2 element) and for extent of TIMEX2 ele-ments (i.e., exact match of entire timexes).2.2 Conditional Random FieldsWe view the recognition of timexes task as a se-quence labeling task in which each token in the text10is classified as being either a timex or not.
One ma-chine learning technique that has recently been in-troduced to tackle the problem of labeling and seg-menting sequence data is conditional random fields(CRFs, (Lafferty et al, 2001)).
CRFs are conditionalprobability distributions that take the form of ex-ponential models.
The special case of linear chainCRFs, which takes the following form, has beenwidely used for sequence labeling tasks:P (y | x) =1Z (x)exp(?t=1?k?kfk (t, yt?1, yt, x)),where Z (x) is the normalization factor, X ={x1, .
.
.
, xn} is the observation sequence, Y ={y1, .
.
.
, yT } is the label sequences, fk and ?k arethe feature functions and their weights respectively.An important property of these models is that proba-bilities are computed based on a set of feature func-tions, i.e., fk (usually binary valued), which are de-fined on both the observation X and label sequencesY .
These feature functions describe different aspectof the data and may overlap, providing a flexible wayof describing the task.CRFs have been shown to perform well in anumber of natural language processing applications,such as POS tagging (Lafferty et al, 2001), shallowparsing or NP chunking (Sha and Pereira, 2003), andnamed entity recognition (McCallum and Li, 2003).In this paper, CRFs are applied to the recognition oftimexes; in our experiments we used the minorThirdimplementation of CRFs (Cohen, 2004).3 Feature EngineeringThe success of applying CRFs depends on the qual-ity of the set of features used and the tagging schemechosen.
Below, we discuss these two aspects ingreater detail.3.1 Feature setsOur baseline feature set consists of simple lexicaland character features.
These features are derivedfrom a context window of two words (left and right).Specifically, the features are the lowercase form ofall the tokens in the span, with each token contribut-ing a separate feature, and the tokens in the left andright context window constitute another set of fea-tures.
These feature sets capture the lexical con-tent and context of timexes.
Additionally, charac-ter type pattern features (such as capitalization, digitsequence) of tokens in the timexes are used to cap-ture the character patterns exhibited by some of thetokens in temporal expressions.
These features con-stitute the basic feature set.Another important feature is the list of coretimexes.
The list is obtained by first extracting thephrases with -TMP function tags from the PennTreebank, and taking the words in these phrases (Marcuset al, 1993).
The resulting list is filtered for stop-words.
Among others, the list of core timexes con-sists of the names of days of the week and months,temporal units ?day,?
?month,?
?year,?
etc.
This listis used to generate binary features.
In addition, thelist is used to guide the design of other complex fea-tures that may involve one or more of token-tag pairsin the context of the current token.
One way of usingthe list for this purpose is to generate a feature thatinvolves bi-grams tokens.
In certain cases, informa-tion extracted from bi-grams, e.g.
+Xx 99 (May 20),can be more informative than information generatedfrom individual tokens.
We refer to these features asthe list feature set.3.2 Tagging schemesA second aspect of feature engineering that weconsider in this paper concerns different taggingschemes.
As mentioned previously, the task of rec-ognizing timexes is reduced to a sequence-labelingtask.
We compare three tagging schemes, IO(our baseline), BCEUN, and BCEUN+PRE&POST.While the first two are relatively standard, the lastone is an extension of the BCEUN scheme.
Theintuition underlying this tagging scheme is that themost relevant features for timex recognition are ex-tracted from the immediate context of the timex,e.g., the word ?During?
in (1) below.
(1) During <TIMEX2>the past week</TIMEX2>,the storm has pounded the city.During-PRE the-B past-C week-E ,-POST thestorm has pounded the city.Therefore, instead of treating these elements uni-formly as outside (N), which ignores their relativeimportance, we conjecture that it is worthwhile to11assign them a special category, like PRE and POSTcorresponding to the tokens immediately precedingand following a timex, and that this leads to im-proved results.4 Post-processing Using a ListIn this section, we describe the proposed methodfor incorporating a list of core lexical timexes forpost-processing the output of a machine learner.
Aswe will see below, although the baseline system(with the IO tagging scheme and the basic featureset) achieves a high accuracy, the recall scores leavemuch to be desired.
One important problem that wehave identified is that timexes headed by core lexicalitems on the list may be missed.
This is either dueto the fact that some of these lexical items are se-mantically ambiguous and appear in a non-temporalsense, or the training material does not cover the par-ticular context.
In such cases, a reliable list of coretimexes can be used to identify the missing timexes.For the purposes of this paper, we have created alist containing mainly headwords of timexes.
Thesewords are called trigger words since they are goodindicators of the presence of temporal expressions.How can we use trigger words?
Before describ-ing our method in some detail, we briefly describea more naive (and problematic) approach.
Observethat trigger words usually appear in a text along withtheir complements or adjuncts.
As a result, pick-ing only these words will usually contribute to tokenrecall but span precision is likely to drop.
Further-more, there is no principled way of deciding whichone to pick (semantically ambiguous elements willalso be picked).
Let?s make this more precise.
Theaim is to take into account the knowledge acquiredby the trained model and to search for the next op-timal sequence of tags, which assigns the missedtimex a non-negative tag.
However, searching forthis sequence by taking the whole word sequenceis impractical since the number of possible tag se-quences (number of all possible paths in a viterbisearch) is very large.
But if one limits the search toa window of size n (n < 6), sequential search willbe feasible.
The method, then, works on the outputof the system.
We illustrate the method by using theexample given in (2) below.
(2) The chairman arrived in the city yesterday, andwill leave next week.
The press conference willbe held tomorrow afternoon.Now, assume that (2) is a test instance (a two-sentence document), and that the system returns thefollowing best sequence (3).
For readability, the tagN is not shown on the words that are assigned nega-tive tags in all the examples below.
(3) The chairman arrived in the city yesterday-U ,and will leave next week .
The press conferencewill be held tomorrow-B afternoon-E .According to (3), the system recognizes only ?yes-terday?
and ?tomorrow afternoon?
but misses ?nextweek?.
Assuming our list of timexes contains theword ?week?, it tells us that there is a missing tem-poral expression, headed by ?week.?
The naivemethod is to go through the above output sequenceand change the token-tag pair ?week-N?
to ?week-U?.
This procedure recognizes the token ?week?
as avalid temporal expression, but this is not correct: thevalid temporal expression is ?next week?.We now describe a second approach to incorpo-rating the knowledge contained in a list of core lexi-cal timexes as a post-processing device.
To illustrateour ideas, take the complete sequence in (3) and ex-tract the following segment, which is a window of 7tokens centered at ?week?.
(4) .
.
.
[will leave next week .
The press] .
.
.We reclassify the tokens in (4) assuming the historycontains the token ?and?
(the token which appears tothe left of this segment in the original sequence) andthe associated parameters.
Of course, the best se-quence will still assign both ?next?
and ?week?
the Ntag since the underlying parameters (feature sets andthe associated weights) are the same as the ones inthe system.
However, since the word sequence in (4)is now short (contains only 7 words) we can main-tain a list of all possible tag sequences for it and per-form a sequential search for the next best sequence,which assigns the ?week?
token a non-negative tag.Assume the new tag sequence looks as follows:(5) .
.
.
[will leave next-B week-E .
The press] .
.
.This tag sequence will then be placed back into theoriginal sequence resulting in (6):12(6) The chairman arrived in the city yesterday-U ,and will leave next-B week-E .
The press con-ference will be held tomorrow-B afternoon-E .In this case, all the temporal expressions will be ex-tracted since the token sequence ?next week?
is prop-erly tagged.
Of course, the above procedure can alsoreturn other, invalid sequences as in (7):(7) a. .
.
.
will leave next-B week-C .
The press .
.
.b.
.
.
.
will leave next week-C .
The press .
.
.c.
.
.
.
will leave next week-C .-E The press .
.
.The final extraction step will not return any timexsince none of the candidate sequences in (7) containsa valid tag sequence.
The assumption here is that ofall the tag sequences, which assign the token ?week?a non-negative tag, those tag sequences which con-tain the segment ?next-B week-E?
are likely to re-ceive a higher weight since the underlying systemis trained to recognize temporal expressions and thephrase ?next week?
is a likely temporal expression.This way, we hypothesize, it is possible to ex-ploit the knowledge embodied in the trained model.As pointed out previously, simply going throughthe list and picking only head words like ?week?will not guarantee that the extracted tokens form avalid temporal expression.
On the other hand, theabove heuristics, which relies on the trained model,is likely to pick the adjunct ?next?.The post-processing method we have just out-lined boils down to reclassifying a small segmentof a complete sequence using the same parameters(feature sets and associated weights) as the originalmodel, and keeping all possible candidate sequencesand searching through them to find a valid sequence.5 Experimental EvaluationIn this section we provide an experimental assess-ment of the feature engineering and post-processingmethods introduced in Sections 3 and 4.
Specifi-cally, we want to determine what their impact is onthe precision and recall scores of the baseline sys-tem, and how they can be combined to boost recallwhile keeping precision at an acceptable level.5.1 Experimental dataThe training data consists of 511 files, and the testdata consists of 192 files; these files were madeavailable in the 2004 Temporal Expression Recog-nition and Normalization Evaluation.
The tempo-ral expressions in the training files are marked withXML tags.
The minorThird system takes care ofautomatically converting from XML format to thecorresponding tagging schemes.
A temporal expres-sion enclosed by <TIMEX2> tags constitutes a span.The features in the training instances are generatedby looking at the surface forms of the tokens in thespans and their surrounding contexts.5.2 Experimental resultsRicher feature sets Table 1 lists the results of thefirst part of our experiments.
Specifically, for everytagging scheme, there are two sets of features, basicand list.
The results are based on both exact-matchand partial match between the spans in the gold stan-dard and the spans in the output of the systems, asexplained in Subsection 2.1.
In both the exact andpartial match criteria, the addition of the list featuresleads to an improvement in recall, and no change ora decrease in precision.In sum, the feature addition helps recall more thanit hurts precision, as the F score goes up nearly ev-erywhere, except for the exact-match/baseline pair.Tagging schemes In Table 1 we also list the ex-traction scores for the tagging schemes we con-sider, IO, BCEUN, and BCEUN+PRE&POST, asdescribed in Section 3.2.Let us first look at the impact of the different tag-ging schemes in combination with the basic featureset (rows 3, 5, 7).
As we go from the baselinetagging scheme IO to the more complex BCEUNand BCEUN+PRE&POS, precision increases onthe exact-match criterion but remains almost thesame on the partial match criterion.
Recall, onthe other hand, does not show the same trend.BCEUN has the highest recall values followed byBCEUN+PRE&POST and finally IO.
In general,IO based tagging seems to perform worse whereasBCEUN based tagging scores slightly above its ex-tended tagging scheme BCEUN+PRE&POST.Next, considering the combination of extend-ing the feature set and moving to a richer taggingscheme (rows 4, 6, 8), we have very much the samepattern.
In both the exact match and the partialmatch setting, BCEUN tops (or almost tops) the two13Exact Match Partial MatchTagging scheme Features Prec.
Rec.
F Prec.
Rec.
FIO (baseline) basic 0.846 0.723 0.780 0.973 0.832 0.897basic + list 0.822 0.736 0.776 0.963 0.862 0.910BCEUN basic 0.874 0.768 0.817 0.974 0.856 0.911basic + list 0.872 0.794 0.831 0.974 0.887 0.928BCEUN+PRE&POS basic 0.882 0.749 0.810 0.979 0.831 0.899basic + list 0.869 0.785 0.825 0.975 0.881 0.925Table 1: Timex: Results of training on basic and list features, and different tagging schemes.
Highest scores(Precision, Recall, F-measure) are in bold face.other schemes in both precision and recall.In sum, the richer tagging schemes function asprecision enhancing devices.
The effect is clearlyvisible for the exact-match setting, but less so forpartial matching.
It is not the case that the learnertrained on the richest tagging scheme outperformsall learners trained with poorer schemes.Post-processing Table 2 shows the results of ap-plying the post-processing method described inSection 4.
One general pattern we observe inTable 2 is that the addition of the list featuresimproves precision for IO and BCEUN taggingscheme and shows a minor reduction in precisionfor BCEUN+PRE&POS tagging scheme in bothmatching criteria.
Similarly, in the presence ofpost-processing, the use of a more complex taggingscheme results in a better precision.
On the otherhand, recall shows a different pattern.
The addi-tion of list features improves recall both for BCEUNand BCEUN+PRE&POS, but hurts recall for the IOscheme for both matching criteria.Comparing the results in Table 1 and Table 2,we see that post-processing is a recall enhancingdevice since all the recall values in Table 2 arehigher than the recall values in Table 1.
Pre-cision values in Table 2, on the other hand, arelower than those of Table 1.
Importantly, theuse of a more complex tagging scheme such asBCEUN+PRE&POS, allows us to minimize thedrop in precision.
In general, the best result (onpartial match) in Table 1 is achieved through thecombination of BCEUN and basic&list featureswhereas the best result in Table 2 is achieved bythe combination of BCEUN+PRE&POS and basic&list features.
Although both have the same over-all scores on the exact match criteria, the latter per-forms better on partial match criteria.
This, in turn,shows that the combination of post-processing, andBCEUN+PRE&POS achieves better results.Stepping back We have seen that the extendedtagging scheme and the post-processing methodsimprove on different aspects of the overall per-formance.
As mentioned previously, the ex-tended tagging scheme is both recall and precision-oriented, while the post-processing method is pri-marily recall-oriented.
Combining these two meth-ods results in a system which maintains both theseproperties and achieves a better overall result.
In or-der to see how these two methods complement eachother it is sufficient to look at the highest scoresfor both precision and recall.
The extended taggingscheme with basic features achieves the highest pre-cision but has relatively low recall.
On the otherhand, the simplest form, the IO tagging schemeand basic features with post-processing, achievesthe highest recall and the lowest precision in par-tial match.
This shows that the IO tagging schemewith basic features imposes a minimal amount ofconstraints, which allows for most of the timexes inthe list to be extracted.
Put differently, it does notdiscriminate well between the valid vs invalid oc-currences of timexes from the list in the text.
At theother extreme, the extended tagging scheme with 7tags imposes strict criteria on the type of words thatconstitute a timex, thereby restricting which occur-rences of the timex in the list count as valid timexes.In general, although the overall gain in score islimited, our feature engineering and post-processingefforts reveal some interesting facts.
First, they showone possible way of using a list for post-processing.14Exact Match Partial MatchTagging scheme Features Prec.
Rec.
F Prec.
Rec.
FIO basic (baseline) 0.846 0.723 0.780 0.973 0.832 0.897basic 0.756 0.780 0.768 0.902 0.931 0.916basic + list 0.772 0.752 0.762 0.930 0.906 0.918BCEUN basic 0.827 0.789 0.808 0.945 0.901 0.922basic + list 0.847 0.801 0.823 0.958 0.906 0.931BCEUN+PRE&POS basic 0.863 0.765 0.811 0.973 0.863 0.915basic + list 0.861 0.804 0.831 0.970 0.906 0.937Table 2: Timex: Results of applying post-processing on the systems in Table 1.
The baseline (from Table 1)is repeated for ease of reference; it does not use post-processing.
Highest scores (Precision, Recall, F-measure) are in bold face.This method is especially appropriate for situationswhere better recall is important.
It offers a means ofcontrolling the loss in precision (gain in recall) byallowing a systematic process of recovering missingexpressions that exploits the knowledge already em-bodied in a probabilistically trained model, therebyreducing the extent to which we have to make ran-dom decisions.
The method is particularly sensitiveto the criterion (the quality of the list in the currentexperiment) used for post-processing.6 Related WorkA large number of publications deals with extractionof temporal expressions; the task is often treated aspart of a more involved task combining recognitionand normalization of timexes.
As a result, manytimex interpretation systems are a mixture of bothrule-based and machine learning approaches (Maniand Wilson, 2000).
This is partly due to the fact thattimex recognition is more amenable to data-drivenmethods whereas normalization is best handled us-ing primarily rule-based methods.
We focused onmachine learning methods for the timex recognitiontask only.
See (Katz et al, 2005) for an overview ofmethods used for addressing the TERN 2004 task.In many machine learning-based named-entityrecognition tasks dictionaries are used for improvingresults.
They are commonly used to generate binaryfeatures.
Sarawagi and Cohen (2004) showed thatsemi-CRFs models for NE recognition perform bet-ter than conventional CRFs.
One advantage of semi-CRFs models is that the units that will be tagged aresegments which may contain one or more tokens,rather than single tokens as is done in conventionalCRFs.
This in turn allows one to incorporate seg-ment based-features, e.g., segment length, and alsofacilitates integration of external dictionaries sincesegments are more likely to match the entries of anexternal dictionary than tokens.
In this paper, westuck to conventional CRFs, which are computation-ally less expensive, and introduced post-processingtechniques, which takes into account knowledge em-bodied in the trained model.Kristjannson et al (2004) introduced constrainedCRFs (CCRFs), a model which returns an optimallabel sequence that fulfills a set of constraints im-posed by the user.
The model is meant to be used inan interactive information extraction environment,in which the system extracts structured information(fields) from a text and presents it to the user, andthe user makes the necessary correction and submitsit back to the system.
These corrections constitutean additional set of constraints for CCRFs.
CCRFsre-computes the optimal sequence by taking theseconstraints into account.
The method is shown toreduce the number of user interactions required invalidating the extracted information.
In a very lim-ited sense our approach is similar to this work.
Thelist of core lexical timexes that we use representsthe set of constraints on the output of the underly-ing system.
However, our method differs in the wayin which the constraints are implemented.
In ourcase, we take a segment of the whole sequence thatcontains a missing timex, and reclassify the wordsin this segment while keeping all possible tag se-quences sorted based on their weights.
We then15search for the next optimal sequence that assigns themissing timex a non-negative tag sequentially.
Onthe other hand, Kristjannson et al (2004) take thewhole sequence and recompute an optimal sequencethat satisfies the given constraints.
The constraintsare a set of states which the resulting optimal se-quence should include.7 ConclusionIn this paper we presented different feature engi-neering and post-processing approaches for improv-ing the results of timex recognition task.
The firstapproach explores the different set of features thatcan be used for training a CRF-based timex recog-nition system.
The second investigates the effect ofthe different tagging scheme for timex recognitiontask.
The final approach we considered applies a listof core timexes for post-processing the output of aCRF system.
Each of these approaches addressesdifferent aspects of the overall performance.
Theuse of a list of timexes both during training and forpost-processing resulted in improved recall whereasthe use of a more complex tagging scheme resultsin better precision.
Their individual overall contri-bution to the recognition performances is limited oreven negative whereas their combination resulted insubstantial improvements over the baseline.While we exploited the special nature of timexes,we did avoid using linguistic features (POS, chunks,etc.
), and we did so for portability reasons.
We fo-cused exclusively on features and techniques thatcan readily be applied to other named entity recog-nition tasks.
For instance, the basic and list featurescan also be used in NER tasks such as PERSON,LOCATION, etc.
Moreover, the way that we haveused a list of core expressions for post-processing isalso task-independent, and it can easily be appliedfor other NER tasks.AcknowledgmentsSisay Fissaha Adafre was supported by the Nether-lands Organization for Scientific Research (NWO)under project number 220-80-001.
Maarten deRijke was supported by grants from NWO, underproject numbers 365-20-005, 612.069.006, 220-80-001, 612.000.106, 612.000.207, 612.066.302, 264-70-050, and 017.001.190.References[Borthwick et al1998] A. Borthwick, J. Sterling,E.
Agichtein, and R. Grishman.
1998.
Exploitingdiverse knowledge sources via maximum entropy innamed entity recognition.
In Workshop on Very LargeCorpora, ACL.
[Cohen2004] W. Cohen.
2004.
Methods for identifyingnames and ontological relations in text using heuris-tics for inducing regularities from data.
http://minorthird.sourceforge.net.
[Ferro et al2004] L. Ferro, L. Gerber, I. Mani, andG.
Wilson, 2004.
TIDES 2003 Standard for the An-notation of Temporal Expressions.
MITRE, April.
[Kalczynski and Chou2005] P.J.
Kalczynski and A. Chou.2005.
Temporal document retrieval model for businessnews archives.
Information Processing and Manage-ment, 41:635?650.
[Katz et al2005] G. Katz, J. Pustejovsky, and F. Schilder,editors.
2005.
Proceedings Dagstuhl Workshop onAnnotating, Extracting, and Reasoning about Timeand Events.
[Kristjannson et al2004] T. Kristjannson, A. Culotta,P.
Viola, and A. McCallum.
2004.
Interactive infor-mation extraction with constrained conditional randomfields.
In Nineteenth National Conference on ArtificialIntelligence, AAAI.
[Lafferty et al2001] J. Lafferty, F. Pereira, and A. McCal-lum.
2001.
Conditional random fields: Probabilisticmodels for segmenting and labeling sequence data.
InProceedings of the International Conference on Ma-chine Learning.
[Mani and Wilson2000] I. Mani and G. Wilson.
2000.Robust temporal processing of news.
In Proceedingsof the 38th ACL.
[Marcus et al1993] M.P.
Marcus, B. Santorini, and M.A.Marcinkiewicz.
1993.
Building a large annotated cor-pus of English: The Penn treebank.
ComputationalLinguistics, 19:313?330.
[McCallum and Li2003] A. McCallum and W. Li.
2003.Early results for Named Entity Recognition with con-ditional random fields, feature induction and web-enhanced lexicons.
In Proceedings of the 7th CoNLL.
[Sarawagi and Cohen2004] S. Sarawagi and W.W. Cohen.2004.
Semi-markov conditional random fields for in-formation extraction.
In NIPs (to appear).
[Sha and Pereira2003] F. Sha and F. Pereira.
2003.
Shal-low parsing with conditional random fields.
In Pro-ceedings of Human Language Technology-NAACL.16
