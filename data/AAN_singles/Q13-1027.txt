Dynamically Shaping the Reordering Search Spaceof Phrase-Based Statistical Machine TranslationArianna Bisazza and Marcello FedericoFondazione Bruno KesslerTrento, Italy{bisazza,federico}@fbk.euAbstractDefining the reordering search space is a cru-cial issue in phrase-based SMT between dis-tant languages.
In fact, the optimal trade-off between accuracy and complexity of de-coding is nowadays reached by harshly lim-iting the input permutation space.
We pro-pose a method to dynamically shape suchspace and, thus, capture long-range wordmovements without hurting translation qual-ity nor decoding time.
The space definedby loose reordering constraints is dynamicallypruned through a binary classifier that predictswhether a given input word should be trans-lated right after another.
The integration ofthis model into a phrase-based decoder im-proves a strong Arabic-English baseline al-ready including state-of-the-art early distor-tion cost (Moore and Quirk, 2007) and hierar-chical phrase orientation models (Galley andManning, 2008).
Significant improvements inthe reordering of verbs are achieved by a sys-tem that is notably faster than the baseline,while BLEU and METEOR remain stable, oreven increase, at a very high distortion limit.1 IntroductionWord order differences are among the most impor-tant factors determining the performance of statisti-cal machine translation (SMT) on a given languagepair (Birch et al 2009).
This is particularly true inthe framework of phrase-based SMT (PSMT) (Zenset al 2002; Koehn et al 2003; Och and Ney, 2002),an approach that remains highly competitive despitethe recent advances of the tree-based approaches.During the PSMT decoding process, the outputsentence is built from left to right, while the inputsentence positions can be covered in different or-ders.
Thus, reordering in PSMT can be viewed asthe problem of choosing the input permutation thatleads to the highest-scoring output sentence.
Due toefficiency reasons, however, the input permutationspace cannot be fully explored, and is therefore lim-ited with hard reordering constraints.Although many solutions have been proposed toexplicitly model word reordering during decoding,PSMT still largely fails to handle long-range wordmovements in language pairs with different syntac-tic structures1.
We believe this is mostly not due todeficiencies of the existing reordering models, butrather to a very coarse definition of the reorder-ing search space.
Indeed, the existing reorderingconstraints are rather simple and typically based onword-to-word distances.
Moreover, they are uni-form throughout the input sentence and insensitiveto the actual words being translated.
Relaxing thiskind of constraints means dramatically increasingthe size of the search space and making the reorder-ing model?s task extremely complex.
As a result,even in language pairs where long reordering is reg-ularly observed, PSMT quality degrades when longword movements are allowed to the decoder.We address this problem by training a binaryclassifier to predict whether a given input positionshould be translated right after another, given thewords at those positions and their contexts.
Whenthis model is integrated into the decoder, its predic-1For empirical evidence, see for instance (Birch et al 2009;Galley and Manning, 2008; Bisazza and Federico, 2012).327Transactions of the Association for Computational Linguistics, 1 (2013) 327?340.
Action Editor: Philipp Koehn.Submitted 1/2013; Revised 5/2013; Published 7/2013.
c?2013 Association for Computational Linguistics.tions can be used not only as an additional featurefunction, but also as an early indication of whetheror not a given reordering path should be further ex-plored.
More specifically, at each hypothesis ex-pansion, we consider the set of input positions thatare reachable according to the usual reordering con-straints, and prune it based only on the reorder-ing model score.
Then, the hypothesis can be ex-panded normally by covering the non-pruned posi-tions.
This technique makes it possible to dynami-cally shape the search space while decoding with avery high distortion limit, which can improve trans-lation quality and efficiency at the same time.The remainder of the paper is organized as fol-lows.
After an overview of the relevant literature,we describe in detail our word reordering model.
Inthe following section, we introduce early pruning ofreordering steps as a way to dynamically shape theinput permutation space.
Finally, we present an em-pirical analysis of our approach, including intrinsicevaluation of the model and SMT experiments on awell-known Arabic-English news translation task.2 Previous WorkIn this paper, we focus on methods that guide thereordering search during the phrase-based decodingprocess.
See for instance (Costa-jussa` and Fonol-losa, 2009) for a review of pre- and post-reorderingapproaches that are not treated here.Assuming a one-to-one correspondence betweensource and target phrases, reordering in PSMT canbe viewed as the problem of searching through a setof permutations of the input sentence.
Thus, twosub-problems arise: defining the set of allowed per-mutations (reordering constraints) and scoring theallowed permutations according to some likelihoodcriterion (reordering model).
We begin with the lat-ter, returning to the constraints later in this section.2.1 Reordering modelingIn its original formulation, the PSMT approachincludes a basic reordering model, called distor-tion cost, that exponentially penalizes longer jumpsamong consecutively translated phrases (f?i?1, f?i):d(f?i?1, f?i) = e?|start(f?i)?
end(f?i?1)?
1|A number of more sophisticated solutions havebeen proposed to explicitly model word reorder-ing during decoding.
These can mostly be groupedinto three families: phrase orientation models, jumpmodels and source decoding sequence models.Phrase orientation models (Tillmann, 2004;Koehn et al 2005; Zens and Ney, 2006; Galley andManning, 2008), also known as lexicalized reorder-ing models, predict the orientation of a phrase withrespect to the last translated one, by classifying itas monotone, swap or discontinuous.
These mod-els have proven very useful for short and medium-range reordering and are among the most widelyused in PSMT.
However, their coarse classificationof reordering steps makes them unsuitable to predictlong-range reorderings.Jump models (Al-Onaizan and Papineni, 2006;Green et al 2010; Yahyaei and Monz, 2010) predictthe direction and length of a jump to perform aftera given input word2.
Both these works achieve theirbest Arabic-English results within a rather small DL:namely, 8 in (Al-Onaizan and Papineni, 2006) and5 in (Green et al 2010), thus failing to capture therare but crucial long reorderings that were their mainmotivation.
A drawback of this approach is thatlong jumps are typically penalized because of theirlow frequency compared to short jumps.
This strongbias is undesirable, given that we are especially in-terested in detecting probable long reorderings.Source decoding sequence models predict whichinput word is likely to be translated at a given stateof decoding.
For instance, reordered source lan-guage models (Feng et al 2010) are smoothed n-gram models trained on a corpus of source sentencesreordered to match the target word order.
When inte-grated into the SMT system, they assign a probabil-ity to each newly translated word given the n-1 pre-viously translated words.
Finally, source word pairreordering models (Visweswariah et al 2011) esti-mate, for each pair of input words i and j, the costof translating j right after i given various features ofi, j and their respective contexts.
Differently fromreordered source LMs, these models are discrimina-tive and can profit from richer feature sets.
At thesame time, they do not employ decoding history-based features, which allows for more effective hy-2In this paper, input (or source) word denotes the word at agiven position of the input sentence, rather than a word type.328pothesis recombination.
The model we are going topresent belongs to this last sub-group, which we findespecially suitable to predict long reorderings.2.2 Reordering constraintsThe reordering constraint originally included in thePSMT framework and implemented in our referencetoolkit, Moses (Koehn et al 2007), is called dis-tortion limit (DL).
This consists in allowing the de-coder to skip, or jump, at most k words from the lasttranslated phrase to the next one.
More precisely, thelimit is imposed on the distortion D between consec-utively translated phrases (f?i?1, f?i):D(f?i?1, f?i) =???start(f?i)?
end(f?i?1)?
1???
?
DLLimiting the input permutation space is necessaryfor beam-search PSMT decoders to function in lin-ear time.
Reordering constraints are also importantfor translation quality because the existing modelsare typically not discriminative enough to guide thesearch over very large sets of reordering hypotheses.Despite their crucial effects on the complexity ofreordering modeling, though, reordering constraintshave drawn less attention in the literature.
The ex-isting reordering constraints are typically based onword-to-word distances ?
IBM (Berger et al 1996)and DL (Koehn et al 2007) ?
or on permutation pat-terns ?
ITG (Wu, 1997).
Both kinds of constraintsare uniform throughout the input sentence, and in-sensitive to the word being translated and to its con-text.
This results in a very coarse definition of thereordering search space, which is problematic in lan-guage pairs with different syntactic structures.To address this problem, Yahyaei and Monz(2010) present a technique to dynamically set theDL: they train a classifier to predict the most prob-able jump length after each input word, and use thepredicted value as the DL after that position.
Un-fortunately, this method can generate inconsistentconstraints leading to decoding dead-ends.
As a so-lution, the dynamic DL is relaxed when needed toreach the first uncovered position.
Translation im-provements are reported only on a small-scale taskwith short sentences (BTEC), over a baseline that in-cludes a very simple reordering model.
In our workwe develop this idea further and use a reorderingmodel to predict which specific input words, ratherthan input intervals, are likely be translated next.Moreover, our solution is not affected by the con-straint inconsistency problem (see Sect.
4).In another related work, Bisazza and Federico(2012) generate likely reorderings of the input sen-tence by means of language-specific fuzzy rulesbased on shallow syntax.
Long jumps are then sug-gested to the PSMT decoder by reducing the distor-tion cost for specific pairs of input words.
In com-parison to the dynamic DL, that is a much finer wayto define the reordering space, leading to consistentimprovements of both translation quality and effi-ciency over a strong baseline.
However, the need ofspecific reordering rules makes the method harder toapply to new language pairs.3 The WaW reordering modelWe model reordering as the problem of decidingwhether a given input word should be translatedafter another (Word-after-Word).
This formulationis particularly suitable to help the decoder decidewhether a reordering path is promising enough tobe further explored.
Moreover, when translating asentence, choosing the next source word to translateappears as a more natural problem than guessinghow much to the left or to the right we shouldmove from the current source position.
The WaWreordering model addresses a binary decision taskthrough the following maximum-entropy classifier:P (Ri,j=Y |fJ1 , i, j) =exp[?m ?mhm(fJ1 , i, j, Ri,j=Y )]?Y ?
exp[?m ?mhm(fJ1 , i, j, Ri,j=Y ?
)]where fJ1 is a source sentence of J words, hm arefeature functions and ?m the corresponding featureweights.
The outcome Y can be either 1 or 0, withRi,j=1 meaning that the word at position j is trans-lated right after the word at position i.Our WaW reordering model is strongly related tothat of Visweswariah et al(2011) ?
hereby calledTravelling Salesman Problem (TSP) model ?
withfew important differences: (i) we do not includein the features any explicit indication of the jumplength, in order to avoid the bias on short jumps;(ii) they train a linear model with MIRA (Cram-mer and Singer, 2003) by minimizing the number329of input words that get placed after the wrong po-sition, while we use a maximum-entropy classifiertrained by maximum-likelihood; (iii) they use anoff-the shelf TSP solver to find the best source sen-tence permutation and apply it as pre-processing totraining and test data.
By contrast, we integrate themaximum-entropy classifier directly into the SMTdecoder and let alits other models (phrase orien-tation, translation, target LM etc.)
contribute to thefinal reordering decision.3.1 FeaturesLike the TSP model (Visweswariah et al 2011),the WaW model builds on binary features similarto those typically employed for dependency parsing(McDonald et al 2005): namely, combinations ofsurface forms or POS tags of the words i and j andtheir context.
Our feature templates are presented inTable 1.
The main novelties with respect to the TSPmodel are the mixed word-POS templates (rows 16-17) and the shallow syntax features.
In particular, weuse the chunk types of i, j and their context (18-19),as well as the chunk head words of i and j (20).
Fi-nally we add a feature to indicate whether the wordsi and j belong to the same chunk (21).
The jumporientation ?
forward/backward ?
is included in thefeatures that represent the words comprised betweeni and j (rows 6, 7, 14, 15).
No explicit indication ofthe jump length is included in any feature.3.2 Training dataTo generate training data for the classifier, we firstextract reference reorderings from a word-alignedparallel corpus.
Given a parallel sentence, differ-ent heuristics may be used to convert arbitrary wordalignments to a source permutation (Birch et al2010; Feng et al 2010; Visweswariah et al 2011).Similarly to this last work, we compute for eachsource word fi the mean ai of the target positionsaligned to fi, then sort the source words accordingto this value.3 As a difference, though, we do notdiscard unaligned words but assign them the mean3Using the mean of the aligned indices makes the gener-ation of reference permutations more robust to alignment er-rors.
Admittedly, this heuristic does not handle well the case ofsource words that are correctly aligned to non-consecutive tar-get words.
However, this phenomenon is also not captured bystandard PSMT models, who only learn continuous phrases.i?2 i?1 i i+1 b j?1 j j+11 w w2 w w w3 w w w w4 w w w w5 w w w w6 w w w7 wall w w8 p p9 p p p10 p p p p11 p p p p12 p p p p13 p p p p p p14 p p p15 pall p p16 w p17 p w18 c c19 c c c c c c20 h h21 belong to same chunk(i, j)?w: word identity, p: POS tag, c: chunk type, h: chunk headTable 1: Feature templates used to learn whether a sourceposition j is to be translated right after i.
Positions com-prised between i and j are denoted by b and generate twofeature templates: one for each position (6 and 14) andone for the concatentation of them all (7 and 15).of their neighbouring words?
alignment means, sothat a complete permutation of the source sentence(?)
is obtained.
Table 2(a) illustrates this procedure.Given the reference permutation, we then gener-ate positive and negative training samples by simu-lating the decoding process.
We traverse the sourcepositions in the order defined by ?, keeping track ofthe positions that have already been covered and, foreach t : 1 ?
t ?
J , generate:?
one positive sample (R?t,?t+1=1) for thesource position that comes right after it,?
a negative sample (R?t,u=0) for each sourceposition in {u : ?t?
?+1 < u < ?t+?+1 ?u $= ?t+1} that has not yet been translated.Here, the sampling window ?
serves to control thesize of the training data and the proportion betweenpositive and negative samples.
Its value naturallycorrelates with the DL used in decoding.
The gener-ation of training samples is illustrated by Table 2(b).330(a) Converting word alignments to a permutation:source words are sorted by their target alnmentsmean a.
The unaligned word ?D?
is assigned themean of its neighbouring words?
a values (2 +5)/2 = 3.5 :(b) Generating binary samples by simulating thedecoding process: shaded rounds represent cov-ered positions, while dashed arrows representnegative samples:Table 2: The classifier?s training data generation process.3.3 Integration into phrase-based decodingRather than using the new reordering model fordata pre-processing as done by (Visweswariah et al2011), we directly integrate it into the PSMT de-coder Moses (Koehn et al 2007).Two main computation phases are required by theWaWmodel: (i) at system initialization time, all fea-ture weights are loaded into memory, and (ii) beforetranslating each new sentence, features are extractedfrom it and model probabilities are pre-computedfor each pair of source positions (i, j) such that|j ?
i ?
1| ?
DL.
Note that this efficient solutionis possible because our model does not employ de-coding history-based features, like the word that wastranslated before the last one, or like the previousjump legth.
This is an important difference with re-spect to the reordered source LM proposed by Fenget al(2010), which requires inclusion of the last ntranslated words in the decoder state.Fig.
1 illustrates the scoring process: when a par-tial translation hypothesis H is expanded by cover-ing a new source phrase f?
, the model returns thelog-probability of translating the words of f?
in thatparticular order, just after the last translated word ofH.
In details, this is done by converting the phrase-internal word alignment4 to a source permutation, injust the same way it was done to produce the model?straining examples.
Thus, the global score is inde-pendent from phrase segmentation, and normalizedacross outputs of different lengths: that is, the proba-bility of any complete hypothesis decomposes into Jfactors, where J is the length of the input sentence.The WaW reordering model is fully compatiblewith, and complementary to the lexicalized reorder-ing (phrase orientation) models included in Moses.Figure 1: Integrating the binary word reordering modelinto a phrase-based decoder: when a new phrase iscovered (dashed boxes), the model returns the log-probability of translating its words in the order definedby the phrase-internal word alignment.4 Early pruning of reordering stepsWe now explain how the WaW reordering model canbe used to dynamically refine the input permutationspace.
This method is not dependent on the particu-lar classifier described in this paper, but can in prin-ciple work with any device estimating the probabil-ity of translating a given input word after another.The method consists of querying the reorderingmodel at the time of hypothesis expansion, and fil-tering out hypotheses solely based on their reorder-ing score.
The rationale is to avoid costly hypoth-esis expansions for those source positions that thereordering model considers very unlikely to be cov-ered at a given point of decoding.
In practice, thisworks as follows:?
at each hypothesis expansion, we first enumer-ate the set of uncovered input positions thatare reachable within a fixed DL, and query theWaW reordering model for each of them5;4Phrase-internal alignments are provided in the phrase table.5The score used to prune a new word range f?
is the log prob-ability of translating the first aligned word of f?
right after thelast translated word of the current hypothesis.
See also Sect.
3.3.331?
only based on the WaW score, we apply his-togram and threshold pruning to this set andproceed to expand the non-pruned positions.Furthermore, it is possible to ensure that local re-orderings are always allowed, by setting a so-callednon-prunable-zone of width ?
around the last cov-ered input position.6According to how the DL, pruning parameters,and ?
are set, we can actually aim at different tar-gets: with a low DL, loose pruning parameters, and?=0 we can try to speed up search without sacrific-ing much translation quality.
With a high DL, strictpruning parameters, and a medium ?, we ensure thatthe standard medium-range reordering space is ex-plored, as well as those few long jumps that arepromising according to the reordering model.
In ourexperiments, we explore this second option with thesetting DL=18 and ?=5.The underlying idea is similar to that of earlypruning proposed by Moore and Quirk (2007),which consisted in discarding possible extensions ofa partial hypothesis based on their estimated scorebefore computing the exact language model score.Our technique too has the effect of introducing ad-ditional points at which the search space is pruned.However, while theirs was mainly an optimizationtechnique meant to avoid useless LM queries, we in-stead aim at refining the search space by exploitingthe fact that some SMT models are more importantthan others at different stages of the translation pro-cess.
Our approach actually involves a continuousalternation of two processes: during hypothesis ex-pansion the reordering score is combined with allother scores, while during early pruning some re-ordering decisions are taken only based on the re-ordering score.
In this way, we try to combine thebenefits of fully integrated reordering models withthose of monolingual pre-ordering methods.5 EvaluationWe test our approach on an Arabic-English newstranslation task where sentences are typically longand complex.
In this language pair, long reorder-ing errors mostly concern verbs, as all of Subject-Verb-Object (SVO), VSO and, more rarerly, VOS6See Bisazza (2013) for technical details on the integrationof word-level pruning with phrase-level hypothesis expansion.constructions are attested in modern written Ara-bic.
This issue is well known in the SMT field andwas addressed by several recent works, with deepor shallow parsing-based techniques (Green et al2009; Carpuat et al 2012; Andreas et al 2011;Bisazza et al 2012).
We question whether our ap-proach ?
which is not conceived to solve this spe-cific problem, nor requires manual rules to predictverb reordering ?
will succeed in improving long re-ordering in a fully data-driven way.As SMT training data, we use all the in-domainparallel data provided for the NIST-MT09 evalua-tion for a total of 986K sentence pairs (31M Englishwords).7 The target LM used to run the main se-ries of experiments is trained on the English side ofall available NIST-MT09 parallel data, UN included(147M words).
In the large-scale experiments, theLM training data also include the sections of the En-glish Gigaword that best fit to the development datain terms of perplexity: namely, the Agence France-Presse, Xinhua News Agency and Associated PressWorldstream sections (2130M words in total).For development and test, we use the newswiresections of the NIST benchmarks: dev06-nw, eval08-nw, eval09-nw consisting of 1033, 813, 586 sen-tences respectively.
Each set includes 4 referencetranslations and the average sentence length is 33words.
To focus the evaluation on problematic re-ordering, we also consider a subset of eval09-nwcontaining only sentences where the Arabic mainverb is placed before the subject (vs-09: 299 sent.
).8As pre-processing, we apply standard tokeniza-tion to the English data, while the Arabic data issegmented with AMIRA (Diab et al 2004) accord-ing to the ATB scheme9.
The same tool also pro-duces POS tagging and shallow syntax annotation.7The in-domain parallel data includes all the provided cor-pora except the UN proceedings, and the non-newswire parts ofthe small GALE-Y1-Q4 corpus (that is 9K sentences of audiotranscripts and web data).
As reported by Green et al(2010)the removal of UN data does not affect baseline performanceson the news benchmarks.8Automatically detected by means of shallow syntax rules.9The Arabic Treebank tokenization scheme isolates con-junctions w+ and f+, prepositions l+, k+, b+, future markers+, pronominal suffixes, but not the article Al+.3325.1 Reordering model intrinsic evaluationBefore proceeding to the SMT experiments, weevaluate the performance of the WaW reorder-ing model in isolation.
All the tested configura-tions are trained with the freely available MegaMToolkit10, implementing the conjugate gradientmethod (Hestenes and Stiefel, 1952), in maximum100 iterations.
Training samples are generatedwithin a sampling window of width ?=10, from asubset (30K sentences) of the parallel data describedabove, resulting in 8M training word pairs11.
Testsamples are generated from TIDES-MT04 (1324 sen-tences, 370K samples with ?=10), one of the corporaincluded in our SMT training data.
Features withless than 20 occurrences are ignored.Classification accuracy.
Table 3 presents preci-sion, recall, and F-score achieved by different fea-ture subsets, where W stands for word-based, P forPOS-based and C for chunk-based feature templates.We can see that all feature types contribute to im-prove the classifier?s performance.
The word-basedmodel achieves the highest precision but a very lowrecall, while the POS-based has much more bal-anced scores.
A better performance overall is ob-tained by combining word-, POS- and mixed word-POS-based features (62.6% F-score).
Finally, theaddition of chunk-based features yields a further im-provement of about 1 point, reaching 63.8% F-score.Given these results, we decide to use the W,P,Cmodel for the rest of the evaluation.Features (templates) P R FW [1-7] 73.1 16.4 26.8P [8-15] 69.5 54.8 61.3W,P [1-17] 70.2 56.5 62.6W,P,C [1-21] 70.6 58.1 63.8Table 3: Classification accuracy of the WaW reorderingmodel on TIDES-MT04, using different feature subsets.The template numbers refer to the rows of Table 1.Ranking accuracy.
A more important aspect toevaluate for our application is how well our model?sscores can rank a typical set of reordering options.In fact, the WaW model is not meant to be used as10http://www.cs.utah.edu/?hal/megam/ (Daume?
III, 2004).11This is the maximum number of samples manageable byMegaM.
However, even scaling from 4M to 8M was onlyslightly helpful in our experiments.
In the future we plan to testother learning approaches that scale better to large data sets.a stand-alone classifier, but as one of several SMTfeature functions.
Moreover, for early reorderingpruning to be effective, it is especially important thatthe correct reordering option be ranked in the top namong those available at the time of a given hypoth-esis expansion.
In order to measure this, we simulatethe decoding process by traversing the source wordsin target order and, for each of them, we examinethe ranking of all words that may be translated next(i. e. the uncovered positions within a given DL).We check how often the correct jump was rankedfirst (Top-1) or at most third (Top-3).
We also com-pute the latter score on long reorderings only (Top-3-long): i. e. backward jumps with distortion D>7and forward jumps with D>6.
In Table 4, resultsare compared with the ranking produced by standarddistortion, which always favors shorter jumps.
Twoconditions are considered: DL=10 corresponding tothe sampling window ?
used to produce the trainingdata, and DL=18 that is the maximum distortion ofjumps that will be considered in our early-pruningSMT experiment.Model DL DL-err Top-1 Top-3 Top-3-longback forw.Distortion 10 2.4 61.8 79.6 50.7 66.018 0.8 62.0 80.0 18.9 52.3WaW 10 2.4 71.2 91.2 76.4 69.318 0.8 71.2 91.8 68.0 51.8Table 4: Word-to-word jump ranking accuracy (%) ofstandard distortion and WaW reordering model, in dif-ferent DL conditions.
DL-err is the percentage of correctjumps beyond DL.
The test set consists of 40K reorderingdecisions: one for each source word in TIDES-MT04.We can see that, in terms of overall accuracies, theWaW reordering model outperforms standard distor-tion by a large margin (about 10% absolute).
Thisis an important result, considering that the jumplength, strongly correlating with the jump likeli-hood, is not directly known to our model.
As re-gards the DL, the higher limit naturally results in alower DL-error rate (percentage of correct jumps be-yond DL): namely 0.8% instead of 2.4%.
However,jump prediction becomes much harder: Top-3 accu-racy of long jumps by distortion drops from 50.7%to 18.9% (backward) and from 66.0% to 52.3% (for-ward).
Our model is remarkably robust to this effecton backward jumps, where it achieves 68.0% accu-333racy.
Due to the syntactic characteristics of Arabicand English, the typical long reordering pattern con-sists in (i) skipping a clause-initial Arabic verb, (ii)covering a long subject, then finally (iii) jumpingback to translate the verb and (iv) jumping forwardto continue translating the rest of the sentence (seeFig.
3 for an example).12 Deciding when to jumpback to cover the verb (iii) is the hardest part ofthis process, and that is precisely where our modelseems more helpful, while distortion always prefersto proceed monotonically achieving a very low ac-curacy of 18.9%.
In the case of long forward jumps(iv), instead, distortion is advantaged as the correctchoice typically corresponds to translating the firstuncovered position, that is the shortest jump avail-able from the last translated word.
Even here, ourmodel achieves an accuracy of 51.8%, only slightlylower than that of distortion (52.3%).In summary, the WaW reordering model signifi-cantly outperforms distortion in the ranking of longjumps.
In the large majority of cases, it is able torank a correct long jump in the top 3 reordering op-tions, which suggests that it can be effectively usedfor early reordering pruning.5.2 SMT experimental setupOur SMT systems are built with the Moses toolkit,while word alignment is produced by the Berke-ley Aligner (Liang et al 2006).
The baseline de-coder includes a phrase translation model, a lexi-calized reordering model, a 6-gram target languagemodel, distortion cost, word and phrase penalties.More specifically, the baseline reordering model is ahierarchical phrase orientation model (Tillmann,2004; Koehn et al 2005; Galley and Manning,2008) trained on all the available parallel data.
Thisvariant was shown to outperform the default word-based on an Arabic-English task.
To make our base-line even more competitive, we apply early distor-tion cost, as proposed by Moore and Quirk (2007).This function has the same value as the standard oneover a complete translation hypothesis, but it antic-ipates the gradual accumulation of the cost, mak-ing hypotheses of the same length more compara-ble to one another.
Note that this option has no ef-12Clearly, we would expect different figures from testing themodel on another language pair like German-English, where theverb is often postponed in the source with respect to the target.fect on the distortion limit, but only on the distor-tion cost feature function.
As proposed by Johnsonet al(2007), statistically improbable phrase pairsare removed from the translation model.
The lan-guage models are estimated by the IRSTLM toolkit(Federico et al 2008) with modified Kneser-Neysmoothing (Chen and Goodman, 1999).Feature weights are optimized by minimumBLEU-error training (Och, 2003) on dev06-nw.
Toreduce the effects of the optimizer instability, wetune each configuration four times and use the av-erage of the resulting weight vectors to translate thetest sets, as suggested by Cettolo et al(2011).Finally, eval08-nw is used to select the early prun-ing parameters for the last experiment, while eval09-nw is always reserved as blind test.5.3 Evaluation metricsWe evaluate global translation quality with BLEU(Papineni et al 2002) and METEOR (Banerjee andLavie, 2005).
These metrics, though, are only in-directly sensitive to word order, and especially un-likely to capture improvements at the level of long-range reordering.
For this reason, we also com-pute the Kendall Reordering Score or KRS (Birchet al 2010) which is a positive score based on theKendall?s Tau distance between the source-outputpermutation pi and the source-reference permuta-tions ?:KRS(pi,?)
= (1??K(pi,?))
?
BPK(pi,?)
=?ni=1?nj=1 d(i, j)12n(n?
1)d(i, j) ={1 if pii < pij and ?i > ?j0 otherwisewhere BP is a sentence-level brevity penalty, similarto that of BLEU.
The KRS is robust to lexical choicebecause it performs no comparison between outputand reference words, but only between the positionsof their translations.
Besides, it was shown to corre-late strongly with human judgements of fluency.Our work specifically addresses long-range re-ordering phenomena in language pairs where theseare quite rare, although crucial for preserving thesource text meaning.
Hence, an improvement at thislevel may not be detected by the general-purposemetrics.
We then develop a KRS variant that is only334sensitive to the positioning of specific input words.Assuming that each input word fi is assigned aweight ?i, the formula above is modified as follows:d?
(i, j) ={?i+?j if pii < pij and ?i > ?j0 otherwiseA similar element-weighted version of Kendall Tauwas proposed by Kumar and Vassilvitskii (2010) toevaluate document rankings in information retrieval.Because long reordering errors in Arabic-Englishmostly affect verbs, we set the weights to 1 for verbsand 0 for all other words to only capture verb re-ordering errors, and call the resulting metric KRS-V.The source-reference word alignments needed tocompute the reordering scores are generated by theBerkeley Aligner previously trained on the trainingdata.
Source-output word alignments are instead ob-tained from the decoder?s trace.5.4 Results and discussionTo motivate the choice of our baseline setup (earlydistortion cost and DL=8), we first compare the per-formance of standard and early distortion costs un-der various DL conditions.????????????????????????????????????????????????????
???
???
???
???????????????
?Figure 2: Standard vs early distortion cost results oneval08-nw under different distortion limits (DL), usingthe medium-size LM.
Best scores are on top-right corner.As shown in Fig.
2, most results are close to eachother in terms of BLEU and KRS, but early distor-tion consistently outperforms the standard one (sta-tistically significant).
The most striking differenceappears at a very high distortion limit (18), wherestandard distortion scores drop by more than 1 BLEUpoint and almost 7 KRS points!
Early distortion ismuch more robust (only -1 KRS when going fromDL=8 to DL=18), which makes our baseline systemespecially strong at the level of reordering.Table 5 presents the results obtained by integrat-ing the WaW reordering model as an additionalfeature function, and by applying early reorderingpruning.
The upper part of the table refers to themedium-scale evaluation, while the lower part refersto the large-scale evaluation.
In each part, statis-tical significance is computed against the baseline[B] by approximate randomization as in (Riezler andMaxwell, 2005).
Run times are obtained by an IntelXeon X5650 processor on the first 500 sentences ofeval08-nw, and exclude loading time of all models.Medium-scale evaluation.
Integrating the WaWmodel as an additional feature function results insmall but consistent improvements in all DL condi-tions, which shows that this type of model conveysinformation that is missing from the state-of-the-artreordering models.
As regards efficiency, the newmodel makes decoding time increase by 8%.Among the DL settings considered, DL=8 is con-firmed as the optimal one ?
with or without WaWmodel.
Raising the DL to 18 with no special prun-ing has a negative impact on both translation qualityand efficiency.
The effect is especially visible on thereordering scores: that is, from 84.7 to 83.9 KRS andfrom 86.2 to 85.8 KRS-V on eval09-nw.
Run timesare almost doubled: from 87 to 164 and from 94 to178 ms/word, that is a 89% increase.We then proceed to the last experiment where thereordering space is dynamically pruned based onthe WaW model score.
As explained in Sect.
4, anon-prunable-zone of width ?=5 is set around thelast covered position.
To set the early pruning pa-rameters, we perform a grid search over the values(1, 2, 3, 4, 5) for histogram and (0.5, 0.25, 0.1) forrelative threshold, and select the values that achievethe best BLEU and KRS on eval08-nw, namely 3 (his-togram) and 0.1 (threshold).
The resulting configu-ration is then re-optimized by MERT on dev06-nw.This setting implies that, at a given point of decod-ing where i is the last covered position, a new wordcan be translated only if:?
it lies within a DL of 5 from i, or?
it lies within a DL of 18 from i and its WaWreordering score is among the top 3 and at leastequal to 1/10 of the best score (in linear space).As shown in Table 5, early pruning achieves thebest results overall: despite the high DL, we report335DL Reo.models eval08-nw eval09-nw vs-09 ms/bleu met krs krs-V bleu met krs krs-V krs-V wordUsing the medium-size LM (147M English tokens):5 hier.lexreo, early disto 44.7 35.1!
83.0!
84.7!
50.3" 38.1 84.6 85.9 84.7 59+ WaW model 44.8 35.1 83.7 85.4 51.0# 38.3# 85.1# 86.6$ 85.5# 648 hier.lexreo, early disto[B] 44.8 35.2 83.4 85.6 50.6 38.1 84.7 86.2 84.8 87+ WaW model 45.0 35.2 83.7$ 85.9 51.1# 38.3# 85.1# 86.8# 85.8# 9418hier.lexreo, early disto 44.7 34.9!
82.4!
84.9!
50.3 38.0" 83.9!
85.8" 84.3" 164+ WaW model 44.8 35.2 82.7!
85.5 51.0$ 38.3# 84.2" 86.2 85.2 178+ early reo.pruning(?=5) 45.0 35.3 83.7$ 86.3# 50.9 38.3# 84.9 87.0# 86.2# 68Using the large interpolated LM (2130M English tokens) and double beam-size:8 hier.lexreo, early disto[B] 46.3 35.0 83.2 85.0 51.6 38.3 84.5 85.8 84.5 257918 hier.lexreo, early disto 45.9" 34.9!
81.7!
84.1!
51.4 38.1!
83.0!
84.6!
83.1!
5462+WaW+reo.pruning(?=5) 46.3 35.2 83.4 85.7# 52.8# 38.6# 84.6 86.6# 85.5# 1588Table 5: Effects of WaW reordering modeling and early reordering pruning on translation quality, measured with% BLEU, METEOR, and Kendall Reordering Score: regular (KRS) and verb-specific (KRS-V).
Statistically significantdifferences with respect to the baseline [B] are marked with #!
at the p ?
.05 level and $" at the p ?
.10 level.Decoding time is measured in milliseconds per input word.no loss in BLEU, METEOR and KRS, but we actuallysee several improvements.
In particular, the gains onthe blind test eval09-nw are +0.3 BLEU, +0.2 ME-TEOR and +0.2 KRS (only METEOR is significant).While these gains are admittedly small, we recallthat our techniques affect rare and isolated eventswhich can hardly emerge from the general-purposeevaluation metrics.
Moreover, to our knowledge,this is the first time that a PSMT system is shown tomaintain a good performance on this language pairwhile admitting very long-range reorderings.Finally and more importantly, the reordering ofverbs improves significantly on both generic testsand on the VS- sentence subset (vs-09): namely, inthe latter, we achieve a notable gain of 1.4 KRS-V.Efficiency is also largely improved by our earlyreordering pruning technique: decoding time is re-duced to 68 ms/word, corresponding to a 22%speed-up over the baseline.Large-scale evaluation.
We also investigatewhether our methods can be useful in a scenariowhere efficiency is less important and more datais available for training.
To this end, we build avery large LM by interpolating the main LM withthree other LMs trained on different Gigaword sec-tions (see Sect.
5).
Moreover, we relax the decoder?sbeam size from the default value of 200 to 400 hy-potheses, to reduce the risk of search errors and ob-tain the best possible baseline performance.By comparing the large-scale with the medium-scale baseline in Table 5, we note that the additionof LM data is especially beneficial for BLEU (+1.5on eval08-nw and +1.0 on eval09-nw), but not asmuch for the other metrics, which challenges thecommonly held idea that more data always improvestranslation quality.Here too, relaxing the DL without special pruninghurts not only efficiency but also translation qual-ity: all the scores decrease considerably, showingthat even the stronger LM is not sufficient to guidesearch through a very large reordering search space.As for our enhanced system, it achieves simi-lar gains as in the medium-scale scenario: that is,BLEU and METEOR are preserved or slightly im-proved despite the very high DL, while all the re-ordering scores increase.
In particular, we report sta-tistically significant improvements in the reorderingof verbs, which is where the impact of our method isexpected to concentrate (+0.7, +0.8 and +1.0 KRS-Von eval08-nw, eval09-nw and vs-09, respectively).These results confirm the usefulness of ourmethod not only as an optimization technique, butalso as a way to improve translation quality on topof a very strong baseline.336SRC!
!
! "
#$!%&' ( )*+, -.
/0$%&' &-1!
2 +1 +03* +045(67!8 +9# +77!
5 :65 &-3*;24<5( &-73!
045( &-=>?
@A ( 0B* +CD EF(23*verb subj.
obj.
compl.ywASl sfyr Almmlkp AlErbyp AlsEwdyp ldY lbnAn EbdAlEzyz xwjp tHrk -h fy AtjAh ...continues ambassador Kingdom Arabian Saudi to Lebanon Abdulaziz Khawja move his in directionREF The Kingdom of Saudi Arabia ?s ambassador to Lebanon Abdulaziz Khawja continues his moves towards ...BASE continue to Saudi Arabian ambassador to Lebanon , Abdulaziz Khwja its move in the direction of ...NEW The Kingdom of Saudi Arabia ?s ambassador to Lebanon , Abdulaziz Khwja continue its move in the direction of ...SRC;#7*$G'( H( +0&B5 ( )I( E4 J<K 65# +L M#NL &-O01 P5 )*QR#7*<5( S!&7=@A ( TU*V3W XY.
#8; #?7* +,adv.
verb obj.
subj.
compl.fymA dEA -hm r}ys Almktb AlsyAsy l- Hrkp HmAs xAld m$El AlY AltzAm AlHyAdmeanwhile called them head bureau political of movement Hamas Khaled Mashal to necessity neutralityREF Meanwhile, the Head of the Political Bureau of the Hamas movement, Khaled Mashal, called upon them to remain neutralBASE The called them, head of Hamas?
political bureau, Khalid Mashal, to remain neutralNEW The head of Hamas?
political bureau, Khalid Mashal, called on them to remain neutralFigure 3: Long reordering examples showing improvements over the baseline system (BASE) when the DL is raised to18 and early pruning based on WaW reordering scores is enabled (NEW).Long jumps statistics and examples.
To betterunderstand the behavior of the early-pruning system,we extract phrase-to-phrase jump statistics from thedecoder log file.
We find that 132 jumps beyond thenon-prunable zone (D>5) were performed to trans-late the 586 sentences of eval09-nw; 38 out of thesewere longer than 8 and mostly concentrated on theVS- sentence subset (27 jumps D>8 performed invs-09).13 This and the higher reordering scores sug-gest that long jumps are mainly carried out to cor-rectly reorder clause-inital verbs over long subjects.Fig.
3 shows two Arabic sentences taken fromeval09-nw, that were erroneuously reordered by thebaseline system.
The system including the WaWmodel and early reordering pruning, instead, pro-duced the correct translation.
The first sentence isa typical example of VSO order with a long subject:while the baseline system left the verb in its Ara-bic position, producing an incomprehensible trans-lation, the new system placed it rightly between theEnglish subject and object.
This reordering involvedtwo long jumps: one with D=9 backward and onewith D=8 forward.The second sentence displays another, less com-mon, Arabic construction: namely VOS, with a per-sonal pronoun object.
In this case, a backward jumpwith D=10 and a forward jump with D=8 were nec-essary to achieve the correct reordering.13Statistics computed on the medium-LM system.6 ConclusionsWe have trained a discriminative model to predictlikely reordering steps in a way that is complemen-tary to state-of-the-art PSMT reordering models.
Wehave effectively integrated it into a PSMT decoder asadditional feature, ensuring that its total score over acomplete translation hypothesis is consistent acrossdifferent phrase segmentations.
Lastly, we have pro-posed early reordering pruning as a novel methodto dynamically shape the input reordering space andcapture long-range reordering phenomena that areoften critical when translating between languageswith different syntactic structures.Evaluated on a popular Arabic-English newstranslation task against a strong baseline, our ap-proach leads to similar or even higher BLEU, ME-TEOR and KRS scores at a very high distortion limit(18), which is by itself an important achievement.At the same time, the reordering of verbs, measuredwith a novel version of the KRS, is consistently im-proved, while decoding gets significantly faster.
Theimprovements are also confirmed when a very largeLM is used and the decoder?s beam size is dou-bled, which shows that our method reduces not onlysearch errors but also model errors even when base-line models are very strong.Word reordering is probably the most difficult as-pect of SMT and an important factor of both its qual-ity and efficiency.
Given its strong interaction withthe other aspects of SMT, it appears natural to solve337word reordering during decoding, rather than beforeor after it.
To date, however, this objective was onlypartially achieved.
We believe there is a promisingway to go between fully-integrated reordering mod-els and monolingual pre-ordering methods.
Thiswork has started to explore it.AknowledgmentsThis work was partially funded by the EuropeanUnion FP7 grant agreement 287658 (EU-BRIDGE).ReferencesYaser Al-Onaizan and Kishore Papineni.
2006.
Distor-tion models for statistical machine translation.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and 44th Annual Meeting ofthe Association for Computational Linguistics, pages529?536, Sydney, Australia, July.Jacob Andreas, Nizar Habash, and Owen Rambow.
2011.Fuzzy syntactic reordering for phrase-based statisticalmachine translation.
In Proceedings of the Sixth Work-shop on Statistical Machine Translation, pages 227?236, Edinburgh, Scotland, July.Satanjeev Banerjee and Alon Lavie.
2005.
METEOR:An automatic metric for MT evaluation with improvedcorrelation with human judgments.
In Proceedings ofthe ACL Workshop on Intrinsic and Extrinsic Evalu-ation Measures for Machine Translation and/or Sum-marization, pages 65?72, Ann Arbor, Michigan, June.A.
L. Berger, P. F. Brown, S. A. Della Pietra, V. J. DellaPietra, J. R. Gillett, A. S. Kehler, and R. L. Mercer.1996.
Language translation apparatus and method ofusing context-based translation models.
United StatesPatent, No.
5510981, Apr.Alexandra Birch, Phil Blunsom, and Miles Osborne.2009.
A quantitative analysis of reordering phenom-ena.
In StatMT ?09: Proceedings of the Fourth Work-shop on Statistical Machine Translation, pages 197?205, Morristown, NJ, USA.Alexandra Birch, Miles Osborne, and Phil Blunsom.2010.
Metrics for MT evaluation: evaluating reorder-ing.
Machine Translation, 24(1):15?26.Arianna Bisazza and Marcello Federico.
2012.
Modi-fied distortion matrices for phrase-based statistical ma-chine translation.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics (Volume 1: Long Papers), pages 478?487, Jeju Is-land, Korea, July.Arianna Bisazza, Daniele Pighin, and Marcello Fed-erico.
2012.
Chunk-lattices for verb reordering inArabic-English statistical machine translation.
Ma-chine Translation, Special Issue on MT for Arabic,26(1-2):85?103.Arianna Bisazza.
2013.
Linguistically Motivated Re-ordering Modeling for Phrase-Based Statistical Ma-chine Translation.
Ph.D. thesis, University of Trento.http://eprints-phd.biblio.unitn.it/1019/.Marine Carpuat, Yuval Marton, and Nizar Habash.
2012.Improved Arabic-to-English statistical machine trans-lation by reordering post-verbal subjects for wordalignment.
Machine Translation, Special Issue on MTfor Arabic, 26(1-2):105?120.Mauro Cettolo, Nicola Bertoldi, and Marcello Federico.2011.
Methods for smoothing the optimizer instabilityin SMT.
In MT Summit XIII: the Thirteenth MachineTranslation Summit, pages 32?39, Xiamen, China.Stanley F. Chen and Joshua Goodman.
1999.
An empiri-cal study of smoothing techniques for language model-ing.
Computer Speech and Language, 4(13):359?393.Marta R. Costa-jussa` and Jose?
A. R. Fonollosa.
2009.State-of-the-art word reordering approaches in statisti-cal machine translation: A survey.
IEICE TRANSAC-TIONS on Information and Systems, E92-D(11):2179?2185.Koby Crammer and Yoram Singer.
2003.
Ultraconser-vative online algorithms for multiclass problems.
J.Mach.
Learn.
Res., 3:951?991, March.Hal Daume?
III.
2004.
Notes on CG and LM-BFGS op-timization of logistic regression.
Paper available athttp://pub.hal3.name, implementation avail-able at http://hal3.name/megam.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004.Automatic Tagging of Arabic Text: From Raw Text toBase Phrase Chunks.
In Daniel Marcu Susan Dumaisand Salim Roukos, editors, HLT-NAACL 2004: ShortPapers, pages 149?152, Boston, Massachusetts, USA.Marcello Federico, Nicola Bertoldi, and Mauro Cettolo.2008.
IRSTLM: an Open Source Toolkit for HandlingLarge Scale Language Models.
In Proceedings of In-terspeech, pages 1618?1621, Melbourne, Australia.Minwei Feng, Arne Mauser, and Hermann Ney.
2010.A source-side decoding sequence model for statisti-cal machine translation.
In Conference of the Associa-tion for Machine Translation in the Americas (AMTA),Denver, Colorado, USA.Michel Galley and Christopher D. Manning.
2008.
Asimple and effective hierarchical phrase reorderingmodel.
In EMNLP ?08: Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 848?856, Morristown, NJ, USA.Spence Green, Conal Sathi, and Christopher D. Man-ning.
2009.
NP subject detection in verb-initial Ara-bic clauses.
In Proceedings of the Third Workshop338on Computational Approaches to Arabic Script-basedLanguages (CAASL3), Ottawa, Canada.Spence Green, Michel Galley, and Christopher D. Man-ning.
2010.
Improved models of distortion cost forstatistical machine translation.
In Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the Association for Com-putational Linguistics (NAACL), pages 867?875, LosAngeles, California.Magnus R. Hestenes and Eduard Stiefel.
1952.
Meth-ods of conjugate gradients for solving linear systems.Journal of Research of the National Bureau of Stan-dards, 49(6):409?436.H.
Johnson, J. Martin, G. Foster, and R. Kuhn.
2007.
Im-proving translation quality by discarding most of thephrasetable.
In In Proceedings of EMNLP-CoNLL 07,pages 967?975.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT-NAACL 2003, pages 127?133, Edmonton,Canada.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne, andDavid Talbot.
2005.
Edinburgh system descriptionfor the 2005 IWSLT speech translation evaluation.
InProc.
of the International Workshop on Spoken Lan-guage Translation, October.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180,Prague, Czech Republic.Ravi Kumar and Sergei Vassilvitskii.
2010.
General-ized distances between rankings.
In Proceedings ofthe 19th international conference on World Wide Web,pages 571?580, New York, NY, USA.
ACM.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, MainConference, pages 104?111, New York City, USA,June.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective dependency parsingusing spanning tree algorithms.
In Proceedings of theconference on Human Language Technology and Em-pirical Methods in Natural Language Processing, HLT?05, pages 523?530, Stroudsburg, PA, USA.Robert C. Moore and Chris Quirk.
2007.
Faster beam-search decoding for phrasal statistical machine transla-tion.
In In Proceedings of MT Summit XI, pages 321?327, Copenhagen, Denmark.F.
Och and H. Ney.
2002.
Discriminative trainingand maximum entropy models for statistical machinetranslation.
In Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 295?302, Philadelhpia, PA.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Erhard Hinrichsand Dan Roth, editors, Proceedings of the 41st AnnualMeeting of the Association for Computational Linguis-tics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association of Compu-tational Linguistics (ACL), pages 311?318, Philadel-phia, PA.Stefan Riezler and John T. Maxwell.
2005.
On somepitfalls in automatic evaluation and significance test-ing for MT.
In Proceedings of the ACL Workshop onIntrinsic and Extrinsic Evaluation Measures for Ma-chine Translation and/or Summarization, pages 57?64, Ann Arbor, Michigan, June.Christoph Tillmann.
2004.
A Unigram OrientationModel for Statistical Machine Translation.
In Pro-ceedings of the Joint Conference on Human LanguageTechnologies and the Annual Meeting of the NorthAmerican Chapter of the Association of Computa-tional Linguistics (HLT-NAACL).Karthik Visweswariah, Rajakrishnan Rajkumar, AnkurGandhe, Ananthakrishnan Ramanathan, and JiriNavratil.
2011.
A word reordering model for im-proved machine translation.
In Proceedings of the2011 Conference on Empirical Methods in Natu-ral Language Processing, pages 486?496, Edinburgh,Scotland, UK., July.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?403.Sirvan Yahyaei and Christof Monz.
2010.
Dynamic dis-tortion in a discriminative reordering model for sta-tistical machine translation.
In International Work-shop on Spoken Language Translation (IWSLT), Paris,France.Richard Zens and Hermann Ney.
2006.
Discriminativereordering models for statistical machine translation.In Proceedings on the Workshop on Statistical Ma-chine Translation, pages 55?63, New York City, June.R.
Zens, F. J. Och, and H. Ney.
2002.
Phrase-based sta-tistical machine translation.
In 25th German Confer-ence on Artificial Intelligence (KI2002), pages 18?32,Aachen, Germany.
Springer Verlag.339340
