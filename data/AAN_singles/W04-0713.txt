An Algorithm for Resolving Individual and Abstract Anaphora inDanish Texts and DialoguesCostanza NavarrettaCenter for SprogteknologiNjalsgade 80,2300 Copenhagen Scostanza@cst.dkAbstractThis paper describes the dar-algorithm for re-solving intersentential pronominal anaphors re-ferring to individual and abstract entities inDanish texts and dialogues.
Individual enti-ties are resolved combining models which iden-tify high degree of salience with high degree ofgivenness (topicality) of entities in the hearer?scognitive model, e.g.
(Grosz et al, 1995), withHajic?ova?
et al?s (1990) salience account whichassigns the highest degree of salience to entitiesin the focal part of an utterance in InformationStructure terms.
These focal entities often in-troduce new information in discourse.
Anaph-ors referring to abstract entities are resolvedwith an extension of the algorithm presentedby Eckert and Strube (2000).
Manual tests ofthe dar-algorithm and other well-known reso-lution algorithms on the same data show thatdar performs significantly better on most typesof anaphor.1 IntroductionMost intersentential anaphor resolution al-gorithms exclusively account for pronominalanaphors with individual nominal antecedents(henceforth IPAs) in texts.
Less attentionhas been given to pronominal anaphors whichrefer to abstract entities evoked by verbalphrases, clauses or discourse segments (hence-forth APAs).
However APAs are quite com-mon in English dialogues, see i.a.
(Byron andAllen, 1998).
Recently two algorithms for re-solving APAs and IPAs in specific English dia-logues have been proposed: Eckert and Strube?s(2000) es00, Byron?s (2002) phora.
APAsare also frequent in Danish.
We found that15% of all pronominal anaphors in our textswere APAs, while they constituted 48% of theanaphors in the analysed dialogues.
Further-more third-person singular pronouns in neutergender which can be IPAs or APAs were APAsin two-third of the cases in both texts and dia-logues.In this paper we describe an algorithm, calleddar, for resolving intersentential IPAs andAPAs in Danish.1 Unlike es00 and phora,dar applies to both texts and dialogues.Differing from most resolution algorithms,dar correctly accounts for the resolution of pro-nouns referring to newly introduced informa-tion, as it is the case in examples (1) and (2).
(1) [Chefen]i fik kun [en s?n]k og [han]k gadi hvert fald ikke videref?re familieforetagendet.
[pid]([The boss]i had only [one son]k and [he]k surelydid not want to carry on the family business.
)(2) A: hvem...hvem arbejdede [din mor]i med?
(with whom... whom did [your mother]i work)B: [Hun]i arbejdede med [vores nabo]k([She]i worked with [our neighbour]k)[Hun]k var enke ... havde tre s?nner [bysoc]([She]k was a widow... had three sons)In (1) the antecedent of the pronoun han(he) is the indefinite object and not the more?given?
definite subject.
In (2) the antecedentof the second occurrence of the pronoun hun(she) is the object vores nabo (our neighbour)which provides the information requested in thepreceding question.
This nominal is assignedlower prominence than the subject pronoun hun(she) in most salience models.
To account forthis type of data the dar-algorithm proposes anovel strategy combining two apparently con-trasting accounts of salience of entities (Navar-retta, 2002a).
The first account, e.g.
(Grosz etal., 1995), assigns the highest degree of salienceto the most known (topical) entities in the dis-course model, the second assigns the highest de-gree of salience to entities in the focal part of ut-terances in Information Structure terms which,often, represent new information (Hajic?ova?
et1dar presupposes that intrasentential anaphors arecorrectly resolved.
At present no resolution algorithmaccounts for all uses of Danish intrasentential pronouns.al., 1990).dar was developed on the basis of the usesof pronouns in three text collections and threecorpora of naturally-occurring dialogues.
Thetexts comprise computer manuals, henceforthedb, novels and newspaper articles.
The dia-logue collections are sl (Duncker and Hermann,1996), consisting of recorded conversations be-tween GPs and their patients, the bysoc cor-pus (Gregersen and Pedersen, 1991) and the pidcorpus (Jensen, 1989) both containing recordedconversations about everyday subjects.In the paper we first present related work(section 2) then we discuss the background forour proposal (section 3).
In section 4 the dar-algorithm is described.
In section 5 we presentsome tests of the algorithm, evaluate it andcompare its performance with the performanceof other known algorithms.
Finally, in section 6,we make some concluding remarks.2 Related WorkThe two algorithms for resolving IPAs andAPAs in English dialogues, es00 and phora,recognise IPAs and APAs on the basis of se-mantic constraints on the argument position oc-cupied by the anaphors.
Both algorithms ac-count for differences in reference between per-sonal and demonstrative pronouns.
In es00demonstrative pronouns preferentially refer toabstract entities, while personal pronouns pref-erentially refer to individual ones.
es00 re-solves IPAs applying Strube?s (1998) algorithm.In phora the antecedents of personal pro-nouns are searched for looking at their degreeof salience which is implemented by word orderas in (Grosz et al, 1995).
Demonstratives, in-stead, are searched for in the list of activatedentities (Gundel et al, 1993) containing nonNP antecedents, which are assumed to be lesssalient.
In phora demonstratives can also referto Kinds.es00 requires that the structure of dialogueshas been marked.
Byron?s phora-algorithmdoes not rely on predefined dialogue structure,but only searches for abstract antecedents ofAPAs in the sentence preceding the anaphor.Thus it does not account for APAs referring tolarger discourse segments.
phora relies on bothsemantic knowledge and a model of speech actsand accounts for more phenomena than es00.Differing from es00, phora has been imple-mented.
A very different strategy for resolv-ing IPAs and APAs in spoken dialogues is pro-posed in (Strube and Mu?ller, 2003).
We will notfurther discuss this proposal, but Strube andMu?ller?s machine learning approach is an inter-esting attempt to automatically resolve anaph-ors without relying on any domain specific re-source or preannotated data.3 Background for DARIn most applied approaches pronominal anaph-ora resolution is equivalent to determiningthe antecedent domain and choosing the mostprominent or salient antecedent among possi-ble candidates.
Although there is not always anidentity relation between linguistic antecedentsand referents, we also follow this strategy, wellaware that it is particularly problematic forAPAs.
In fact, the same linguistic expressioncan evoke different abstract objects dependingon the context in which the APA occurs, see(Webber, 1991).Determining the degree of salience of dis-course elements, henceforth DEs, is essential toanaphor resolution because personal pronounsrefer to the most salient candidate antecedentthat matches the given predication (Sidner,1983).
Nearly all salience-based models iden-tify high degree of salience with high degree ofgivenness of DEs.
In fact, although the vari-ous algorithms use different criteria for rankingDEs such as linear order, hierarchy of grammat-ical roles, information structure, Prince?s Famil-iarity Scale (Prince, 1981), they all assign thehighest prominence to the DEs which are mosttopical, known, bound, familiar and thus given,i.a.
(Grosz et al, 1995; Brennan et al, 1987;Strube and Hahn, 1996; Strube, 1998).
Grosz etal.
(1995) also suggest that continuing speakingabout the same elements in a discourse segmentis perceived as more coherent than shifting thefocus of attention.
They implement this by thefollowing ranking of transition states:continue > retain > shift.One salience model departs from the given-ness2 assumption.
It has been proposed byHajic?ova?
et al (1990) and assigns the highestdegree of salience to DEs in the focal part of anutterance in information structure terms (Sgallet al, 1986).
These entities often represent newinformation.
Hajic?ova?
et al?s approach is orig-inal and can account for the data in (1) and(2).
However, it is problematic from an appliedpoint of view.
In the first place it is difficult to2Here givenness subsumes concepts such as topicalityand familiarity.determine the information structure of all ut-terances.
Secondly, focal candidate antecedentsare ranked highest in Hajic?ova?
et al?s model,but they still compete with given candidate an-tecedents in their system.
Finally the data doesnot confirm that all entities in the focal part ofan utterance have the highest degree of accessi-bility.We agree with Hajic?ova?
?s insight, but in orderto operationalise the role of focality in resolu-tion in a reliable way we propose the following.Accessibility by default is connected with given-ness as assumed in most resolution algorithms.However, speakers can explicitly change the de-gree of accessibility of entities in discourse bymarking them as salient with information struc-ture related devices.
These entities representthe main focus of an utterance, have the high-est degree of salience and are, in the majorityof cases, the preferred antecedents of anaphors.In these cases the shift of focus of attention is,in our opinion, as coherent as continuing speak-ing about the same entities, because it is prean-nounced to the addressee.
On the basis of thedata we propose a list of identifiable construc-tions in which explicit focus marking occurs andthe focalDEs have the highest degree of saliencein our data.3 Examples from the list are the fol-lowing:a: Entities referred to by NPs which are focallymarked structurally.
In Danish this markingoccurs in clefts, existential and topicalised con-structions.4b: Entities referred to by NPs that follow fo-cusing adverbs, as in (1).c: Entities focally marked by the prosody (ifthis information is available) and/or entitiesproviding the information requested in ques-tions, as in (2).The hierarchy of verbal complements canmodel givenness preference in Danish.
As inEnglish pronouns have high givenness degree(pronominal chain preference).
In addition tosalience preferences we found that parallelismcan account for numerous uses of Danish anaph-ors.
According to parallelism in adjacent utter-ances with parallel grammatical complements,the preferred antecedent of an anaphor in thesecond utterance is the linguistic expression in3Many of these constructions are also studied in theInformation Structure literature and in some studies onanaphora.4Nominals in clefts are also assigned high salience ine.g.
(Sidner, 1983).the first utterance with the same grammaticalfunction.
Inspired by the work of (Kameyama,1996) we have defined a preference interactionmodel to be used in resolution.
Our model isgiven in figure 1.5 The interaction model statesthat givenness preferences are overridden by fo-cality preference, when in conflict, and that theyall are overridden by parallelism.
Also in Dan-Parallelism ?
Focality ?
Pronominal chain ?GivennessFigure 1: Interaction of preferencesish demonstrative and personal pronouns referto entities with different status in the discoursemodel.
Weak (cliticised and unstressed) pro-nouns usually refer to the most salient entity inthe utterance.
Strong (stressed and demonstra-tive) pronouns emphasise or put in contrast theentities they refer to and/or indicate that theirantecedents are not the most expected ones.6Demonstratives preferentially refer to abstractentities, while personal pronouns preferentiallyrefer to individual entities in ambiguous con-texts.
All these differences are implemented indar.Approx.
half of the APA occurrences in ourdialogues refer to entities evoked by larger dis-course segments (more turn takings).
Thus wefollow Eckert and Strube?s approach of mark-ing the structure of dialogues and searching forAPA antecedents in the right frontier of the dis-course tree (Webber, 1991).
dar presupposesdifferent discourse structures for texts and dia-logues.dar follows the es00 and phora strategyof discriminating between IPAs and APAs byrules looking at the semantic constraints onthe predication contexts in which the anaphorsoccur.
dar relies on many more discriminat-ing rules than es00.
These rules were definedanalysing large amounts of data and using theencodings of the Danish parole computationallexicon (Braasch et al, 1998; Navarretta, 1997).dar uses language-specific rules to account5The interaction model was defined on the basis ofthe data and the results of a survey of pronominal uses.Commonsense preferences which override all the otherpreferences (see inter alia (Hobbs, 1983) are not imple-mented.6The most frequent Danish third person singular gen-der pronoun det can both be a personal pronoun (cor-responding to it) and a demonstrative pronoun (corre-sponding to this/that).
In the latter case it is alwaysstressed.for Danish APAs.
These occur in much morecontexts than in English where elliptical con-structions or other anaphors such as too and soare used.
Examples of Danish-specific uses ofabstract anaphors are given in (3) and (4).
(3) Han var sulten.
Det var jeg ikke.
[pid](lit.
He was hungry.
That was I not.
)(My friends were hungry.
I wasn?t.
)(4) Han kunne sv?mme, men det kunne hunikke.(lit.
He could swim, but it could she not.
)(He could swim, but she couldn?t.
)A language-specific rule recognising APAs isthe following: constructions with modal verbsand an object, such as x skal man (lit.
x shallone) (one shall), x vil man (lit.
x will one) (onewill).An example of a rule identifying IPAs is thefollowing: adjectival constructions in which theprepositional complement only subcategorisesfor concrete entities such as let for x (easy forx), fuld af x (full of x).4 The DAR-algorithm4.1 Search Space and DE listsdar presupposes the discourse structure de-scribed by Grosz and Sidner (1986).
The min-imal discourse unit is the utterance U .
Para-graphs correspond to discourse segments intexts.
Discourse segments in dialogues weremanually marked.
The dialogues were struc-tured with Synchronising Units (SU) accordingto the definitions in es00.The immediate antecedent search space of apronoun x in utterance Un is the previous utter-ance, Un?1.
If Un is the first component in SUmin dialogues the immediate search space for x isSUm?1.
dar assumes two antecedent domainsdepending on whether the pronoun has or hasnot been recognised as an IPA.
The antecedentdomain for IPAs is first Un?1 and then the pre-ceding utterances in the right frontier of the dis-course tree searched for in recency order.7 Theantecedent domain for APAs or anaphors whichcan both be IPAs and APAs is Un?1.dar operates on two lists of DEs, the Ilistand the Alist.
The Ilist contains the NPs re-ferred to in Un?1 ranked according to their de-gree of salience and enriched with informationon gender, number, animacy and other sim-ple semantic types necessary to implement se-lectional restrictions.
In the Ilist information7The search space in es00 is the preceding utterancefor all pronouns.1 A-list2 within same U , I in dialogues,: clause to theleft of the clause containing the anaphor3 within previous U (I): rightmost main clauseand subordinate clauses to its right4 within previous Us (Is): rightmost completesentenceFigure 3: The es00 context rankingabout the grammatical role of nominals is pro-vided and strongly focally marked elements areindicated.
The leftmost element in the Ilist isthe most salient one.
Givenness and focalitypreferences are accounted for in the Ilist, as il-lustrated in figure 2.
Focally marked entitiesare put in front of the list while the remainingDEs are ordered according to verbal comple-ment order.
Inside verbal complements nom-inals are ordered according to their occurrenceorder as illustrated in the second row of figure 2.The abstract entities which are referred to byan APA in Un?1 or SUm?1 are encoded in theAlist.
They are removed from the list after anew utterance (SU in dialogues) has been pro-cessed if they have not been mentioned in it.The context ranking for abstract entities is thatproposed by Eckert and Strube (2000) and isgiven in figure 3.4.2 The Algorithmdar consists of two different functions Re-solveDet and ResolveIpa.
The former is ap-plied if the actual pronoun x is third personsingular neuter, while the latter is applied in allthe remaining cases:if x is singular & neuterthen go to ResolveDet(x)else go to ResolveIpa(x)ResolveIpa takes the IPA x as argument andlooks for possible antecedents in the Ilist forthe preceding Un?1 or Sm?1, after having ap-plied syntactic constraints and selectional re-strictions on the elements of the list.
Three dif-ferent cases are considered: (A) no antecedenthas been found in the immediate search space;(B) one antecedent has been found; (C) moreantecedents have been found.If no antecedent has been found (case A),ResolveIpa looks for the highest ranked an-tecedent in recency order in the Ilists of thepreceding discourse.
If an antecedent is foundthe algorithm returns it.
If no antecedent isFOCAL MARKED > SUBJECT > OBJECT/PrepOBJECT > OBJECT 2 > OTHERCOMPLS > ADJUNCTS??????????????????????????????????????
?NCOMPL1 >prec NCOMPL2 >prec .
.
.>prec NCOMPLnFigure 2: Order of DEs in the Ilistfound, x is classified as inferable.8 If one an-tecedent is found (case B), it is returned.
Ifmore candidate antecedents are found (case C),ResolveIpa performs tests, implementing thepreference interaction model described in sec-tion 3, as follows.
If Un and Un?1 are paral-lel9 and one of the candidate antecedents hasthe same grammatical role in Un?1 as x in Un,this ?parallel?
antecedent is marked.
In the re-maining cases the algorithm marks the highestranked candidate in the Ilist.
Pronouns are pre-ferred, unless there are focally marked candi-date antecedents.
At this point the algorithmindividuates the preferred antecedent on the ba-sis of x?s type.
If x is weak the marked candi-date proposed in the preceding steps is returnedtogether with the list of the remaining candi-date antecedents (possible ambiguity).
If x isstrong the highest ranked candidate antecedentwhich was not marked in the preceding stepsis returned together with the list of candidateantecedents.10 The approach of marking ambi-guities resembles that proposed by Kameyama(1996).The main structure of the function Re-solveDet is inspired by es00.
ResolveDettests the pronoun x using the IPA and APAdiscriminating rules discussed in section 3.
Ifx is IPA, the function ResolveIpa-neu is ap-plied.
If x is APA the function ResolveApa isapplied.
Finally, if the pronoun is neither IPAnor APA, ResolveDet looks at its type.
If xis strong the algorithm attempts to find an ab-stract antecedent (ResolveApa), while if it isweak dar tries to find an individual antecedent(ResolveIpa-neu).
ResolveIpa-neu is likeResolveIpa except that it returns if no NP an-tecedents are found in Un?1 (case A) so thatResolveApa can be applied.8In dar inferables comprise pronouns whose an-tecedents must be inferred by the context, plural pro-nouns with complex antecedents and generic uses of det(it).9Parallelism is investigated in coordinated, adjacentor explicitly contrasted utterances.10A special rule in dar is applied to the demonstra-tives dette/denne/disse (this/these) which never coreferwith subject candidates.ResolveApa distinguishes between types ofpronoun.
If x is weak, the preferred antecedentis searched for among the elements indicated inthe context ranking, unless it is the object of theverb g?re (do), modals, have (have) or the ab-stract subject in copula constructions.
In thesecases the pronoun is resolved to the VP of theelement in the A-list or in the context ranking.If x is strong ResolveApa attempts to resolveor classify it as vague depending on the typeof pronoun.
This part of the algorithm is spe-cific to Danish and accounts for the fact thatdifferent strong pronouns preferentially refer todifferent abstract entities in the data.Resolved APAs are inserted into the Alist.In case of failure ResolveApa returns so thatResolveIpa-neu can be applied.
If both func-tions fail, the pronoun is classified as vague.4.3 Some ExamplesIn the following we look at the resolution of ex-ample (2) from section 3 and the example in(5).
(5): Du har sv?rt ved at se musemark?ren p?ask?rmen.
Hvordan klarer du det?
[edb](You have difficulties seing the mouse-cursor(common-gend) on the screen (common-gend).How do you manage it/this (neuter gender))?The simplified Ilists and Alists after each ut-terance has been processed in example (2) aregiven in figure 4.
(2) contains three SUs.
U2is an I/A thus it belongs to two synchronisingunits (SU1 and SU2).
The Ilist after U1 hasbeen processed, contains one element, din mor(your mother).
In U2 the personal pronoun hun(she) occurs, thus ResolveIpa is applied.
Itresolves hun to the compatible NP in the Ilist,din mor.
After U2 has been processed the Ilistcontains two elements in this order: the focalmarked entity vores nabo (our neighbour) andthe pronoun hun (= din mor).
ResolveIpa re-solves the occurrence of the pronoun hun (she)in U3 to the most salient candidate NP in theIlist, vores nabo.
Here focal preference over-rides pronominal chain preference.
The simpli-fied Ilists and Alists after the two utterances in(5) have been processed are given in figure 5.After U1 has been processed there are two com-SU1: U1 (I) U2 (I/A):U1: hvem...hvem arbejdede din mor med?
(with whom... whom did your mother work)Ilist: [din mor]Alist :[]?????????????????
?SU2: U2 (I/A)U2: Hun arbejdede med vores nabo(She worked with our neighbour)Ilist: [vores nabo,hun=din mor]Alist : []?????????????????
?SU3: U3 (I)U3: Hun var enke ... havde tre s?nner(She was a widow... had three sons)Ilist: [hun=vores nabo,tre s?nner]Alist : []Figure 4: Ilists and Alists for example (2)U1: Du har sv?rt ved at se musemark?ren p?ask?rmen.Ilist : [musemark?ren, sk?rmen]Alist :[]?????????????????????
?U2: Hvordan klarer du det?Ilist :[]Alist :[det=U1]Figure 5: Ilists and Alists for example (5)mon gender singular NPs in the Ilist, muse-mark?ren (the mouse cursor) and sk?rmen (thescreen).
In U2 the singular neuter gender pro-noun det (it) occurs, thus ResolveDet is ap-plied.
The pronoun is neither IPA nor APAaccording to the discriminating rules.
ThenResolveDet attempts to find an individualantecedent of the weak pronoun, applying thefunction ResolveIpa-neu.
ResolveIpa-neufails because the two DEs in the Ilist do notagree with the pronoun.
Then the functionResolveApa resolves x looking at the contextranking.
Being the Alist empty, U1, is proposedas antecedent.
The resolved APA is added tothe Alist.5 Tests and EvaluationWe have manually tested dar on randomly cho-sen texts and dialogues from our collections.The performance of dar on dialogues has beencompared with that of es00.
The functionfor resolving IPAs (ResolveIpa) has similarlybeen tested on texts, where APAs were ex-cluded.
We have compared the obtained re-sults with those obtained by testing bfp (Bren-nan et al, 1987) and str98 (Strube, 1998).
Inall tests the intrasentential anaphors have beenmanually resolved.
Expletive and cataphoricuses of pronouns have been marked and ex-cluded from the tests.
Dialogue act units weremarked and classified by three persons followingthe strategy proposed in (Eckert and Strube,2000).
The reliability for the two annotationtasks (?-statistics (Carletta, 1996)) was of 0.94and 0.90 respectively.
Pronominal anaphorswere marked, classified and resolved by twoannotators.
The ?-statistics for the pronounclassification was 0.86.
When the annotatorsdid not agree upon resolution, the pronoun wasmarked as ambiguous and excluded from evalu-ation.
The results obtained for bfp and str98are given in table 1, while the results of dar?sResolveIpa are given in table 2.
Because darboth classifies and resolves anaphors, both pre-cision and recall are given in table 2.
Precisionindicates the proportion of the resolved pro-nouns which are correctly resolved, while recallindicates the proportion of all pronouns resolvedby humans which are correctly resolved by thealgorithm.The results indicate that ResolveIpa per-forms significantly better than bfp and str98on the Danish texts.
The better performance ofdar was due to the account of focal and par-allelism preferences and of the different refer-ence mechanisms of personal and demonstrativepronouns.
Furthermore dar recognises somegeneric pronouns and inferable pronouns andexcludes them from resolution, but often failsto recognise antecedentless and inferable pluralpronouns, because it often finds a plural nom-inal in the preceding discourse and proposes itas antecedent.
The lack of commonsense knowl-edge explains many incorrectly resolved anaph-ors.
The results of the test of the dar algo-algorithm corr.resolved res.human precisionbfp 513 645 79.53str98 524 645 81.24Table 1: Results of bfp and str98 on textscorr.res.
res.overall res.hum.
precis recall575 651 645 88.33 89.14Table 2: Results of ResolveIpa on textsrithm on written texts are in table 3.
Theseresults are good compared with the results ofthe function ResolveIpa (table 2).
The dis-criminating rules identify correctly IPAs andresolution IPAAlgorithm correctly resolved resolved overall human resolution precision recall f-meaurees00 258 411 414 62.77 62.31 62.48dar 289 386 414 74.87 68.81 71.71resolution APAAlgorithm correctly resolved resolved overall human resolution precision recall f-measurees00 179 286 269 62.59 66.54 64.5dar 194 277 269 70.04 72.19 69.13Table 4: Results of es00 and dar on dialoguesAPAs in the large majority of the cases.
Recog-nition failure often involves pronouns in con-texts which are not covered by the discriminat-ing rules.
In particular dar fails to resolve sin-gular neuter gender pronouns with distant an-tecedents and to identify vague anaphors, be-cause it always ?finds?
an antecedent in the con-text ranking.
Correct resolution in these casesrequires a deep analysis of the context.
Theresolution IPAcorr.res.
res.overall res.hum.
precis recall560 651 645 86.02 86.82resolution APAcorr.res.
res.overall res.hum.
precis recall63 87 77 72.41 81.82Table 3: Results of dar on textsresults of applying dar and es00 on Danish di-alogues are reported in table 4.11 In the lastcolum the overall performance of the two algo-rithms is given as f-measure (F) which is definedas 1?
1P +(1??
)1Rwhere P is precision, R is recalland ?
is the weight of P and R. We have as-signed the same weight to P and R (?
= 0.5)and thus F = 2PRP+R .
The results of the tests in-dicate that dar resolves IPAs significantly bet-ter than es00 (which uses str98).
The betterperformance of dar is also due to the enlargedresolution scope respect to the one used in es00.dar correctly resolves more Danish demonstra-tive pronouns than es00, because it accountsfor language-specific particularities.
In general,however, the resolution results for APAs aresimilar to those obtained for es00.
This is notsurprising, because dar uses the same resolu-tion strategy on these pronouns.
dar performsbetter on texts than on dialogues.
This reflectsthe more complex nature of dialogues.
The re-sults indicate that the IPA/APA discriminat-11We extended es00 with the Danish-specific identifi-cation rules before applying it.ing rules also work well on dialogues.
The casesof resolution failure were the same as for thetexts.
As an experiment we applied dar on thedialogues without relying on the predefined di-alogue structure.
In this test the recognitionof IPAs and APAs was still good, however thesuccess rate for IPAs was 60.1 % and for APAswas only 39.3%.
Many errors were due to thefact that antecedents were searched for in thepreceding discourse in linear order and that un-grounded utterances were included in the dis-course model.6 Concluding RemarksIn this paper we presented dar, an algorithmfor resolving IPAs and APAs in Danish textsand dialogues.
In dar differences between thereferential characteristics of Danish weak andstrong pronouns are accounted for and a novelstrategy for resolving individual anaphors isproposed.
This strategy combines givennesswith focality preferences to model salience andalso accounts for parallelism preferences.
darperforms significantly better on IPAs than al-gorithms which only rely on givenness-basedsalience models.
The strategy and the generalassumptions behind dar should be tested onother languages.Differing from es00 and phora, dar hasbeen developed for and tested on both texts anddialogues.
dar extends the es00 strategy ofclassifying and resolving (some types of) APAs.The tests of dar indicate that the es00?s ap-proach of recognising APAs is also promisingfor texts and other languages than English.dar has not been compared with phorawhich is the only abstract anaphora algorithmimplemented.
We find the algorithm very inter-esting because it addresses many of the samephenomena, but with different strategies.
Itwould be useful to combine some of these strate-gies with the approaches proposed in dar andes00 to improve the still problematic resolutionof abstract anaphors.ReferencesA.
Braasch, C. Navarretta, and N.H. S?rensen.1998.
Danish lexicon documentation.
Techni-cal Report LE-PAROLE.
WP3.3-CST, CST.S.
F. Brennan, M. W. Friedman, and C. J. Pol-lard.
1987.
A Centering Approach to Pro-nouns.
In Proceedings of the 25th AnnualMeeting of the Association for ComputationalLinguistics (ACL?87), pages 155?162, Cali-fornia, USA.
Stanford University.D.
Byron and J. Allen.
1998.
Resolving Demon-strative Pronouns in the TRAINS93 corpus.In Proceedings of the Second Colloquium onDiscourse Anaphora and Anaphor Resolution(DAARC 2), pages 68?81.D.
K. Byron.
2002.
Resolving Pronominal Ref-erence to Abstract Entities.
In Proceedings ofthe 40th Annual Meeting of the Associationfor Computational Linguistics (ACL 2002).J.
Carletta.
1996.
Assessing agreement on clas-sification tasks.
the kappa statistic.
Compu-tational Linguistics, 22(2):249?254.D.
Duncker and J. Hermann.
1996.
Pa-tientord og l?geord - s?rord eller f?lle-sord?
M?anedsskrift for Praktisk L?gegern-ing - Tidsskrift for Praktiserende L?gersEfteruddannelse, pages 1019?1030.M.
Eckert and M. Strube.
2000.
Dialogue acts,synchronising units and anaphora resolution.Journal of Semantics, 17:51?89.F.
Gregersen and I. L. Pedersen, editors.
1991.The Copenhagen study in urban sociolinguis-tics.
Reitzel.B.
J. Grosz and C. L. Sidner.
1986.
Attention,Intentions, and the Structure of Discourse.Computational Linguistics, 12(3):175?284.B.
Grosz, A. K. Joshi, and S. Weinstein.
1995.Centering:A Framework for Modeling the Lo-cal Coherence of Discourse.
ComputationalLinguistics, 21(2):203?225.J.
K. Gundel, N. Hedberg, and R. Zacharski.1993.
Cognitive status and the form of re-ferring expressions in discourse.
Language,69(2):274?307.E.
Hajic?ova?, P.
Kubon?, and V. Kubon?.
1990.Hierarchy of Salience and Discourse Analysisand Production.
In H. Karlgren, editor, Pro-ceedings of the 13th International Conferenceon Computational Linguistics (COLING?90),volume III, pages 144?148, Helsinki.J.
R. Hobbs.
1983.
Why Is Discourse Coher-ent?
In Fritz Neubauer, editor, Coherence InNatural-Language Texts, volume 38 of Papersin Textlinguistics, pages 29?70.
Helmut BuskeVerlag Hamburg.K.
A. Jensen.
1989.
Projekt invandrerdansk.Technical report, Copenhagen University.M.
Kameyama.
1996.
Indefeasible Semanticsand Defeasible Pragmatics.
In M. Kanazawa,C.
Pin?on, and H. de Stwart, editors, Quanti-fiers, Deduction and Context, pages 111?138.CSLI, Stanford, CA.C.
Navarretta.
1997.
Encoding Danish Verbs inthe PAROLE Model.
In R. Mitkov, N. Ni-colov, and N. Nikolov, editors, Proceedingsof RANLP?97.Recent Advances in NaturalLanguage Processing, pages 359?363, TzigovChark, Bulgaria.C.
Navarretta.
2002a.
Combining Informa-tion Structure and Centering-based Mod-els of Salience for Resolving Intersenten-tial Pronominal Anaphora.
In A. Branco,T.
McEnery, and R.Mitkov, editors, Pro-ceedings of the 4th Discourse Anaphora andAnaphora Resolution Colloqium, pages 135?140.
Edic?oes Colibri.E.
F. Prince.
1981.
Toward a taxonomy ofgiven-new information.
In P. Cole, editor,Radical Pragmatics, pages 223?255.
Aca-demic Press.P.
Sgall, E.
Hajic?ova?, and J. Panevova?.
1986.The Meaning of the Sentence in its Semanticand Pragmatic Aspects.
Reidel, Dordrecht.C.
Sidner.
1983.
Focusing in the Comprehen-sion of Definite Anaphora.
In M. Brady andR.
Berwick, editors, Computational Models ofDiscourse, pages 267?330.
MIT Press.M.
Strube and U. Hahn.
1996.
Functional Cen-tering.
In Proceedings of the 34th Interna-tional Conference on Computational Linguis-tics (ACL?96), pages 270?277, Ca.M.
Strube and C. Mu?ller.
2003.
A ma-chine learning approach to pronoun resolu-tion in spoken dialogue.
In Proceedings of theACL?03, pages 168?175.M.
Strube.
1998.
Never Look Back: An Al-ternative to Centering.
In Proceedings ofthe 36th Annual Meeting of the Associationfor Computational Linguistics and the 17thInternational Conference on ComputationalLinguistics (COLING-ACL?98), volume II,pages 1251?1257.B.
L. Webber.
1991.
Structure and Osten-sion in the Interpretation of Discourse Deixis.Natural Language and Cognitive Processes,6(2):107?135, January.
