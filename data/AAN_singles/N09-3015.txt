Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 84?89,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsTowards Unsupervised Recognition of Dialogue ActsNicole NovielliDept.
of Informatics, University of Barivia Orabona 4I-70125 Bari, Italynovielli@di.uniba.itCarlo StrapparavaFBK-irstvia Sommarive, PovoI-38050 Trento, Italystrappa@fbk.euAbstractWhen engaged in dialogues, people per-form communicative actions to pursue specificcommunicative goals.
Speech acts recogni-tion attracted computational linguistics sincelong time and could impact considerably ahuge variety of application domains.
We studythe task of automatic labeling dialogues withthe proper dialogue acts, relying on empiri-cal methods and simply exploiting lexical se-mantics of the utterances.
In particular, wepresent some experiments in supervised andunsupervised framework on both an Englishand an Italian corpus of dialogue transcrip-tions.
The evaluation displays encouraging re-sults in both languages, especially in the unsu-pervised version of the methodology.1 IntroductionPeople proceed in their conversations through a se-quence of dialogue acts to yield some specific com-municative goal.
They can ask for information,agree or disagree with their partner, state some factsand express opinions.Dialogue Acts (DA) attracted linguistics (Austin,1962; Searle, 1969) and computational linguisticsresearch (Core and Allen, 1997; Traum, 2000) sincelong time.
With the advent of the Web, a largeamount of material about natural language inter-actions (e.g.
blogs, chats, conversation transcripts)has become available, raising the attractiveness ofempirical methods analyses on this field.
There isa large number of application domains that couldbenefit from automatically labeling DAs: e.g.
con-versational agents for monitoring and supportinghuman-human remote conversations, blogs, forumsand chat logs analysis for opinion mining, interper-sonal stances modeling by mean of conversationalanalysis, automatic meeting summarizations and soon.
These applications require a deep understandingof the conversational structure and the ability of thesystem to understand who is telling what to whom.This study defines a method for automatically la-beling dialogues with the proper speech acts by re-lying on empirical methods.
Even if prosody andintonation surely play a role (e.g.
(Stolcke et al,2000; Warnke et al, 1997)), nonetheless languageand words are what the speaker uses to convey thecommunicative message and are just what we haveat disposal when we consider texts found on theWeb.
Hence, we decided to simply exploit lexicalsemantics of the sentences.
We performed some ex-periments in a supervised and unsupervised frame-work on both an English and an Italian corpora ofdialogue transcriptions, achieving good results in allsettings.
Unsupervised performance is particularlyencouraging, independently from the used language.The paper is organized as follows.
Section 2 givesa brief sketch of the NLP background on DialogueActs recognition.
In Section 3 we introduce the En-glish and Italian corpora of dialogues, their charac-teristics and DA labeling.
In Section 4 we describethe preprocessing of the data sets.
Then Section 5explains the supervised and unsupervised settings,showing the experimental results obtained on thetwo corpora and providing an error analysis.
Finally,in Section 6 we conclude the paper with a brief dis-cussion and some directions for future work.84Speaker Dialogue Act UtteranceA OPENING Hello Ann.B OPENING Hello Chuck.A STATEMENT Uh, the other day, I attended a conference here at Utah State University on recyclingA STATEMENT and, uh, I was kind of interested to hear cause they had some people from the EPA andlots of different places, and, uh, there is going to be a real problem on solid waste.B OPINION Uh, I didn?t think that was a new revelation.A AGREE /ACCEPT Well, it?s not too new.B INFO-REQUEST So what is the EPA recommending now?Table 1: An excerpt from the Switchboard corpus2 BackgroundA DA can be identified with the communicative goalof a given utterance (Austin, 1962).
Researchers usedifferent labels and definitions to address this con-cept: speech act (Searle, 1969), adjacency pair part(Schegloff, 1968) (Sacks et al, 1974), game move(Power, 1979)Traditionally, the NLP community has employedDA definitions with the drawback of being do-main or application oriented.
Recently some effortshave been made towards unifying the DA annotation(Traum, 2000).
In the present study we refer to adomain-independent framework for DA annotation,the DAMSL architecture (Dialogue Act Markup inSeveral Layers) by (Core and Allen, 1997).Recently, the problem of DA recognition hasbeen addressed with promising results: Poesio andMikheev (1998) combine expectations about thenext likely dialogue ?move?
with information de-rived from the speech signal features; Stolcke etal.
(2000) employ a discourse grammar, formal-ized in terms of Hidden Markov Models, combiningalso evidences about lexicon and prosody; Keizer etal.
(2002) make use of Bayesian networks for DArecognition in dutch dialogues; Grau et al (2004)consider naive Bayes classifiers as a suitable ap-proach to the DA classification problem; a partiallysupervised framework has also been explored byVenkataraman et al (2005)Regardless of the model they use (discoursegrammars, models based on word sequences or onthe acoustic features or a combination of all these)the mentioned studies are developed in a supervisedframework.
In this paper, one goal is to explore alsothe use of a fully unsupervised methodology.3 Data SetsIn the experiments of the present paper we exploittwo corpora, both annotated with DAs labels.
Weaim at developing a recognition methodology asgeneral as possible, so we selected corpora whichare different in content and language: the Switch-board corpus (Godfrey et al, 1992), a collectionof transcriptions of spoken English telephone con-versations about general interest topics, and an Ital-ian corpus of dialogues in the healthy-eating domain(Clarizio et al, 2006).In this section we describe the two corpora, theirfeatures, the set of labels used for annotating the di-alogue acts with their distributions and the data pre-processing.3.1 DescriptionThe Switchboard corpus is a collection of Englishhuman-human telephone conversations (Godfrey etal., 1992) between couples of randomly selectedstrangers.
They were asked to choose one generalinterest topic and to talk informally about it.
Fulltranscripts of these dialogues are distributed by theLinguistic Data Consortium.
A part of this cor-pus is annotated (Jurafsky et al, 1997) with DAlabels (overall 1155 conversations, for a total of205,000 utterances and 1.4 million words)1.
Table1 shows a short sample fragments of dialogues fromthe Switchboard corpus.The Italian corpus had been collected in the scopeof some previous research about Human-ECA inter-action.
A Wizard of Oz tool was employed (Clarizioet al, 2006) and during the interaction, a conver-sational agent (i.e.
the ?wizard?)
played the role of1ftp.ldc.upenn.edu/pub/ldc/public\_data/swb1\_dialogact\_annot.tar.gz85Label Description Example Italian EnglishINFO-REQUEST Utterances that are pragmatically, semantically,and syntactically questions?What did you do when your kidswere growing up?
?34% 7%STATEMENT Descriptive, narrative, personal statements ?I usually eat a lot of fruit?
37% 57%S-OPINION Directed opinion statements ?I think he deserves it.?
6% 20%AGREE-ACCEPT Acceptance of a proposal, plan or opinion ?That?s right?
5% 9%REJECT Disagreement with a proposal, plan, or opinion ?I?m sorry no?
7% .3%OPENING Dialogue opening or self-introduction ?Hello, my name is Imma?
2% .2%CLOSING Dialogue closing (e.g.
farewell and wishes) ?It?s been nice talking to you.?
2% 2%KIND-ATT Kind attitude (e.g.
thanking and apology) ?Thank you very much.?
9% .1%GEN-ANS Generic answers to an Info-Request ?Yes?, ?No?, ?I don?t know?
4% 4%total cases 1448 131,265Table 2: The set of labels employed for Dialogue Acts annotation and their distribution in the two corporaan artificial therapist.
The users were free to inter-act with it in natural language, without any partic-ular constraint.
This corpus is about healthy eatingand contains (overall 60 dialogues, 1448 users?
ut-terances and 15,500 words).3.2 LabellingBoth corpora are annotated following the DialogueAct Markup in Several Layers (DAMSL) annotationscheme (Core and Allen, 1997).
In particular theSwitchboard corpus employs a revision (Jurafsky etal., 1997).2Table 2 shows the set of labels employed withtheir definitions, examples and distributions in thetwo data sets.
The categories maintain the DAMSLmain characteristic of being domain-independentand can be easily mapped back into SWBD-DAMSLones, and maintain their original semantics.
Thus,the original SWBD-DAMSL annotation had beenautomatically converted into the categories includedin our markup language.34 Data preprocessingTo reduce the data sparseness, we used a POS-taggerand morphological analyzer (Pianta et al, 2008) forpreprocessing both corpora.
So we considered lem-mata instead of tokens in the format lemma#POS.
Inaddition, we augment the features of each sentencewith a set of linguistic markers, defined according to2The SWBD-DAMSL modifies the original DAMSL frame-work by further specifying some categories or by adding extrafeatures (mainly prosodic) which were not originally includedin the scheme.3Also we did not consider the utterances formed only bynon-verbal material (e.g.
laughter).the semantic of the DA categories.
We hypothesize,in fact, these features could play an important rolein defining the linguistic profile of each DA.
The ad-dition of these markers is performed automatically,by just exploiting the output of the POS-tagger andof the morphological analyzer, according to the fol-lowing rules:?
WH-QTN, used whenever an interrogative de-terminer (e.g.
?what?)
is found, according to theoutput of the POS-tagger;?
ASK-IF, used whenever an utterance presentsthe pattern of a ?Yes/No?
question.
ASK-IF andWH-QTN markers are supposed to be relevantfor the INFO-REQUEST category;?
I-PERS, used for all declarative utteranceswhenever a verb is in the first person form, sin-gular or plural (relevant for the STATEMENT);?
COND, used for conditional form is detected.?
SUPER, used for superlative adjectives.?
AGR-EX, used whenever an agreement ex-pression (e.g.
?You?re right?, ?I agree?)
is de-tected (relevant for AGREE-ACCEPT);?
NAME, used whenever a proper name followsa self-introduction expression (e.g.
?My nameis?)
(relevant for the OPENING);?
OR-CLAUSE, used for or-clauses, that is ut-terance starting by ?or?
(should be helpful forthe characterization of the INFO-REQUEST);?
VB, used only for the Italian, when a dialectalform of agreement expression is detected.5 Dialogue Acts RecognitionWe conducted some experiments both in a super-vised and unsupervised settings.865.1 SupervisedRegarding the supervised experiments, we usedSupport Vector Machines (Vapnik, 1995), in partic-ular SVM-light package (Joachims, 1998) under itsdefault configuration.
We randomly split the twocorpora into 80/20 training/test partitions.
SVMshave been used in a large range of problems, in-cluding text classification, image recognition tasks,bioinformatics and medical applications, and theyare regarded as the state-of-the-art in supervisedlearning.
We got .71 and .77 of F1 measures respec-tively for the Italian and English corpus.
Table 4reports the performance for each direct act.5.2 UnsupervisedIt is not always easy to collect large training, partlybecause of manual labeling effort and moreover be-cause often it is not possible to find it.Schematically, our unsupervised methodology is:(i) building a semantic similarity space in whichwords, set of words, text fragments can be repre-sented homogeneously, (ii) finding seeds that prop-erly represent dialogue acts and considering theirrepresentations in the similarity space, and (iii)checking the similarity of the utterances.To get a similarity space with the required charac-teristics, we used Latent Semantic Analysis (LSA),a corpus-based measure of semantic similarity pro-posed by Landauer (Landauer et al, 1998).
In LSA,term co-occurrences in a corpus are captured bymeans of a dimensionality reduction operated by asingular value decomposition (SVD) on the term-by-document matrix T representing the corpus.SVD decomposes the term-by-document matrixT into three matrices T = U?kVT where ?k isthe diagonal k ?
k matrix containing the k singu-lar values of T, ?1 ?
?2 ?
.
.
.
?
?k, and Uand V are column-orthogonal matrices.
When thethree matrices are multiplied together the originalterm-by-document matrix is re-composed.
Typicallywe can choose k?
k obtaining the approximationT ' U?k?VT .LSA can be viewed as a way to overcome someof the drawbacks of the standard vector space model(sparseness and high dimensionality).
In fact, theLSA similarity is computed in a lower dimensionalspace, in which second-order relations among termsand texts are exploited.
The similarity in the result-ing vector space is then measured with the standardcosine similarity.
Note also that LSA yields a vec-tor space model that allows for a homogeneous rep-resentation (and hence comparison) of words, sen-tences, and texts.
For representing a word set ora sentence in the LSA space we use the pseudo-document representation technique, as described byBerry (1992).
In practice, each text segment is repre-sented in the LSA space by summing up the normal-ized LSA vectors of all the constituent words, usingalso a tf.idf weighting scheme (Gliozzo and Strappa-rava, 2005).Label SeedsINFO-REQ WH-QTN, Question Mark, ASK-IF, huhSTATEMENT I-PERS, IS-OPINION Verbs which directly express opinion orevaluation (guess, think, suppose, affect)AGREE-ACC AGR-EX, yep, yeah, absolutely, correctREJECT Verbs which directly express disagreement(disagree, refute)OPENING Greetings (hi, hello), words and markers re-lated to self-introduction (name, NAME)CLOSING Interjections/exclamations ending dis-course (alright, okeydoke), Expressionsof thanking (thank) and farewell (bye,bye-bye, goodnight, goodbye)KIND-ATT Wishes (wish), apologies (apologize),thanking (thank) and sorry-for (sorry,excuse)GEN-ANS no, yes, uh-huh, nopeTable 3: The seeds for the unsupervised experimentThe methodology is completely unsupervised.We run the LSA using 400 dimensions (i.e.
k?, assuggested by (Landauer et al, 1998)) respectivelyon the English and Italian corpus, without any DAlabel information.
Starting from a set of seeds(words) representing the communicative acts (seethe complete sets in Table 3), we build the corre-sponding vectors in the LSA space and then we com-pare the utterances to find the communicative actwith higher similarity.
To compare with SVM, theperformance is measured on the same test set parti-tion used in the supervised experiment (Table 4).We defined seeds by only considering the commu-nicative goal and the specific semantic of every sin-gle DA, just avoiding as much as possible the over-lapping between seeds groups.
We wanted to design87Italian EnglishSVM LSA SVM LSALabel prec rec f1 prec rec f1 prec rec f1 prec rec f1INFO-REQ .92 .99 .95 .96 .88 .92 .92 .84 .88 .93 .70 .80STATEMENT .85 .68 .69 .76 .66 .71 .79 .92 .85 .70 .95 .81S-OPINION .28 .42 .33 .24 .42 .30 .66 .44 .53 .41 .07 .12AGREE-ACC .50 .80 .62 .56 .50 .53 .69 .74 .71 .68 .63 .65REJECT - - - .09 .25 .13 - - - .01 .01 .01OPENING .60 1.00 .75 .55 1.00 .71 .96 .55 .70 .20 .43 .27CLOSING .67 .40 .50 .25 .40 .31 .83 .59 .69 .76 .34 .47KIND-ATT .82 .53 .64 .43 .18 .25 .85 .34 .49 .09 .47 .15GEN-ANS .20 .63 .30 .27 .38 .32 .56 .25 .35 .54 .33 .41micro .71 .71 .71 .66 .66 .66 .77 .77 .77 .69 .69 .69Table 4: Evaluation of the two methods on both corporaan approach which is as general as possible, so wedid not consider domain words.
The seeds are thesame for both languages, which is coherent with ourgoal of defining a language-independent method.5.3 Experimental Results and DiscussionWe evaluate the performance of our method in termsof precision, recall and f1-measure (see Table 4) ac-cording to the DA labels given by annotators in thedatasets.
As baselines we consider (i) most-frequentlabel assignment (respectively 37% for Italian, 57%for English) for the supervised setting, and (ii) ran-dom DA selection (11%) for the unsupervised one.Results are quite satisfying (Table 4).
In particu-lar, the unsupervised technique is largely above thebaselines, for both the Italian and the English exper-iments.
The methodology is independent from thelanguage and the domain: the Italian corpus is a col-lection of dialogue about a very restricted domainwhile the Switchboard conversations are essentiallytask-free.
Moreover, in the unsupervised setting weuse in practice the same seed definitions.
Secondly,it is independent on the differences in the linguis-tic style due to the specific interaction scenario andinput modality.
Finally, the performance is not af-fected by the difference in size of the two data sets.Error analysis.
After conducting an error analy-sis, we noted that many utterances are misclassi-fied as STATEMENT.
One possible reason is thatstatements usually are quite long and there is a highchance that some linguistic markers that character-ize other dialogue acts are present in those sen-tences.
On the other hand, looking at the corpora weobserved that many utterances which appear to belinguistically consistent with the typical structure ofstatements have been annotated differently, accord-ing to the actual communicative role they play.
Forsimilar reasons, we observed some misclassifica-tion of S-OPINION as STATEMENT.
The only sig-nificative difference between the two labels seemsto be the wider usage of ?slanted?
and affectivelyloaded lexicon when conveying an opinion.
Anothercause of confounding is the confusion among thebackchannel labels (GEN-ANS, AGREE-ACC andREJECT) due to the inherent ambiguity of commonwords like yes, no, yeah, ok.Recognition of such cases could be improved (i)by enabling the classifiers to consider not only thelexical semantics of the given utterance (local con-text) but also the knowledge about a wider contextwindow (e.g.
the previous n utterances), (ii) by en-riching the data preprocessing (e.g.
by exploiting in-formation about lexicon polarity and subjectivity pa-rameters).
We intend to follow both these directionsin our future research.6 Conclusions and Future WorkThis study aims at defining a method for DialogueActs recognition by simply exploiting the lexical se-mantics of dialogue turns.
The technique had tobe independent from some important features of thecorpus being used such as domain, language, size,interaction scenario.
In a long-term perspective, wewill employ the technique in conversational analysisfor user attitude classification (Martalo et al, 2008).The methodology starts with automatically en-88riching the corpus with additional features, such aslinguistic markers.
Then the unsupervised case con-sists of defining a very simple and intuitive set ofseeds that profiles the specific dialogue acts, andsubsequently performing a similarity analysis in alatent semantic space.
The performance of the unsu-pervised experiment has been compared with a su-pervised state-of-art technique such as Support Vec-tor Machines, and the results are quite encouraging.Regarding future developments, we will investi-gate how to include in the framework a wider con-text (e.g.
the previous n utterances), and the intro-duction of new linguistic markers by enriching thepreprocessing techniques.
In particular, it would beinteresting to exploit the role of slanted or affective-loaded lexicon to deal with the misclassification ofopinions as statements.
Along this perspective, DArecognition could serve also as a basis for conver-sational analysis aimed at improving a fine-grainedopinion mining in dialogues.ReferencesJ.
Austin.
1962.
How to do Things with Words.
OxfordUniversity Press, New York.M.
Berry.
1992.
Large-scale sparse singular value com-putations.
International Journal of SupercomputerApplications, 6(1).G.
Clarizio, I. Mazzotta, N. Novielli, and F. deRosis.2006.
Social attitude towards a conversational char-acter.
In Proceedings of the 15th IEEE InternationalSymposium on Robot and Human Interactive Commu-nication, pages 2?7, Hatfield, UK, September.M.
Core and J. Allen.
1997.
Coding dialogs with theDAMSL annotation scheme.
In Working Notes of theAAAI Fall Symposium on Communicative Action inHumans and Machines, Cambridge, MA.A.
Gliozzo and C. Strapparava.
2005.
Domains kernelsfor text categorization.
In Proceedengs of (CoNLL-2005), University of Michigan, Ann Arbor, June.J.
Godfrey, E. Holliman, and J. McDaniel.
1992.SWITCHBOARD: Telephone speech corpus for re-search and development.
In Proceedings of ICASSP-92, pages 517?520, San Francisco, CA.
IEEE.S.
Grau, E. Sanchis, M. J. Castro, and D. Vilar.
2004.
Di-alogue act classification using a bayesian approach.
InProceedings of SPECOM-04, pages 495?499, Saint-Petersburg, Russia, September.T.
Joachims.
1998.
Text categorization with SupportVector Machines: learning with many relevant fea-tures.
In Proceedings of the European Conference onMachine Learning.D.
Jurafsky, E. Shriberg, and D. Biasca.
1997.
Switch-board SWBD-DAMSL shallow-discourse-function an-notation coders manual, draft 13.
Technical Report97-01, University of Colorado.S.
Keizer, R. op den Akker, and A. Nijholt.
2002.
Dia-logue act recognition with bayesian networks for dutchdialogues.
In K. Jokinen and S. McRoy, editors, Pro-ceedings 3rd SIGdial Workshop on Discourse and Di-alogue, pages 88?94, Philadelphia, PA, July.T.
K. Landauer, P. Foltz, and D. Laham.
1998.
Introduc-tion to latent semantic analysis.
Discourse Processes,25.A.
Martalo, N. Novielli, and F. deRosis.
2008.
Attitudedisplay in dialogue patterns.
In AISB 2008 Conven-tion on Communication, Interaction and Social Intel-ligence, Aberdeen, Scotland, April.E.
Pianta, C. Girardi, and R. Zanoli.
2008.
The TextProtool suite.
In Proceedings of LREC, Marrakech (Mo-rocco), May.M.
Poesio and A. Mikheev.
1998.
The predictive powerof game structure in dialogue act recognition: Experi-mental results using maximum entropy estimation.
InProceedings of ICSLP-98, Sydney, December.R.
Power.
1979.
The organisation of purposeful dia-logues.
Linguistics, 17:107?152.H.
Sacks, E. Schegloff, and G. Jefferson.
1974.
A sim-plest systematics for the organization of turn-taking forconversation.
Language, 50(4):696?735.E.
Schegloff.
1968.
Sequencing in conversational open-ings.
American Anthropologist, 70:1075?1095.J.
Searle.
1969.
Speech Acts: An Essay in the Philoso-phy of Language.
Cambridge University Press, Cam-bridge, London.A.
Stolcke, N. Coccaro, R. Bates, P. Taylor, C. Van Ess-Dykema, K. Ries, E. Shriberg, D. Jurafsky, R. Mar-tin, and M. Meteer.
2000.
Dialogue act modeling forautomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26(3):339?373.D.
Traum.
2000.
20 questions for dialogue act tax-onomies.
Journal of Semantics, 17(1):7?30.V.
Vapnik.
1995.
The Nature of Statistical Learning The-ory.
Springer-Verlag.A.
Venkataraman, Y. Liu, E. Shriberg, and A. Stol-cke.
2005.
Does active learning help automatic dia-log act tagging in meeting data?
In Proceedings ofEUROSPEECH-05, Lisbon, Portugal.V.
Warnke, R. Kompe, H. Niemann, and E. No?th.
1997.Integrated dialog act segmentation and classificationusing prosodic features and language models.
In Pro-ceedings of 5th European Conference on Speech Com-munication and Technology, volume 1, pages 207?210, Rhodes, Greece.89
