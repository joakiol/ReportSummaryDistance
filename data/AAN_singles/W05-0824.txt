Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 137?140,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005RALI: SMT shared task system descriptionPhilippe Langlais, Guihong Cao and Fabrizio GottiRALIDe?partement d?Informatique et de Recherche Ope?rationnelleUniversite?
de Montre?alSuccursale Centre-VilleH3C3J7 Montre?al, Canadahttp://rali.iro.umontreal.caAbstractThanks to the profusion of freely avail-able tools, it recently became fairlyeasy to built a statistical machine trans-lation (SMT) engine given a bitext.
Theexpectations we can have on the qualityof such a system may however greatlyvary from one pair of languages to an-other.
We report on our experimentsin building phrase-based translation en-gines for the four pairs of languages wehad to consider for the SMT shared-task.1 IntroductionMachine translation is nowadays mature enoughthat it is possible without too much effort to de-vise automatically a statistical translation systemfrom just a parallel corpus.
This is possiblethanks to the dissemination of valuable packages.The performance of such a system may howevergreatly vary from one pair of languages to an-other.
Indeed, there is no free lunch for systemdevelopers, and if a black box approach can some-times be good enough for some applications (wecan surely accomplish translation gisting with theFrench-English and Spanish-English systems wedeveloped during this exercice), making use ofthe output of such a system for, let?s say, qual-ity translation is another kettle of fish (especiallyin our case with the Finnish-English system weended-up with).We devoted two weeks to the SMT shared task,the aim of which was precisely to see how wellsystems can do across different language families.We began with a core system which is describedin the next section and from which we obtainedbaseline performances that we tried to improveupon.Since the French- and Spanish-English sys-tems produced output that were comprehensi-ble enough1, we focussed on the two languageswhose translations were noticeably worse: Ger-man and Finnish.
For German, we tried to movearound words in order to mimic English word or-der; and we tried to split compound words.
Thisis described in section 4.
For the Finnish/Englishpair, we tried to decompose Finnish words intosmaller substrings (see section 5).In parallel to that, we tried to smooth a phrase-based model (PBM) making use of WORDNET.We report on this experiment in section 3.
We de-scribe in section 6 the final setting of the systemswe used for submitting translations and their of-ficial results as computed by the organizers.
Fi-nally, we conclude our two weeks of efforts insection 7.2 The core systemWe assembled up a phrase-based statistical engineby making use of freely available packages.
Thetranslation engine we used is the one suggestedwithin the shared task: PHARAOH (Koehn, 2004).The input of this decoder is composed of a phrase-based model (PBM), a trigram language modeland an optional set of coefficients and thresholds1What we mean by this is nothing more than we weremostly able to infer the original meaning of the source sen-tence by reading its automatic translation.137pair WER SER NIST BLEUfi-en 66.53 99.20 5.3353 18.73de-en 60.70 98.40 5.8411 21.11fr-en 53.77 98.20 6.4717 27.69es-en 53.84 98.60 6.5571 28.08Table 1: Baseline performances measured on the500 top sentences of the DEV corpus in terms ofWER (word error rate), SER (sentence error rate),NIST and BLEU scores.which control the decoder.For acquiring a PBM, we followed the ap-proach described by Koehn et al (2003).
In brief,we relied on a bi-directional word alignment ofthe training corpus to acquire the parameters ofthe model.
We used the word alignment pro-duced by Giza (Och and Ney, 2000) out of anIBM model 2.
We did try to use the alignmentproduced with IBM model 4, but did not noticesignificant differences over our experiments; anobservation consistent with the findings of Koehnet al (2003).
Each parameter in a PBM can bescored in several ways.
We considered its rela-tive frequency as well as its IBM-model 1 score(where the transfer probabilities were taken froman IBM model 2 transfer table).
The languagemodel we used was the one provided within theshared task.We obtained baseline performances by tuningthe engine on the top 500 sentences of the devel-opment corpus.
Since we only had a few param-eters to tune, we did it by sampling the parameterspace uniformly.
The best performance we ob-tained, i.e., the one which maximizes the BLEUmetric as measured by the mteval script2 is re-ported for each pair of languages in Table 1.3 Smoothing PBMs with WORDNETAmong the things we tried but which did notwork well, we investigated whether smoothingthe transfer table of an IBM model (2 in our case)with WORDNET would produce better estimatesfor rare words.
We adapted an approach proposedby Cao et al (2005) for an Information Retrievaltask, and computed for any parameter (ei, fj) be-2http://www.nist.gov/speech/tests/mt/mt2001/resourcelonging to the original model the following ap-proximation:p?
(ei|fj) ??e?Epwn(ei|e)?
pn(e|fj)where E is the English vocabulary, pn desig-nates the native distribution and pwn is the proba-bility that two words in the English side are linkedtogether.
We estimated this distribution by co-occurrence counts over a large English corpus3.To avoid taking into account unrelated but co-occurring words, we used WORDNET to filter inonly the co-occurrences of words that are in re-lation according to WORDNET.
However, sincemany words are not listed in this resource, we hadto smooth the bigram distribution, which we didby applying Katz smoothing (Katz, 1997):pkatz(ei|e) ={c?
(ei,e|W,L)Pejc(ej ,e|W,L)if c(ei, e|W,L) > 0?
(e)pkatz(ei) otherwisewhere c?
(a, b|W,L) is the good-turing dis-counted count of times two words a and b that arelinked together by a WORDNET relation, co-occurin a window of 2 sentences.We used this smoothed model to score the pa-rameters of our PBM instead of the native trans-fer table.
The results were however disappoint-ing for both the G-E and S-E translation direc-tions we tested.
One reason for that, may bethat the English corpus we used for computingthe co-occurrence counts is an out-of-domain cor-pus for the present task.
Another possible ex-planation lies in the fact that we considered bothsynonymic and hyperonymic links in WORDNET;the latter kind of links potentially introducing toomuch noise for a translation task.4 The German-English taskWe identified two major problems with our ap-proach when faced with this pair of languages.First, the tendency in German to put verbs at theend of a phrase happens to ruin our phrase acqui-sition process, which basically collects any boxof aligned source and target adjacent words.
This3For this, we used the English side of the provided train-ing corpus plus the English side of our in-house Hansard bi-text; that is, a total of more than 7 million pairs of sentences.138can be clearly seen in the alignment matrix of fig-ure 1 where the verbal construction could clarifyis translated by two very distant German wordsko?nnten and erla?utern.
Second, there are manycompound words in German that greatly dilutethe various counts embedded in the PBM table.. .
.
.
.
.
.
.
.
.
.
.
.
?erla?utern .
.
.
.
.
.
.
?
.
.
.
.
.punkt .
.
.
.
.
.
.
.
.
?
.
.
.einen .
.
.
.
.
.
.
.
?
. "
.
.mir .
.
.
.
.
.
.
.
.
.
.
?
.sie .
.
.
.
.
?
.
.
.
.
.
.
.oder .
.
.
.
?
.
.
.
.
.
.
.
.kommission .
.
.
?
.
.
.
.
.
.
.
.
.die .
.
?
.
.
.
.
.
.
.
.
.
.ko?nnten .
.
.
.
.
.
?
.
.
.
.
.
.vielleicht .
?
.
.
.
.
.
.
.
.
.
.
.NULL .
.
.
.
.
.
.
.
.
.
.
.
.N p t c o y c c a p f m .U e h o r o o l o o eL r e m u u a i rL h m l r nEnglish perhaps the commission or you couldclarify a point for me .German vielleicht ko?nnten die kommission odersie mir einen punkt erla?utern .Figure 1: Bidirectional alignment matrix.
A crossin this matrix designates an alignment valid inboth directions, while the " symbol indicates anuni-directional alignment (for has been alignedwith einen, but not the other way round).4.1 Moving around German wordsFor the first problem, we applied a memory-basedapproach to move around words in the Germanside in order to better synchronize word orderin both languages.
This involves, first, to learn-ing transformation rules from the training corpus,second, transforming the German side of this cor-pus; then training a new translation model.
Thesame set of rules is then applied to the Germantext to be translated.The transformation rules we learned concern afew (five in our case) verbal constructions thatwe expressed with regular expressions built onPOS tags in the English side.
Once the locusevu of a pattern has been identified, a rule is col-lected whenever the following conditions apply:for each word e in the locus, there is a target wordf which is aligned to e in both alignment direc-tions; these target words when moved can lead toa diagonal going from the target word (l) associ-ated to eu?1 to the target word r which is alignedto ev+1.The rules we memorize are triplets (c, i, o)where c = (l, r) is the context of the locus and iand o are the input and output German word order(that is, the order in which the tokens are found,and the order in which they should be moved).For instance, in the example of Figure 1,the Verb Verb pattern match the locus couldclarify and the following rule is acquired:(sie einen, ko?nnten erla?utern,ko?nnten erla?utern), a paraphrase ofwhich is: ?whenever you find (in this order)the word ko?nnten and erla?utern in a Germansentence containing also (in this order) sie andeinen, move ko?nnten and erla?utern between sieand einen.A set of 124 271 rules have been acquiredthis way from the training corpus (for a total of157 970 occurrences).
The most frequent rule ac-quired is (ich herrn, mo?chte danken,mo?chte danken), which will transform a sen-tence like ?ich mo?chte herrn wynn fu?r seinenbericht danken.?
into ?ich mo?chte danken herrnwynn fu?r seinen bericht.
?.In practice, since this acquisition process doesnot involve any generalization step, only a fewrules learnt really fire when applied to the test ma-terial.
Also, we devised a fairly conservative wayof applying the rules, which means that in prac-tice, only 3.5% of the sentences of the test corpuswhere actually modified.The performance of this procedure as measuredon the development set is reported in Table 2.
Assimple as it is, this procedure yields a relative gainof 7% in BLEU.
Given the crudeness of our ap-proach, we consider this as an encouraging im-provement.4.2 Compound splittingFor the second problem, we segmented Germanwords before training the translation models.
Em-pirical methods for compound splitting applied to139system WER SER NIST BLEUbaseline 60.70 98.40 5.8411 21.11swap 60.73 98.60 5.9643 22.58split 60.67 98.60 5.7511 21.99swap+split 60.57 98.40 5.9685 23.10Table 2: Performances of the swapping and thecompound splitting approaches on the top 500sentences of the development set.German have been studied by Koehn and Knight(2003).
They found that a simple splitting strat-egy based on the frequency of German words wasthe most efficient method of the ones they tested,when embedded in a phrase-based translation en-gine.
Therefore, we applied such a strategy tosplit German words in our corpora.
The resultsof this approach are shown in Table 2.Note: Both the swapping strategy and the com-pound splitting yielded improvements in terms ofBLEU score.
Only after the deadline did we findtime to train new models with a combination ofboth techniques; the results of which are reportedin the last line of Table 2.5 The Finnish-English taskThe worst performances were registered on theFinnish-English pair.
This is due to the aggluti-native nature of Finnish.
We tried to segment theFinnish material into smaller units (substrings) bymaking use of the frequency of all Finnish sub-strings found in the training corpus.
We main-tained a suffix tree structure for that purpose.We proceeded by recursively finding the mostpromising splitting points in each Finnish tokenof C characters FC1 by computing split(FC1 )where:split(F ji ) =??
?|F ji | if j ?
i < 2maxc?
[i+2,j?2] |Fci |?split(F jc+1) otherwiseThis approach yielded a significant degradationin performance that we still have to analyze.6 Submitted translationsAt the time of the deadline, the best translationswe had were the baselines ones for all the lan-guage pairs, except for the German-English onewhere the moving of words ranked the best.
Thisdefined the configuration we submitted, whose re-sults (as provided by the organizers) are reportedin Table 3.pair BLEU p1/p2/p3/p4fi-en 18.87 55.2/24.7/13.1/7.1de-en 22.91 58.9/29.0/16.8/10.3es-en 28.49 62.4/34.5/21.9/14.4fr-en 28.89 62.6/34.7/22.0/14.6Table 3: Results measured by the organizers forthe TEST corpus.7 ConclusionWe found that, while comprehensible translationswere produced for pairs of languages such asFrench-English and Spanish-English; things didnot go as well for the German-English pair andespecially not for the Finnish-English pair.
Wehad a hard time improving our baseline perfor-mance in such a tight schedule and only man-aged to improve our German-English system.
Wewere less lucky with other attempts we imple-mented, among them, the smoothing of a trans-fer table with WORDNET, and the segmentationof the Finnish corpus into smaller units.ReferencesG.
Cao, J. Nie, and J. Bai.
2005.
Integrating Wordrelationships into Language Models.
In to appearin Proc.
of SIGIR.S.
Katz.
1997.
Estimation of Probabilities fromSparse Data for the Language Model Component ofa Speech Recognizer.
IEEE Transactions on Acous-tics Speech and Signal Processing, 35.Philipp Koehn and Kevin Knight.
2003.
EmpiricalMethods for Compound Splitting.
In EACL, Bu-dapest, Hungary.P.
Koehn, F.J. Och, and D. Marcu.
2003.
StatisticalPhrase-Based Translation.
In Proceedings of HLT,pages 127?133.P.
Koehn.
2004.
Pharaoh: a Beam Search Decoderfor Phrase-Based SMT.
In Proceedings of AMTA,pages 115?124.F.J.
Och and H. Ney.
2000.
Improved StatisticalAlignment Models.
In Proceedings of ACL, pages440?447, Hongkong, China.140
