Proceedings of the 43rd Annual Meeting of the ACL, pages 499?506,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsResume Information Extraction with Cascaded Hybrid ModelKun Yu Gang Guan Ming ZhouDepartment of Computer Scienceand TechnologyDepartment of ElectronicEngineering Microsoft Research AsiaUniversity of Science andTechnology of China Tsinghua University5F Sigma Center, No.49 ZhichunRoad, HaidianHefei, Anhui, China, 230027 Bejing, China, 100084 Bejing, China, 100080yukun@mail.ustc.edu.cn guangang@tsinghua.org.cn mingzhou@microsoft.comAbstractThis paper presents an effective approachfor resume information extraction tosupport automatic resume managementand routing.
A cascaded informationextraction (IE) framework is designed.
Inthe first pass, a resume is segmented intoa consecutive blocks attached with labelsindicating the information types.
Then inthe second pass, the detailed information,such as Name and Address, are identifiedin certain blocks (e.g.
blocks labelledwith Personal Information), instead ofsearching globally in the entire resume.The most appropriate model is selectedthrough experiments for each IE task indifferent passes.
The experimental resultsshow that this cascaded hybrid modelachieves better F-score than flat modelsthat do not apply the hierarchicalstructure of resumes.
It also shows thatapplying different IE models in differentpasses according to the contextualstructure is effective.1 IntroductionBig enterprises and head-hunters receivehundreds of resumes from job applicants every day.Automatically extracting structured informationfrom resumes of different styles and formats isneeded to support the automatic construction ofdatabase, searching and resume routing.
Thedefinition of resume information fields varies indifferent applications.
Normally, resumeinformation is described as a hierarchical structureThe research was carried out in Microsoft Research Asia.with two layers.
The first layer is composed ofconsecutive general information blocks such asPersonal Information, Education etc.
Then withineach general information block, detailedinformation pieces can be found, e.g., in PersonalInformation block, detailed information such asName, Address, Email etc.
can be further extracted.Info Hierarchy Info Type (Label)General InfoPersonal Information(G1);Education(G2); ResearchExperience(G3); Award(G4);Activity(G5); Interests(G6);Skill(G7)PersonalDetailed Info(PersonalInformation)Name(P1); Gender(P2);Birthday(P3); Address(P4); Zipcode(P5); Phone(P6);Mobile(P7); Email(P8);Registered Residence(P9);Marriage(P10); Residence(P11);Graduation School(P12);Degree(P13); Major(P14)DetailedInfoEducationalDetailed Info(Education)Graduation School(D1);Degree(D2); Major(D3);Department(D4)Table 1.
Predefined information types.Based on the requirements of an ongoingrecruitment management system whichincorporates database construction with IEtechnologies and resume recommendation(routing), as shown in Table 1, 7 generalinformation fields are defined.
Then, for PersonalInformation, 14 detailed information fields aredesigned; for Education, 4 detailed informationfields are designed.
The IE task, as exemplified inFigure 1, includes segmenting a resume intoconsecutive blocks labelled with generalinformation types, and further extracting thedetailed information such as Name and Addressfrom certain blocks.Extracting information from resumes with highprecision and recall is not an easy task.
In spite of499Figure 1.
Example of a resume and the extracted information.constituting a restricted domain, resumes can bewritten in multitude of formats (e.g.
structuredtables or plain texts), in different languages (e.g.Chinese and English) and in different file types(e.g.
Text, PDF, Word etc.).
Moreover, writingstyles could be very diversified.Among the methods in IE, Hidden Markovmodelling has been widely used (Freitag andMcCallum, 1999; Borkar et al, 2001).
As a state-based model, HMMs are good at extractinginformation fields that hold a strong order ofsequence.
Classification is another popular methodin IE.
By assuming the independence ofinformation types, it is feasible to classifysegmented units as either information types to beextracted (Kushmerick et al, 2001; Peshkin andPfeffer, 2003; Sitter and Daelemans, 2003), orinformation boundaries (Finn and Kushmerick,2004).
This method specializes in settling theextraction problem of independent informationtypes.Resume shares a document-level hierarchicalcontextual structure where the related informationunits usually occur in the same textual block, andtext blocks of different information categoriesusually occur in a relatively fixed order.
Suchcharacteristics have been successfully used in thecategorization of multi-page documents byFrasconi et al (2001).In this paper, given the hierarchy of resumeinformation, a cascaded two-pass IE framework isdesigned.
In the first pass, the general informationis extracted by segmenting the entire resume intoconsecutive blocks and each block is annotatedwith a label indicating its category.
In the secondpass, detailed information pieces are furtherextracted within the boundary of certain blocks.Moreover, for different types of information, themost appropriate extraction method is selectedthrough experiments.
For the first pass, since thereexists a strong sequence among blocks, a HMMmodel is applied to segment a resume and eachblock is labelled with a category of generalinformation.
We also apply HMM for theeducational detailed information extraction for thesame reason.
In addition, classification basedmethod is selected for the personal detailedinformation extraction where information itemsappear relatively independently.Tested with 1,200 Chinese resumes,experimental results show that exploring thehierarchical structure of resumes with thisproposed cascaded framework improves theaverage F-score of detailed information extraction500greatly, and combining different IE models indifferent layer properly is effective to achievegood precision and recall.The remaining part of this paper is structured asfollows.
Section 2 introduces the related work.Section 3 presents the structure of the cascadedhybrid IE model and introduces the HMM modeland SVM model in detail.
Experimental resultsand analysis are shown in Section 4.
Section 5provides a discussion of our cascaded hybridmodel.
Section 6 is the conclusion and future work.2 Related WorkAs far as we know, there are few publishedworks on resume IE except some products, forwhich there is no way to determine the technicaldetails.
One of the published results on resume IEwas shown in Ciravegna and Lavelli (2004).
Inthis work, they applied (LP)2 , a toolkit of IE, tolearn information extraction rules for resumeswritten in English.
The information defined intheir task includes a flat structure of Name, Street,City, Province, Email, Telephone, Fax and Zipcode.
This flat setting is not only different fromour hierarchical structure but also different fromour detailed information pieces.Besides, there are some applications that areanalogous to resume IE, such as seminarannouncement IE (Freitag and McCallum, 1999),job posting IE (Sitter and Daelemans, 2003; Finnand Kushmerick, 2004) and address segmentation(Borkar et al, 2001; Kushmerick et al, 2001).Most of the approaches employed in theseapplications view a text as flat and extractinformation from all the texts directly (Freitag andMcCallum, 1999; Kushmerick et al, 2001;Peshkin and Pfeffer, 2003; Finn and Kushmerick,2004).
Only a few approaches extract informationhierarchically like our model.
Sitter andDaelemans (2003) present a double classificationapproach to perform IE by extracting words frompre-extracted sentences.
Borkar et al (2001)develop a nested model, where the outer HMMcaptures the sequencing relationship amongelements and the inner HMMs learn the finerstructure within each element.
But theseapproaches employ the same IE methods for allthe information types.
Compared with them, ourmodel applies different methods in different sub-tasks to fit the special contextual structure ofinformation in each sub-task well.3 Cascaded Hybrid ModelFigure 2 is the structure of our cascaded hybridmodel.
The first pass (on the left hand side)segments a resume into consecutive blocks with aHMM model.
Then based on the result, the secondpass (on the right hand side) uses HMM to extractthe educational detailed information and SVM toextract the personal detailed information,respectively.
The block selection module is used todecide the range of detailed information extractionin the second pass.Figure 2.
Structure of cascaded hybrid model.3.1 HMM Model3.1.1 Model DesignFor general information, the IE task is viewed aslabelling the segmented units with predefined classlabels.
Given an input resume T which is asequence of words w1,w2,?,wk, the result ofgeneral information extraction is a sequence ofblocks in which some words are grouped into acertain block T = t1, t2,?, tn, where ti is a block.Assuming the expected label sequence of T is L=l1,l2,?, ln,  with each block being assigned a label li,we get the sequence of block and label pairs Q=(t1,l1), (t2, l2),?,(tn, ln).
In our research, we simplyassume that the segmentation is based on thenatural paragraph of T.Table 1 gives the list of information types to beextracted, where general information isrepresented as G1~G7.
For each kind of generalinformation, say Gi, two labels are set: Gi-B meansthe beginning of Gi, Gi-M means the remainderpart of Gi.
In addition, label O is defined torepresent a block that does not belong to anygeneral information types.
With these positionalinformation labels, general information can beobtained.
For instance, if the label sequence Q for501a resume with 10 paragraphs is Q=(t1, G1-B), (t2,G1-M) , (t3, G2-B) , (t4, G2-M) , (t5, G2-M) , (t6, O) ,(t7, O) , (t8, G3-B) , (t9, G3-M) , (t10, G3-M), threetypes of general information can be extracted asfollows: G1:[t1, t2], G2:[t3, t4, t5], G3:[t8, t9, t10].Formally, given a resume T=t1,t2,?,tn, seek alabel sequence L*=l1,l2,?,ln, such that theprobability of the sequence of labels is maximal.
)|(maxarg* TLPLL=  (1)According to Bayes?
equation, we have)()|(maxarg* LPLTPLL?=  (2)If we assume the independent occurrence ofblocks labelled as the same information types, wehave?==niii ltPLTP1)|()|(  (3)We assume the independence of wordsoccurring in ti and use a unigram model, whichmultiplies the probabilities of these words to getthe probability of ti.
},...,{   where), |()|( 211miimrrii wwwtlwPltP ==?=(4)If a tri-gram model is used to estimate P(L), wehave?=??
?=niiii lllPllPlPLP321121 ),|()|()()( (5)To extract educational detailed informationfrom Education general information, we useanother HMM.
It also uses two labels Di-B and Di-M to represent the beginning and remaining part ofDi, respectively.
In addition, we use label O torepresent that the corresponding word does notbelong to any kind of educational detailedinformation.
But this model expresses a text T asword sequence T=w1,w2,?,wn.
Thus in this model,the probability P(L) is calculated with Formula 5and the probability P(T|L) is calculated by?==niii lwPLTP1)|()|(  (6)Here we assume the independent occurrence ofwords labelled as the same information types.3.1.2 Parameter EstimationBoth words and named entities are used asfeatures in our HMMs.
A Chinese resume C=c1?,c2?,?,ck?
is first tokenized into C= w1,w2,?,wkwith a Chinese word segmentation system LSP(Gao et al, 2003).
This system outputs predefinedfeatures, including words and named entities in 8types (Name, Date, Location, Organization, Phone,Number, Period, and Email).
The named entitiesof the same type are normalized into single ID infeature set.In both HMMs, fully connected structure withone state representing one information label isapplied due to its convenience.
To estimate theprobabilities introduced in 3.1.1, maximumlikelihood estimation is used, which are),(),,(),|(212121??????
=iiiiiiii llcountlllcountlllP  (7))(),()|(111???
=iiiii lcountllcountllP  (8)ordsdistinct w mcontainsistatewhere,),(),()|(1?== mriririrlwcountlwcountlwP(9)3.1.3 SmoothingShort of training data to estimate probability is abig problem for HMMs.
Such problems may occurwhen estimating either P(T|L) with unknown wordwi or P(L) with unknown events.Bikel et al (1999) mapped all unknown wordsto one token _UNK_ and then used a held-out datato train the bi-gram models where unknown wordsoccur.
They also applied a back-off strategy tosolve the data sparseness problem when estimatingthe context model with unknown events, whichinterpolates the estimation from training corpusand the estimation from the back-off model withcalculated parameter ?
(Bikel et al, 1999).
Freitagand McCallum (1999) used shrinkage to estimatethe emission probability of unknown words, whichcombines the estimates from data-sparse states ofthe complex model and the estimates in relateddata-rich states of the simpler models with aweighted average.In our HMMs, we first apply Good Turingsmoothing (Gale, 1995) to estimate the probabilityP(wr|li) when training data is sparse.
For word wrseen in training data, the emission probability isP(wr|li)?
(1-x), where P(wr|li) is the emissionprobability calculated with Formula 9 and x=Ei/Si(Ei is the number of words appearing only once instate i and Si is the total number of wordsoccurring in state i).
For unknown word wr, theemission probability is x/(M-mi), where M is thenumber of all the words appearing in training data,502and mi is the number of distinct words occurring instate i.
Then, we use a back-off schema (Katz,1987) to deal with the data sparseness problemwhen estimating the probability P(L) (Gao et al,2003).3.2 SVM Model3.2.1 Model DesignWe convert personal detailed informationextraction into a classification problem.
Here weselect SVM as the classification model because ofits robustness to over-fitting and high performance(Sebastiani, 2002).
In the SVM model, the IE taskis also defined as labelling segmented units withpredefined class labels.
We still use two labels torepresent personal detailed information Pi: Pi-Brepresents the beginning of Pi and Pi-M representsthe remainder part of Pi.
Besides of that, label Omeans that the corresponding unit does not belongto any personal detailed information boundariesand information types.
For example, for part of aresume ?Name:Alice (Female)?, we got three unitsafter segmentation with punctuations, i.e.
?Name?,?Alice?, ?Female?.
After applying SVMclassification, we can get the label sequence as P1-B,P1-M,P2-B.
With this sequence of unit and labelpairs, two types of personal detailed informationcan be extracted as P1: [Name:Alice] and P2:[Female].Various ways can be applied to segment T. Inour work, segmentation is based on the naturalsentence of T. This is based on the empiricalobservation that detailed information is usuallyseparated by punctuations (e.g.
comma, Tab tag orEnter tag).The extraction of personal detailed informationcan be formally expressed as follows: given a textT=t1,t2,?,tn, where ti is a unit defined by thesegmenting method mentioned above, seek a labelsequence L* = l1,l2,?,ln, such that the probabilityof the sequence of labels is maximal.
)|(maxarg* TLPLL=  (10)The key assumption to apply classification in IEis the independence of label assignment betweenunits.
With this assumption, Formula 10 can bedescribed as?===niiilllLtlPLn 1...,* )|(maxarg21(11)Thus this probability can be maximized bymaximizing each term in turn.
Here, we use theSVM score of labelling ti with li to replace P(li|ti).3.2.2 Multi-class ClassificationSVM is a binary classification model.
But in ourIE task, it needs to classify units into N classes,where  N is two times of the number of personaldetailed information types.
There are two popularstrategies to extend a binary classification task toN classes (A.Berger, 1999).
The first is One vs. Allstrategy, where N classifiers are built to separateone class from others.
The other is Pairwisestrategy, where N?
(N-1)/2 classifiers consideringall pairs of classes are built and final decision isgiven by their weighted voting.
In our model, weapply the One vs. All strategy for its goodefficiency in classification.
We construct oneclassifier for each type, and classify each unit withall these classifiers.
Then we select the type thathas the highest score in classification.
If theselected score is higher than a predefined threshold,then the unit is labelled as this type.
Otherwise it islabelled as O.3.2.3 Feature DefinitionFeatures defined in our SVM model aredescribed as follows:Word: Words that occur in the unit.
Each wordappearing in the dictionary is a feature.
We useTF?IDF as feature weight, where TF means wordfrequency in the text, and IDF is defined as:wNNLogwIDF 2)( =  (12)N: the total number of training examples;Nw: the total number of positive examples that contain word wNamed Entity: Similar to the HMM models, 8types of named entities identified by LSP, i.e.,Name, Date, Location, Organization, Phone,Number, Period, Email, are selected as binaryfeatures.
If any one type of them appears in thetext, then the weight of this feature is 1, otherwiseis 0.3.3 Block SelectionBlock selection is used to select the blocksgenerated from the first pass as the input of thesecond pass for detailed information extraction.Error analysis of preliminary experiments showsthat the majority of the mistakes of generalinformation extraction resulted from labelling non-503Personal Detailed Info (SVM) Educational Detailed Info (HMM) Model Avg.P (%) Avg.R (%) Avg.F (%) Avg.P (%) Avg.R (%) Avg.F (%)Flat 77.49 82.02 77.74 58.83 77.35 66.02Cascaded 86.83 (+9.34) 76.89 (-5.13) 80.44 (+2.70) 70.78 (+11.95) 76.80 (-0.55) 73.40 (+7.38)Table 2.
IE results with cascaded model and flat model.boundary blocks as boundaries in the first pass.Therefore we apply a fuzzy block selectionstrategy, which not only selects the blocks labelledwith target general information, but also selectstheir neighboring two blocks, so as to enlarge theextracting range.4 Experiments and Analysis4.1 Data and Experimental SettingWe evaluated this cascaded hybrid model with1,200 Chinese resumes.
The data set was dividedinto 3 parts: training data, parameter tuning dataand testing data with the proportion of 4:1:1.
6-folder cross validation was conducted in all theexperiments.
We selected SVMlight (Joachims,1999) as the SVM classifier toolkit and LSP (Gaoet al, 2003) for Chinese word segmentation andnamed entity identification.
Precision (P), recall (R)and F-score (F=2PR/(P+R)) were used as the basicevaluation metrics and macro-averaging strategywas used to calculate the average results.
For thespecial application background of our resume IEmodel, the ?Overlap?
criterion (Lavelli et al, 2004)was used to match reference instances andextracted instances.
We define that if theproportion of the overlapping part of extractedinstance and reference instance is over 90%, thenthey match each other.A set of experiments have been designed toverify the effectiveness of exploring document-level hierarchical structure of resume and choosethe best IE models (HMM vs. classification) foreach sub-task.z Cascaded model vs. flat modelTwo flat models with different IE methods(SVM and HMM) are designed to extract personaldetailed information and educational detailedinformation respectively.
In these models, nohierarchical structure is used and the detailedinformation is extracted from the entire resumetexts rather than from specific blocks.
These twoflat models will be compared with our proposedcascaded model.z Model selection for different IE tasksBoth SVM and HMM are tested for all the IEtasks in first pass and in second pass.4.2 Cascaded Model vs. Flat ModelWe tested the flat model and cascaded modelwith detailed information extraction to verify theeffectiveness of exploring document-levelhierarchical structure.
Results (see Table 2) showthat with the cascaded model, the precision isgreatly improved compared with the flat modelwith identical IE method, especially foreducational detailed information.
Although there issome loss in recall, the average F-score is stilllargely improved in the cascaded model.4.3 Model Selection for Different IE TasksThen we tested different models for the generalinformation and detailed information to choose themost appropriate IE model for each sub-task.Model Avg.P (%) Avg.R (%)SVM 80.95 72.87HMM 75.95 75.89Table 3.
General information extraction withdifferent models.Personal DetailedInfoEducationalDetailed Info Model Avg.P(%)Avg.R(%)Avg.P(%)Avg.R(%)SVM 86.83 76.89 67.36 66.21HMM 79.64 60.16 70.78 76.80Table 4.
Detailed information extraction withdifferent models.Results (see Table 3) show that compared withSVM, HMM achieves better recall.
In ourcascaded framework, the extraction range ofdetailed information is influenced by the result ofgeneral information extraction.
Thus better recallof general information leads to better recall ofdetailed information subsequently.
For this reason,504we choose HMM in the first pass of our cascadedhybrid model.Then in the second pass, different IE models aretested in order to select the most appropriate onefor different sub-tasks.
Results (see Table 4) showthat HMM performs much better in both precisionand recall than SVM for educational detailedinformation extraction.
We think that this isreasonable because HMM takes into account thesequence constraints among educational detailedinformation types.
Therefore HMM model isselected to extract educational detailed informationin our cascaded hybrid model.
While for thepersonal detailed information extraction, we findthat the SVM model gets better precision andrecall than HMM model.
We think that this isbecause of the independent occurrence of personaldetailed information.
Therefore, we select SVM toextract personal detailed information in ourcascaded model.5 DiscussionOur cascaded framework is a ?pipeline?approach and it may suffer from error propagation.For instance, the error in the first pass may betransferred to the second pass when determiningthe extraction range of detailed information.Therefore the precision and recall of detailedinformation extraction in the second pass may bedecreased subsequently.
But we are not surewhether N-Best approach (Zhai et al, 2004) wouldbe helpful.
Because our cascaded hybrid modelapplies different IE methods for different sub-tasks,it is difficult to incorporate the N-best strategy byeither simply combining the scores of the first passand the second pass, or using the scores of thesecond pass to do re-ranking to select the bestresults.
Instead of using N-best, we apply a fuzzyblock selection strategy to enlarge the search scope.Experimental results of personal detailedinformation extraction show that compared withthe exact block selection strategy, this fuzzystrategy improves the average recall of personaldetailed information from 68.48% to 71.34% andreduce the average precision from 83.27% to81.71%.
Therefore the average F-score isimproved by the fuzzy strategy from 75.15% to76.17%.Features are crucial to our SVM model.
Forsome fields (such as Name, Address andGraduation School), only using words as featuresmay result in low accuracy in IE.
The namedentity (NE) features used in our model enhance theaccuracy of detailed information extraction.
Asexemplified by the results (see Table 5) onpersonal detailed information extraction, afteradding named entity features, the F-score areimproved greatly.Field Word +NE (%)  Word  (%)Name 90.22 3.11Birthday 87.31 84.82Address 67.76 49.16Phone 81.57 75.31Mobile 70.64 58.01Email 88.76 85.96Registered Residence 75.97 72.73Residence 51.61 42.86Graduation School 40.96 15.38Degree 73.20 63.16Major 63.09 43.24Table 5.
Personal detailed information extractionwith different features (Avg.F).In our cascaded hybrid model, we apply HMMand SVM in different pass separately to explorethe contextual structure of information types.
Itguarantees the simplicity of our hybrid model.However, there are other ways to combine state-based and discriminative ideas.
For example, Pengand McCallum (2004) applied ConditionalRandom Fields to extract information, whichdraws together the advantages of both HMM andSVM.
This approach could be considered in ourfuture experiments.Some personal detailed information types do notachieve good average F-score in our model, suchas Zip code (74.50%) and Mobile (73.90%).
Erroranalysis shows that it is because these fields do notcontain distinguishing words and named entities.For example, it is difficult to extract Mobile fromthe text ?Phone: 010-62617711 (13859750123)?.But these fields can be easily distinguished withtheir internal characteristics.
For example, Mobileoften consists of certain length of digital figures.To identify these fields, the Finite-StateAutomaton (FSA) that employs hand-craftedgrammars is very effective (Hsu and Chang, 1999).Alternatively, rules learned from annotated dataare also very promising in handling this case(Ciravegna and Lavelli, 2004).We assume the independence of wordsoccurring in unit ti to calculate the probability505P(ti|li) in HMM model.
While in Bikel et al (1999),a bi-gram model is applied where each word isconditioned on its immediate predecessor whengenerating words inside the current name-class.We will compare this method with our currentmethod in the future.6 Conclusions and Future WorkWe have shown that a cascaded hybrid modelyields good results for the task of informationextraction from resumes.
We tested differentmodels for the first pass and the second pass, andfor different IE tasks.
Our experimental resultsshow that the HMM model is effective in handlingthe general information extraction and educationaldetailed information extraction, where there existsstrong sequence of information pieces.
And theSVM model is effective for the personal detailedinformation extraction.We hope to continue this work in the future byinvestigating the use of other well researched IEmethods.
As our future works, we will apply FSAor learned rules to improve the precision and recallof some personal detailed information (such as Zipcode and Mobile).
Other smoothing methods suchas (Bikel et al 1999) will be tested in order tobetter overcome the data sparseness problem.7 AcknowledgementsThe authors wish to thank Dr. JianFeng Gao, Dr.Mu Li, Dr. Yajuan Lv for their help with the LSPtool, and Dr.
Hang Li, Yunbo Cao for theirvaluable discussions on classification approaches.We are indebted to Dr. John Chen for hisassistance to polish the English.
We want alsothank Long Jiang for his assistance to annotate thetraining and testing data.
We also thank the threeanonymous reviewers for their valuable comments.ReferencesA.Berger.
Error-correcting output coding for textclassification.
1999.
In Proceedings of the IJCAI-99Workshop on Machine Learning for Information Filtering.D.M.Bikel, R.Schwartz, R.M.Weischedel.
1999.
An algorithmthat learns what?s in a name.
Machine Learning,34(1):211-231.V.Borkar, K.Deshmukh and S.Sarawagi.
2001.
Automaticsegmentation of text into structured records.
InProceedings of ACM SIGMOD Conference.
pp.175-186.F.Ciravegna, A.Lavelli.
2004.
LearningPinocchio: adaptiveinformation extraction for real world applications.
Journalof Natural Language Engineering, 10(2):145-165.A.Finn and N.Kushmerick.
2004.
Multi-level boundaryclassification for information extraction.
In Proceedings ofECML04.P.Frasconi, G.Soda and A.Vullo.
2001.
Text categorizationfor multi-page documents: a hybrid Na?ve Bayes HMMapproach.
In Proceedings of the 1st ACM/IEEE-CS JointConference on Digital Libraries.
pp.11-20.D.Freitag and A.McCallum.
1999.
Information extractionwith HMMs and shrinkage.
In AAAI99 Workshop onMachine Learning for Information Extraction.
pp.31-36.W.Gale.
1995.
Good-Turing smoothing without tears.
Journalof Quantitative Linguistics, 2:217-237.J.F.Gao, M.Li and C.N.Huang.
2003.
Improved source-channel models for Chinese word segmentation.
InProceedings of ACL03.
pp.272-279.C.N.Hsu and C.C.Chang.
1999.
Finite-state transducers forsemi-structured text mining.
In Proceedings of IJCAI99Workshop on Text Mining: Foundations, Techniques andApplications.
pp.38-49.T.Joachims.
1999.
Making large-scale SVM learning practical.Advances in Kernel Methods - Support Vector Learning.MIT-Press.S.M.Katz.
1987.
Estimation of probabilities from sparse datafor the language model component of a speech recognizer.IEEE ASSP, 35(3):400-401.N.Kushmerick, E.Johnston and S.McGuinness.
2001.Information extraction by text classification.
In IJCAI01Workshop on Adaptive Text Extraction and Mining.A.Lavelli, M.E.Califf, F.Ciravegna, D.Freitag, C.Giuliano,N.Kushmerick and L.Romano.
2004.
A critical survey ofthe methodology for IE evaluation.
In Proceedings of the4th International Conference on Language Resources andEvaluation.F.Peng and A.McCallum.
2004.
Accurate informationextraction from research papers using conditional randomfields.
In Proceedings of HLT/NAACL-2004.
pp.329-336.L.Peshkin and A.Pfeffer.
2003.
Bayesian informationextraction network.
In Proceedings of IJCAI03.
pp.421-426.F.Sebastiani.
2002.
Machine learning in automated textcategorization.
ACM Computing Surveys, 34(1):1-47.A.D.Sitter and W.Daelemans.
2003.
Information extractionvia double classification.
In Proceedings of ATEM03.L.Zhai, P.Fung, R.Schwartz, M.Carpuat and D.Wu.
2004.Using N-best lists for named entity recognition fromChinese speech.
In Proceedings of HLT/NAACL-2004.506
