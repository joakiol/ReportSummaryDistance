Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 65?74,Avignon, France, 24 April 2012. c?2012 Association for Computational LinguisticsParsing the Past ?
Identification of Verb Constructions in Historical TextEva Pettersson?, Bea?ta Megyesi and Joakim NivreDepartment of Linguistics and PhilologyUppsala University?Swedish National Graduate Schoolof Language Technologyfirstname.lastname@lingfil.uu.seAbstractEven though NLP tools are widely used forcontemporary text today, there is a lack oftools that can handle historical documents.Such tools could greatly facilitate the workof researchers dealing with large volumesof historical texts.
In this paper we pro-pose a method for extracting verbs and theircomplements from historical Swedish text,using NLP tools and dictionaries developedfor contemporary Swedish and a set of nor-malisation rules that are applied before tag-ging and parsing the text.
When evaluatedon a sample of texts from the period 1550?1880, this method identifies verbs with anF-score of 77.2% and finds a partially orcompletely correct set of complements for55.6% of the verbs.
Although these re-sults are in general lower than for contem-porary Swedish, they are strong enough tomake the approach useful for informationextraction in historical research.
Moreover,the exact match rate for complete verb con-structions is in fact higher for historicaltexts than for contemporary texts (38.7%vs.
30.8%).1 IntroductionToday there is an abundance of NLP tools thatcan analyse contemporary language and extractinformation relevant to a particular user need, butthere is a real lack of tools that can handle histor-ical documents.
Historians and other researchersworking with older texts are still mostly forced tomanually search large amounts of text in order tofind the passages of interest to their research.
De-veloping tools to facilitate this process is a greatchallenge, however, as historical texts vary greatlyin both spelling and grammar between differentauthors, genres and time periods, and even withinthe same text, due to the lack of spelling conven-tions.
In addition to this, there is a shortage ofannotated resources that can be used for the de-velopment and evaluation of new tools.The work presented in this paper has been car-ried out in cooperation with historians, who arestudying what men and women did for a livingin the Early Modern Swedish society.
Currently,the historians are manually extracting segmentsdescribing work activities from a number of his-torical texts, and entering them into a database,the Gender and Work Database.
Their work so farhas shown that the typical segment describing anactivity of work is a verb construction, that is, averb together with its complements (A?gren et al,2011).
(Examples of such segments can be foundbelow in Table 1.)
It is very likely that the manualeffort and the time needed by the historians to findthese segments and enter them into the databasecould be substantially reduced if verbs and theircomplements were automatically extracted andpresented to the historian.
This would give a gen-eral overview of the content of a text, and thetask of the historian would be to select those seg-ments that are actually describing work activities.By linking extracted segments back to larger pas-sages of text, historians would also be able to findadditional segments that were missed by the firstautomatic extraction.
The core of such a systemwould be a component for identifying verb con-structions in running text.We propose a method for automatically iden-tifying verbs and their complements in varioustypes of historical documents, produced in theEarly Modern Swedish period (1550?1800).
Themethod is based on using existing NLP tools for65contemporary Swedish, in particular a part-of-speech tagger and a syntactic parser, and auto-matically normalising the input text into a moremodern orthography before running it throughthe tagger and parser.
In order to increase theprecision of complement extraction, we use va-lency dictionaries to filter out unlikely comple-ments in the output of the syntactic parser.
Usingthis method, we are able to identify verbs withan F-score of 77.2% and find a partially or com-pletely correct set of complements for 55.6% ofthe verbs.
To our knowledge, extracting verb con-structions from historical texts is a task that hasnot been directly addressed in previous research,which means that these results are also importantin setting benchmarks for future research.The paper is structured as follows.
Section 2reviews related work.
Section 3 describes themethod for identification of verbs and comple-ments in more detail.
Section 4 presents the dataand evaluation metrics used in our experiments,and Section 5 discusses the results of the evalua-tion.
Finally, Section 6 concludes the paper.2 Related WorkUsing NLP tools for analysing historical texts isstill to a large extent unexplored.
There is how-ever a growing interest in this area, and there havebeen attempts to analyse historical texts (1) by us-ing contemporary NLP tools as they are, (2) byusing such tools in combination with normalisa-tion rules and/or dictionaries covering historicallanguage variation, and (3) by training new toolson annotated historical corpora.Pennacchiotti and Zanzotto (2008) concludedthat contemporary NLP tools are not suitable asthey are for analysing historical text.
They triedto use a contemporary dictionary, morphologicalanalyser and part-of-speech tagger to analyse Ital-ian texts from the period 1200?1881.
In their ex-periments, the dictionary only covered approxi-mately 27% of the words in the oldest text, ascompared to 62.5% of the words in a contem-porary Italian newspaper text.
Consequently, themorphological analyser based on the dictionaryreached an accuracy of only 48%, as comparedto 91% for contemporary text.
Similarly, the part-of-speech tagger used reached an accuracy of only54%, as compared to 97% for contemporary text.Oravecz et al (2010) included a standardis-ation/normalisation step in their work on semi-automatically annotating a corpus of Old Hun-garian.
Normalisation was performed using anoisy channel model combined with morphologi-cal analysis filtering and decision tree reranking.Combining these methods, they reached a normal-isation precision of 73.3%.Rocio et al (1999) used a grammar of contem-porary Portuguese to syntactically annotate me-dieval Portuguese texts.
A dictionary and inflec-tional rules for medieval Portuguese were addedto the parser, to make it suitable for handling thesetexts.
This approach proved to be successful forpartial parsing of medieval Portuguese texts, eventhough there were some problems remaining con-cerning grammar limitations, dictionary incom-pleteness and insufficient part-of-speech tagging.Sa?nchez-Marco et al (2011) adapted an ex-isting NLP tool to deal with Old Spanish.
Theadapted tool had an accuracy of 94.5% in find-ing the right part of speech, and 89.9% accuracyin finding the complete morphological tag.
Theadaptation was performed on the basis of a 20 mil-lion token corpus of texts from the 12th to the 16thcentury, and included expansion of the dictionary,modification of tokenisation and affixation rules,and retraining of the tagger.
The retraining wasbased on a gold standard of 30,000 tokens, wherethe tokens were first pre-annotated with the con-temporary tagger, and then manually corrected.Adding new words to the dictionary had the high-est impact on the results.
This was done by au-tomatically generating word forms through map-ping old spelling variants to their contemporarycounterparts.Pettersson and Nivre (2011) presented a studyon automatically extracting verbs from Swedish17th century texts, using contemporary languagetechnology tools combined with normalisationof the input text.
The verb extraction processincluded an iterative process of normalisationand morphological analysis, followed by part-of-speech tagging for disambiguation of competinginterpretations and for analysing words still un-known to the morphological analyser after all nor-malisation rules had been applied.
Using thismethod, verbs were extracted with 82% precisionand 88% recall.
The study also included the re-sults of using only the part-of-speech tagger forverb recognition, i.e., dropping the morphologi-cal analyser.
This resulted in a small decrease inprecision to 81% and in recall to 86%.663 Extraction of Verb ConstructionsIn this paper, we will focus on adapting existingNLP tools by adding normalisation rules prior toprocessing.
We will mainly follow the method-ology for verb extraction described in Petters-son and Nivre (2011), but adding the extractionof not only the verbs themselves, but also theiradherent complements.
It would perhaps havebeen desirable to use tools specifically trained foranalysing historical texts.
This would however bea resource-demanding task, considering the lackof annotated data and the language variation, andis currently not a realistic scenario.The goal is to automatically extract verbs andrelevant complements from historical texts, in or-der to give an overview of the contents and presentsegments that are possibly describing work activ-ities.
In this context, we use the term complementin a broad sense and do not impose a sharp dis-tinction between complements and adjuncts, es-pecially not for prepositional phrases.
This is mo-tivated by the fact that in the Gender and WorkDatabase, both segments that would traditionallybe seen as complements and phrases that wouldrather be categorised as adjuncts have been con-sidered relevant.A closer look at the database shows that 67%of the entered segments consist of a verb with adirect object.
Other common constructions areverbs with a prepositional complement (11%),verbs with both a direct object and a preposi-tional complement (10%), and (intransitive) verbswithout complements (7%).
Table 1 illustratesthe most common construction types found inthe database, which have been used to define therules for extracting complements from parsed sen-tences.
There were also a small number of seg-ments (8 in total), that we were not able to cate-gorise.3.1 System OverviewThe extraction of verbs and their complements isbasically performed in five steps:1.
Tokenisation2.
Normalisation3.
Part-of-speech tagging4.
Parsing5.
Extraction of verb constructionsFreq Comp Source Text Example273 dobj dhe ba?rgadhe [Ho?o?
]they harvested [Hay]47 pcomp [med een ha?st] kio?rttdriven [with a horse]43 dobj [det kio?pet] Han+ [med ha?nness man] giortpcomp [the bargain] Hemade [with her husband]30 intrans malato grind5 dobj hulpit [Muremest:]+ [inla?ggia Trappestenar]infc helped [the Bricklayer][to make a Stone Stair]3 indobj [honom] [Ja?rnet] sa?lltt+ sold [him] [the Iron]dobj1 subc tillsee [att icke barnenskulle go?ra skada]see to it [that the childrendo not do any harm]Table 1: Segments describing work activities in theGender and Work Database; verbs underlined; com-plements in brackets.
Grammatical functions: dobj =direct object, pcomp = prepositional complement, in-trans = intransitive, indobj = indirect object, infc = in-finitive clause, subc = subordinate clause.Tokenisation is performed with a simple tokeniserfor Swedish that has not been adapted for histori-cal texts.3.2 NormalisationAfter tokenisation, each word is normalised to amore modern spelling using a set of 29 hand-crafted rules.
The rules were developed us-ing a text sample from Per Larssons dombok,a selection of court records from 1638 (Edling,1937), a sample that has not been used in sub-sequent evaluation.
An example of a normalisa-tion rule is the transformation of the letter com-bination sch into sk, as in the old spelling schallthat is normalised to the contemporary spellingskall (?shall/should?).
Some additional rules werealso formulated based on the reformed Swedishspelling introduced in 1906 (Bergman, 1995).This set of rules includes the transformation ofdouble vowels into a single vowel, as in so?o?ka,which is normalised into so?ka (?search?
).673.3 Part-of-speech TaggingThe purpose of part-of-speech tagging in our ex-periments is both to find the verbs in the text andto prepare for the parsing step, in which the com-plements are identified.
Part-of-speech tagging isperformed using HunPOS (Hala?csy et al, 2007),a free and open source reimplementation of theHMM-based TnT-tagger by Brants (2000).
Thetagger is used with a pre-trained language modelbased on the Stockholm-Umea?
Corpus (SUC), abalanced, manually annotated corpus of differenttext types representative of the Swedish languagein the 1990s, comprising approximately one mil-lion tokens (Gustafson-Capkova?
and Hartmann,2006).
Megyesi (2009) showed that the HunPOStagger trained on SUC, is one of the best perform-ing taggers for (contemporary) Swedish texts.3.4 ParsingThe normalised and tagged input text is parsed us-ing MaltParser version 1.6, a data-driven depen-dency parser developed by Nivre et al (2006a).In our experiments, the parser is run with a pre-trained model1 for parsing contemporary Swedishtext, based on the Talbanken section of theSwedish Treebank (Nivre et al, 2006b).
Theparser produces dependency trees labeled withgrammatical functions, which can be used to iden-tify different types of complements.3.5 Extraction of Verb ConstructionsThe extraction of verb constructions from thetagged and parsed text is performed in two steps:1.
Every word form analysed as a verb by thetagger is treated as the head of a verb con-struction.2.
Every phrase analysed as a dependent of theverb by the parser is treated as a complementprovided that it has a relevant grammaticalfunction.The following grammatical functions are definedto be relevant:1.
Subject (SS)2.
Direct object (OO)3.
Indirect object (IO)1http://maltparser.org/mco/swedish parser/swemalt.html4.
Predicative complement (SP)5.
Prepositional complement (OA)6.
Infinitive complement of object (VO)7.
Verb particle (PL)Subjects are included only if the verb has beenanalysed as a passive verb by the tagger, in whichcase the subject is likely to correspond to the di-rect object in the active voice.In an attempt to improve precision in the com-plement extraction phase, we also use valencydictionaries for filtering the suggested comple-ments.
The valency frame of a verb tells us whatcomplements the verb is likely to occur with.The assumption is that this information couldbe useful for removing unlikely complements,i.e., complements that are not part of the valencyframe for the verb in question.
The followingexample illustrates the potential usefulness of thismethod:J midler tijd kom greffuinnans gotze fougte thijttHowever, the Countess?
estate bailiff came thereIn this case, the parser analysed the partial nounphrase greffuinnans gotze (?the Countess?
estate?
)as a direct object connected to kom (?came?
).However, since the word kom is present in the va-lency dictionaries, we know that it is an intransi-tive verb that does not take a direct object.
Hence,this complement can be removed.
The valencydictionaries used for filtering are:1.
The Lexin dictionary, containing 3,550 verblemmas with valency information.22.
The Parole dictionary, containing 4,308 verblemmas with valency information.33.
An in-house machine translation dictionary,containing 2,852 verb lemmas with valencyinformation.4 Experimental Setup4.1 DataIn order to evaluate the accuracy of our method,we have used ten texts from the period 1527?1737.
The text types covered are court records2http://spraakbanken.gu.se/lexin/valens lexikon.html3http://spraakdata.gu.se/parole/lexikon/swedish.parole.lexikon.html68and documents related to the Church.
In total,there are 444,075 tokens in the corpus, distributedas follows (number of tokens in parentheses):Court records:1.
Per Larssons dombok (subset),1638(11,439)2.
Hammerdals tingslag, 1649?1686 (66,928)3.
Revsunds tingslag, 1649?1689 (101,020)4.
Vendels socken, 1615?45 (59,948)5.
Vendels socken, 1736?37 (55,780)6.
O?stra ha?rads i Njudung,1602?1605(34,956)Documents related to the Church:1.
Va?stera?s recess, 1527 (12,193)2.
1571 a?rs kyrkoordning (49,043)3.
Uppsala mo?tes beslut, 1593 (26,969)4.
1686 a?rs kyrkolag (25,799)A gold standard of 40 randomly selected sen-tences from each text was compiled, i.e., in total400 sentences.
The gold standard was producedby manually annotating the sentences regardingverbs and complements.
Because sentences aremuch longer in these texts than in contemporarytexts, the 400 sentences together contain a total of3,105 verbs.
Each word form that was interpretedas a verb was annotated with the tag VB, and com-plements were enclosed in brackets labeled withtheir grammatical function.
This is illustrated inFigure 1, which shows an annotated segment fromthe test corpus.For comparison with contemporary text, wemake use of a subset of the Stockholm-Umea?
Cor-pus of contemporary Swedish text, SUC (Ejerhedand Ka?llgren, 1997).
This subset contains thosesegments in SUC that have been syntacticallyannotated and manually revised in the SwedishTreebank.
In total, the subset includes approxi-mately 20,000 tokens.
Since the tagger used in theexperiments on historical texts is trained on thewhole of SUC, we had to slightly modify the ex-traction algorithm in order not to evaluate on thesame data as the tagger has been trained.
Whentesting the algorithm on contemporary text, wetherefore trained a new model for the tagger, in-cluding all tokens in SUC except for the tokensreserved for evaluation.Anklagadhes/VB1 Was accused/VB1[SSvb1 [SSvb1ryttaren the horse-riderHindrik HindrikHyldh HyldhSSvb1] SSvb1]hwilken who[OOvb2 [OOvb2mo?krenkningh rapeOOvb2] OOvb2]giordt/VB2 done/VB2medh withen agienta girlElin ElinEriksdotter Eriksdotteri inSika?s Sika?s, ,hwarfo?re whyra?tten the Courthonnom himtilspordhe/VB3 asked/VB3[OOvb3 [OOvb3om ifhan he[OOvb4 [OOvb4dhetta thisOO vb4] OO vb4]giordt/VB4 done/VB4hafwer/VB5 has/VB5OO vb3] OO vb3]Figure 1: Annotated segment in the test corpus.4.2 Evaluation MetricsIn order to get a more fine-grained picture of thesystem?s performance, we want to evaluate threedifferent aspects:1.
Identification of verbs2.
Identification of complements3.
Identification of holistic verb constructionsThe identification of verbs depends only on thepart-of-speech tagger and can be evaluated usingtraditional precision and recall measures, compar-ing the tokens analysed as verbs by the tagger tothe tokens analysed as verbs in the gold standard.The identification of complements depends onboth the tagger and the parser and can also be69evaluated using precision and recall measures.In this case, every complement identified by theparser is compared to the complements annotatedin the gold standard.
Precision is the number ofcorrect complements found by the parser dividedby the total number of complements output bythe parser, while recall is the number of correctcomplements found by the parser divided by thenumber of complements in the gold standard.We do not take the labels into account whenassessing complements as correct or incorrect.The motivation for this is that the overall aimof the complement extraction is to present verbexpressions to historians, for them to considerwhether they are describing work activities ornot.
In this context, only textual strings willbe of interest, and grammatical function labelsare ignored.
For example, assume that the goldstandard is:lefverere [IO honom] [OO Sa?dh]deliver [IO him] [OO grain]and that the system produces:lefverere [OO honom]deliver [OO him]In this context, the complement honom (?him?
)will be regarded as correct, even though it hasbeen analysed as a direct object instead of anindirect object.
On the other hand, the evaluationof complement identification is strict in thatit requires the complement found to coincideexactly with the complement in the gold standard.For example, assume the gold standard is:effterfra?gat [OA om sinss manss do?dh]asked [OA about her husband?s death]and that the system produces:effterfra?gat [OA om sinss manss]asked [OA about her husband?s]In this case, the complement will not be regardedas correct because it does not cover exactly thesame textual string as the gold standard annota-tion.The identification of holistic verb construc-tions, that is, a verb and all its complements,depends on the identification of verbs and com-plements, as well as the optional filtering ofcomplements using valency dictionaries.
Herewe want to evaluate the entire text segmentextracted in a way that is relevant for the intendedapplication of the system.
First of all, this meansthat partially correct constructions should betaken into account.
Consider again the earlierexample:effterfra?gat [OA om sinss manss do?dh]asked [OA about her husband?s death]and assume that the system produces:effterfra?gat [OA om sinss manss]asked [OA about her husband?s]As noted above, this complement would be con-sidered incorrect in the precision/recall evaluationof complement extraction, even though only oneword is missing as compared to the gold standard,and the output would probably still be valuable tothe end-user.
Secondly, we should consider the to-tal segment extracted for a verb including all com-plements, rather than inspecting each complementseparately.In order to reflect partially correct comple-ments and take the total segment extracted foreach verb into account, we use a string-basedevaluation method for the identification of holis-tic verb constructions.
In this evaluation, all la-bels and brackets are removed before comparingthe segments extracted to the segments in the textcorpus and each extracted instance is classified asfalling into one of the four following categories:?
Fully correct complement set (F)?
Partially correct complement set (P)?
Incorrect complement set (I)?
Missing complement set (M)A complement set is regarded as fully correct ifthe output string generated by the system is iden-tical to the corresponding gold standard string.Since labels and brackets have been removed,these analyses will be regarded as identical:lemnat [IO swaranden] [OO tid]given [IO the defendant] [OO time]70lemnat [OO swaranden tid]given [OO the defendant time]A complement set is regarded as partially correctif the output string generated by the system has anon-empty overlap with the corresponding goldstandard string.
For example, the following threesets of analyses will be considered as partiallycorrect (gold standard top, system output bottom):lefverere [IO honom] [OO Sa?dh]deliver [IO him] [OO Grain]lefverere [OO honom]deliver [OO him]effterfra?gat [OA om sinss manss do?dh]asked [OA about her husband?s death]effterfra?gat [OA om sinss manss]asked [OA about her husband?s]betale [PL a?ter] [IO ha?r Mattz] [OO Ra?gen]pay [PL back] [IO mister Mattz] [OO the Rye]betale [OO a?ter ha?r Mattz]pay [OO back mister Mattz]A (non-empty) complement set is regarded as in-correct if the output string has no overlap with thegold standard string.
Finally, a complement set isregarded as missing if the output string is emptybut the gold standard string is not.
It is worth not-ing that the four categories are mutually exclusive.5 Results and DiscussionIn this section, we evaluate the identification ofverbs, complements and holistic verb construc-tions using the data and metrics described in theprevious section.5.1 VerbsResults on the identification of verbs using part-of-speech tagging, with and without normalisa-tion, are reported in Table 2.
As can be seen, recalldrastically increases when normalisation rules areapplied prior to tagging, even though the normal-isation rules used in this experiment are formu-lated based on a subset of one single 17th cen-tury text, and the test corpus contains samples ofvarious text types ranging from 1527?1737.
Nor-malisation also has a small positive effect on pre-cision, and the best result for historical texts is78.4% precision and 76.0% recall.
This is slightlyPrecision Recall F-scoreRaw 75.4 60.0 66.9Norm 78.4 76.0 77.2SUC 99.1 99.1 99.1Table 2: Identification of verbs by tagging.
Raw = Un-normalised input text.
Norm = Normalisation of inputprior to tagging.
SUC = Subset of Stockholm-Umea?corpus of contemporary Swedish texts, as described insection 4.1.lower than the results presented by Pettersson andNivre (2011) where only 17th century text wasused for evaluation, indicating that the normalisa-tion rules are somewhat biased towards 17th cen-tury text, and that the results could be improvedif normalisation were adapted to specific time pe-riods.
It is also worth noting that the results aresubstantially lower for historical text than the re-sults for contemporary text, with precision and re-call at 99.1%, but still high enough to be useful inthe intended context of application.Tokens that are still erroneously analysed bythe tagger include the following cases:?
tokens where the old spelling is identicalto an existing, but different, word formin contemporary language; for example,the spelling skal would in contemporarylanguage be considered a noun (?shell?
)but in the old texts this spelling is usedfor a word that is nowadays spelled skall(?shall/should?)
and should be regarded as averb;?
ambiguous words; for example, past partici-ples are often spelled the same way as thecorresponding past tense verb, but participlesare not regarded as verb forms in our experi-ments;4?
tokens that have not been normalised enoughand thus do not correspond to a word formrecognised by the tagger, e.g., the wordform lemnas which in contemporary lan-guage should be spelled as la?mnas (?beleft?
).4Participles are only used adjectivally in Swedish, as theperfect tense is formed using a distinct supine form of theverb.71Precision Recall F-scoreRaw 24.8 27.5 26.1Norm 28.3 28.2 28.2+Valency 33.1 25.5 28.8SUC 68.2 70.7 69.5+Valency 71.8 56.2 63.0Table 3: Identification of complements by parsing.Raw = Unnormalised input text.
Norm = Normalisa-tion of input prior to tagging and parsing.
+Valency =Adding valency filtering to the setting in the preced-ing row.
SUC = Subset of Stockholm-Umea?
corpus ofcontemporary Swedish texts, as described in section4.1.5.2 ComplementsRecall and precision for the identification of com-plements using parsing are presented in Table 3.In this case, normalisation has a smaller effectthan in the case of tagging and affects precisionmore than recall.
Adding a filter that eliminatesunlikely complements based on the valency frameof the verb in existing dictionaries predictably im-proves precision at the expense of recall and re-sults in a small F-score improvement.Again, the best scores on the historical textsare much lower than the corresponding results forcontemporary text, with an F-score of 28.8% inthe former case and 69.5% in the latter, but it isworth remembering that precision and recall onexactly matching complements is a harsh metricthat is not directly relevant for the intended appli-cation.
Finally, it is worth noting that the valencyfilter has a large negative impact on recall for themodern texts, resulting in a decrease in the F-score, which indicates that the parser in this caseis quite successful at identifying complements (inthe wide sense) that are not covered by the va-lency dictionaries.5.3 Verb ConstructionsAs argued in section 4.2, precision and recall mea-sures are not sufficient for evaluating the extrac-tion of holistic verb constructions.
A more rele-vant assessment is made by counting the numberof fully correct, partially correct, incorrect andmissing complement sets for the verbs identified.Table 4 summarises the results in accordance withthis metric.First of all, we see that normalisation again hasa rather small effect on overall results, increas-F P I MRaw 32.6 20.3 29.3 17.8Norm 34.5 19.5 25.2 20.8+Valency 38.7 16.9 18.9 25.5SUC 30.3 54.2 9.1 6.4+Valency 30.8 47.9 6.8 14.6Table 4: Identification of holistic verb constructions.F = Fully correct, P = Partially correct, I = Incorrect,M = Missing.
Raw = Unnormalised input text.
Norm= Normalisation of input prior to tagging and parsing.+Valency = Adding valency filtering to the setting inthe preceding row.
SUC = Subset of Stockholm-Umea?corpus of contemporary Swedish texts, as described insection 4.1.ing the number of fully correct constructions anddecreasing the number of incorrect constructions,but also leading to an increase in the number ofmissing complements.
Adding the valency fil-ter to remove unlikely complements has a simi-lar effect and increases the percentage of correctlyextracted verb constructions to 38.7% while de-creasing the share of incorrect constructions to18.9%.
However, it also increases the percent-age of verbs with missing complement sets from20.8% to 25.5%.
This is partly due to the factthat some of the verbs are used in a slightly dif-ferent way in historical text as compared to con-temporary text, meaning that the valency framesare not as reliable.
For example, the verb avsta?(?refrain?)
in the historical corpus is used with adirect object, as in Anders Andersson afsta?dt sittskatte hemman (?Anders Andersson refrained hishomestead?
), whereas in a contemporary contextthis verb would more likely be used with a prepo-sitional complement, avsta?
fra?n na?gonting (?re-frain from something?
).In total, 55.6% of the verbs are assigned a fullyor partially correct set of complements.
This isagain lower than the result for contemporary texts(78.7%), but the difference is smaller than for theprevious metrics, which is encouraging given thatthe evaluation in this section is most relevant forthe intended application.
Moreover, it is worthnoting that the difference is mostly to be foundin the category of partially correct constructions,where the best result for modern texts is 54.2%,to be compared to 16.9% for the historical texts.With respect to fully correct constructions, how-ever, the results are actually better for the histor-72ical texts than for the modern texts, 38.7% vs.30.8%, a rather surprising positive result.6 ConclusionWe have presented a method for automatically ex-tracting verbs and their complements from histor-ical Swedish texts, more precisely texts from theEarly Modern era (1550?1800), with the aim ofproviding language technology support for histor-ical research.
We have shown that it is possibleto use existing contemporary NLP tools and dic-tionaries for this purpose, provided that the inputtext is first (automatically) normalised to a moremodern spelling.
With the best configuration ofour tools, we can identify verbs with an F-scoreof 77.2% and find a partially or completely cor-rect set of complements for 55.6% of the verbs.To the best of our knowledge, these are the firstresults of their kind.In addition to presenting a method for the iden-tification of verb constructions, we have also pro-posed a new evaluation framework for such meth-ods in the context of information extraction forhistorical research.
As a complement to standardprecision and recall metrics for verbs and theircomplements, we have evaluated the text seg-ments extracted using the categories fully correct,partially correct, incorrect, and missing.
Oneimportant topic for future research is to validatethis evaluation framework by correlating it to theperceived usefulness of the system when usedby historians working on the Gender and WorkDatabase.
Preliminary experiments using a proto-type system indicate that this kind of support canin fact reduce the time-consuming, manual workthat is currently carried out by historians and otherresearchers working with older texts.Another topic for future research concerns thevariation in performance across time periods andtext types.
In the current evaluation, court recordsand papers related to the Church ranging from1527 to 1737 have been sampled in the gold stan-dard.
It would be interesting to explore in moredetail how the program performs on the oldesttexts as compared to the youngest texts, and oncourt records as compared to the other genres.ReferencesMaria A?gren, Rosemarie Fiebranz, Erik Lindberg, andJonas Lindstro?m.
2011.
Making verbs count.
Theresearch project ?Gender and Work?
and its method-ology.
Scandinavian Economic History Review,59(3):271?291.
Forthcoming.Go?sta Bergman.
1995.
Kortfattad svenskspra?khistoria.
Prisma Magnum, Stockholm, 5thedition.Thorsten Brants.
2000.
TnT - a statistical part-of-speech tagger.
In Proceedings of the 6th AppliedNatural Language Processing Conference (ANLP),Seattle, Washington, USA.Nils Edling.
1937.
Uppla?ndska dombo?cker.
Almqvist& Wiksells.Eva Ejerhed and Gunnel Ka?llgren.
1997.
StockholmUmea?
Corpus.
Version 1.0.
Produced by Depart-ment of Linguistics, Umea?
University and Depart-ment of Linguistics, Stockholm University.
ISBN91-7191-348-3.Sofia Gustafson-Capkova?
and Britt Hartmann.
2006.Manual of the Stockholm Umea?
Corpus version 2.0.Technical report, December.Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.2007.
HunPos - an open source trigram tagger.In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics, pages209?212, Prague, Czech Republic.Bea?ta B. Megyesi.
2009.
The open source taggerHunPos for Swedish.
In Proceedings of the 17thNordic Conference on Computational Linguistics(NODALIDA).Joakim Nivre, Johan Hall, and Jens Nilsson.
2006a.MaltParser: A data-driven parser-generator for de-pendency parsing.
In Proceedings of the 5thinternational conference on Language Resourcesand Evaluation (LREC), pages 2216?2219, Genoa,Italy, May.Joakim Nivre, Jens Nilsson, and Johan Hall.
2006b.Talbanken05: A Swedish treebank with phrasestructure and dependency annotation.
In Proceed-ings of the 5th international conference on Lan-guage Resources and Evaluation (LREC, pages 24?26, Genoa, Italy, May.Csaba Oravecz, Ba?lint Sass, and Eszter Simon.
2010.Semi-automatic normalization of Old Hungariancodices.
In Proceedings of the ECAI Workshop onLanguage Technology for Cultural Heritage, SocialSciences, and Humanities (LaTeCH), pages 55?59,Faculty of Science, University of Lisbon Lisbon,Portugal, August.Marco Pennacchiotti and Fabio Massimo Zanzotto.2008.
Natural language processing across time: Anempirical investigation on Italian.
In Advances inNatural Language Processing.
GoTAL, LNAI, vol-ume 5221, pages 371?382.Eva Pettersson and Joakim Nivre.
2011.
Automaticverb extraction from historical Swedish texts.
InProceedings of the 5th ACL-HLT Workshop on Lan-guage Technology for Cultural Heritage, Social Sci-ences, and Humanities, pages 87?95, Portland, OR,73USA, June.
Association for Computational Linguis-tics.Vito Rocio, Ma?rio Amado Alves, Jose?
Gabriel Lopes,Maria Francisca Xavier, and Grac?a Vicente.
1999.Automated creation of a partially syntactically an-notated corpus of Medieval Portuguese using con-temporary Portuguese resources.
In Proceedings ofthe ATALA workshop on Treebanks, Paris, France.Cristina Sa?nchez-Marco, Gemma Boleda, and Llu??sPadro?.
2011.
Extending the tool, or how to an-notate historical language varieties.
In Proceedingsof the 5th ACL-HLT Workshop on Language Tech-nology for Cultural Heritage, Social Sciences, andHumanities, pages 1?9, Portland, OR, USA, June.Association for Computational Linguistics.74
