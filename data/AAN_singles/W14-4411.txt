Proceedings of the 8th International Natural Language Generation Conference, pages 83?92,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsTowards a Description of Symbolic MapsDaniel Couto ValeSFB/TR8 Spatial CognitionUniversity of Bremendanielvale@uni-bremen.deElisa ValesSFB/TR8 Spatial CognitionUniversity of Bremenevales@uni-bremen.deRumiya IzgalievaSFB/TR8 Spatial CognitionUniversity of Bremenrumiya@uni-bremen.deAbstractSymbolic resources for text synthesis andtext analysis are typically created and storedseparately.
In our case, we have a KPML-resource (Nigel) and a CCG for English.
Inthis paper, we argue that reversing efficientresources such as ours cannot in general beachieved.
For this reason, we propose asymbolic map that can be convertedautomatically into both synthesis- andanalysis-oriented resources.
We show thatcompleteness of description can only beachieved by such a map while efficiencyconcerns can only be tackled by the directedrules of task-oriented resources not becauseof the current state of the art, but becausereversing task-oriented symbolic resources isimpossible in principle.1 IntroductionCurrently, symbolic resources guiding textanalysis and text synthesis are created and storedseparately.
Several researchers have attemptedto use the same resource for both tasks (Kasper,1988; Neumann, 1991; Neumann and vanNoord, 1992; Strzalkowski, 1994; O?Donnell,1994; Pulman, 1995; Klarner, 2005) motivatedby the fact  that this would not only becognitively more plausible but also allowtranslation at a semantic level, integration ofnew words from analysis into synthesis,reduction of costs in engineering as well asmaking it easier to share information amongresearch groups of different fields.The resources we currently use in human-robot interaction in English are also separate: aKPML-resource (Nigel) and a CCG.
Thespecialty about Nigel and our CCG is that theyshare not only the same kind of semantics, butalso the same mapping between symbolic andsemantic structures.
Here ?symbolic structure?
isunderstood as KPML?s ?structure?
and CCG?s?sign?, and corresponds to ?grammaticalconstructions?
of cognitive semantics (Lakoff,1987), to ?linguistic mediation?
of truth-reference semantics (Smith and Brogaard,2003), and to ?wording?
of systemic functionallinguistics (Matthiessen, 1995; Matthiessen andHalliday, 1999; Matthiessen and Halliday, 2004;Halliday and Matthiessen, 2014).In this paper, we shall review the availabledirected rules that constitute the resources inKPML and OpenCCG and argue that they areuseful in their respective tasks ?
either synthesisor analysis, ?
but are either unsuitable or notcompetitive for the inverse task.Aiming not  at  reversibility but  at  reusability,we propose to create a map between symbolicand semantic structures that can be compiledinto both synthesis-oriented and analysis-oriented resources.
With this approach, we aimat  separating concerns, so that efficiency can betackled by the directed rules of task-orientedresources and completeness of description by aless efficient uncompiled shared symbolic map.2 Irreversibility of Current ResourcesIn computational linguistics, approaches totext processing can be divided into statisticaland categorial according to the usage of gradedor binary relations between inputs and outputs ofprocessing.
Approaches can also be divideddepending on whether the textual content is arepresentation of something else (symbolic) orwhether it is a representation of the text  itself(non-symbolic).
In this sense, approaches thathave a semantic structure as input  or output aresymbolic and those that make use of a syntactictree whose composite-component relations donot match the ones of semantics are not.
Thepresent  work falls into the symbolic subset.Although our initial attempt  is categorial, theideas presented here can be used in statisticalapproaches as well, provided that theseapproaches are symbolic in nature.Looking from the perspective of thephilosophy of language, in the last  50 years,computational efforts in categorial symbolic textprocessing have converged on one single notionof a symbolic map.
In such a notion, bothsymbolic (lexical or grammatical) and semanticstructures play an essential role in decidingwhich analytical and synthetic hypotheses are tobe taken further or discarded.
On the textsynthesis front, systemic networks were used byboth KOMET  and Penman engines as directedrules for text synthesis.
Those engines were laterunified into the KOMET-Penman Multilingual83Engine (KPML Engine) (Bateman, 1995a;Bateman, 1995b; Bateman, 1996; Bateman,1997).
On the text analysis front, typed-featureunification was developed and implemented inengines for a family of highly lexicalisedgrammatical frameworks (HLG).
CombinatoryCategorial Grammars (CCG) (Steedman, 1987;Steedman, 1996; Steedman, 1998; Steedman andBaldridge, 2011) are a special type of HLG thatreduce the task of text analysis to accepting orrejecting hypotheses of both symbolic andsemantic composition during functionalunification.
KPML and OpenCCG are then onlycandidates for consideration because they allowthe implementation of a shared symbolic map.In other words, a pair of engines that supportsuch a map is a necessary and sufficientcondition for the reusability scheme we propose.In the following, we shall review thegrammatical notions embedded in the resourcesfor KPML and OpenCCG in order to support  ourargumentation that reversibility of such directedresources is not to be achieved.2.1 Resources for KPMLAccording to the KPML documentation(Bateman, 1996) and our own inspection ofNigel, resources for KMPL may contain threekinds of realisation operations: structural (insert,conflate, expand), linear (partition, order, order-at-front, order-at-end), and inter-rank (preselect,agreement, classify, outclassify, inflectify,lexify).Below symbolic structure, textual tokens areproduced by morphological realisation operatorsof two kinds: one for selecting token copies(preselect-substance, preselect-substance-as-stem, preselect-substance-as-property), and onefor modifying them (morphose).These realisation operators are bundled inwording ?patterns?
that  are linked to classes ofwordings (grammatical features).
The typologyarising from these classes is used as a networkof options (network of grammatical systems)among structure kinds.
The selection of astructure kind of a system is done by a decisiontree (chooser).
Each decision in the decision treeis achieved by inspecting (inquiry) a semanticand lexical specification for a text.
The decisiontree contains not  only decisions (ask) but  alsomappings from lexical/semantic constituents tofunctions of symbolic constituents (identify,copyhub, choose, pledge, termpledge).
Valuescan be associated with a function (concept,modification-specification, terms, term).Finally, there are four ways to produce atoken in KPML.
Three of them consist  ofselecting a word and selecting its form with aform class.
The actual token production is left  toa morphological component.
Two word selectionstrategies are: selecting a word grammatically(lexify, classify, outclassify) and selecting aword associated with a particular conceptualvalue (term-resolve-id).
A mapping betweenconcepts and words is provided either byconcept-word links (annotate-concept) or byembedding word specifications into what wouldotherwise be a pure semantic specification (lex).A distinct mapping function between theintersection of form classes and word patternindexes is implemented in LISP for everylinguistic resource.
At the morphological level, atoken is produced by selecting a token modeland applying any necessary morphologicalmodifications to it  (preselect-substance,preselect-substance-as-stem, preselect-substance-as-property, morphose).Therefore, as with any other categorial textsynthesiser, KPML traverses a network ofoptions among progressively finer types ofstructures and makes choices between differentstructure types depending on semantical andlexical restrictions.
Its speciality comes not fromthe general approach, but from the amount andquality of detailed linguistic knowledge appliedto the synthesis of text in Nigel, which makesNigel a good option for our applications thatdemand natural utterances.
This is also the mainreason why so many attempts have been made touse Nigel for text analysis.2.2 Resources for OpenCCGOpenCCG, as for any other engine usingchart  parsing, relies on the assumption that ahypothesised structure is only to be considered ifit  is part  of a structure for the whole input text.This assumption of syntagmatic holism was firstformulated by Frege (1884) and Wittgenstein(1921; 1922).
Chart parsing with CCGs goesbeyond: both syntagmatic and paradigmaticholisms are to be enforced, i.e.
semantic fittingis used as a filter for analytical hypotheses aswell.
Such a paradigmatic holism was firstformulated by Davidson (1967).OpenCCG is an engine for analysing textswith CCGs (Steedman and Baldridge, 2011;Boz?ahin et al., 2005).
It classifies word formsinto categories according to their affordances ofcombining with other word forms and structuresin the process of building up larger structuresand construing meaning.
In this process, theempty slots of semantic frames, associated witha word, are filled up by the semantic values ofthe structures that  the word form combines with.84Only complete symbolic and semantic structuresthat represent  the whole text are kept by the textanalyser (although incomplete structures mayalso be retrieved for online text processing).There are two kinds of combinatorycategories: the complete (atomic) does notcombine with any other structure; theincomplete (complex) has either a frame withempty slots or is missing word parts, so itcombines with other structures for semantic orsymbolic completion.Incomplete categories of symbolic structuresare turned into a complete category by theOpenCCG engine whenever a structure that iscombinable with a preceding or followingstructure of a certain kind is preceded orfollowed by a structure of this kind.
Slashes \, |and / indicate that a structure of a combinatorycategory is combinable with a structure thatrespectively precedes it, is adjacent  to it, orfollows it.
For instance, the structure of sawholding a two-slot  frame in the clause Mary sawJohn can be said to belong to the categoryClause\Mention/Mention, because it  expects acomplete mention (Mention) of the sensed thingafter it and a complete mention (Mention) of thesenser before it.
The resulting structure aftercombination is a complete clause (Clause).In addition, slashes come in four differentgeneralities: they may allow no composition (?
),only harmonic compositions (?
), only crossingcompositions (?)
or any composition (?
).The smallest  structures in OpenCCG areword forms.
Word forms (morph entries) map atoken pattern (word) to a word id (stem), acombinatory category tag (pos), the meaning ofthe word (class), and a list of form classes (fs-macros) and slot fillers (lf-macros).
Thisterminal mapping is equivalent  to the map fromgrammatical functions to lexical and semanticalstructures in KPML.2.3 KPML-Analysis and CCG-SynthesisKay (1979; 1985) developed the FunctionalUnification Grammar (FUG) and Kasper (1988)used FUG for exploring text  analysis with Nigel.Analysing a clause took about 1 minute (cur-rently approx.
500ms assuming 120-times fasterprocessors) and analysing a complex clause tookseveral minutes.
Kasper concluded grammarsneeded to be ?tuned?
and augmented for theinverse task, but also that some informationwould be superfluous and counterproductive foreither text  synthesis or text  analysis.
FollowingKasper, O?Donnell (1994) reduced thedescriptive complexity of Nigel to create a textanalyser.
After this, Henschel (1995; 1997)attempted to analyse text with the full Nigelgrammatical description again by abstracting anopen-world typology from a systemic networkand compiling the Nigel resource completely forthe first time into a typed-feature-structureresource.
However, the resource was unusablefor practical text  analysis.
When reviewing theseprevious attempts, Bateman (2008) pointed outthat the conception of systemic-functionalresources alone, as it is, cannot support effectiveautomatic text analysis due to fundamentaltheoretical concerns.
That  is, the paradigmaticorganisation of the systemic-functional approachraises an enormous search space problem whenused for text  analysis because the network doesnot have information about  which grammaticalfeature is relevant  for any given text token.
Ifone uses such a network for analysing text, oneneeds to produce a complete set  of all possibleintersections of grammatical features in order topredict all supported analyses, which is thesolution provided by Kasper and by Henschel.Bateman shows that this is computationallyintractable for the full version of Nigel?s noungroup and Nigel?s clause.On the CCG side, broad-coverage surfacerealisation has also been attempted (White et  al.,2007; Rudnick, 2010).
In order for a CCG towork for text  synthesis, it  was enriched with acustomised semantics.
The resulting searchspace was still too large and, for this reason, asearch heuristic was applied using n-grams, pos-tags, supertags, and semantic values forevaluation of paths.
The realisation achievedpromising scores with a time-limit  of 15 secondswhen trained over the CCGBank ?
a derivationcorpus with the same sentences as the PennTreeBank ?
and tested over the same sentences.However, the decision of synthesising a textwith a search heuristic is a consequence of thefact that  the used resource does not hold all theinformation necessary for a guided searchalgorithm for text synthesis.
The reason for thisis also of a theoretical nature.
Once structuralinformation is embedded in word forms,combinatory categories and type changes, it isimpossible to take this information back out ofthem and repack it in a network of optionswithout  counting on two essential constructs forsynthesis: on the one side, semantic compositionand semantic paradigms and, on the other side, aparadigmatic organisation of classes of structureprovided by disjunct  unions of structure classes(systems).
CCGs do not  and could not, forefficiency reasons, rely on logical disjunctions,which are essential for text synthesis.To make the consequences of this limitationmore clear, let  us take an example of how85combinatory operators are declared in resourcesfor OpenCCG  (abbreviations: C = Clause, M =Mention, f = Figure, e = Element):?
danced (I danced)?
stopped dancing (I stopped dancing)?
started dancing (I started dancing)(C[mode-2]:f\M:e0) => (C[mode-?]:f\M:e0)@f<hasTense>e1:Past?
am here (I am here)(C[mode-1]:f\M:e0) => (C[mode-?]:f\M:e0)@f:State(<hasTense>e1:Present)?
am (I am dancing)am := (C[mode-?]:f\M:e0)/(C[mode-6]:f\M:e0)@f:Change(<hasTense>e1:Present)?
will (I will dance)will := (C[mode-?]:f\M:e0)/(C[mode-4]:f\M:e0)@f<hasTense>e1:Future?
stopped (I stopped dancing)stopped := (C[mode-2]:f\M:e0)/(C[mode-6]:f\M:e0)@f<hasPhase>e1:Stop?
started (I started dancing)started := (C[mode-2]:f\M:e0)/(C[mode-6]:f\M:e0)@f<hasPhase>e1:StartSimplified extract of our CCG-resourceThe above combinatory categories and type-changes cover different semantic contributions,which are not  automatically organisable intosystems of symbolic and semantic classes.
First,the resource for OpenCCG does not  have theinformation that  Past, Present, and Futureconstitute a semantic disjunction of TENSE andthat Start  and Stop belong to a distinct  semanticdisjunction of PHASE.
Moreover, the resourcedoes not  have the information that  finite clauseshave tense and that  non-finite clauses do not, sothat it  could decide which system to traverse foreach kind of clause.
And, finally, we cannotguarantee that  an inspection of the figure typehappens before the selection of 1) the presentauxiliary am  in I am  dancing  representing achange in the present and 2) the present  form amof the process of Being in I am  here (instead Iam  being here) representing a present state.
Thisincapability of grouping contrasting options andof conditioning and ordering systems within anetwork demands a search algorithm withbacktracking.
Because of the computationalcosts of backtracking, it also demands a searchheuristic as engineering solution.3 Symbolic MapWe acknowledge the unsuitability of task-oriented resources for the inverse tasks ofsynthesis and analysis and shall tackle the issuesof bridging a paradigmatic text  synthesis and asyntagmatic text analysis at a theoretical level.We propose to describe a symbolic-semanticmap that  can be compiled into task-orientedresources for separate engines (concretely here:KPML and OpenCCG): a scheme that falls intothe Reusability Scheme A (reversibility type) ofKlarner (2005) (see Figure 1).
In our case, thisreusability scheme applies to both grammar andlexicon.Figure 1.
Reusability SchemeIn our argumentation, we shall propose areformulation of Nigel as a description in OWLof a symbolic map that  supports the proposedcompilation.
Moving from specific to general,we shall point  out which mapping strategies canbe used and show that every descriptive regionof Nigel is representable in such a map.3.1 SketchBateman (2008) has sketched how anautomatic text analysis with systemic-functionaltheory ('systemic parse') needs to look.
It  needsa functional description for sequences of texttokens, including the necessary information bothfor assigning grammatical features to structuresand for identifying composites on a sequence ofconstituents.
Such a symbolic map, we shall see,needs to account  for the systemic-functionaltrinocular view of symbolic systems: fromabove, from below and from around.
Moreover,it  also needs to account for two differentaffordances required for a classification ofstructures: one that  organises disjoint  classes asa system of grammatical features for textsynthesis and another that  organises the samedisjunctions as restrictions for the combinationof incomplete structures in text  analysis.
Theformer organisation moves all information ofstructure into the grammatical network, whereasthe latter organisation moves it into word forms.In the reusability scheme of our newresource, we keep the structural information outof the systemic network and out of the wordforms.
It is stored in a symbolic map that  allowsus to pack it  into the two task-orientedresources, i.e.
into the systemic network for textsynthesis and into word forms/type changes fortext analysis.
We have chosen to represent this86information in Description Logic (OWL-DL)since both the typology embedded in a systemicnetwork for KPML and the typology of featuresin the types file for OpenCCG can be derivedfrom such descriptions.3.2 Trinocular ViewWhen classifying symbolic units, we notonly conceive of them as patterns forrecognition and for expression (from below), butalso as bricks for building up a whole with givenparts and for selecting parts for a planned whole(from around), and also as devices forconstruing meaning and for realising it  (fromabove).
Therefore, all classes of symbols in oursymbolic map will be defined based on theiraffordances as patterns, bricks, and devices.
Soour approach is different  from that of Henschel(1995; 1997) not only in the fact  that  we will notextract  a typology in description logic from asystemic network (in fact, we will do theopposite), but also in the fact that each structurewill be specified in our description as threeparticulars: one classified from above, one fromaround, and one from below.
The classificationfrom above is convertible into KPML-inquiries,the classification from around is convertible topreselectable grammatical features in KPML,and the classification from below is related togroups of realisation statements in KPML.
Thedefinitions of brick classes and of pattern classesare responsible for their functions as meaning-making devices (see Figure 2).
In the following,w e d i s c u s s h o w t h e s e c o n c e p t s a r eoperationalised for CCG.Figure 2.
Description of Clause in Prot?g?3.3 Word vs Form vs CopyMoving bottom up in the creation of adescriptive theory, we define a token as asegment  of text that matches a continuouspattern (of phonemes or graphemes) suitable forboth recognition or expression.Looking from above, a choice of tokens in atoken sequence such as helped?out in he helpedme out represents one single semantic value andis here understood as corresponding to a singleword, namely HelpOut.Looking from around, a word form ?
that  ofwhich a text token is a copy ?
is defined ascomposing a particular word and belonging to aparticular form class.
For the word HelpOut,there are two tokens and therefore two forms,one of them being that of helped  and the otherone being that of out in he helped me out.3.4 Pattern vs Brick vs DeviceAt the leaves of the semantic dependencystructure are the semantic values of words and atthe corresponding leaves of the symbolicstructure are not  words, but  the forms of words.In this sense, a particular word form is related tothree notions: 1) a particular pattern that is usedfor recognising and producing tokens (copy), 2)a device for realising and construing meaning(word), and 3) a brick for construing largersymbolic structures (form).
At this point, wehave a triplicity of composition.
While a brick ispart of a larger symbolic structure, its semanticvalue is part  of a larger semantic structure andits physical pattern is recognisable orproduceable in a larger text.
In KPML, asemantic structure is specified externally and thecorrespondence between symbolic and semanticcompositionality is guaranteed by the restrictionof attaching either the same semantic structureor parts of it to the parts of its correspondingsymbolic structure.
In OpenCCG, the samecompositionality is guaranteed by applying the?-function of an incomplete constituent to thevalues of complete constituents (categoryapplication) or by composing the ?-functions oftwo cha ined incomple te cons t i tuen t s(combinatory rules).Moreover, symbolic compositionality islinear in nature.
As reflected in both KPML andOpenCCG, the position of symbolic constituentsmay be fixed in relation to other constituentswhile the semantic constituents cannot.
Forinstance, the position of nice in relation to day inhave a nice day is typically realised with theoperation ?order Epithet:nice Classifier:day?
inKPML while it is embedded in the wordcategories ?nice:Classifier/Classifier?
and?day:Classifier?
in OpenCCG.4 Target: Nigel coverageWe shall propose a map for every structureclass covered by Nigel by tackling thetheoretical issues.4.1 TermsIn Nigel, form classes are used for selectingparticular forms of a word while in a CCG theyare used for limiting the applicability of thecategory of a matched token.
Usually the form87selection and its applicability are related toeither role or agreement restrictions.In the Nigel grammar, some word classes aredefined for automatically creating tokens fromthe stem of a word such as the verb classes ?es-ed?
for verbs such as wish (wishes, wished).
Forindicating the existence of irregular patterns,there are word classes such as ?irr?.
There arealso word classes which are used for controllingthe selection of a token index based on a set ofform classes (or inflectional features) such as?inflectable?, ?noun?, and ?verb?.
All of theseword classes together belong to morphologybecause they are meant to guide the selection oftoken models and their modifications into thepatterns to print out or recognise.
With suchclasses, Nigel is able to reduce the description ofa word to a short code such as the following:<Word id=?Arrive?><Class name=?Process?
/><Class name=?EndingWith-e-es-ed-ing?
/><SampleMap><Sample name=?stem?
value=?arrive?
/></SampleMap></Word>Sample 1.
Word ArriveWe store the classes of copies, forms, andwords in a lexical ontology together with theirrelations.
In this way, we are able to generate thesame systemic network for the rank of word inKPML and, at the same time, all word forms andword form classes for OpenCCG.In addition, there are word classes used ascriteria for selecting words in Nigel.
These arethe grammatical ?
or closed-class ?
words.
Forthem, there is a number of different selectingcriteria which are better explained at the rankswhere these selections are made (clause, phrase,or group).In CCG, the morphological entries are notwords, but forms.
As in KPML, forms have aword identifier (stem), inflectional/agreementclasses (macros), they have an attribute for formapplicability (pos) and may have an additionalsemantic value in case of lexical words (class).Therefore, the word exemplified in Sample 1,can be compiled via ontological reasoning intothe following structure:<entry word=?arrive?
stem=?Arrive?
class=?Arrive?macros=?
@mode-1 @mention-1 @base @Arrive?
/><entry word=?arrives?
stem=?Arrive?
class=?Arrive?macros=?
@mode-1 @mention-2 @base @Arrive?
/><entry word=?arrive?
stem=?Arrive?
class=?Arrive?macros=?
@mode-1 @mention-3 @base @Arrive?
/><entry word=?arrived?
stem=?Arrive?
class=?Arrive?macros=?
@mode-2 @mention-1 @base @Arrive?
/>[?
]Sample 2.
Forms of Word Arrive in CCGA sample word ontology and the java codefor generating resources can be found at https://github.com/DanielCoutoVale/SymbolicMap.4.2 CompositesIn the beginning of every traversal of thesystemic network, a symbolic structure isclassified either as a clause, a group or phrase, aword or a morpheme.
By listing all preselectableclasses, we came to the conclusion that  there is afine-grained rank region that includes not onlyclauses, phrases, groups, and words, butsubtypes of these.
Clauses are either complexesor simplexes, either dependent or independent.Phrases and groups can be either a nominalgroup, a quantity group, a quality group, anadverbial group or a prepositional phrase.
Thesesubtypes can have further specifications that weshall call here, for simplification, clause modeand noun group case.
At  this point, below thepreselectable classes, it is possible to propose acomposite structure whose further specificationis exclusively semantical and lexical in natureand whose fitting is governed exclusively by thecompositionality of the semantic structure.
Thispossibility was also noticed by Henschel in herfinal remarks (Henschel, 1997).At this point  of the traversal, for eachparticular class of structure, there is a semanticcorrespondent.
Sequences are realised by clausecomplexes, Figures by clause simplexes,Elements by phrases and groups.
Subtypes ofElements are realised by subtypes of phrases andgroups: Circumstances by prepositional phrasesand adverbial groups, Things by noun groups,Qualities by adjectival groups, Quantities byquantity groups.
Finally, Elements have twoother subtypes: Processes and Modalities, whichoccupy respectively the heads of clauses andphrases (see Figure 3).Figure 3.
OntoGraf of Clause in Prot?g?Since we need to allow changing the type ofcomplete structures into combinable constituentsof larger structures during text  analysis, adescription of symbolic systems must  store moreinformation than Nigel at  this point.
How thesetype-changes are achieved shall be explained inthe following.4.3 AdjunctsType changing in OpenCCG provides a wayto implement  the separation between pattern,brick, and device.
For instance, this operatorallows us to create simple rules for very88(Qualification/Qualifier) and nice (Qualifier) toresult in the complete structure of very nice(Qualification).
Then, by adding the possibilityof changing the type Qualification intoClassifier/Classifier, we are able to turn thecategory of this symbolic structure into anadjunct for the classifier wine (Classifier) in thisis a very nice wine.
At  the same time, we stillallow it to be a complement of the process is(Clause\Mention/Qualification) in this wine isvery nice.4.4 Grammatical Word SelectionIn addition to the currently defined semanticelements, the semantic specification of Nigelalso contains properties for answering semanticqueries.
These semantic queries embed atypology of deictics, of tense, and of phaseinside of the systemic network.
In order toembed these typologies into word forms, thesemantic types must be moved to the semanticontology.
For instance, the meaning of the inKPML is that it  is a ?nonselective?, ?nontypic?,?nominal?, and ?specific?
instantiation of a?class?
of ?non-interactants?.
The grammaticalfeature of the is a subtype of all these otherfeatures.
During text analysis, the can beassigned the corresponding grammatical featurewhile the supertypes of this feature can beinferred with an ontology after the analysis.4.5 SpecificationIn Nigel, there are systems whose featuresare realised either by selecting a unit/form classor by creating a head/tail structure.
Tense is anexample of this.
On the one hand, positive futureis realised by adding will (T0-head) andselecting the infinitive form for the head of theremaining verbal group (T0-tail) such as make init will make sense.
On the other hand, positivepresent  is realised by selecting the present formfor the head of the verbal group (T0-atom) suchas makes in it makes sense.
Therefore, for eachregion in each rank that creates a specificationof clauses, phrases, or groups, we need to haveeither a head-tail structure or an atom forKPML.
The respective corresponding structuresfor OpenCCG would be an incomplete categoryor a type-change.4.6 ComplementsCircumstance complements such as of Maryin in front of Mary create no new challenges fordescription.
Figure complements, on the otherhand, do.
The clause, as the representation of afigure (state or event), is a symbolic structurewhose constituents represent the elements of asemantic figure.
Nigel adds the representativefunctions of clause constituents in the traversalof a figure typology.
Each level of the typologydecides whether a semantic role is present or notin the figure and therefore if a constituent musthave the function of such a role.
Roles includethose of actor, actee, senser, sensum, sayer,target, verbiage, carrier, attribute, identified,identifier among others.
Semantic roles and theirpresence for a given figure type are storedoutside the system in a separate typology(GUM-3) (Bateman et al., 2010).
Thecorrespondent of the transitivity region inOpenCCG would be the mapping of logicalvariables to the diamond modes of a figure nodeas specified in the XML below:<satop nomvar=?SimpleAction?><diamond mode=?hasProcess?><nomvar name=?Process?/></diamond><diamond mode=?hasActor?><nomvar name=?Actor?/></diamond></satop>Sample 3.
Logical Form in OpenCCGWhich process words can be used in eachfigure type need not  be defined in KPMLbecause both the figure type (SimpleAction,AffectingAction, etc.)
and the process type(Running, Jumping, Singing, Seeing, etc.)
aredefined in the semantic specification that ispassed to KPML as an input  for text synthesis.This mapping from process types to figure typesis necessary in OpenCCG and, therefore,process words need to be assigned process typesso that  SimpleActionProcesses are associatedwith a derivation family that has a medium/actor, and so that AffectingActionProcesses areassociated with a derivation family that has anagent/actor and a medium/goal, and so on.
Thewhole set of rules involving transitivity can beautomatically derived from a typology of figuresboth for KPML and for OpenCCG that includessuch process classes.In addition, in KPML, voice is implementedby mapping the transitive functions describedabove (actor, actee, recipient, senser, sensum,sayer, target...) to a smaller set of ergativefunctions (agent, medium, beneficiary).
Forexample, the clause the duke gave my aunt theteapot has the duke as actor, my aunt as recipientand the teapot as goal in the transitive structureand the duke as agent, my aunt as beneficiary,and the teapot as medium in the ergativestructure.
For each figure type, there is amapping of specific transitive functions toergative functions.
The ergative functions are theones that get mapped to the subject, the direct(-object) and the indirect(-object) functions89depending on the voice (agent-receptive voice,medium-receptive voice, and beneficiary-receptive voice).
To implement a similar voiceconstruct in OpenCCG, we propose a strategy ofmoving the mapping of transitive-ergativefunctions to a secondary step of reasoning aftertext analysis (example in https://github.com/DanielCoutoVale/SymbolicMap).
After doingthis, the actual voice structure can beimplemented with categories such as Clause\Mention/Mention/Mention/Process for theauxiliary word was in the teapot was given bythe duke to my aunt and with the type changingrule Process ?> Clause\Mention/Mention/Mention applied to the Process gave in the dukegave my aunt a teapot.
Which category or ruleto apply depends on the ergative functions ofeach figure type ?
e.g.
figures with a mediumand no agent  do not  have a ?passive?
form.Culmination ?
the choice between the teapotwas given my aunt by the duke and the teapotwas given by the duke to my aunt ?
was realisedin OpenCCG together with voice.5 EvaluationFor evaluation, we targeted the only realchallenge in the relation between Nigel and ourCCG (clause complements) by creating a simplesymbolic map with two ranks (clause andmention), with three figure types, three voicesand two culminations (complements).
Thisresource was compiled into a systemic networkand into combinatory categories and typechange rules successfully.
Text synthesis andtext analysis work as intended, that  is,algorithmically without  backtracking.
Forinstance, the automatically generated CCG givesthe correct standard analysis for the duke gavemy aunt the teapot according to SFG as seen inthe Table 1:the duke gave my aunt the teapotActor Process Recipient GoalAgent Beneficiary MediumTable 1.
Analysis for the duke as subjectFor utterances such as my aunt was given theteapot by the duke see Tables 2-3, twohypotheses of analysis are given by CCG.
Bothanalyses are correct  if only symbolic andsemantic compositionality is taken into account.An analysis, according to which the teapotreceives someone?s aunt  (Table 3), can only bediscarded when knowledge about  the world (andnot about language) is applied.my aunt was given the teapotby thedukeRecipient Process Goal ActorBeneficiary Medium AgentTable 2.
Analysis 1 for my aunt as subjectmy aunt was given the teapotby thedukeGoal Process Recipient ActorMedium Beneficiary AgentTable 3.
Analysis 2 for my aunt as subjectThe compilation speed for OpenCCG wordforms is very slow: one second per word formon a computer with 2.6 Ghz processor.
Thecompilation of OpenCCG combinatorycategories, type changing rules, KPML lexiconand network, on the other hand, is efficient.Once compiled, the speed of text  analysis is thatof a regular hand-written resource for OpenCCGand is equivalent in size and quality throughcode inspection.6 ConclusionIn this paper, we have shown that task-oriented resources for KPML and OpenCCG donot contain the necessary information for doingthe inverse task and that  their directed rulescannot encode the information that  is necessaryfor the resources to become reversible.Therefore, we have adopted a third strategyof creating a completely descriptive mapbetween symbolic and semantic structures thatcan be compiled into a systemic network andinto combinatory categories and type changingrules.Our evaluation has shown that the approachis sound and is able to solve previouslyidentified issues on a theoretical level.
However,we are still unsure about the amount  ofengineering resources that would be needed inorder to complete the same coverage of Nigelwithin such a paradigm.
Nevertheless, from thepilot study undertaken, the approach appearspromising.AcknowledgementsWe gratefully acknowledge the support  ofthe Deutsche Forschungsgemeinschaft  (DFG)through the Collaborative Research Center SFB/TR8 Spatial Cognition.90ReferencesJohn A. Bateman.
1995a.
Basic technology formultilingual theory and practise: the KPMLdevelopment enviroment.
In Proceedings of theWorkshop on Multilingual Text GenerationIJCAI-95, pages 1?12.
Montreal.John A. Bateman.
1995b.
KPML: the KOMET-Penman Multilingual Linguistic ResourceDevelopment Environment.
In Proceedings ofthe Fifth European Workshop on NaturalLanguage Generation, pages 219?222.
Leiden.John A. Bateman.
1996.
KPML DevelopmentEnvironment.
GMD-ForschungszentrumInformationstechnik GmbH, Sankt Augustin.John A. Bateman.
1997.
Enabling technology formultilingual natural language generation: theKPML development environment.
NaturalLanguage Engineering, 3(1):15?55.John A. Bateman.
2008.
Systemic-functionallinguistics and the notion of linguistic structure:unanswered questions, new possibilities.Meaning in context implementing intelligentapplications of language studies, pages 24?58.Continuum, London/New York.John A. Bateman, Joana Hois, Robert Ross, andThora Tenbrink.
2010.
A linguistic ontology ofspace for natural language processing.
ArtificialIntelligence, 174(14):1027?1071.Cem Boz?ahin, Geert-Jan Kruijff, and MichaelWhite.
2005.
Specifying Grammars forOpenCCG: A Rough Guide.
Retrieved fromhttp://www.metu.edu.tr/~bozsahin/nli/ceng563/link/grammars-rough-guide.pdfDonald Davidson.
1967.
Truth and Meaning.Synthese, 17(1):304?323.Friedrich Ludwig Gottlob Frege.
1884.
Grundlagender Arithmetik: eine logisch mathematischeUntersuchung ?ber den Begriff der Zahl.Wilhelm K?bner, Breslau.Michael A.K.
Halliday and Christian M.I.M.Matthiessen.
2014.
Halliday's Introduction toFunctional Grammar, 4th edition.
Routledge,London/New York.Renate Henschel.
1995.
Traversing the Labyrinth ofFeature Logics for a Declarative Implementationof Large Scale Systemic Grammars.
Retrievedfrom http://www.elsnet.org/publications/clnlp95Renate Henschel.
1997.
Compiling SystemicGrammar into Feature Logic Systems.
Retrievedfrom http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.3153&rep=rep1&type=pdfRobert T. Kasper.
1988.
An experimental parser forsystemic grammars.
In Proceedings of theTwelfth International Conference onComputational Linguistics, pages 309?312,Budapest.Martin Kay.
1979.
Functional Grammar.
InProceedings of the Berkeley Linguistics Society.pages 142?158, Berkeley.JP Martin Kay.
1985.
Parsing in functionalunification grammar.
Natural Language Parsing.Cambridge University Press, Cambridge, UK.Martin Klarner.
2005.
Reversibility and re-usabilityof resources in NLG and natural language dialogsystems.
In Proceedings of the Tenth EuropeanWorkshop on Natural Language Generation,pages 185-190.
Aberdeen.George Lakoff.
1987.
Women, fire and dangerousthings: what categories reveal about the mind.University of Chicago Press, Chicago.Christian M.I.M.
Matthiessen.
1995.Lexicogrammatical cartography: englishsystems.
International Language SciencesPublishers, Tokyo.Christian M.I.M.
Matthiessen and Michael A.K.Halliday.
1999.
Construing experience throughmeaning: a language-based approach tocognition.
Continuum, London/New York.Christian M.I.M.
Matthiessen and Michael A.K.Halliday.
2004.
An introduction to functionalgrammar, 3rd edition.
Oxford University Press,New York.G?nter Neumann.
1991.
A bidirectional model fornatural language processing.
In Proceedings ofthe Fifth Conference on European chapter of theAssociation for Computational Linguistics, pages245?250, Berlin.G?nter Neumann and Gertjan van Noord.
1992.
Self-monitoring with reversible grammars.
InProceedings of the Fourteenth InternationalConference on Computational Linguistics, pages700?706, Nantes.Michael O'Donnell.
1994.
Sentence analysis andgeneration: a systemic perspective.
Ph.D. thesis,University of Sydney, Sydney.Stephen G. Pulman.
1995. Review of ReversibleGrammar in Natural Language Processing.
InComputational Linguistics, 21:269?271.Alex Rudnick.
2010. Review: realization with CCG.Retrieved from http://www.cs.indiana.edu/~alexr/nonpubs/alexr-ccg-generation.pdf91Barry Smith and Berit Brogaard.
2003.
A UnifiedTheory of Truth and Reference.
Logique etAnalyse, 43:1?46.Mark Steedman.
1987.
Combinatory grammars andparasitic gaps.
Natural Language and LinguisticTheory, 5(3):403?439.Mark Steedman.
1996.
A very short introduction toCCG.
Retrieved from http://www.inf.ed.ac.uk/teaching/courses/nlg/readings/ccgintro.pdfMark Steedman.
1998.
Categorial Grammar.
TheMIT Encyclopedia of Cognitive Sciences, pages1?9.
MIT Press, Cambridge, MA.Mark Steedman and Jason Baldridge.
2011.Combinatory Categorial Grammar.
Non-Transformational Syntax, pages 181?224.Blackwell, Oxford, UK.Tomek Strzalkowski.
1994.
Reversible Grammar.Reversible Grammar in Natural LanguageProcessing, pages xiii?xxi.
Springer Science+Business Media, Dordrecht.Michael White, Rajakrishnan Rajkumar, and ScottMartin.
2007.
Towards broad coverage surfacerealization with CCG.
In Proceedings of theWorkshop on Using Corpora for NLG LanguageGeneration and Machine Translation, pages22-30, Brighton.Lugwig Josef Johann Wittgenstein.
1921.
Logisch-Philosophische Abhandlung.
Annalen derNaturphilosophie, 14:185-262.Lugwig Josef Johann Wittgenstein.
1922.
TractatusLogico-Philosophicus.
Kegan Paul, TrenchTrubner & Co, London.92
