Why Are They Excited?Identifying and Explaining Spikes in Blog Mood LevelsKrisztian Balog Gilad Mishne Maarten de RijkeISLA, University of AmsterdamKruislaan 403, 1098 SJ Amsterdamkbalog,gilad,mdr@science.uva.nlAbstractWe describe a method for discovering ir-regularities in temporal mood patterns ap-pearing in a large corpus of blog posts,and labeling them with a natural languageexplanation.
Simple techniques basedon comparing corpus frequencies, coupledwith large quantities of data, are shown tobe effective for identifying the events un-derlying changes in global moods.1 IntroductionBlogs, diary-like web pages containing highlyopinionated personal commentary, are becomingincreasingly popular.
This new type of media of-fers a unique look into people?s reactions and feel-ings towards current events, for a number of rea-sons.
First, blogs are frequently updated, and likeother forms of diaries are typically closely linkedto ongoing events in the blogger?s life.
Second, theblog contents tend to be unmoderated and subjec-tive, more so than mainstream media?expressingopinions, thoughts, and feeling.
Finally, the largeamount of blogs enables aggregation of thousandsof opinions expressed every minute; this aggrega-tion allows abstractions of the data, cleaning outnoise and focusing on the main issues.Many blog authoring environments allow blog-gers to tag their entries with highly individual (andpersonal) features.
Users of LiveJournal, one ofthe largest weblog communities, have the optionof reporting their mood at the time of the post;users can either select a mood from a predefinedlist of common moods such as ?amused?
or ?an-gry,?
or enter free-text.
A large percentage of Live-Journal users tag their postings with a mood.
Thisresults in a stream of hundreds of weblog poststagged with mood information per minute, fromhundreds of thousands of users across the globe.The collection of such mood reports from manybloggers gives an aggregate mood of the blogo-sphere for each point in time: the popularity ofdifferent moods among bloggers at that time.In previous work, we introduced a tool fortracking the aggregate mood of the blogosphere,and showed how it reflects global events (Mishneand de Rijke, 2006a).
The tool?s output includesgraphs showing the popularity of moods in blogposts during a given interval; e.g., Figure 1 plotsthe mood level for ?scared?
during a 10 day pe-riod.
While such graphs reflect some expectedpatterns (e.g., an increase in ?scared?
around Hal-loween in Figure 1), we have also witnessed spikesand drops for which no associated event wasFigure 1: Blog posts labeled ?scared?
during the October 26?November 5, 2005 interval.
The dotted (black) curve indi-cates the absolute number of posts labeled ?scared,?
whilethe solid (red) curve shows the rate of change.known to us.
In this paper, we address this is-sue: we seek algorithms for identifying unusualchanges in mood levels and explaining the under-lying reasons for these changes.
By ?explanation?we mean a short snippet of text that describes theevent that caused the unusual mood change.To produce such explanations, we proceed asfollows.
If unusual spikes occur in the level ofmood m, we examine the language used in blogposts labeled with m around and during the pe-riod in which the spike occurs.
We interpret words207that are not expected given a long-term languagemodel for m as signals for the spike in m?s level.To operationalize the idea of ?unexpected words?for a given mood, we use standard methods forcorpus comparison; once identified, we use the?unexpected words?
to consult a news corpus fromwhich we retrieve a small text snippet that we thenreturn as the desired explanation.In Section 2 we briefly discuss related work.Then, we detail how we detect spikes in mood lev-els (in Section 3) and how we generate natural lan-guage explanations for such spikes (in Section 4).Experimental results are presented in Section 5,and in Section 6 we present our conclusions.2 Related workAs to burstiness phenomena in web data, Klein-berg (2002) targets email and research papers, try-ing to identify sharp rises in word frequencies indocument streams.
Bursts can be found by search-ing periods when a given word tends to appear atunusually short intervals.
Kumar et al (2003) ex-tend Kleinberg?s algorithm to discover dense pe-riods of ?bursty?
intra-community link creation inthe blogspace, while Nanno et al (2004) extend itto work on blogs.
We use a simple comparison be-tween long-term and short-term language modelsassociated with a given mood to identify unusualword usage patterns.Recent years have witnessed an increase in re-search on extracting subjective and other non-factual aspects of textual content; see (Shanahan etal., 2005) for an overview.
Much work in this areafocuses on recognizing and/or annotating evalu-ative textual expressions.
In contrast, work thatexplores mood annotations is relatively scarce.Mishne (2005) reports on text mining experimentsaimed at automatically tagging blog posts withmoods.
Mishne and de Rijke (2006a) lift this workto the aggregate level, and use natural languageprocessing and machine learning to estimate ag-gregate mood levels from the text of blog entries.3 Detecting spikesOur first task is to identify spikes in moods re-ported in blog posts.
Many of the moods reportedby LiveJournal users display a cyclic behavior.There are some obvious moods with a daily cycle.For instance, people feel awake in the morningsand tired in the evening (Figure 2).
Other moodsshow a weekly cycle.
For instance, people drinkmore at the weekends (Figure 3).Figure 2: Daily cycles for ?awake?
and ?tired.
?Figure 3: Weekend cycles for ?drunk.
?Our idea of detecting spikes tries to deal withthese cyclic events and aims at finding globalchanges.
Let POSTS (mood, date, hour) be thenumber of posts labelled with a given mood andcreated within a one-hour interval at the speci-fied date.
Similarly, ALLPOSTS (date, hour) isthe number of all posts created within the intervalspecified by the date and hour.
The ratio of postslabeled with a given mood to all posts could beexpressed for all days of a week (Sunday, .
.
.
, Sat-urday) and for all one-hour intervals (0, .
.
.
, 23)using the formula:R(mood, day, hour) =?DW (date)=day POSTS (mood, date, hour)?DW (date)=day ALLPOSTS (date, hour),where day = 0, .
.
.
, 6 and DW (date) is a day-of-the-week function that returns 0, .
.
.
, 6 dependingon the date argument.The level of a given mood is changed withina one-hour interval of a day, if the ratio of postslabelled with that mood to all posts, created withinthe interval, is significantly different from the ratiothat has been observed on the same hour of thesimilar day of the week.
Formally:D(mood, date, hour) =POSTS(mood,date,hour)ALLPOSTS(date,hour)R(mood,DW (date), hour) .If |D| (the absolute value of D) exceeds a thresh-old we conclude that a spike has occurred, while208the sign of D makes it possible to distinguish be-tween positive and negative spikes.
The absolutevalue of D expresses the degree of the peak.This method of identifying spikes allows us tolook at a period of a few hours instead of onlyone, which is an effective smoothing method, es-pecially if a sufficient number of posts cannot beobserved for a given mood.4 Explaining peaksOur next task is to explain the peaks identified bythe methods listed previously.
We proceed in twosteps.
First, we discover features in the peakinginterval which display a significantly different lan-guage usage from that found in the general lan-guage associated with the mood.
Then we formqueries using these ?overused?
words as well asthe date(s) of the peaking interval and run these asqueries against a news corpus.4.1 Overused words To discover the reasonsunderlying mood changes we use corpus-basedtechniques to identify changes in language usage.We compare two corpora: (1) the full set of blogposts, referred to as the standard corpus, and (2) acorpus associated with the peaking interval, re-ferred to as the sample corpus.To compare word frequencies across the twocorpora we apply the log-likelihood statisticaltest (Dunning, 1993).
Let Oi be the observedfrequency of a term, Ni its total frequency, andEi = (Ni ?
?i Oi)/?i Ni its expected frequencyin corpus i (where i takes values 1 and 2 for thestandard and sample corpus, respectively).
Then,the log-likelihood value is calculated according tothis formula: ?2 ln?
= 2?i Oi ln(OiEi).4.2 Finding explanations Given the start andend dates of a peaking interval and a list ofoverused words from this period, a query isformed.
This query is then submitted to (head-lines of) a news corpus.
A headline is retrieved ifit contains at least one of the overused words andis dated within the peaking interval or the day be-fore the beginning of the peak.
The hits are rankedbased on the number of overused terms containedin the headline.5 ExperimentsIn this section we illustrate our methods with someexamples and provide a preliminary analysis oftheir effectiveness.5.1 The blog corpus Our corpus consists ofall public blogs published in LiveJournal duringa 90 day period from July 5 to October 2, 2005,adding up to a total of 19 million blog posts.
Foreach entry, the text of the post along with the dateand time are indexed.
Posts without an explicitmood indication (10M) are discarded.
We appliedstandard preprocessing steps (stopword removal,stemming) to the text of blog posts.5.2 The news corpus The collection con-tains around 1000 news headlines that havebeen published in Wikinews (http://www.wikinews.org) during the period of July-September, 2005.5.3 Case studies We present three particularcases where an irregular behavior in a certainmood could be observed.
We examine how accu-rately the overused terms describe the events thatcaused the spikes.5.3.1 Harry Potter In July, 2005, a peak in?excited?
was discovered; see Figure 4, where theshaded (green) area indicates the ?peak area.
?Figure 4: Peak in ?excited?
around July 16, 2005.Step 1 of our peak explanation method (Sec-tion 4) reveals the following overused terms dur-ing the peak period: ?potter,?
?book,?
?excit,??hbp,?
?read,?
?princ,?
?midnight.?
Step 2 ofour peak explanation method (Section 4) exploitsthese words to retrieve the following headlinefrom the news collection: ?July 16.
Harry Potterand the Half-Blood Prince released.
?5.3.2 Hurricane Katrina Our next exam-ple illustrates the need for careful thresholdingwhen defining peaks (see Section 3).
We showpeaks in ?worried?
discovered around late Au-gust, with a 40% and 80% threshold.
Clearly, farmore peaks are identified with the lower threshold,while the peaks identified in the bottom plot (withthe higher threshold), all appear to be clear peaks.The overused terms during the peak period include?orlean,?
?worri,?
?hurrican,?
?gas,?
?katrina?
In209Figure 5: Peaks in ?worried?
around August 29, 2005.
(Top:threshold 40% change; bottom: threshold 80% change)Step 2 of our explanation method we retrieve thefollowing news headlines (top 5 shown only):(Sept 1) Hurricane Katrina: Resources regardingmissing/located people(Sept 2) Crime in New Orleans sharply increasesafter Hurricane Katrina(Sept 1) Fats Dominomissing in the wake of Hur-ricane Katrina(Aug 30) At least 55 killed by Hurricane Katrina;serious flooding across affected region(Aug 26) Hurricane Katrina strikes Florida, killsseven5.3.3 London terror attacks On July 7 asharp spike could be observed in the ?sad?
mood;see Figure 6; the tone of the shaded area shows thedegree of the peak.
Overused terms identified forthis period include ?london,?
?attack,?
?terrorist,??bomb,?
?peopl?, ?explos.?
Consulting our newsFigure 6: Peak in ?sad?
around July 7, 2005.corpus produced the following top ranked results:(July 7) Coordinated terrorist attack hits London(July 7) British PrimeMinister Tony Blair speaksabout London bombings(July 7) Bomb scare closes main Edinburgh thor-oughfare(July 7) France raises security level to red in re-sponse to London bombings(July 6) Tanzania accused of supporting terror-ism to destabilise Burundi5.4 Failure analysis Evaluation of the meth-ods described here is non-trivial.
We found thatour peak detection method is effective despite itssimplicity.
Anecdotal evidence suggests that ourapproach to finding explanations underlying un-usual spikes and drops in mood levels is effective.We expect that it will break down, however, in casethe underlying cause is not news related but, for in-stance, related to celebrations or public holidays;news sources are unlikely to cover these.6 ConclusionsWe described a method for discovering irregulari-ties in temporal mood patterns appearing in a largecorpus of blog posts, and labeling them with anatural language explanation.
Our method showsthat simple techniques based on comparing corpusfrequencies, coupled with large quantities of data,are effective for identifying the events underlyingchanges in global moods.Acknowledgments This research was supportedby the Netherlands Organization for ScientificResearch (NWO) under project numbers 016.-054.616, 017.001.190, 220-80-001, 264-70-050,365-20-005, 612.000.106, 612.000.207, 612.013.-001, 612.066.302, 612.069.006, 640.001.501, and640.002.501.ReferencesT.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Comput.
Ling., 19(1):61?74.J.
Kleinberg.
2002.
Bursty and hierarchical structure instreams.
In Proc.
8th ACM SIGKDD Intern.
Conf.
onKnowledge Discovery and Data Mining, pages 1?25.R.
Kumar, J. Novak, P. Raghavan, and A. Tomkins.
2003.
Onthe bursty evolution of blogspace.
In Proc.
12th Intern.World Wide Web Conf., pages 568?576.G.
Mishne and M. de Rijke.
2006a.
Capturing global moodlevels using blog posts.
In AAAI 2006 Spring Symp.
onComputational Approaches to Analysing Weblogs (AAAI-CAAW 2006).
To appear.G.
Mishne and M. de Rijke.
2006b.
MoodViews: Toolsfor blog mood analysis.
In AAAI 2006 Spring Symp.
onComputational Approaches to Analysing Weblogs (AAAI-CAAW 2006).G.
Mishne.
2005.
Experiments with mood classification inblog posts.
In Style2005 ?
1st Workshop on Stylistic Anal-ysis of Text for Information Access, at SIGIR 2005.T.
Nanno, T. Fujiki, Y. Suzuki, and M. Okumura.
2004.
Au-tomatically collecting, monitoring, and mining Japaneseweblogs.
In Proc.
13th International World Wide WebConf., pages 320?321.J.G.
Shanahan, Y. Qu, and J. Wiebe, editors.
2005.
Comput-ing Attitude and Affect in Text: Theory and Applications.Springer.210
