Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 53?56,New York, June 2006. c?2006 Association for Computational LinguisticsAgreement/Disagreement Classication:Exploiting Unlabeled Data using Contrast ClassiersSangyun Hahn Richard LadnerDept.
of Computer Science and EngineeringUniversity of Washington, Seattle, WA{syhahn,ladner}@cs.washington.eduMari OstendorfDept.
of Electrical EngineeringUniversity of Washington, Seattle, WAmo@ee.washington.eduAbstractSeveral semi-supervised learning methodshave been proposed to leverage unlabeleddata, but imbalanced class distributions inthe data set can hurt the performance ofmost algorithms.
In this paper, we adaptthe new approach of contrast classifiers forsemi-supervised learning.
This enables usto exploit large amounts of unlabeled datawith a skewed distribution.
In experimentson a speech act (agreement/disagreement)classification problem, we achieve betterresults than other semi-supervised meth-ods.
We also obtain performance com-parable to the best results reported so faron this task and outperform systems withequivalent feature sets.1 IntroductionIn natural language understanding research withdata-driven techniques, data labeling is an essentialbut time-consuming and costly process.
To allevi-ate this effort, various semi-supervised learning al-gorithms such as self-training (Yarowsky, 1995), co-training (Blum and Mitchell, 1998; Goldman andZhou, 2000), transductive SVM (Joachims, 1999)and many others have been proposed and success-fully applied under different assumptions and set-tings.
They all aim to improve classification accu-racy by exploiting more readily available unlabeleddata as well as labeled examples.
However, theseiterative training methods have shortcomings whentrained on data with imbalanced class distributions.One reason is that most classifiers underlying thesemethods assume a balanced training set, and thuswhen one of the classes has a much larger number ofexamples than the other classes, the trained classifierwill be biased toward the majority class.
The imbal-ance will propagate through subsequent iterations,resulting in a more skewed data set upon which afurther biased classifier will be trained.
To exploitunlabeled data in learning an inherently skewed datadistribution, we introduce a semi-supervised classi-fication method using contrast classifiers, first pro-posed by Peng et al (Peng et al, 2003).
It approx-imates the posterior class probability given an ob-servation using class-specific contrast classifiers thatimplicitly model the difference between the distrib-ution of labeled data for that class and the unlabeleddata.In this paper, we will explore the applicabil-ity of contrast classifiers to the problem of semi-supervised learning for identifying agreements anddisagreements in multi-party conversational speech.These labels represent a simple type of ?speech act?that can be important for understanding the interac-tion between speakers, or for automatically summa-rizing or browsing the contents of a meeting.
Thisproblem was previously studied (Hillard et al, 2003;Galley et al, 2004), using a subset of ICSI meet-ing recording corpus (Janin et al, 2003).
In semi-supervised learning, there is a challenge due to animbalanced class distribution: over 60% of the dataare associated with the default class and only 5% arewith disagreements.532 Contrast ClassifierThe contrast classifier approach was developed byPeng et aland successfully applied to the problemof identifying protein disorder in a protein struc-ture database (outlier detection) and to finding arti-cles about them (single-class detection) (Peng et al,2003).
A contrast classifier discriminates betweenthe labeled and unlabeled data, and can be usedto approximate the posterior class probability of agiven data instance as follows.
Taking a Bayesianapproach, a contrast classifier for the j-th class isdefined as:ccj(x) =rjg(x)(1 ?
rj)hj(x) + rjg(x)(1)where hj(x) is the likelihood of x generated byclass j in the labeled data, g(x) is the distributionof unlabeled data, and rj is the relative proportionof unlabeled data compared to the labeled data forclass j.
This discriminates the class j in the la-beled data from the unlabeled data.
Here, we con-strain rj = 0.5 for all j, using resampling to addressclass distribution skew, as described below.
Rewrit-ing equation 1, hj(x) can be expressed in terms ofccj(x) as:hj(x) =1 ?
ccj(x)ccj(x)?
r1 ?
r ?
g(x).
(2)Then, the posterior probability of an input x for classj, p(j|x), can be approximated as:p(j|x) = hj(x)qj?i hi(x)qi(3)where qj is the prior class probability which canbe approximated by the fraction of instances in theclass j among the labeled data.
By substituting eq.
2into eq.
3, we obtain:p(j|x) = qj ?
(1 ?
ccj(x))/ccj(x)?i qi ?
(1 ?
cci(x))/cci(x).
(4)Notice that we do not have to explicitly estimateg(x).
Eq.
4 can be used to construct the MAP clas-sifier:c?
= arg maxj1 ?
ccj(x)ccj(x)?
qj (5)To approximate the class-specific contrast classifier,ccj(x), we can choose any classifier that outputs aprobability, such as a neural net, logistic regression,or an SVM with outputs calibrated to produce a rea-sonable probability.Typically a lot more unlabeled data are avail-able than labeled data, which causes class imbalancewhen training a contrast classifier.
In a supervisedsetting, a resampling technique is often used to re-duce the effect of imbalanced data.
Here, we use acommittee of classifiers, each of which is trained ona balanced training set sampled from each class.
Tocompute the final output of the classifier, we imple-mented four different strategies.?
For each class, average the outputs of the con-trast classifiers in the committee, and use theaverage as ccj(x) in eq.
5.?
Average only the outputs of contrast classifierssmaller than their corresponding threshold, andthe fraction of the included classifiers is usedas the strength of the probability output for theclass.?
Use a meta classifier whose inputs are the out-puts of the contrast classifiers in the commit-tee for a class, and whose output is modeled bytraining it from a separate, randomly sampleddata set.
The output of the meta classifier isused as ccj(x).?
Classify an input as the majority class onlywhen the outputs of the meta classifiers forthe other classes are all larger than their cor-responding thresholds.Another benefit of the contrast classifier approachis that it is less affected by imbalanced data.
Whentraining the contrast classifier for each class, it usesthe instances in only one class in the labeled data,and implicitly models the data distribution withinthat class independently of other classes.
That is,given a data instance, the distribution within a class,hj(x), determines the output of the contrast classi-fier for the class (eq.
1), which in turn determinesthe posterior probability (eq.
4).
Thus it will not beas highly biased toward the majority class as a clas-sifier trained with a collection of data from imbal-anced classes.
Our experimental results presented inthe next section confirm this benefit.543 ExperimentsWe conducted experiments to answer the followingquestions.
First, is the contrast classifier approachapplicable to language processing problems, whichoften involve large amounts of unlabeled data?
Sec-ond, does it outperform other semi-supervised learn-ing methods on a skewed data set?3.1 Features and data setsThe data set used consists of seven transcripts out of75 meeting transcripts included in the ICSI meet-ing corpus (Janin et al, 2003).
For the study, 7meetings were segmented into spurts, defined as achunk of speech of a speaker containing no longerthan 0.5 second pause.
The first 450 spurts in eachof four meetings were hand-labeled as either posi-tive (agreement, 9%), negative (disagreement, 6%),backchannel (23%) or other (62%).To approximate ccj(x) we use a Support VectorMachine (SVM) that outputs the probability of thepositive class given an instance (Lin et al, 2003).We use only word-based features similar to thoseused in (Hillard et al, 2003), which include the num-ber of words in a spurt, the number of keywordsassociated with the positive and negative classes,and classification based on keywords.
We also ob-tain word and class-based bigram language modelsfor each class from the training data, and computesuch language model features as the perplexity of aspurt, probability of the spurt, and the probability ofthe first two words in a spurt, using each languagemodel.
We also include the most likely class by thelanguage models as features.3.2 ResultsFirst, we performed the same experiment as in(Hillard et al, 2003) and (Galley et al, 2004), usingthe contrast classifier (CC) method .
Among the fourmeetings, the data from one meeting was set asidefor testing.
Table 1 compares the 3-class accuracyof the contrast classifier with previous results, merg-ing positive and backchannel class together into oneclass as in the other work.
When only lexical fea-tures are used (the first three entries), the SVM-based contrast classifier using meta-classifiers givesthe best performance, outperforming the decisiontree in (Hillard et al, 2003) and the maximum en-Table 1: Comparison of 3-way classification accu-racy on lexical (lex) vs. expanded (exp) featuressets.AccuracyHillard-lex 82Galley-lex 85.0SVM-lex 86.3CC-lex 86.7Galley-exp 86.9Table 2: Comparison of the classification perfor-manceMethod 3-way A/D A/DAcc confusion recoveryunsupervised 79 8 83cc 81.4 4 82.4cc-threshold 76.7 6 85.2cc-meta 86.7 5 81.3cc-meta-thres 87.1 5 82.4tropy model in (Galley et al, 2004).
It also outper-formed the SVM trained using the labeled data only.The contrast classifier is also competitive with thebest case result in (Galley et al, 2004) (last entry),which adds speaker change, segment duration, andadjacency pair sequence dependency features usinga dynamic Bayesian network.In table 2, we report the performance of the fourclassification strategies described in section 2.
Forcomparison, we include a result from Hillard, ob-tained by training a decision tree on the labels pro-duced by their unsupervised clustering technique.Meta classifiers usually obtained higher accuracy,but averaging often achieved higher recovery ofagreement/disagreement (A/D) spurts.
The use ofthresholds increases A/D recovery, with a decreasein accuracy.
We obtained the best accuracy usingboth meta classifiers and thresholds together here,but we more often obtained higher accuracy usingmeta classifiers only.Next, we performed experiments on the entireICSI meeting data.
Only 1,318 spurts were labeled,and 62,944 spurts were unlabeled.
Again, one of thelabeled meeting transcripts was set aside as a test set.We compared the SVM trained only on labeled data55Table 3: Classification performance, training on theentire ICSI data set.
F is defined as 2prp+r where p ismacro precision and r is the macro recall.Method Acc F Neg recallSVM 85.4 72.6 21.1self-training 80.4 65.3 5.2cotraining 85.1 73.8 47.4cc 83.0 75.5 68.5with three semi-supervised methods: self-training,co-training, and the contrast classifier with a meta-classifier.
The self-training iteratively trained anSVM with additional data labeled with confidenceby the previously trained SVM.
For the co-training,each of an SVM and a multilayer backpropagationnetwork was trained on the labeled data and the un-labeled data classified with high confidence (99%)by one classifier were used as labeled data for fur-ther training the other classifier.
We used two differ-ent classifiers, instead of two independent view ofthe input features as in (Goldman and Zhou, 2000).Table 3 shows that the SVM obtained high accu-racy, but the F measure and the recall of the smallestclass, negative, is quite low.
The bias toward the ma-jority class propagates through each iteration in self-training, so that only 5% of the negative tokens weredetected after 30 iterations.
We observed the samepattern in co-training; its accuracy peaked after twoiterations (85.1%) and then performance degradeddrastically (68% after five iterations) due in part toan increase in mislabeled data in the training set (aspreviously observed in (Pierce and Cardie, 2001))and in part because the data skew is not controlledfor.
The contrast classifier performs better than theothers in both F measure and negative class recall,retaining reasonably good accuracy.4 ConclusionIn summary, our experiments on agree-ment/disagreement detection show that semi-supervised learning using contrast classifiers is aneffective method for taking advantage of a largeunlabeled data set for a problem with imbalancedclasses.
The contrast classifier approach outper-forms co-training and self-training in detectingthe infrequent classes.
We also obtain good per-formance relative to other methods using simplelexical features and performance comparable to thebest result reported.The experiments here kept the feature set fixed,but results of (Galley et al, 2004) suggest thatfurther gains can be achieved by augmenting thefeature set.
In addition, it is important to assessthe impact of semi-supervised training with recog-nizer output, where gains from using unlabeled datamay be greater than with reference transcripts as in(Hillard et al, 2003).ReferencesA.
Blum and T. Mitchell.
1998.
Combining labeled andunlabeled data with co-training.
In Proc.
Conferenceon Computational Learning Theory (COLT-98), pages92?100.M.
Galley, K. McKeown, J. Hirschberg, and E. Shriberg.2004.
Identifying agreement and disagreement in con-versational speech: use of Bayesian networks to modeldependencies.
In Proc.
ACL.S.
Goldman and Y. Zhou.
2000.
Enhancing supervisedlearning with unlabeled data.
In Proc.
the 17th ICML,pages 327?334.D.
Hillard, M. Ostendorf, and E. Shriberg.
2003.
Detec-tion of agreement vs. disagreement in meetings: train-ing with unlabeled data.
In Proc.
HLT-NAACL.A.
Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart,N.
Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stol-cke, and C. Wooters.
2003.
The ICSI meeting corpus.In ICASSP-03.T.
Joachims.
1999.
Transductive inference for text clas-sification using support vector machines.
In Proc.ICML, pages 200?209.H.
T. Lin, C. J. Lin, and R. C. Weng.
2003.
A noteon platt?s probabilistic outputs for support vector ma-chines.
Technical report, Dept.
of Computer Science,National Taiwan University.K.
Peng, S. Vucetic, B. Han, H. Xie, and Z. Obradovic.2003.
Exploiting unlabeled data for improving accu-racy of predictive data mining.
In ICDM, pages 267?274.D.
Pierce and C. Cardie.
2001.
Limitations of co-trainingfor natural language learning from large datasets.
InProc.
EMNLP-2001).D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Proc.
ACL,pages 189?196.56
