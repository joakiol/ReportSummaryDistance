Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 46?53,Sydney, July 2006. c?2006 Association for Computational LinguisticsDRT Representation of Degrees of BeliefYafa Al-RahebNational Centre for Language TechnologyDublin City UniversityIrelandyafa.alraheb@gmail.comAbstractThis paper investigates the problems facing mod-elling agents?
beliefs in Discourse RepresentationTheory (DRT) and presents a viable solution in theform of a dialogue-based DRT representation ofbeliefs.
Integrating modelling dialogue interactioninto DRT allows modelling agents?
beliefs, inten-tions and mutual beliefs.
Furthermore, it is one ofthe aims of the paper to account for the importantnotion of agents?
varying degrees of belief in differ-ent contexts.11 IntroductionHeydrich et al remark that ?serious description ofnatural dialogue seems to necessitate that we con-sider the mental states of the speakers involved?
(1998).2 This is a step that is by no means easy.
Itis the aim of this paper to integrate previous workon beliefs in DRT and dialogue theory in order tomodel the mental states of agents in dialogue.The connection between beliefs, intentions andspeech or dialogue acts has been noted in the liter-ature.
Stalnaker notes, for instance, that[i]f we understand contexts, and thespeech acts made in contexts, in termsof the speaker?s beliefs and intentions,we have a better chance of giving sim-pler and more transparent explanationsof linguistic behaviour (Stalnaker 2002:720).The kind of agent beliefs we are concerned withhere arises in dialogue interaction.
The nature of1I gratefully acknowledge support from Science Founda-tion Ireland grant 04/IN/I527.2Other names for mental state used in the literature in-clude ?information state?, ?conversational score?, and ?dis-course context?
(Larsson and Traum 2000).interaction dictates that the strength or degree ofbelief varies depending on contextual factors.
Thiscan be seen from the following example:(1) A: I want to make a booking for mywife.B: Yeah.A: What time is the Thailand flight onMonday?B: It?s at 2 pm.In example (1) B does not necessarily need to be-lieve the presupposition (given information) thatA has a wife.
For the purposes of the conversa-tion, which is providing A with information, B cansimply ?go along with?
the presupposition and nothave it as a member of his beliefs (i.e.
his beliefset) (Stalnaker 2002).
Similarly, let us consider thefollowing example, (2).
The speaker is a customerin a clothing shop.
(2) S1: I want to buy a dress for my wife.H1: Is it for a formal occasion?S2: Yes.H2: What is her favourite colour?S3: She doesn?t like red anymore.H3: Does your wife like black?S4: YesAs the speaker, S, introduces the presuppositionthat he has a wife, the hearer, H, can come to theconclusion that S believes S has a wife.
However,when the hearer comes to refer to S?s wife, H doesnot necessarily have to believe S has a wife.
Hcan simply go along with the information that thespeaker has a wife and use this form of acceptancein H2 without committing to ?strongly believing?it.
Indeed, the speaker may be buying a dress forhis mistress rather than his wife.
By going along46with it, the hearer does not have to commit him-self to believing that the speaker has a wife.
Whatis more at stake than believing that the speaker in-deed has a wife and not a mistress is closing thesale.
Contrast examples (1) and (2) with example(3):(3) S1: You have to get Peter?s son a Chris-tening present.H1: Peter has a son?S2: Sorry I forgot to mention that be-fore.H2: Ok, what sort of present should Iget him?S3: A toy would be nice.In this context, the hearer, H, is required to commitmore strongly to the presupposition of Peter hav-ing a son than simply going along with it, since His being asked to buy a Christening present.
Thefact that H2 agrees to buying a present for Peter?sson reflects more commitment to the presuppo-sition than B shows in example (1).
Considera-tions of this kind lead to the conclusion that dif-ferent contexts call for varying strengths of beliefsand belief representation.
We shall not attempt todescribe all the contextual factors that can causestrength of belief to vary.
The point is, rather, thatwe clearly need to model strength of belief andno current model of DRT incorporates such a pro-posal.
This paper, thus, makes an original proposalfor including a system for graded beliefs in the be-lief spaces (or sets) of both the speaker and thehearer.Bearing this in mind, there is a need in DRT forrepresenting the differing beliefs of agents in dia-logue and their beliefs (meta-beliefs) about otheragents?
beliefs or mental state.
By focussing onthe intentions of speakers and hearers and infer-ring agents?
intentions in making an utterance, theapproach presented in this paper aims at fulfillingthis need.
It follows that, to have a ?full?
theory ofbeliefs and to have an insight into the mental statesof agents in dialogue (the speaker and the hearer),it is necessary to have a representation of agents?beliefs, degrees of beliefs, and the dialogue actsexpressed by their utterances (Asher 1986).
This isalso in order to strengthen the link between utter-ances and agents?
intentions in dialogue.
The di-alogue act or function performed by the utterancetells us something about the speaker?s beliefs.
Fur-thermore, what is also needed is a representationof beliefs that are shared between, or are commonto, the two agents.The question is: how can DRT best model be-liefs?
The following section, 2, outlines the prob-lems facing modelling beliefs in DRT.
Section 3presents a graded view of agents?
beliefs in dia-logue as a solution to these problems.
This is fol-lowed by a description of the relationship betweenbelief and mutual belief, section 4, and then of therelationship between belief and dialogue acts, sec-tion 5.2 Problems Facing Modelling Beliefs inDRTAccording to Heydrich et al (1998), paradigms ofdynamic semantics (DRT, Situation Semantics andDynamic Predicate Logic) face three obstacles inmodelling dialogue.
First, there is the problem ofadapting the paradigm, originally made to modelmonological discourse, to the description of dia-logue with different agents.
The second problemis the description of mental states and the beliefsof the agents.
The third problem is in explaininghow the mental states are related to overt linguisticbehaviour.With respect to the first problem, DRT has grad-ually attempted to address problems of belief rep-resentation in dialogue.
For example, in Prole-gomena, Kamp introduces a simple model of ver-bal communication (Kamp 1990: 71), which con-sists of two agents, A and B, and their mentalstates K(A) and K(B).
Later work by Kamp etal.
(2005) introduces agent modelling for single-sentence discourse, namely the hearer.
The treat-ment presented in this paper allows the represen-tation of dialogue with different agents, thus, ad-dressing the first problem identified by Heydrichet al (1998).With regard to the second problem, however,DRT has been primarily concerned with repre-senting utterances containing propositional atti-tudes such as ?believe?, rather than the beliefs andmeta-beliefs of agents.
Segmented-DRT (SDRT)has mainly focused on belief update and revision(Asher and Lascarides 2003).
The treatment inthis paper takes previous work on beliefs in dy-namic semantics as a starting point and extends itto reach a richer representation of the interactionbetween mental states and the linguistic content ofutterances.
For example, both speaker and hearermental states are represented and the beliefs and47meta-beliefs of agents are reviewed after each ut-terance.As a semantic theory, DRT tells us which dis-course referents are needed in context.
However,DRT does not deal with planning, nor with prag-matic aspects of contexts rendered through re-lating the current utterance to agents?
intentions.Kamp et al?s (2005) expansion of the original,also known as ?vanilla?, DRT (Poesio and Traum1997a), deal minimally with intentions.
To dealwith the third problem mentioned by Heydrich etal., Al-Raheb (2005) has already outlined a prag-matic extension to DRT that makes it appropriatefor linking the current utterance and agents?
inten-tions.The present paper aims to show how that linkcan be strengthened through modelling agents?
in-tentions and relating them to the dialogue actscommunicated via utterances.
In relation to thislink, the significance of degrees of belief is ex-plained in the following section.drs1:i you mdrs2:sc1: buy(you,c2)c2: newShoes(s)attitude(you, ?ACCEPT?, drs3)drs3:attitude(i, ?ACCEPT?, drs2)attitude(i, ?BEL?, drs4)drs4:yb1: mary(m)b2: party(y)b3: has(m,y)attitude(you, ?BEL?, drs5)drs5:sb4: mary(m)b5: party(y)b6: has(m,y)b7: buy(you,b8)b8: newShoes(s)attitude(you, ?INT?, drs6)drs6:y sp1: mary(m)p2:party(y)p3: has(m,y)a1: buy(you,a2)a2: newShoes(s)inform(you, i, a1)Figure 1: Hearer Recognition of S13 Degrees of BeliefTo our knowledge, there is no account in DRTthat accommodates strengths or degrees of beliefof agents in dialogue.
This section addresses thisgap and proposes initially two strengths of beliefinvolved in dialogue to be expanded in future re-search to include further degrees of belief.
Modalexpressions, including words such as ?possibly?and ?might?, are evidence that there exist more de-grees of belief than the ones discussed in this pa-per.The beliefs of an agent are ?her model of howthings are?
(Traum 1994: 15).
The notion of belief(or strong belief) is to be understood in relationto the agent: it is what the agent takes to be true.There is an important philosophical background tothe discussion of ?belief?
and ?knowledge?.
It isoutside the scope of this paper to review all theliterature here.
Quine (1960), Hintikka (1962),Lewis (1969, 1979), and Davidson (1983) are rep-resentative.
The term ?belief?
is understood in thispaper to refer to propositions strongly held by theagent to be true and when making utterances relat-ing to them, the speaker not only commits herselfto their truth but also communicates to the hearerthat she, the speaker, believes those proposition tobe true.Another degree of belief called acceptance isaccounted for in this model.
Acceptance consistsof the agent?s weakly believed propositions.
Theagent may be going along with what the speakeris saying or has acquired a new proposition basedon the speaker?s utterance which has not yet beenconfirmed into a stronger belief.To illustrate what is meant by the distinction be-tween belief and acceptance, let us look at:(4) S1: I need to buy new shoes for Mary?sparty.H1: Try Next on Henry Street.The speaker tells the hearer that she has to buynew shoes for Mary?s party.
In this example, thehearer already (strongly) believes there is a partyand he suggests a place where the speaker can buythem.
Figure 1 demonstrates the hearer?s mentalstate after hearing the speaker?s utterance, S1.
Thehearer?s mental state is represented by a DiscourseRepresentation Structure (DRS), which containsthree sub-DRSs, one for intention (referred to by?attitude(you, ?INT?, drs6)?
and the label for theintention DRS, drs6), another for the belief DRScontaining strong beliefs (referred to by ?attitude(i,?BEL?, drs4)?
and the the label for the belief DRS,drs4), and finally the acceptance DRS contain-ing weak beliefs (referred to by ?attitude(i, ?AC-CEPT?, drs2)?
and the the label for the acceptance48DRS, drs2).3If we change example (4) so that the hearer doesnot actually hold the belief that there is a party, asin:(5) S1: I need to buy new shoes for Mary?sparty.H1: I didn?t realize Mary is throwing aparty.S2: Yeah she is.
It?s next Tuesday.H2: You can probably buy them at Next.The hearer does not necessarily need to stronglybelieve that Mary is throwing a party.
He can ?goalong with?
or accept it and even suggest a placewhere the speaker can buy the shoes.
The exis-tence of a party does not affect the hearer person-ally or directly, i.e.
he does not need to act onit.
However, let us now consider the effect if wechange the example again so that the hearer doesnot know about Mary?s party, nor that he is re-quired to buy new shoes, as in:(6) S1: You need to buy new shoes forMary?s party.H1: I didn?t realize Mary is throwing aparty.S2: Yeah she is.
You should try Next onHenry Street.H2: I will.This time, for the hearer to commit to buyingsomething for a party (in H2) that he did not evenknow existed suggests a stronger degree of beliefthan that of ?going along with?
the speaker havingto buy it.
The existence of the party affects thehearer personally and directly.
Therefore, agree-ing to buy new shoes justifies the inference that hebelieves rather than just accepts there is a party.This is what the paper describes as belief, or astrong degree of belief.
Contrast Figure 1 with thefigure representing the speaker?s mental state afterhearing H2 in example 6, Figure 2.4 Beliefs and Mutual BeliefsThe treatment of beliefs that we are developinghere requires an explicit account of how the be-lief spaces or DRSs of two agents can interact.3Inside the agent?s DRS, ?i?
is used to refer to the agentand ?you?
is used to refer to the other agent.
Assertions aremarked by ?an?, presuppositions by ?pn?, believed informa-tion by ?bn?
and accepted information by ?cn?.drs1:i you mdrs2: attitude(you, ?ACCEPT?, drs3)drs4:attitude(i, ?ACCEPT?, drs2)attitude(i, ?BEL?, drs4)drs4:s nb1: mary(m)b2:party(y)b3: has(m,y)b4: buy(you,b5)b5: newShoes(s)b6: try(you,b7)b7: next(n)attitude(you, ?BEL?, drs5)drs5:b8: mary(m)b9:party(y)b10: has(m,y)b11: buy(you,b12)b12: newShoes(s)b13: try(you,b13)b14: next(n)attitude(you, ?INT?, drs7)drs7:s np1: newShoes(s)p2: next(n)a1: buy(you,p1)a2: try(you,p2)inform(you,i,a1)inform(you,i,a2)Figure 2: Speaker Recognition of H2?Mutual belief?, also referred to as ?mutual knowl-edge?, is the term used by Traum (1994) amongothers, where a group of individuals may believeX, where X may or may not be true.
Stalnaker?s(2002) ?common belief?
is comparable to whatothers call mutual belief.
For X to be a mutualbelief, it has to be accessible to a group; all be-lieve X and all believe that all believe X, and allbelieve that all believe that all believe X.In face-to-face communication, the hearer be-lieves that the speaker believes what she, thespeaker, is communicating.
On the other hand, un-less the hearer indicates doubt or objects to whatthe speaker is saying, the speaker assumes that thehearer believes what the speaker has said ?
whichis consistent with expectations under Gricean co-operativeness assumptions (1989).
The speakeralso assumes that the hearer now has the belief thatthe speaker believes what she just said.
This as-sumption is what leads to ?mutual?
beliefs (Kamp1990: 79).However, mutual belief can be viewed as theprocess of establishing that the speaker and thehearer hold the same belief.
One way in whichthis process may occur is when the speaker holdsa belief and communicates that belief to the hearer.49This belief may then be adopted by the hearer whocan provide feedback to the speaker that the infor-mation communicated has now acquired the statusof belief in an ideal situation with a cooperativehearer.
When both participants reach the conclu-sion that S bel(ieves) X, H bel X, H bel S bel X,and S bel H bel X, then mutual belief is estab-lished.
The speaker in example (7) believes herneighbour is a weirdo.
Whether the utterance isinformative (new) or not depends on the context.In this example, (7), the speaker may not alreadyhave the belief that the hearer believes her neigh-bour is a weirdo.
(7) Speaker: My neighbour is such aweirdo.Hearer: Yeah, he is.
I saw him peepingthrough your window the other day.However, after the hearer makes his utterance, thespeaker can now strongly believe that the hearerbelieves her neighbour is a weirdo, that he believesshe believes her neighbour is a weirdo, and nowshe believes he believes her neighbour is a weirdo.Figure 3 shows the level of nesting to accommo-date the mutual belief that the speaker?s neighbouris a weirdo.
It is possible when this level of nestingis reached to have a separate DRS or space for mu-tual beliefs, called ?mutual belief DRS?.
In whichcase, the propositions held in drs6, can now beremoved from drs6 and added to the ?mutual be-lief DRS?.
Figure 3 represents the speaker?s men-tal state after the hearer makes his utterance.
Forthe purposes of this example, the DRT representedin Figure 3 will mainly focus on the speaker?s be-lief DRT.Achieving mutual belief is immensely helpedby dialogue acts.
For example, when a hearerprovides strong feedback about a new proposition(cf.
drs7 in Figure 3), the speaker can come tobelieve the hearer believes that proposition.
Sec-tion 5 shows the importance of considering the di-alogue acts expressed by an assertion (new infor-mation) and their relationship to degrees of beliefand strengthening of beliefs.5 Beliefs and Dialogue ActsWhen someone makes an assertion, they commu-nicate not only information they assume to be newto the hearer, but also communicate to the hearerinformation about their own beliefs.
In order todrs1:i youdrs2:attitude(you, ?ACCEPT?, drs3)drs3:attitude(i, ?ACCEPT?, drs2)attitude(i, ?BEL?, drs4)drs4:x yb1: neighbour(x)b2: have(i,x)b3: weirdo(x)b4: window(y)b5: have(i,y)b6: peeping-through(x,y)b7: saw(you,b6)attitude(you, ?BEL?, drs5)drs5:b8: neighbour(x)b9: have(i,x)b10: weirdo(x)b11: window(y)b12: have(i,y)b13: peeping-through(x,y)b14: saw(you,b13)attitude(i, ?BEL?, drs6)drs6:b15: neighbour(x)b16: have(i,x)b17: weirdo(x)b18: window(y)b19: have(i,y)b20: peeping-through(x,y)b21: saw(you,b20)attitude(you, ?INT?, drs7)drs7:x yp1: neighbour(x)p2: weirdo(x)p3: window(y)p4: have(i,y)a1: peeping-through(x,y)a2: saw(you,a1)strongPosFeedback(you,i,p2)inform(you,i,a2)Figure 3: Speaker Recognitionmodel beliefs in dialogue, it is necessary to un-derstand what the representation of dialogue in-volves.
A dialogue is ?a cooperative undertakingof agents engaged in developing and transform-ing their common situation?, involving verbal andnon-verbal action (Heydrich et al 1998: 21).
Ina dialogue, utterances give rise to dialogue acts(cf.
agents?
intention DRSs in Figures 1, 2 and3), named speech acts by some, and conversationacts by others (Traum 1994).One of the features of dialogue acts is how theyaffect the agents?
mental states.
As Traum pointsout, ?...
speech acts are a good link between themental states of agents and purposeful communi-cation?
(Traum 1999: 30).
Each agent in dialogueneeds to have a representation of their beliefs andthe other agent?s beliefs or cognitive state in or-der for a dialogue act to be felicitous in Austin?sand Searle?s sense (Asher 1986).
That is to say,dialogue acts depend on agents?
beliefs for inter-pretation.50Each assertion made has one ?function?
or more.For example, the function of a statement could beto make a claim about the world.
Traum (1997) di-vides statements into ?assert?, ?re-assert?, and ?in-form?.
?Assert?
is trying to ?change?
the belief ofthe addressee.
The result of assert is that the hearernow assumes that the speaker is trying to get thehearer to believe the assertion.
?Re-assert?
can beused when participants try to verify old informa-tion, and not necessarily inform of something new.?Inform?
means that the speaker is trying to pro-vide the hearer with information that the hearerdid not have before.
However, Traum does notgo further to discuss cases where agents believetheir utterances (Traum 1994: 14).
It is one of theclaims of this paper that agents in dialogue eitherstrongly or weakly believe their utterances in orderto be cooperative.
It is possible to extend this ap-proach in order to include cases where agents arepurposefully deceitful.
However, this is left for fu-ture research.The adapted dialogue acts, or functions, in thisspaper?s treatment of beliefs in DRT are mainly?inform?, ?change belief?
and ?other?.
?Inform?is used to communicate new information to thehearer, whereas ?change belief?
(or to use Poesioand Traum?s (1997b) dialogue act term ?assert?
)is used to change the hearer?s beliefs about someproposition.
The importance of the representationintroduced in section 3 in relation to dialogue actstranspires in allowing us to make the distinctionbetween the dialogue acts ?inform?
and ?changebelief?
(?assert?).
To ?inform?
the hearer of X, thespeaker needs to have the belief in her beliefs thatthe hearer does not believe X, i.e.
bel(S,?
bel(H,X)).
This is a constraint to making an informativeutterance.
Figure 4 shows the speaker?s beliefs be-fore making the utterance in example (8).
(8) The X-Files DVD is on sale on Amazon.The speaker believes the hearer does not al-ready believe that the X-Files DVD is on sale onAmazon, drs3.
This is demonstrated by the miss-ing propositions representing ?on sale on Amazon?
?onSale(x, b4)?
and ?at(a)?
from drs3 in Figure 4.On the other hand, to make a ?change belief?
oran ?assert?, the speaker would have reason to be-lieve that the hearer believes something differentor the opposite of what the speaker believes, bel(S,bel(H, ?
X)).
The DRT treatment of beliefs pro-posed in this paper allows us to reflect this indrs1:i you x aattitude(i, ?BEL?, drs2)drs2:b1: xFilesDVD(x)b2: amazon(a)b3: onSale(x, b4)b4: at(a)attitude(you, ?BEL?, drs3)drs3:b5: xFilesDVD(x)Figure 4: Inform: Speaker?s utterancedrs1:i you x aattitude(i, ?BEL?, drs2)drs2:b1: xFilesDVD(x)b2: amazon(a)b3: onSale(x, b4)b4: at(a)attitude(you, ?BEL?, drs3)drs3: b5: xFilesDVD(x)b6: not(onSale(x))Figure 5: Change beliefFigure 5, drs3, in which the speaker believes thehearer believes the X-Files DVD is not on sale,?not(onSale(x))?.The category ?Other?
embraces any dialogue actother than ?inform?
and ?change belief?, whoserecognition involves the same process explainedfor others, e.g.
?suggest?, ?clarify?, and ?explain?.4The dialogue acts ?accept?
and ?reject?
come un-der the umbrella of feedback as they can be in re-sponse to, for instance, a ?suggest?
dialogue act.The dialogue act ?clarify?
is used when a heareris having difficulty recognizing the speaker?s ut-terance.5 On the other hand, ?explain?
is whenthe speaker responds to the hearer?s clarificationrequest and provides a clarifying utterance.
Thehearer can accept, believe, or reject that explana-tion.
The dialogue act ?suggest?
also instigates oneof three reactions: the hearer can accept, believe orreject that suggestion and may provide feedback toindicate which is his reaction.
It is of more inter-est to this paper to examine the effects of dialogueacts on the hearer?s beliefs, and what dialogue actssuggest about the speaker?s beliefs.4It is possible for this category to be expanded to in-clude more dialogue acts such as ?question?, ?answer?, ?self-correct?
and ?offer?.5Clarification is a form of feedback.
?I didn?t hear whatyou said?
is both ?feedback?
act and an ?inform?
(Schegloff etal.
1977).51	 Figure 6: Feedback5.1 Feedback and Agents?
BeliefsTraum (1994) suggests that when an assertion ismade, the hearer has an obligation to producean ?understanding act?.
In general, acknowledge-ment is expected in Traum?s treatment of speechacts.
This means that when a hearer responds with?okay?, the hearer can be taken to be providingan acknowledgement and an acceptance.
How-ever, the hearer does not always provide feedback.Grounding often happens as a result of implicitrather than overt feedback and acknowledgement(Bunt 1995).6 In fact, the treatment outlined inthis paper maintains that the lack of feedback is tobe considered a form of ?weak positive feedback?,an extension to Dynamic Interpretation Theory?s(DIT) positive feedback (Bunt 1995).
The hearerdoes not object to the speaker?s utterance by notproviding feedback, since if the hearer did object,he would explicitly do so.When the speaker makes an assertion, thehearer may indicate that the message has been re-ceived (weak positive feedback), example (9.b).Weak positive feedback may indicate understand-ing, continued attention, or acknowledgement,such as ?uh huh?, and ?yeah?
(Clark and Schaefer1989).
Another case of weak positive feedback isprovided by example (9.a) where the hearer doesnot say anything.
It is assumed that the hearer didnot have any problems and has received the asser-tion, A.
In the case of weak feedback, it can beargued that this represents the ?acceptance?
of A.7Another response for the hearer is ?strong posi-6Grounding is a term adapted by Traum (1994) fromClark and Schaefer?s (1989) work on establishing commonground.7This does not cancel cases where for social reasons, suchas politeness, the hearer does not necessarily agree with thespeaker, but does not wish to indicate it.
The speaker canwrongly or rightly come to the conclusion that the hearer ac-cepts the assertion.tive feedback?
(another extension to DIT?s positivefeedback), where the hearer not only indicates re-ception of A, but also that she agrees that A (cf.drs7 Figure 3).
This is where confirming adoptionof new beliefs takes place, example (9.c).
Reject-ing A is another way of giving feedback, negativefeedback, as in example (9.d).
(9) Speaker: Mary loves John.a.
Hearer:b. Hearer: aha.c.
Hearer: I couldn?t agree more!d.
Hearer: No, Mary is besotted withTom!There are also degrees of belief that can be ex-pressed according to the speech act used, firm ver-sus ?tentative?.
Poesio and Traum pay less atten-tion to ?the attitudes expressed by the acts?
(Poesioand Traum 1998: 221).
Unlike Traum?s model, theeffects of the dialogue acts?
employed in agents?DRSs on agents?
beliefs are considered in this pa-per.
Figure 6 demonstrates the link between feed-back dialogue acts and agents?
beliefs.6 ConclusionAs this paper has demonstrated, beliefs vary instrength according to context.
Beliefs also changewith the coming of new information.
The DRTtreatment discussed here allows for the represen-tation of strong beliefs and weaker beliefs as wellas changes to beliefs.
Agents in a dialogue mayform stronger beliefs as the dialogue progresses,requiring moving the content of their weaker be-liefs to the stronger belief space.In sum, there is no account in standard DRT thataccommodates degrees of belief of agents in dia-logue.
This paper has addressed this omission andsuggested two degrees of belief involved in dia-logue, namely ?belief?
and ?acceptance?.
It is sug-52gested that this is the initial step in representingagents?
mental states in dialogue-oriented DRT.However, this paper does not deal with wordswhich introduce more degrees of belief than thetwo addressed in the model.
It would be interest-ing to see more degrees of belief represented in aDRT dialogue model of agents in future research.It is possible that such modal expressions can bearranged on a scale corresponding to degrees ofbelief (cf.
Werth 1999).
Moreover, this paper hasaccounted for agent?s mutual beliefs and linkedagents?
beliefs and intentions to the dialogue actsof their utterances, in order to address the prob-lematic nature of accounting for belief in DRT.ReferencesAl-Raheb, Y.
2005.
Speaker/Hearer Representation in a Dis-course Representation Theory Model of Presupposition: AComputational-Linguistic Approach.
Phd.
University ofEast Anglia.Asher, N. 1986.
?Belief in Discourse Representation The-ory?.
Journal of Philosophical Logic 15, pp.
127?189.Asher, N. and Lascarides, A.
2003.
Logics of Conversation.Cambridge: Cambridge University Press.Bunt, H. 1995.
?Dynamic Interpretation and Dialogue The-ory?.
In: M. Taylor, F. Neel, and D. Bouwhuis (Eds.).
TheStructure of Multimodal Dialogue, Volume 2. pp.
139?166.Amsterdam: John Benjamins 2000.Clark, H. and Schaefer, E. 1989.
?Contributing to Discourse?.Cognitive Science 13, pp.
259?294.Davidson, D. 1983.
?A Coherence Theory of Truth andKnowledge?.
In: D. Henrich (Ed.).
Kant oder Hegel.
pp.433?438.
Stuttgart: Klett-Cotta Buchhandlung.Gazdar, G. 1979.
?A Solution to the Projection Problem?.In: C. Oh and D. Dineen (Eds.).
Syntax and Semantics II:Presupposition.
New York: Academic Press.Grice, P. 1989.
Studies in the Way of Words.
Cambridge,MA: Harvard University Press.Heydrich, W., Kuhnlein, P., and Rieser, H. 1998.
?A DRT-Style Modelling of Agents?
Mental States in ConstructionDialogue?.
In: Proceedings of Workshop on LanguageTechnology 13 (Twendial ?98), TWLT.
Faculty of Infor-matics, the University of Twente: The Netherlands.Hintikka, J.
1962.
Knowledge and Belief: An Introduction tothe Logic of the Two Notions.
Mimeo: Indiana UniversityLinguisitics Club.Horton, D. and Hirst, G. 1988.
?Presuppositions as Beliefs?.In: Coling-88: Proceedings of the 12th International Con-ference on Computational Linguistics.
pp.
255?260.
Bu-dapest: Hungary.Kamp, H. 1990.
?Prolegomena to a Structural Account of Be-lief and Other Attitudes?.
In: C. Anderson and J.
Owens(Eds.).
Propositional Attitudes: The Role of Content inLogic, Language, and Mind.
Stanford, CA: CSLI Publi-cations.Kamp, H., van Genabith, J., and Reyle, U.
2005.The Handbook of Logic.
Unpublished Manuscript.http://www.ims.uni-stuttgart.de/?hans/.Larsson, S. and Traum, D. 2000.
?Information State and Dia-logue Management in the TRINDI Dialogue Move EngineToolkit?.
In: Natural Language Engineering.
Special Is-sue on Spoken Language Dialogue System Engineering.pp.
323?340.Lewis, D. 1969.
Convention: A Philosophical Study.
Har-vard University Press.Lewis, D. 1979.
?Attitudes de dicto and de re?.
PhilosophicalReview 88, pp.
513?543.Poesio, M. and Traum, D. 1997a.
?Conversational Actionsand Discourse Situations?.
Computational Intelligence 13,pp.
309?347.Poesio, M. and Traum, D. 1997b.
?Representing Conversa-tion Acts in a Unified Semantic/Pragmatic Framework?.In: Working Notes of AAAI Fall Symposium on Com-municative Action in Humans and Machines.
pp.
67?74.Cambridge, MA: MIT Press.Poesio, M. and Traum, D. 1998.
?Towards an Axiomatizationof Dialogue Acts?.
In: J. Hulstijn and A. Nijholt (Eds.
).Formal Semantics and Pragmatics of Dialogue, Proceed-ings of Twendial?
98. pp.
207?221.
Universiteit Twente:Enschede.Quine, W. 1960.
Word and Object.
Cambridge MA: MITPress.Schegloff, E., Jefferson, G., and Sacks, H. 1977.
?The Prefer-ence for Self-Correction in the Organization of Repair inConversation?.
Language 53, pp.
361?382.Stalnaker, R. 1974.
?Pragmatic Presupposition?.
In: M. Mu-nitz and P. Unger (Eds.).
Semantic and Philosophy.
pp.197?214.
New York: New York University Press.Stalnaker, R. 1988.
?Belief Attribution and Context?.
In: R.Grimm and D. Merrill (Eds.).
Contents of Thought.
Pro-ceedings of the 1985 Oberlin Colloquium in Philosophy.pp.
140?156.
Tucson State: The University of ArizonaPress.Stalnaker, R. 1999.
Context and Content.
Oxford: OxfordUniversity Press.Stalnaker, R. 2002.
?Common ground?.
Linguistics and Phi-losophy 25(5-6), pp.
701?721.Traum, D. 1994.
A Computational Theory of Grounding inNatural Language Conversation.
Phd and tr 545.
Com-puter Science Department, Univeristy of Rochester.Traum, D. 1997.
?Report on Multiparty Dialogue Sub-groupon Forward-looking Communicative Function?.
In: Stan-dards for Dialogue Coding in Natural Language Process-ing, Dagstuhl-Seminar Report no.
167.Traum, D. 1999.
?Computational Models of Grounding inCollaborative Systems?.
In: Working notes of AAAI FallSymposium on Psychological Models of Communication.pp.
124-131.
North Falmouth, Massachusetts.Werth, P. 1999.
Text Worlds: Representing Conceptual Spacein Discourse.
New York: Longman.53
