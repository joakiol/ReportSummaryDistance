Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1870?1881,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsOn the Similarities BetweenNative, Non-native and Translated TextsElla RabinovichM?Sergiu NisioiNoam Ordan?Shuly Wintner?MIBM Haifa Research Labs?Department of Computer Science, University of HaifaSolomon Marcus Center for Computational Linguistics, University of Bucharest?The Arab College for Education, Haifa{ellarabi,sergiu.nisioi,noam.ordan}@gmail.com, shuly@cs.haifa.ac.ilAbstractWe present a computational analysis ofthree language varieties: native, advancednon-native, and translation.
Our goal isto investigate the similarities and differ-ences between non-native language pro-ductions and translations, contrasting bothwith native language.
Using a collec-tion of computational methods we estab-lish three main results: (1) the three typesof texts are easily distinguishable; (2) non-native language and translations are closerto each other than each of them is to nativelanguage; and (3) some of these character-istics depend on the source or native lan-guage, while others do not, reflecting, per-haps, unified principles that similarly af-fect translations and non-native language.1 IntroductionThis paper addresses two linguistic phenomena:translation and non-native language.
Our maingoal is to investigate the similarities and differ-ences between these two phenomena, and contrastthem with native language.
In particular, we areinterested in the reasons for the differences be-tween translations and originals, on one hand, andnative and non-native language, on the other.
Dothey reflect ?universal?
principles, or are they de-pendent on the source/native language?Much research in translation studies indicatesthat translated texts have unique characteristics.Translated texts (in any language) constitute a sub-language of the target language, sometimes re-ferred to as translationese (Gellerstam, 1986).
Theunique characteristics of translationese have beentraditionally classified into two categories: proper-ties that stem from interference of the source lan-guage (Toury, 1979), and universal traits resultingfrom the translation process itself, independentlyof the specific source and target languages (Baker,1993; Toury, 1995).
The latter so-called transla-tion universals have triggered a continuous debateamong translation studies researchers (Mauranenand Kujam?aki, 2004; House, 2008; Becher, 2010).Similarly, over half a century of research onsecond language acquisition (SLA) established thepresence of cross-linguistic influences (CLI) innon-native utterances (Jarvis and Pavlenko, 2008).CLI is a cover term proposed by Kellerman andSharwood-Smith (1986) to denote various phe-nomena that stem from language contact situa-tions such as transfer, interference, avoidance, bor-rowing, etc.1In addition, universal traits result-ing from the learning process itself have been no-ticed regardless of the native language, L1.2Forexample, similar developmental sequences havebeen observed for negation, question formation,and other sentence structures in English (Dulayand Burt, 1974; Odlin, 1989) for both Chinese andSpanish natives.
Phenomena such as overgener-alization, strategies of learning (Selinker, 1972),psychological factors (Ellis, 1985), and culturaldistance (Giles and Byrne, 1982) are also influen-tial in the acquisition process.There are clear similarities between translationsand non-native language: both are affected by thesimultaneous presence of (at least) two linguisticsystems, which may result in a higher cognitiveload (Shlesinger, 2003).
The presence of the L1may also cause similar CLI effects on the targetlanguage.On the other hand, there are reasons to believe1To avoid terminological conflicts, we shall henceforthuse CLI to denote any influence of one linguistic system overanother, w.r.t.
both translations and non-native productions.2For simplicity, we will use L1 to refer both to the na-tive language of a speaker and to the source language of atranslated text.
We use target language to refer to second andtranslation languages (English in this paper).1870that translationese and non-native language shoulddiffer from each other.
Translations are producedby native speakers of the target language.
Non-natives, in contrast, arguably never attain native-like abilities (Coppieters, 1987; Johnson and New-port, 1991), however this hypothesis is stronglydebated in the SLA community (Birdsong, 1992;Lardiere, 2006).Our goal in this work is to investigate three lan-guage varieties: the language of native speakers(N), the language of advanced, highly fluent non-native speakers (NN), and translationese (T).
Weuse the term constrained language to refer to thelatter two varieties.
We propose a unified com-putational umbrella for exploring two related ar-eas of research on bilingualism: translation studiesand second language acquisition.
Specifically, weput forward three main hypotheses: (1) The threelanguage varieties have unique characteristics thatmake them easily distinguishable.
(2) Non-nativelanguage and translations are closer to each otherthan either of them is to native language.
(3) Someof these characteristics are dependent on the spe-cific L1, but many are not, and may reflect uni-fied principles that similarly affect translations andnon-native language.We test these hypotheses using several corpus-based computational methods.
We use super-vised and unsupervised classification (Section 4)to show that the three language varieties are easilydistinguishable.
In particular, we show that nativeand advanced non-native productions can be ac-curately separated.
More pertinently, we demon-strate that non-native utterances and translationscomprise two distinct linguistic systems.In Section 5, we use statistical analysis to ex-plore the unique properties of each language vari-ety.
We show that the two varieties of constrainedlanguage are much closer to each other than theyare to native language: they exhibit poorer lexicalrichness, a tendency to use more frequent words, adifferent distribution of idiomatic expressions andpronouns, and excessive use of cohesive devices.This is an unexpected finding, given that both na-tives and translators (in contrast to non-natives)produce texts in their mother tongue.Finally, in Section 6 we use language modelingto show that translations and non-native languageexhibit similar statistical properties that clearly re-flect cross-linguistic influences: experiments withdistinct language families reveal salient ties be-tween the two varieties of constrained language.The main contribution of this work is thus the-oretical: it sheds light on some fundamental ques-tions regarding bilingualism, and we expect it tomotivate and drive future research in both SLAand translation studies.
Moreover, a better under-standing of constrained language may also havesome practical import, as we briefly mention in thefollowing section.2 Related workCorpus-based investigation of translationese hasbeen a prolific field of recent research, laying outan empirical foundation for the theoretically moti-vated hypotheses on the characteristics of transla-tionese.
More specifically, identification of trans-lated texts by means of automatic classificationshed light on the manifestation of translation uni-versals and cross-linguistic influences as markersof translated texts (Baroni and Bernardini, 2006;van Halteren, 2008; Gaspari and Bernardini, 2008;Kurokawa et al, 2009; Koppel and Ordan, 2011;Ilisei and Inkpen, 2011; Volansky et al, 2015;Rabinovich and Wintner, 2015; Nisioi, 2015b),while Gaspari and Bernardini (2008) introduceda dataset for investigation of potential commontraits between translations and non-native texts.Such studies prove to be important for the develop-ment of parallel corpora (Resnik and Smith, 2003),the improvement in quality of plagiarism detection(Potthast et al, 2011), language modeling, andstatistical machine translation (Lembersky et al,2012, 2013).Computational approaches also proved benefi-cial for theoretical research in second languageacquisition (Jarvis and Pavlenko, 2008).
Numer-ous studies address linguistic processes attributedto SLA, including automatic detection of highlycompetent non-native writers (Tomokiyo andJones, 2001; Bergsma et al, 2012), identificationof the mother tongue of English learners (Kop-pel et al, 2005; Tetreault et al, 2013; Tsvetkovet al, 2013; Nisioi, 2015a) and typology-drivenerror prediction in learners?
speech (Berzak et al,2015).
These studies are instrumental for languageteaching and student evaluation (Smith and Swan,2001), and can improve NLP applications such asauthorship profiling (Estival et al, 2007) or gram-matical error correction (Chodorow et al, 2010).Most of these studies utilize techniques that aremotivated by the same abstract principles associ-1871ated with L1 influences on the target language.To the best of our knowledge, our work is thefirst to address both translations and non-nativelanguage under a unifying computational frame-work, and in particular to compare both with na-tive language.3 Methodology and experimental setup3.1 DatasetOur dataset3is based on the highly homogeneouscorpus of the European Parliament Proceedings(Koehn, 2005).
Note that the proceedings are pro-duced as follows: (1) the utterances of the speak-ers are transcribed; (2) the transcriptions are sentto the speaker who may suggest minimal editingwithout changing the content; (3) the edited ver-sion is then translated by native speakers.
Note inparticular that the texts are not a product of simul-taneous interpretation.In this work we utilize a subset of Europarl inwhich each sentence is manually annotated withspeaker information, including the EU state rep-resented and the original language in which thesentence was uttered (Nisioi et al, 2016).
Thetexts in the corpus are uniform in terms of style,respecting the European Parliament?s formal stan-dards.
Translations are produced by native En-glish speakers and all non-native utterances are se-lected from members not representing UK or Ire-land.
Europarl N consists of texts delivered by na-tive speakers from England.Table 1 depicts statistics of the dataset.4Incontrast to other learner corpora such as ICLE(Granger, 2003), EFCAMDAT (Geertzen et al,2013) or TOEFL-11 (Blanchard et al, 2013),this corpus contains translations, native, and non-native English of high proficiency speakers.
Mem-bers of the European Parliament have the right touse any of the EU?s 24 official languages whenspeaking in Parliament, and the fact that some ofthem prefer to use English suggests a high degreeof confidence in their language skills.3.2 PreprocessingAll datasets were split by sentence, cleaned(text lowercased, punctuation and empty lines re-moved) and tokenized using the Stanford tools3The dataset is available at http://nlp.unibuc.ro/resources.html4Appendix A provides details on the distribution of NNand T texts by various L1s.sub-corpus sentences tokens typesnative (N) 60,182 1,589,215 28,004non-native (NN) 29,734 783,742 18,419translated (T) 738,597 22,309,296 71,144total 828,513 24,682,253 117,567Table 1: Europarl corpus statistics: native, non-native and translated texts.
(Manning et al, 2014).
For the classificationexperiments we randomly shuffled the sentenceswithin each language variety to prevent interfer-ence of other artifacts (e.g., authorship, topic) intothe classification procedure.
We divided the datainto chunks of approximately 2,000 tokens, re-specting sentence boundaries, and normalized thevalues of lexical features by the number of to-kens in each chunk.
For classification we usedPlatt?s sequential minimal optimization algorithm(Keerthi et al, 2001; Hall et al, 2009) to train sup-port vector machine classifiers with the default lin-ear kernel.In all the experiments we used (the maximal)equal amount of data from each category, thus wealways randomly down-sampled the datasets in or-der to have a comparable number of examples ineach class; specifically, 354 chunks were used foreach language variety: N, NN and T.3.3 FeaturesThe first feature set we utilized for the classifica-tion tasks comprises function words (FW), proba-bly the most popular choice ever since Mostellerand Wallace (1963) used it successfully for theFederalist Papers.
Function words proved to besuitable features for multiple reasons:(1) they ab-stract away from contents and are therefore lessbiased by topic; (2) their frequency is so high thatby and large they are assumed to be selected un-consciously by authors; (3) although not easily in-terpretable, they are assumed to reflect grammar,and therefore facilitate the study of how structuresare carried over from one language to another.
Weused the list of approximately 400 function wordsprovided in Koppel and Ordan (2011).A more informative way to capture (admittedlyshallow) syntax is to use part-of-speech (POS) tri-grams.
Triplets such as PP (personal pronoun) +VHZ (have, 3sg present) + VBN (be, past partici-ple) reflect a complex tense form, represented dis-tinctively across languages.
In Europarl, for ex-ample, this triplet is highly frequent in translations1872from Finnish and Danish and much rarer in trans-lations from Portuguese and Greek.
In this workwe used the top-3,000 most frequent POS trigramsin each corpus.We also used positional token frequency(Grieve, 2007).
The feature is defined as counts ofwords occupying the first, second, third, penulti-mate and last positions in a sentence.
The motiva-tion behind this feature is that sentences open andclose differently across languages, and it shouldbe expected that these opening and closing de-vices will be transferred from L1 if they do notviolate the grammaticality of the target language.Positional tokens were previously used for trans-lationese identification (Volansky et al, 2015) andfor native language detection (Nisioi, 2015a).Translations are assumed to exhibit explicita-tion: the tendency to render implicit utterancesin the source text more explicit in the translationproduct.
For example, causality, even though notalways explicitly expressed in the source, is ex-pressed in the target by the introduction of cohe-sive markers such as because, due to, etc.
(Blum-Kulka, 1986).
Similarly, Hinkel (2001) conducteda comparative analysis of explicit cohesive de-vices in academic texts by non-native English stu-dents, and found that cohesive markers are dis-tributed differently in non-native English produc-tions, compared to their native counterparts.
Tostudy this phenomenon, we used the set of over100 cohesive markers introduced in Hinkel (2001).4 The status of constrained languageTo establish the unique nature of each languagevariety in our dataset, we perform multiple pair-wise binary classifications between N, NN, and T,as well as three-way classifications.
Table 2 re-ports the results; the figures reflect average ten-fold cross-validation accuracy (the best result ineach column is boldfaced).In line with previous works (see Section 2),classification of N?T, as well as N?NN, yieldsexcellent results with most features and featurecombinations.
NN?T appears to be easily distin-guishable as well; specifically, FW+POS-trigramscombination with/without positional tokens yields99.57% accuracy.
The word maybe is among themost discriminative feature for NN vs. T, beingoverused in NN, as opposed to perhaps, which ex-hibits a much higher frequency in T; this may indi-cate a certain degree of formality, typical of trans-lated texts (Olohan, 2003).
The words or, whichand too are considerably more frequent in T, im-plying higher sentence complexity.
This trait isalso reflected by shorter NN sentences, comparedto T: the average sentence length in Europarl is 26tokens for NN vs. 30 for T. Certain decisivenessdevices (sure, very) are underused in T, in accor-dance with Toury (1995)?s law of standardization(Vanderauwera, 1985).
The three-way classifica-tion yields excellent results as well; the highestaccuracy is obtained using FW+positional tokenswith/without POS-trigrams.feature / dataset N-NN N-T NN-T 3-wayFW 98.72 98.72 96.89 96.60POS (trigrams) 97.45 98.02 97.45 95.10pos.
tok 99.01 99.01 98.30 98.11cohesive markers 85.59 87.14 82.06 74.19FW+POS 99.43 99.57 99.57 99.34FW+pos.
tok 99.71 99.85 98.30 99.52POS+pos.
tok 99.57 99.57 99.01 99.15FW+POS+pos.
tok 99.85 99.85 99.57 99.52Table 2: Pairwise and three-way classification re-sults of N, NN and T texts.A careful inspection of the results in Table 2 re-veals that NN?T classification is a slightly yet sys-tematically harder task than N?T or N?NN; thisimplies that NN and T texts are more similar toeach other than either of them is to N.To emphasize this last point, we analyze theseparability of the three language varieties by ap-plying unsupervised classification.
We perform bi-secting KMeans clustering procedure previouslyused for unsupervised identification of transla-tionese by Rabinovich and Wintner (2015).
Clus-tering of N, NN and T using function words intothree clusters yields high accuracy, above 90%.For the sake of clusters?
visualization in a bidi-mensional plane, we applied principal componentanalysis for dimensionality reduction.Figure 1: Clustering of N, NN and T into three (a)and two (b) clusters using function words.
Clus-ters?
centroids in (a) are marked by black circles;square sign stands for instances clustered wrongly.1873The results are depicted in Figure 1 (a).
Evi-dently, NN and T exhibit higher mutual proximitythan either of them with N. Fixing the number ofexpected clusters to 2 further highlights this obser-vation, as demonstrated in Figure 1 (b): both NNand T instances were assigned to a single cluster,distinctively separable from the N cluster.We conclude that the three language varieties(N, NN, and T) constitute three different, distin-guishable ontological categories, characterized byvarious lexical, syntactic and grammatical proper-ties; in particular, the two varieties of constrainedlanguage (NN and T) represent two distinct lin-guistic systems.
Nevertheless, we anticipate NNand T to share more common tendencies and reg-ularities, when compared to N. In the followingsections, we put this hypothesis to the test.5 L1-independent similaritiesIn this section we address L1-independent simi-larities between NN and T, distinguishing themfrom N. We focus on characteristics which aretheoretically motivated by translation studies andwhich are considered to be L1-independent, i.e.,unrelated to cross-linguistic influences.
We hy-pothesize that linguistic devices over- or under-represented in translation would behave similarlyin highly competent non-native productions, com-pared to native texts.To test this hypothesis, we realized various lin-guistic phenomena as properties that can be easilycomputed from N, NN and T texts.
We refer to thecomputed characteristics as metrics.
Our hypoth-esis is that NN metric values will be similar to T,and that both will differ from N. We used equally-sized texts of 780K tokens for N, NN and T; theexact computation is specified for each metric.For the sake of visualization, the three valuesof each metric (for N, NN and T) were zero-one scaled by total-sum normalization.
Figure 2graphically depicts the normalized metric values.We now describe and motivate each metric.
Weanalyze the results in Section 5.1 and establishtheir statistical significance in Section 5.2.Lexical richness Translated texts tend to exhibitless lexical diversity (Al-Shabab, 1996).
Blum-Kulka (1986) suggested that translated texts makedo with less words, which is reflected by theirlower type-to-token ratio (TTR) compared to thatof native productions.
We computed the TTR met-ric by dividing the number of unique (lemmatized)tokens by the total number of tokens.Mean word rank Halverson (2003) claims thattranslators use more prototypical language, i.e.,they regress to the mean (Shlesinger, 1989).
We,therefore, hypothesize that rarer words are usedmore often in native texts than in non-native pro-ductions and translationese.
To compute this met-ric we used a BNC-based ranked list of 50K En-glish words5, excluding the list of function words(see Section 3.3).
The metric value was calculatedby averaging the rank of all tokens in a text; tokensthat do not appear in the list of 50K were excluded.Collocations Collocations are distributed differ-ently in translations and in originals (Toury, 1980;Kenny, 2001).
Common and frequent colloca-tions are used almost subconsciously by nativespeakers, but will be subjected to a more carefulchoice by translators and, presumably, by fluentnon-native speakers (Erman et al, 2014).
For ex-ample, the phrase make sure appears twice moreoften in native Europarl texts than in NN, and fivetimes more than in T; bear in mind has almostdouble frequency in N, compared to NN and T.Expressions such as: bring forward, figure out, inlight of, food chain and red tape appear dozensof times in N, as opposed to zero occurrences inNN and T Europarl texts.
This metric is definedby computing the frequency of idiomatic expres-sions6in terms of types.Cohesive markers Translations were proven toemploy cohesion intensively (Blum-Kulka, 1986;?ver?as, 1998; Koppel and Ordan, 2011).
Non-native texts tend to use cohesive markers differ-ently as well: sentence transitions, the major cohe-sion category, was shown to be overused by non-native speakers regardless of their native language(Hinkel, 2001).
The metric is defined as the fre-quency of sentence transitions in the three lan-guage varieties.Qualitative comparison of various markers be-tween NN and T productions, compared to N inthe Europarl texts, highlights this phenomenon: inaddition is twice as frequent in NN and T thanin N; according, at the same time and thus occurthree times more frequently in NN and T, com-pared to N; moreover is used four times more fre-5https://www.kilgarriff.co.uk we used thelist extracted from both spoken and written text.6Idioms were taken from https://en.wiktionary.org/wiki/Category:English_idioms.
The list was minimally cleaned up.1874lexical richness?mean word rank?pronouns?collocation (types)?transitions0.30.350.4zero-onescalenormalizedvaluenative (N) translated (T) non-native (NN)Figure 2: Metric values in N, NN and T. Tree-way differences are significant in all metric categories and?*?
indicates metrics with higher pairwise similarity of NN and T, compared individually to N.quently; and to conclude is almost six times morefrequent.Personal pronouns We expect both non-nativespeakers and translators to spell out entities (bothnouns and proper nouns) more frequently, as ameans of explicitation (Olohan, 2002), thus lead-ing to under-use of personal pronouns, in contrastto native texts.
As an example, his and she aretwice more frequent in N than in NN and T.We define this metric as the frequency of (all)personal and possessive pronouns used in the threelanguage varieties.
The over-use of personal pro-nouns in N utterances, is indeed balanced out bylower frequency of proper and regular nouns inthese texts, compared to T and NN.75.1 AnalysisEvidently (see Figure 2), translationese and non-native productions exhibit a consistent pattern inboth datasets, compared to native texts: NN andT systematically demonstrate lower metric valuesthan N for all characteristics (except sentence tran-sitions, where both NN and T expectedly sharea higher value).
All metrics except mean wordrank exhibit substantial (sometimes dramatic) dif-ferences between N, on the one hand, and NN andT, on the other, thus corroborating our hypothe-sis.
Mean word rank exhibits a more moderatevariability in the three language varieties, yield-ing near identical value in NN and T; yet, it showsexcessive usage in N.The differences between metric values are sta-tistically significant for all metrics (Section 5.2).7Normalized frequencies of nouns and proper nouns are0.323, 0.331 and 0.345 for N, T, and NN, respectively.Moreover, in all cases (except transitions), the dif-ference between NN and T metrics is significantlylower than the difference between either of themand N, implying a higher proximity of NN andT distributions, compared individually to N. Thisfinding further emphasizes the common tenden-cies between NN and T.As shown in Figure 2, NN and T are systemati-cally and significantly different from N. Addition-ally, we can see that T is consistently positionedbetween N and NN (except for sentence transi-tions), implying that translations produced by na-tive speakers tend to resemble native utterances toa higher degree than non-native productions.5.2 Statistical significanceInspired by the results depicted in Figure 2, wenow put to test two statistical hypotheses: (1) N,NN and T productions do not represent identicalunderlying distributions, i.e., at least one pair isdistributed differently; and consequently, (2) NNand T productions exhibit higher similarity (interms of distance) than either of them with N. Wetest these hypotheses by applying the bootstrap-ping statistical analysis.Bootstrapping is a statistical technique involv-ing random re-sampling (with replacement) fromthe original sample; it is often used to assign ameasure of accuracy (e.g., a confidence interval) toan estimate.
Specifically, let CN, CNNand CTde-note native, non-native and translated sub-corporaof equal size (780K tokens).
Let CALLdenote theconcatenation of all three sub-corpora, resultingin a total of 2,340M tokens.
We further denotea function computing a metric m by fm; when ap-plied to C, its value is fm(C).
The sum of pair-1875wise distances between the three individual datasetmetrics is denoted by Dtotal:Dtotal= |fm(CN)?
fm(CNN)|+|fm(CN)?
fm(CT)|+ |fm(CNN)?
fm(CT)|High values of Dtotalindicate a difference be-tween the three language varieties.
To examinewhether the observed Dtotalis high beyond chancelevel, we use the bootstrap approach, and repeatthe following process 1,000 times:8we sampleCALLwith replacement (at sentence granularity),generating in the j-th iteration equal-sized samples?CNj,?CNNj,?CTj.
The corresponding distance esti-mate, therefore, is:?Dtotalj= |fm(?CNj)?
fm(?CNNj)|+|fm(?CNj)?
fm(?CTj)|+ |fm(?CNNj)?
fm(?CTj)|We repeat random re-sampling and computationof?Dtotalj1,000 times, and estimate the p-valueof?Dtotalby calculation of its percentile withinthe series of (sorted)?Dtotaljvalues, where j ?
(1, .
.
.
, 1000).
In all our experiments the origi-nal distance Dtotalexceeds the maximum estimatein the series of?Dtotalj, implying highly significantdifference, with p-value<0.001 for all metrics.In order to stress this outcome even further, wenow test whether (the constrained) NN and T ex-hibit higher pairwise similarity, as opposed to N.We achieve this by assessment of the distance be-tween NN and T productions, compared to the dis-tance between N and its closest production (again,in terms of distance): either NN or T. We sampleCN, CNNand CT(with replacement) separately,constructing?CN,?CNNand?CT, respectively, anddefine the following distance function:?Ddifj= |fm(?CNj)?fm(?CjK)|?|fm(?CNNj)?fm(?CTj)|whereK=????
?NN if |fm(CN)?
fm(CNN)| <|fm(CN)?
fm(CT)|T otherwiseWe repeat re-sampling and computation of?Ddifj1,000 times for each metric value in both8This sample size is proven sufficient by the highly sig-nificant results (very low p-value).datasets and sort the results.
The end points ofthe 95% confidence interval are defined by esti-mate values with 2.5% deviation from the min-imum (min-end-point) and the maximum (max-end-point) estimates.
We assess the p-value of thetest by inspecting the estimate underlying the min-end-point; specifically, in case the min-end-pointis greater than 0, we consider p<0.05.
Metric cat-egories exhibiting higher NN-T similarity than ei-ther N-NN or N-T are marked with ?*?
in Figure 2.6 L1-related similaritiesWe hypothesize that both varieties of constrainedlanguage exhibit similar (lexical, grammatical,and structural) patterns due to the influence of L1over the target language.
Consequently, we antic-ipate that non-native productions of speakers of acertain native language (L1) will be closer to trans-lations from L1 than to translations from other lan-guages.Limited by the amount of text available for eachindividual language, we set out to test this hypoth-esis by inspection of two language families, Ger-manic and Romance.
Specifically, the Germanicfamily consists of NN texts delivered by speak-ers from Austria, Germany, Netherlands and Swe-den; and the Romance family includes NN speak-ers from Portugal, Italy, Spain, France and Roma-nia.
The respective T families comprise transla-tions from Germanic and Romance originals, cor-responding to the same countries.
Table 3 providesdetails on the datasets.sentences tokens typesGermanic NN 5,384 132,880 7,841Germanic T 269,222 7,145,930 43,931Romance NN 6,384 180,416 9,838Romance T 307,296 9,846,215 49,925Table 3: Europarl Germanic and Romance fami-lies: NN and T.We estimate L1-related traces in the two va-rieties of constrained language by the fitness ofa translationese-based language model (LM) toutterances of non-native speakers from the samelanguage family.
Attempting to trace structuraland grammatical, rather than content similarities,we compile five-gram POS language models fromGermanic and Romance translationese (GerT andRomT, respectively).9We examine the predic-9For building LMs we used the closed vocabulary of Penn1876tion power of these models on non-native produc-tions of speakers with Germanic and Romance na-tive languages (GerNN and RomNN), hypothesiz-ing that an LM compiled from Germanic transla-tionese will better predict non-native productionsof a Germanic speaker and vice versa.
The fitnessof a language model to a set of sentences is esti-mated in terms of perplexity (Jelinek et al, 1977).For building and estimating language modelswe used the KenLM toolkit (Heafield, 2011), em-ploying modified Kneser-Ney smoothing withoutpruning.
Compilation of language-family-specificmodels was done using 7M tokens of Germanicand Romance translationese each; the test dataconsisted of 5350 sentences of Germanic and Ro-mance non-native productions.
Consequently, forperplexity experiments with individual languageswe utilized 500 sentences from each language.
Weexcluded OOVs from all perplexity computations.Table 4 reports the results.
Prediction of GerNNby the GerT language model yields a slightlylower perplexity (i.e., a better prediction) than pre-diction by RomT.
Similarly, RomNN is much bet-ter predicted by RomT than by GerT.
These differ-ences are statistically significant: we divided theNN texts into 50 chunks of 100 sentences each,and computed perplexity values by the two LMsfor each chunk.
Significance was then computedby a two-tailed paired t-test, yielding p-values of0.015 for GerNN and 6e-22 for RomNN.LM / NN GerNN LM / NN RomNNGerT 8.77 GerT 8.64RomT 8.79 RomT 8.43Table 4: Perplexity: fitness of Germanic and Ro-mance translationese LMs to Germanic and Ro-mance NN test sets.As a further corroboration of the above re-sult, we computed the perplexity of the GerT andRomT language models with respect to the lan-guage of NN speakers, this time distinguishingspeakers by their country of origin.
We used thesame language models and non-native test chunksof 500 sentences each.
Inspired by the outcomeof the previous experiment, we expect that NNproductions by Germanic speakers will be betterpredicted by GerT LM, and vice versa.
Figure 3presents a scatter plot with the results.A clear pattern, evident from the plot, revealsTreebank POS tag set.AustriaNetherlandsSwedenGermanyFranceItalyRomaniaSpainPortugalPerplexity by GerTPerplexitybyRomTFigure 3: Perplexity of the GerT and RomT lan-guage models with respect to non-native utter-ances of speakers from various countries.that all English texts with underlying Romance na-tive languages (under the diagonal) are better pre-dicted (i.e., obtain lower perplexity) by the RomTLM.
All Germanic native languages (except Ger-man), on the other hand, are better predicted bythe GerT LM.
This finding further supports the hy-pothesis that non-native productions and transla-tionese tend to exhibit similar L1-related traits.7 ConclusionWe presented a unified computational approachfor studying constrained language, where manyof the features were theoretically motivated.
Wedemonstrated that while translations and non-native productions are two distinct language vari-eties, they share similarities that stem from lowerlexical richness, more careful choice of idiomaticexpressions and pronouns, and (presumably) sub-conscious excessive usage of explicitation cohe-sive devices.
More dramatically, the languagemodeling experiments reveal salient ties betweenthe native language of non-native speakers andthe source language of translationese, highlightingthe unified L1-related traces of L1 in both scenar-ios.
Our findings are intriguing: native speakersand translators, in contrast to non-native speakers,use their native language, yet translation seems togravitate towards non-native language use.The main contribution of this work is empirical,establishing the connection between these types oflanguage production.
While we believe that thesecommon tendencies are not incidental, more re-search is needed in order to establish a theoretical1877explanation for the empirical findings, presumably(at least partially) on the basis of the cognitive loadresulting from the simultaneous presence of twolinguistic systems.
We are interested in expandingthe preliminary results of this work: we intend toreplicate the experiments with more languages andmore domains, investigate additional varieties ofconstrained language and employ more complexlexical, syntactic and discourse features.
We alsoplan to investigate how the results vary when lim-ited to specific L1s.AcknowledgmentsThis research was supported by the Israeli Min-istry of Science and Technology.
We are im-mensely grateful to Yuval Nov for much adviceand helpful suggestions.
We are also indebted toRoy Bar-Haim, Anca Bucur, Liviu P. Dinu, andYosi Mass for their support and guidance duringthe early stages of this work, and we thank ouranonymous reviewers for their valuable insights.ReferencesOmar S. Al-Shabab.
1996.
Interpretation and thelanguage of translation: creativity and conven-tions in translation.
Janus, Edinburgh.Mona Baker.
1993.
Corpus linguistics and trans-lation studies: Implications and applications.
InMona Baker, Gill Francis, and Elena Tognini-Bonelli, editors, Text and technology: in honourof John Sinclair, John Benjamins, Amsterdam,pages 233?252.Marco Baroni and Silvia Bernardini.
2006.
Anew approach to the study of Translationese:Machine-learning the difference between orig-inal and translated text.
Literary and LinguisticComputing 21(3):259?274.Viktor Becher.
2010.
Abandoning the notion of?translation-inherent?
explicitation: Against adogma of translation studies.
Across Languagesand Cultures 11(1):1?28.Shane Bergsma, Matt Post, and David Yarowsky.2012.
Stylometric analysis of scientific arti-cles.
In Proceedings of the 2012 Conferenceof the North American Chapter of the Associ-ation for Computational Linguistics: HumanLanguage Technologies.
Association for Com-putational Linguistics, pages 327?337.Yevgeni Berzak, Roi Reichart, and Boris Katz.2015.
Contrastive analysis with predictivepower: Typology driven estimation of grammat-ical error distributions in ESL.
In Proceedingsof the 19th Conference on Computational Natu-ral Language Learning.
pages 94?102.David Birdsong.
1992.
Ultimate attainment in sec-ond language acquisition.
Language 68(4):706?755.Daniel Blanchard, Joel Tetreault, Derrick Hig-gins, Aoife Cahill, and Martin Chodorow.
2013.TOEFL11: A corpus of non-native english.
ETSResearch Report Series 2013(2):i?15.Shoshana Blum-Kulka.
1986.
Shifts of cohe-sion and coherence in translation.
In Ju-liane House and Shoshana Blum-Kulka, editors,Interlingual and intercultural communicationDiscourse and cognition in translation and sec-ond language acquisition studies, Gunter NarrVerlag, volume 35, pages 17?35.Martin Chodorow, Michael Gamon, and JoelTetreault.
2010.
The utility of article and prepo-sition error correction systems for English lan-guage learners: Feedback and assessment.
Lan-guage Testing 27(3):419?436.Rene Coppieters.
1987.
Competence differencesbetween native and near-native speakers.
Lan-guage 63(3):544?573.Heidi C. Dulay and Marina K. Burt.
1974.
Naturalsequences in child second language acquisition.Language learning 24(1):37?53.Rod Ellis.
1985.
Understanding Second LanguageAcquisition.
Oxford Applied Linguistics.
Ox-ford University Press.Britt Erman, Annika Denke, Lars Fant, and FannyForsberg Lundell.
2014.
Nativelike expressionin the speech of long-residency L2 users: Astudy of multiword structures in L2 English,French and Spanish.
International Journal ofApplied Linguistics .Dominique Estival, Tanja Gaustad, Son BaoPham, Will Radford, and Ben Hutchinson.2007.
Author profiling for English emails.
InProceedings of the 10th Conference of the Pa-cific Association for Computational Linguistics.pages 263?272.Federico Gaspari and Silvia Bernardini.
2008.Comparing non-native and translated language:Monolingual comparable corpora with a twist.In Proceedings of The International Symposium1878on Using Corpora in Contrastive and Transla-tion Studies.Jeroen Geertzen, Theodora Alexopoulou, andAnna Korhonen.
2013.
Automatic linguistic an-notation of large scale L2 databases: The EF-Cambridge open language database (EFCAM-DAT).
In Proceedings of the 31st Second Lan-guage Research Forum.
Cascadilla ProceedingsProject, Somerville, MA.Martin Gellerstam.
1986.
Translationese inSwedish novels translated from English.
In LarsWollin and Hans Lindquist, editors, TranslationStudies in Scandinavia, CWK Gleerup, Lund,pages 88?95.Howard Giles and Jane L. Byrne.
1982.
An inter-group approach to second language acquisition.Journal of Multilingual and Multicultural De-velopment 3(1):17?40.Sylviane Granger.
2003.
The international cor-pus of learner English: a new resource for for-eign language learning and teaching and secondlanguage acquisition research.
Tesol Quarterlypages 538?546.Jack Grieve.
2007.
Quantitative authorship attri-bution: An evaluation of techniques.
Literaryand Linguistic Computing 22(3):251?270.Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-hard Pfahringer, Peter Reutemann, and Ian H.Witten.
2009.
The WEKA data mining soft-ware: an update.
SIGKDD Explorations11(1):10?18.Sandra Halverson.
2003.
The cognitive basis oftranslation universals.
Target 15(2):197?241.Kenneth Heafield.
2011.
KenLM: Faster andsmaller language model queries.
In Proceed-ings of the Sixth Workshop on Statistical Ma-chine Translation.
Association for Computa-tional Linguistics, pages 187?197.Eli Hinkel.
2001.
Matters of cohesion in L2academic texts.
Applied Language Learning12(2):111?132.Juliane House.
2008.
Beyond intervention: Uni-versals in translation?
trans-kom 1(1):6?19.Iustina Ilisei and Diana Inkpen.
2011.
Transla-tionese traits in Romanian newspapers: A ma-chine learning approach.
International Journalof Computational Linguistics and Applications2(1-2).Scott Jarvis and Aneta Pavlenko.
2008.
Crosslin-guistic influence in language and cognition.Routledge.Frederick Jelinek, Robert L. Mercer, Lalit R. Bahl,and J. K. Baker.
1977.
Perplexity?a measure ofthe difficulty of speech recognition tasks.
Jour-nal of the Acoustical Society of America 62:S63.Supplement 1.Jacqueline S. Johnson and Elissa L. Newport.1991.
Critical period effects on universal prop-erties of language: The status of subjacency inthe acquisition of a second language.
Cognition39(3):215?258.S.S.
Keerthi, S.K.
Shevade, C. Bhattacharyya, andK.R.K.
Murthy.
2001.
Improvements to platt?ssmo algorithm for svm classifier design.
NeuralComputation 13(3):637?649.Eric Kellerman and Michael Sharwood-Smith.1986.
Crosslinguistic Influence in SecondLanguage Acquisition.
Language TeachingMethodology Series.
Pearson College Division.Dorothy Kenny.
2001.
Lexis and creativity intranslation: a corpus-based study.
St. Jerome.Philipp Koehn.
2005.
Europarl: A parallel corpusfor statistical machine translation.
MT Summit.Moshe Koppel and Noam Ordan.
2011.
Trans-lationese and its dialects.
In Proceedings ofthe 49th Annual Meeting of the Associationfor Computational Linguistics: Human Lan-guage Technologies.
Association for Compu-tational Linguistics, Portland, Oregon, USA,pages 1318?1326.Moshe Koppel, Jonathan Schler, and Kfir Zigdon.2005.
Determining an author?s native languageby mining a text for errors.
In Proceedings ofthe eleventh ACM SIGKDD international con-ference on Knowledge discovery in data mining.ACM, pages 624?628.David Kurokawa, Cyril Goutte, and Pierre Is-abelle.
2009.
Automatic detection of translatedtext and its impact on machine translation.
InProceedings of MT-Summit XII.
pages 81?88.Donna Lardiere.
2006.
Ultimate Attainment inSecond Language Acquisition: A Case Study.L.
Erlbaum.Gennadi Lembersky, Noam Ordan, and ShulyWintner.
2012.
Language models for machinetranslation: Original vs. translated texts.
Com-putational Linguistics 38(4):799?825.1879Gennadi Lembersky, Noam Ordan, and ShulyWintner.
2013.
Improving statistical ma-chine translation by adapting translation mod-els to translationese.
Computational Linguistics39(4):999?1023.Christopher D. Manning, Mihai Surdeanu, JohnBauer, Jenny Finkel, Steven J. Bethard, andDavid McClosky.
2014.
The Stanford CoreNLPnatural language processing toolkit.
In Proceed-ings of 52nd Annual Meeting of the Associationfor Computational Linguistics: System Demon-strations.
Association for Computational Lin-guistics, Baltimore, Maryland, pages 55?60.A.
Mauranen and P. Kujam?aki, editors.
2004.Translation universals: Do they exist?.
JohnBenjamins.Frederick Mosteller and David L Wallace.
1963.Inference in an authorship problem: A compar-ative study of discrimination methods applied tothe authorship of the disputed Federalist Papers.Journal of the American Statistical Association58(302):275?309.Sergiu Nisioi.
2015a.
Feature analysis for nativelanguage identification.
In Alexander F. Gel-bukh, editor, Proceedings of the 16th Interna-tional Conference on Computational Linguis-tics and Intelligent Text Processing (CICLing2015).
Springer, Lecture Notes in ComputerScience.Sergiu Nisioi.
2015b.
Unsupervised classificationof translated texts.
In Chris Biemann, SiegfriedHandschuh, Andr?e Freitas, Farid Meziane, andElisabeth M?etais, editors, Natural LanguageProcessing and Information Systems: Proceed-ings of the 20th International Conference onApplications of Natural Language to Informa-tion Systems, NLDB.
Springer, volume 9103 ofLecture Notes in Computer Science, pages 323?334.Sergiu Nisioi, Ella Rabinovich, Liviu P. Dinu,and Shuly Wintner.
2016.
A corpus of native,non-native and translated texts.
In Proceedingsof the Tenth International Conference on Lan-guage Resources and Evaluation, LREC 2016.Terence Odlin.
1989.
Language Transfer: Cross-Linguistic Influence in Language Learning.Cambridge Applied Linguistics.
CambridgeUniversity Press.Maeve Olohan.
2002.
Leave it out!
using a com-parable corpus to investigate aspects of explic-itation in translation.
Cadernos de Traduc?
?ao1(9):153?169.Maeve Olohan.
2003.
How frequent are the con-tractions?
A study of contracted forms in thetranslational English corpus.
Target 15(1):59?89.Lin ?ver?as.
1998.
In search of the third code:An investigation of norms in literary translation.Meta 43(4):557?570.Martin Potthast, Alberto Barr?on-Cede?no, BennoStein, and Paolo Rosso.
2011.
Cross-languageplagiarism detection.
Language Resources andEvaluation 45(1):45?62.Ella Rabinovich and Shuly Wintner.
2015.
Unsu-pervised identification of translationese.
Trans-actions of the Association for ComputationalLinguistics 3:419?432.Philip Resnik and Noah A. Smith.
2003.
The webas a parallel corpus.
Computational Linguistics29(3):349?380.Larry Selinker.
1972.
Interlanguage.
Interna-tional Review of Applied Linguistics in Lan-guage Teaching 10(1?4):209?232.Miriam Shlesinger.
1989.
Simultaneous Interpre-tation as a Factor in Effecting Shifts in the Po-sition of Texts on the Oral-literate Continuum.Master?s thesis, Tel Aviv University, Facultyof the Humanities, Department of Poetics andComparative Literature.Miriam Shlesinger.
2003.
Effects of presentationrate on working memory in simultaneous inter-preting.
The Interpreters Newsletter 12:37?49.Bernard Smith and Michael Swan.
2001.
LearnerEnglish: A teacher?s guide to interference andother problems.
Ernst Klett Sprachen.Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language iden-tification shared task.
In Proceedings of theEighth Workshop on Building Educational Ap-plications Using NLP.
Association for Compu-tational Linguistics.Laura Mayfield Tomokiyo and Rosie Jones.
2001.You?re not from?round here, are you?
: naiveBayes detection of non-native utterance text.
InProceedings of the second meeting of the NorthAmerican Chapter of the Association for Com-putational Linguistics on Language technolo-gies.
Association for Computational Linguis-tics, pages 1?8.1880Gideon Toury.
1979.
Interlanguage and its mani-festations in translation.
Meta 24(2):223?231.Gideon Toury.
1980.
In Search of a Theory ofTranslation.
The Porter Institute for Poetics andSemiotics, Tel Aviv University, Tel Aviv.Gideon Toury.
1995.
Descriptive TranslationStudies and beyond.
John Benjamins, Amster-dam / Philadelphia.Yulia Tsvetkov, Naama Twitto, Nathan Schnei-der, Noam Ordan, Manaal Faruqui, VictorChahuneau, Shuly Wintner, and Chris Dyer.2013.
Identifying the L1 of non-native writers:the CMU-Haifa system.
In Proceedings of theEighth Workshop on Innovative Use of NLP forBuilding Educational Applications.
Associationfor Computational Linguistics, pages 279?287.Hans van Halteren.
2008.
Source language mark-ers in EUROPARL translations.
In Donia Scottand Hans Uszkoreit, editors, COLING 2008,22nd International Conference on Computa-tional Linguistics, Proceedings of the Confer-ence, 18-22 August 2008, Manchester, UK.pages 937?944.Ria Vanderauwera.
1985.
Dutch Novels Translatedinto English: The transformation of a ?minor-ity?
literature.
Rodopi.Vered Volansky, Noam Ordan, and Shuly Wintner.2015.
On the features of translationese.
DigitalScholarship in the Humanities 30(1):98?118.Appendix A - Distribution of L1s inTranslations and Non-native TextsWe assume that native languages of non-nativespeakers are highly correlated with (although notstrictly identical to) their country of origin.country of origin tokens(T) tokens(NN)Austria - 2KBelgium - 67KBulgaria 25K 6KCyprus - 35KCzech Republic 21K 3KDenmark 444K 14KEstonia 32K 50KFinland 500K 81KFrance 3,486K 28KGermany 3,768K 17KGreece 944K 13KHungary 167K 38KItaly 1,690K 15KLatvia 38K 13KLithuania 177K 18KLuxembourg - 46KMalta 28K 40KNetherlands 1,746K 64KPoland 522K 36KPortugal 1,633K 54KRomania 244K 29KSlovakia 88K 6KSlovenia 43K 1KSpain 1,836K 54KSweden 951K 52KTable 5: Distribution of L1s by country.1881
