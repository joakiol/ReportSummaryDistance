Preference Semantics, III-Formedness, and MetaphorDan Fass and Yorick Wi lksCognitive Studies CentreUniversity of EssexWivenhoe ParkWivenhoe Park, ColchesterEssex C04 3SQ EnglandThis paper is about the relationships between Preference Semantics (PS) and ill-formedness, and between Preference Semantics and metaphor.
Two types of"preference", declarative and procedural, are distinguished.
The PS framework is exam-ined with respect to notions of well- and ill-formedness, and two criteria for i l l-formednessare distinguished, both of which are possessed by PS: an absolute criterion that correspondsto conventional notions of well- and il l-formedness, and a relative criterion that does not.Four possible strategies are described for representing ill-formed input in general, andmetaphors in particular.
The strategies and the semantic representations produced by themare compared regarding their correspondence to human understanding (admittedly superfi-cial given the shallowness of the PS representation) and their ability to produce correctsentence translations.
We conclude that, because of the ambiguity of many individual andextended metaphors, two broad types of metaphor representation strategy are needed.
Acontrol mechanism is described that uses both these major types of strategy and thatpermits the temporary semantic representation of metaphorical ambiguity.0.
IntroductionWe use the term "Preference Semantics" (PS) to indi-cate not programs that have parsed English into asemantic representation, or the details of that seman-tic representation (all of which could have been differ-ent), but rather the underlying principles.
The mainprinciples or claims are as follows (and underlie thesequence of papers Wilks 1968, 1973, 1975, 1978).The last two will be of most concern to us here:a) It is possible to pass from English to a semanticrepresentation without a module devoted explicit-ly to syntactic analysis, and without traditionalsyntactic classification of words or sentence com-ponents (for example, N, NP, VP).
The necessarygeneralisations for parsing can all be expressed inthe terms needed for the semantic representation.Moreover, these need not result in any kind oftext "skimming" that misses essential features ofthe text and its content.b) The representation need not be of the model the-oretic type, and the classic problems of quantifi-cation, etc., can be dealt with by special proce-dures.c) The description of the representat ion and theprocedures that generate it should all be proce-dural and, most important,  the representat ionshould be the product of a few, general, and au-tonomous (not content-dependent)  procedures.Moreover,  the procedures should be consistentwith a Least Effort principle of language under-standing (Wilks 1975).d) The representation is based on a set of semanticprimitives, of differing types (actions, substan-tives, qualities, etc.
), but no claims are made thatthe set is universal: there could be many alterna-tive sets for special tasks, domains, or cultures.All that is required is there be some privileged setto generate a representation.e) The representat ion emphasises the linear, ratherthan the recursive, propert ies of language: itsstructure therefore emphasizes linear boundariesof clauses and phrases (but with no special rolefor sentences) as a basis for a surface representa-tion from which progressively deeper representa-tions can be obtained by inference.
The repre-Copyright 1984 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or  specific permission.0362-613X/83/030178-10503.00178 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983Dan Fass and Yorick Wilks Preference Semantics, III-Formedness, and Metaphorsentational item corresponding to the piece oflanguage between two such boundaries (whether aword or a sentence) we call a template, which is acomplex structure (see below) having no associa-tions with the term as used to denote a string ofsurface items, as in vision analysis.f) The representation is formed upon a principle ofpreference for the "best  fit": thus, there is nosingle correct representation (except in specialcircumstances) for a text string, but the best,most internally coherent representation, chosenfrom among competing representations.
Represen-tational structures can be seen as "preferr ing"other associated representations, and an overallrepresentation for a text is produced by allowingmaximal satisfaction of such preferences, whichwill mean (as in the political analogy on whichthe notion is based) that some constituent repre-sentations do not have their local preferences at-isfied.g) The last representational principle has a correlateat the level of text relationships: i l l -formedness(and, we shall claim below, metaphor)  is not abinary, yes-no, matter but a function of repre-sentational satisfaction, which includes being afunction of the state of the dictionary for thewords and higher level items constituting the text.To put it crudely, i l l -formedness is a matter ofwhat the analysis system believes the dictionaryand state of the world to be, and how far it canbe extended by rule with the aid of the knowledgestructures available.
To use an example fromWilks (1978)(1) The car drank gasolinewill be ill-formed or not, depending on what youbelieve about drinking and about cars (thus cross-ing what would be, for many, a semantic-pragmatic boundary), and similarly for(2) John ran a miledepending on beliefs about running and distance(and so similarly for the so-called syntax-semantics distinction and the class of "intransitiveverbs").It is part of principle (a) above that preference is asyntactic notion as well as a semantic notion in thatone general rule can deal with both sorts of conven-tionally distinguished phenomena.
Thus (2) is ill-formed just because \[run\] prefers no object, just as\[believe\] prefers a propositional object (a full templatein the terms set out below) but will accept a humanobject nevertheless.
However, in this short paper wearbitrarily restrict ourselves to phenomena that wouldconventionally be considered matters of word-sensesemantics.On this view, much of what has often been thoughtof as i l l-formed - particularly violations of Katzianselection restrictions (Katz and Postal 1964) - is notonly not il l-formed but is typical of normal usage, andmust not be rejected if it can be accommodated by theprocedures of PS.
The emphasis here is rather differ-ent from the standard one: on the PS view, the viola-tion of preferences (such as those of drink for an ani-mate agent or a liquid object) is the norm, and mustnot be treated as an exceptional matter, outside thecore of English.
Such locutions are statistically sonormal and understood even when wholly novel, thattheir representation and processing must he performedas part of the central processes of a language under-stander.Some of the above points can be found incorporat-ed in other language understanding systems, for exam-ple Schank and his associates (Schank 1975) for (a) -except for their predilection for NPs - (b), (d) - ex-cept for their insistence on a universal set of primitives- and more recently (e).
For (b) almost any classicalexample semantic net system (Simmons 1973, Hendrix1975).
What we shall do here is develop the last twoprinciples towards a general theory of the understand-ing of il l-formed and metaphorical language.The concrete setting of our current research is theconstruction of a semantics/knowledge-based pellingcorrector, but we shall not emphasise that here.1.
A Br ie f  Resume of  the  P re ference  Semant icsSys temThe following terminology will be useful: a semanticformula is a representation of a word-sense; it con-tains a head, which represents the "main element" inthe sense - for example, whether a noun refers to aMAN or a THING, or whether a verb denotes an act ofTHINKing, or of DOing.
Its internal structure is ofleft-right dependency.The following is a simplified semantic formula forthe action drink:(3) ((*ANI SUBJ) (((FLOW STUFF) OBJE)(MOVE CAUSE)))Reading the formula for drink, it is an action, prefer-ably done by animate things (*ANI SUBJ) to liquids((FLOW STUFF) OBJE).
The SUBJ case displays thepreferred agents of actions, and the OBJE case thepreferred objects, or patients.A template is a structure, based on slots for threesemantic formulas that can themselves have dependentformulas, such that the whole structure represents apossible "message".
A template can have any numberof formulas (from one to any).
Each fragment of asentence (clause or phrase) has templates matchedonto it during parsing and the existence of more thanone template per fragment is representational mbigui-ty, to be reduced by examining the internal " f i t"  ofAmerican Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 179Dan Fass and Yorick Wi lks Preference Semantics, III-Formedness, and Metaphortemplates, and the external relations between tem-plates for successive fragments of text.The formulas in each template are determined tosee if their preferences are satisfied.
In what follows,\[square brackets\] denote the formula for a word.
So,for example, \[crook (man)\] denotes the formula forthe human sense of the word crook.The sentence(4) The policeman interrogated the crookwill produce two candidate interpretations, which aretemplates of formulas, written left to right, filling itsaction-agent-object slots\[policeman\] \[interrogated\] \[crook (man)\]\[policeman\] \[interrogated\] \[crook (thing)\].So, we have two possible template representations(that is, two possible readings) for the sentence.The template expansion algorithm seeks to resolvethis: it looks into subparts of the formulas to see ifany preferences are satisfied.
\[interrogate\] prefers ahuman actor; this is marked in both representations.It also prefers a human object: \[crook (man)\] cansatisfy this preference, but \[crook (thing)\] cannot.So we have (in the following, -~ or *- representssatisfied preferences)(4a) \[policeman\] -- \[interrogates\] *- \[crook (man)\](4b) \[policeman\] -~ \[interrogates\] [crook (thing)\]The first of these has the larger number of satisfiedpreferences, or greater "semantic density", so it ispreferred.
The template representation chosen here,the one with the highest semantic density, has fullpreferential links between every pair of formulas.In the case of a sentence like (1) that contains afailed preference (whether or not it is metaphor, forexample The VDU interrogated the crook), the firstreading is accepted because there are no other compet-ing readings.2.
Three Types of Dictionary InformationThe semantic information in dictionary entries(formulas) can be categorised into three types, whichwill be exemplified in the semantic formula for drink(3).
(i) Inherent information: "data"The semantic properties that a dictionary en-try contains specifically about the item itself.In a semantic formula, the main example ofthis is its head primitive(s), for example(MOVE CAUSE).
(ii) Label information: "labels"Case information describing the case rela-tionships between a dictionary entry and oth-er dictionary entries.
Label information ex-ists in the case subparts of semantic formulasas case primitives like SUBJ (to be interpret-ed as AGENT) in (*ANI SUBJ), and OBJE in((FLOW STUFF) OBJE).
(iii) Contextual information: "expectations"The inherent semantic information that a dic-tionary entry expects other dictionary entriesto possess as inherent information.
Like la-bel information, contextual information existsin the case subparts of semantic formulas assemantic primitives or subformulas like *ANIand (FLOW STUFF).When disambiguating word-senses, all three typesof information are used.
In section 1 above, we sawhow the template expansion algorithm resolved (4):\[interrogate\] prefers a human object, where "object"is label information, and "human" is contextual infor-mation.
\[crook (man)\] satisfies this preference be-cause its head primitive - inherent information - ishuman.We wish to distinguish dictionary entries that con-tain semantic ontextual information and those that donot:?
predicatesContextual information occurs in the semanticformulas for verbs, adjectives, nominalisedverbs, and idioms (Wilks 1975, Boguraev 1979).Dictionary entries for prepositions, called para-plates (Wilks 1975) or preplates (Boguraev1979), larger structures that tie templates to-gether and have the function of inference rules,also contain contextual information becausethey specify the semantic class of head noun orverb being modified and the head noun of modi-fying prepositional phrase, but they are outsidethe scope of discussion here.?
non-predicatesSimple nouns like table, car, and chopper, whichdo not contain contextual information in theirsemantic formulas at the top level (that is, \[car\]might contain coding that humans use cars toachieve a goal, but that would not appear at thetop level of the "goals of cars").By "predicate"  we mean specifically dictionaryentries containing semantic contextual information atthe top level, and not the more general use of theterm.3.
Two Types of "Preference"This section examines the notion of preference andmakes an important distinction between a declarativeand a procedural version of preference (Fass 1983).3.1.
Preference-as-restrictionA preference is (dictionary) information in a semanticformula expressing some kind of restriction on thesemantic context in which a word-sense can occur.180 American Journal of Computat ional  Linguistics, Volume 9, Numbers 3-4, Ju ly-December 1983Dan Fass and Yorick Wilks Preference Semantics, III-Formedness, and MetaphorTwo observations:Preferences-as-restr ict ions are binary.A preference is either satisfied or violated: itcannot be partially satisfied.
This is because ofthe organisation and generality of PS semanticprimitives, which are hierarchically organisedbut only at two levels of generality.
For exam-ple, the "class element" primitive *ANI includesthe class of primitives (BEAST, MAN, FOLK,SIGN, or THIS), that is, any animate entity.There can be no partially satisfied preferenceswith the present set of primitives, as would bethe case if BEAST could satisfy a preference forMAN because both are in the class *ANI.A preference is a piece o f  contextual  information.Although a preference coding occurs within acase subpart of a formula, the correspondinglabel information is not part of that preference.As preferences-as-restr ict ions are contextual, it isonly predicates that have them in PS.
But ifpreferences-as-restrictions referred instead to inherentinformation, then non-predicates would also have pref-erences.
Consider the helicopter meaning of the wordchopper, whose formula has the head primitive THING(that is, physical object).
If a preference describedinherent information, then we could view choppers aspreferr ing to be THINGs but not having to be THINGs.We shall consider just this in section 6.3.2.
P re ference-as -procedurePreference is viewed as a procedure for assigningscores to competing alternative representat ions andchoosing the best one.
In PS, preference-as-procedureuses as its criterion for choosing between competingsentence readings the number of preferences-as-restrictions that are satisfied.The four key elements of preference-as-procedureare:?
product ion - it produces all sentence readingswhether or not they contain preference viola-tions;?
scoring - readings are scored according to howmany preference satisfactions they contain;?
comparison - whether or not an individual read-ing is accepted depends on a comparison withother readings;?
selection - the best reading (that is, the one withthe most preference satisfactions) is taken, evenif it contains preference violations.By choosing the best available, preference-as-procedure as a single procedure has two ef fects  when itoperates: it disambiguates word-senses and at the sametime provides system robustness (that is, a sentencereading is always returned).It should be emphasised that preference-as-procedure is a general strategy, used to provide disam-biguation and robustness at many different levels inthe PS system, not just with preferences-as-restrictions.
The two types of preference are separa-ble from each other: preferences-as-restrictions can beused by other procedures, and preference-as-procedurecan be used with other types of dictionary informa-tion.4.
The Pre ference  Semant ics  Sys tem and I l l -Formed Input4.1.
P re ference  Semant ics  and i l l - formednessWe can best understand a Preference Semantics ap-proach to i l l -formedness by comparing it with Katzand Postal 's (1964) semantic markers/select ion re-striction approach.
Katz and Postal's approach em-bodies a binary principle of semantic well-formednesssimilar to that assumed in standard generative syntax:well-formed and ill-formed.A selection restriction is binary - a semantic mark-er either fits a selection restriction or it does not.Preferences-as-restrictions, as they appear in semanticformulas, are also binary (and equivalent o selectionrestrictions): a semantic class either satisfies a prefer-ence or it does not.
With the binary principle, there isan absolute criterion for i l l -formedness: a semanticrelation can be labelled il l-formed by examining thatrelation alone, without looking at any others.At the level of the constituent or sentence,preference-as-procedure is different from a selectionrestrictions approach.
This should be clear if we ex-amine a selection restrictions approach using the samefour elements we used for preference-as-procedure:?
product ion - only those sentence readings withall their selection restrictions fulfilled are pro-duced;?
scor ing -  there are only two scores - (i) "well-formed":  all selection restrictions fulfilled, or(ii) " i l l - formed":  one or more restrictions areviolated;?
compar ison - none.
Readings are conSideredindividually, without comparison against otherreadings;?
selection - the sentence reading with all selectionrestrictions fulfilled is taken, if such exists.The preference approach adopts a different, unaryprinciple of " formedness".
If a preference in a sen-tence is violated, then a reading is sti l l  produced forthat sentence, so being " formed"  is like being well-formed in the selection restrictions ense.But whether that (preference violating) reading isaccepted as if it was well-formed, or rejected as if itwas il l-formed, depends on whether there are otherpossible readings for that sentence and on the natureof these readings:?
The reading is accepted if either there are noother readings for the sentence or if all the oth-er readings for the sentence have more prefer-American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 181Dan Fass and Yorick Wi lks Preference Semantics, III-Formedness, and Metaphorence violations.
In such situations, the PS sys-tem assumes that the writer meant to producethe reading, that is, that it is some novel use oflanguage (for example, metaphor) and is well-formed.?
The reading is rejected if there is another eadingfor the sentence that has fewer preference viola-tions.
However, being rejected in this way isprobably not tantamount o being i l l -formedbecause, in some other circumstances, entencescontaining a preference violation (like the re-jected reading) could be accepted as the bestavailable.If all the preferences are fulfilled in a reading of aconstituent, then, although the const i tuent /sentencemay be "wel l - formed" in the selection restrictionssense, that reading may not necessarily be accepted.This is because there may be another reading of thesame sentence that also has all of its preferences satis-fied and is equally acceptable.So, the difference between PS and Katz andPostal's approach is at the procedural level.
With theunary principle of PS, the criterion for i l l-formednessis relative: a reading can only be labelled " i l l - formed"after comparing it with other readings, and not by ex-amining that reading alone, which is why preference-as-procedure produces all readings, whether or notthey contain preference violations.So, we have distinguished two criteria for ill-formedness: absolute and relative.
Within PS, thecriterion of absolute i l l -formedness is used for thesemantic relations between individual word-senses(3.1.
), and relative il l-formedness for readings of con-stituents of sentences (3.2.).4.2.
The nature of preference violationsPreference violations between two words can becaused either by some " tota l "  mismatch of word-senses, as between \[interrogates\] and \[crook (thing)\]in (4b); or by some metaphorical relation, as there isbetween \[car\] and \[drink\] in (1) The car drankgasoline.
Examining the preference violation itselfdoes not reveal its nature; we can only discover thetype of preference violation by examining competingreadings (if any), which is what preference-as-procedure does.
If all the other readings have morepreference violations, then the reading containing thesingle preference violation is assumed to be appropri-ate and a metaphor.However,  we can produce sentences containing ametaphor in which examining the alternative sentencereadings cannot help establish what type of preferenceviolation we have.
Consider the sentence(5) That chopper drinks gasolinewhich contains a metaphor (Van Eynde 1982).There are two readings of the sentence, based onthe ambiguity of chopper as either "ax"  or"helicopter".
The two template representations are:(Sa) \[chopper (helicopter)\] \[drinks\] --- \[gasoline\](5a) \[chopper (ax)\] \[drinks\] --- \[gasoline\]Both \[chopper (helicopter)\] and \[chopper (ax)\] havethe semantic head THING (physical object), and bothviolate the preference of \[drink\] for an ANIMATEagent.
In this example, the PS system cannot discrimi-nate between the two sentence readings - one contain-ing mismatched word-senses (5b), the other containinga metaphor (5a) - in terms of their number of satis-fied preferences.
So it is unable to decide which read-ing is metaphorical (and appropriate).Because a preference violation locates failed se-mantic relations, we can try to determine whether ornot that violation is caused by a metaphor by applyingadditional semantic information there.
In the nextsection we consider the sort of semantic informationnecessary to resolve (5) and one suggested way ofrepresenting that information.5.
Semantic Information about MetaphorVan Eynde (1982) has pointed out that the standardPS system cannot choose the correct reading fromtemplates (5a) and (5b) above.
He suggested a set ofrules, polysemy rules, that can recognise one of theviolations as being caused by a metaphor and choosethe correct reading.Polysemy rules are applicable to metaphors involv-ing a predicate and a non-predicate; they can be usednot only to choose between readings like (5a) and(5b) but also to confirm that a single reading producedfor a sentence like (1) is a metaphorical one.
Meta-phors between two non-predicates, for example "Thisencyclopaedia is a gold-mine (Rumelhart 1979), areexcluded from consideration in this paper.It is very important o divorce two issues concern-ing PS and metaphor:  first, ways of recognising andchoosing a reading containing a metaphor,  that is,polysemy rules, described in section 5.1. below; sec-ond, possible strategies for representing that metaphor-ical reading, described in section 6.
Polysemy rulescan be combined with a number of those strategies.5.1.
Polysemy rulesWhat is essential first of all is to provide additionalsemantic information to distinguish the vehicle sensefrom the ax sense of chopper.
Van Eynde introduces anew primitive VEHICLE, which he uses as head primi-tive of the vehicle sense of chopper.A polysemy rule looks like this:(6) condition: certain environmental data, such as:A is the AGENT slot of a templateand B is an action in the ACTION182 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, Ju ly-December 1983Dan Fass and Yorick Wilks Preference Semantics, III-Formedness, and Metaphorslot of the same template.
Subjectpreference of B --- ANIMATE.
Headprimitive of A = VEHICLE.assignment: Head primitive of A := ANIMATE.The format of the above we take to be self-evident.The rule would normally be understood to run its as-signment whenever the condition is satisfied.
On ahistorical note one can compare polysemy rules withthe very general dictionary extension rules of Givon(1967).The effect of this particular ule is to change data,that is to alter the head primitive of the helicoptersense of chopper.
Note that, with rules of this type,the assignment can either?
change the data by modifying the inherent semanticinformation in the non-predicate (thus making itanimate), so that the unchanged semantic formulafor drink (preferring an animate agent) will stillpick out this reading; or,?
alternatively, one could change the expectations,modifying the semantic formula for drink (thepredicate), so that it accepts vehicular agents assecond best to genuinely animate ones; or,?
one could modify \[drink\] more radically, by  chang-ing its inherent data (see below); or,?
we could just leave both formulas unchanged.We will consider these four alternatives in section 6.5.2.
DiscussionThe first point to note is that polysemy rules alone donot provide a means of recognising the initial conflictbetween chopper and drinks, and does not provide ameans of selecting the sentence reading containing thecorrect sense of chopper.
Thus, polysemy rules cannotoperate on their own but only within some more gen-eral word-sense disambiguation mechanism such as PS,in some such way as the following: for sentence (5),only after the template expansion algorithm of PS hasproduced the two readings (5a) and (5b) can polysemyrules be applied to the non-predicate involved in thepreference violation, and the template expansion al-gorithm tried again.
One of the readings for the sen-tence will now have no preference violations(5c) \[chopper (helicopter)\] --,- \[drinks\] --- \[gasoline\]and is accepted.In the foregoing (5.1.
), we have embedded VanEynde's polysemy rule (6) within some general PSenvironment for making choices between readingsafter (6) has altered the available readings.
It wasnecessary to do this because, as we pointed out, therule alone does not specify how to select readings.Moreover, Van Eynde sees rules like (6) as operatingwithin a production system.
If that production systemwas uncontrolled, then such rules would run whenevertheir conditions were satisfied.
The control regime forthose rules is hard to imagine, and would certainly bevery complex.6.
The Representat ion  of Metaphor  and Ill-Formed InputIn this section we describe and compare four strategiesfor representing ill-formed input in general and meta-phors in particular, in semantic representations.
It isassumed that a process with the power of that de-scribed in section 5 above has located a preferenceviolation or "semantic conflict" and recognised it asbeing a metaphor.6.1.
Four s t rateg ies  for  the  representat ion  ofmetaphorWe will illustrate these strategies using sentence(1) The car drank gasolinethough we could also have considered reading (5a) ofsentence (5) as an example.
The best reading for (1)has a conflict between the expectation of the predicate\[drink\] expecting an animate agent as subject and thedata in the non-predicate because the actual subject(the car) is inanimate.
If we built a semantic repre-sentation of this sentence, then the conflict wouldremain in the representation.Obvious strategic hoices are:(i) Passive strategyRelax the preference of the predicate and acceptthe semantic representation with the conflict un-resolved (Wilks 1975); at no point are data orexpectations changed, and the analysis systemsimply accepts the representation it is given.
(ii) CTD, or Change The Data, strategyChange the inherent data in the non-predicate insuch a way that it meets the expectations (VanEynde 1982).
So, in sentence (1) alter the dataand replace the head primitive VEHICLE in \[car\]by the primitive ANIMATE in the semantic repre-sentation.
This is one top-down (expectationdriven) approach: in the case of conflict betweenwhat you have and what you expect, change whatyou have and be guided by your expectations.
(iii) CTE, or Change The Expectations, trategyChange the expectations in the predicate in sucha way that they meet the data (Van Eynde 1982).So, for sentence (1) alter its semantic representa-tion by changing the expectation that the subjectof \[drink\] must be ANIMATE to VEHICLE(iv) Active strategyA more radical approach, explored in Wilks(1978), would produce a completely new formula\[drink\] by rule and equivalent to \[consume\], mod-ifying inherent and expectational data, so as toaccept an animate agent (car).
This approachuses the wider context of frame-like representa-tions, called pseudo-texts, in addition to semanticAmerican Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 183Dan Fass and Yorick Wilks Preference Semantics, III-Formedness, and Metaphorformulas.
At its crudest the method consisted offinding particular facts (when faced with (1))about cars in its frame-like data base such thatcars did operate on gasoline in a manner semanti-cally related to drinking.
The only fact locatedwas "cars consume gasoline" and so a \[drink\] hada new representation added, namely the appropri-ate formula from the dictionary entry for\[consume\].
This is a top-down, knowledge-drivenapproach, but cannot be termed CTE or CTDsince no formula of drink is modified but a newone slotted into the templates for that particulari l l-formed locution.
We shall compare this methodwith the others above, that need less detailed andcumbersome context than frame methods and aremore narrowly semantic.6.2.
Comparison of the four strategiesThe strategies are compared in two ways.
First, thedegree to which the semantic representations contain-ing metaphors produced by the different strategiescorrespond to human understanding of those meta-phors.
Given the shallowness of a PS representation,that correspondence can be no more than superficial.Secondly, whether or not the semantic representationsof the different strategies would assist in concretecomputational tasks, such as producing correct transla-tions.Most, if not all, individual metaphors can be reador understood in two ways.
For example, the meta-phor in (1) can be understood either by viewing thepredicate drink as the car-like consuming of petrol, orby seeing the non-predicate car as having some humanproperties.
Within PS, the CTE strategy and the activestrategy reflect the first, predicate reading by alteringsemantic information in the predicate; the CTD strate-gy reflects the second, non-predicate reading bychanging inherent information in the non-predicate.No single strategy reflects both readings.
By leavingthe preference violation in the semantic representation,the passive strategy does not reflect either reading anddoes not reflect human understanding of metaphor atall.In extended metaphors (those beyond a singleclause), the initial metaphorical reading can be carriedover in either the non-predicate or the predicate.Consider the following extended metaphors that arealso cases of gapping (Hankamer 1973):(7) The car drank gasoline and (the car) purred toitself(8) The car drank gasoline and the taxi (drank)dieselIn (7), the metaphorical usage of the non-predicate caris continued; in (8), it is the predicate drink.We now examine how closely the strategies of 6.1.reflect our understanding of extended metaphors like(7) and (8).
To do this, we shall assume a simplifiedform of rules for filling dummy template nodes (Wilks1975).
Those more familiar with Chomsky (1977) canthink of this in terms of a form of trace mechanism inwhich the trace node in the template representing thesecond clause inherits information from the controllingnode in the first clause.
Hence in (7) the formula ofcar will be inherited by the empty agent node in thetemplate containing \[purr\].Let us consider (7) first.
What happens when eachstrategy encounters \[car\] and \[drink\] in the first clauseof the sentence, and then encounters \[car\] inheritedfrom the first template and \[purr\] in the secondclause?When the CTD strategy encounters \[car\] and\[drink\], it removes the preference violation betweenthem by reassigning VEHICLE as ANIMATE in thenon-predicate \[car\].
This modified formula of \[car\] isinherited from the first template; \[purr\] expects ananimate SUBJ and \[car\] is now ANIMATE, so there isno preference violation between them.The CTE strategy removes the preference violationbetween \[car\] and \[drink\] by changing the SUBJ pref-erence of the predicate \[drink\] from ANIMATE toVEHICLE.
\[car\] is unchanged and is inherited un-changed.
Because \[car\] is still marked as inanimate,there is a preference violation with purr, which causesthe CTE strategy to alter the SUBJ preference of \[purr\]to VEHICLE.The passive strategy does not change either \[car\] or\[drink\], leaving the preference violation between them.A second preference violation is left in the secondclause as well.With the active strategy, a car-frame (or pseudo-text) is used, and \[drink\] would have a new consumesense and there would be no effect on \[car\].
Hence,the frame would be accessed again for the secondclause, but would either find no new sense for purr inthe limited context of to itself (which would becomejust a passively accepted, though preference-violating,template) or it could hope to re-apply the active strat-egy and find from the car frame that the only noisecars were noted as making (other than in conditions oftrouble where they would backfire, etc.)
was hum,which could be imposed in place of \[purr\], and wouldbe confirmed by a causal inference from the beneficialeffect of \[consume gasoline\].
However, this might bedifficult to embody in a serious knowledge representa-tion since there is no non-metaphorical description-inEnglish of the noise of cars.So for (7) the active and passive strategies bothleave preference violations in the second clause.
TheCTE and CTD strategies do not, but of these two, theCTD strategy more closely reflects human understand-ing.184 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, Ju ly -December 1983Dan Fass and Yorick Wilks Preference Semantics, III-Formedness, and MetaphorNow let us examine (8), The car drank gasoline andthe taxi diesel.
When processing (8), the CTD strategychanges semantic information in the non-predicate\[car\].
\[drink\] is unchanged and is inherited unalteredby the second template.
\[taxi\] is inanimate, but\[drink\] expects an animate subject, so there is a pref-erence violation, which will cause the semantic infor-mation in \[taxi\] to be changed in its turn.The CTE strategy will change the SUBJ preferenceof the predicate \[drink\] to VEHICLE.
This modifiedversion of drink is then inherited by the second tem-plate.
As \[taxi\] is a VEHICLE, there is no preferenceviolation between \[drink\] and \[taxi\].The passive strategy changes neither set of infor-mation, which leads to preference violations in bothclauses.
The active strategy would construct a newconsume sense for \[drink\] that would be inherited bythe action node of the second template.
As \[taxi\] is aVEHICLE, there would be no preference violationbetween \[taxi\] and the new sense of drink.In (8), where the metaphorical usage continued inthe predicate, the CTE and active strategies mostclosely reflect human understanding because both havethe effect of changing the predicate's expectations of, its subject.
However, in (7), where the metaphoricalusage continued in the non-predicate, the CTD strate-gy was best because it changed the inherent data inthe non-predicate.If we take the production of correct translation as amin imum constraint on interpretation strategy, thenthe changes the four strategies make to semantic rep-resentations are important because the effect of onestrategy can be to produce a correct translation whileanother can cause a mistranslation.Consider(9) The car drinks gasoline and (the car) does notwork wellwhere the metaphor in the first clause does not extendto the gapped second clause.
Assuming a node inher-itance mechanism once again, \[car\] will be inherited inthe second clause.If the non-predicate \[car\] is inherited unaltered,then that sentence is translated correctly as La voitureboit de l'essence t ne march pas bien because marcher,the appropriate translation of work, expects an inani-mate subject.
It is because they leave \[car\] unchangedthat the passive, CTE, and active strategies all producethe correct translation of (9).However,  the CTD strategy reassigns \[car\] asANIMATE, and this modified formula of car is inherit-ed into the second template.
The effect of this is totranslate the sentence wrongly as La voiture boit del'essence t ne travail pas bien because travailler, anoth-er translation of work, expects an animate subject.
(9) is not meant to be taken as decisive evidence infavour of the CTE strategy or the frame-based activestrategy.
We are sure that sentences can be foundwhere altering the predicate's emantic informationwould cause mistranslations, where only the CTD orpassive strategy would produce correct translations(there are probably sentences for which the passivestrategy would produce mistranslations too): a strategythat produces a correct translation for one sentencemay well mistranslate another.
It is not possible topursue these possibilities in detail here because itwould involve too much detail of the mechanisms bywhich a translation equivalent in the target language islocated - for example, by a full semantic matching asin the MARGIE system (Schank et al 1973), or from aprior guidance to possible target equivalents, as inWilks (1973).
That degree of detail would change theemphasis of this paper, in which translation is no morethan a minimum condition that semantic strategiesdealing with il l-formedness must meet.Because individual metaphors are ambiguous, thatis, can be read or understood in two directions, no onestrategy is adequate.
The passive strategy is totallyunsatisfactory.
Strategies that alter the semantic in-formation of non-predicates (CTD strategy) are inap-propriate for predicate readings of individual meta-phors and for extended metaphors that continue apredicate reading such as the one in sentence (8).Equally, we cannot have only strategies that alter thesemantic information of predicates (CTE or activestrategy) because of both non-predicate readings ofindividual metaphors and extended metaphors continu-ing a non-predicate reading like (7).As a result of the preceding comparison of strate-gies in terms of correspondence to human understand-ing and production of correct translations, it is clearthat both strategies that change expectations andstrategies that change data are needed.
Since boththese major types of strategy are fallible, how will theproper strategy be selected?In the next section we propose a control mecha-nism using both types of strategy that makes the cor-rect selections (in terms of human understanding andaccurate translations above), that is, it allows individu-al metaphors like the one in (9) to be represented byboth types of strategy, selects the CTE strategy forexamples uch as (8), the CTD strategy for those suchas (7), and no strategy at all for sentences like(10) The cat drank milk and the dog (drank) waterthat do not contain metaphor.6.3.
Cont ro l  o f  the  s t ra teg iesIn this section we consider only single representativeexamples of a strategy that changes expectations andone that changes data: these will be the CTE and CTDstrategies.
We limit our demonstration of the controlmechanism to the sentences of 6.2. containing a gap-American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 185Dan Fass and Yorick Wi lks Preference Semantics, III-Formedness, and Metaphorped clause - that is, (7), (8), (9), and (10) - thoughwe believe it to be generally applicable.We shall deal with the case of no metaphor first.
Ifno metaphor is found in the first clause, as in (1), thena single template with the largest number of prefer-ences is chosen in the normal way (see section 1).If, as in (7), (8), and (9), a metaphor is encoun-tered in the first clause, then both major types ofstrategy are applied, producing two competing tem-plates for the clause representing metaphorical ambi-guity, that is, the two possible readings of the meta-phor (data and expectations important o the metaphorare included below):(1 la) \[car (VEHICLE)\] ~ \[drinks (SUBJVEHICLE)\]* .
*- \[gasoline\]( l ib )  \[car (ANIMATE)\]* -~ \[drinks (SUBJANIMATE)\] --- \[gasoline\]Any semantic formula whose semantic information hasbeen altered is marked by the control mechanism(indicated above by an *).
The template ( l l a )  pro-duced by the CTE strategy has an altered predicate\[drink\]; the template ( l ib )  produced by the CTDstrategy has an altered non-predicate \[car\].If the second clause is a case of gapping, then thedummy node in the second template is analysed.
Ifthere is a single (unmarked) template representing thefirst clause, then the first clause did not contain ametaphor and the dummy node in the second templateinherits the semantic formula from the controllingnode in the first template in the way described earlier(section 6.2.).
Hence, for (10), \[drink\] is inherited.If there are two (marked) templates representingthe first clause, as with ( l l a )  and ( l lb ) ,  then a meta-phor is present.
Though the mechanism also operatesif the dummy node in the second template is a predi-cate (as in (8)), let us suppose that the missing node isa non-predicate, as in (9) The car drinks gasoline anddoes not work well or (7).To allow for individual metaphors like (9), thecontrol mechanism assumes that the metaphor in thefirst clause has not been continued in the second: anunaltered version of the non-predicate is placed in thedummy node of the second template, taken from thetemplate with an altered predicate because it containsthe unaltered non-predicate.
So, for sentence (9), theunaltered \[car (VEHICLE)\] is taken from the templatewith the altered predicate ( l l a ) ,  and a new templatefor the second clause (shown below in much simplifiedform) is produced:(12) \[car (VEHICLE)\] ~ \[works (SUBJ VEHICLE)\]If there is no preference violation between that unal-tered non-predicate and the other nodes of the secondtemplate, then, provided no other reading has moresatisfied preferences, it is that reading of the templatethat is accepted.If, though, we have a case of extended metaphor asin (7) The car drank gasoline and purred to itself, thenthere is a preference violation between the unalterednon-predicate \[car (VEHICLE)\] and the predicate inthe template for the second clause.
So, for (7), thefollowing template (much simplified) is produced:(13) \[car (VEHICLE)\] \[purred (SUBJ ANIMATE)\](13) must have more satisfied preferences than anyother competing template but - and here the controlmechanism departs from the standard preference-as-procedure - even if (13) has more satisfied prefer-ences than any other template, it is not accepted as itis, because it contains a preference violation between\[car\] and \[purr\].
Instead, a new template for the sec-ond clause is created: its empty node is filled with thealtered version of the same formula \[car (ANIMATE)\],inherited from the other template representing the firstclause ( l lb ) ,  the one containing the amended non-predicate:(14) \[car (ANIMATE)\] ~ \[purred (SUBJ ANIMATE)\]This template is accepted if it has more satisfied pref-erences than any other.
Because the second case ofinheritance was from the template containing theamended non-predicate, the control mechanism knowsthat the CTD strategy was appropriate for the firstclause: the template containing the amended non-predicate, appears in the semantic representation forthe sentence as a whole.
Hence the control mecha-nism handles cases of extended metaphor like (7) and(8).However, for sentences containing a single meta-phor such as (9) and (1), the ambiguity of the meta-phor remains unresolved as two possible templates,( l l a )  and ( l lb ) .
In terms of the means of compari-son used in 6.2.
(correspondence to human under-standing and production of correct translations), thereis no need to keep both templates, so the templatewith the altered predicate is retained (the product ofthe CTE or active strategy), somewhat arbitrarily, be-cause we believe this reading to be the more commonof the two.AcknowledgmentsThis research is currently supported by Science andEngineering Research Council contract GR/C /44938,"Intelligent knowledge-based spelling correction", andby the European Community DGXIII, Luxembourg,under contract ETL-1-E, "Linguistics for machinetranslation".The authors would like to thank Doug Arnold andClaire Grover for their many helpful comments andsuggestions, and one of our reviewers for his/her corn-186 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, Ju ly-December 1983Dan Fass and Yorick Wi lks Preference Semantics, III-Formedness, and Metaphorments about selecting between CTD and CTE strate-gies.ReferencesBoguraev, B.K.
1979 Automatic Resolution of Linguistic Ambigu-ities.
Technical Report No.
l l .
Computer Science Department,University of Cambridge, England.Chomsky, N. 1977 On Wh-Movement.
In Culicover, P.; Wasow,T.
; and Akmajian, A., Eds., Formal Syntax.
Academic Press,New York: 71-132.Erlandsen, J.; Van Eynde, F.; McNaught, J.; Somers, H.; andDestombes, L. 1982 Dictionary and Semantics in Eurotra.Eurotra Contract Report ET-10-SEM.
European Communities,Luxembourg.Fass, D.C. 1983 Preference.
In McNaught et al (1983) Part 111,Section I.Givon, T. 1967 Transformation of Ellipsis, Sense Developmentand Rules of Lexical Derivation.
Memo SP-2896.
SytemsDevelopment Corporation, Santa Monica, California.Hankamer, J.
1973 Unacceptable Ambiguity.
Linguistic Inquiry4: 17-68.Hendrix, G. 1975 Expanding the Utility of Semantic NetworksThrough Partitioning.
Proceedings of the Fourth InternationalJoint Conference on Artificial Intelligence.
Thilisi, USSR: 115-121.Katz, J. and Postal.
P. 1964 An Integrated Theory of LinguisticDescription.
MIT Press, Cambridge, Massachusetts.McNaught, J.; Arnold, D.; Bennett, P.; Fass, D.C.; Grover, C.;Huang, X.; Johnson, R.; Somers, H.; Whitelock, P.; and Wilks,Y.A.
1983 Structure, Strategies, and Taxonomy.
EurotraContract Report ETL-I-E. European Communities, Luxem-bourg.Rumelhart, D.E.
1979 Some Problems with the Notion of LiteralMeanings.
In Ortony, A., Ed., Metaphor and Thought.
Cam-bridge University Press, Cambridge, England: 78-90.Schank, R.C.
1975 Conceptual Information Processing.
NorthHolland, Amsterdam, Holland.Schank, R.C.
; Goldman, N.; Reiger, C.; and Riesbeck, C. 1973MARGIE: Memory, Analysis, Response Generation, and Infer-ence in English.
Proceedings of the Third International JointConference on Artificial Intelligence.
SRI, Menlo Park, Califor-nia: 255-261.Simmons, R.F.
1973 Semantic Networks: Their Computation andUse for Understanding English Sentences.
In Schank, R.C.
andColby, K.M., Eds., Computer Models of Thought and Language.W.H.
Freeman, San Francisco, California: 63-113.Van Eynde, F. 1982 Ambiguity.
In Erlandsen et al (1982),Chapter 5.Wilks, Y.A.
1968 Computable Semantic Derivations.
MemoSP-3017.
Systems Development Corporation, Santa Monica,California.Wilks, Y.A.
1973 An Artificial Intelligence Approach to MachineTranslation.
In Schank, R.C.
and Colby, K.M., Eds., ComputerModels of Thought and Language.
W.H.
Freeman, San Francisco,California: 114-151.Wilks, Y.A.
1975 A Preferential Pattern-Seeking Semantics forNatural Language Inference.
Artificial Intelligence 6: 53-74.Wilks, Y.A.
1978 Making Preference More Active.
ArtificialIntelligence 10:l -1 I.American Journal of Computational Linguistics, Volume 9, Numbers 3-4, Ju ly-December 1983 187
