Proceedings of the ACL Interactive Poster and Demonstration Sessions,pages 1?4, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAn Information-State Approach to Collaborative ReferenceDavid DeVault1 Natalia Kariaeva2 Anubha Kothari2 Iris Oved3 and Matthew Stone11Computer Science 2Linguistics 3Philosophy and Center for Cognitive ScienceRutgers UniversityPiscataway NJ 08845-8020Firstname.Lastname@Rutgers.EduAbstractWe describe a dialogue system that workswith its interlocutor to identify objects.Our contributions include a concise, mod-ular architecture with reversible pro-cesses of understanding and generation,an information-state model of reference,and flexible links between semantics andcollaborative problem solving.1 IntroductionPeople work together to make sure they understandone another.
For example, when identifying an ob-ject, speakers are prepared to give many alternativedescriptions, and listeners not only show whetherthey understand each description but often help thespeaker find one they do understand (Clark andWilkes-Gibbs, 1986).
This natural collaboration ispart of what makes human communication so robustto failure.
We aim both to explain this ability and toreproduce it.In this paper, we present a novel model of collab-oration in referential linguistic communication, andwe describe and illustrate its implementation.
As weargue in Section 2, our approach is unique in com-bining a concise abstraction of the dynamics of jointactivity with a reversible grammar-driven model ofreferential language.
In the new information-statemodel of reference we present in Section 3, inter-locutors work together over multiple turns to asso-ciate an entity with an agreed set of concepts thatcharacterize it.
On our approach, utterance planningand understanding involves reasoning about howdomain-independent linguistic forms can be usedin context to contribute to the task; see Section 4.Our system reduces to four modules: understanding,update, deliberation and generation, together withsome supporting infrastructure; see Section 5.
Thisdesign derives the efficiency and flexibility of refer-ential communication from carefully-designed rep-resentation and reasoning in this simple architecture;see Section 6.
With this proof-of-concept implemen-tation, then, we provide a jumping-off point for moredetailed investigation of knowledge and processes inconversation.2 Overview and Related WorkOur demonstration system plays a referential com-munication game, much like the one that pairs ofhuman subjects play in the experiments of Clark andWilkes-Gibbs (1986).
We describe each episode inthis game as an activity involving the coordinatedaction of two participants: a director D who knowsthe referent R of a target variable T and a matcherM whose task is to identify R. Our system can playeither role, D or M, using virtual objects in a graph-ical display as candidate targets and distractors, andusing text as its input and output.
Our system usesthe same task knowledge and the same grammarwhichever role it plays.
Of course, the system alsodraws on private knowledge to decide how best tocarry out its role; for now it describes objects usingthe domain-specific iteration proposed by Dale andReiter (1995).
The knowledge we have formalized istargeted to a proof-of-concept implementation, butwe see no methodological obstacle in adding to the1system?s resources.We exemplify what our system does in (1).
(1) a.
S: This one is a square.b.
U: Um-hm...c. S: It?s light brown.d.
U: You mean like tan?e.
S: Yeah.f.
S: It?s solid.g.
U: Got it.The system (S) and user (U) exchange seven utter-ances in the course of identifying a tan solid square.We achieve this interaction using the information-state approach to dialogue system design (Larssonand Traum, 2000).
This approach describes dialogueas a coordinated effort to maintain an agreed recordof the state of the conversation.
Our model contrastswith traditional plan-based models, as exemplifiedby Heeman and Hirst?s model of goals and beliefsin collaborative reference (1995).
Our approach ab-stracts away from such details of individuals?
men-tal states and cognitive processes, for principled rea-sons (Stone, 2004a).
We are able to capture thesedetails implicitly in the dynamics of conversation,whereas plan-based models must represent them ex-plicitly.
Our representations are simpler than Hee-man and Hirst?s but support more flexible dialogue.For example, their approach to (1) would have in-terlocutors coordinating on goals and beliefs abouta syntactic representation for the tan solid square;for us, this description and the interlocutors?
com-mitment to it are abstract results of the underlyingcollaborative activity.Another important antecedent to our work isPurver?s (2004) characterization of clarification ofnames for objects and properties.
We extend thiswork to develop a treatment of referential descriptiveclarification.
When we describe things, our descrip-tions grow incrementally and can specify as muchdetail as needed.
Clarification becomes correspond-ingly cumulative and open-ended.
Our revised in-formation state includes a model of cumulative andopen-ended collaborative activity, similar to that ad-vocated by Rich et al (2001).
We also benefit froma reversible goal-directed perspective on descriptivelanguage (Stone et al, 2003).3 Information StateOur information state (IS) models the ongoing col-laboration using a stack of tasks.
For a task of col-laborative reference, the IS tracks how interlocutorstogether set up and solve a constraint-satisfactionproblem to identify a target object.
In any state, Dand M have agreed on a target variable T and a set ofconstraints that the value of T must satisfy.
When Mrecognizes that these constraints identify R, the taskends successfully.
Until then, D can take actionsthat contribute new constraints on R. Importantly,what D says adds to what is already known about R,so that the identification of R can be accomplishedacross multiple sentences with heterogeneous syn-tactic structure.Our IS also allows subtasks of questioning or clar-ification that interlocutors can use to maintain align-ment.
The same constraint-satisfaction model isused not only for referring to displayed objects butalso for referring to abstract entities, such as actionsor properties.
Our IS tracks the salience of entityand property referents and, like Purver?s, maintainsthe previous utterance for reference in clarificationquestions.
Note, however, that we do not factorupdates to the IS through an abstract taxonomy ofspeech acts.
Instead, utterances directly make do-main moves, such as adding a constraint, so our ar-chitecture allows utterances to trigger an open-endedrange of domain-specific updates.4 Linguistic RepresentationsThe way utterances signal task contributions isthrough a collection of presupposed constraints.
Tounderstand an utterance, we solve the utterance?sgrammatically-specified semantic constraints.
Aninterpretation is only feasible if it represents acontextually-appropriate contribution to the ongoingtask.
Symmetrically, to generate an utterance, weuse the grammar to formulate a set of constraints;these constraints must identify the contribution thesystem intends to make.
We view interpreted lin-guistic structures as representing communicative in-tentions; see (Stone et al, 2003) or (Stone, 2004b).As in (DeVault et al, 2004), a knowledge in-terface mediates between domain-general meaningsand the domain-specific ontology supported in a par-ticular application.
This allows us to build inter-2pretations using domain-specific representations forreferents, for task moves, and for the domain prop-erties that characterize referents.5 ArchitectureOur system is implemented in Java.
A set of in-terface types describes the flow of information andcontrol through the architecture.
The representationand reasoning outlined in Sections 3 and 4 is ac-complished by implementations of these interfacesthat realize our approach.
Modules in the architec-ture exchange messages about events and their in-terpretations.
(1) Deliberation responds to changesin the IS by proposing task moves.
(2) Generationconstructs collaborative intentions to accomplish theplanned task moves.
(3) Understanding infers col-laborative intentions behind user actions.
Genera-tion and understanding share code to construct inten-tions for utterances, and both carry out a form of in-ference to the best explanation.
(4) Update advancesthe IS symmetrically in response to intentions sig-naled by the system or recognized from the user;the symmetric architecture frees the designer fromprogramming complementary updates in a symmet-rical way.
Additional supporting infrastructure han-dles the recognition of input actions, the realizationof output actions, and interfacing between domainknowledge and linguistic resources.Our system is designed not just for users to inter-act with, but also for demonstrating and debuggingthe system?s underlying models.
Processing can bepaused at any point to allow inspection of the sys-tem?s representations using a range of visualizationtools.
You can interactively explore the IS, includingthe present state of the world, the agreed directionof the ongoing task, and the representation of lin-guistic distinctions in salience and information sta-tus.
You can test the grammar and other interpretiveresources.
And you can visualize the search spacefor understanding and generation.6 ExampleLet us return to dialogue (1).
Here the system rep-resents its moves as successively constraining theshape, color and pattern of the target object.
In gen-erating (1c), the system iteratively elaborates its de-scription from brown to light brown in an attemptto identify the object?s color unambiguously.
Theuser?s clarification request at (1d) marks this de-scription of color as problematic and so triggers anested instance of the collaborative reference task.At (1e) the system adds the user?s proposed con-straint and (we assume) solves this nested subtask.The system returns to the main task at (1f) havinggrounded the color constraint and continues by iden-tifying the pattern of the target object.Let us explore utterance (1c) in more detail.
TheIS records the status of the identification process.The system is the director; the user is the matcher.The target is represented provisionally by a dis-course referent t1, and what has been agreed so faris that the current target is a square of the rele-vant sort for this task, represented in the agent assquare-figure-object(t1).
In addition, the system hasprivately recorded that square o1 is the referent itmust identify.
For this IS, it is expected that thedirector will propose an additional constraint iden-tifying t1.
The discourse state represents t1 as beingin-focus, or available for pronominal reference.Deliberation now gives the generator a specificmove for the system to achieve:(2) add-constraint(t1,color-sandybrown(t1))The content of the move in (2) is that the systemshould update the collaborative reference task to in-clude the constraint that the target is drawn in a par-ticular, domain-specific color (RGB value F4-A4-60,or XHTML standard ?sandy brown?).
The systemfinds an utterance that achieves this by exploringhead-first derivations in its grammar; it arrives at thederivation of it?s light brown in (3).
(3)brown [present predicative adjective]HHHHHit [subject] light [color degree adverb]A set of presuppositions connect this linguisticstructure to a task domain; they are given in (4a).The relevant instances in this task are shown in (4b).
(4) a. predication(M)?brown(C)?
light(C)b. predication(add-constraint)?brown(color-sandybrown)?light(color-sandybrown)3The utterance also uses it to describe a referentX so presupposes that in-focus(X) holds.
Themove effected by the utterance is schematized asM(X ,C(X)).
Given the range of possible task movesin the current context, the constraints specified bythe grammar for (3) are modeled as determining theinstantiation in (2).
The system realizes the utter-ance and assumes, provisionally, that the utteranceachieves its intended effect and records the new con-straint on t1.Because the generation process incorporates en-tirely declarative reasoning, it is normally reversible.Normally, the interlocutor would be able to identifythe speaker?s intended derivation, associate it withthe same semantic constraints, resolve those con-straints to the intended instances, and thereby dis-cover the intended task move.
In our example, thisis not what happens.
Recognition of the user?s clari-fication request is triggered as in (Purver, 2004).
Thesystem fails to interpret utterance (1d) as an appro-priate move in the main reference task.
As an alter-native, the system ?downdates?
the context to recordthe fact that the system?s intended move may be thesubject of explicit grounding.
This involves push-ing a new collaborative reference task on the stackof ongoing activities.
The system remains the direc-tor, the new target is the variable C in interpretationand the referent to be identified is the property color-sandybrown.
Interpretation of (1d) now succeeds.7 DiscussionOur work bridges research on collaborative dialoguein AI (Rich et al, 2001) and research on pragmat-ics in computational linguistics (Stone et al, 2003).The two traditions have a lot to gain from reconcil-ing their assumptions, if as Clark (1996) suggests,people?s language use is coextensive with their jointactivity.
There are implications both ways.For pragmatics, our model suggests that languageuse requires collaboration in part because reachingagreement about content involves substantive socialknowledge and coordination.
Indeed, we suspectthat collaborative reference is only one of many rel-evant social processes.
For collaborative dialoguesystems, adopting rich declarative linguistic repre-sentations enables us to directly interface the coremodules of a collaborative system with one another.In language understanding, for example, we can col-lapse together notional subprocesses like semanticreconstruction, reference resolution, and intentionrecognition and solve them in a uniform way.Our declarative, reversible approach supports ananalysis of how the system?s specifications drive itsinput-output behavior.
The architecture of this sys-tem thus provides the groundwork for further in-vestigations into the interaction of social, linguis-tic, cognitive and even perceptual and developmen-tal processes in meaningful communication.AcknowledgementsSupported in part by NSF HLC 0308121.
Thanks toPaul Tepper.ReferencesH.
H. Clark and D. Wilkes-Gibbs.
1986.
Referring as acollaborative process.
Cognition, 22:1?39.H.
H. Clark.
1996.
Using Language.
Cambridge.R.
Dale and E. Reiter.
1995.
Computational interpreta-tions of the Gricean maxims in the generation of refer-ring expressions.
Cognitive Science, 18:233?263.D.
DeVault, C. Rich, and C. L. Sidner.
2004.
Naturallanguage generation and discourse context: Comput-ing distractor sets from the focus stack.
In FLAIRS.P.
Heeman and G. Hirst.
1995.
Collaborating on refer-ring expressions.
Comp.
Ling., 21(3):351?382.S.
Larsson and D. Traum.
2000.
Information state anddialogue management in the TRINDI dialogue moveengine toolkit.
Natural Language Eng., 6:323?340.M.
Purver.
2004.
The Theory and Use of ClarificationRequests in Dialogue.
Ph.D. thesis, Univ.
of London.C.
Rich, C. L. Sidner, and N. Lesh.
2001.
COL-LAGEN: applying collaborative discourse theory tohuman-computer interaction.
AI Magazine, 22:15?25.M.
Stone, C. Doran, B. Webber, T. Bleam, and M. Palmer.2003.
Microplanning with communicative intentions.Comp.
Intelligence, 19(4):311?381.M.
Stone.
2004a.
Communicative intentions and conver-sational processes.
In J. Trueswell and M. K. Tanen-haus, editors, Approaches to Studying World-SituatedLanguage Use, pages 39?70.
MIT.M.
Stone.
2004b.
Intention, interpretation and the com-putational structure of language.
Cognitive Science,28(5):781?809.4
