An empi r i ca l  lnethod  fo r  ident i fy ing  and  t rans la t ing  techn ica lte rmino logySayori ShimohataResearch & Development  Group,Oki Electric Industry  Co., Ltd.Crystal  Tower 1-2-27 Shirolni,Chuo-ku,  Osaka 540-6025 Japansh imohat  a245 ~oki.
co.j pAbstractThis paper describes a. method for retrievingpatterns of words a.nd expressions frequentlyused in a. specific dom a.in and building a. dictio-nary for ma.chine translatiou(MT).
The methoduses an untagged text corpus in retrieving wordsequences a.nd simplified pa.rt-of-speech tern-plates in identifying their synta.ctic a.tegories.The pa.per presents e?perimenta.l results for a.p-plying the words and expressions to a pattern-based ma.chine translation system.1 I n t roduct ionTh.ere has been a. continuous interest in corpus-based approa.ches which retrieve words and ex-pressions in connection with a specific domain(we call them technical terms herea.fter).
Theymay correspond to syntactic phra.ses or compo-nents of syntactic relationships and ha.ve beenfound useful in various application area.s, in-cluding inibrmation e?tra.ction, text sumlna.-riza.tion, and ma.chine tra.nsla.tion.
Am.ong oth-ers, a. knowledge of technica\] terminology is in-dispensa.ble for machine tra.nsla.tion beca.use us-age and mea.ning of technica.1 terms a.re oftenquite different from their literal interpreta.tion.One a.pproa.ch for identifying technical termi-nology is a. rule-ba.sed a.pproa.eh which learnsl.oca.1 syntactic patterns from a training cor-pus.
A variety of methods ha.ve been developedwithin this fra.mework, (Ra.msha.w, 1995) (Arga.-mon et al, 1999) (Ca.rdie and Pierce, 1.999) a.ndachieved good results for the considered ta.sk.Surprisingly, though, little work ha.s been d.e-voted to lea.rning local syntactic pa.tterns be-sides noun phrases.
Another drawback of thisa.pproach is tha.t it requires substa.ntiM trainingcorpora, in many cases with pa.rt-of-speech tags.An.
alternative approa.ch is a. statistical onewhich retrieves recurrent word sequences asco\]loca.tiolls (Sma.dja., 1993)(Ha.runo et a.1.,1996)(Shimolla.ta et a.1., :1997).
This a.pproachis robust and pra.ctical because it uses t)laintext corpora, without a.ny inibrmation depen-dent on a la.ngua.ge.
Unlike the former N)-proa.ch, this a.pproach extra.cts va.rious types oflocal pa.tterns a.t the same time.
Therefore,post-processing, such as part of speech ta.ggingand syntactic category identifica.tion, is neces-sary when we a.pply them to NLP applica.tions.This pa.per presents a. method for identify-ing technicM terms froni a. corpus and a.pl)ly-ing them to a. ma.chine tra.nsla.tion system.
Theproposed method retrieves local pa.tterns by uti-lizing the n-gram statistics a.nd identifies theirsyntactic categories with.
simple pa.rt-ofspeechteml)la.tes.
We ma.ke 3. ma.chine trans\]a.tion dic-tiona.ry from the retrieved patterns and tra.ns-late documents in the Sa.lne doma.in a.s the orig-inal corpus.In the next section, we briefly describe apa.ttern-based machine translation.
The follow-ing section explains how th.e proposed methodworks in detail.
We th.en present experimenta.lresults a.nd conclude with a discussion.2 Pat tern -based  MT sys temh pattern-ha.seal MT system uses a set of bilin-gua.1 pa.tterns(CFG rules) (Abeille et a.l., 1990)(Ta.keda., 1.996) (Shimohata.
et a.l., 1.999).
In thepa.rsing process, the engine performs a. CFG-parsing for a.n input sentence and rewrites treesby a.pplying the source pa.tterns.
3'erminalsand non-terminals are processed under the sa.mefra.lnework but lexicalized pa.tterns ha.re priorityover symbolized pa.tterns 1 A plausible parseWe define a symbolized pattern as a pattern with-out a. terminal and ~L lexicalizcd pattern as that withmore than one terminal, we prepares 1000 symbolizedpatterns a.nd 130,000 lexicalizcd patterns as a system782tree will be selected among possible parse treesby the number of l)atterns applied.
Then thepa.rse tree is tr~msferred into target language byusing target patterns which correspond to thesource patterns.Figure 1 shows an example of translationpatterns between Fmglish and .lapanese.
EachC1 G rule) has co l  English pattern(a left-half ' ,' 'responding aal)anese pattern(a right-half CFGrule).
Non-terminals are bracketed with in-dex numbers which represents correspondenceof non-terminals between the source and targetpattern.S *--\[I:NP\] \[2:VP\] S ~--\[I:NP\] ~(subj) \[2:VP\]NP ~a \[I:NP\] NP *-\[I:NP\]VP ~---\[I:VT\] [2:NP\] VP '~--\[2:NP\] ,~(dobj) \[I:VT\]VP +-take \[I:NP\] VP ~---\[I:NP\] ~(dobj)nj-7~("do")VP ~-- take a bath VP "*-J~=t:t~("bath") \[5("in") ,,'~'7~("enter")V ~-- take V ',-'~7~("take")N '--" bath N ~--J:~,~("l)ath")Figure 1: translation l)atternsThe pattern ibrmat is simple but highly de-scriptive.
It can represent complicated linguis-tic phenomena nd even correspondences be-tween the languages with quite different struc-tures, l)'urthermore, a.l\] the knowledge necessaryfl)r the translation, whether syntactic or lexical,are compiled in the same pattern tbrmat.
Ow-ing to these fea.tures, we can easily apply theretrieved technical terms to a real MT system.3; Algor i thm1,'igure 2 shows an outline of the l)roposednlethod.
The inpu t is an untagged :~nonolingu alcorpus, while the output is a dolnain dictionaryfor machine translation.
The process is con>prised of 3 phases: retrieving local patterns, as-signing their syntactic ategories with part-of-speech(POS) templates, and making translationpatterns.
The dictionary is used when an MTsystem translates a text in the same domain asthe corpus.We assume that the input is an English cor-pus and the dictionary is used for an English-Japanese MT system.
In the remainder of thissection, we will explain each phase in detail withEnglish and Japanese xamples.dictiona.ry.3.1 Retrieving local pat ternsWe have ah'eady proposed a method for retriev-ing word sequences (Shimohata et al, 1997).This method generates all n-character (or n-word) strings appearing in a text and tiltersout ffagl-nenta.1 strings with the distribution ofwords adjacent to the strings.
This is basedon the idea.
that adjacent words are widely dis-tributed if the string is meaningful, m~d are lo-calized if the string is a substring of a meaning-ful string.The method introduces entropy value to mea-sure the word distribution.
Let the string t)e8tr, the adjacent words Wl...w,~, and the fre-quency of str frcq(.slr).
The probability of eachpossible adjacent word p(wi) is then:p(wi) -  frcq(wi)frcq(str) (\])At ttla,t time~ the entropy of ,~tr H(.qtr) is de-tined a.s:t l ( , t , . )
= (2)i=1Calculating the entropy of both sides of ,qtr,the lower one is used as ll(,tr).
Then thestrings whose entropy is larger than a giventhreshold are retrieved as local pattexns.3.2 I dent i fy ing  syntact i c  categoriesSince the strings are just word sequences, thel)rocess gives tllem syntactic categories.
Foreach str .str~1.
assign pa.rt-ofspeech tags tl, ... t~.
to thecoH\]ponent words Wl, ... /vr~2.
match tag sequence tl, ... t,~ with part-of-speech templates 7~3.
give sir corresponding syntactic category,5'6'i, it' it matches Ti3.2.1 Assigning part-of-speech tagsThe process uses a simplified part-of speech setshown in table 1. l?unction words are assignedas they are, while content words except for ad-verb are fallen into only one part of speechword.
Four kinds of words "be", "do", "'not",and "to" are assigned to speciM tags be, do,not, and to respectively.There are several reasons to use the simplitiedPOS tags:783Retrieve local patterns-- -* Identify syntactic categoriesMake translation patterns5 )nFigure 2: outlinePOS tag part of speechartadvauxeonjdetprepprnpuncbedonottowordarticleadverbauxiliary verbconjunctiondeterminerprepositionpronounpunctuation.
do~"~Ot""to"th.e othersTable 1: part-of-speech tags?
it may sometimes be difl3cult to identifyprecise parts of speech in such a local pat-tern.?
words are often used beyond parts of speechin technical terminology?
it is eml)irically found that word sequencesretrieved through n-gram statistics havedistributional concentration several syn-tactic categories.Theretbre, we think the simplified POS tags aresufficient o identify syntactic ategories.The word sequence w~, ... w,~ is representedfor a part-of-speech tag sequence t l ,  ... ti.
Fig-ure 3 shows examples of POS tagging.
Italicthe fue l  tankart word worddo this s tep ?do det,prn word puncto oprn  theto word artFigure 3: examples of POS tagginglines are given word sequences and bold linesare POS tag sequences.
If a word falls into twoor more parts of speech, all possible POSs wi\]\]be assigned like "this" in the second example.3.2.2 Matching POS templatesThe process identifies a syntactic ategory(SC)of sir by checking if str's tag sequence tl, ...tn matches a given POS template 7}.
If they784match,  s t r  is given a syntact ic  category ,5'Cicorresponding to 5/).
Table 2 shows examt)lesof I)OS teml)la.tes and corresl)onding SCs 2SC POS templateNN?prepVTV-edV1,'UNC(., '0 (wo,.d l (.o,q) , (,,)o,,d)(., '0 (wo,.d) + (pw,  I~o)(,,,'0.
(.,u.~ I~.o Iv,',,,) * (.,o,,d) + (.,.t)(~) (wo,.d) + (v,'~v)(., '0:( .u .
I~,o I l,,',,)(,~o,.a)((.
'~ \[ .*,..
I ~o.j Ida* I *','?
*, I v,',,)+If SC is N, delete art and generate:NP '-- st,-NP +-strIf SC is VT, delete (aux\[tolprn) and art and generate:VP (-- str \[ 1 :NP\]VP ~-- \[I:NP\] ~(dobj) st*" "ej-~Cdo" )If SC is v, delete (auxltolprn) generate:V +--sO"V *-- str ~("do" )3'M)le 2: POS telnplates ~md corresponding SCsThe templa?es are described in the l'orm ofregula.r expressions(Rl~;) a .
The first templ~tein table 2, for exanrple, :m~tches a string whosetag sequence begins with an article, contains 0or m ore rel)etitions of content word s or conj u n c-tions, a.nd ends with a content word.
"the fuelta,nk" in tigure 3 is applied to this templa.tes aaldgiven a SC "N".3.3 Making  t rans la t ion  pat ternsThe process converts the strings into transla-tion l)a.tterns.
The l)roblem here is that  we needto generate bilingual translation l)al;terns frommonolingua\] strings.
We use heuristic rules onborr0wing word s from foreign \]angu ages ..1l!
'igure 4 is an example of conversion rides tbrgenerat ing English-Jal)anese translation pa.t-terns.
To give an exa.mple, "to open tile" infigure 3, whose SC is vT, is converted into thefollowing patterns in accorda.nce with the sec-ond rule in figure 4.Figure d: conversion rules for generttting trans-lation l)a.tterns4 Eva luat ionVVe have tested our algorithln in building adoma.in dict ionary and malting a. translationwith it.
A corpus used in the exl)eriment is aCOml)uter nlanual comprising 167,023 words (in22,0d i sentences).The corl)us contains 24,7137 n-grooms whichappear  more than twice.
Among them, 7,6116strings are extracted over the entropy threshold1.
Table 3 is a list of top 20 strings (exceptfor single words and function word sequences)retrieved from the test c()rptlS.These strings a.re c~tego:rized into 1,239 POSpatterns.
Table 4 is a. list of to I) 10 POS l)at;-terns aim the numl)ers of strings classitied intothenl, hi this exper iment,  he top 10 POS pat-terns a.ccount for dg.d % of a.ll 1'OS patterns.
Itsubstant iates the fa.ct that  the retr ieved stringstend to concentr~te in certa.in POS patterns.VP ~--open \[I:NP\]VP *--\[I:NP\] :~(dobj) open ~7~("do")2 Note that tile POS templates are strongly dependenton tile features of n-gram strings.a ,.,, causes tile resulting RP, to match 0 or more rep-etitions of the preceding I{E. "+" causes the resultingRE to match I or more rel)etitions of the preceding RI!'.
"1:" creates a RE exl)ression that will match either righto,: left of "l"- "(...)" indicates the start and end of ~Lgroup.4 In Japanese, foreign words, especially in technicalterminology, are often used as they are in katakana (tiLephonetic spelling for foreign words) followed by functionwords which indicate their parts of speech For example,English verbs are followed by "suru", a verb wliich means"do" in English.f r cq  POS1886553368229160158121.1.0810181Wol:dword wordart wordart word wordword prepword artword word wordto wordprep art wordprep wordTable 4: top 10 P()S p~tterns785.lI(str) freq(atr) .st," IIH(, , -) f req(st r )  str5.514.484.4:63.923.793.763.673.583.563.55247149910010616330929736169180see alsothe serverclick OK .use this functionthe functionthe followingthe filein the Server Manager ,using theCGI programs3.553.543.463.463 A43.363.293.233.223.2255220920916817219213221371575the clientuse timthe userclick thethe catalog agentthe requeston pagea specifiedif you want toyour serverTable 3: top 20 stringsIn the matching process, we prepared 15 tem-plates and 6 SCs.
Table 5 is a result of SCidentification.
2,462 strings(32.3 %) are notlnatched to any templates.
The table indicatesthat most strings retrieved in this method areidentified as N and NP.
It is quite reasonablebecause the majority of the technical terms aresupposed to be nouns and noun phrases.improved in parsing 104improved in word selection 467about the same 160same 21.2not imt)roved 57total 1000SC number of patternsNPN+prepVPVP+prepVTV722200321017778Table 5: result of SC identificationThe retrieved translation patterns total1,21.9.
Figure 5 shows an example of transla-tion patterns retrieved by our method.We, then, converted them to an MT dictio-nary and made a translation with and withoutit.
Table 6 summarizes the evaluation resultstranslating randomly selected 1.,000 sentencesfi'om the test corpus.
Compared with the trans-lations without the dictionary, the translationswith the dictionary improved 571 in parsing andword selection.Figure 6 illustrates changes in translations.Each column consists of an input sentence, atranslation without the dictionary, and a trans-lation with the dictionary.
Bold English wordsTable 6: Translation evaluation resultscorrespond to underlined a apanese.First two examples show improvement inword selection.
The transl ations of" map(verb)"and "exec" are changed from word-for-wordtransla.tions to non-translation word sequences.Although "to make a map" and "exective" arenot wrong translations, they are irrelevant inthe computer manual context.
On the contrary,the domain dictionary reduces confltsion causedby the wrong word selection.Wrong parsing and incomplete p~rsing arealso reduced as shown in the next two exam-ples.
In the third example, "Next" should be anoun, while it is usually used as an adverb.
Thedomain dictionary solved the syntactic ambi-guity properly because it has exclusive priorityover system dictionaries.
In the forth example,"double-click" is an unknown word which couldcause incomplete parsing.
But the phrase wasparsed as a verb correctly.The last one is an wrong example of Japaneseverb selection.
That was a main cause of er-rors and declines.
The reason why the un-desirable Japanese verbs were selected is that786NP *- fiflly-qualified omain nameNP ~ text search engineNP ~ access log for\[1 :NP\]VP *-- save \[I:NP\]V ~ deallocateNP +-- fully-qualified omain nameNP ~ text search engineNP ~- \[I:NP\] (/)("of") access logVP ~ \[I:NP\] ~(dobj)save "-4-7-o("do '')V ~ deallocate 71"~("do")l!
'igure 5: tile retrieved transla.tion patternsType the URL prefix you want o nmp.&tgtztaqnap \[.,("perform a l~?Zt , '~URL prefix ~"('ff\[..C'a2L:kl,~'oThe exee tag allows an IITML file to execute an arbitrary progranl on the server;~("exeet ive 's  lag") \[~+)---z {---~ HTML 7741bJa{{fc,~tgJr21 q~.la{exec ~ It: IITML 7741bh~ server 0){\]~,-~?g'fft:lq~Ja~gt~{~gT~O){~ag ;Type the full name of your server, and then click Next..:.,~ It_ @~j~)  i~tgtza)+Y--/l--cDB~tg~*jd-Jb-C~,Jv~btg~bXo~t3tz(T) server O)~tg~@~4-3U~ Next ,~ click I~t3~U~oGo to the Control Panel and dot,ble-elick the Services icon.Cont,ol 'anel .
'x{~ta2;~t,x, ~5-eJ-a%\[~- tE.
("double-") \[~ Services 74n>~p IJ'yO~j-7~ ("elicld') oControl Panel - ' x{~'g  Services icon ,~double-click L,("double-click")td2~b~oSelling additional document directories~I~\]N0) F ' z~) tb 'b -~4 D~JbIJ"~N<("put, place") 7"~:~\]JlllY) document \[Z directory ~gT~("ass i~~U_~Figure 6: example sentences in the test corl)usthe method added deta.ult semantic intbrmationto the retrieved nouns and noun phrases.
Wehope to overcome it by a. model tha.t cla.ssiliesnoun pllrases, for example using verb-noun ora,djective-n ou :n relation s.5 Re la ted  workAs mentioned in section 1, there are two ap-proaches in corpus-based technica.l term re-tr ievah a rule-based approach and a statisticala~pproach.
Major ditlhre:nces between the two3,re:?
the former uses a tagged corlItls while thelatter  uses an untagged one.?
the former retrieves words and phrases witha designated syntact ic  category while thebttter :retrieves that  with various syntact iccategories at the same time.Our method uses the latter  ~pproa, ch becausewe think it more practical both in resources andin applications.For colnparison~ we refer here to Smadja'smethod (1993) because this method and theproposed method have much in connnon.
Inboth cases, technicaJ terms are retrieved froma.n untagged corpus with n-gram statistics andgiven syntact ic  ategories for NI,P applica.tions.The methods are diflhrent in that Sma.dja uses a787parser for syntactic ategory identification whilewe use POS templates.
A parser may add moreprecise syntactic ategory than I?OS templates.However, we consider it not to be critical underthe specific condition that the variety of inputpatterns is very small.
In terms of portability,the proposed method has an advantage.
Actu-ally, adding POS templates i not so time con-suming as developing a parser.We have applied the translation patterns re-trieved by this method to a real MT system.As a result, 57.1.
% of translations were im-proved with 1,219 translation patterns.
To ourknowledge, little work has gone into quantify-ing its effectiveness to NLP applications.
Werecognize that the method leaves room for im-provement in making translation patterns.
We,therefore, plan to introduce techniques for find-ing translational equivalent from bilingual cor-pora (Me\]amed, 1998) to our method.6 Conc lus ionWe have presented a method for identifyingtechnical terminology and building a domaindictionary tbr MT.
Applying the method totechnical manuM in English yielded positive re-suits.
We have found that the proposed methodwould dramatically improve the performance oftranslation.
In the future work, we plan to in-vestigate the availability of POS patterns whichare not categorized into any SCs.ReferencesAbeille A., Schabes Y., and .loshi A. K.1.990.
"Using Lexicalized Tags for MachineTranslation".
In Proceicdings of the lnticrna-tional Gbnficricncic on Computational Linguis-tics(COLIN@, pages 1-6.Argamon, S., l)agan, I., and Krymolowski,YuvM.
1999.
A Memory-Based Approachto Learning Shallow Natural Language Pat-terns.
In Procicedirtgs of the 17th COLINGand the 36th Anmtal Meeting of A CL, pages67-73.Cardie, C. and Pierce, D. 1.999.
The Role ofLexicalization and Pruning for Base NounPhrase Grammars In Proceedings of the16th National Conference on Artificial Inticl-Iigencc, pages 423-430.Haruno, M., Ikehara, S., and Yamazaki, T.1996.
Learning BilinguM Collocations byWord-Level Sorting.
In Proceedings of the16th COL1NG, pages 525 530.Melamed,I.D.
1998.
Empirical Methods for MTLexicon l)evelopment In Gerber, L. and Far-well, 1).
Eds.
Machine IYanslation and theInformation Soup, Springer-Verlag.Ramshaw, L.A., and Marcus, M.P.
1995.Text; Chunking using Transformation-BasedLearning In P~vcccdings of the 3rd Workshopon Very La,~qic Corpora , pages 82-94:.Shimohata,S., Sugio,T., and Nagata,J.
1997.Retrieving Collocations by Co-occurrencesand Word Order Constraints.
In Proceedingsof thic 35th Annual Mcicting of ACL, pages476-481..Shimohata, S. et al 1999.
"Machine Trans-lation System PENSEE: System Design andImplenlentation," In 1)roicicedings of MachineTranslation Summit VII, pp.380-384.Smadja,l?.A.
1993.
Retrieving Collocationsfl'om Text: Xtract.
In Cbmputational Lin-guistics, 19(1), pages 143 177.Takeda K. 1996.
"Pattern-Based Context-lheeGrammars for Machine Translation".
In Pro-ceedings of the 3/tth Annual Meeting of A CL,pages 14:4-151.788
