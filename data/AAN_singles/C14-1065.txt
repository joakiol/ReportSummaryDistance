Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 688?697, Dublin, Ireland, August 23-29 2014.A Generative Model for Identifying Target Companies of MicroblogsYeyun Gong, Yaqian Zhou, Ya Guo, Qi Zhang, Xuanjing HuangShanghai Key Laboratory of Intelligent Information ProcessingSchool of Computer Science, Fudan University825 Zhangheng Road, Shanghai, P.R.China{12110240006, zhouyaqian, 13210240002, qz, xjhuang}@fudan.edu.cnAbstractMicroblogging services have attracted hundreds of millions of users to publish their status, ideasand thoughts, everyday.
These microblog posts have also become one of the most attractive andvaluable resources for applications in different areas.
The task of identifying the main targets ofmicroblogs is an important and essential step for these applications.
In this paper, to achieve thistask, we propose a novel method which converts the target company identification problem tothe translation process from content to targets.
We introduce a topic-specific generative methodto model the translation process.
Topic specific trigger words are used to bridge the vocabularygap between the words in microblogs and targets.
We examine the effectiveness of our approachvia datasets gathered from real world microblogs.
Experimental results demonstrate a 20.2%improvement in terms of F1-score over the state-of-the-art discriminative method.1 IntroductionWith the rapid growth of social media, about 72% of adult internet users are also members ofa social networking site1.
Over the past few years, microblogging has become one of the mostpopular services.
Meanwhile, microblogs have also been widely used as sources for analyzing publicopinions (Bermingham and Smeaton, 2010; Jiang et al., 2011), prediction (Asur and Huberman, 2010;Bollen et al., 2011), reputation management (Pang and Lee, 2008; Otsuka et al., 2012), and many otherapplications (Bian et al., 2008; Sakaki et al., 2010; Becker et al., 2010; Guy et al., 2010; Lee and Croft,2013; Guy et al., 2013).
For most of these applications, identifying the microblogs that are relevant tothe targets of interest is one of the basic steps (Lin and He, 2009; Amig?o et al., 2010; Qiu et al., 2011;Liu et al., 2013).
Let us firstly consider the following example:Example 1: 11?
MacBook Air can run for up to five hours on a single charge.
?MacBook Air?
can be considered to be the target being discussed on the microblog, and we can alsoinfer from the microblog that it is related to Apple Inc.
The ability to discriminate which company isbeing referred to in a microblog is required by many applications.Previous studies on fine-grained sentiment analysis and aspect-based opinion mining proposedsupervised (Popescu and Etzioni, 2005; Liu et al., 2012a; Liu et al., 2013) and unsupervised methods (Huand Liu, 2004; Wu et al., 2009; Zhang et al., 2010) to extract targets of opinion expressions.
Based onthe associations between opinion targets and opinion words, some methods were also introduced tosimultaneously solve the opinion expression and target extraction problems (Qiu et al., 2011; Liu et al.,2012a).
However, most of the existing methods in this area only focus on extracting items about whichopinions are expressed in a given domain.
The implicated information of targets is rarely considered.Moreover, domain adaptation is another big challenge for these fine-grained methods in processingdifferent domains.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1It is reported by the Pew Research Center?s Internet & American Life Project in Aug 5, 2013.688The WePS-32(Amig?o et al., 2010) and RepLab 20133(Amig?o et al., 2013) evaluation campaigns alsoaddressed the problem from the perspective of the disambiguation of company names in microblogs.Microblogs that contain company names at a lexical level are classified based on whether it refersto the company or not.
Various approaches have been proposed to address the task with differentmethods (Pedersen et al., 2006; Yerva et al., 2010; Zhang et al., 2012; Spina et al., 2012; Spina etal., 2013).
However, the microblogs that do not contain company names cannot be correctly processedusing these methods.
From analyzing the data, we observe that a variety of microblog posts belong tothis type.
They only contain products names, slang terms, and other related company content.To achieve this task, in this paper, we propose the use of a translation based model to identify the targetsof microblogs.
We assume that the microblog posts and targets describe the same topic using differentlanguages.
Hence, the target identification problem can be regarded as a translation process from thecontent of the microblogs to the targets.
We integrate latent topical information into the translationmodel to facilitate the translation process.
Because product names, series, and other related informationare important indicators for this task, we also incorporate this background knowledge into the model.
Toevaluate the proposed method, we collect a large number of microblogs and manually annotate a subsetof these as golden standards.
We compare the proposed method with state-of-the-art methods using theconstructed dataset.
Experimental results demonstrate that the proposed approach can achieve betterperformance than the other approaches.2 The Proposed Method2.1 The Generation ProcessGiven a corpus D = {di, 1 ?
i ?
|D|}, which contains a list of microblogs {di}.
A microblog is asequence of Ndwords denoted by wd= {wd1, wd2, ..., wdNd}.
Each microblog contains a set of targetsdenoted by cd= {cd1, cd2, ..., cdMd}.
A word is defined as an item from a vocabulary with V distinctwords indexed by w = {w1, w2, ..., wV}.
The nth word in the dth microblog is associated with not onlyone topic zdn, but also an indicator variable ldnwhich indicates whether wdnbelongs to the ontology(ldn= 1), which contains company names, product names, series, and other related information, or is acommon word (ldn= 0).
Each target is from the vocabulary with C distinct company names indexed byc = {c1, c2, ..., cC}.
The mth target in the dth microblog is associated with a topic zdm.
The notationsused in this paper are summarized in Table 1.
Fig.
1 shows the graphical representation of the generationprocess.
The generative story for each microblog is as follows:1.
Sample word distribution ?t,lfromDir(?l) for each topic t = 1, 2, ..., T and each label l = 1, ..., L.2.
For each microblog d=1,2,...,|D|a.
Sample topic distribution ?dfrom Dir(?)b.
For each word n = 1, 2, ..., Ndi.
Sample a topic zdn= t from Multinomial(?d)ii.
Sample a label ldn= l from the distribution over labels, vd,niii.
Sample a wordw according to multinomial distribution P (wdn= w|zdn= t, ldn= l, ?t,l)c. For each target m = 1, 2, ...,Mdi.
Sample a topic zdm= t from Multinomial(?d)ii.
Sample a target cdm= c according to probability P (cdm= c|wd, ld, zdm= t, B)As described above, we use ldnto incorporate the ontology information into the model.
In this work,we construct an ontology which contains 4,926 company names, 7,632 abbreviations, and 26,732 productnames.
These companies names are collected based on the top search queries in different categories4.We propose to use the distribution vd,nto indicate the probability of variable ldn.
We set vd,nby applying2http://nlp.uned.es/weps/weps-33http://www.limosine-project.eu/events/replab20134http://top.baidu.com/boards689wdnzdn?d?cdmzdmB?t,l?lldnvd,nfdn?MdNd|D|VTLFigure 1: The graphical representation of the proposed model.
Shaded circles are observations orconstants.
Unshaded ones are hidden variables.various sources of ontology (presented by ?)
and the context features of the word wdn(presented by fdn).In this work, we only consider the word itself as its context feature.
This information is encoded intothe hyperparameters {?w|w ?
{w1, w2, ..., wV}}, where ?wis hyperparameter for the word w, and?w0+ ?w1= 1.
For each word w in the ontology, we set ?w1to a value 0.9, ?w0to a value 0.1.
For eachword w not contained by ontology, we set ?w1to a value 0 and ?w0to a value 1.
Based on the ontology,vd,ncould be set as follows:P (ldn= l|wdn= w) = vd,nl=?wl?w1+ ?w0, l ?
{0, 1}(1)2.2 Model InferenceWe use collapsed Gibbs sampling (Griffiths and Steyvers, 2004) to obtain samples of hidden variableassignment and to estimate the model parameters from these samples.On the microblog content side, the conditional probability of a latent topic and label for the nth wordin the dth microblog is:Pr(zdn= t, ldn= l|wdn= w,w?n, z?n, l?n) ?
?wl?w1+ ?w0?Nw,?nt,l+ ?lN?nt,l+ V ?l?Nt,?nd+ ?N?nd+ T?,(2)where Nw,?nt,lis the number of the word w that are assigned to topic t under the label l; N?nt,lis thenumber of all the words that are assigned to topic t under the label l; Nt,?ndis the number of topic t inthe microblog d; N?ndis the number of all the topics in the document d; ?n indicates taking no accountof the current position n.Given the conditional probability of zdn= t, ldn= l, we formalize the marginal probability of zdn= tas follows:Pr(zdn= t|wdn= w,w?n, z?n, l?n) ?L?1?l=0?wl?w1+ ?w0?Nw,?nt,l+ ?lN?nt,l+ V ?l?Nt,?nd+ ?N?nd+ T?
(3)690Table 1: The notation used in the proposed model.|D| The number of microblogs in the data setV The number of unique words in the vocabularyC The number of companiesT The number of topicsL The number of labelsNdThe number of words in the dth microblogMdThe number of companies in the dth microblogwdAll the words in the dth microblogcdAll the targets in the dth microblogzdThe topic of the words in the dth microblogldThe label of the words in the dth microblogB The topic-specific word alignment table between a word and a target?t,lDistribution of words for each topic t and each label l?dDistribution of topics in microblog dvd,nDistribution of labels for word wdnNw,?nt,lThe number of the word w that is assigned to topic t under the label l except the position nN?nt,lThe number of all the words that are assigned to topic t under the label l. except the position nNt,?ndThe number of topic t in the microblog d except the position nN?ndThe number of all the topics in the microblog d except the position nNc,wt,lThe number of the target c that co-occurs with the word w labeled as l under topic tAfter re-assigning the topic zdn= t for the current word, the conditional probability of ontology labelfor the nth word in the dth microblog is:Pr(ldn= l|wdn= w, zdn= t,w?n, z?n, l?n) ?
?wl?w1+ ?w0?Nw,?nt,l+ ?lN?nt,l+ V ?l(4)On the target side, we perform topic assignments for each target as follows:Pr(zdm= t|cdm= c, c?m,w, l, z?m) ?Nd?n=1?ldnNc,wdn,?mt,ldnNwdnt,ldn+ ?C?Nt,?md+ ?N?md+ T?,(5)where ?ldnis the weight for the label (?1> 1, ?0= 1); Nc,wdn,?mt,ldnis the number of the company c thatco-occurs with the word wdnlabeled as ldnunder topic t; ?C is a smoothing part; Nwdnt,ldnis the number ofthe word wdnlabeled as ldnunder topic t; Nt,?mdis the number of occurrences of topic t in the documentd; N?mdis the number of occurrences of all the topics in the document d; ?m indicates taking no accountof the current position m.Based on the above equations, after enough sampling iterations, we can estimate word alignment tableB, Bc,w,t,l= ?lNc,wt,lNwt,l+?C.
Some companies just occur few times, and most of the words co-occur withthem also alignment with other companies, for this case, we use ?C to smooth, where C represent thenumber of company c. And also we can estimate topic distribution ?
for each document, and worddistribution ?
for each topic and each label, as follows:?td=Ntd+ ?Nd+ T?, ?t,lw=Nwt,l+ ?lNt,l+ V ?lThe possibility table Bc,w,t,lhas a potential size of V ?C ?T ?L.
The data sparsity may pose a problemin estimating Bc,w,t,l.
To reduce the data sparsity problem, we introduce the remedy in our model.
We691employ a linear interpolation with topic-free word alignment probability to avoid data sparsity problem:B?c,w,t,l= ?Bc,w,t,l+ (1?
?
)P (c|w),(6)where P (c|w) is topic-free word alignment probability between the word w and the company c. ?
istrade-off of two probabilities ranging from 0.0 to 1.0.2.3 Target Company ExtractionJust like standard LDA, the proposed method itself finds a set of topics but does not directly extracttargets.
Suppose we have a dataset which contains microblogs without targets, we can use the collapsedGibbs sampling to estimate the topic and label for the words in each microblog.
The process is the sameas described in Section 3.2.After the hidden topics and label of the words in each microblog become stable, we can estimate thedistribution of topics for the dth microblog by: P (t|wd) = ?td=Ntd+?Nd+T?.
With the word alignment tableB?, we can rank companies for the dth microblog in unlabeled data by computing the scores:Pr(cdm|wd) ?T?t=1Nd?n=1P (cdm|t, wdn, ldn, B?)
?
P (t|wd)P (wdn|wd),(7)where P (wdn|wd) is the weight of the word wdnin the microblog content wd.
In this paper, we useinverse document frequency (IDF) score to estimate it.
Based on the ranking scores calculated by Eq.
(7),we can extract the top-ranked targets for each microblog to users.3 ExperimentsIn this section, we will introduce the experimental results and datasets we constructed for training andevaluation.
We will firstly describe the how we construct the datasets and their statistics.
Then wewill introduce the experiment configurations and baseline methods.
Finally, the evaluation results andanalysis will be given.3.1 DatasetsWe started by using Sina Weibo?s API5to collect public microblogs from randomly selected users.
Thedataset contains 282.2M microblogs published by 1.1M users.
We use RAW-Weibo to represent it in thefollowing sections.
Based on the collected raw microblogs, we constructed three datasets for evaluationand training.3.1.1 Training dataSince social media users post thoughts, ideas, or status on various topics in social medias, there are ahuge number of related companies.
Manually constructing training data is a time consuming and costprocess.
In this work, we propose a weakly manual method based on ontology and hashtag.
A hashtag isa string of characters preceded by the symbol #.
In most cases, hashtags can be viewed as an indicationto the context of the tweet or as the core idea expressed in the tweet.
Hence, we can use hashtag as thetargets.We extract the microblogs whose hashtags contain ontology items as training data and thecorresponding ontology items as targets.
Obviously, the training data constructed based on this methodis not perfect.
However, since this method can effectively generate a great quantity of data, we thinkthat general characteristics can be modeled with the generated training data.
To evaluate the corpus,we randomly selected 100 microblogs from the training data and manually labeled their targets.
Theaccuracy of the sampled dataset is 91%.
It indicates that the proposed training data generation methodis effective.
From the RAW-Weibo dataset, we extracted a total of 1.79M microblogs whose hashtagscontain more than one target.
Training instances for 2,574 target companies are included in the trainingdata.5http://open.weibo.com/6923.1.2 Test dataFor evaluation, we manually constructed a dataset RAN-Weibo, which contains 2,000 microblogs selectedfrom RAW-Weibo.
Three annotators were asked to label the target companies for each microblog.
Toevaluate the quality of annotated dataset, we validate the agreements of human annotations using Cohen?skappa coefficient.
The average ?
among all annotators is 0.626.
It indicates that the annotations arereliable.Since some targets are ambiguous, inspired by the evaluation campaigns WePS-3 and RepLab 2013,we also constructed a dataset AMB-Weibo, where microblogs include 10 popular company names whichmay cause ambiguity.
For each target, we randomly selected and annotated 200 microblogs as goldenstandards.
Three annotators were also asked to label whether the microblog is related the given target ornot.
The agreements of human annotations were also validated through Cohen?s kappa coefficient.
Theaverage ?
among all annotators is 0.692.3.2 Experiment ConfigurationsWe use precision (P ), recall (R), and F1-score (F1) to evaluate the performance.
We ran our modelwith 500 iterations of Gibbs sampling.
We use 5-fold cross-validation in the training data to optimizehyperparameters.
The number of topics is set to 30.
The other settings of hyperparameters are as follows:?
= 50/T , ?
= 0.1, ?
= 20, ?
= 0.5.
The smoothing parameter ?
is set to 0.8.For baselines, we compare the proposed model with the following baseline methods.?
Naive Bayes (NB): The target identification task can be easily formalized as a classification task,where each target is considered as a classification label.
Hence, we applied Naive Bayes to modelthe posterior probability of each target given a microblog.?
Support Vector Machine (SVM): The content of microblogs are represented as vectors and SVMis used to model the classification problem.?
IBM1: Translation model (IBM model-1) is applied to obtain the alignment probability betweenwords and targets.?
TTM: Topical translation model (TTM) was proposed by Ding et al.
(2013) to achieve microbloghashtag suggestion task.
We adopted it to estimate the alignment probability between words andtargets.3.3 Experimental ResultsWe evaluate the proposed method from the following perspectives: 1) comparing the proposed methodwith the state-of-the-art methods on the two evaluation datasets; 2) identifying the impacts of parameters.Table 2 shows the comparisons of the proposed method with the state-of-the-arts discriminativeand generative methods on the evaluation dataset RAN-Weibo.
?Our?
denotes the method proposedin previous sections.
?Our w/o BG?
represents the proposed method without background knowledge.From the results, we can observe that the proposed method is better than other methods.
Discriminativemethods achieve worse results than generative methods.
We think that the large number of targets isone of the main reasons of the low performances.
The results of the proposed models with and withoutontology information also show that background knowledge can benefit both the precision and recall.TTM achieves better performance than IBM1.
It indicates that topical information is useful for thistask.
The performances of our method are significantly better than TTM.
It illustrates that our smoothingmethod and incorporation of background knowledge are effective.From the description of the proposed model, we can know that there are several hyperparameters inthe proposed model.
To evaluate the impacts of them, we evaluate two crucial ones among all of them,the number of topics T and the smoothing factor ?.
Table 3 shows the influence of the number of topics.From the table, we can observe that the proposed model obtains the best performance when T is set to30.
And performance decreases with more number of topics.
We think that data sparsity may be one ofthe main reasons.
With much more topic number, the data sparsity problem will be more serious when693Table 2: Evaluation results of NB, SVM, IBM1, TTM, and our method on the evaluation dataset RAN-Weibo.Methods Precision Recall F1NB 0.168 0.154 0.161SVM 0.312 0,286 0.298IBM1 0.236 0.214 0.220TTM 0.356 0.327 0.341Our w/o BG 0.488 0.448 0.467Our 0.522 0.479 0.500Table 3: The influence of the number of topics T of the proposed method.T Precision Recall F110 0.516 0.473 0.49330 0.522 0.479 0.50050 0.508 0.466 0.48670 0.489 0.449 0.468100 0.488 0.448 0.467estimating topic-specific translation probability.
Table 4 shows the influence of the translation probabilitysmoothing parameter ?.
When ?
is set to 0.0, it means that the topical information is omitted.
Comparingthe results of ?
= 0.0 and other values, we can observe that the topical information can benefit this task.When ?
is set to 1.0, it represents the method without smoothing.
The results indicate that it is necessaryto address the sparsity problem through smoothing.Figure 2 shows the results of different methods on the dataset AMB-Weibo.
All the models are trainedwith same dataset as the above experiments.
From the results, we can observe that the F1-scores varyfrom less than 0.40 up to almost 0.60.
The performances?
variations of other methods are also huge.
Wethink that training data size and difficulty level are two main reasons.
The size of training data of differenttargets vary greatly in the dataset.
However, comparing with other method, the proposed method is themost stable one.
Comparing with other methods, the proposed method achieves better performance thanother methods for all targets.4 Related WorkOrganization name disambiguation task is fundamental problems in many NLP applications.
The taskaims to distinguish the real world relevant of a given name with the same surface in context.
WePS-36(Amig?o et al., 2010) and RepLab 20137(Amig?o et al., 2013) evaluation campaigns have also addressedthe problem from the perspective of disambiguation organization names in microblogs.
Pedersen etal.
(2006) proposed an unsupervised method for name discrimination.
Yerva et al.
(2010) used supportvector machines (SVM) classifier with various external resources, such as WordNet, metadata profile,category profile, Google set, and so on.
Kozareva and Ravi (2011) proposed to use latent dirichletallocation to incorporate topical information.
Zhang et al.
(2012) proposed to use adaptive method forthis task.
However, most of these methods focused on the text with predefined surface words.
Thedocuments which do not contain organization names or person names can not be well processed by thesemethods.To bridge the vocabulary gap between content and hashtags, Liu et al.
(2012b) proposed to usetranslation model to handle it.
They modeled the tag suggestion task as a translation process from6http://nlp.uned.es/weps/weps-37http://www.limosine-project.eu/events/replab2013694Table 4: The influence of the smoothing parameter ?
of the propose method.?
Precision Recall F10.0 0.471 0.432 0.4510.2 0.490 0.449 0.4690.4 0.495 0.454 0.4740.6 0.511 0.468 0.4890.8 0.522 0.479 0.5001.0 0.519 0.476 0.49600.10.20.30.40.50.60.71 2 3 4 5 6 7 8 9 10F1-ScoreNB SVM IBM1 TTM Our w/o BG OurFigure 2: Evaluation results of NB, SVM, IBM1, TTM, and our method on the different companies inthe test dataset AMB-Weibo.document content to tags.
Ding et al.
(2013) extended the translation based method and introduced atopic-specific translation model to process the multiple meanings of words in different topics.
Motivatedby these methods, we also propose to use topic-specific translation model to handle vocabulary problem.Based on the model, in this work, we incorporate the background knowledge information into the model.5 ConclusionsTo identify target companies of microblogs, in this paper, we propose a novel topical translationmodel to achieve the task.
The main assumption is that the microblog posts and targets describethe same thing with different languages.
We convert the target identification problem to a translationprocess from content of microblogs to targets.
We integrate latent topical information into translationmodel to hand the themes of microblogs in facilitating the translation process.
We also incorporatebackground knowledge (such as product names, series, et al.)
into the generation model.
Experimentalresults on a large corpus constructed from a real microblog service and a number of manually labeledgolden standards of easily ambiguous entities demonstrate that the proposed method can achieve betterperformance than other approaches.6 AcknowledgementThe authors wish to thank the anonymous reviewers for their helpful comments.
This work waspartially funded by 973 Program (2010CB327900), National Natural Science Foundation of China(61003092,61073069), Shanghai Leading Academic Discipline Project (B114) and ?Chen Guang?project supported by Shanghai Municipal Education Commission and Shanghai Education DevelopmentFoundation(11CG05).695ReferencesEnrique Amig?o, Javier Artiles, Julio Gonzalo, Damiano Spina, Bing Liu, and Adolfo Corujo.
2010.Weps3 evaluation campaign: Overview of the on-line reputation management task.
In CLEF (NotebookPapers/LABs/Workshops).Enrique Amig?o, Jorge Carrillo de Albornoz, Irina Chugur, Adolfo Corujo, Julio Gonzalo, Tamara Mart?
?n, EdgarMeij, Maarten Rijke, and Damiano Spina.
2013.
Overview of replab 2013: Evaluating online reputationmonitoring systems.
In Information Access Evaluation.
Multilinguality, Multimodality, and Visualization,volume 8138 of Lecture Notes in Computer Science, pages 333?352.
Springer Berlin Heidelberg.S.
Asur and B.A.
Huberman.
2010.
Predicting the future with social media.
In Proceedings of WI-IAT 2010.Hila Becker, Mor Naaman, and Luis Gravano.
2010.
Learning similarity metrics for event identification in socialmedia.
In Proceedings of WSDM ?10.Adam Bermingham and Alan F. Smeaton.
2010.
Classifying sentiment in microblogs: is brevity an advantage?
InProceedings of CIKM ?10.Jiang Bian, Yandong Liu, Eugene Agichtein, and Hongyuan Zha.
2008.
Finding the right facts in the crowd:factoid question answering over social media.
In Proceedings of WWW ?08.Johan Bollen, Huina Mao, and Xiaojun Zeng.
2011.
Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1 ?
8.Zhuoye Ding, Xipeng Qiu, Qi Zhang, and Xuanjing Huang.
2013.
Learning topical translation model formicroblog hashtag suggestion.
In Proceedings of IJCAI 2013.Thomas L. Griffiths and Mark Steyvers.
2004.
Finding scientific topics.
In Proceedings of the National Academyof Sciences, volume 101, pages 5228?5235.Ido Guy, Naama Zwerdling, Inbal Ronen, David Carmel, and Erel Uziel.
2010.
Social media recommendationbased on people and tags.
In Proceedings of SIGIR ?10.Ido Guy, Uri Avraham, David Carmel, Sigalit Ur, Michal Jacovi, and Inbal Ronen.
2013.
Mining expertise andinterests from social media.
In Proceedings of WWW ?13.Minqing Hu and Bing Liu.
2004.
Mining opinion features in customer reviews.
In Proceedings of AAAI?04.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao.
2011.
Target-dependent twitter sentimentclassification.
In Proceedings of ACL-HLT 2011, Portland, Oregon, USA.Zornitsa Kozareva and Sujith Ravi.
2011.
Unsupervised name ambiguity resolution using a generative model.In Proceedings of the First Workshop on Unsupervised Learning in NLP, EMNLP ?11, pages 105?112,Stroudsburg, PA, USA.
Association for Computational Linguistics.Chia-Jung Lee and W. Bruce Croft.
2013.
Building a web test collection using social media.
In Proceedings ofSIGIR ?13, SIGIR ?13.Chenghua Lin and Yulan He.
2009.
Joint sentiment/topic model for sentiment analysis.
In Proceedings of CIKM?09.Kang Liu, Liheng Xu, and Jun Zhao.
2012a.
Opinion target extraction using word-based translation model.
InProceedings of EMNLP-CoNLL ?12.Zhiyuan Liu, Chen Liang, and Maosong Sun.
2012b.
Topical word trigger model for keyphrase extraction.
InProceedings of COLING.Kang Liu, Liheng Xu, and Jun Zhao.
2013.
Syntactic patterns versus word alignment: Extracting opinion targetsfrom online reviews.
In Proceedings of ACL 2013, Sofia, Bulgaria.Takanobu Otsuka, Takuya Yoshimura, and Takayuki Ito.
2012.
Evaluation of the reputation network using realisticdistance between facebook data.
In Proceedings of WI-IAT ?12, Washington, DC, USA.Bo Pang and Lillian Lee.
2008.
Opinion mining and sentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135,January.696Ted Pedersen, Anagha Kulkarni, Roxana Angheluta, Zornitsa Kozareva, and Thamar Solorio.
2006.
Anunsupervised language independent method of name discrimination using second order co-occurrence features.In Computational Linguistics and Intelligent Text Processing, pages 208?222.Ana-Maria Popescu and Oren Etzioni.
2005.
Extracting product features and opinions from reviews.
InProceedings of HL-EMNLP 2005, Vancouver, British Columbia, Canada.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011.
Opinion word expansion and target extraction throughdouble propagation.
Comput.
Linguist., 37(1):9?27, March.Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010.
Earthquake shakes twitter users: real-time eventdetection by social sensors.
In Proceedings of the 19th international conference on World wide web, WWW?10, pages 851?860, New York, NY, USA.
ACM.Damiano Spina, Edgar Meij, Maarten de Rijke, Andrei Oghina, Minh Thuong Bui, and Mathias Breuss.
2012.Identifying entity aspects in microblog posts.
In Proceedings of SIGIR ?12.Damiano Spina, Julio Gonzalo, and Enrique Amig?o.
2013.
Discovering filter keywords for company namedisambiguation in twitter.
Expert Systems with Applications, 40(12):4986 ?
5003.Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu.
2009.
Phrase dependency parsing for opinion mining.In Proceedings of EMNLP 2009, Singapore.Surender Reddy Yerva, Zoltn Mikls, and Karl Aberer.
2010.
It was easy, when apples and blackberrieswere only fruits.
In Martin Braschler, Donna Harman, and Emanuele Pianta, editors, CLEF (NotebookPapers/LABs/Workshops).Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O?Brien-Strain.
2010.
Extracting and ranking product featuresin opinion documents.
In Proceedings of COLING ?10.Shu Zhang, Jianwei Wu, Dequan Zheng, Yao Meng, and Hao Yu.
2012.
An adaptive method for organization namedisambiguation with feature reinforcing.
In Proceedings of the 26th Pacific Asia Conference on Language,Information, and Computation, pages 237?245, Bali,Indonesia, November.
Faculty of Computer Science,Universitas Indonesia.697
