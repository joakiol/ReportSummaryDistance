Proceedings of the 6th Workshop on Building and Using Comparable Corpora, pages 121?128,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsGathering and Generating Paraphrases from Twitterwith Application to NormalizationWei Xu+ Alan Ritter?
Ralph Grishman++New York University, New York, NY, USA{xuwei, grishman}@cs.nyu.edu?University of Washington, Seattle, WA, USAaritter@cs.washington.eduAbstractWe present a new and unique para-phrase resource, which contains meaning-preserving transformations between infor-mal user-generated text.
Sentential para-phrases are extracted from a compara-ble corpus of temporally and topicallyrelated messages on Twitter which of-ten express semantically identical infor-mation through distinct surface forms.
Wedemonstrate the utility of this new re-source on the task of paraphrasing andnormalizing noisy text, showing improve-ment over several state-of-the-art para-phrase and normalization systems 1.1 IntroductionSocial media services provide a massive amountof valuable information and demand NLP toolsspecifically developed to accommodate their noisystyle.
So far not much success has been reportedon a key NLP technology on social media data:paraphrasing.
Paraphrases are alternative ways toexpress the same meaning in the same languageand commonly employed to improve the perfor-mance of many other NLP applications (Madnaniand Dorr, 2010).
In the case of Twitter, Petrovic?
etal.
(2012) showed improvements on first story de-tection by using paraphrases extracted from Word-Net.Learning paraphrases from tweets could be es-pecially beneficial.
First, the high level of in-formation redundancy in Twitter provides a goodopportunity to collect many different expressions.Second, tweets contain many kinds of paraphrasesnot available elsewhere including typos, abbre-viations, ungrammatical expressions and slang,1Our Twitter paraphrase models are availableonline at https://github.com/cocoxu/twitterparaphrase/which can be particularly valuable for many appli-cations, such as phrase-based text normalization(Kaufmann and Kalita, 2010) and correction ofwriting mistakes (Gamon et al 2008), given thedifficulty of acquiring annotated data.
Paraphrasemodels that are derived from microblog data couldbe useful to improve other NLP tasks on noisyuser-generated text and help users to interpret alarge range of up-to-date abbreviations (e.g.
dlt ?Doritos Locos Taco) and native expressions (e.g.oh my god ?
{oh my goodness | oh my gosh | ohmy gawd | oh my jesus}) etc.This paper presents the first investigation intoautomatically collecting a large paraphrase cor-pus of tweets, which can be used for buildingparaphrase systems adapted to Twitter using tech-niques from statistical machine translation (SMT).We show experimental results demonstrating thebenefits of an in-domain parallel corpus whenparaphrasing tweets.
In addition, our paraphrasemodels can be applied to the task of normalizingnoisy text where we show improvements over thestate-of-the-art.Relevant previous work has extracted sentence-level paraphrases from news corpora (Dolan etal., 2004; Barzilay and Lee, 2003; Quirk et al2004).
Paraphrases gathered from noisy user-generated text on Twitter have unique character-istics which make this comparable corpus a valu-able new resource for mining sentence-level para-phrases.
Twitter also has much less context thannews articles and much more diverse content, thusposing new challenges to control the noise in min-ing paraphrases while retaining the desired super-ficial dissimilarity.2 Related WorkThere are several key strands of related work, in-cluding previous work on gathering parallel mono-lingual text from topically clustered news articles,normalizing noisy Twitter text using word-based121models, and applying out-of-domain paraphrasesystems to improve NLP tasks in Twitter.On the observation of the lack of a large para-phrase corpus, Chen and Dolan (2011) have re-sorted to crowdsourcing to collect paraphrases byasking multiple independent users for descriptionsof the same short video.
As we show in ?5, how-ever, this data is very different from Twitter, soparaphrase systems trained on in-domain Twitterparaphrases tend to perform much better.The task of paraphrasing tweets is also relatedto previous work on normalizing noisy Twitter text(Han and Baldwin, 2011; Han et al 2012; Liuet al 2012).
Most previous work on normaliza-tion has applied word-based models.
While thereare challenges in applying Twitter paraphrase sys-tems to the task of normalization, access to paral-lel text allows us to make phrase-based transfor-mations to the input string rather than relying onword-to-word mappings (for more details see ?4).Also relevant is recent work on collecting bilin-gual parallel data from Twitter (Jehl et al 2012;Ling et al 2013).
In contrast, we focus on mono-lingual paraphrases rather than multilingual trans-lations.Finally we highlight recent work on apply-ing out-of-domain paraphrase systems to improveperformance at first story detection in Twitter(Petrovic?
et al 2012).
By building better para-phrase models adapted to Twitter, it should be pos-sible to improve performance at such tasks, whichbenefit from paraphrasing Tweets.3 Gathering A Parallel Tweet CorpusThere is a huge amount of redundant informationon Twitter.
When significant events take place inthe world, many people go to Twitter to share,comment and discuss them.
Among tweets onthe same topic, many will convey similar mean-ing using widely divergent expressions.
Whereasresearchers have exploited multiple news reportsabout the same event for paraphrase acquisition(Dolan et al 2004), Twitter contains more vari-ety in terms of both language forms and types ofevents, and requires different treatment due to itsunique characteristics.As described in ?3.1, our approach first identi-fies tweets which refer to the same popular eventas those which mention a unique named entity anddate, then aligns tweets within each event to con-struct a parallel corpus.
To generate paraphrases,we apply a typical phrase-based statistical MTpipeline, performing word alignment on the paral-lel data using GIZA++ (Och and Ney, 2003), thenextracting phrase pairs and performing decodinguses Moses (Koehn et al 2007).3.1 Extracting Events from TweetsAs a first step towards extracting paraphrases frompopular events discussed on Twitter, we need away to identify Tweets which mention the sameevent.
To do this we follow previous work by Rit-ter et al(2012), extracting named entities andresolving temporal expressions (for example ?to-morrow?
or ?on Wednesday?).
Because tweets arecompact and self-contained, those which mentionthe same named entity and date are likely to refer-ence the same event.
We also employ a statisticalsignificance test to measure strength of associationbetween each named entity and date, and therebyidentify important events discussed widely amongusers with a specific focus, such as the release ofa new iPhone as opposed to individual users dis-cussing everyday events involving their phones.By gathering tweets based on popular real-worldevents, we can efficiently extract pairwise para-phrases within a small group of closely relatedtweets, rather than exploring every pair of tweetsin a large corpus.
By discarding frequent but in-significant events, such as ?I like my iPhone?
and?I like broke my iPhone?, we can reduce noiseand encourage diversity of paraphrases by requir-ing less lexical overlap.
Example events identifiedusing this procedure are presented in Table 1.3.2 Extracting Paraphrases Within EventsTwitter users are likely to express the same mean-ing in relation to an important event, however notevery pair of tweets mentioning the same eventwill have the same meaning.
People may haveopposite opinions and complicated events such aspresidential elections can have many aspects.
Tobuild a useful monolingual paraphrase corpus, weneed some additional filtering to prevent unrelatedsentence pairs.If two tweets mention the same event and alsoshare many words in common, they are very likelyto be paraphrases.
We use the Jaccard distancemetric (Jaccard, 1912) to identify pairs of sen-tences within an event that are similar at the lexicallevel.
Since tweets are extremely short with littlecontext and include a broad range of topics, usingonly surface similarity is prone to unrelated sen-122Entity/Date Example TweetsVote for Obama on November6th!Obama11/6/2012OBAMA is #winning his 2ndterm on November 6th 2012.November 6th we will re-electObama!
!Bought movie tickets to seeJames Bond tomorrow.
I?m abig #007 fan!James Bond11/9/2012Who wants to go with me andsee that new James Bond movietomorrow?I wanna go see James Bond to-morrowNorth Korea Announces De-cember 29 Launch Date forRocketNorth Korea12/29/2012Pyongyang reschedules launchto December 29 due to ?techni-cal deficiency?North Korea to extend rocketlaunch period to December 29Table 1: Example sentences taken from automat-ically identified significant events extracted fromTwitter.
Because many users express similar in-formation when mentioning these events, there aremany opportunities for paraphrase.tence pairs.
The average sentence length is only11.9 words in our Twitter corpus, compared to18.6 words in newswire (Dolan et al 2004) whichalso contains additional document-level informa-tion.
Even after filtering tweets with both theirevent cluster and lexical overlap, some unrelatedsentence pairs remain in the parallel corpus.
Forexample, names of two separate music venues inthe same city might be mismatched together if theyhappen to have concerts on the same night thatpeople tweeted using a canonical phrasing like ?Iam going to a concert at in Austin tonight?.4 Paraphrasing Tweets forNormalizationParaphrase models built from grammatical text arenot appropriate for the task of normalizing noisytext.
However, the unique characteristics of theTwitter data allow our paraphrase models to in-clude both normal and noisy language and conse-quently translate between them.
Our models havea tendency to normalize because correct spellingsand grammar are most frequently used,2 but thereis still danger of introducing noise.
For the pur-poses of normalization, we therefore biased ourmodels using a language model built using texttaken from the New York Times which is used torepresent grammatical English.Previous work on microblog normalization ismostly limited to word-level adaptation or out-of-domain annotated data.
Our phrase-based mod-els fill the gap left by previous studies by exploit-ing a large, automatically curated, in-domain para-phrase corpus.Lexical normalization (Han and Baldwin, 2011)only considers transforming an out-of-vocabulary(OOV) word to its standard form, i.e.
in-vocabulary (IV) word.
Beyond word-to-word con-versions, our phrase-based model is also able tohandle the following types of errors without re-quiring any annotated data:Error type Ill form Standardform1-to-many everytime every timeincorrect IVs can?t wantforcan?t wait forgrammar I?m going amovieI?m going toa movieambiguities 4 4 / 4th / for /fourKaufmann and Kalita (2010) explored machinetranslation techniques for the normalization taskusing an SMS corpus which was manually anno-tated with grammatical paraphrases.
Microblogs,however, contain a much broader range of contentthan SMS and have no in-domain annotated dataavailable.
In addition, the ability to gather para-phrases automatically opens up the possibility tobuild normalization models from orders of mag-nitude more data, and also to produce up-to-datenormalization models which capture new abbrevi-ations and slang as they are invented.5 ExperimentsWe evaluate our system and several baselinesat the task of paraphrasing Tweets using pre-viously developed automatic evaluation metricswhich have been shown to have high correlationwith human judgments (Chen and Dolan, 2011).2Even though misspellings and grammatical errors arequite common, there is much more variety and less agree-ment.123In addition, because no previous work has evalu-ated these metrics in the context of noisy Twitterdata, we perform a human evaluation in which an-notators are asked to choose which system gen-erates the best paraphrase.
Finally we evaluateour phrase-based normalization system against astate-of-the-art word-based normalizer developedfor Twitter (Han et al 2012).5.1 Paraphrasing Tweets5.1.1 DataOur paraphrase dataset is distilled from a largecorpus of tweets gathered over a one-year periodspanning November 2011 to October 2012 usingthe Twitter Streaming API.
Following Ritter etal.
(2012), we grouped together all tweets whichmention the same named entity (recognized usinga Twitter specific name entity tagger3) and a ref-erence to the same unique calendar date (resolvedusing a temporal expression processor (Mani andWilson, 2000)).
Then we applied a statistical sig-nificance test (the G test) to rank the events, whichconsiders the corpus frequency of the named en-tity, the number of times the date has been men-tioned, and the number of tweets which mentionboth together.
Altogether we collected more than3 million tweets from the 50 top events of each dayaccording to the p-value from the statistical test,with an average of 229 tweets per event cluster.Each of these tweets was passed through a Twit-ter tokenizer4 and a simple sentence splitter, whichalso removes emoticons, URLs and most of thehashtags and usernames.
Hashtags and usernamesthat were in the middle of sentences and mightbe part of the text were kept.
Within each eventcluster, redundant and short sentences (less than 3words) were filtered out, and the remaining sen-tences were paired together if their Jaccard simi-larity was no less than 0.5.
This resulted in a par-allel corpus consisting of 4,008,946 sentence pairswith 800,728 unique sentences.We then trained paraphrase models by applyinga typical phrase-based statistical MT pipeline onthe parallel data, which uses GIZA++ for wordalignment and Moses for extracting phrase pairs,training and decoding.
We use a language modeltrained on the 3 million collected tweets in the de-coding process.
The parameters are tuned over de-3https://github.com/aritter/twitter_nlp4https://github.com/brendano/tweetmotifvelopment data and the exact configuration are re-leased together with the phrase table for systemreplication.Sentence alignment in comparable corpora ismore difficult than between direct translations(Moore, 2002), and Twitter?s noisy style, shortcontext and broad range of content present ad-ditional complications.
Our automatically con-structed parallel corpus contains some proportionof unrelated sentence pairs and therefore does re-sult in some unreasonable paraphrases.
We pruneout unlikely phrase pairs using a technique pro-posed by Johnson et al(2007) with their recom-mended setting, which is based on the significancetesting of phrase pair co-occurrence in the parallelcorpus (Moore, 2004).
We further prevent unrea-sonable translations by adding additional entriesto the phrase table to ensure every phrase has anoption to remain unchanged during paraphrasingand normalization.
Without these noise reductionsteps, our system will produce paraphrases withserious errors (e.g.
change a person?s last name)for 100 out of 200 test tweets in the evaluation in?5.1.5.At the same time, it is also important to promotelexical dissimilarity in the paraphrase task.
Fol-lowing Ritter et.
al.
(2011) we add a lexical sim-ilarity penalty to each phrase pair in our system,in addition to the four basic components (transla-tion model, distortion model, language model andword penalty) in SMT.5.1.2 Evaluation DetailsThe beauty of lexical similarity penalty is that itgives control over the degree of paraphrasing byadjusting its weight versus the other components.Thus we can plot a BLEU-PINC curve to expressthe tradeoff between semantic adequacy and lexi-cal dissimilarity with the input, where BLUE (Pa-pineni et al 2002) and PINC (Chen and Dolan,2011) are previously proposed automatic evalua-tion metrics to measure respectively the two crite-ria of paraphrase quality.To compute these automatic evaluation met-rics, we manually prepared a dataset of gold para-phrases by tracking the trending topics on Twitter5and gathering groups of paraphrases in November2012.
In total 20 sets of sentences were collectedand each set contains 5 different sentences that ex-press the same meaning.
Each sentence is used5https://support.twitter.com/articles/101125-faqs-about-twitter-s-trends124Input OutputHostess is going outta biz hostess is going out of businessREPUBLICAN IMMIGRATION REFORM IS ATHING NOWgop imigration law is a thing nowFreedom Writers will always be one of my favmoviesfreedom writers will forever be one of my favoritemoviessources confirm that Phil Jackson has cancelledall weekend plans and upcoming guest appear-ances, will meet with LAL front officesource confirms that phil jackson has canceled allweekend plans , upcomin guest appearances andwill meet with lakers front officeTable 2: Example paraphrases generated by our system on the test data.once as input while other 4 sentences in the sameset serve as reference translation for automaticevaluation of semantic adequacy using BLEU.5.1.3 BaselinesWe consider two state-of-the-art paraphrase sys-tems as baselines, both of which are trained onparallel corpora of aligned sentences.
The first oneis trained on a large-scale corpus gathered by ask-ing users of Amazon?s Mechanical Turk Service(Snow et al 2008) to write a one-sentence de-scription of a short video clip (Chen and Dolan,2011).
We combined a phrase table and distor-tion table extracted from this parallel corpus withthe same Twitter language model, applying theMoses decoder to generate paraphrases.
The ad-ditional noise removal steps described in ?5.1.1were found helpful for this model during devel-opment and were therefore applied.
The secondbaseline uses the Microsoft Research paraphrasetables that are automatically extracted from newsarticles in combination with the Twitter languagemodel.65.1.4 ResultsFigure 1 compares our system against both base-lines, varying the lexical similarity penalty foreach system to generate BLEU-PINC curves.Our system trained on automatically gatheredin-domain Twitter paraphrases achieves higherBLEU at equivalent PINC for the entire length ofthe curves.
Table 2 shows some sample outputs ofour system on real Twitter data.One novel feature of our approach, comparedto previous work on paraphrasing, is that it cap-tures many slang terms, acronyms, abbreviationsand misspellings that are otherwise hard to learn.6No distortion table or noisy removal process is appliedbecause the parallel corpus is not available.lll ll l l l ll lllllll ll0 20 40 6005101520PINCBLEUl OursVideoMSRFigure 1: Results from automatic paraphrase eval-uation.
PINC measures n-gram dissimilarity fromthe source sentence, whereas BLEU roughly mea-sures n-gram similarity to the reference para-phrases.Several examples are shown in table 3.
The richsemantic redundancy in Twitter helps generate alarge variety of typical paraphrases as well (see anexample in table 4).5.1.5 Human EvaluationIn addition to automatic evaluation, we also per-formed a human evaluation in which annotatorswere asked to pick which system generated thebest paraphrase.
We used the same dataset of200 tweets gathered for the automatic evaluationand generated paraphrases using the 3 systems inFigure 1 with the highest BLEU which achieve aPINC of at least 40.
The human annotators werethen asked to pick which of the 3 systems gener-ated the best paraphrase using the criteria that itshould be both different from the original and also125Input Top-ranked Outputsamped pumpedlemme kno let me knowbb bigbang, big brothersnl nbcsnl, saturday night liveapply 4 tix apply for tickets, ask for tickets,applying for ticketsthe boys one direction (a band, whosemembers are often referred as?the boys?
), they, the boy, thegys, the lads, my boys, the direc-tion (can be used to refer to theband ?one direction?
), the onedi-rection, our boys, our guysoh my god oh my gosh, omfg, thank thelord, omg, oh my lord, thank yougod, oh my jesus, oh godcan?t wait cant wait, cant wait, cannot wait,i cannot wait, so excited, cntwait, i have to wait, i can?wait,ready, so ready, so pumped, seri-ously can?wait, really can?t waitTable 3: Example paraphrases of noisy phrasesand slang commonly found on TwitterInput Top-ranked Outputswho wantto get abeerwants to get a beer, so who wantsto get a beer, who wants to goget a beer, who wants to get beer,who want to get a beer, trying toget a beer, who wants to buy abeer, who wants to get a drink,who wants to get a rootbeer, whotrying to get a beer, who wants tohave a beer, who wants to ordera beer, i want to get a beer, whowants to get me a beer, who elsewants to get a beer, who wants towin a beer, anyone wants to geta beer, who wanted to get a beer,who wants to a beer, someone toget a beer, who wants to receive abeer, someone wants to get a beerTable 4: Example paraphrases of a given sentence?who want to get a beer?Ours Video MSR020406080100120annotator 1annotator 2Figure 2: Number of paraphrases (200 in total)preferred by the annotators for each systemcapture as much of the original meaning as pos-sible.
The annotators were asked to abstain frompicking one as the best in cases where there wereno changes to the input, or where the resultingparaphrases totally lost the meaning.Figure 2 displays the number of times each an-notator picked each system?s output as the best.Annotator 2 was somewhat more conservativethan annotator 1, choosing to abstain more fre-quently and leading to lower overall frequencies,however in both cases we see a clear advantagefrom paraphrasing using in-domain models.
Asa measure of inter-rater agreement, we computedCohen?s Kappa between the annotators judgmentas to whether the Twitter-trained system?s outputbest.
The value of Cohen?s Kappa in this case was0.525.5.2 Phrase-Based NormalizationBecause Twitter contains both normal and noisylanguage, with appropriate tuning, our modelshave the capability to translate between these twostyles, e.g.
paraphrasing into noisy style or nor-malizing into standard language.
Here we demon-strate its capability to normalize tweets at thesentence-level.5.2.1 BaselinesMuch effort has been devoted recently for devel-oping normalization dictionaries for Microblogs.One of the most competitive dictionaries avail-able today is HB-dict+GHM-dict+S-dict used byHan et al(2012), which combines a manually-constructed Internet slang dictionary , a small(Gouws et al 2011) and a large automatically-126derived dictionary based on distributional andstring similarity.
We evaluate two baselines usingthis large dictionary consisting of 41181 words;following Han et.
al.
(2012), one is a simple dic-tionary look up.
The other baseline uses the ma-chinery of statistical machine translation using thisdictionary as a phrase table in combination withTwitter and NYT language models.5.2.2 System DetailsOur base normalization system is the same asthe paraphrase model described in ?5.1.1, exceptthat the distortion model is turned off to excludereordering.
We tuned the system towards cor-rect spelling and grammar by adding a languagemodel built from all New York Times articleswritten in 2008.
We also filtered out the phrasepairs which map from in-vocabulary to out-of-vocabulary words.
In addition, we integrated thedictionaries by linear combination to increase thecoverage of phrase-based SMT model (Bisazza etal., 2011).5.2.3 Evaluation DetailsWe adopt the normalization dataset of Han andBaldwin (2011), which was initially annotatedfor the token-level normalization task, and whichwe augmented with sentence-level annotations.It contains 549 English messages sampled fromTwitter API from August to October, 2010.5.2.4 ResultsNormalization results are presented in figure 5.Using only our phrase table extracted from Twit-ter events we achieve poorer performance than thestate-of-the-art dictionary baseline, however wefind that by combining the normalization dictio-nary of Han et.
al.
(2012) with our automaticallyconstructed phrase-table we are able to combinethe high coverage of the normalization dictionarywith the ability to perform phrase-level normaliza-tions (e.g.
?outta?
?
?out of?
and examples in?4) achieving both higher PINC and BLEU thanthe systems which rely exclusively on word-levelmappings.
Our phrase table also contains manywords that are not covered by the dictionary (e.g.?pts?
?
?points?, ?noms?
?
?nominations?
).6 ConclusionsWe have presented the first approach to gather-ing parallel monolingual text from Twitter, andbuilt the first in-domain models for paraphrasingBLEU PINCNo-Change 60.00 0.0SMT+TwitterLM 62.54 5.78SMT+TwitterNYTLM 65.72 9.23Dictionary 75.07 22.10Dicionary+TwitterNYTLM 75.12 20.26SMT+Dictionary+TwitterNYTLM 77.44 25.33Table 5: Normalization performancetweets.
By paraphrasing using models trainedon in-domain data we showed significant per-formance improvements over state-of-the-art out-of-domain paraphrase systems as demonstratedthrough automatic and human evaluations.
Weshowed that because tweets include both normaland noisy language, paraphrase systems built fromTwitter can be fruitfully applied to the task of nor-malizing noisy text, covering phrase-based nor-malizations not handled by previous dictionary-based normalization systems.
We also make ourTwitter-tuned paraphrase models publicly avail-able.
For future work, we consider developing ad-ditional methods to improve the accuracy of tweetclustering and paraphrase pair selection.AcknowledgmentsThis research was supported in part by NSF grantIIS-0803481, ONR grant N00014-08-1-0431, andDARPA contract FA8750- 09-C-0179.ReferencesRegina Barzilay and Lillian Lee.
2003.
Learn-ing to paraphrase: an unsupervised approach usingmultiple-sequence alignment.
In Proceedings of the2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology - Volume 1, NAACL?03.Arianna Bisazza, Nick Ruiz, and Marcello Federico.2011.
Fill-up versus interpolation methods forphrase-based smt adaptation.
In International Work-shop on Spoken Language Translation (IWSLT), SanFrancisco, CA.David L. Chen and William B. Dolan.
2011.
Collect-ing highly parallel data for paraphrase evaluation.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL-2011),Portland, OR, June.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.
InProceedings of Coling 2004.127Michael Gamon, Jianfeng Gao, Chris Brockett,Alexander Klementiev, William B. Dolan, DmitriyBelenko, and Lucy Vanderwende.
2008.
Using con-textual speller techniques and language modeling foresl error correction.
IJCNLP.S.
Gouws, D. Hovy, and D. Metzler.
2011.
Unsu-pervised mining of lexical variants from noisy text.In Proceedings of the First workshop on Unsuper-vised Learning in NLP, pages 82?90.
Associationfor Computational Linguistics.Bo Han and Timothy Baldwin.
2011.
Lexical normali-sation of short text messages: Makn sens a# twitter.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies, volume 1, pages 368?378.Bo Han, Paul Cook, and Timothy Baldwin.
2012.
Au-tomatically constructing a normalisation dictionaryfor microblogs.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 421?432, Stroudsburg, PA,USA.P.
Jaccard.
1912.
The distribution of the flora in thealpine zone.
New Phytologist, 11(2):37?50.Laura Jehl, Felix Hieber, and Stefan Riezler.
2012.Twitter translation using translation-based cross-lingual retrieval.
In Proceedings of the SeventhWorkshop on Statistical Machine Translation, pages410?421.
Association for Computational Linguis-tics.J.H.
Johnson, J. Martin, G. Foster, and R. Kuhn.
2007.Improving translation quality by discarding most ofthe phrasetable.Max Kaufmann and Jugal Kalita.
2010.
Syntac-tic normalization of twitter messages.
In Interna-tional Conference on Natural Language Processing,Kharagpur, India.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions.Wang Ling, Guang Xiang, Chris Dyer, Alan Black, andIsabel Trancoso.
2013.
Microblogs as parallel cor-pora.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics.Fei Liu, Fuliang Weng, and Xiao Jiang.
2012.
Abroadcoverage normalization system for social me-dia language.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Lin-guistics (ACL 2012), Jeju, Republic of Korea.Nitin Madnani and Bonnie J. Dorr.
2010.
Generatingphrasal and sentential paraphrases: A survey of data-driven methods.
Comput.
Linguist.Inderjeet Mani and George Wilson.
2000.
Robust tem-poral processing of news.
In Proceedings of the38th Annual Meeting on Association for Computa-tional Linguistics, ACL ?00, pages 69?76, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Robert C. Moore.
2002.
Fast and accurate sentencealignment of bilingual corpora.
In Proceedings ofthe 5th Conference of the Association for MachineTranslation in the Americas on Machine Transla-tion: From Research to Real Users, AMTA ?02.Robert C. Moore.
2004.
On log-likelihood-ratios andthe significance of rare events.
In Proceedings of the2004 Conference on Empirical Methods in NaturalLanguage Processing, pages 333?340.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Comput.
Linguist.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics.Sas?a Petrovic?, Miles Osborne, and Victor Lavrenko.2012.
Using paraphrases for improving first storydetection in news and twitter.Chris Quirk, Chris Brockett, and William Dolan.2004.
Monolingual machine translation for para-phrase generation.
In Proceedings of EMNLP 2004.Alan Ritter, Colin Cherry, and William B. Dolan.
2011.Data-driven response generation in social media.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing.Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.2012.
Open domain event extraction from twitter.In KDD, pages 1104?1112.
ACM.Rion Snow, Brendan O?Connor, Daniel Jurafsky, andAndrew Y. Ng.
2008.
Cheap and fast?but is itgood?
: evaluating non-expert annotations for naturallanguage tasks.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?08.128
