Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 457?464Manchester, August 2008Extending a Thesaurus with Words from Pan-Chinese SourcesOi Yee Kwong??
and Benjamin K.
Tsou?
?Department of Chinese, Translation and Linguistics?Language Information Sciences Research CentreCity University of Hong KongTat Chee Avenue, Kowloon, Hong Kong{rlolivia, rlbtsou}@cityu.edu.hkAbstractIn this paper, we work on extending aChinese thesaurus with words distinctlyused in various Chinese communities.The acquisition and classification of suchregion-specific lexical items is an impor-tant step toward the larger goal of con-structing a Pan-Chinese lexical resource.In particular, we extend a previous studyin three respects: (1) to improve auto-matic classification by removing dupli-cated words from the thesaurus, (2) toexperiment with classifying words at thesubclass level and semantic head level,and (3) to further investigate the possibleeffects of data heterogeneity between theregion-specific words and words in thethesaurus on classification performance.Automatic classification was based onthe similarity between a target word andindividual categories of words in the the-saurus, measured by the cosine function.Experiments were done on 120 targetwords from four regions.
The automaticclassification results were evaluatedagainst a gold standard obtained fromhuman judgements.
In general accuracyreached 80% or more with the top 10 (outof 80+) and top 100 (out of 1,300+) can-didates considered at the subclass leveland semantic head level respectively,provided that the appropriate data sourceswere used.?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.1 IntroductionA unique problem in Chinese language process-ing arises from the extensive lexical variationsamong major Chinese speech communities.
Al-though different communities (e.g.
Beijing, HongKong, Taipei and Singapore) often share a largecore lexicon, lexical variations could occur in atleast two ways.
On the one hand, even the sameword forms shared by various communities couldbe used with different meanings.
For instance,the word??
(ju1wu1)1 refers to general hous-ing in Mainland China but specifically to housingunder the Home Ownership Scheme in HongKong.
On the other hand, there are substantiallydifferent lexical items used for lexicalizingcommon or region-specific concepts.
For exam-ple, while the word ??
(zhu4fang2) is similarlyused as ??
to mean general housing inMainland China, it is rarely seen in the HongKong context; and ??
(xia4gang3) is specific,if not exclusive, to Mainland China for referringto a special concept of unemployment.Existing Chinese lexical resources are oftenbased on language use in one particular regionand are therefore not comprehensive enough tocapture the substantial regional variation as animportant part of the lexical knowledge, whichwill be useful and critical for many NLP applica-tions, including natural language understanding,information retrieval, and machine translation.Tsou and Kwong (2006) proposed a compre-hensive Pan-Chinese lexical resource, using alarge and unique synchronous Chinese corpus asan authentic source of lexical variation amongvarious Chinese speech communities.
They alsostudied the feasibility of taking an existing Chi-nese thesaurus as leverage and classifying newwords from various Chinese communities withrespect to the classificatory structure therein(Kwong and Tsou, 2007).
They used the catego-1 The transcriptions in brackets are based on Hanyu Pinyin.457ries at the subclass level of the Tongyici Cilin (????
?, abbreviated as Cilin hereafter) for thetask.
The classification was done by comparingthe similarity of a target word (i.e.
the word to beclassified) and individual categories of words inthe thesaurus based on a feature vector of co-occurring words in a corpus.
Since words in thethesaurus are mostly based on lexical items usedin Mainland China, and the target words comefrom various Chinese communities, a major issuein the classification task is thus the heterogeneityof the data sources.
It was hypothesized that thedatasets from which the features were extracted(for the target words and words in the thesaurusrespectively) may affect the performance ofautomatic classification.
The experimental re-sults supported the hypothesis in part, and theactual effect varied with datasets from individualregions.
Moreover, there is room to improve theoverall accuracy for the method to be useful inpractice, and it appears that the duplicated wordsin the thesaurus might have skewed the similaritymeasurement to a certain extent.The current study thus attempts to extend thisprevious study in three respects: (1) to improveautomatic classification by removing duplicatedwords from the thesaurus, (2) to experiment withclassifying words at the subclass level and se-mantic head level (a finer level), and (3) to fur-ther investigate the possible effects of data het-erogeneity between the region-specific wordsand words in the thesaurus on classification per-formance.In Section 2, we will briefly review relatedwork and the background of the current study.
InSections 3 and 4, we will describe the materialsused and the experimental setup respectively.Results will be presented in Section 5 and dis-cussed in Section 6, followed by a conclusion inSection 7.2 Related WorkTo build a semantic lexicon, one has to identifythe relation between words within a semantichierarchy, and to group similar words togetherinto a class.
Previous work on automatic meth-ods for building semantic lexicons could be di-vided into two main groups.
One is automaticthesaurus acquisition, that is, to identify syno-nyms or topically related words from corporabased on various measures of similarity (e.g.Riloff and Shepherd, 1997; Lin, 1998; Caraballo,1999; Thelen and Riloff, 2002; You and Chen,2006).Another line of research, which is moreclosely related to the current study, is to extendexisting thesauri by classifying new words withrespect to their given structures (e.g.
Tokunaga etal., 1997; Pekar, 2004).
An early effort alongthis line is Hearst (1992), who attempted to iden-tify hyponyms from large text corpora, based ona set of lexico-syntactic patterns, to augment andcritique the content of WordNet.
Ciaramita(2002) compared several models in classifyingnouns with respect to a simplified version ofWordNet and signified the gain in performancewith morphological features.
For Chinese, Tseng(2003) proposed a method based on morphologi-cal similarity to assign a Cilin category to un-known words from the Sinica corpus which werenot in the Chinese Electronic Dictionary andCilin; but somehow the test data were taken fromCilin, and therefore could not really demonstratethe effectiveness with unknown words found inthe Sinica corpus.Kwong and Tsou (2007) attempted to classifywords distinctly used in Beijing, Hong Kong,Singapore, and Taiwan, with respect to the Cilinclassificatory structure.
They brought up the is-sue of data heterogeneity in the task.
In general,automatic classification of words via similaritymeasurement between two words, or between aword and a class of words, was often done onwords from a similar data source, with the as-sumption that the feature vectors under compari-son are directly comparable.
In the Pan-Chinesecontext, however, the words to be classifiedcome from corpora collected from various Chi-nese speech communities, but the words in thethesaurus are often based on usages found in aparticular community, such as Mainland China inthe case of Cilin.
It is thus questionable whetherthe words in Cilin would appear in comparablecontexts in texts from other places, thus affectingthe similarity measurement.
In view of this het-erogeneous nature of the data, they experimentedwith extracting feature vectors for the Cilinwords from different datasets and found that theclassification of words from Taipei was mostaffected in this regard.In general, up to 85% accuracy was reachedwith the top 15 candidates for classification atthe Cilin subclass level.
This performance, how-ever, should be improved for the method to beuseful in practice.
It is observed that Cilin, asmost other thesauri, does not have a mutuallyexclusive classification.
Many words appear inmore than one category (at various levels).
Suchduplication may affect the similarity comparison458between a target word and words in a category.The current study thus attempts to avoid this con-founding factor by removing duplicated wordsfrom Cilin for the comparison of similarity, andto extend the classification to a finer level.3 Materials3.1 The Tongyici CilinThe Tongyici Cilin (?????)
(Mei et al,1984) is a Chinese synonym dictionary, or moreoften known as a Chinese thesaurus in the tradi-tion of the Roget?s Thesaurus for English.
TheRoget?s Thesaurus has about 1,000 numberedsemantic heads, more generally grouped underhigher level semantic classes and subclasses, andmore specifically differentiated into paragraphsand semicolon-separated word groups.
Similarly,some 70,000 Chinese lexical items are organizedinto a hierarchy of broad conceptual categories inCilin.
Its classification consists of 12 top-levelsemantic classes, 94 subclasses, 1,428 semanticheads and 3,925 paragraphs.
It was first pub-lished in the 1980s and was based on lexical us-ages mostly of post-1949 Mainland China.
In thecurrent study, we will focus on the subclass leveland semantic head level.
Some example sub-classes and semantic heads are shown in Table 1.We classify words with respect to the subclasslevel and semantic head level (that is, second andthird levels in the Cilin organisation).
Moreover,we skip class K and class L as the former con-tains mostly function words and the latter longerexpressions.
We are thus considering 88 sub-classes and 1,356 semantic heads in this study.Within classes A to J, there are 7,517 wordswhich were found to appear in more than onecategory.
Upon removing these entries, 44,588words were used in the similarity comparison forthe current study.Class Subclasses Semantic HeadsA ?
(Human) Aa ?
Ae ??
(Occupation)  Af??
(Identity) ?
AnAa01 ?
Ae10 ??
??
??
??
(com-mander, soldier) ?
An07B ?
(Things) Ba ?
Bb ???
(Shape) ?
Bi ??(Animal)?
Bm ??
(Material)?Bq ??
(Clothing) ?
BrBa01 ?
Bm08 ?
?
(coal, carbon) ?
Bn03??
(room) ?
Br14C ?????
(Time andSpace)Ca ??
(Time)  Cb ??
(Space) Ca01 ?
Ca18 ?
(year) ?
Cb28 ??
(loca-tion) ?
Cb30D ????
(Abstract entities)Da ??
??
(Condition) ?
Df ??
(Ide-ology) ?
Di ??
??
(Society) Dj ??
(Economics) ?
Dm ??
(Organization)Dn ??
??
(Quantity)Da01 ?
Di10 ??
??
(group, party) ?Dj04 ??
??
??
??
(capital, interest)Dj05 ??
??
(currency, invoice) ?
Dm01??
(government) ?
Dn10E ??
(Characteristics)Ea ?
Ed ??
(Property)?
Ef Ea01 ?
Ed03 ?
?
(goodness, badness) ?Ef14F ??
(Action) Fa ?
Fd ????
(Body action) Fa01 ?
Fb01 ?
?
(run) ?
Fd09G ????
(Psycho-logical activities)Ga ?
Gb ????
(Psychological activi-ties)?
GcGa01 ?
Gb01 ??
??
??
??
(imag-ine, think) ?
Gc04H ??
(Activities)Ha ?
He ????
(Economic activi-ties) ?
Hd ??
(Production) ?
Hf ????
(Transportation) Hg ????
(Scien-tific research)?
Hi ??
(Social contact)Hj ??
(Livelihood)Ha01 ?
Hc09 ??
??
??
??
??
(incharge, administer, lead) ?
He03 ?
?
(buy,sell) ?
Hg01 ??
??
??
(teach,demo) ?
Hj12 ?
??
??
??
(do, coop-erate, try) ?
Hn13I ?????
(Phe-nomenon and state)Ia ?
If ??
(Circumstance)  Ig ??(Process)?
IhIa01 ?
Ig01 ??
??
(begin, end) ?
Ih05??
??
??
(increase, decrease) ?
Ih13J ??
(Association)Ja ??
(Liaison)  Jb ??
(Similarity andDifference) Jc ??
(Matching) ?
JeJa01 ?
Jc01 ??
??
??
(adapt,match) ?
Je14Table 1  Some Examples of Cilin Subclasses and Semantic Heads3.2 The LIVAC Synchronous CorpusLIVAC (http://www.livac.org) stands for Lin-guistic Variation in Chinese Speech Communi-ties.
It is a synchronous corpus developed anddynamically maintained by the Language Infor-mation Sciences Research Centre of the CityUniversity of Hong Kong since 1995 (Tsou andLai, 2003).
The corpus consists of newspaperarticles collected regularly and synchronouslyfrom six Chinese speech communities, namelyHong Kong, Beijing, Taipei, Singapore, Shang-459hai, and Macau.
Texts collected cover a varietyof domains, including front page news stories,local news, international news, editorials, sportsnews, entertainment news, and financial news.Up to December 2007, the corpus has alreadyaccumulated over 250 million character tokenswhich, upon automatic word segmentation andmanual verification, yielded about 1.2 millionword types.For the present study, we made use of subcor-pora consisting of the financial news sectionscollected over the 9-year period 1995-2004 fromBeijing (BJ), Hong Kong (HK), Singapore (SG),and Taipei (TW).
Table 2 shows the sizes of thesubcorpora.Region Size of Financial Subcorpus(rounded to nearest 1K)Word Token Word TypeBJ 232K 20KHK 970K 38KSG 621K 28KTW 254K 22KTable 2  Sizes of Individual Subcorpora3.3 Test DataKwong and Tsou (2006) observed that among theunique lexical items found from the individualsubcorpora, only about 30-40% are covered byCilin, but not necessarily in the expected senses.In other words, Cilin could in fact be enrichedwith over 60% of the unique items from variousregions.In the current study, we sampled the most fre-quent 30 words distinctly and predominantlyused in each of the BJ, HK, SG, and TW subcor-pus.
Classification was based on their similaritywith each of the Cilin subclasses and semanticheads, compared by the cosine measure, as dis-cussed in Section 4.2.4 Experiments4.1 Setting the Gold StandardThree linguistics undergraduate students and oneresearch student on computational linguisticsfrom the City University of Hong Kong wereasked to assign what they would consider to bethe most appropriate Cilin category (at the sub-class and semantic head level) to each of the 120target words.All human judges reported difficulties in vari-ous degrees in assigning Cilin categories to thetarget words.
The major problem came from theregional specificity and thus the unfamiliarity ofthe judges with the respective lexical items andcontexts.
For example, all judges reported prob-lem with the term ??
(zi4cuo1), one of the tar-get words from Singapore referring to ????
(zi4cuo1gu3shi4, CLOB in the Singaporeanstock market), which is specific to Singapore.Notwithstanding the difficulty, the inter-annotator agreement, as measured by Kappa, wasfound to be 0.6870 at the subclass level and0.5971 at the semantic head level.We took a ?loose?
approach to form the goldstandard, which includes all categories (at thesubclass level and semantic head level respec-tively) assigned by one or more judges.
Auto-matic classification will be considered ?correct?if any of these categories is matched.4.2 Automatic ClassificationEach target word was compared to all Cilin cate-gories and automatically classified to the cate-gory which is most similar to it.
The Cilin datawas first pre-processed to remove duplicatedwords.We compute the similarity by the cosine be-tween the two corresponding feature vectors con-taining all co-occurring content words in a cor-pus within a window of ?5 words (excludingmany general adjectives and adverbs, and num-bers and proper names were all ignored).
Thefeature vector of a Cilin category is based on theunion of the features from all individual mem-bers in the category.The cosine of two feature vectors vv  and wv  iscomputed aswvwvwv vvvvvv ?=),cos(The feature vector of a given target word isextracted from the respective subcorpus fromwhich the target word was found (called the tar-get subcorpus hereafter).
To study the data het-erogeneity effect, we experimented with twoconditions for the extraction of feature vectorsfor Cilin words: from the target subcorpus orfrom the BJ subcorpus which is assumed to berepresentative of usages in Mainland China.All automatic classification results wereevaluated against the gold standard based on hu-460Sub-tw-tw01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline With Duplicates No DuplicatesSub-hk-hk01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline With Duplicates No DuplicatesSub-sg-sg01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline With Duplicates No DuplicatesSub-bj-bj01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline With Duplicates No DuplicatesSub-bj-bj01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline Sub-bj-bjSub-tw-tw and Sub-tw-bj01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline Sub-tw-tw Sub-tw-bjSub-hk-hk and Sub-hk-bj01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline Sub-hk-hk Sub-hk-bjSub-sg-sg and Sub-sg-bj01020304050607080901000 5 10 15Top N CandidatesAccuracy(%)Baseline Sub-sg-sg Sub-sg-bjman judgements as discussed in Section 4.1.Classification performance is measured based onthe correctness of the top N candidates.4.3 BaselineA simple baseline measure was obtained by rank-ing the subclasses in descending order of thenumber of words they cover.
It was assumedthat the bigger the subclass size, the more likelyit covers a new term.
The top N candidates inthis ranking were checked against the gold stan-dard as above.5 ResultsIn the following discussion, we will use labels inthe form of <Cat>-<Target>-<CilinFeatSource>to refer to the various testing conditions, whereCat refers to the category type, Target to theoriginating source of the target words, and Cilin-FeatSource to the source from which the featurevectors for the Cilin words were extracted.
Thusthe label Sub-hk-hk means classification of HKtarget words at the Cilin subclass level, with fea-ture vectors for target words and Cilin words ex-tracted from the HK subcorpus; and the labelHead-tw-bj means classification of TW targetwords at the Cilin semantic head level, with fea-ture vectors for the target words extracted fromthe TW subcorpus and those for the Cilin wordsextracted from the BJ subcorpus.5.1 Pre-processing of CilinFigure 1 shows the comparison of classificationaccuracy for words from the four regions at thesubclass level before and after duplicates in Cilinwere removed.
All feature vectors were ex-tracted from the respective target corpora.Figure 1  Effect of Pre-processing CilinIt can be seen from Figure 1 that removingduplicated words in Cilin could improve the clas-sification of words from all regions at the sub-class level.5.2 Data Heterogeneity EffectAs explained earlier, since the words to be classi-fied come from various Chinese speech commu-nities, but the words in Cilin are mostly based onusages found in Mainland China, it is uncertainwhether the words in Cilin would appear in com-parable contexts in texts from other places, forthe similarity measurement to be effective.Hence, we experimented with two conditions forextracting feature vectors for the Cilin words.While the features for a target word to be classi-fied are extracted from the respective target sub-corpus, the features for the Cilin words are ex-tracted either from the target subcorpus or fromthe BJ subcorpus.
Figure 2 shows the data het-erogeneity effect on the classification of targetwords from various regions at the subclass level.Figure 2  Data Heterogeneity EffectThe data heterogeneity effect is most notice-able for the TW words.
Extracting features forthe Cilin words from the BJ subcorpus alwaysgives better classification results for the TWwords, than if the features were extracted fromthe TW subcorpus.
The difference between Sub-hk-hk and Sub-hk-bj, and that between Sub-sg-sgand Sub-sg-bj, however, is not as great.
Thissuggests that the lexical difference is particularlysignificant between BJ and TW.5.3 Fine-grainedness of ClassificationThe semantic head level is more fine-grainedthan the subclass level, and is expected to be461Head-bj-bj01020304050607080901000 10 20 30 40 50 60 70 80 90 100 110Top N CandidatesAccuracy(%)Head-bj-bjHead-tw-tw and Head-tw-bj01020304050607080901000 10 20 30 40 50 60 70 80 90 100 110Top N CandidatesAccuracy(%)Head-tw-tw Head-tw-bjHead-hk-hk and Head-hk-bj01020304050607080901000 10 20 30 40 50 60 70 80 90 100 110Top N CandidatesAccuracy(%)Head-hk-hk Head-hk-bjHead-sg-sg and Head-sg-bj01020304050607080901000 10 20 30 40 50 60 70 80 90 100 110Top N CandidatesAccuracy(%)Head-sg-sg Head-sg-bjmore difficult for classification.
Figure 3 showsthe results of classification at the semantic headlevel, with the effect of data heterogeneity.Figure 3  Semantic Head Level ClassificationIt is observed from Figures 2 and 3 that dataheterogeneity affects the classification of TWwords at both the subclass and semantic headlevel.
In both cases, features for Cilin words ex-tracted from BJ subcorpus work better than thosefrom TW subcorpus.
A somewhat opposite ef-fect was observed for SG target words, especiallybeyond the top 5 to 10 candidates.
There is notmuch difference for the HK target words.The classification at the semantic head level isexpectedly less precise than that at the subclasslevel.
At the subclass level, 80% or more accu-racy could be reached with the top 10 candidatesconsidered, whereas the top 50 candidates ormore would be needed to reach a similar level ofaccuracy at the semantic head level.
This is nev-ertheless encouraging in view of the total numberof categories at the semantic head level.6 Discussions6.1 Overall Classification AccuracyFrom the results reported in the last section, itcan be seen that removing the duplicated wordsin Cilin could help improve the classificationaccuracy at all conditions.
This is because somewords, which appear in more than one categoryat the subclass or semantic head level, mightskew the similarity measured between a targetword and a given category.
An example will bediscussed in Section 6.3.In general, the top 10 candidates could lead toover 80% accuracy at the subclass level (muchimproved from previous results before removingduplicates in Cilin, where it usually took the top15 candidates to reach about 80% accuracy).
Atthe semantic head level, the top 50 candidatescould lead to over 70% accuracy for HK and TWwords and to 80% or more for BJ and SG words.The accuracy, nevertheless, is also dependent onthe datasets from which features were extracted,as shown in Sections 5.2 and 5.3 above and fur-ther discussed below.6.2 Regional VariationThe various Chinese speech communities mightdiffer not only in the lexical items they use, butalso in the way they use the lexical items incommon.
The demand on cross-cultural knowl-edge thus poses a challenge for building a Pan-Chinese lexical resource manually.
Cilin, forinstance, is quite biased in language use inMainland China, and it requires experts withknowledge of a wide variety of Chinese terms tobe able to manually classify lexical items specificto other Chinese speech communities.
It is there-fore even more important to devise robust waysfor automatic classification of words from vari-ous regions.The data heterogeneity effect is quite differentfor the classification of SG words and TW words,but apparently not very significant for HK words.Beyond the top 5 to 10 candidates, features ex-tracted from the SG subcorpus for Cilin wordsseem to have an advantage.
This suggests thatalthough the SG subcorpus shares those words inCilin, the context in which they are used mightbe slightly different from their use in MainlandChina.
Thus extracting their contextual featuresfrom the SG subcorpus might better reflect theirusage and make them more comparable with thetarget words from SG.
For the TW words, on thecontrary, features for Cilin words extracted fromthe BJ subcorpus always have an advantage overthose extracted from the TW subcorpus.
AsKwong and Tsou (2006) observed, Beijing andTaipei data share the least number of lexicalitems among the four regions under investigation.Words in Cilin therefore might not have the ap-propriate contextual feature vectors extractedfrom the TW subcorpus.6.3 Analysis for Individual WordsIn order to study the actual effect of various ex-perimental conditions on the classification ofindividual target words, we also worked out thechange in the ranking (?r) of the correct categoryfor each target word.
A negative ?r thus corre-462sponds to an improvement in the classification asthe new ranking of the correct category is smaller(earlier) than the old one.
Table 3 shows someexamples with improvement in this regard.
TheRank column refers to the rank of the correctcategory in Sub-{bj,hk,tw,sg}-bj, ?r(D) is thechange after duplicates were removed from Cilin,and ?r(H) is the change from Sub-x-x conditions.No.
Word (Region) Rank ?r(D) ?r(H)1 ???
(BJ) 1 -6 -2 ???
(BJ) 3 -15 -3 ??
(BJ) 1 -1 -4 ??
(BJ) 1 -2 -5 ??
(BJ) 3 -2 -6 ??
(HK) 4 -4 -67 ??
(HK) 2 -3 -68 ???
(HK) 1 -6 -19 ??
(HK) 1 -8 -510 ??
(HK) 2 -4 -511 ??
(SG) 1 -3 -412 ??
(SG) 1 -12 -113 ???
(SG) 1 -3 -114 ???
(SG) 2 -2 -415 ???
(SG) 2 -7 116 ??
(TW) 3 -1 -1317 ???
(TW) 2 -3 -718 ??
(TW) 1 0 -319 ??
(TW) 6 -3 -2020 ??
(TW) 3 -6 -5Table 3  Ranking Change for Individual Words2Take the example of the BJ target word ???
(xin4xi1hua4, informationize).
Before dupli-cated words were removed from Cilin, the mostappropriate subclass (Ih:Change) ranked 7th inthe automatic classification.
Upon the removalof duplicated words, subclass Ih ranked first inthe results.
The words shared by other top rank-ing subclasses (e.g.
Je:influence, Da:condition,etc.)
such as ?
(jia1, increase), ?
(tui1, push),??
(ti2gao1, raise), etc., may have skewed thesimilarity comparison by introducing manycommon co-occurring words which are not par-ticularly characteristic of any subclass.For the TW target word ??
(tou2xin4, in-vestment trust), the appropriate subclass2 English gloss: 1-informationize, 2-re-employed, 3-unemployed, 4-resist drought, 5-quality check, 6-generaltrend of stock market, 7-buy in stocks, 8-H stock, 9-interestrate, 10-sell (stocks), 11-Singaporean dollar, 12-Malaysianstocks, 13-closing price, 14-rights issue, 15-holding spacerate, 16-investment trust, 17-growth rate, 18-financial hold-ings, 19-over-bought, 20-bank.
(Dm:organization) soared from the 16th to the3rd when features were extracted for the Cilinwords from the BJ subcorpus instead of the TWsubcorpus.
It was observed that both vectorshave a large part in common, but the one ex-tracted from TW subcorpus contained manymore spurious features which might not be char-acteristic of the subclass, thus affecting the simi-larity score.It is also apparent that region-specific butcommon concepts like ???
(xie3zi4lou2, of-fice), ??
(zu3wu1, apartment), and ??
(si1zhai2, private residence), etc., are more ad-versely affected when features for Cilin wordswere extracted from the BJ subcorpus instead ofthe respective target subcorpora, while othermore core financial concepts could often takeadvantage of the former.
Thus it appears that thedomain and concept specificity could also affectthe effectiveness of the method.6.4 Future DirectionsThere is room to improve the results at both thesubclass and semantic head level.
More qualita-tive analysis is needed for the data heterogeneityeffect.
The category size, and as pointed outabove, the domain and concept specificity arealso worth further investigation.
The latter willthus involve the classification of words fromother special domains like sports, as well as thosefrom the general domain.One problem we need to address in the nextstep is the class imbalance problem as Cilin cate-gories could differ considerably in size, whichwill affect the number of features and subsequentclassification.
For this we plan to try the k near-est neighbours approach.
In addition, the fea-tures might need to be constrained, as simple co-occurrence might be too coarse for distinguishingthe subtle characteristics among Cilin categories.7 ConclusionWe have worked on extending a Chinese thesau-rus with words distinctly used in various Chinesecommunities.
Classification results have im-proved as duplicated words in Cilin were re-moved.
In view of the demand on cross-culturalknowledge for building a Pan-Chinese lexicalresource manually, it is particularly important todevise robust ways for automatic acquisition ofsuch a resource.
Automatic classification ofwords with respect to an existing classificatorystructure with proper datasets for feature extrac-tion should be a prominent direction in this re-463gard.
Further investigation is needed to betterunderstand the interaction among data heteroge-neity, category size, feature selection, and thedomain and concept specificity of the words.AcknowledgementsThe work described in this paper was supportedby a grant from the Research Grants Council ofthe Hong Kong Special Administrative Region,China (Project No.
CityU 1317/03H).
The au-thors would like to thank Jingbo Zhu for usefuldiscussions on an earlier draft of this paper, andthe anonymous reviewers for their comments onthe submission.ReferencesCaraballo, S.A. (1999)  Automatic construction of ahypernym-labeled noun hierarchy from text.
InProceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics (ACL?99),Maryland, USA, pp.120-126.Ciaramita, M. (2002)  Boosting automatic lexical ac-quisition with morphological information.
In Pro-ceedings of the ACL?02 Workshop on Unsuper-vised Lexical Acquisition, Philadelphia, USA,pp.17-25.Hearst, M. (1992)  Automatic Acquisition of Hypo-nyms from Large Text Corpora.
In Proceedings ofthe 14th International Conference on Computa-tional Linguistics (COLING-92), Nantes, France,pp.539-545.Kwong, O.Y.
and Tsou, B.K.
(2006)  Feasibility ofEnriching a Chinese Synonym Dictionary with aSynchronous Chinese Corpus.
In T. Salakoski, F.Ginter, S. Pyysalo and T. Pahikkala (Eds.
), Ad-vances in Natural Language Processing: Proceed-ings of FinTAL 2006.
Lecture Notes in ArtificialIntelligence, Vol.4139, pp.322-332, Springer-Verlag.Kwong, O.Y.
and Tsou, B.K.
(2007)  Extending aThesaurus in the Pan-Chinese Context.
In Pro-ceedings of the 2007 Joint Conference on Empiri-cal Methods in Natural Language Processing andComputational Natural Language Learning(EMNLP-CoNLL-2007), Prague, pp.325-333.Lin, D. (1998)  Automatic Retrieval and Clustering ofSimilar Words.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Lin-guistics and 17th International Conference onComputational Linguistics (COLING-ACL?98),Montreal, Canada, pp.768-774.Mei et al ???????????????
(1984)???????
(Tongyici Cilin).
?????
(Commercial Press) / ??????
?.Pekar, V. (2004)  Linguistic Preprocessing for Distri-butional Classification of Words.
In Proceedingsof the COLING2004 Workshop on Enhancing andUsing Electronic Dictionaries, Geneva.Riloff, E. and Shepherd, J.
(1997)  A corpus-basedapproach for building semantic lexicons.
In Pro-ceedings of the Second Conference on EmpiricalMethods in Natural Language Processing, Provi-dence, Rhode Island, pp.117-124.Thelen, M. and Riloff, E. (2002)  A BootstrappingMethod for Learning Semantic Lexicons using Ex-traction Pattern Contexts.
In Proceedings of the2002 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP 2002), Philadelphia,USA.Tokunaga, T., Fujii, A., Iwayama, M., Sakurai, N. andTanaka, H. (1997)  Extending a thesaurus by clas-sifying words.
In Proceedings of the ACL Work-shop on Automatic Information Extraction andBuilding of Lexical Semantic Resources for NLPApplications, Madrid, pp.16-21.Tseng, H. (2003)  Semantic Classification of ChineseUnknown Words.
In the Proceedings of the ACL-2003 Student Research Workshop, CompanionVolume to the Proceedings of the 41st AnnualMeeting of the Association for Computational Lin-guistics, Sapporo, Japan.Tsou, B.K.
and Kwong, O.Y.
(2006)  Toward a Pan-Chinese Thesaurus.
In Proceedings of the Fifth In-ternational Conference on Language Resourcesand Evaluation (LREC 2006), Genoa, Italy.Tsou, B.K.
and Lai, T.B.Y.
???????
(2003)????????????.
In B. Xu, M. Sunand G. Jin ??????????
(Eds.
), ??????????????
(Issues in ChineseLanguage Processing).
????????
,pp.147-165You, J-M. and Chen, K-J.
(2006)  Improving ContextVector Models by Feature Clustering for Auto-matic Thesaurus Construction.
In Proceedings ofthe Fifth SIGHAN Workshop on Chinese LanguageProcessing, COLING-ACL 2006, Sydney, Austra-lia, pp.1-8.464
