Proceedings of NAACL HLT 2009: Short Papers, pages 117?120,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsTopic Identification Using Wikipedia Graph CentralityKino CourseyUniversity of North Texas and Daxtron Laboratories, Inc.kino@daxtron.comRada MihalceaUniversity of North Texasrada@cs.unt.eduAbstractThis paper presents a method for automatictopic identification using a graph-centrality al-gorithm applied to an encyclopedic graph de-rived from Wikipedia.
When tested on a dataset with manually assigned topics, the systemis found to significantly improve over a sim-pler baseline that does not make use of the ex-ternal encyclopedic knowledge.1 IntroductionDocument topics have been used for a long time bylibrarians to improve the retrieval of a document,and to provide background or associated informationfor browsing by users.
They can also assist search,background information gathering and contextual-ization tasks, and enhanced relevancy measures.The goal of the work described in this paper is toautomatically find topics that are relevant to an inputdocument.
We refer to this task as ?topic identifica-tion?
(Medelyan and Witten, 2008).
For instance,starting with a document on ?United States in theCold War,?
we want to identify relevant topics, suchas ?history,?
?Global Conflicts,?
?Soviet Union,?
andso forth.
We propose an unsupervised method fortopic identification, based on a biased graph cen-trality algorithm applied to a large knowledge graphbuilt from Wikipedia.The task of topic identification goes beyond key-word extraction, since relevant topics may not benecessarily mentioned in the document, and insteadhave to be obtained from some repositories of ex-ternal knowledge.
The task is also different fromtext classification, since the topics are either notknown in advance or are provided in the form ofa controlled vocabulary with thousands of entries,and thus no classification can be performed.
In-stead, with topic identification, we aim to find topics(or categories1) that are relevant to the document athand, which can be used to enrich the content of thedocument with relevant external knowledge.2 Dynamic Ranking of Topic RelevanceOur method is based on the premise that externalencyclopedic knowledge can be used to identify rel-evant topics for a given document.The method consists of two main steps.
In the firststep, we build a knowledge graph of encyclopedicconcepts based on Wikipedia, where the nodes in thegraph are represented by the entities and categoriesthat are defined in this encyclopedia.
The edges be-tween the nodes are represented by their relation ofproximity inside the Wikipedia articles.
The graphis built once and then it is stored offline, so that itcan be efficiently use for the identification of topicsin new documents.In the second step, for each input document, wefirst identify the important encyclopedic concepts inthe text, and thus create links between the content ofthe document and the external encyclopedic graph.Next, we run a biased graph centrality algorithm onthe entire graph, so that all the nodes in the exter-nal knowledge repository are ranked based on theirrelevance to the input document.2.1 WikipediaWikipedia (http://en.wikipedia.org) is a free onlineencyclopedia, representing the outcome of a contin-uous collaborative effort of a large number of vol-unteer contributors.
The basic entry is an article,which defines an entity or an event, and consists of ahypertext document with hyperlinks to other pageswithin or outside Wikipedia.
In addition to arti-1Throughout the paper, we use the terms ?topic?
and ?cate-gory?
interchangeably.117cles, Wikipedia also includes a large number of cat-egories, which represent topics that are relevant toa given article (the July 2008 version of Wikipediaincludes more than 350,000 such categories).We use the entire English Wikipedia to build anencyclopedic graph for use in the topic identificationprocess.
The nodes in the graph are represented byall the article and category pages in Wikipedia, andthe edges between the nodes are represented by theirrelation of proximity inside the articles.
The graphcontains 5.8 million nodes, and 65.5 million edges.2.2 Wikify!In order to automatically identify the important en-cyclopedic concepts in an input text, we use the un-supervised system Wikify!
(Mihalcea and Csomai,2007), which identifies the concepts in the text thatare likely to be highly relevant for the input docu-ment, and links them to Wikipedia concepts.Wikify!
works in three steps, namely: (1) candi-date extraction, (2) keyword ranking, and (3) wordsense disambiguation.
The candidate extraction stepparses the input document and extracts all the pos-sible n-grams that are also present in the vocabularyused in the encyclopedic graph (i.e., anchor texts forlinks inside Wikipedia or article or category titles).Next, the ranking step assigns a numeric value toeach candidate, reflecting the likelihood that a givencandidate is a valuable keyword.
Wikify!
uses a?keyphraseness?
measure to estimate the probabil-ity of a term W to be selected as a keyword ina document by counting the number of documentswhere the term was already selected as a keywordcount(Dkey) divided by the total number of docu-ments where the term appeared count(DW ).
Thesecounts are collected from all the Wikipedia articles.P (keyword|W ) ?
count(Dkey)count(DW )(1)Finally, a simple word sense disambiguationmethod is applied, which identifies the most likelyarticle in Wikipedia to which a concept should belinked to.
The algorithm is based on statistical meth-ods that identify the frequency of meanings in text,combined with symbolic methods that attempt tomaximize the overlap between the current documentand the candidate Wikipedia articles.
See (Mihalceaand Csomai, 2007) for more details.2.3 Biased Ranking of the Wikipedia GraphStarting with the graph of encyclopedic knowledge,and knowing the nodes that belong to the input doc-ument, we want to rank all the nodes in the graphso that we obtain a score that indicates their impor-tance relative to the given document.
We can do thisby using a graph-ranking algorithm biased towardthe nodes belonging to the input document.Graph-based ranking algorithms such as PageR-ank are essentially a way of deciding the importanceof a vertex within a graph, based on global informa-tion recursively drawn from the entire graph.
Oneformulation is in terms of a random walk through adirected graph.
A ?random surfer?
visits nodes ofthe graph, and has some probability of jumping tosome other random node of the graph.
The rank ofa node is an indication of the probability that onewould find the surfer at that node at any given time.Formally, let G = (V,E) be a directed graph withthe set of vertices V and set of edges E, where E isa subset of V ?
V .
For a given vertex Vi, let In(Vi)be the set of vertices that point to it (predecessors),and let Out(Vi) be the set of vertices that vertex Vipoints to (successors).
The PageRank score of a ver-tex Vi is defined as follows (Brin and Page, 1998):S(Vi) = (1?
d) + d ?
?j?In(Vi)1|Out(Vj)|S(Vj)where d is a damping factor usually set to 0.85.In a ?random surfer?
interpretation of the rankingprocess, the (1 ?
d) portion represents the proba-bility that a surfer navigating the graph will jumpto a given node from any other node at random, andthe summation portion indicates that the process willenter the node via edges directly connected to it.
Us-ing a method inspired by earlier work (Haveliwala,2002), we modify the formula so that the (1 ?
d)component also accounts for the importance of theconcepts found in the input document, and it is sup-pressed for all the nodes that are not found in theinput document.S(Vi) = (1?d)?Bias(Vi)+d?
?j?In(Vi)1|Out(Vj)|S(Vj)where Bias(Vi) is only defined for those nodes ini-tially identified in the input document:Bias(Vi) = f(Vi)?j?InitalNodeSetf(Vj)and 0 for all other nodes in the graph.InitalNodeSet is the set of nodes belongingto the input document.118Note that f(Vi) can vary in complexity from a de-fault value of 1 to a complex knowledge-based es-timation.
In our implementation, we use a combi-nation of the ?keyphraseness?
score assigned to thenode Vi and its distance from the ?Fundamental?category in Wikipedia.3 ExperimentsWe run two experiments, aimed at measuring the rel-evancy of the automatically identified topics with re-spect to a manually annotated gold standard data set.In the first experiment, the identification of theimportant concepts in the input text (used to bias thetopic ranking process) is performed manually, by theWikipedia users.
In the second experiment, the iden-tification of these important concepts is done auto-matically with the Wikify!
system.
In both experi-ments, the ranking of the concepts from the encyclo-pedic graph is performed using the dynamic rankingprocess described in Section 2.We use a data set consisting of 150 articles fromWikipedia, which have been explicitly removedfrom the encyclopedic graph.
All the articles inthis data set include manual annotations of the rele-vant categories, as assigned by the Wikipedia users,against which we can measure the quality of the au-tomatic topic assignments.
The 150 articles havebeen randomly selected while following the con-straint that they each contain at least three articlelinks and at least three category links.
Our task isto rediscover the relevant categories for each page.Note that the task is non-trivial, since there are morethan 350,000 categories to choose from.
We eval-uate the quality of our system through the standardmeasures of precision and recall.3.1 Manual Annotation of the Input TextIn this first experiment, the articles in the gold stan-dard data set alo include manual annotations of theimportant concepts in the text, i.e., the links to otherWikipedia articles as created by the Wikipedia users.Thus, in this experiment we only measure the accu-racy of the dynamic topic ranking process, withoutinterference from the Wikify!
system.There are two main parameters that can be set dur-ing a system run.
First, the set of initial nodes usedas bias in the ranking can include: (1) the initial setof articles linked to by the original document (viathe Wikipedia links); (2) the categories listed in thearticles linked to by the original document2; and (3)both.
Second, the dynamic ranking process can berun through propagation on an encyclopedic graphthat includes (1) all the articles from Wikipedia; (2)all the categories from Wikipedia; or (3) all the arti-cles and the categories from Wikipedia.Figures 1 and 2 show the precision and recall forthe various settings.
Bias and Propagate indicatethe selections made for the two parameters, whichcan be set to either Articles, Categories, or Both.00.020.040.060.080.10.120.140.160.180  20  40  60  80  100PrecisionTop N topics returnedBiasArticles- PropCategoriesBiasCategories- PropArticles PropCategoriesBiasArticles BiasCategories- PropCategoriesBiasArticles- PropArticles PropCategoriesBiasArticles BiasCategories- PropArticlesBiasCategories- PropArticlesBiasArticles- PropArticlesBiasArticles BiasCategories- PropArticles PropCategoriesBiasCategories- PropCategoriesBaselineFigure 1: Precision for manual input text annotations.00.050.10.150.20.250.30.350.40.450.50  20  40  60  80  100RecallTop N topics returnedBiasArticles- PropCategoriesBiasCategories- PropArticles PropCategoriesBiasArticles BiasCategories- PropCategoriesBiasArticles- PropArticles PropCategoriesBiasArticles BiasCategories- PropArticlesBiasCategories- PropArticlesBiasArticles- PropArticlesBiasArticles BiasCategories- PropArticles PropCategoriesBiasCategories- PropCategoriesBaselineFigure 2: Recall for manual input text annotations.As seen in the figures, the best results are obtainedfor a setting where both the initial bias and the prop-agation include all the available nodes, i.e., both ar-ticles and categories.
Although the primary task isthe identification of the categories, the addition ofthe article links improves the system performance.2These should not be confused with the categories includedin the document itself, which represent the gold standard anno-tations and are not used at any point.119To place results in perspective, we also calculate abaseline (labeled as ?Baseline?
in the plots), whichselects by default all the categories listed in the arti-cles linked to by the original document.3.2 Automatic Annotation of the Input TextThe second experiment is similar to the first one, ex-cept that rather than using the manual annotationsof the important concepts in the input document,we use instead the Wikify!
system that automat-ically identifies these important concepts by usingthe method briefly described in Section 2.2.
The ar-ticle links identified by Wikify!
are treated in thesame way as the human anchor annotations from theprevious experiment.
In this experiment, we havean additional parameter, which consists of the per-centage of links selected by Wikify!
out of the totalnumber of words in the document.
We refer to thisparameter as keyRatio.
The higher the keyRatio, themore terms are added, but also the higher the poten-tial of noise due to mis-disambiguation.Figures 3 and 4 show the effect of varying thevalue of the keyRatio parameter on the precision andrecall of the system.
Note that in this experiment, weonly use the best setting for the other two parametersas identified in the previous experiment, namely aninitial bias and a propagation step that include allavailable nodes, i.e., both articles and categories.00.050.10.150.20.250  20  40  60  80  100PrecisionTop N topics returnedkeyRatio= 0.01keyRatio= 0.02keyRatio= 0.04keyRatio= 0.06keyRatio= 0.08keyRatio= 0.16keyRatio= 0.32Baseline keyRatio= 0.04Figure 3: Precision for automatic input text annotationsThe system?s best performance occurs for a keyratio of 0.04 to 0.06, which coincides with the ratiofound to be optimal in previous experiments usingthe Wikify!
system (Mihalcea and Csomai, 2007).Overall, the system manages to find many relevanttopics for the documents in the evaluation data set,despite the large number of candidate topics (more00.050.10.150.20.250.30.350  20  40  60  80  100RecallTop N topics returnedkeyRatio= 0.01keyRatio= 0.02keyRatio= 0.04keyRatio= 0.06keyRatio= 0.08keyRatio= 0.16keyRatio= 0.32Baseline keyRatio= 0.04Figure 4: Recall for automatic input text annotationsthan 350,000).
Additional experiments performedagainst a set of documents from a source other thanWikipedia are reported in (Coursey et al, 2009).4 ConclusionsIn this paper, we presented an unsupervised systemfor automatic topic identification, which relies on abiased graph centrality algorithm applied on a graphbuilt from Wikipedia.
Our experiments demonstratethe usefulness of external encyclopedic knowledgefor the task of topic identification.AcknowledgmentsThis work has been partially supported by award#CR72105 from the Texas Higher Education Coor-dinating Board and by an award from Google Inc.The authors are grateful to the Waikato group formaking their data set available.ReferencesS.
Brin and L. Page.
1998.
The anatomy of a large-scalehypertextual Web search engine.
Computer Networksand ISDN Systems, 30(1?7).K.
Coursey, R. Mihalcea, and W. Moen.
2009.
Usingencyclopedic knowledge for automatic topic identifi-cation.
In Proceedings of the Conference on NaturalLanguage Learning, Boulder, CO.T.
Haveliwala.
2002.
Topic-sensitive PageRank.
InProceedings of the Eleventh International World WideWeb Conference, May.O.
Medelyan and I. H. Witten.
2008.
Topic indexingwith Wikipedia.
In Proceedings of the AAAI WikiAIworkshop.R.
Mihalcea and A. Csomai.
2007.
Wikify!
: linking doc-uments to encyclopedic knowledge.
In Proceedingsof the Sixteenth ACM Conference on Information andKnowledge Management, Lisbon, Portugal.120
