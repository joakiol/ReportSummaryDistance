Maximal Incrementality in Linear Categorial DeductionMark HeppleDept.
of Computer ScienceUniversity of SheffieldRegent Court, Portobello StreetSheffield S1 4DP, UKhepple?dcs, hef .
ac.
ukAbst ractRecent work has seen the emergence of acommon framework for parsing categorialgrammar (CG) formalisms that fall withinthe 'type-logical' tradition (such as theLambek calculus and related systems),whereby some method of linear logic the-orem proving is used in combination witha system of labelling that ensures only de-ductions appropriate to the relevant gram-matical ogic are allowed.
The approachesrealising this framework, however, have notso far addressed the task of incrementalparsing - -  a key issue in earlier work with'flexible' categorial grammars.
In this pa-per, the approach of (Hepple, 1996) is mod-ified to yield a linear deduction system thatdoes allow flexible deduction and hence in-cremental processing, but that hence alsosuffers the problem of 'spurious ambiguity'.This problem is avoided via normalisation.1 I n t roduct ionA key attraction of the class of formalisms known as'flexible' categorial grammars is their compatibilitywith an incremental style of processing, in allow-ing sentences to be assigned analyses that are fullyor primarily left-branching.
Such analyses designatemany initial substrings of a sentence as interpretableconstituents, allowing its interpretation to be gener-ated 'on-line' as it is presented.
Incremental inter-pretation has been argued to provide for efficientlanguage processing, by allowing early filtering ofimplausible readings.
1This paper is concerned with the parsing of cat-egorial formalisms that fall within the 'type-logical'1Within the categorial field, the significance of incre-mentality has been emphasised most notably in the workof Steedman, e.g.
(Steedman, 1989).tradition, whose most familiar representative is theassociative Lambek calculus (Lambek, 1958).
Re-cent work has seen proposals for a range of suchsystems, differing in their resource sensitivity (andhence, implicitly, their underlying notion of 'lin-guistic structure'), in some cases combining differ-ing resource sensitivities in one system.
2 Many ofthese proposals employ a 'labelled deductive sys-tem' methodology (Gabbay, 1996), whereby types inproofs are associated with labels which record proofinformation for use in ensuring correct inferencing.A common framework is emerging for parsingtype-logical formalisms, which exploits the labelleddeduction idea.
Approaches within this frameworkemploy a theorem proving method that is appropri-ate for use with linear logic, and combine it with alabelling system that restricts admitted deductionsto be those of a weaker system.
Crucially, linear logicstands above all of the type-logical formalisms pro-posed in the hierarchy of substructural logics, andhence linear logic deduction methods can provide acommon basis for parsing all of these systems.
Forexample, Moortgat (1992) combines a linear proofnet method with labelling to provide deduction forseveral categorial systems.
Morrill (1995) showshow types of the associative Lambek calculus maybe translated to labelled implicational linear types,with deduction implemented via a version of SLDresolution.
Hepple (1996) introduces a linear deduc-tion method, involving compilation to first order for-mulae, which can be combined with various labellingdisciplines.
These approaches, however, are not dir-ected toward incremental processing.In what follows, we show how the method of(Hepple, 1996) can be modified to allow processingwhich has a high degree of incrementality.
Thesemodifications, however, give a system which suffers2See, for example, the formalisms developed in(Moortgat & Morrill, 1991), (Moortgat & Oehrle, 1994),(Morrill, 1994), (Hepple, 1995).344the problem of 'derivational equivalence', also called'spurious ambiguity', i.e.
allowing multiple proofswhich assign the same reading for some combina-tion, a fact which threatens processing efficiency.
Weshow how this problem is solved via normalisation.2 Imp l i ca t iona l  L inear  Log icLinear logic is an example of a "resource-sensitive"logic, requiring that each assumption ('resource') isused precisely once in any deduction.
For the implic-ational fragment, the set of formulae ~ are definedby 5 r ::= A \[ ~'o-~- (with A a nonempty set ofatomic types).
A natural deduction formulation re-quires the elimination and introduction rules in (1),which correspond semantically to steps of functionalapplication and abstraction, respectively.
(1) Ao-B : a B: b IS: v\]o-E A:aA: (ab) o- IAo-B : Av.aThe proof (2) (which omits lambda terms) illustratesthat 'hypothetical reasoning' in proofs (i.e.
the useof additional assumptions that are later dischargedor cancelled, such as Z here) is driven by the presenceof higher-order formulae (such as Xo- (yc -z )  here).
(2) Xo-(Yo--Z) Yo-W Wo--Z \[Z\]WYYo-ZXVarious type-logical categorial formalisms (orstrictly their implicational fragments) differ fromthe above system only in imposing further restric-tions on resource usage.
For example, the associ-ative Lambek calculus imposes a linear order overformulae, in which context, implication divides intotwo cases, (usually written \ and /) depending onwhether the argument ype appears to the left orright of the functor.
Then, formulae may combineonly if they are adjacent and in the appropriateleft-right order.
The non-associative Lambek cal-culus (Lambek, 1961) sets the further requirementthat types combine under some fixed initial brack-etting.
Such weaker systems can be implementedby combining implicational linear logic with a la-belling system whose labels are structured objectsthat record relevant resource information, i.e.
of se-quencing and/or bracketting, and then using this in-formation in restricting permitted inferences to onlythose that satisfy the resource requirements of theweaker logic.3 F i r s t -o rder  Compi la t ionThe first-order formulae are those with only atomicargument types (i.e.
~" ::= A I .~o-A).Hepple (1996) shows how deductions in implica-tional linear logic can be recast as deductions in-volving only first-order formulae.
3 The method in-volves compiling the original formulae to indexedfirst-order formulae, where a higher-order initial for-mula yields multiple compiled formulae, e.g.
(omit-ting indices) Xo-(yo--Z) would yield Xo-Y and Z,i.e.
with the subformula relevant o hypotheticalreasoning (Z) effectively excised from the initial for-mulae, to be treated as a separate assumption, leav-ing a first-order residue.
Indexing is used in ensuringgeneral inear use of resources, but also notably toensure proper use of excised subformulae, i.e.
so thatZ, in our example, must be used in deriving the argu-ment of Xo-Y, and not elsewhere (otherwise invaliddeductions would be derivable).The approach is best explained by example.
Inproving Xo-(Yo--Z), Yo-W, Wo--Z =~ X, compila-tion of the premise formulae yields the indexed for-mulae that form the assumptions of (3), where for-mulae (i) and (iv) both derive from Xo--(Yo-Z).
(Note in (3) that the lambda terms of assumptionsare written below their indexed types, simply to helpthe proof fit in the column.)
Combination is allowedby the single inference rule (4).
(3) (i) (ii) (iii) (iv){i}:Xo-(Y:{j}) {k}:Yo-(W:0) {l}:Wo--(Z:0) {j}:Z)~t.x( )tz.t ) )~u.yu Av.wv z{j, l} :W:wz{j, k, l}: Y: y(wz){i, j, k, l}: X: x()tz.y(wz))(4) ?
: Ao--(B:~) :Av.a ?
: B : b lr = ?t~?r :  A: a\[b//vlEach assumption i  (3) is associated with a set con-taining a single index, which serves as the unique3The point of this manoeuvre (i.e.
compiling to first-order formulae) is to create a deduction method which,like chart parsing for phrase-structure grammar, avoidsthe need to recompute intermediate r sults when search-ing exhaustively for all possible analyses, i.e.
where anycombination of types contributes to more than one over-all analysis, it need only be computed once.
The incre-mental system to be developed in this paper is similarlycompatible with a 'chart-like' processing approach, al-though this issue will not be further addressed withinthis paper.
For earlier work on chart-parsing type-logicalformalisms, pecifically the associative Lambek calculus,see KSnig (1990), Hepple (1992), K5nig (1994).345identifier for that assumption.
The index sets of aderived formula identify precisely those assumptionsfrom which it is derived.
The rule (4) ensures appro-priate indexation, i.e.
via the condition rr = ?~?,where t~ stands for disjoint union (ensuring linearusage).
The common origin of assumptions (i) and(iv) (i.e.
from Xo--(Yo-Z)) is recorded by the factthat (i)'s argument is marked with (iv)'s index (j).The condition a C ~b of (4) ensures that (iv) mustcontribute to the derivation of (i)'s argument (whichis needed to ensure correct inferencing).
Finally, ob-serve that the semantics of (4) is handled not bysimple application, but rather by direct substitutionfor the variable of a lambda expression, employing aspecial variant of substitution, notated _\[_//_\] (e.g.t\[s//v\] to indicate substitution of s for v in t), whichspecifically does not act to avoid accidental binding.In the final inference of (3), this method allows thevariable z to fall within the scope of an abstractionover z, and so become bound.
Recall that introduc-tion inferences of the original formulation are associ-ated with abstraction steps.
In this approach, theseinferences are no longer required, their effects hav-ing been compiled into the semantics.
See (Hepple,1996) for more details, including a precise statementof the compilation procedure.4 F lex ib le  Deduct ionThe approach just outlined is unsuited to incre-mental processing.
Its single inference rule allowsonly a rigid style of combining formulae, where or-der of combination is completely determined by theargument order of functors.
The formulae of (3), forexample, must combine precisely as shown.
It is notpossible, say, to combine assumptions (i) and (if) to-gether first as part of a derivation.
To overcome thislimitation, we might generalise the combination ruleto allow composition of functions, i.e.
combinationsakin to e.g.
Xo-Y, Yo--W ==> Xo-W.
However, thetreatment of indexation in the above system is onethat does not readily adapt to flexible combination.We will transform these indexed formulae to an-other form which better suits our needs, using thecompilation procedure (5).
This procedure returnsa modified formula plus a set of equations that spe-cify constraints on its indexation.
For example, theassumptions (i-iv) of (3) yield the results (6) (ignor-ing semantic terms, which remain unchanged).
Eachatomic formula is partnered with an index set (ortypically a variable over such), which correspondsto the full set of indices to be associated with thecomplete object of that category, e.g.
in (i) we have(X+?
), plus the equation ?
= {i}Wrr which tells usthat X's index set ?
includes the argument formulaY's index set rr plus its own index i.
The furtherconstraint equation ?
= {i}t~rr indicates that theargument's index set should include j (c.f.
the con-ditions for using the original indexed formula).
(5) 0.(?
: x :  t) = ( (x+?)
: t,0)where X atomic0.(?
: Xo-Y :  t) = (Z: t,C)where 0.1(?, Xo--Y) = (Z, C)0.1(?,x) = ( (x+7) ,  {7 = ?
})where X atomic, 7 a fresh variable0.1 (?, Xl?
- (  Y :  7r)) = (X2o--(Y+7), C')where 6, 7 fresh variables, 6 := ?~70"1(6, X 1) = (X2, C)C' = C u {~r c 7}(unless ~r = 0, when C = C')(6) i. old formula: {i}: Xo--(Y:{j})new formula: (X+C)o-(Y+Tr)constraints: {?
= {i}~rr, {j} C 7r}if.
old formula: {k}:Yo-(W:O)new formula: (V+a)o-(W%3)constraints: {a = {k}~/~}iii.
old formula: {l} :Wo-(Z:O)new formula: (W+7)o-(Z+~)constraints: {7 = {l}t~}iv.
old formula: {j} :Znew formula: (Z+{j})constraints: 0(7) Ac--B : Av.a B : bA: a\[bllv\]The previous inference rule (4) modifies to (7),which is simpler since indexation constraints are nowhandled by the separate constraint equations.
Weleave implicit the fact that use of the rule involvesunification of the index variables associated with thetwo occurrences of "B" (in the standard manner).The constraint equations for the result of the com-bination are simply the sum of those for the formulaecombined (as affected by the unification step).
Forexample, combination of the formulae from (iii) and(iv) of (6) requires unification of the index set expres-sions 6 and {j}, yielding the result formula (W+7)plus the single constraint equation V = {l}tg{j},which is obviously satisfiable (with 3' = {j,l}).
Acombination is not allowed if it results in an unsat-isfiable set of constraints.
The modified approachso neatly moves indexation requirements off into theconstraint equation domain that we shall henceforthdrop all consideration of them, assuming them to beappropriately managed in the background.346We can now state a generalised composition ruleas in (8).
The inference is marked as \[m, n\], wherem is the argument position of the 'functor' (alwaysthe lefthand premise) that is involved in the com-bination, and n indicates the number of argumentsinherited from the 'argument' (righthand premise).The notation "o--Zn...o--Zl" indicates a sequence ofn arguments, where n may be zero, e.g.
the case \[1,0\]corresponds precisely to the rule (7).
Rule (8) allowsthe non-applicative derivation (9) over the formulaefrom (6) (c.f.
the earlier derivation (3)).
(8) Xo-Y .
.
.
.
o--Y1 Ymo-Z .
.
.
.
o'-ZlAyl ...y,, .a Azl ...z~ .b\[m, n\]Xo- Z .... o- Zl o-Y,,_ 1-.o-Y1Ayl ...ym- 1 Zl ...z,.a\[b // ym \](9) (i) (ii) (iii) (iv)Xc-Y  Yo -W Wo-Z  ZAt.x(Az.t) Au.yu Av.wv zXo-W: Au.x(kz.yu) \[1,11\[1,1\]xo-z: ~v.x(~z.y(wv))x :  x(,~z.y(wz) )\[1 215 Incrementa l  Der ivat ionAs noted earlier, the relevance of flexible CGs toincremental processing relates to their ability toassign highly left-branching analyses to sentences,so that many initial substrings are treated as in-terpretable constituents.
Although we have adap-ted the (Hepple, 1996) approach to allow flexibilityin deduction, the applicability of the notion 'left-branching' is not clear since it describes the formof structures built in proof systems where formu-lae are placed in a linear order, with combinationdependent on adjacency.
Linear deduction meth-ods, on the other hand, work with unordered collec-tions of formulae.
Of course, the system of labellingthat is in use - -  where the constraints of the 'real'grammatical logic reside - -  may well import wordorder information that limits combination possibil-ities, but in designing a general parsing method forlinear categorial formalisms, these constraints mustremain with the labelling system.This is not to say that there is no order informa-tion available to be considered in distinguishing in-cremental and non-incremental nalyses.
In an in-cremental processing context, the words of a sen-tence are delivered to the parser one-by-one, in 'left-to-right' order.
Given lexical ook-up, there will thenbe an 'order of delivery' of lexical formulae to theparser.
Consequently, we can characterise an incre-mental analysis as being one that at any stage in-cludes the maximal amount of 'contentful' combin-ation of the formulae (and hence also lexical mean-ings) so far delivered, within the limits of possiblecombination that the proof system allows.
Notethat we have not in these comments reintroducedan ordered proof system of the familiar kind by theback door.
In particular, we do not require formu-lae to combine under any notion of 'adjacency', butsimply 'as soon as possible'.For example, if the order of arrival of the formulaein (9) were (i,iv)-<(ii)-<(iii) (recall that (i,iv) origin-ate from the same initial formula, and so must ar-rive together), then the proof (9) would be an incre-mental analysis.
However, if the order instead was(ii)-<(iii)-<(i,iv), then (9) would not be incremental,since at the stage when only (ii) and (iii) had ar-rived, they could combine (as part of an equivalentalternative analysis), but are not so combined in (9).6 Der ivat iona l  Equiva lence,Dependency  &: Normal i sa t ionIt seems we have achieved our aim of a linear deduc-tion method that allows incremental analysis quiteeasily, i.e.
simply by generalising the combina-tion rule as in (8), having modified indexed formu-lae using (5).
However, without further work, this'achievement' is of little value, because the result-ing system will be very computationally expensivedue to the problem of 'derivational equivalence' or'spurious ambiguity', i.e.
the existence of multipledistinct proofs which assign the same reading.
Forexample, in addition to the proof (9), we have alsothe equivalent proof (10).
(10) (i) (ii) (iii) (iv)Xo--Y Yo-W Wo-Z ZAt.x(Az.t) Au.yu Av.wv zYo--Z : )~v.y(wv) \[1,1\]Y: y(wz)x :  z( az y( wz ) )\[1,0\]\[1,0\]The solution to this problem involves pecifying anormal form for deductions, and allowing that onlynormal form proofs are constructed) Our route tospecifying a normal form for proofs exploits a corres-pondence between proofs and dependency structures.Dependency grammar (DG) takes as fundamental~This approach of 'normal form parsing' has beenapplied to the associative Lambek calculus in (K6nig,1989), (Hepple, 1990), (Hendriks, 1992), and to Combin-atory Categorial Grammar in (Hepple & Morrill, 1989),(Eisner, 1996).347the notions of head and dependent.
An analogy isoften drawn between CG and DG based on equatingcategorial functors with heads, whereby the argu-ments sought by a functor are seen as its dependents.The two approaches have some obvious differences.Firstly, the argument requirements of a categorialfunctor are ordered.
Secondly, arguments in CG arephrasal, whereas in DG dependencies are betweenwords.
However, to identify the dependency rela-tions entailed by a proof, we may simply ignore argu-ment ordering, and we can trace through the proof toidentify those initial assumptions ('words') that arerelated as head and dependent by each combinationof the proof.
This simple idea unfortunately runsinto complications, due to the presence of higher or-der functions.
For example, in the proof (2), sincethe higher order functor's argument category (i.e.Yo--Z) has subformuiae corresponding to compon-ents of both of the other two assumptions, Yo -Wand Wo--Z, it is not clear whether we should viewthe higher order functor as having a dependency re-lation only to the 'functionally dominant' assump-tion Yo-W, i.e.
with dependencies a in ( l la),  or toboth the assumptions Yo-W and Wo-Z, i.e.
withdependencies as perhaps in either ( l lb)  or (l lc).The compilation approach, however, lacks this prob-lem, since we have only first order formulae, amongstwhich the dependencies are clear, e.g.
as in (12).
(11) (a) ~ f~Xo-(Yo-Z) Yo-W Wo-Z?
Xo- (Yo-Z) Yo-W Wo-ZXo-(Yo-Z) Yo-W Wo-Z(12) #-5Xo--Y Yo-W Wo-Z ZSome preliminaries.
We assume that proof as-sumptions explicitly record 'order of delivery' in-formation, marked by a natural number, and so takethe form: nx NFurther, we require the ordering to go beyond simple'order of delivery' in relatively ordering first order as-sumptions that derive from the same original higher-order formula.
(This move simply introduces omeextra arbitrary bias as a basis for distinguishingproofs.)
It is convenient o have a 'linear' nota-tion for writing proofs.
We will write (n /X  \[a\])for an assumption (such as that just shown), and(X Y / Z \[m, n\]) for a combination of subproofs Xand Y to give result formula Z by inference \[m, n\].
(13) dep((X Y / Z \[m,n\])) = {(i , j ,k)}where gov(m, X) = (i, k), fun(Y) = j(14) dep*((n/X \[a\])) -- 0dep*((X Y / Z \[re, n\]))= {~} U dep*(X) U dep*(Y)where 5 = dep((X Y / Z \[m, n\]))The procedure dep, defined in (13), identifies thedependency relation established by any combina-tion, i.e.
for any subproof P = (X Y / Z \[m,n\]),dep(P) returns a triple ( i , j ,k),  where i , j  identifythe head and dependent assumptions for the com-bination, and k indicates the argument position ofthe head assumption that is involved (which hasnow been inherited to be argument m of the functorof the combination).
The procedure dep*, definedin (14), returns the set of dependencies stablishedwithin a subproof.
Note that dep employs the pro-cedures gov (which traces the relevant argumentback to its source assumption - -  the head) and fun(which finds the functionally dominant assumptionwithin the argument subproof - -  the dependent).
(15) gov(i, (n/x \[a\])) = (n, i)gov(i, (x  Y / z \[m, n\])) = gov((i - m + 1), Y)whereto<i< (m+n)gov(i, (X Y / Z \[m, n\])) = gov(i, X)where i < mgov(i, (X Y / Z \[m, n\])) = gov((i - n + 1), X)where (m + n) < i(16) fun((n/X \[a\])) = nfun((X Y / Z \[re, n\])) = fun(X)From earlier discussion, it should be clear that an'incremental nalysis' is one in which any depend-ency to be established is established as soon as pos-sible in terms of the order of delivery of assumptions.The relation << of (17) orders dependencies in termsof which can be established earlier on, i.e.
6 << 7 ifthe later-arriving assumption of 6 arrives before thelater-arriving assumption of 7- Note however that6,7 may have the same later arriving assumption(i.e.
if this assumption is involved in more than onedependency).
In this case, << arbitrarily gives pre-cedence to the dependency whose two assumptionsoccur closer together in delivery order.348(17) 5<<7 (whereh=( i , j , k ) ,7=(x ,y ,z ) )if\] (max(/,j) < max(x,y) V(max(/,j) = max(x, y) Amin(i, \]1 > rain(x, y)))We can use << to define an incremental normalform for proofs, i.e.
an incremental proof is onethat is well-ordered with respect o << in the sensethat every combination (X Y / Z \[m, n\]) within itestablishes a dependency 5 which follows under <<every dependency 5' established within the sub-proofs X and Y it combines, i.e.
5' << 5 for each5' 6 dep*(X) tJ dep*(Y).
This normal form is usefulonly if we can show that every proof has an equi-valent normal form.
For present purposes, we cantake two proofs to be equivalent if\] they establishidentical sets of dependency relations.
5(18) trace(/,j, ( i /X  \[a\])) = jtrace(/,j, (X Y / Z \[m,n\])) = (m + k -  1)where i 6 assure(Y)trace(i, j, Y) = ktrace(i,j, (X Y / Z \[m,n\])) = kwhere i 6 assure(X)trace(i, j ,X) = k, k < mtrace(i, j, (X Y / Z \[m, hi)) = (k + n - 1)where i 6 assure(X)trace(i, j, X) = k, k > m(19) assum((i /x \[a\])) = {i}assum((X Y / Z fro, n\]))= assum(X) U assum(Y)We can specify a method such that given a setof dependency relations :D we can construct a cor-responding proof.
The process works with a set ofsubproofs 7), which are initially just the set of as-sumptions (i.e.
each of the form (n /F  \[a\])), andproceeds by combining pairs of subproofs together,until finally just a single proof remains.
Each stepinvolves electing a dependency 5 (5 = (i, j, k)) from/) (setting D := D - {5} for subsequent purposes),removing the subproofs P, Q from 7) which containthe assumptions i , j  (respectively), combining P, Q(with P as functor) to give a new subproof R which5This criterion turns out to be equivalent o onestated in terms of the lambda terms that proofs generate,i.e.
two proofs will yield identical sets of dependency re-lations iff they yield proof terms that are fly-equivalent.This observation should not be surprising, since the setof 'dependency relations' returned for a proof is in es-sence just a rather unstructured summary of its func-tional relations.is added to 7) (i.e.
P := (7) - {P, Q}) u {R}).
It isimportant to get the right value for m in the combin-ation fro, n\] used to combine P, Q, so that the correctargument of the assumption i (as now inherited tothe end-type of P) is involved.
This value is givenby m = trace(i, k, P) (with trace as defined in (18)).The process of proof construction is nondetermin-istic, in the order of selection of dependencies for in-corporation, and so a single set of dependences canyield multiple distinct, but equivalent, proofs (as wewould expect).To build normal form proofs, we only need to limitthe order of selection of dependencies using <<, i.e.requiring that the minimal element under << is se-lected at each stage.
Note that this ordering restric-tion makes the selection process deterministic, fromwhich it follows that normal forms are unique.
Put-ting the above methods together, we have a completenormal form method for proofs of the first-order lin-ear deduction system, i.e.
for any proof P, we canextract its dependency relations and use these toconstruct a unique, maximally incremental, altern-ative proof - -  the normal form of P.7 P roo f  Reduct ion  andNormal i sa t ionThe above normalisation approach is somewhat non-standard.
We shall next briefly sketch how normal-isation could instead be handled via the standardmethod of proof reduction.
This method involvesdefining a contraction relation (t>l) between proofs,which is typically stated as a number of contractionrules of the form X t>l Y, where X is termed a redexand Y its contractum.
Each rule allows that a proofcontaining a redex be transformed into one wherethat occurrence is replaced by its contractum.
Aproof is in normal form if\] it contains no redexes.The contraction relation generates a reduction rela-tion (t>) such that X reduces to Y (X \[> Y) if\] Y isobtained from X by a finite series (possibly zero) ofcontractions.
A term Y is a normal form of X iff ?is a normal form and X \[> Y.We again require the ordering relation << definedin (17).
A redex is any subproof whose final stepis a combination of two well-ordered subproofs,which establishes a dependency that undermineswell-orderedness.
A contraction step modifies theproof to swap this final combination with the finalone of an immediate subproof, so that the depend-encies the two combinations establish are now ap-propriately ordered with respect o each other.
Thepossibilities for reordering combination steps divideinto four cases, which are shown in Figure 1.
This re-349xXY Z X Z Y\[m, n\] ~ is, t\]V where s < m 1:> V'\[8, t\] \ [ (m + t - 1), n\]W WY z X Y ZIra, n\] - -  \[(s - m + 1), t\]V where m _< s I> V'\[s, t\] - -  Ira, (n + t - 1)\] W s < (m+ n) WxX Y Z X Z Y~\[m,n \ ]  ~\[ (s  -- n + 1),t\]V where s_> ( re+n)  D V'\[~, t\] Ira, ~\]W wY Z X Y ZIra, n\] - - \ [8 ,  (t - n + :)\]V t> V'- -  \[s, t\] \ [ (m + s - 1), n\]W WFigure 1: Local Reordering of Combination Steps: the four casesduction system can be shown to exhibit the property(called strong normalisation) that  every reduction isfinite, from which it follows that  every proof has anormal form.
68 Normal  fo rm pars ingThe technique of normal form parsing involves en-suring that  only normal form proofs are construc-ted by the parser, avoiding the unnecessary workof building all the non-normal form proofs.
At anystage, all subproofs o far constructed are in normalform, and the result of any combination is admittedonly provided it is in normal form, otherwise it isdiscarded.
The result of a combination is recognisedas non-normal form if it establishes a dependencythat is out of order with respect to that of the fi-nal combination of at least one of the two subproofscombined (which is an adequate criterion since thesubproofs are well-ordered).
The procedures definedabove can be used to identify these dependencies.9 The  Degree  o f  Inc rementa l i tyLet us next consider the degree of incremental itythat the above system allows, and the sense in which6To prove strong normalisation, it is sufficient o givea metric which assigns to each proof a finite non-negativeinteger score, and under which every contraction reducesa proof's score by a non-zero amount.
The followingmetric tt can be shown to suffice: (a) for P = (nIX \[a\]),#(P) = 0, (b) for P=(XY  / Z \[m,n\]), whose finalstep establishes a dependency a, #(P) = it(X) + ~u(Y) +D, where D is the number of dependencies 5' such that<< a', which are established in X and Y, i.e.
D = \[A\]whereA={5'  \] 5 'edep , (X)  Udep,(Y) A 5<<5'} .it might be considered maximal.
Clearly, the systemdoes not allow full 'word-by-word'  incrementality,i.e.
where the words that  have been delivered at anystage in incremental processing are combined to givea single result formula, with combinations to incor-porate each new lexical formula as it a r r ives /  Forexample, in incremental processing of Today Johnsang, the first two words might yield (after compil-ation) the f irst-order formulae so-s  and np, whichwill not combine under the rule (8).
sInstead, the above system will allow preciselythose combinations that  establish functional rela-tions that  are marked out in lexical type structure(i.e.
subcategorisation),  which, given the parMlel-ism of syntax and semantics, corresponds to allow-ing those combinations that  establish semantical lyrelevant functional relations amongst lexical mean-ings.
Thus, we believe the above system to exhibitmaximal  incremental ity in relation to allowing 'se-mantical ly contentful'  combinations.
In dependencyterms, the system allows any set of initial formulaeto combine to a single result iff they form a con-nected graph under the dependency relations thatobtain amongst hem.Note that  the extent of incremental i ty allowed byusing 'generalised composit ion'  in the compiled first-order system should not be equated with that  which7For an example of a system allowing word-by-wordincrementality, see (Milward, 1995).SNote that this is not to say that the system is un-able to combine these two types, e.g.
a combinationso--s, np =~ so-(so-np) is derivable, with appropriatecompilation.
The point rather is that such a combina-tion will typically not happen as a component in a proofof some other overall deduction.350would be allowed by such a rule in the original (non-compiled) system.
We can illustrate this point usingthe following type combination, which is not an in-stance of even 'generalised' composition.Xo-(Yo-Z), Yo--W =~ Xo-(Wo-Z)Compilation of the higher-order assumption wouldyield Xo--Y plus Z, of which the first formula cancompose with the second assumption Yo-W to giveXo-W, thereby achieving some semantically con-tentful combination of their associated meanings,which would not be allowed by composition over theoriginal formulae.
910 Conc lus ionWe have shown how the linear categorial deductionmethod of (Hepple, 1996) can be modified to allowincremental derivation, and specified an incrementalnormal form for proofs of the system.
These resultsprovide for an efficient incremental linear deductionmethod that can be used with various labelling dis-ciplines as a basis for parsing a range of type-logicalformalisms.ReferencesJason Eisner 1996.
'Efficient Normal-Form Parsingfor Combinatory Categorial Grammar.'
Proc.
o/ACL-3~.Dov M. Gabbay.
1996.
Labelled eductive systems.Volume 1.
Oxford University Press.Herman Hendriks.
1992.
'Lambek Semantics: nor-malisation, spurious ambiguity, partial deductionand proof nets', Proc.
of Eighth Amsterdam Col-loquium, ILLI, University of Amsterdam.Mark Hepple.
1990.
'Normal form theorem provingfor the Lambek calculus'.
Proc.
of COLING-90.Mark Hepple.
1992. '
Chart Parsing Lambek Gram-mars: Modal Extensions and Incrementality',Proc.
of COLING-92.Mark Hepple.
1995.
'Mixing Modes of LinguisticDescription in Categorial Grammar'.
ProceedingsEA CL-7, Dublin.Mark Hepple.
1996.
'A Compilation-Chart Methodfor Linear Categorial Deduction'.
Proc.
ofCOLING-96, Copenhagen.9This combination corresponds to what in a direc-tional system Wittenburg (1987) has termed a 'predict-ive combinator', e.g.
such as X/(Y/Z), Y/W =v W/Z.Indeed, the semantic result for the combination i  thefirst-order system corresponds closely to that whichwould be produced under Wittenburg's rule.Mark Hepple & Glyn Morrill.
1989.
'Parsing andderivational equivalence.'
Proc.
of EA CL-4.Esther KSnig.
1989.
'Parsing as natural deduction'.Proc.
of ACL-2ZEsther KSnig.
1990.
'The complexity of pars-ing with extended categorial grammars' Proc.
ofCOLING-90.Esther KSnig.
1994.
'A Hypothetical Reasoning Al-gorithm for Linguistic Analysis.'
Journal of Logicand Computation, Vol.
4, No 1, ppl-19.Joachim Lambek.
1958.
'The mathematics ofsentence structure.'
American MathematicalMonthly, 65, pp154-170.Joachim Lambek.
1961.
'On the calculus of syn-tactic types.'
R. Jakobson (Ed), Structure ofLanguage and its Mathematical Aspects, Proceed-ings of the Symposia in Applied Mathematics XII,American Mathematical Society.David Milward.
1995.
'Incremental Interpretationof Categorial Grammar.'
Proceedings EACL-7,Dublin.Michael Moortgat.
1992.
'Labelled deductive sys-tems for categorial theorem proving'.
Proc.
ofEighth Amsterdam Colloquium, ILLI, Universityof Amsterdam.Michael Moortgat & Richard T. Oehrle.
1994.
'Ad-jacency, dependency and order'.
Proc.
of NinthAmsterdam Colloquium.Michael Moortgat & Glyn Morrill.
1991.
'Headsand Phrases: Type Calculus for Dependency andConstituency.'
To appear: Journal of Language,Logic and Information.Glyn Morrill.
1994.
Type Logical Grammar: Cat-egorial Logic of Signs.
Kluwer Academic Publish-ers, Dordrecht.Glyn Morrill.
1995.
'Higher-order Linear LogicProgramming of Categorial Deduction'.
Proc.
ofEA CL- 7, Dublin.Mark J. Steedman.
1989.
'Grammar, interpreta-tion and processing from the lexicon.'
In Marslen-Wilson, W. (Ed), Lexical Representation a d Pro-cess, MIT Press, Cambridge, MA.Kent Wittenburg.
1987.
'Predictive Combinators:A method for efficient parsing of CombinatoryCategorial Grammars.'
Proc.
of ACL-25.351
