A Lazy Way to Chart-Parse with Categorial GrammarsIllRemo Pareschi  and Mark  Steedman ?Dept.
of AI and Centre for Cognitive Science, Univ.
of Edinburgh, *?and Dept.
of Computer and Information Science, Univ.
of Pennsylvania ?ABSTRACTThere has recendy been a revival of interest in CategorialGrammars (CG) among computational linguists.
The variousversions noted below which extend pure CG by includingoperations such as functional composition have been claimedto offer simple and uniform accounts of a wide range of naturallanguage (NL) constructions involving bounded andunbounded "movement" and coordination "reduction" in anumber of languages.
Such grammars have obvious advan-tages for computational applications, provided that they can beparsed efficiently.
However, many of the proposed extensionsengender proliferating semantically equivalent surface syntac-tic analyses.
These "spurious analyses" have been claimed tocompromise their efficient parseability.The present paper descn~oes a simple parsing algorithm for ourown "combinatory" extension of CG.
This algorithm offers auniform treatment for "spurious" syntactic ambiguities and the"genuine" structural ambiguities which any processor mustcope with, by exploiting the assodativRy of functional compo-sition and the procedural neutrality of the combinatory rulesof grammar in a bottom-up, left-to-fight parser which deliversall semantically distinct analyses via a novel unification-basedextension of chart-parsing.1.
Combinatory Categorial Grammars"Pure" categorial grammar (CG) is a grammatical notation,equivalent in power to context-free grammars, which puts allsyntactic information in the lexicon, via the specification of allgrammatical entities as either functions or arguments.
Forexample, such a grammar might capture the obvious intuitionsconcerning constituency in a sentence like John must leave byidentifying the VP leave and the NP John as the arguments ofthe tensed verb must, and the verb itself as a function combin-ing to its right with a VP, to yield a predicate -- that is, aleftward-combining function-from-NPs-into-sentences.
Onecommon "slash" notation for the types of such functionsexpresses them as triples of the for~ <result, direction, argu.merit>, where result and argument are themselves syntactictypes, and direction is indicated by "/" (for rightward-combining functions) or '~," (for leftward).
Must then gets thefollowing type-assignment:(I) must : -  (SkNP)/VPIn pure categorial grammar, the only other element is a single"combinatory" rule of Functional Application.
which givesrise to the following two instances: 11 All combinatory roles are written as productions in thepresent paper, in contrast with the reduction rule notation used in theearlier papers.
The change is intended to aid comparison with othertmification-based grammars, and has no theoretical significance.~) a. R ightward Appl icat ion:X --> X/Y Yb.
Leftward Appl icat ion:X --> Y X\YThese rules allow functions to combine with inunediam~ adja-cent a~uments in the obv~us way, to ~dd the obv~ sur-face su'ucmres and interpretations, a  in:~) John must leaveNP (S\NP)/VP VP.
.
.
.
.
.
.
.
.
.
.
.
.
>applyS\NP<applySCombinatory Categorial Grammar (CCG) (Ades and Steedman1982, Smedman 1985, Smedman 1986) adds a number offurther elementary operations on fimcfions and arguments mthe combinatory component These operadons conespond tocertain of the primitive combinamrs used by Curry and Feys(1958) to define the foundations of the ~calculus, notablyincluding functional composition and "type raising".
Forexample:(4) a.
Subject Type Raising:S/(S\NP) B> NPb.
R ightward Composit ion:X/Z --> X/Y Y/ZThese combin-tory operations allow additional, non-standard"surface structures" like the following, which arises from thetype-raising of the subject John into a function over predicates,which composes with the verb, which is of course a function/no predicates:(5) John must leaveNP (S\NP)/VP VP>raiseS/(S\NP).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
>composeS/VP>applySIn general, wherever orthodox surface structure posits a rightbranching slructure like (a) below, these new operations willallow not only the left branching structure (b), but every mix-lure of right- and left- branching in between:(6) a.  sA / B "/... C" ~D81b.
y , /X '~~A s ~'B ...~ C ~DThe linguistic motivation for including such operations, (andthe grounds for contesting the standard linguists' view of sur-face constituency), for details of which the reader is referred tothe bibliography, sterns from the possibility of extracting over,and also coordinating, a wide range of such non-standard com-posed structures.
A crucial feature of this theory of grammar isthat the novel operation of functional composition is assoc/a-tire so that all the novel analyses like (5)are semanticallyequivalent to the relevant canonical analysis, like O).
On theother hand, roles of type raising simply map arguments intofunctions over the functions of which they are argument, pro-ducing the same result, and thus are by themselves responsiblefor no change in generative capacity;, indeed, they can simplybe regarded as tools which enable functional composition tooperate in circumstances where one or both the constituentswhich need to be combined initially are not associated with afunctional type, as when combining a subject NP with the verbwhich follows it.Grammars of this kind, and the related variety proposed byKarmrmen (1986), achieve simplicity in the grammar of move-ment and coordination at the expense of multiplying thenumber of derivations according to which an unambiguoussuing such as the sentence above can be parsed.
While wehave suggested in earlier papers (Ades and Steedman 1982,Pareschi 1986) that this property can be exploited for incre-mental semantic interpretation and evaluation, a suggestionwhich has been explored further by Haddock (1987) and Hin-richs and Polanyi (1986), two potentially serious problemsarise from these spurious ambiguities.
The fast is the possibil-ity of producing a whole set of semantically equivalent ana-lyses for each reading of a given siring.
The second moreserious problem is that of efficiently coping with non-determinism in the face of such proliferating ambiguity in sur-face analyses.The problem of avoiding equivalent derivations i common toparsers of all grammars, even context-flee phrase-structuregrammars.
Since all the spurious derivations are by clef'tuitionsemantically equivalent, he solution seems obvious: just findone of them, say via a "reduce rast" strategy of the kind pro-posed by Ades and Steedman (1982).
The problem with thisproposal arises from the fact that, assuming left-to-right pro-cessing, Rightward Composition may preempt the constructionof constituents which are needed as arguments by leftwardcombining functional types.
2 Such a depth-fast processor can-not take advantage of standard techniques for eliminatingbacktracking, such as chart-parsing (Kay, 1980), because thesubconstituents for the alternative analysis will not in generalhave been built.
For example, if we have produced a left-branching analysis like (b) above, and then rind that we needthe constituent X in analysis (a) (say to attach a modifier), wewill be forced to redo the entire analysis, since not one of thesubcoustituents of X (such as Y) was a constituent under theprevious analysis.
Nor of course can we afford a standardbreadth-fast trategy.
Karttunen (1986a) has pointed out that aparser which associates a canonical interpretation structure2 If we had chosen to prc~Js fight-to-left, hen an identicalproblem would arise from the involvement ofLeftward Composition.with substzings in a chart can always distinguish a spuriousnew analysis of the same string from a genuinely differentanalysis: spurious analyses produce results that are the sameas one already installed on the chart.
However, the spuriousambiguity problem remains acute.
In order to produce only thegenuinely distinct readings, it seems that all of the spuriousanalyses must be explored, even if they can be discarded gain.Even for short strings, this can lead to an unmanageableenlargement of the search space of the processor.
Similarly,the problem of reanalysis under backtracking still threatens tooverwhelm the parser.
In the face of this problem Wittonburg(1986) has recently argued that massive heuristic guidance bystrategies quite problematically related to the grammar itselfmay be required to parse at all with acceptable costs in the faceof spurious ambiguities ( ee also Wittenburg, this conference.
)The present paper concerns an alternative unification-basedchart-parsing solution which is grammatically transparent, andwhich we claim to be generally applicable to parsing "genuine"attachment ambiguities, under exteusions to CG which involveassociative operations.2.
Unification-based Comblnatory Categorlal GrammarsAs Kamunen (1986), Uszkoreit (1986), Wittenburg (1986),and Zeevat et al (1986) have noted, unification-based compu-tational enviroments (Shieber 1986) offer a natural choice forimplementing the categories and combination roles of CGs,because of their rigorously dermed declarative semantics.
Wedescribe below a unification-besed realisation of CCG which isboth transparent to the linguistically motivated properties ofthe theory of granu'nar and can be directly coupled to the pars-ing methodology we offer further on.2.1.
A Restricted Version of Graph-unificationWe assume, like all unification formalisms, that grammaticalconstituents can be represented asfeature-structures, which weencode as directed acyclic graphs (dags).
A dag can be either:.
(i) a constant(ii) a variable(iii) a finite set of label-value pairs (features), where anyvalue is itself a dag, and each label is associated withone and only one valueWe use round brackets to def'me sets, and we notate features as\[label value\].
We refer to variables with symbols tarting withcapital etters, and to labels and constants with symbols tart-ing with lower-case letters.
The following is an example of adag:(7) ( \[a e\]\[b ( \ [ c  x\]\[d f\])\])Like other unification based grammars, we adopt degs as thedata-structures encoding categorial feature informationbecause of the conceptual perspicuity of their set-theoreticdef'mitio~ However, the variety of unification between dagsthat we adopt is more resu'ictive than the one used in standardgraph-unification formalisms like PATR-2 (Shieber 1986), andclosely resembles term-unification as adopted in logic-programming languages.82We define unification by first defining a partial ordering ofsubsumption over dags in a similar (albeit more reslricted) wayto previous work discussed in Shieber (1986).
A dag D 1 sub-sumes a dag D2 if the information contained in D 1 is a (notnecessarily proffer ) subset of the information contaified in D 2.Thus, variables ubsume all other dags, as they contain noinformation at all.
Conversely, a constant subsumes, and issubsumed by, itself alone.
Finally, subsumptlon between dagswhich are feature-sets is defined as follows.
We refer to twofeature-sets D 1 and D?
as variants of each other if there is anisomorphism d mapphSg each feature in D 1 onto a feature withthe same label in D 9.
Then a feature-set D1 subsumes afeature-set D 2 if and oilly if:(i) D 1 and D 2 are variants; and(ii) if o~ f ), where f i s  a feature in D 1 and f is a feature inD 2, then the value o f f  subsumes tile value o f f .The unification of two dags D 1 and D,~ is then def'med as themost general dag D which is subsume?d by beth D 1 and D 2.Like most other unification-based approaches, we assume thatfrom a procedural point of view, the process of obtaining theunification of two dags D 1 and D 9 requires that they be des-tructively modified to becfime the-same dag D. (We also usethe term unification to refer to this process.
)For example let D 1 and D 2 be the two following dags:(g) ( \ [a  ( \ [b c \ ] ) \ ]  ( \ [a  Y\]\[d g\] \[d z\]\[e X\]) \[e z\])Then the following dag is the unification of D 1 and D2:(9) ( \[a ( \['b c\] ) \]\[d g\]\[e g\] )However, under the present definition of unification, asopposed to the more general PATR-2 def'mition" the above isnot the unification of the following pair of dags:(10) (\[a (\[b c \ ] ) \ ]  (\[d Z\]\[d g\]) \[e z\])These two dags are not unifiable in present erms, becauseunder the above clef'tuition of suhsumption" unification of twofeature sets can only succeed if they are variants.
It followsthat a dag resulting from unification must have the samefeature population as the two feature su-uctures that it unifies.The present clef'tuition of unification thus resembles term unifi-cation in invariably yielding a feature-set with exactly thesame structure as both of the input feature-sets, via the insten-tiation of variables.
The only difference from standard termunification is that it is defined over dags, rather than standardterms.
By contrast, standard graph-unification can yield afeature-set containing features initially entirely missing fromone or other of the unified feature-sets.
The significance of thispoint will emerge later on, in the discussions of the proceduralneutrality of combinatory rules in section 2.4, and of therelated transparency property of functional categories in sec-tion 2.3.
Since the properties in question inhere to the gram-mar itself, to which unification is merely transparent, there isnothing in our approach that is incompatible with the moregeneral definition of graph unification offered by PATR-2.However, in order to establish the correctness of our proposalfor efficient parsing of extended categorial grammars using themore general definition" we would have had to neutralise itsgreater power with more laborious constraints on the encodingof entries in the categorial lexicon as dags than those we actu-ally require below.
The more restricted version we proposepreserves most of the advantages of gjraph over term data-su'uctures pointed out in Shieber (1986)/2.2.
Categories as Features StructuresWe encode constituents corresponding to non-functionalcategories, such as the noun-phrases below, as feature-setsdefining the three major attributes yraax, phonology andsenmntics, abbreviated for reasons of space to syn, pho, andson (the examples of feature-based categories given below areof course simplified for the purposes of concise exposition --for instance, we omit any specification of agreement informa-tion in the value associated with the syn(tax) label):(II) John:- (\[syn np\]\[pho john\]\[sem john' \] )(12) Mary:- ( \[syn np\]\[pho mary\]\[sem mary' \] )Constituents corresponding to functional categories arefeature-sets characterized by a triple of am-ibutes, result, direc.t/on, end argument, abbreviated tores, dir, and ar 8.
The valueassociated with dir(ection) can be instantiated to one of theconstants / and \ and the values associated with res(ult) andarg(ument) can be associated with any functional or non-functional category.
(Thus our functions are "curried", andmay be higher order.
)We impose the simple but crucial requirement of transparencyover the well-formedness of functional categories in fcamre-based CCG.
Intuitively, this requirement corresponds to theidea that any change to the structure of the value of arg(ument)caused by unification must be reflected in the value of res(ult).Given the definition of unification in the section above, thisrequirement can be simply stated as follows:(13) Functional categories must be transparent, in the sensethat every uninstantiated feature in the value of afunction's arg(ument) feature - that is, every featurewhose value is a variable -- must share that variablevalue with some feature in the value of the function'sres( ult) feature.Thus, whenever a feature in a function's arg(ument) is instan-tiated by unification, some other feature in its res(uh) will beiastantiated i entically, as a side-effect of the destructivereplacement of structures imposed by unification.
Variables inthe value of the arg(ument) of a functional category thereforehave the sole effect of increasing the specificity of the informa-tion contained in the value of its res(uh).
As the combinatoryrules of CCG build new constituents exclusively in terms ofinformation already contained in the categories that they com-bine, a requirement that all the functional categories in the lex-icon be transparent in mm guarantees the transparency of anyfunctional category assigned to complex constituents generatedby the grammar.3 Calder (1987) and Thompson (1987) have independentlymotivated similar approaches to constraining unification in encoding83The fotlowing feature-based functional category for a lexical=ansitive tensed verb obeys the ~ransparency requiremem (theoperator * indicates suing concatenation):(14) loves :-(\[res (\[res (\[syn s\]\[pho Pl*loves*P2\]\[sem ( \[act loving\]\[agent S1 \]\[patient $2\] ) \] } \]\[air \ \ ]\[arg ( \ [ syn  np\]\[pho P1 \]\[sem SI\])\] )\]\[dir / \ ]\[arg (\[syn np\]\[pho P2\]\[sem $2\] ) \] )When two adjacent feamre-su~ctures corresponding toa func-tion category X 1 and an argument X9 are combined by func-tional application, a new feature-strucfin'e X 0 is constructed byunifying the argument feature-su'ucture X 2 with the value ofthe arg(ument) in the function feature s~'ucture X 1.
The resultX n is then unified with the res(~dt) of the function.
For exam-pl~., Rightward Application can be expressed in a notationadapted from PATR-2 as follows.
We use the notation <I 1 ...1~> for a path of feature labels of length n, and we identif\]7 asXn(<11 ... I_>) the value associated with the feature identifiedby-the-path"<11 ... 1.> in the dag corresponding to a categoryX_.
We indicate udification with the equality sign, =.
Right-w~rd Application can then be written as:(15) Rightward Application:X 0 --> X 1 X 2X 1 (<direction>) - /X 1 (<arg>) : X 2X 1 (<result>) X 0Application of this rule to the functional feature-set (14) for thetransitive verb loves and the feature-set (12)for the noun-phrase Mary yields the following structure for the verb.phraseloves Mary:(16) loves Mary:-(\[res (\[syn s\]\[pho Pl*loves*mary\]\[sem ( \[act loving\]\[agent S1 \]\[patient mary' \] ) \]) \]\[dir \\]\[arg (\[syn np\]\[pho PI\]\[sem Sl\] ) \] )To rightward-compose two functional categories according mrule (4b), we similarly unify the appropriate ar&(ument) andres(ult) features of the input functions according to the follow-ing rule:linguistic theories.
(17) Rightward Composition:X 0 --> X 1 X 2X 1 (<direction>) - /X 2 (<direction>) i /X 1 (<arg>) X 2 (<result>)X 2 (<direction>) X 0 (<direction>)X 1 (<result>) X 0 (<result>)X 2 (<arg>) X 0 (<arg>)For example, suppose that the non-functional feature-set( I I )  for the noun-phrase John is type-raised into the followingfunctional feature-set, according to rule (4a), whoseunification-based version we omit here:(is) John : --(Ires (\[syn s\]\[pho P\]\[sem S\])\]\[air / \ ]\[arg (\[res ( \[syn s\]\[pho P\]\[sem S\] ) \]\[dir \\]\[arg (\[syn np\]\[pho john\]\[sem john'\]) \]) 1)Thin (18)can be combined by Rightward Composition with(14) to obtain the following feature structure for the functionalcategory corresponding to John love~.
(19) John loves :-(\[res (\[syn s\]\[pho john*loves*P2\]\[sem (\[act loving\]\[agent john'\]\[patient $2\])\])\]\[dir /\]\[arg (\[syn np\]\[pho P2 \]\[sem $2\])1)Leftward-combining rules are defined analogously to therightward-combining rules above.2.3.
Derivational Equivalence Modulo CompositionLet us denote the operations of applying and composingcategories by writing apply(X, Y) and comp(X, Y) respec-tively.
Then by the definition of the operations themselves,and in particular because of the associativity of functionalcomposition, the following equivalences hold across type-derivations:(20) app ly  (comp (X 1, X2), X3)apply (X I, apply~X 2, X 3) )(21) comp(comp(X4, X5) , X6)- comp(X4, comp(X 5, X6))More formally, the left-hand side and right-hand side of bothequations define equivalent terms in the combinatory logic of84Curry and Feys (1958).
4 It follows that all alternative deriva-tions of an arbitrary sequence of functions and arguments hatare allowed by different orders of application and compositionin which a composition is merely traded for an,~pplication alsodefine quivalent terms of Combinatory Logic."So.
for instance, a type for the sentence John loves Mary canbe assigned either by rightward-composing the type-raisedfunction John, (18), with loves.
(14), to obtain the feature-structure (19)for John loves, and then rightward applying(19) to Mary, (12).
to obtain a feature-structure for the wholesentence; or.
conversely, it can be assigned by rightward-applying loves.
(14), to Mary, (12), to obtain the feature-structure (16)for loves Mary, and then rightward-applyingJohn.
(18).
to (16) to obtain the final feamre-su'ucmre.
In bothcases, as the reader may care to verify, the type-assignment weget is the following:(22) John loves Mary:-(\[syn s\]\[pho john*loves*mary\]\[sem (\[act loving\]\[agent john' \]\[patient mary' \] ) \] )An important property of CCO is that it unites syntactic andsemantic combination i  uniform operations of application andcomposition.
Unification-based CCG makes this identificationexplicit by uniting the syntactic type of a constituent and itsinterpretation in a single feature-based type.
It follows that allderivations for a given suing induced by functional composi-tion correspond to the same unique feature-based type, whic~cannot be assigned to any other constituent in the grammar.
"This property, which we characterize formally elsewhere, is adirect consequence of the fact that unification is itself an asso-ciative operation.It follows in turn that a feature-based category like (22) associ-ated with a given constituent ot only contains all the informa-tion necessary for its grammatical interpretation, but alsodetermines an equivalence lass of derivations for that consti-tuent, a point which is related to Karttunen's (1986) proposalfor the spurious ambiguity problem (cf.
secn.
1 above), butwhich we exploit differently, as follows.2.4.
Procedural Neutrality of Combinatory RulesThe rules of combinatory eategorial grammar are purelydeclarative, and unification preserves this property, so that, aswith other unification-based grammatical formalisms (cf.Shieber 1986).
there is no procedural constraint on their use.So far.
we have only considered examples in which such rulesare applied "bottom-up", as in example (16).
in which the ruleof application (15) is used to define the feature structure X 0 onthe left-hand side of the rule in terms of the feature structures4 The terms are equivalent in the technical sense that theyreduce to an identical normal form.5 The inclusion of certain higher-order function catesories inthe lexicon (of which "modifiers of modifiers" Hkeformerly would bean example in English) means that composition may affect he argu-ment structure itself, thereby changing me.~ning and giving rise tonon-equivalent terms.
This possibility does not affect he present pro-posal, ~d can be ignored.o If there is genuine ambiguity, a constitoent will of course heassigned more than one type.X 1 and X 2 on the fight, respectively instantiated asthe func-tion loves (14)and its argument Mary ~12).
However, otherprocedural realizations are equally viable.'
In particular, it is aproperty of rules (15)and (17), (and of all the cumbinatoryrules permitted in the theory -- of.
Steedman 1986) that if anytwo out of the three lements hat hey relate are specified, thenthe third is entirely and uniquely determined.
This property,which we call procedural neutrality follows from the form ofthe rules themselves and from the transparency property(13) of functional categories, t~ier the definition of unifica-tion given in section 2.1 above.
"This property of the grammar offers a way to short-circuit theentire problem of non-determinism in a chart-based parser forgrammars characterised by spurious analyses engendered byassociative rules such as composition.
The procedural neutral-ity of the combinatory ules allows a processor to recover con-stituents which are "implicit" in analysed constituents in thesense that they would have been built if some other equivalentanalysis had happened to have been the one followed by theprocessor.
For example, consider the situation where, facedwith the suing John loves Mary dealt with in the last section,the processor has avoided multiple analyses by composingJohn, (18), with loves, (14), to obtain John loves, (19), and hasthen applied that to Mary, (12), to obtain John loves Mary(22), ignoring the other analysis.
If the parser ams out toneed the constituent loves Mary, (16), (as it will ff it is to find asensible analysis when the sentence turns out to be John lovesMary mad/y), then it can recover that constituent by clef'ruing itvia the rule of Rightward Application in terms of the featurestructures for John loves Mary, (22), and John, (18).
These twofeature structures can be used to respectively instantiate X 0and X I in the rule as stated at (15).
The reader may verify tl~tinstanttating the rule in this way determines the required con-stituent to be exactly the same category as (16).This particular procedural lternative tothe bottom-up invoca-tion of combinatery ules will be central to the parsing algo-rithm which we present in the following section, so it will beconvenient togive it a name.
Since it is the "parent" categoryX 0 and the "left-constituent" category X l that are instantiated,it seems natural to call this alternative l~ft-branch instantla-tlon of a combinatory ule, a term which we contrast with thebottom-up instantlatlon invoked in earlier examples.The significance of this point is as follows.
Let us supposethat we can guarantee that a parser will always make available,say in a chart, the constituent that could have combined under7 There is an obvious analogy here with the fact thatunification-based programming languages like Prolog do not have anypredefmed distinction between the input and the output parameters of ?given l~r~uw-From a formal point of view, procedural neutrality is ?
conse-quence of the fact that unification-based combinatory roles, as charac-terised above, are e.xJens/ona/.
Thus, we follow Pereira nd Shieher(1984) in claiming that he "bottom-up" realization of a unification-based rule ?
corresponds to the unification of a structure E?
encodingthe equational constraints of r, and a structure D r corresponding to themerging of the structures instentiating the elemcnu of the right-handside of r. A stmcmreN r is consequently assigned as the insumtiation fthe left-hand side of ?
by individuating a relevant substructure of theunification of the pair <D.
E >.
If ?
is a rule of unification-basedf -  ?
.
.
.
CCG, then the fact that N_ ts the mstanuauon f the left-hand side of ??
r , beth m terms of <D_ Er> and <D E ?
guarantees that D and D '?
.
.
F r '  ?
?
?
are tdenucal (m the sense that hey subsume each other).85bottom-up instantiation as a left-cenatiment with an implicitfight-constituent to yield the same result as the analysis thatwas actually followed.
In that case, the processor will be ableto recover the implicit right-constituent by left-branch instan-tiation of a single combinatory ule, without restarting syntac-tic analysis and without backtracking or search of any kind.The following algorithm does just that.3.
A Lazy Chart Parsing MethodologyDerivafional equivalence modulo composition, together withthe procedural neutrality of unification-based combinatoryrules, allows us to def'me a novel generalisadon f the classicchart parsing technique for extended CGs, which is "lazy" inthe sense that:a) only edges corresponding to one of the set of semanti-cally equivalent analyses are installed on the chart;b) surface constituents of already parsed parts of the inputwhich are not on the chart are directly generated fromthe structures which are, rather than being built fromscratch via syntactic reanalysis.3.1.
A Bottom-up Left-to-Right AlgorithmThe algorithm we decribe here implements a bottom-up, left-to-right parser which delivers all semantically distinct ana-lyses.
Other algorithms based on alternative control strategiesare equally feas~le.
In this specific algorithm, the distinctionbetween active and inactive dges is drawn in a rather diffeae+Ltway from the standard one.
For an edge E to be active does notmeanthat it is associated with an incomplete constituent(indeed, the distinction between complete and incomplete con-stituents is eliminated in CCG); it simply means that E canIrigger new actions of the parser to install other edges, afterwhich E itself becomes inactive.
By contrast, inactive edgescannot initiate modifications tothe state of the parser.Active edges can be added to the chart according to the threefollowing actions:Scanning: if a is a word in the input string then, foreach lexical entry X associated with a, add an activeedge labeled X spanning the vertices corresponding tothe position of a on the chart.Lifting: if E is an active edge labeled X 1. then forevery unary lrule of type raising which can-be instan-tiated as X O ~> X 1 add an active edge E 0 labeled X0and spannifig the sanie vertices of E 1.Reducing: if an edge E 9 labeled X9 has a left-adjacentedge E 1 labeled X I aKd there is ~ combinatory rulewhich c-an be instanfiated as X 0 --~---> X 1 X~ then addan active edge E 0 labeled X n spanning fife sr3rting ver-tex of E 1 and the ending ver~x F.. 2.The operational meaning of Scanning and Lifting should beclear enough.
The Reducing action is the workhorse of theparser, building new constituents by invoking combinatoryrules via bottom-up instantiadon.
Whenever Reducing iseffected over two edges E 1 and E 2 to obtain a new edge E 0 weensure that:E l is marked as a left-generator f E N. If the rule in thegr'~mmar which was used is RightWard Composition,then E 2 is marked as a right-generator of E 0.The intuition behind this move is that right.generators arerightward functional categories which have been composedinto, and will therefore give rise to spurious analyses ff theytake part in further ightward combinations, as a consequenceof the property of derivational equivalence modulo composi-tion, discussed in section 2.3.
Left-generators correspondinstead to choice points from where it would have been possi-ble to obtain a derivationally different but semanticallyequivalent constituent analysis of some part of the input string.They thus constitute suitable constituents for use in recovering/mpl/c/t right-constituents of other constituents in the chart viathe invocation of combinatory rules under the procedure ofleft-branch instantiation discussed in the last section.In order to state exactly how this is done, we need to introducethe left-starter relation, corresponding to the lransitive closureof the left-generator relation:(i) A left-generator L of an edge E is a left-starter of E.(ii) If  L is a left-sterter of E, then any left-starter of L is aleft-stsrter ofE.The parser can now add inactive dges cones~nding to impli-c/t right-constituents according to the fonowing action:Revealing:.
if an edge E is labeled by a leftward-lookingfunctional type X and there is a combinatory ule whichcan be instantiated sX'  ~> X2Xthen i f(i) there is an edge E 0 labeled Xn left-adjacent to E(ii) E 0 has a left-starter E 1 labele~ X 1(iii) there is a combinatory'rule which'can be instantiatedesX 0 ~ X IX  2then add to the chart an inactive edge E 2 labeled X~spanning the ending vertex of E 1 and the starting vertexof E, unless there is already an e~ige labelled in the sameway and spanning the same vertices.
Mark E?as  aright-generator of E 0 if the rule used in (iii) was'Righi-ward Composition.To summarise the section so far:.
if the parser is devised so asto avoid putting on the chart subeonsfiments which would leadto redundant equivalent derivations, non-determiuism in thegrammar will always give rise to cases which require some ofthe excluded constituents.
In a left-to-right processor this typi-cally happens when the argument required by a leftward-looking fimctional type has been mistakenly combined in theanalysis of a substring left-adjacent to that leftward-lookingtype.
However, such an implicit or hidden constituent couldhave only been obtained through an equivalent derivation pathfor the left-adjacent substring.
It follows that we can "reveal"it on the chart by invoking a combinatory ule in terms of left-branch instantiation.We can now informally characterize the algorithm itself as fol-lows:the parser does Scanning for each word in the inputstring going left-to-rightmoreover, whenever an active edge A is added to thechart, then the following actions are taken in order.
(i) the parser does Lifting over A(ii) if A is labeled by a leftward-looking type, thenfor every edge E left-adjacant toA the parser doesRevealing over E with respect to A86(iii) for every edge E left-adjacent to A the parser doesReducing over E and A, with the constraint thatff A is not labeled by a leftward-looking type thenE must not be a right-generator of any edge E'the parser eturns the set of categories associated withedges spanning the whole input, if such a set is notempty; it fails otherwise,.3.2.
An ExampleIn the interests of brevity and simplicity, we eschew all detailsto do with unifieafion itself in the following examples of theworkings of the parser, reverting to the original categorialnotation for CCG of section 1, bearing in mind that thecategories are now to be read strictly as a shorthand for thefuller notation of un/fication-based CCG.
For similar easonsof simplicity in exposition, we assume for the present purposethat the only type-raising rule in the grammar is the subjectrule (4a).The algorithm analy~es the sentence John loves Mary madly asfollows.
First, the parser Scans the first word John, ed~g tothe chart an active NP edge corresponding to its sole lexicalentry, and spanning the word in question, thus:(23) ?
Jo.. .Z~._~ ?NP(We adopt the convention that active edges are indicated byupper-case categories, while inactive edges will be indicatedwith lower-easo categories.)
Since the edge in question isactive, it fails under the second clause of the algorithm.
TheLifting condition (i) of this clause applies, since there is a rulewhich type raises over NP, so a new active edge of typeS/(S~rP) is added, spanning the same word, John (no otherconditions apply to the NP active edge, and it becomes inac-tive):(24) .
,~!
(S\NP)npNeither Lifting.
Revealing, nor Reducing yield any new edges,so the new active edge merely becomes inactive.
The nextword is Scanned to add a new lexical active edge of type(S~NP)/NP spanning loves:.
(25) s/(s\np)~ ~  loves .The new lexical edge Reduces with the type-raised subject oyield a new active edge of type S/NP.
The subject category ismarked as the new edge's left-generator, and (because thecombinatory rule was Rightward Composition) the verbcategory is marked as its right-generator.
Nothing moreresults from loves, and neither Lifting, Revealing nor Reducingyield anything from the new edge, so it too becomes inactive,and the next word is Sc~rmed to add a new lexical active NPedge corresponding to Mary:(26) ~ / n pnp ( s \n~/np  NPThis edge yields two new active edges before becoming inac-five, one of type S/(S~P) via Lifting and the subject rule, andone of type S, via Reducing with the s/np edge to its left by theForward application rule (we omit the former from the illustra-lion, because nothing further happens to it, but it is therenonetheless): ~The s/np edge is in addition marked as the left generator f theS.
Note that Reducing would potentially have allowed a thirdnew active edge corresponding to loves Mary to be added byReducing the new active NP edge corresponding toMary withthe left-adjacent (s~np)/np edge, loves.
However.
this edge hasbeen marked as a right generator, and is therefore not allowedto Reduce by the algorithm.Nothing new results from the new active S edge, so it becomesinactive and the next word mad/y is scanned to add a newactive e d g ~(28) ~__~/~~/np:~ohpg~ loves ~.
~.
.
.~  madly .
( s \np~--/np ~ (S \ N-~\[~--~S \NP )This active edge, being a leftward=looking functional type, pre-cipitates Revealing.
Since there is a rule (Backward Applica-tion.
2a) which would allow madly, (S~IP)~(S~IP) tocombinewith a left-adjacent s~np, and there is a rule (Forwards Appli-cation, 2a) which would allow a left-starter John .
.
.
.~hine  with ~h en ,~p  to yield the s which is le~-~to madly, (and since there is no left-adjacent s~np therealready), the rule of Forward Application can be invoked viaLeft-branch Instantiation to Reveal the inactive edge lovesMary, s ~ p .
~ ~ ' ~ , ~..- ~ , .~- , .
.o , , .
, , , .
~- , ,  ,.
~a .~._~.
.~._ .~.~ ( S \ N P )  \ (S\NP)The (still) active backward modier mad/y can now Reducewith the newly introduced s~mp, to yield a new active edgeS~P corresponding to loves Mary madly, before becominginactive: ~(30) ///~/,/cs\~p~ ~',,o/np ",~.
'/John TM.~ loves~._ Marg~..._Lmadly ~.The new active edge potentially gives rise to two semanticallyequivalent Reductions with the subject John to yield S -- onewith its ground np type, and one with its raised type, s/(s~np).Only one of these is effected, because of a detail dealt with inthe next section, and the algorithm terminates with a single Sedge spanning the str/n~" ~.np ~np l /np  np_/(s\np) \ (s\npJ/In an attachment-ambiguous sentence like the following, whichwe leave as an exercise, two predicates, believes John lovesMary and loves Mary.
are revealed in the penultimate stage ofthe analysis, and two semantically distinct analyses result"(32) Fred believes John loves Mary passionatelySpace permits us no more than to note that this procedure will87also cope with another class of constructions which constitutea major source of non-determinism in natural language pars-ing, namely the diverse coordinate constructions whosecategorial analysis is discussed by Dowty (1985) and Steed-man (1985, 1987).4.
Type Raising and Spurious AmbiguityAs noted at example (30) above, type raising rules introduce asecond kind of spurious ambiguity connected to the interac-tions of such rules with functional application rather than func-tional composition.
If the processor can Reduce via a rule ofapplication on a type.raised category, then it can also alwaysinvoke the opposite rule of appHcaton to the u~aised versionof the same category to yield the same result.
Spurious ambi-guity of this kind is trivially easy to avoided, as (u~l~e thekind associated with composition), it can always be detectedlocally by the following redundancy check on attachment ofnew edges to the chart in Reducing: when Reducing creates anedge via functional application, then it is only added to thechart if there is no edge associated with the same featurestructure and spanning the same vertices already on the chart.5.
Alternative Control Strategies and Grammatical For-mailsmsThe algorithm described above is a pure bottom-up arsingprocedure which has a close relative in the Cocke-Kasami-Younger algorithm for context-free phrase-strucnne grammars.However, our chart-parsing methodology is completely open toalternative control options.
In particular, Pareschi (forthcom-ing) describes an adaptation of the Farley algorithm, which, invirtue of its top-down prediction stage, allows for efficientapplication of more genera\] type-raising rules than are con-sidered here.
Formal proofs of the correcmess of both thesealgorithms wili be presented in the same reference.The possibility of exploiting this methodology for improvingprocessing of other unification-based xtensions of CG involv-ing spurious ambiguity, like the one reported in Kartmnen(1986a), is also under exploration.6.
ConclusionThe above approach to chart-parsing with extensions to CGscharacterised by spurious ambiguities allows us to def'me algo-rithms which do not build significantly more edges than chartparsers for more standard theories of grammar.
Our techniqueis fully transparent with respect to our grammatical formalism,since it is based on properties of associativity and proceduralneutrality inherent in the grammar itself.
9ACKNOWLEDGEMENTSWe thank Inge Bethke, Kit F'me, Ellen Hays, Aravind Joshi, DaleMiller, Henry Thompson, Bonnie Lynn Webher, and Kent Wittenbergfor help and advice.
Parts of the research were supported by: an Edin-burgh Univeni W Research Studentship; anESPRIT grant (project 393)to CCS, Univ.
Edinburgh; a Sloan Foundation grant o the CognitiveScience Program, Univ.
Pennsylvania; and NSF grant IRI-10413 A02.ARO grant DAA6-29- 84K-0061 and DARPA grant N0014-85-K0018to CIS, Univ.
Pennsylvania.9 Chart parsers based on the methodology described here andwritten in Quintus Prolog have been developed ona Sun workstation.REFERENCESAdes, A. and Steedman, M. J.
(1982) On the Order of Words.Linguistics and Philosophy, 44, 517-518.Calder, J.
(1987) Typed Unification for Natural LanguageProcessing.
Ms, Univ.
of EdinburghCurry, H. B. and Feys, R. (1958) Combinatory Logic,Volume I. Amsterdam: North Holland.Dowry, D. (1985).
Type raising, functional composition andnon-constituent coordination.
In R. Oehrle et al (eds.
),Categorial Grammars and Natural Language Structures,Durdrecht, Reidel.
(In press).Haddock, N. J.
(1987) Incremental Interpretation andCombinatory Categorial Grammar.
In Proceedings ofthe Tenth International Joint Conference on Artifi-cial Intelligence, Milan, Italy, August, 1987.Hinrichs, E. and Polanyi, L. (1986) Pointing the Way.
Papersfrom the Parasession on Pragrnatics and GrammaticalTheory at the Twenty-Second Regional Meeting of theChicago Linguistic Society, pp.298-314.Karttunen, L. (1986) Radical Lexicalism.
Paper presented atthe Conference on Alternative Conceptions of PhraseStructure, July 1986, New York.Kay, M. (1980) Algorithm Schemata and Data Structures inSyntactic Processing.
Technical Report No.
CSL-80- 12,XEROX Palo Alto Research Centre.Pareschi, Remo.
1986.
Combinatory Categorial Grammar,Logic Programming, and the Parsing of NaturalLanguage.
DAI Working Paper, University of Edinburgh.Pareschi, R. (forthcoming) PhD Thesis, Univ.
Edinburgh.Pereint, F. C. N. and Shieber, S. M. (1984) The Semantics ofGrammar Formalisms Seen as Computer Languages.
InProceedings of the 22rid Annual Meeting of the ACL,Stanford, July 1984, pp.123-129.Shieber, S. M. (1986) An Introduction to Unification-basedApproaches to Grammar, Chicago: Univ.
Chicago Press.Stcedman, M. (1985) Dependency and Coordination in theGrammar of Dutch end English.
Language, 61,523-568.Steedmen,M.
(1986) Combinatory Grammars and ParasiticGaps.
Natural Language and Linguistic Theory, toappear.Steedman, M. (1987) Coordination and Constituency in aCombinatory Grammar.
In Mark Baltin and Tony Kroch.(eds.
), Alternative Conceptions of Phrase Structure,University of Chicago Press: Chicago.
(To appear.)Thompson.
H. (1987) FBF- An Alternative to PATR as aGrammatical Assembly Language.
Research Paper,Department of A.I, Univ.
Edinburgh.Uszkoreit, H. (1986) Categorial Unification Grammars.
InProceedings of the l lth International Conference onComputational Linguistics, Bonn, August.
1986, pp187-194.Wittenburg, K. W. (1986) Natural Language Parsing withCombinatory Categorial Grammar in a Graph-Unification-Based Formalism.
PhD Thesis, Deparunemof Linguistics, University of Texas.Zeevat, H., Klein, E. and Calder, J.
(1987) An Introduction toUnification Categorial Grammar.
In N. Haddock et al(eds.
), Edinburgh Working Papers in Cognitive Science,1: Categorial Grammar, Unification Grammar, and Pars-ing.88
