Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 1?9,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsDecoding with Syntactic and Non-Syntactic Phrases in a Syntax-BasedMachine Translation SystemGreg Hanneman and Alon LavieLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 USA{ghannema,alavie}@cs.cmu.eduAbstractA key concern in building syntax-based ma-chine translation systems is how to improvecoverage by incorporating more traditionalphrase-based SMT phrase pairs that do notcorrespond to syntactic constituents.
At thesame time, it is desirable to include as muchsyntactic information in the system as pos-sible in order to carry out linguistically mo-tivated reordering, for example.
We applyan extended and modified version of the ap-proach of Tinsley et al (2007), extractingsyntax-based phrase pairs from a large parallelparsed corpus, combining them with PBSMTphrases, and performing joint decoding in asyntax-based MT framework without loss oftranslation quality.
This effectively addressesthe low coverage of purely syntactic MT with-out discarding syntactic information.
Further,we show the potential for improved transla-tion results with the inclusion of a syntacticgrammar.
We also introduce a new syntax-prioritized technique for combining syntacticand non-syntactic phrases that reduces overallphrase table size and decoding time by 61%,with only a minimal drop in automatic trans-lation metric scores.1 IntroductionThe dominance of traditional phrase-based statisti-cal machine translation (PBSMT) models (Koehn etal., 2003) has recently been challenged by the de-velopment and improvement of a number of newmodels that explicity take into account the syntaxof the sentences being translated.
One simple ap-proach is to limit the phrases learned by a standardPBSMT translation model to only those contiguoussequences of words that additionally correspond toconstituents in a syntactic parse tree.
However, a to-tal reliance on such syntax-based phrases has beenshown to be detrimental to translation quality, as thespace of phrase segmentation of a parallel sentenceis heavily constrained by both the source-side andtarget-side tree structures.
Noting that the numberof phrase pairs extracted from a corpus is reduced byaround 80% when they are required to correspond tosyntactic constituents, Koehn et al (2003) observedthat many non-constituent phrase pairs that wouldnot be included in a syntax-only model are in factextremely important to system performance.
Sincethen, researchers have explored effective ways forcombining phrase pairs derived from syntax-awaremethods with those extracted from more traditionalPBSMT.
Briefly stated, the goal is to retain the highlevel of coverage provided by non-syntactic PBSMTphrases while simultaneously incorporating and ex-ploiting specific syntactic knowledge.Zollmann and Venugopal (2006) overcome the re-strictiveness of the syntax-only model by startingwith a complete set of phrases as produced by tra-ditional PBSMT heuristics, then annotating the tar-get side of each phrasal entry with the label of theconstituent node in the target-side parse tree thatsubsumes the span.
They then introduce new con-stituent labels to handle the cases where the phrasalentries do not exactly correspond to the syntacticconstituents.
Liu et al (2006) also add non-syntacticPBSMT phrases into their tree-to-string translationsystem.
Working from the other direction, Martonand Resnik (2008) extend a hierarchical PBSMT1system with a number of features to prefer or dis-prefer certain types of syntactic phrases in differentcontexts.
Restructuring the parse trees to ease theirrestrictiveness is another recent approach: in partic-ular, Wang et al (2007) binarize source-side parsetrees in order to provide phrase pair coverage forphrases that are partially syntactic.Tinsley et al (2007) showed an improvement overa PBSMT baseline on four tasks in bidirectionalGerman?English and Spanish?English translationby incorporating syntactic phrases derived from par-allel trees into the PBSMT translation model.
Theyfirst word align and extract phrases from a parallelcorpus using the open-source Moses PBSMT toolkit(Koehn et al, 2007), which provides a baseline SMTsystem.
Then, both sides of the parallel corpus areparsed with independent automatic parsers, subtreesfrom the resulting parallel treebank are aligned, andan additional set of phrases (with each phrase corre-sponding to a syntactic constituent in the parse tree)is extracted.
The authors report statistically signif-icant improvements in translation quality, as mea-sured by a variety of automatic metrics, when thetwo types of phrases are combined in the Moses de-coder.Our approach in this paper is structurally similarto that of Tinsley et al (2007), but we extend ormodify it in a number of key ways.
First, we ex-tract both non-syntactic PBSMT and syntax-drivenphrases from a parallel corpus that is two orders ofmagnitude larger, making our system competitivein size to state-of-the-art SMT systems elsewhere.Second, we apply a different algorithm for subtreealignment, proposed by Lavie et al (2008), whichproceeds bottom-up from existing statistical wordalignments, rather than inducing them top-downfrom lexical alignment probabilities.
Third, in addi-tion to straightforwardly combining syntax-derivedphrases with traditional PBSMT phrases, we demon-strate a new combination technique that removesPBSMT phrases whose source-language strings arealready covered by a syntax-derived phrase.
Thisnew syntax-prioritized technique results in a 61%reduction in the size of the combined phrase tablewith only a minimal decrease in automatic transla-tion metric scores.
Finally, and crucially, we carryout the joint decoding over both syntactic and non-syntactic phrase pairs in a syntax-aware MT sys-tem, which allows a syntactic grammar to be put inplace on top of the phrase pairs to carry out linguis-tically motivated reordering, hierarchical decoding,and other operations.After this introduction, we first describe the baseMT system we used, its formalism for specify-ing translation rules, and the method for extract-ing syntax-derived phrase pairs from a parallel cor-pus (Section 2).
Section 3 gives the two methodsfor combining PBSMT phrases with our syntacticphrases, and introduces our first steps with includ-ing a grammar in the syntax-based translation frame-work.
The results of our experiments are describedin Section 4 and are further discussed in Section 5.Finally, Section 6 offers some conclusions and di-rections for future work.2 Base Translation SystemThe base MT system used for our experiments is thestatistical transfer (?Stat-XFER?)
framework (Lavie,2008).
The core of the framework is a transfer en-gine using two language-pair-dependent resources:a grammar of weighted synchronous context-freerules, and a probabilistic bilingual lexicon.
Oncethe resources have been provided, the Stat-XFERframework carries out translation in a two-stage pro-cess, first applying the lexicon and grammar to syn-chronously parse an input sentence, then runninga monotonic decoder over the resulting lattice ofscored translation pieces assembled during parsingto produce a final string output.
Reordering is ap-plied only in the first stage, driven by the syntacticgrammar; the second-stage monotonic decoder onlyassembles translation fragments into complete hy-potheses.2.1 Lexicon and Grammar FormalismEach Stat-XFER bilingual lexicon entry has a syn-chronous context-free grammar (SCFG) expressionof the source- and target-language production rules,shown in abbreviated format below, where cs and ctrepresent source- and target-side syntactic categorylabels and ws and wt represent source- and target-side word or phrase strings.cs :: ct ?
[ws] :: [wt]2Each entry in the lexicon is assigned a pair of rulescores (rt|s and rs|t) based on cs, ws, ct, and wt1.The rt|s score is a maximum-likelihood estimateof the distribution of target-language translationsand source- and target-language syntactic categoriesgiven the source string (Equation 1); this is similarto the usual ?target-given-source?
phrasal probabil-ity in standard SMT systems.
The rs|t score is sim-ilar, but calculated in the reverse direction to give asource-given-target probability (Equation 2).rt|s = #(wt, ct, ws, cs)#(ws) + 1 (1)rs|t = #(wt, ct, ws, cs)#(wt) + 1 (2)The add-one smoothing in the denominators coun-teracts overestimation of the rule scores of lexicalentries with very infrequent source or target sides.Stat-XFER grammar rules have a similar form,shown below via an example.NP :: NP ?
[DET1 N2 de N3] :: [DET1 N3 N2]The SCFG backbone may include lexicalized items,as above, as well as non-terminals and pre-terminalsfrom the grammar.
Constituent alignment infor-mation, shown here as co-indexes on the non-terminals, specifies one-to-one correspondences be-tween source-language and target-language con-stituents on the right-hand side of the SCFG rule.Rule scores rt|s and rs|t for grammar rules, if theyare learned from data, are calculated in the same wayas the scores for lexical entries.2.2 Syntax-Based Phrase ExtractionIn this section, we briefly summarize the automaticresource extraction approach described by Lavie etal.
(2008) and recently extended by Ambati andLavie (2008), which we use here, specifically as ap-plied to the extraction of syntax-based phrase pairsfor the bilingual lexicon.The grammar and lexicon are extracted from alarge parallel corpus that has been statistically word-aligned and independently parsed on both sides with1If no syntactic category information is available, cs and ctcan be set to dummy values, but the rule score equations remainunchanged.automatic parsers.
Word-level entries for the bilin-gual lexicon are directly taken from the word align-ments; corresponding syntactic categories for theleft-hand side of the SCFG rules are obtained fromthe preterminal nodes of the parse trees.
Phrase-level entries for the lexicon are based on node-to-node alignments in the parallel parse trees.
In thestraightforward ?tree-to-tree?
scenario, a given nodens in one parse tree S will be aligned to a node ntin the other parse tree T if the words in the yield ofns are all either aligned to words within the yield ofnt or have no alignment at all.
If there are multiplenodes nt satisfying this constraint, the node in thetree closest to the leaves is selected.
Each alignednode pair (ns, nt) produces a phrase-level entry inthe lexicon, where the left-hand sides of the SCFGrule are the labels of ns and nt, and the right-handsides are the yields of those two nodes in their re-spective trees.
In the expanded ?tree-to-tree-string?configuration, if no suitable node nt exists, a newnode n?s is introduced into T as a projection of ns,spanning the yield of the words in T aligned to theyield of ns.
At the end of the extraction process ineither case, the entry counts are collected and scoredin the manner described in Section 2.1.3 Combination with PBSMT PhrasesConceptually, we take the opposite approach to thatof Tinsley et al (2007) by adding traditional PBSMTphrases into a syntax-based MT system rather thanthe other way around.
We begin by running steps3 through 5 of the Moses training script (Koehn etal., 2007)2, which results in a list of phrase pair in-stances for the same word-aligned corpus to whichwe applied the syntax-based extraction methods inSection 2.2.
Given the two sets of phrases, we ex-plore two methods of combining them.?
Direct Combination.
Following the method ofTinsley et al (2007), we directly combine thecounts of observed syntax-based phrase pairswith the counts of observed PBSMT phrasepairs.
This results in a modified probabilitymodel in which a higher likelihood is movedonto syntactic phrase pairs that were also ex-tractable using traditional PBSMT heuristics.
It2See also www.statmt.org/moses.3Decoder Phrase Type # Phrases METEOR BLEU TERStat-XFER Syntactic only, PHR 917,266 0.5654 0.2734 56.49Stat-XFER Syntactic only, frag 1,081,233 0.5653 0.2741 56.54Stat-XFER Syntactic only, gra 1,081,233 0.5665 0.2772 56.26Stat-XFER PBSMT only 8,069,480 0.5835 0.3018 54.26Stat-XFER Direct combination, PHR 8,071,773 0.5835 0.3009 54.21Stat-XFER Direct combination, frag 9,150,713 0.5841 0.3026 54.52Stat-XFER Direct combination, gra 9,150,713 0.5855 0.3034 54.28Stat-XFER Syntax-prioritized, PHR 2,888,154 0.5800 0.2961 54.79Stat-XFER Syntax-prioritized, frag 3,052,121 0.5802 0.2979 54.78Stat-XFER Syntax-prioritized, gra 3,052,121 0.5813 0.2991 54.73Moses PBSMT only, mono 8,145,083 0.5911 0.3139 53.77Moses PBSMT only, lex RO 8,145,083 0.5940 0.3190 53.48Figure 1: Results on the test set for all phrase table configurations.
For BLEU, bold type indicates the best Stat-XFERbaseline and the configurations statistically equivalent to it (paired bootstrap resampling with n = 1000, p = 0.05).also allows either extraction mechanism to in-troduce new entries into the combined phrasetable that were not extracted by the other, thuspermitting the system to take full advantage ofcomplementary information provided by PB-SMT phrases that do not correspond to syntac-tic constituents.?
Syntax-Prioritized Combination.
Under thismethod, we take advantage of the fact thatsyntax-based phrase pairs are likely to bemore precise translational equivalences thantraditional PBSMT phrase pairs, since con-stituent boundaries are taken into account dur-ing phrase extraction.
PBSMT phrases whosesource-side strings are already covered by anentry from the syntactic phrase table are re-moved; the remaining PBSMT phrases arecombined as in the direct combination methodabove.
The effect on the overall system isto trust the syntactic phrase pairs in the caseswhere they exist, supplementing with PBSMTphrase pairs for non-constituents.For each type of phrase-pair combination, we testthree variants when jointly decoding syntax-basedphrases, which come with syntactic information,along with PBSMT phrases, which do not.
In thefirst configuration (?PHR?
), all extracted phrase la-bels for syntactic phrases are mapped to a generic?PHR?
tag to simulate standard SMT monotonic de-coding; this matches the treatment given throughoutto our extracted non-syntactic phrases.
In the sec-ond variant (?frag?
), the phrase labels in the largenonterminal sets used by our source- and target-sideparsers are mapped down to a smaller set of 19 la-bels that we use for both sides.
The same translationphrase pair may occur with multiple category labelsin this case if it was extracted with different syn-tactic categories from different trees in the corpus.In a third variant (?gra?
), a small manually devel-oped grammar is additionally inserted into the sys-tem.
The Stat-XFER system behaves the same wayin each variant.
All phrase pairs are applied jointlyto the input sentence during the parsing stage, get-ting added to the translation according to their syn-tactic category and scores, although phrases taggedas PHR cannot participate in any grammar rules.The second-stage decoder then receives the joint lat-tice and assembles complete output hypotheses re-gardless of syntactic category labels.4 ExperimentsWe extracted the lexical resources for our MT sys-tem from version 3 of the French?English Europarlparallel corpus (Koehn, 2005), using the officiallyreleased training set from the 2008 Workshop inStatistical Machine Translation (WMT)3.
This givesus a corpus of approximately 1.2 million sentence3www.statmt.org/wmt08/shared-task.html4Phrase Table # Entries # Source Sides Amb.
FactorTotal syntax-prioritized table 3,052,121 113,988 26.8Syntactic component 1,081,233 39,105 27.7PBSMT component 1,970,888 74,883 26.3Total baseline PBSMT table 8,069,480 113,972 70.8Overlap with syntax-prioritized 6,098,592 39,089 156.0Figure 2: Statistical characteristics of the syntax-prioritized phrase table (top) compared with the baseline PBSMTphrase table (bottom).
The ambiguity factor is the ratio of the number of unique entries to the number of uniquesource sides, or the average number of target-language alternatives per source phrase.pairs.
Statistical word alignments are learned in bothdirections with GIZA++ (Och and Ney, 2003), thencombined with the ?grow-diag-final?
heuristic.
Forthe extraction of syntax-based phrase pairs, we ob-tain English-side constituency parses using the Stan-ford parser (Klein and Manning, 2003), and French-side constituency parses using the Xerox XIP parser(A?
?t-Mokhtar et al, 2001).
In phrase extraction,we concentrate on the expanded tree-to-tree-stringscenario described in Section 2.2, as it results ina nearly 50% increase in the number of extractedphrase pairs over the tree-to-tree method.
For de-coding, we construct a suffix-array language model(Zhang and Vogel, 2006) from a corpus of 430 mil-lion words, including the English side of our train-ing data, the English side of the Hansard corpus, andnewswire data.
The ?gra?
variant uses a nine-rulegrammar that is meant to address the most commonlow-level reorderings between French and English,focusing mainly on the reordering between nouns ornoun phrases and adjectives or adjective phrases.Our test set is the 2000-sentence ?test2007?
dataset, also released as part of the WMT workshopseries.
We report case-insensitive scores on ver-sion 0.6 of METEOR (Lavie and Agarwal, 2007)with all modules enabled, version 1.04 of IBM-styleBLEU (Papineni et al, 2002), and version 5 of TER(Snover et al, 2006).Figure 1 gives an overall summary of our resultson the test2007 data.
Overall, we train and test 10different configurations of phrase pairs in the Stat-XFER decoder.
We begin by testing each type ofphrase separately, producing one set of baseline sys-tems with only phrase pairs that correspond to syn-tactic constituents (?Syntactic only?)
and one base-line system with only phrase pairs that were ex-tracted from Moses (?PBSMT only?).
We then testour two combination techniques, and their variants,as described in Section 3.
Statistical significanceis tested on the BLEU metric using paired boot-strap resampling (Koehn, 2004) with n = 1000 andp = 0.05.
In the figure, the best baseline system andthe configurations statistically equivalent to it are in-dicated in bold type.
In addition to automatic met-ric scores, we also list the number of unique phrasepairs extracted for each configuration.
(Because ofthe large number of phrase pairs, we pre-filter themto only the set whose source sides appear in the testdata; these numbers are the ones reported.
)As an additional point of comparison, we buildand tune a Moses MT system on the same dataas our Stat-XFER experiments.
The Moses systemwith a 4-gram language model and a distance-6 lex-ical reordering model (?lex RO?)
scores similarly tostate-of-the-art systems of this type on the test2007French?English data (Callison-Burch et al, 2007).Without the reordering model (?mono?
), the Mosessystem is as comparable as possible in design andresources to the Stat-XFER PBSMT-only configu-ration.
We do not propose in this paper a head-to-head performance comparison between the Stat-XFER and Moses decoders; rather, we report resultson both to gain a better understanding of the im-pact of the non-syntactic lexical reordering modelin Moses compared with the impact of the syntacticgrammar in Stat-XFER.5 Discussion5.1 Phrasal Coverage and PrecisionOne observation apparent in Figure 1 is that we haveagain confirmed that a total restriction to syntax-5Source: Il faut que l?
opinion publique soit informe?e pleinement sur les caracte?ristiques dutest dont je parle .Reference: Public opinion must be fully informed of the characteristics of the test I am talkingabout .Syntax only: It | is | that | the public | be informed | fully | on | the characteristics | of the test | Iam talking about | .PBSMT only: We must | that public opinion gets noticed | fully | on the characteristics of the |test | above .Direct comb.
: We must | that public opinion gets noticed | fully on | the characteristics of the |test | above .Syntax-prioritized: It is important that | the public | be informed | fully on | the characteristics | of thetest | I am talking about | .Figure 3: A translation example from the test set showing the output?s division into phrases.
In the syntax-prioritizedtranslation, English phrases that derived from syntax-based phrasal entries are shown in italics.based phrases is detrimental to output quality.
Alikely reason for this, as Tinsley et al (2007) sug-gested, is that the improved precision and infor-mativeness of the syntactic phrases is not enoughto overcome their relative scarcity when comparedto non-syntactic PBSMT phrases.
(The syntacticphrase table is only 11 to 13% of the size of the PB-SMT phrase table.)
It is important to note that thisscarcity occurs at the phrasal level: though there are294 unknown word types in our test set when trans-lating with only syntactic phrase pairs, this num-ber only drops to 277 with the inclusion of PBSMTphrases.
The largest phrase table configuration, di-rect combination, yields statistically equivalent per-formance to the baseline system created using stan-dard PBSMT extraction heuristics.
Its key benefitis that the inclusion of syntactic information in thephrase pairs, where possible, leaves open the door tofurther improvement in scores with the addition of alarger syntactic grammar.
We have thus addressedthe syntax-only phrase coverage problem withoutgiving up syntactic information.An interesting conclusion is revealed in the anal-ysis of the sizes and relative overlaps of the phrasetables in each of our translation conditions.
Inthe absence of significant grammar, the equiva-lence of scores between the PBSMT-only and direct-combination scenarios is understandable given theminimal change in the size of the phrase table.
Outof nearly 8.1 million entries, only 2293 entirely newentries are provided by adding the syntactic phrasetable; further, these phrases are relatively rare longphrases that do not have much effect on the trans-lation of the overall test set.
On the other hand, thesyntax-prioritized phrase table is extremely differentin nature ?
and only 37.8% of the size of the base-line PBSMT phrase table ?
yet still attains nearlythe same automatic metric scores.
There, we canclearly see the effect of the syntactic phrases, sincethe 3,052,121 phrases used in the fragmented vari-ant of that scenario are more noticibly split between1,970,888 PBSMT phrases (64.6%) and 1,081,233syntax-based phrases (35.4%).Some statistics for the makeup of the syntax-prioritized phrase table, compared to the baselinePBSMT phrase table, are shown in Figure 2.
Foreach, we calculate the ?ambiguity factor,?
or theaverage number of target-language alternatives foreach source-language phrase in the table.
This anal-ysis shows not only that the distribution of tradi-tional PBSMT phrases is rather different from thatof the syntactic phrases, it is also different from thenon-syntactic PBSMT phrases that are preserved inthe syntax-prioritized table.
In effect, given a base-line PBSMT phrase table, the syntax prioritizationreplaces phrase entries for 39,089 source-languagephrases, each with an average of 156 different target-language translations, with 39,105 source phrases,each with an average of 27.7 syntactically motivatedtarget translations ?
a net savings of 5.0 million6Source: Je veux saluer , a` mon tour , l?
intervention forte et substantielle du pre?sident Prodi .Reference: I too would like to welcome Mr Prodi ?s forceful and meaningful intervention .PHRI welcomeS, in turn ,NPthe strong and substantial speechADJPstrong and substantialADJsubstantialCONandADJstrongNspeechDETthePPof President ProdiPU.Figure 4: A translation example from the test set showing the result of including the nine-rule grammar in the syntax-prioritized combination.
The SMT-only translation of the noun phrase is the decisive intervention and substantial.phrase pairs.
This is a strong indication that, be-cause of the more accurate phrase boundary detec-tion, the syntactic phrases are a much more preciserepresentation of translational equivalence.
An ad-ditional benefit is a significant reduction in decodingtime, from an average of 27.3 seconds per sentencewith the baseline PBSMT phrase table to 10.7 sec-onds per sentence with the syntax-prioritized tablewith the grammar included.Improved precision due to the inclusion of syn-tactic phrases can be seen by examining a translationexample and the phrasal chunks that produce it (Fig-ure 3).
In the syntax-prioritized output, the Englishphrases deriving from syntax-based phrase pairs areshown in italic, while the phrases deriving from PB-SMT pairs are in normal type.
The example showsan effective combination of on-target translations forsyntactic constituents, when they are available, withnon-syntactic phrases to handle constituent bound-aries or places where parallel constituents are dif-ficult to extract.
The translation pieces be informedand I am talking about, though they exist in the base-line PBSMT phrase table, do not make it into thetop-best translation in the PBSMT-only scenario be-cause of its high ambiguity factor.5.2 Effect of Syntactic InformationAlthough our current experiments do not show a sig-nificant increase in automatic metric scores with theaddition of a small grammar, we can see the po-tential power of grammar in examining further sen-tences from the output.
For example, in Figure 4,standard PBSMT phrase extraction is able to pick upthe adjective?noun reordering when translating fromintervention forte to decisive intervention.
However,in this sentence we have an adjective phrase follow-ing the noun, and there is no pre-extracted phrasepair for the entire constituent, so our system builtfrom only PBSMT phrases produces the incorrectnoun phrase translation the decisive intervention andsubstantial.
Our nine-rule grammar, specifically tar-geted for this scenario, is able to correct the structureof the sentence by applying two rules to produce thestrong and substantial speech.Analysis of the entire test set further suggests thateven our small grammar produces correct and pre-cise output across all phrase table configurations, al-though the total number of applications of the ninerules remains low.
There are 590 rule applicationsin the one-best output on the test set in the syntax-only configuration, 472 applications in the syntax-prioritized configuration, and 216 applications in thedirect combination.
In each configuration, we man-ually inspected all rule applications in the first 200sentences and classified them as correctly reorderingwords in the English output (?good?
), incorrectly re-ordering (?bad?
), or ?null.?
This last category de-notes applications of monotonic structure-buildingrules that did not feed into a higher-level reorderingrule.
The results of this analysis are shown in Fig-ure 5.
Overall, we find that the grammar is 97% ac-curate in its applications, making helpful reorderingchanges 88% of the time.Given the preceding analysis ?
and the fact thatour inclusion of a lexicalized reordering model in7Phrase Table Good Bad NullSyntactic only 47 3 8Syntax-prioritized 45 1 3Direct combination 25 0 0Figure 5: Manual analysis of grammar rule applicationsin the first 200 sentences of the test set.Moses resulted in automatic metric gains of only0.0051 BLEU, 0.0029 METEOR, and 0.29 TER ?we believe that further experiments with a muchlarger syntactic grammar will lead to a more signif-icant improvement in automatic metric scores andtranslation quality.6 Conclusions and Future WorkWe have extended and applied an algorithm for com-bining syntax-based phrases from a parallel parsedcorpus with non-syntactic phrases from phrase-based SMT within the context of a statistical syntax-based translation framework.
Using a much largercorpus than has previously been employed for thisapproach, we produce jointly decoded output sta-tistically equivalent to a monotonic decoding usingstandard PBSMT phrase-extraction heuristics, re-taining syntactic information and setting the stagefor further improvements by incorporating a syntac-tic grammar into the translation framework.
Ourpreliminary nine-rule grammar, targeted for two spe-cific English?French linguistic phenomena, alreadyshows promise in performing linguistically moti-vated reordering that cannot be captured formally bya standard PBSMT model.We present a syntax-prioritized method of com-bining phrase types into a single phrase table by al-ways selecting a syntax-based phrase pair when oneis available for a given source string.
This new com-bination style reduces the size of the resulting phrasetable and total decoding time by 61%, with onlya minor degradation in MT performance.
We sug-gest that this is because the syntax-derived phrases,when they can be extracted, are a much more precisemethod of describing correct translational equiva-lences.As yet, we have made only minimal use of theStat-XFER framework?s grammar capabilities.
Inour experiments, the full tree-to-tree-string rule-extraction process of Ambati and Lavie (2008) pro-duces more than 2 million unique SCFG rules whenapplied to a corpus the size of the Europarl.
Not onlyis translating with such a large set computationallyintractable, but empirically nearly 90% of the ruleswere observed only once in the parallel parsed cor-pus, making it difficult to separate rare but correctrules from those due to noise in the parses and wordalignments.
With the view of moving beyond ourmanually written nine-rule grammar, but wanting toget only the most useful rules from the entire auto-matically extracted set, we are currently investigat-ing methods for automatic scoring or selection of areasonable number of grammar rules for a particularlanguage pair.
Given that the majority of our phrasepairs, even in the syntax-prioritized combination, arenon-syntactic, we have also conducted preliminaryexperiments with ?syntactifying?
them so that theymay also be used by grammar rules to produce largertranslation fragments.The experiments in this paper used the grow-diag-final heuristic for word alignment combination be-cause it has been shown to provide the highest preci-sion on the subtree node alignment method by whichwe extract syntax-based phrase pairs (Lavie et al,2008).
However, this is a trade-off that sacrificessome amount of recall.
Experimenting with differ-ent symmetric alignment heuristics may lead to amore optimal configuration for phrase-pair extrac-tion or combination with PBSMT phrases.
We alsosuspect that the choice of source- and target-sideparsers plays a significant role in the number andnature of phrase pairs we extract; to address this,we are in the process of re-trying our line of exper-iments using the Berkeley parser (Petrov and Klein,2007) for English, French, or both.AcknowledgmentsThis research was supported in part by NSF grantIIS-0534217 (LETRAS) and the DARPA GALEprogram.
We thank the members of the Parsing andSemantics group at Xerox Research Center Europefor parsing the French data with their XIP parser.ReferencesSalah A?
?t-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2001.
A multi-input dependency parser.
In8Proceedings of the Seventh International Workshop onParsing Technologies, Beijing, China, October.Vamshi Ambati and Alon Lavie.
2008.
Improving syntaxdriven translation models by re-structuring divergentand non-isomorphic parse tree structures.
In Proceed-ings of the Eighth Conference of the Association forMachine Translation in the Americas, pages 235?244,Waikiki, HI, October.Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,Christof Monz, and Josh Schroeder.
2007.
(Meta-)evaluation of machine translation.
In Proceedings ofthe Second Workshop on Statistical Machine Transla-tion, pages 136?158, Prague, Czech Republic, June.Dan Klein and Christopher D. Manning.
2003.
Fast exactinference with a factored model for natural languageparsing.
In Advances in Neural Information Process-ing Systems 15, pages 3?10.
MIT Press, Cambridge,MA.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT-NAACL 2003, pages 48?54, Edmonton,Alberta, May?June.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the ACL 2007 Demo and Poster Sessions, pages177?180, Prague, Czech Republic, June.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395, Barcelona, Spain, July.Philipp Koehn.
2005.
Europarl: A parallel corpus for sta-tistical machine translation.
In Proceedings of the 10thMachine Translation Summit, pages 79?86, Phuket,Thailand, September.Alon Lavie and Abhaya Agarwal.
2007.
METEOR: Anautomatic metric for MT evaluation with high levels ofcorrelation with human judgments.
In Proceedings ofthe Second Workshop on Statistical Machine Transla-tion, pages 228?231, Prague, Czech Republic, June.Alon Lavie, Alok Parlikar, and Vamshi Ambati.
2008.Syntax-driven learning of sub-sentential translationequivalents and translation rules from parsed parallelcorpora.
In Proceedings of the Second ACL Work-shop on Syntax and Structure in Statistical Transla-tion, pages 87?95, Columbus, OH, June.Alon Lavie.
2008.
Stat-XFER: A general search-basedsyntax-driven framework for machine translation.
InComputational Linguistics and Intelligent Text Pro-cessing, Lecture Notes in Computer Science, pages362?375.
Springer.Yang Liu, Qun Liu, and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machine trans-lation.
In Proceedings of the 21st International Con-ference on Computational Linguistics and 44th AnnualMeeting of the ACL, pages 609?616, Sydney, Aus-tralia, July.Yuval Marton and Philip Resnik.
2008.
Soft syntacticconstraints for hierarchical phrase-based translation.In Proceedings of ACL-08: HLT, pages 1003?1011,Columbus, OH, June.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automatic eva-lution of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA,July.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACLHLT 2007, pages 404?411, Rochester, NY, April.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
InProceedings of the Seventh Conference of the Associ-ation for Machine Translation in the Americas, pages223?231, Cambridge, MA, August.John Tinsley, Mary Hearne, and Andy Way.
2007.
Ex-ploiting parallel treebanks to improve phrase-basedstatistical machine translation.
In Proceedings of theSixth International Workshop on Treebanks and Lin-guistic Theories, pages 175?187, Bergen, Norway, De-cember.Wei Wang, Kevin Knight, and Daniel Marcu.
2007.
Bi-narizing syntax trees to improve syntax-based machinetranslation accuracy.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 746?754, Prague, Czech Re-public, June.Ying Zhang and Stephan Vogel.
2006.
Suffix array andits applications in empirical natural language process-ing.
Technical Report CMU-LTI-06-010, CarnegieMellon University, Pittsburgh, PA, December.Andreas Zollmann and Ashish Venugopal.
2006.
Syntaxaugmented machine translation via chart parsing.
InProceedings of the Workshop on Statistical MachineTranslation, pages 138?141, New York, NY, June.9
