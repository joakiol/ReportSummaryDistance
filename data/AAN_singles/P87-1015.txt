CHARACTERIZING STRUCTURAL DESCRIPTIONS PRODUCED BY VARIOUS.GRAMMATICAL FORMALISMS*K. Vijay-Shanker David J.
We i r  Aravind K. JoshiDeparunent of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, Pa 19104ABSTRACTWe consider the structural descriptions produced by vari-ous grammatical formalisms in ~ of the complexity of thepaths and the relationship between paths in the sets of structuraldescriptions that each system can generate.
In considering therelationship between formalisms, we show that it is useful toabstract away from the details of the formalism, and examinethe nature of their derivation process as reflected by propertiesof their deriva:ion trees.
We find that several of the formalismsconsidered can be seen as being closely related since they havederivation tree sets with the same structure as those producedby Context-Free C-ramma~.
On the basis of this observation,we describe aclass of formalisms which we call Linear Context-Free Rewriting Systems, and show they are recognizable in poly-nomial time and generate only semilinear languages.1 IntroductionMuch of the study of grammatical systems in computationallinguistics has been focused on the weak generative capacity ofgrammatical forma~sm- Little attention, however, has been paidto the structural descriptions that these formalisms can assign tostrings, i.e.
their strong generative capacity.
This aspect of theformalism is  beth linguistically and computationally important.For example, Gazdar (1985) discusses the applicability of In-dexed Grammars (IG's) to Natural Language in terms of thestructural descriptions assigned; and Berwick (1984) discussesthe strong generative capacity of Lexical-Functional GrammarCLFG) and Government and Bindings grammars (GB).
The workof Thatcher (1973) and Rounds (1969) define formal systemsthat generate tree sets that are related to CFG's and IG's.We consider properties of the tree sets generated by CFG's,Tree Adjoining Grammars (TAG's), Head GrammarS (HG's),Categorial Grammars (CG's), and IG's.
We examine both thecomplexity of the paths of trees in the tree sets, and the kindsof dependencies that the formalisms can impose between paths.These two properties of the tree sets are not only linguisticallyrelevant, but also have computational importance.
By consider-ing derivation trees, and thus abstracting away from the details ofthe composition operation and the structures being manipuht_ed,we are able to state the similarities and differences between the"This work was partially supported byNSF grants MCS-82-19116-CER, MC$-$2-07294 and DCR-84-10413, ARO grant DAA 29-84-9-0027, and DARPA grantN00014-85-K001& We are very gateful to Tony Kroch, Michael Palis, SuniiShende, and Mark $teedman for valuable discussions.formalisms.
It is striking that from this point of view many for-malisms can be grouped together as having identically s~'uctm'edderivation tree sets.
This suggests that by generalizing the notionof context-freeness in CFG's, we can define a class of grarnmati-ca\] formalisms that manipulate more complex structures.
In thispaper, we outline how such family of formalisms can be defined,and show that like CFG's, each member possesses a number ofdesirable linguistic and computational properties: in particular,the constant growth property and polynomial recognizability.2 Tree Sets of Various Formalisms2.1 Context-Free GrammarsFrom Thateheds (1973) work, it is obvious that the complexityof the set of paths from root to frontier of trees in a local set (thetree set of a CFG) is regular ~.
We define the path set of a tree 7as the set of strings that label a path from the root to frontier of7.
The path set of a tree set is the union of the path sets of treesin that tree set.
It can be easily shown from Thateher's resultthat the path set of every local set is a regular set.
As a result,CFG's can not provide the structural descriptions in which thereare nested ependencies between symbols labelling a path.
Forexample, CFG's cannot produce trees of the form shown in Fig-ure I in which there are nested ependencies between S and NPnodes appearing on the spine of the tree.
Gazdar (1985) arguesthis is the appropriate analysis of unbounded dependencies in thehypothetical Scandinavian language Norwedish.
He also arguesthat paired English complementizers may also require structuraldescriptions whose path sets have nested ependencies.2.2 Head Grammars  and Genera l ized CFG'sHead Grammars (HG's), introduced by Pollard (1984), is a for-realism that manipulates headed strings: i.e., strings, one ofwhose symbols is distinguished as the head.
Not only is con-catenation of these s~ings possible, but head wrapping can beused to split a string and wrap it around another string.
Theproductions of HG's are very similar to those of CFG's exceptthat the operation used must be made explicit.
Thus, the treesets generated by HG's are similar to those of CFG's, with eachnode annotated by the operation (concatenation r wrapping)used to combine the headed s~ngs derived by the daughters ofIThatcher actually chxacter/zed recognizable s t~ for the purposes ofthispaper we do not distinguish t em from local gels.104S*AsANP vPAV S'AMp sv PPIFigure 1: Nested dependencies in Norwedishthat node.
A derivation tree giving an analysis of Dutch subor-dinate clauses is given in Figure 2.NP VPRR/N V SN V $N V S / .~I IN V/N  IFigure 2: HG analysis of Dutch subordinate clausesHG's are a special case of a class of formalisms calledGeneralized Context-Free Grammars, also introduced by Pol-lard (1984).
A formalism in this class is defined by a finiteset of operations (of which concatenation a d wrapping are twopossibilities).
As in the case of HG's the annotated tree sets forthese formalisms have the same structure as local sets.2.3 Tree Adjoining GrammarsTree Adjoining Grzrnmars, a tree rewriting formalism, was intro-duced by Joshi, Levy and Takabashi (1975) and Joshi (1983/85).A TAG consists of a finite set of elementary trees that are ei-ther initial trees or auxg/ary trees.
Trees are composed usingan operation called adjoining, which is defined as follows.
Letbe some node labeled X in a tree 3' (see Figure 3).
Let 3" bea tree with root and foot labeled by X.
When -/' is ad jo inedat r/ in the tree 3' we obtain a tree 3"".
The subtree under ~1is excised from 3', the tree 3" is inserted in its place and theexcised subtree is inserted below the foot of 3".It can be shown that he path set of the tree set generated bya TAG G is a context-free language.
TAG's can be used to giveY: Si ' .
sr'."
x /?,,,Figure 3: Adjunction operationthe structural descriptions discussed by Gazdar (1985) for theunbounded nested ependencies in Norwedish, for cross serialdependencies in Dutch subordinate clauses, and for the nestingsof paired English complementizers.From the definition of TAG's, it follows that the choice ofadjunodon is not dependent on the history of the derivation.Like CFG's, the choice is predetermined bya finite number ofrules encapsulated in the grammar.
Thus, the derivation treesfor TAG's have the same structure as local sets.
As with HG'sderivation structures are annotated; in the case of TAG's, by thetrees used for adjunction and addresses of nodes of the elemen-tary tree where adjuoctions occurred.We can define derivation trees inductively on the length ofthe derivation of a tree 3'.
If 3' is an elementary tree, the deriva-tion tree consists of a single node labeled 3'.
Suppose 3' resultsfrom the adjunction of 3"1,..., 3"k at the k distinct tree addressesn l , .
.
.
,  nk in some elementary tree 3", respectively.
The treedenoting this derivation of 3' is rooted with a node labeled 7'having k sublrees for the derivations of 3"z,..., 3'k.
The edgefrom the root to the subtree for the derivation of 3'~ is labeledby the address n~.
To show that the derivation tree set of aTAG is a local set, nodes are labeled by pairs consisting of thename of an elementary tree and the address at which it was ad-joined, instead of labelling edges with addresses.
The followingrule corresponds to the above derivation, where 3'1,..., 3"k arederived from the auxiliary trees ~1 .
.
.
.
.
~k, respectively.
(3", n) - -  h i ) .
.
.for all addresses n in some elementary tree at which 7 ~ can beadjoined.
If 3" is an initial tree we do not include an address onthe left-hand side.2.4 Indexed GrammarsThere has been recent interest in the application of IndexedGrammars (IG's) to natural languages.
Gazdar (1985) considersa number of linguistic analyses which IG's (but not CFG's) canmake, for example, the Norwedish example shown in Figure i.The work of Rounds (1969) shows that the path sets of trees de-rived by IG's (like those of TAG's) are context-free languages.Trees derived by IG's exhibit a property that is not exhibited bythe trees sets derived by TAG's or CFG's.
Informally, two ormore paths can be dependent on each other:, for example, theycould be required to be of equal ength as in the trees in Figure 4.105IG's can generate trees with dependent paths as in Figure 4b.Although the path set for trees in Figure 4a is regular, no CFG$ aa ~ b ~ a /A  /Ba ?
b ?/A  /B  .
.
aa b(a) (b)Figure 4: Example with dependent pathsgenerates such a tree set.
We focus on this difference betweenthe U'ee sets of CFG's and IG's, and formaliTe the notion ofdependence between paths in a tree set in Section 3.An IG can he viewed as a CFG in which each nonterminal?
is associated with a stack.
Each production can push or popsymbols on the stack as can he seen in the following productionsthat generate tree of the form shown in Figure 4b.- .
s(n,,)  push- share- ,,A(o,) popB(~a) --  bB(a) popAO - -BO - bGazdar (1985) argues that sharing of stacks can be used to giveanalyses for coordination.
Analogous to the sharing of stacksin IG's, Lexical-Functional Grammar's (LFG's) use the unifi-cation of unbounded hierarchical structures.
Unification is usedin LFG's to produce structures having two dependent spinesof unbounded length as in Figure 5.
Bresnan, Kaplan, Peters,and Zaenen (1982) argue that these structures are needed to de-scribe erossed-serial dependencies in Dutch subordinate clauses.Gaadar (1985) considers a restriction of lG's in which no moresNF VPJan NP VP V*IPlet NP VP V V*I I IMms NP ~ V V'{ IV{Figure 5: LFG analysis of Dutch subordinate clausesthan one nonterminal on the right-hand-side of a production caninherit he stack from the left-hand-side.
Unbounded ependen-cies between branches are not possible in such a system.
TAG'scan be shown to be equivalent to this restricted system.
Thus,TAG's can not give analyses in which dependencies betweenarbitrarily large branches exist.2.5 Categor ia l  GrammarsSteedman (1986) considers Categorial Grammars in which boththe operations of function application and composition may beused, and in which function can specify whether they take theirarguments from their right or left.
While the generative powerof CG's is greater that of CFG's, it appears to be highly con-strained.
Hence, their relationship to formalisms uch as HG'sand TAG's is of interest.
On the one hand, the definition of com-position in Steedm~- (1985), which technically permits compo-sition of functions with unbounded number of arguments, gen-erates tree sets with dependent paths such as those shown inFigure 6.
This kind of dependency arises from the use of theb 2Figure 6: Dependent branches from Categorial Grammarscomposition operation to compose two arbitrarily large cate-gories.
This allows an unbounded amount of information abouttwo separate paths (e.g.
an encoding of their length) to be com-bined and used to influence the later derivation.
A consequenceof the ability to generate tree sets with this property is that CG'sunder this definition can generate the following language whichcan not be gener~_t_~_ by either TAG's or HG's.
{a a 1 a 2 b I b 2 b \[ n=n l  +-2}On the other hand, no linguistic use is made of this generalform of composition and Steedman (personal communication)and Steedman (1986) argues that a more limited definition ofcomposition is more natural.
With this restriction the resultingtree sets will have independent paths.
The equivalence of CG'swith this restriction to TAG's and HG's is, however, still anopen problem.2.6 Mu l t i component  TAG'sAn extension of the TAG system was introduced by Joshi et al(1975) and later redefined by Joshi (1987) in which the adjunc-tion operation is defined on sets of elementary trees rather thansingle trees.
A multicomponent Tree Adjoining Grammar (MC-TAG) consists of a finite set of finite elementary tree sets.
Wemust adjoin all trees in an auxiliary tree set together as a singlestep in the derivation.
The adjuncfion operation with respectto tree sets (multicomponent adjunction) is defined as follows.106Each member of a set of trees can be adjoined into distinct nodesof trees in a single elementary tree set, i.e, derivations alwaysinvolve the adjunction of a derived auxiliary tree set into anelementary tree set.Like CFG's, TAG's, and HG's the derivation tree set of aMCTAG will be a local set.
The derivation trees of a MCTAGare similar to those of a TAG.
Instead of the names of elementarytrees of a TAG, the nodes are labeled by a sequence of namesof trees in an elementary tree set.
Since trees in a tree setare adjoined together, the addressing scheme uses a sequence ofpairings of the address and name of the elementary tree adjoinedat that address.
The following context-frue production capturesthe derivation step of the grammar shown in Figure 7, in whichthe trees in the auxiliary tree set are adjoined into themselves atthe root node (address e).The path complexity of the tree set generated by a MCTAG is notnecessarily context-free.
Like the string languages ofMCTAG's,the complexity of the path set increases as the cardinality of theelementary tree sets increases, though oth the string languagesand path sets wil l  always be semilinear.MCTAG's are able to generate tree sets having dependentpaths.
For example, the MCTAG shown in Figure 7 generatestrees of the form shown in Figure 4b.
The number of paths thatAI  J ,/J / ,Figure 7: A MCTAG with dependent pathscan be dependent is bounded by the grammar (in fact the max-imum cardinality of a tree set determines this bound).
Hence,trees shown in Figure 8 can not be generated by any MCTAG(but can be generated by an IG) because the number of pairs ofdependent paths grows with n.hc i la t ,  aIAA AA `1 A , I`1 `1 `1 `1 `1 `1 `1 AI I I I I I I Id II ~I dl 41 ?
?
?he i lh t .
=Figure 8: Trees with unbounded dependenciesSince the derivation trees of TAG's, MCTAG's, and HG'sare local sets, the choice of the structure used at each point ina derivation in these systems does not depend on the contextat that point within the derivation.
Thus, as in CFG's, at anypoint in the derivation, the set of structures that can be appliedis determined only by a finite set of rules encapsulated by thegrammar.
We characterize a class of formalisms that have thisproperty in Section 4.
We loosely describe the class of all suchsystems as Linear Context-Free Rewriting Formalisms.
As isdescribed in Section 4, the property of having a derivation treeset that is a local set appears to be useful in showing importantproperties of the languages generated by the formalisms.
Thesemflineerity ofTree Adjoining Languages (TAL's), MCTAL's,and Head Languages (I-IL's) can be proved using this property,with suitable restrictions on the composition operations.3 Dependencies between PathsRoughly spe~ki,g, we say that a tree set contains trees withdependent paths if there are two paths p.~ = u~v.~ and q.y =u.lw.1 in each -/ E r' such that u-y is some, possibly empty,shared initial subpath; v.y and w.y are not hounded in length;and there is some "dependence" (such as equal ength) betweenthe set of all v.~ and w. r for each ~/ E I'.
A tree set may besaid to have dependencies between paths if some "appropriate"subset can be shown to have dependent paths as defined above.We attempt to formalize this notion in terms of the treepumping lemma which can be used to show that a tree setdoes not have dependent paths.
Thatcher (1973) describes atree pumping lemma for recognizable s ts related to the suingpumping \]emma for regular sets.
The tree in Figure 9a can bedenoted by tlt2t3 where tree substitution is used instead of con-catenation.
The tree pumping lemm2 states that if there is tree,t = ht2ts ,  generated by a CFG G, whose height is more thana predetermined bound k, then all trees of the form tlt2t 3 foreach i >_ 0 will also generated by (3 (as shown in Figure 9b).The suing pumping lemma for CFG's (uvuTz!/-theorem) can beseen as a corollary of this lemma.$xw(=) Co)Figure 9: Tree pumping lemma for local setsThe fact that local sets do not have dependent paths follows107from this pumping lemma: a single path can be pumped in-dependently.
For example, let us consider a tree set containingtrees of the form shown in Figure 4a.
The tree t~ must be on oneof the two branches.
Pumping ta will change only one branchand leave the other b~aach unaffected.
Hence, the resulting treeswiU no longer have two branches of equal size,We can give a tree pumping lemma for TAG's by adapt-ing the uvwzy-tbeorem for CFL's since the Uee sets of TAG'shave independent and context-free paths.
This pumping \]emmastates that if there is tree, t = tzt2tat4ts, gener=_t_-~_ by a TAGG, such that its height is more than a predetermined bound k,then all trees of the form tst~tot~ts for each i _> 0 will alsogenerated by G. Similarly, for tree sets with independent pathsand more complex path sets, tree pumping lemmas can be given.We adapt he string pumping lemmn for the class of languagescorresponding to the complexity of the path set.A geometrical progression of language families defined byWeir (1987) involves tree sets with increasingly complex pathsets.
The independence of paths in the tree sets of the k tagrammatical formalism in this hierarchy can be shown by meansof tree pumping lemma of the form i ~ i ~zt~ts t  4 .
.
.
t2k+Z t~k+Z+S.The path set of ~ sets at level k + 1 have the complexity ofthe string language of level k.The independence of paths in a tree set appears to be animportant property.
A formalism generating tree sets with com-plex path sets can still generate only semilinc~r languages ffits tree sets have independent paths, and semilinear path se~For example, the formalisms in the hierarchy described abovegenerate semflinear languages although their path sets becomeincreasingly more complex as one moves up the hierarchy.
Fromthe point of view of recognition, independent paths in the deriva-t/on structures suggests that a top-down parser (for example) canwork on each branch independently, which may lead to efficientpa~sing using an algorithm based on the Divide and Conquertechnique.4 L inear  Context -F ree  Rewr i t ing  SystemsFrom the discussion so far it is clear that a number of formalismsinvolve some type of context-free r writing (they have derivationtrees that are local sets).
Our goal is to define a class of formalsystems, and show that any member of this class will possesscertain attractive properties.
In the remainder of the paper, weoutline how a class of Linear Context-Free Rewriting Systems(LCFRS's) may be defined and sketch how semifinearity andpolynomial recognition of these systems follows.4.1 Def in i t ionIn defining LCFRS's, we hope to generalize the definition ofCFG's to formalisms manipulating any structure, e.g.
strings,trees, or graphs.
To be a member of LCI~S a formalism mustsatisfy two restrictions.
First, any grammar must involve a fi-nite number of elementary structures, composed using a finitenumber of composition operations.
These operations, as we seebelow, are restricted to be size preserving (as in the case ofconcatenation i  CFG) which implies that they will be linearand non-erasing.
A second res~iction on the forma~ms i  thatchoices during the derivation are independent of the context inthe derivation.
As will be obvious later, their derivation treesets will be local sets as are those of CFG's.Each derivation of a grammm" can be represented bya gener-alized context-free derivation tree.
These derivation trees showhow the composition operations were used to derive the finalstructures from elementary structm'es.
Nodes are annotated bythe name of the composition operation used at that step in thederivation.
As in the case of the derivation trees of CFG's,nodes are labeled by a member of some finite set of symbols(perhaps only implicit in the grnrnmm" as in TAG's) used to de-note derived structures.
Frontier nodes are annotated by zeroarity functions con'esponding to elementary su'uctures.
Eachtreelet (an internal node with all its children) represents he useof a rule that is encapsulated by the g~a,-,,~.
The grammarencapsulates (either explicitly or implicitly) a finite number ofrules that can be written as follows:A - .
- , / , , (A~ .
.
.
.
, A . )
n > 0In the case of CFG's, for each productionp = A -* utA1 ?
.
.
unAnun+I(where ui is a string of terminals) the function fp is defined asfollows.In the case of TAG's, a derivation step in which the deriveduees ~z,..., ~- are adjoined into ~ at the addresses is , .
.
.
,  i , ,would involve the use of the following rule 2.- .4 , , , , ,  ..... , .
(Bs  .
.
.
.
.
~ .
)The composition operations in the case of CFG's are parame-terized by the productions.
In TAG's the elementary ~ee andaddresses where adjunction takes place are used to instantiatethe operation.To show that the derivation trees of any grammar in LCFRSis a /oca/ set, we can rewrite the annotated erivation treessuch that every node is labelled by a pair to include the com-position operations.
These systems are similar to those de-scribed by Pollard (1984) as Generalized Context-Free Gram-mars (GCFG's).
Unlike GCF*G'S, however, the compositionoperations of LCFRS's are restricted to be linear (do not du-plicate unboundedly large s~mcmres) and nonerasing (do noterase unbounded structures, a restriction made in most moderntransformational grammars).
These two resWictions impose theconstraint that the remit of composing any two s~ucmres shouldbe a sa-ucture whose "size" is the sum of its constituents plussome constant For example, the operation fp discussed in thecase of CF'G's (in Section 4.1) adds the constant equal to thesum of the length of the strings us , .
.
.
,  u,+z.Since we are considering formalisms with arbitrary struc-tures it is difficult to precisely specify all of the restrictionson the composition operations that we believe would appropri-ately generalize the concatenation operation for the particular2 We denote ?
tree derived from the elemeatany Wee -f by the symbol '~.108structures used by the formalism.
In considering recognition ofLCFRS's, we make further assumption concerning the contri-butinn of each structure to the input suing, and how the com-position operations combine structores in this respect.
We canshow that languages generated by LCFRS's are semilinear aslong as the composition operation does not remove any terminalsymbols from its arguments.4.2 Semi l inear i ty  of  LCFRL 'sSemillnearity and the closely related constant growth property(a consequence of semilinearity) have been discussed in the con-text of grammars for naUtral anguages by Joshi (1983185) andBerwick and Weinberg (1984).
Roughly speaking, a language,L, has the property of semillnearity if the number of occurrencesof each symbol in any suing is a linear combination of the oc-currences of these symbols in some fixed finite set of strings.Thus, the length of any suing in L is a linear combination of thelength of swings in some fixed finite subset of L, and thus L issaid to have the constant growth property.
Although this prop-erty is not structural, it depends on the structural property thatsentences can be built from a finite set of clauses of boundedstructure as noted by Joshi (1983/85).The property of semilinearity is concerned only with theoccurrence of symbols in strings and not their order.
Thus, anylanguage that is letter equivalent to a semilinear language isalso semilinear.
Two strings are letter equivalent if they containequal number of occurrences of each terminal symbol, and twolanguages are letXer equivalent if every string in one language isletter equivalent to a string in the other language and vice-versa.Since every CFL is known to be semillnear (Parikh, 1966), inorder to show semilinearity of some language, we need onlyshow the existence of a leUer equivalent CFL.Our definition of LCFRS's insists that the composition op-erations are linear and nonerasing.
Hence, the terminal sym-bols appearing in the structures that are composed are not lost(though a constant number of new symbols may be inUxaluced).If ~P(A) gives the number of occurrences of each terminal in thestructure named by A, then, given the constraints imposed onthe formalism, for each rule A --* fp(A1 .
.
.
.
.
An)  we have theequality?
(A) = ?
(A~) +.
.
.
+ ?(A.)
+ cpwhere cp is some constant.
We can obtain a letter equivalentCFL defined by a CFG in which the for each rule as above,we have the production A -*  A1 .
.
.
A ,up  where ~P(up) = cp.Thus, the language generated by a grammar of a LCFRS issemilinear.4.3 Recognit ion of  LCFRL 'sWe now turn our attention to the recognition of suing languagesgenerated by these formalisms (LCFRL's).
As suggested at theend of Section 3, the restrictions that have been specified inthe definition of LCFRS's suggest hat they can be efficientlyrecognized.
In this section for the purposes of showing thatpolynomial time recognition is possible, we make the additionalrestriction that the contribution of a derived structure to the in-put string can be specified by a bounded sequence of substringsof the input.
Since each composition operation is linear andnonerasing, a bounded sequences of substrings associated withthe resulting structure is obtained by combining the substrings ineach of its arguments using only the concatenation peration, in-cluding each substring exactly once.
CFG's, TAG's, MCTAG'sand HG's are all members of this class since they satisfy theserestrictions.Giving a recognition algorithm for LCFRL's involves de-scribing the subs~ings of the input that are spanned by thestructures derived by the LCFRS's and how the compositionoperation combines these substrings.
For example, in TAG'sa derived auxiliary tree spans two substrings (to the left andright of the foot node), and the adjunction operation inserts an-other substring (spanned by the subtree under the node whereadjunction takes place) between them (see Figure 3).
We canrepresent any derived tree of a TAG by the two subsc~ngs thatappear in its frontier, and then define how the adjunction opera-t/on concatenates the substrings.
Similarly, for all the LCFRS's,discussed in Section 2, we can define the relationship between astructure and the sequence of suhstrings it spans, and the effectof the composition operations on sequences of subsU'ings.A derived structure will be mapped onto a sequencezl  .
.
.
.
, zt of subsU'ings (not necessarily contiguous in the in-puO, and the composition operations will be mapped onto func-tions that can defined as follows .f ( (= ,  .
.
.
.
.
=.
, ) ,  (y,  .
.
.
.
.
y .~) )  = (~, .
.
.
.
.
,,,,,)where each zl is the concatenation f strings from z j ' s  and y~'s.The linear and nonerasing assumptions about he operations dis-cussed in Section 4.1 require that each zj  and Yk is used exactlyonce to define the swings z l , .
.
.
,  z,~ 3.
Some of the operationswill be constant functions, corresponding to elementary s~uc-rares, and will be written as f0  ---- (z l , .
.
.z~),  where each z~ isa constant, he string of terminal symbols a1,~ .
.
.
an~,~.This representation f strncV.tres by substrings and the com-position operation by its effect on subswings is related to thework of Rounds (1985).
Although embedding this version ofLCFRS's in the framework of ILFP developed by Rounds (1985)is straightforward, our motivation was to capture propertiesshared by a family of grammatical systems and generalize themdefining a class of related formafisms.
This class of formalismshave the properties that their derivation trees are local sets, andmanipulate objects, using a finite number of composition oper-ations that use a finite number of symbols.
With the additionalassumptions, inspired by Rounds (1985), we can show that mem-bers of this class can be recognized in polynomial time.4.3.1 A l te rnat ing  Tur ing  Mach inesWe use Alternating Turing Machines (Chandra, Kozen, andStockmeyer, 1981) to show that polynomial time recognitionis possible for the languages discussed in Section 4.3.
An ATMhas two types of states, existential nd universal.
In an existen-tial state an ATM behaves like a nondeterminlstic TM, accepting3 In order to simplify the following discussion, we assume that each compositionoperation is binary.
It is easy to generalize to the case of n-ary operations.109if one of the applicable moves leads to acceptance; in an uni-versal state the ATM accepts if all the applicable moves lead toacceptance.
An ATM may be thought of as spawning indepen-dent processes for each applicable move.
A k-tape ATM, M,has a read-only input tape and k read-write work tapes.
A $~pof an ATM consists of reading a symbol from each tape andoptionally moving each head to the left or right one tape ceiLA configuration of M consists of a state of the finite control,the nonblank contents of the input tape and k work tapes, andthe position of each head.
The space of a configuration is thesum of the lengths of the nonblank tape contents of the k worktapes.
M works in space 5(n) if for every string that M ac-cepts no configuration exceeds pace S(n).
It has been shownin (Chandra et al, 1981) that if M works in space logn thenthere is a deterministic TM which accepts the same language inpolynomial time.
In the next section, we show how an ATMcan accept he slrings generated by a grammar in a LCFRS for-realism in logspace, and hence show that each fatally can berecognized in polynomial time.4.3.2 Recogn i t ion  by  ATMWe define an ATM, M, reCOgni~ng a language gener~t~ bya grammar, G, having the properties discussed in Section 4.3.It can be seen that M performs a top-down recognition of theinput ax .
.
.
a,~ in logspace.The rewrite rules and the definition of the composition op-erations may be stored in the finite state control since G usesa finite number of them.
Suppose M has to determine whetherthe k substrings zx , .
.
.
,  zk can be derived from some symbolA.
Since each zi is a contiguous ubstrin 8 of the input (saya~x .
.
.
a~2), and no two substrings overlap, we can represent ziby the pair of intoge~'s (ix, i2).
We assume that M is in an ex-istential state qA, with integers ix and i2 representing z~ in the(2i - 1) th and 2i *h work tape, for 1 _< i _< k.For each rule p : A --, fp(B, C) such that fp is mappedonto the function fp defined by the following rule.M' breaks zx , .
.
.
, zk  into substrings z l , .
.
.
,Zn~ andYx .
.
.
.
.
Y,,2 conforming to the definition of fp.
M spawns asmany processes as there are ways of breaklng up zx, .
.
.
.
zkand rules with A on their left-hand-side.
Each spawned processmust check if zx , .
.
.
,  zn: and yx , .
.
.
,  Yn2 can be derived fromB and C, respectively.
To do this, the z 's  and y's are storedin the next 2nx + 2n2 tapes, and M goes to a universal state.Two processes are spawned requiring B to derive zx , .
.
.
, zn land C to derive ~./x , .
.
.
,  Yn2.
Thus, for example, one successorprocess will be have M to be in the existential state qs withthe indices encoding zx, .
.
.
.
zn~ in the firat 2nl tapes.For rules p : A - ,  fp0  such that fp is constant func-tion, giving an elementary structure, fp is defined such thatfp0  ---- (zx .
.
.
zk) where each z is a constant string.
M mustenter a universal state and check that each of the k constantsubstrings are in the appropriate place (as determined by thecontents of the first 2k work tapes) on the input tape.
In addi-tion to the tapes required to store the indices, M requires onework tape for splitting the substrings.
Thus, the ATM has nomore than 6k m'x -4- I work tapes, where k m'x is the maximumnumber of substrings spanned by a derived structure.
Since thework tapes store integers (which can be written in binary) thatnever exceed the size of the input, no configuration has space x-ceeding O(log n).
Thus, M works in logspace and recognitioncan be done on a deterministic TM in polynomial tape.5 DiscussionWe have studied the structural descriptions (trce sets) that canbe assigned by various gr-mr-at;cal systems, and classified theseformalisms on the basis of two fentures: path complexity; andpath independence.
We contrasted formalisms uch as CFG's,HG's, TAG's and MCTAG's, with formalisms uch as IG's andunificational systems uch as LFG's and FUG's.We address the question of whether or not a formalismcan generate only slructural descriptions with independent paths.This property reflects an important aspect of the underlying lin-guistic theory associated with the formalism.
In a grammarwhich generates independent paths the derivations of siblingconstituents can not share an unbounded amount of information.The importance of this property becomes clear in contrasting the-ories underlying GPSG (Gazdar, Klein, Pullum, and Sag, 1985),and GB (as described by Berwick, 1984) with those underly-ing LFG and FUG.
It is interesting to note, however, that theability to produce a bounded number of dependent paths (wheretwo dependent paths can share an unbounded amount of infor-mation) does not require machinery as powerful as that used inLFG, FUG and IG's.
As illustrated by MCTAG's, it is possiblefor a formalism to give tree sets with bounded ependent pathswhile still sharing the constrained rewriting properties of CFG's,HG's, and TAG's.In order to observe the similarity between these constrainedsystems, it is crucial to abstract away from the details of thestrucUwes and operations used by the system.
The similaritiesbecome apparent when they are studied at the level of deriva-tion structures: derivation tree sets of CFG's, HG's, TAG's,and MCTAG's are all local sets.
Independence of paths at thislevel reflects context freeness of rewriting and suggests why theycan be recognized efficiently.
As suggested in Section 4.3.2, aderivation with independent paths can be divided into subcom-putatious with limited sharing of information.We outlined the definition of a family of constrained gram-matical formalisms, called Linear Context-Free Rewriting Sys-tems.
This family represents an attempt to generalize the prop-erties shared by CFG's, HG's, TAG's, and MCTAG's.
LikeHG's, TAG's, and MCTAG's, members of LCFRS can manipu-late structures mere complex than terminal strings and use com-position operations that are more complex that concatenation.We place certain restrictions on the composition operations ofLCFRS's, restrictions that are shared by the composition opera-tions of the constrained grammatical systems that we have con-sidered.
The operations must be linear and nonerasing, i.e., theycan not duplicate or erase structure from their arguments.
Noticethat even though IG's and LFG's involve CFG-like productions,110they are (linguistically) fundamentally different from CFG's be-cause the composition operations need not be linear.
By sharingstacks (in IG's) or by using nonlinear equations over f-structares(in FUG's and LFG's), structures with unbounded dependenciesbetween paths can be generat_~i_.
LCFRS's share several proper-ties possessed by the class of m//d/y context-sensitive formalismsdiscussed by Joshi (1983/85).
The results described in this papersuggest a characterization of mild context-sensitivity in terms ofgeneralized context-freeness.Having defined LCFRS's, in Section 4.2 we established thesem/1/nearity (and hence constant growth property) of the lan-guages generated.
In considering the recognition of these lan-guages, we were forced to be more specific regarding the re-lationship between the structures derived by these formalismsand the substrings they span.
We insisted that each slzucturedominates a bounded number of (not necessarily adjacent) sub-strings.
The composition operations are mapped onto operationsthat use concatenation to define the substrings panned by theresulting strucntres.
We showed that any system defined in thisway can be recocniTed in polynomial time.
Members of LCFRSwhose operations have this property can be translated into theILFP notation (Rounds, 1985).
However, in order to capture theproperties of various grammatical systems under consideration,our notation is more restrictive that ILFP, which was designedas a general logical notation to characterize the complete class oflanguages that are recognizable in polynomial time.
It is knownthat CFG's, HG's, and TAG's can be recognized in polynomialtime since polynomial time algorithms exist in for each of theseformalisms.
A corollary of the result of Section 4.3 is that poly-nomial time recognition of MCTAG's is possible.As discussed in Section 3, independent paths in tree sets,rather than the path complexity, may be crucial in characteriz-ing semilinearity and polynomial time recognition.
We wouldlike to relax somewhat the constraint on the path complexityof formalisms in LCFRS.
Formalisms uch as the restricted in-dexed grammars (Gazdar, 1985) and members of the hierarchyof grammatical systems given by Weir (1987) have independentpaths, but more complex path sets.
Since these path sets aresemillnear, the property of independent paths in their tree setsis sufficient to cause semilinearity of the languages generatedby them.
In addition, the restricted version of CG's (discussedin Section 6) generates Use sets with independent paths and wehope that it can be included in a more general definition ofLCFRS's containing formalisms whose tree sets have path setsthat are themselves LCFRL's (as in the case of the restrictedindexed grammars, and the hierarchy defined by Weir).LCFRS's have only been loosely defined in this paper; wehave yet to provide a complete set of formal properties associ-ated with members of this class.
In thi s paper, our goal has beento use the notion of LCFRS's to classify grammatical systemson the basis of their strong generative capacity.
In consideringthis aspect of a formalism, we hope to better understand the re-lationship between the structural descriptions generated by thegrammars of a formalism, and the properties of semilinearityand polynomial recognizability.ReferencesBerwick, R., 1984.
Strong generative capacity, weak generative capac-ity, and modern linguistic theories.
Comput.
Ling.
10:189-202.Betwick, R. and Weinberg, A., 1984.
The Grammatical Basis of Lin.guistic Performance.
MIT Press, Cambridge, MA.Breanan, J. W.; Kaplan, R. M.; Peters, P. S.; and Zaenen, A., 1982.Cross-serial Dependencies in Dutch.
Ling.
Inqu/ry 13:613-635.Chandn, A. K.; Kozen, D. C.; and Stockmeyer, L J., 1981.
Alternation.J.
ACM 28:114-122.Gazdar, G., 1985.
Applicability of Indexed Grammars to Natural Lan.guages.
Technical Report CSLI-85-34, Center for Study of Languageand Information.Gazdar, G.; Klein, E.; Pullum, G. K.; and Sag, I.
A., 1985.
General-ized Phrase Structure Grammars.
Blackwell Publishing, Oxford.
Alsopublished by Harvard University Press, Cambridge, MA.Joshi, A. K., 1985.
How Much Context-Sensitivity is Necessary forCharacterizing Structural Descriptions - - Tree Adjoining Grammars.
InDowry, D.; Karuunan, L; and Zwicky, A.
(editors), Natural LanguageProceauing ~ Theoretical, Computational nd Psychological Perspec-tive.
Cambridge University Press, Hew York, NY.
Originally presentedin 1983.Joshi, A. K., 1987.
An Introduction to Tree Adjoining Grammars.
InManaater-gamer, A.
(editor), Mathematics of Language.
John Ben-jamins, Amsterdam.Jeshi, A. K.: Levy, L. S.; and Takahashi, M., 1975.
Tree AdjunctGrammars.
J Comput.
Syst.
Sci.
10(I).Perikh, IL, 1966.
On Context Free Languages.
J. ACM 13:570--581.Pollard, C., 1984.
Generalized Phrase Structure Grammars, HeadGrammars and Natural Language.
PhD thesis, Stanford University.Rounds, W. C. LFP: A Logic for Linguistic Descriptions and an Anal-ysis of its Complexity.
To appear in Comput.
Ling.Rounds, W. C., 1969.
Context-free Grammars on Trees.
In IEEE \]OthAnnual Symposium on Switching and Automata Theory.Steedman, M. J., 1985.
Dependency and Coordination i the Grammarof Dutch and English.
Language 61".523-568.Steedman, M., 1986.
Combinntory Grammars and Parasitic Gaps.
Nat-ural Language and Linguistic Theory (to appear).Thatcher, J. W., 1973.
Tree Automata: An informal survey.
In Aho,A.
V. (editor), Currents in the Theory of Computing, pages 143-172.Prentice Hall Inc., Englewood Cliffs, NJ.Weir, D. J., 1987.
Context-Free Grammars to Tree Adjoining Gran-mmars and Beyond.
Technical Report, Department of Computer andInformation Science, University of Pennsylvania, Philadelphia.111
