Automated Induction of Sense in ContextJames PUSTEJOVSKY, Patrick HANKS, Anna RUMSHISKYBrandeis UniversityWaltham, MA 02454, USA{jamesp,patrick,arum}@cs.brandeis.edu1 IntroductionIn this work, we introduce a model for sense assign-ment which relies on assigning senses to the con-texts within which words appear, rather than to thewords themselves.
We argue that word senses assuch are not directly encoded in the lexicon of thelanguage.
Rather, each word is associated with oneor more stereotypical syntagmatic patterns, whichwe call selection contexts.
Each selection context isassociated with a meaning, which can be expressedin any of various formal or computational manifesta-tions.
We present a formalism for encoding contextsthat help to determine the semantic contribution of aword in an utterance.
Further, we develop a method-ology through which such stereotypical contexts forwords and phrases can be identified from very largecorpora, and subsequently structured in a selectioncontext dictionary, encoding both stereotypical syn-tactic and semantic information.
We present somepreliminary results.2 CPA MethodologyThe Corpus Pattern Analysis (CPA) technique usesa semi-automatic bootstrapping process to producea dictionary of selection contexts for predicatesin a language.
Word senses for verbs are distin-guished through corpus-derived syntagmatic pat-terns mapped to Generative Lexicon Theory (Puste-jovsky (1995)) as a linguistic model of interpreta-tion, which guides and constrains the induction ofsenses from word distributional information.
Eachpattern is specified in terms of lexical sets for eachargument, shallow semantic typing of these sets, andother syntagmatically relevant criteria (e.g., adver-bials of manner, phrasal particles, genitives, nega-tives).The procedure consists of three subtasks: (1) themanual discovery of selection context patterns forspecific verbs; (2) the automatic recognition of in-stances of the identified patterns; and (3) automaticacquisition of patterns for unanalyzed cases.
Ini-tially, a number of patterns are manually formulatedby a lexicographer through corpus pattern analysisof about 500 occurrences of each verb lemma.
Next,for higher frequency verbs, the remaining corpus oc-currences are scrutinized to see if any low-frequencypatterns have been missed.
The patterns are thentranslated into a feature matrix used for identifyingthe sense of unseen instances for a particular verb.In the remainder of this section, we describe thesesubtasks in more detail.
The following sections ex-plain the current status of the implementation ofthese tasks.2.1 Lexical DiscoveryNorms of usage are captured in what we call selec-tion context patterns.
For each lemma, contextsof usage are sorted into groups, and a stereotypi-cal CPA pattern that captures the relevant semanticand syntactic features of the group is recorded.
Forexample, here is the set of common patterns for theverb treat.
(1) CPA pattern set for treat:I.
[[Person 1]] treat [[Person 2]] ({at | in} [[Location]])(for [[Event = Injury | Ailment]]); NO [Adv[Manner]]II.
[[Person 1]] treat [[Person 2]] [Adv[Manner]]IIIa.
[[Person]] treat [[TopType 1]] {{as | like} [[TopType 2]]}IIIb.
[[Person]] treat [[TopType]] {{as if | as though | like}[CLAUSE]}IV.
[[Person 1]] treat [[Person 2]] {to [[Event]]}V. [[Person]] treat [[PhysObj | Stuff 1]] (with [[Stuff 2]])There may be several patterns realizing a singlesense of a verb, as in (IIIa/IIIb) above.
Addi-tionally, many patterns have alternations, recordedin satellite CPA patterns.
Alternations are linkedto the main CPA pattern through the same sense-modifying mechanisms as those that allow for coer-cions to be understood.
However, alternations aredifferent realizations of the same norm.
For exam-ple, the following are alternations for treat, pattern(I):[[Person 1 <--> Medicament | Med-Procedure | Institution]][[Person 2 <--> Injury | Ailment | Bodypart]]CPA PatternsA CPA pattern extends the traditional notion of se-lectional context to include a number of other con-textual features, such as minor category parsing andsubphrasal cues.
Accurate identification of the se-mantically relevant aspects of a pattern is not anobvious and straightforward procedure, as has some-times been assumed in the literature.
For example,the presence or absence of an adverbial of manner inthe third valency slot around a verb can dramaticallyalter the verb?s meaning.
Simple syntactic encodingof argument structure, for instance, is insufficient todiscriminate between the two major senses of theverb treat, as illustrated below.
(3) a.
They say their bosses treat them with respect.b.
Such patients are treated with antibiotics.The ability to recognize the shallow semantic typeof a phrase in the context of a predicate is of coursecrucial ?for example, in (3a) recognizing the PP as(a) an adverbial, and (b) an adverbial of manner,rather than an instrumental co-agent (as in (3b)),is crucial for assigning the correct sense to the verbtreat above.There are four constraint sets that contribute tothe patterns for encoding selection contexts.
Theseare:(4) a.
Shallow Syntactic Parsing: Phrase-level recogni-tion of major categories.b.
Shallow Semantic Typing: 50-100 primitive shal-low types, such as Person, Institution, Event, Abstract, Ar-tifact, Location, and so forth.
These are the top types se-lected from the Brandeis Shallow Ontology (BSO), and aresimilar to entities (and some relations) employed in NamedEntity Recognition tasks, such as TREC and ACE.c.
Minor Syntactic Category Parsing: e.g., loca-tives, purpose clauses, rationale clauses, temporal adjuncts.d.
Subphrasal Syntactic Cue Recognition: e.g.,genitives, partitives, bare plural/determiner distinctions,infinitivals, negatives.The notion of a selection context pattern, as pro-duced by a human annotator, is expressed as a BNFspecification in Table 1.1 This specification relieson word order to specify argument position, and iseasily translated to a template with slots allocatedfor each argument.
Within this grammar, a seman-tic roles can be specified for each argument, but thisinformation currently is not used in the automatedprocessing.Brandeis Shallow OntologyThe Brandeis Shallow Ontology (BSO) is a shallowhierarchy of types selected for their prevalence inmanually identified selection context patterns.
Atthe time of writing, there are just 65 types, in termsof which patterns for the first one hundred verbshave been analyzed.
New types are added occasion-ally, but only when all possibilities of using existingtypes prove inadequate.
Once the set of manuallyextracted patterns is sufficient, the type system willbe re-populated and become pattern-driven.The BSO type system allows multiple inheri-tance (e.g.
Document v PhysObj and Document vInformation.
The types currently comprising theontology are listed below.
The BSO contains typeassignments for 20,000 noun entries and 10,000 nom-inal collocation entries.1Round brackets indicate optional elements of the pattern,and curly brackets indicate syntactic constituents.Corpus-driven Type SystemThe acquisition strategy for selectional preferencesfor predicates proceeds as follows:(5) a. Partition the corpus occurrences of a predicate accordingto the selection contexts pattern grammar, distinguishedby the four levels of constraints mentioned in (4).
Theseare uninterpreted patterns for the predicate.b.
Within a given pattern, promote the statisticallysignificant literal types from the corpus for each argumentto the predicate.
This induces an interpretation of thepattern, treating the promoted literal type as the specificbinding of a shallow type from step (a) above.c.
Within a given pattern, coerce all lexical heads in thesame shallow type for an argument, into the promotedliteral type, assigned in (b) above.
This is a coercion of alexical head to the interpretation of the promoted literaltype induced from step (b) above.In a sense, (5a) can be seen as a broad multi-levelpartitioning of the selectional behavior for a pred-icate according to a richer set of syntactic and se-mantic discriminants.
Step (5b) can be seen as cap-turing the norms of usage in the corpus, while step(5c) is a way of modeling the exploitation of thesenorms in the language (through coercion, metonymy,and other generative operations).
To illustrate theway in which CPA discriminates uninterpreted pat-terns from the corpus, we return to the verb treat asit is used in the BNC.
Two of its major senses, aslisted in (1), emerge as correlated with two distinctcontext patterns, using the discriminant constraintsmentioned in (4) above.CPA-Pattern ?
Segment verb-lit Segment | verb-lit Segment | Segment verb-lit | CPA-Pattern ?;?
ElementSegment ?
Element | Segment Segment | ??
Segment ??
| ?(?
Segment ?)?
| Segment ?|?
SegmentElement ?
literal | ?[?
Rstr ArgType ?]?
| ?[?
Rstr literal ?]?
| ?[?
Rstr ?]?
| ?[?
NO Cue ?]?
| ?[?
Cue ?
]?Rstr ?
POS | Phrasal | Rstr ?|?
Rstr | epsilonCue ?
POS | Phrasal | AdvCueAdvCue ?
ADV ?[?
AdvType ?
]?AdvType ?
Manner | Dir | LocationPhrasal ?
OBJ | CLAUSE | VP | QUOTEPOS ?
ADJ | ADV | DET | POSDET | COREF POSDET | REFL-PRON | NEG |MASS | PLURAL | V | INF | PREP | V-ING | CARD | QUANT | CONJArgType ?
?[?
SType ?]?
| ?[?
SType ?=?
SubtypeSpec ?]?
| ArgType ?|?
ArgType | ?[?
SType ArgIdx ?]?
|?[?
SType ArgIdx ?=?
SubtypeSpec ?
]?SType ?
AdvType | TopType | Entity | Abstract | PhysObj | Institution | Asset | Location | Human | Animate |Human Group | Substance | Unit of Measurement | Quality | Event | State of Affairs | ProcessSubtypeSpec ?
SubtypeSpec ?|?
SubtypeSpec | SubtypeSpec ?&?
SubtypeSpec | Role | Polarity | LSetRole ?
Role | Role ?|?
Role | Benficiary | Meronym | Agent | PayerPolarity ?
Negative | PositiveLSet ?
Worker | Pilot | Musician | Competitor | Hospital | Injury | Ailment | Medicament | Medical Procedure |Hour-Measure | Bargain | Clothing | BodyPart | Text | Sewage | Part | Computer | AnimalArgIdx ?
<number> verb-lit ?
<verb-word-form>literal ?
word word ?
<word>CARD ?
<number> NEG ?
notPOSDET ?
my | your | ... INF ?
toQUANT ?
CARD | a lot | longer | more | many | ...Table 1: Pattern grammar(6) a.
[[Person 1]] treat [[Person 2]]; NO [Adv[Manner]]b.
[[Person 1]] treat [[Person 2]] [Adv[Manner]]Given a distinct (contextual) basis on which to an-alyze the actual statistical distribution of the wordsin each argument position, we can promote statisti-cally relevant and significant literal types for thesepositions.
For example, for pattern (a) above, thisinduces Doctor as Person 1, and Patient as boundto Person 2.
This produces the interpreted contextpattern for this sense as shown below.
(7) [[doctor]] treat [[patient]]Promoted literal types are corpus-derived andpredicate-dependent, and are syntactic heads ofphrases that occur with the greatest frequency in ar-gument positions for a given sense pattern; they aresubsequently assumed to be subtypes of the particu-lar shallow type in the pattern.
Step (5c) above thenenables us to bind the other lexical heads in these po-sitions as coerced forms of the promoted literal type.This can be seen below in the concordance sample,where therapies is interpreted as Doctor, and peopleand girl are interpreted as Patient.
(8) a. a doctor who treated the girl till an ambulance arrived.b.
over 90,000 people have been treated for cholerac.
nonsurgical therapies to treat the breast cancer, whichModel BiasThe assumption within GL is that semantic typesin the grammar map systematically to default syn-tactic templates (cf.
Pustejovsky (1995)).
Theseare termed canonical syntactic forms (CSFs).
Forexample, the CSF for the type proposition is atensed S. There are, however, many possible real-izations (such as infinitival S and NP) for this typedue to the different possibilities available from gen-erative devices in a grammar, such as coercion andco-composition.
The resulting set of syntactic formsassociated with a particular semantic type is calleda phrasal paradigm for that type.
The model biasprovided by GL acts to guide the interpretation ofpurely statistically based measures.2.2 Automatic Recognition of Pattern UseEssentially, this subtask is similar to the traditionalsupervised WSD problem.
Its purpose is (1) to testthe discriminatory power of CPA-derived feature-set, (2) to extend and refine the inventory of featurescaptured by the CPA patterns, and (3) to allow forpredicate-based argument groupings by classifyingunseen instances.
Extension and refinement of theinventory of features should involve feature induc-tion, but at the moment this part has not been im-plemented.
During the lexical discovery stage, lex-ical sets that fill some of the argument slots in thepatterns are instantiated from the training exam-ples.
As more predicate-based lexical sets withinshallow types are explored, the data will permitidentification of the types of features that unite ele-ments in lexical sets.2.3 Automatic Pattern AcquisitionThe algorithm for automatic pattern acquisition in-volves the following steps:(9) a.
Collect all constituents in a particular argument position;b.
Identify syntactic alternations;c. Perform clustering on all nouns that occur in a particularargument position of a given predicate;d. For each cluster, measure its relatedness to the knownlexical sets, obtained previously during the lexical discoverystage and extended through WSD of unseen instances.
Ifnone of the existing lexical sets pass the distance threshold,establish the cluster as a new lexical set, to be used in futurepattern specification.Step (9d) must include extensive filtering proceduresto check for shared semantic features, looking forcommonality between the members.
That is, theremust be some threshold overlap between subgroupsof the candidate lexical set and and the existing se-mantic classes.
For instance, checking if, for a cer-tain percentage of pairs in the candidate set, therealready exists a set of which both elements are mem-bers.3 Current ImplementationThe CPA patterns are developed using the BritishNational Corpus (BNC).
The sorted instances areused as a training set for the supervised disambigua-tion.
For the disambiguation task, each pattern istranslated into into a set of preprocessing-specificfeatures.The BNC is preprocessed with the RASP parserand semantically tagged with BSO types.
TheRASP system (Briscoe and Carroll (2002)) gener-ates full parse trees for each sentence, assigning aprobability to each parse.
It also produces a set ofgrammatical relations for each parse, specifying therelation type, the headword, and the dependent ele-ment.
All our computations are performed over thesingle top-ranked tree for the sentences where a fullparse was successfully obtained.
Some of the RASPgrammatical relations are shown in (10).
(10) subjects: ncsubj, clausal (csubj, xsubj)objects: dobj, iobj, clausal complementmodifiers: adverbs, modifiers of event nominalsWe use endocentric semantic typing, i.e., the head-word of each constituent is used to establish its se-mantic type.
The semantic tagging strategy is simi-lar to the one described in Pustejovsky et al (2002),and currently uses a subset of 24 BSO types.A CPA pattern is translated into a feature set,currently using binary features.
It is further com-plemented with other discriminant context featureswhich, rather than distinguishing a particular pat-tern, are merely likely to occur with a given subsetof patterns; that is, the features that only partiallydetermine or co-determine a sense.
In the future,these should be learned from the training set throughfeature induction from the training sample, but atthe moment, they are added manually.
The result-ing feature matrix for each pattern contains featuressuch as those in (11) below.
Each pattern is trans-lated into a template of 15-25 features.
(11) Selected context features:a. obj institution: object belongs to the BSO type ?Insti-tution?b.
subj human group: subject belongs to the BSO type ?Hu-manGroup?c.
mod adv ly: target verb has an adverbial modifier, with a-ly adverbd.
clausal like: target verb has a clausal argument intro-duced by ?like?e.
iobj with: target verb has an indirect object introducedby ?with?f.
obj PRP: direct object is a personal pronoung.
stem VVG: the target verb stem is an -ing formEach feature may be realized by a number of RASPrelations.
For instance, a feature dealing withobjects would take into account RASP relations?dobj?, ?obj2?, and ?ncsubj?
(for passives).4 Results and DiscussionThe experimental trials performed to date are toopreliminary to validate the methodology outlinedabove in general terms for the WSD task.
Our re-sults are encouraging however, and comparable tothe best performing systems reported from Senseval2.
For our experiments, we implemented two ma-chine learning algorithms, instance-based k-NearestNeighbor, and a decision tree algorithm (a version ofID3).
Table 2 shows the results on a subset of verbsthat have been processed, also listing the number ofpatterns in the pattern set for each of the verbs.2verb number of training accuracypatterns set ID3 kNNedit 2 100 87% 86%treat 4 200 45% 52%submit 4 100 59% 64%Table 2: Accuracy of pattern identificationFurther experimentation is obviously needed toadequately gauge the effectiveness of the selectioncontext approach for WSD and other NLP tasks.It is already clear, however, that the traditionalsense enumeration approach, where senses are asso-ciated with individual lexical items, must give wayto a model where senses are assigned to the contextswithin which words appear.
Furthermore, becausethe variability of the stereotypical syntagmatic pat-terns that are associated with words appears to berelatively small, such information can be encoded aslexically-indexed contexts.
A comprehensive dictio-nary of such contexts could prove to be a powerfultool for a variety of NLP tasks.ReferencesT.
Briscoe and J. Carroll.
2002.
Robust accurate statistical anno-tation of general text.
Proceedings of the Third InternationalConference on Language Resources and Evaluation (LREC2002).J.
Pustejovsky, A. Rumshisky, and J. Castano.
2002.
RerenderingSemantic Ontologies: Automatic Extensions to UMLS throughCorpus Analytics.
In LREC 2002 Workshop on Ontologiesand Lexical Knowledge Bases..J. Pustejovsky.
1995.
Generative Lexicon.
Cambridge (Mass.
):MIT Press.2Test set size for each lemma is 100 instances, selected outof several randomly chosen segments of BNC, non-overlappingwith the training set
