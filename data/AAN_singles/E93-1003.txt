Experiments in Reusabil ity of Grammatical ResourcesDoug Arno ld  ?
Ton i  Bad ia  ?, Jose f  van  Genab i th% Ste l la  Markantonatou  ?S te fan  Momma% Lou isa  Sad ler  ?, Pau l  Schmidt  ?
?Dept  of Language and Linguistics, Univers i ty of Essex, Colchester C04  3SQ, UK?Un ivers i ta t  Pompeu Fabra, La Ramba 32, 08002 Barcelona, Spain?
IMS-CL ,  Azenbergstraf le 12, Univers i ty of Stut tgart ,  D-W7000 Stut tgart ,  GermanyDIAI, Martin-Luther-Strai~e 14, D-W6600 Sa~rbrficken 3, Germanydoug;marks; louisa@essex.ac.uk, tbadia@upf.es,steff ; josef@ims.uni-stuttgart.de, paul@iai.uni-sb.deAbst rac t  1 In t roduct ionSubstantial formal grammatical and lex-ical resources exist in various NLP sys-tems and in the form of textbook speci-fications.
In the present paper we reporton experimental results obtained in man-ual, semi-antomatic and automatic migra-tion of entire computational ortextbook de-scriptions (as opposed to a more informalreuse of ideas or the design of a single "poly-theoretic" representation) from a varietyof formalisms into the ALEP formalism.
1The choice of ALEP (a comparatively lean,typed feature structure formalism based onrewrite rules) was motivated by the as-sumption that the study would be mostinteresting if the target formalism is rel-atively mainstream without overt ideolog-ical commitments o particular grammat-ical theories.
As regards the source for-malisms we have attempted migrations ofdescriptions in HPSG (which uses fully-typed feature structures and has a strong'non-derivational' f avour), ETS (an un-typed stratificational formalism which es-sentially uses rewrite rules for feature struc-tures and has run-time non-monotonic de-vices) and LFG (which is an un-typed con-straint and CF-PSG based formalism withextensions such as existential, negative andglobal well-formedness constraints).1 The work reported in this paper was supported bythe CEC as part of the project ET10/52.Reusability of grammatical resources i an importantidea.
Practically, it has obvious economic benefits inallowing grammars to be developed cheaply; for the-oreticians it is important in allowing new formalismsto be tested out, quickly and in depth, by providinglarge-scale grammars.
It is timely since substantialcomputational grammatical resources exist in vari-ous NLP systems, and large scale descriptions mustbe quickly produced if applications are to succeed.Meanwhile, in the CL community, there is a percep-tible paradigm shift towards typed feature structureand constraint based systems and, if successful, mi-gration allows such systems to be equipped with largebodies of descriptions drawn from existing resources.In principle, there are two approaches to achiev-ing the reuse of grammatical and lexical resources.The first involves toring or developing resources insome theory neutral representation language, and isprobably impossible in the current state of knowl-edge.
In this paper, we focus on reusability throughmigration--the transfer of linguistic resources (gram-matical and lexical descriptions) from one compu-tational formalism into another (a target computa-tional formalism).
Migration can be completely man-ual (as when a linguist attempts to encode the analy-ses of a particular linguistic theory in some compu-tationally interpreted formalism), semi-automatic orautomatic.
The starting resource can be a paper de-scription or an implemented, runnable grammar.The literature on migration is thin, and practicalexperience is episodic at best.
Shieber's work (e.g.\[Shieber 1988\]) is relevant, but this was concernedwith relations between formalisms, rather than onmigrating grammars per se.
He studied the extentto which the formalisms of FUG, LFG and GPSGcould be reduced to PATlt-II.
Although these stud-12ies explored the expressivity of the different grammarformalisms (both in the strong mathematical nd inthe functional sense, i.e.
not only which class ofstring sets can be described, but also what can bestated directly or naturally, as opposed to just beingencoded somehow or other), the reduction was notintended to be the basis of migration of descriptionswritten in the formalisms.
In this respect he workdescribed below differs substantially from Shieber'swork: our goal has to be to provide grammars in thetarget formalisms that can be directly used for fur-ther work by linguists, e.g.
extending the coverage orrestructuring the description to express new insights,etc.The idea of migration raises some general ques-tions.?
What counts as successful migration?
(e.g.what properties must the output/target descrip-tion have and which of these properties are cru-cial for the reuse of the target description?).?
How conceptually close must source and targetbe for migration to be successful??
How far is it possible to migrate descriptions ex-pressed in a richer formalism (e.g.
one that usesmany expressive devices) into a poorer formal-ism?
For example, which higher level expres-sive devices can be directly expressed in a 'lean'formalism, which ones might be compiled owninto a lean formalism, and which ones are trulyproblematic?
Are there any general hints thatmight be given for any particular class of higherlevel expressive devices?
When should effort beput into finding encodings for richer devices, andwhen should the effort go into simply extendingthe target formalism??
How important is it that the source formalismhave a well-defined semantics?
How far candifficulties in this area be off-set if the gram-mars/descriptions are well-documented??
How does the existence of non-monotonic de-vices within a source formalism effect migrata-bility, and is it possible to identify, for a givensource grammar, uses of these mechanisms thatare not truly non-monotonic in nature and couldthus still be modelled inside a monotonic de-scription??
To what extent are macros and preprocessors auseful tool in a step-wise migration from sourceto target?We can provide some answers in advance of ex-perimentation.
In particular, successful migrationimplies that the target description must be practi-cally usablc that is, understandable and extensible.There is one exception to this, which is where a largegrammatical resource is migrated solely to test the(run-time) capabilities of a target formalism.
Practi-cally, usability implies at least I /O equivalence withthe source grammar but should .ideally also imply thepreservation of general properties uch as modular-ity, compactness and user-friendliness of the specifi-cation.This paper reports on and derives some lessonsfrom a series of on-going experiments in whichwe have attempted automatic, semi-automatic andmanual migration of implemented grammatical ndlexical resources and of textbook specifications, writ-ten in various 'styles', to the ALEP formalism (seebelow).
The choice of ALEP was motivated by theassumption the study would be most interesting ifthe target formalism is relatively mainstream.
2 Asregards the 'style' and expressivity of source for-malisms, we have carried out migrations from HPSG,which uses fully-typed feature structures and a vari-ety of richly expressive devices, from ETS grammarsand lexicons 3 (ETS is an untyped stratificationalformalism essentially using rewrite rules for featurestructures), and from an LFG grammar 4 (LFG is astandard untyped AVS formalism with some exten-sions, with a CFG backbone).2 The  Migrat ion  Exper iments2.1 The Target  Formal ismThe target formalism, ALEP, is a first prototype im-plementation of the formalism specified in the ET-6 design study (the ET-6 formalism \[Alshawi et al1991\]).
ET-6 was intended to be an efficient, main-stream CL formalism without ideological commit-ments to particular grammatical theories and suit-able for large-scale implementations.
It is declara-tive, monotonic and reversible, although in ET-6 andin ALEP it is possible to model certain on-monotonicoperations (e.g.
getting some treatment of defaultsout of parametrised macros).
ALEP is CF-PSG rulebased and supports feature structures which aretyped and simple inheritance between types.
Typeinformation and inheritance is effective only at com-pile time.
ALEP provides atoms, lists, booleans andterms as basic types.
Complex structured types andsimple inheritance relations are defined by the user ina type system specification.
In addition to standardgrammar ules which are effective during a parse(generation) the formalism provides refinement ruleswhich operate on the output of the parser and spec-ify values which are still undefined after parsing byusing only unification.
Although the core formal-ism is rather conservative, for reasons of efficiency,it is intended to support the eventual inclusion ofa periphery including external constraint processing20f course, for practical purposes one might want tomigrate resources to a non-standaxd formalism, providedit is relatively easy to understand.3Developed at Saaxbrficken, Essex and UMIST duringthe EUROTRA project.4Developed at Stuttgart as part of the EUROTRAaccompanying research, see \[Meier 1992\].13modules.
Similarly, it does not (yet) directly providepotentially computationally expensive xpressive de-vices such as e.g.
set-valued features and operationson sets, functionally dependent vMues, separation ofID and LP statements, multiple inheritance or mem-bership and concatenation constraints on lists.
Theidea is that such extensions should be provided, prob-ably as external modules, as and when they are foundto be necessary.
52.2 Manua l  M igrat ion  f rom HPSGAlthough both HPSG and ALEP use typed featurestructures and support type inheritance, they dif-fer crucially in that HPSG specifications are con-sciously non-derivational nd strongly modularisedin terms of sets of principles, immediate dominanceschemata nd linear precedence statements operat-ing as constraints on typed feature structures.
Toachieve this, HPSG employs a number of powerfuldescriptive devices, including list and set operations(often expressed as functionally dependent values),and multiple type inheritance.
The focus for theHPSG , ALEP conversion, then, is to what ex-tent can the latter, rather lean formalism support ina reasonable way the style of linguistic specificationfound in HPSG (the source specifications for this ex-eriment was the description of English provided inollard & Sag 1992\]).Various approaches to conversion are possible.
Forexample, it would be possible to define a user lan-guage permitting the expression of principles (inmuch the same way as some formalisms permit fea-ture percolation principles to be separately stated)and a compiler into ALEP allowing their effects tobe expanded into the rules.
In this spirit, follow-ing the work of Mellish \[Mellish 1988\] the techniqueof encoding boolean combinations of atomic featurevalues so that satisfaction can be checked by unifi-cation is adopted in the ET-6 formalism \[Alshawi etal.
1991\].Since there were open questions as what could bedirectly expressed in ALEP, in this conversion experi-ment we first took a direct approach, essentially em-ploying ALEP as a feature term rewriting system forHPSG specifications.
The focus of this conversionwas mainly on exploring the limits of the expressiv-ity of ALEP and thus identifying which higher levelexpressive devices could not be treated.The resulting translation is not as perspicuous,modular, compact and maintainable as the originalHPSG specification.
Migration results in a fragmen-tation and particularisation of the linguistic infor-mation encoded in the original specification.
This isbecause (i) HPSG principles and schemata have tobe compiled out into (possibly large) sets of ALEPSApar t  f rom invest igat ing issues involved in migrat ionof descriptions, one motivation for these experiments ito explore just which devices are essential for expressinglinguistically motivated grammatical descriptions.phrase-structure ules; and (ii) some descriptionscast in a richly expressive formalism have to be sim-ulated and can often only be approximated in ALEP.For example, ID-2 and the valence principle as itapplies to ID-2, (1) has to be approximated with setsof ALEP rules of the form in (2), because of the lackof the functional constraint va l_append.
(1) ID-2 and Valence Principle (simplified):\[SYlgSEM \[ LOC \[ CAT \[ COMPS e 1DRTS l HDTR\[ SYNSEN \[ L0C l CAT l CONPS va l _append(@ 1,  @2)COMPDTRS @2\](2)  ALEP  rules for ID2:id_2_0  = s ign :{  .
.
.
.
comps => I'\] .
.
.
.  }
->\ [ s ign :{  .... comps  => \[\] .... }\] head  1.id_2_1 = s ign :{  .
.
.
.
comps => \ [ \ ]  .
.
.
.  }
->\ [ s ign :{  .
.
.
.
comps => IX\]  .
.
.
.  }
,s ign :{  .
.
.
.
synsel => X .
.
.
.
}\] head 1.id_2_2 = sign:{ .
.
.
.
comps -> \[\] .
.
.
.  }
->\ [ s ign :{  .
.
.
.
comps => IX,Y\]  .
.
.
.
},sign:{ .
.
.
.
synsel -> I .
.
.
.
},s ign :{  .
.
.
.
synse l  => Y .
.
.
.
}\] head 1.id_2_3 = .
.
.
.
.
.
.
.
.
.
.
.
.Of course, by adopting binary branching trees andaltering the ID and Subcategorisation principles itwould be possible to avoid some of this verbosity, butfor the purposes of our experiment we considered itimportant o investigate the migration of the sourceformalism as is.Note that the resulting ALEP specification i  (2) isas compact, perspicuous and maintainable as in anyrule based grammar formalism, although it comparesbadly with HPSG in these terms.
While initially itseemed that it was possible to create a usable, ex-tensible and understandable ALEP grammar on thebasis of HPSG specifications, there is one feature ofHPSG which remains problematic, that of set-valuedfeatures and set operations.
The difficulty comes inmodelling principles such as the HPSG QuantifierInheritance Principle (QIP), which relies on the op-erations uch as set union and complementation.In ALEP set union can be approximated to a certainextent in terms of list concatenation i  a differencelist based threading approach.
However, since thecurrent implementation of ALEP does not even pro-vide membership constraints on list representations,element and set difference constraints can only be ap-proximated in terms of a multitude of minimally dif-fering rules naming elements in set representations.This approach is only safe if the following two con-ditions hold:?
the sets involved are finite?
elements in the difference list representations ofsets are uniqueEven for small sets, however, any exhaustive im-plementation of set difference in terms of naming el-14"SYNSEM: \[LOC: \[CONTENT:\[QUANTS:RETR U HQUANTS\]\]\]QSTORE:(HQSTORE U QUANTS1 U...U QUANTS,}- RETRRETRVD:RETRFHDTR:\[SYNSEM:\[LOC: \[ ONTENT:\[QUANTS:HQUANTS\]\] \]\]\]DTRS: I ?TRI IQSTO.\] RE:QuANTSI\] J LDTR.
\[QSTORE:QUANTS,\]Figure h Quantifier Inheritance Principle (simplified)ements in the representation results in an unaccept-able number of rules and associated parse time.
Insome cases we were able to avoid this problem byrelegating e.g.
quantifier etrieval to sets of refine-ment rules which operate on parse objects which areeffectively underspecified for quantifier scope.It soon became clear that sets of refinement rulesare not a general solution for the modelling of el-ement or set complement constraints in HPSG be-cause they operate on the output of a parse andhence cannot decide about the 'phrase' structure ofa sign.
Introducing and filling gaps, however, is cen-tral to the structure of a sign.
The Nonlocal FeaturePrinciple (NFP) which is at the heart of the ttPSGtreatment of unbounded ependency constructions(UDCs) ensures that SYNSEM I NONLOC I INHER valuesare discharged in terms of a set difference specifica-tion which cannot be implemented in terms of setsof refinement rules since it directly decides aboutthe well-formedness of strings in terms of the phrasestructure of the sign.IOTR.
: \[SYNSEM:\[NONtOC:tINHER:Sn\]\]\]Figure 2: Nonlocal Feature Principle (simplified)Furthermore, parasitic gap phenomena in English asin That was the rebel eader who rivals of_ shot _suggest hat at least as far as the NFP is concernedit is problematic to asssume that elements in the dif-ference list representations of sets are unique.
Thisassumption is crucial to modeling set union in termsof list concatenation.Formally, HPSG principles can either be given thestatus of proper types or that of typed feature struc-ture templates acting as constraints on other featurestructures.
In ALEP the first option is not availableto us since apart from subtype or supertype infor-mation the type system specification does not allowthe specification of a type other than in terms ofits root attributes and the type of their correspond-ing values and more importantly it does not supportmultiple inheritance required to inherit principles toother types.
In order to recapture some of the loss ofmodularity in compiling out HPSG principles oversets of ALEP rules we thus tried to pursue the sec-ond option using m4 macros to directly state princi-ples.
m4 is a standard UNIX facility which allows forparameterised and non-parameterised macros, con-ditional expansions and numeric operations.
Macrosare expanded externally to ALEP and not during com-pilation time.
Each HPSG principle can be rep-resented as a feature structure template which inturn can be specified in terms of a macro defini-tion, or so it seems.
The problem here, however, isthat since IIPSG principles mutually constrain signs,the conjunction of such principles (at least in simplecases) corresponds to the unification (or merging) oftheir feature structure template representations (ifthe conjunction is satisfiable).
What standard macrofacilities achieve is effectively a simple lexical expan-sion of strings and it is impossible to get the mergingeffect of unification of template feature structures outof a modular macro specification of such templates.Basically, three options are available to us:(i) To get the overlapping effect of unification weintegrate different principles into one macro.
(ii) We define extended types with special attributesfor each of the relevant HPSG principles whichare expanded by modular macro definitions ofthe principles and get the unification effect fromALEP at compile time through proper coindexa-tion.phrase{phrase ffi> QS{PHRASE},hfp ffi> @S{HEAD_FEATURE_PRINC},sp ~> @S{SEMANTICS_PRINC},qip -> QS{QUANTIF_INHERIT_PRINC},valp => GS{VALENCY_PRINC}}(iii) We use a more powerful 'macro' processor likee.g.
Prolog which provides the unification effectand define a map into ALEP.In the case of (i) the modularity of ttPSG withseparately stated, but interacting principles is lost.
(ii) hasthe disadvantage that the ALEP specificationsgrow in size while in the case of (iii) we are not con-15sidering the expressivity of the target formalism it-self.2.3 Automat ic  M igrat ion  f rom ETS B-rulesIn this section we draw some general conclusionsfollowing from our experience of attempting auto-matic migration from an untyped rule-based formal-ism.
Specifically, the source for this experiment wasthe structure-building rules of some relatively largeETS grammars.
The ETS formalism is "badly be-haved" in that it contains a rich array of devices ad-ditional to the structure-building or B-rules, many ofwhich are non-monotonic, and which apply at run-tim e (they are mainly output filters and various typesof feature percolation rules).
We have written an au-tomatic compiler in Prolog which calculates a verysimple type system and automatically migrates thestructure rules and lexical descriptions.
With respectto the source formalism in question, the followingpoints are to be noted:?
The run-time non-monotonic devices found inETS are extremely problematic to take into ac-count in automatic direct migration.
We doubtwhether it would be possible to write an intelli-gent compiler which directly encoded the effectof these devices in the resultant ALEP rule set.
Ifthey are ignored in the migration process, thenof course the source and target descriptions arenot I /O equivalent.?
The B-rules themselves allow optionality, Kleeneclosure, positive Kleene closure and disjunctionover (sequences of) daughters to any degree ofembedding within each other.
In ALEP suchrules have to be compiled out into a normalform which allows only for optionality over sin-gle daughters and no disjunctions of daughters.The size of the resulting rule set is such thatit cannot be reasonably maintained.
The sizealso means that it is impossible for a linguist tomanually "correct" an overgenerating grammarresulting from the omission of filters and featurerules above.?
In some cases, it became apparent during themigration process that the intended semanticsof the (very complex) phrase structure rules wasunclear (e.g.
regarding the scope of variables inKleene starred constituents).One conclusion is that one of the crucial ingredi-ents is the quality and detail of the documentationof grammars.
With good documentation it is oftenpossible to get around the effects of unclear ule se-mantics, because the rule writers intention can beunderstood.
The lack of such documentation is se-rious, since it means the migrator has to try to in-tuit the intended behaviour by attempting to run thesource grammars in the source formalism.Similarly, so long as the intended interpretation isclear, it may be possible to deal with non-monotonicdevices.
This is most obvious where the non-monotonic effects do not persist to run-time (butsee also our discussion of the LFG migration below).For example the ALVEY grammar \[Carroll 1991\] hasthem, but since there is an object grammar stagein which all this is compiled out, the non-montonicdevices can be avoided by taking the object gram-mar as the input to migration.
The issue is thenwhether it is possible to automatically 'recompact'the target grammar in some linguistically useful way,or whether all extension and maintenance should bedone in the source formalism.Note further that even if the grammars resultingfrom a migration are not linguistically useful (for ex-ample, because the grammar is not maintainable orextensible), they may serve some purpose in testingthe capacity of the target formalism to operate (ef-ficiently) with very large rule sets (for example, inour experimentation, a rule set of some 1,500 rulesderived by automatic migration caused ALEP to failto compute the link relation).ETS lexical descriptions are more successfully mi-gratable because their semantics is clear.
Simpleparameterised macros have been used in a semi-automatic migration process.2.4 Automat ic  LFG impor ta t ion  in to  ALEPLFG is an untyped constraint-based linguistic for-realism with rich expressive devices built around aCFG backbone.
The formalism has been imple-mented in various ystems, including XEROX PARC'sGrammar Writer's Workbench, and the CHARONsystem developed as part of the accompanying re-search for EUROTRA-D carried out at the Universityof Stuttgart.
Our automatic migration experimentstarted from grammars written for the latter system.We have written a Prolog program that translatesautomatically from an LFG notation that is veryclose to the original specification in \[Bresnan 1982\]i n to  ALEP.
For reasons explained further below, theprogram cannot succeed in all cases.
It is, however,capable of detecting those cases reliably, and gener-ates warnings where the fully automatic translationfails.
6 Examples for typical rules from the sourcegrammar are shown in figure 3.
7The translation of the rule format illustrated in fig-ure 3 into a PROLOG readable form is performed bya subcomponent of the CHARON system.
The auto-matic translation procedure makes use of the outputof this precompilation step.The rule format supports optionality of con-stituents, nested optionalities and Kleene starredrule parts, which have to be expanded in the ALI,~Ptranslation.
ALEP only supports optionality of singledaughters in the RHS of rules.
In our case, this partof the expansion is done by the preprocessor.
TheeThe program was developed by Dieter Kohl at IMS.7The caret sign and the lowercase v are ASCII repre-sentations of the metavariables T and 1, respectively.16VP'' -> VP'\ [v{/ (- vco~)  = v/ =v  /}---- V\].Cl -> CVP2= v{/ " = v{/(" VTYPE) = v2/(" VTYPE) = v l  /}\[(" FCOMP) = v{ /  (" VTYPE) = v: f in/ (" VTYPE) = inf /}/}.Figure 3: Sample grammar rules from the source de-scriptionresult of compiling out Kleene starred rules and op-tionalities i  that the object grammar quickly reachesa size that can no longer be reasonably maintainedand the target description contains elements (in thiscase auxiliary categories) which are not part of thelinguistic intuition of the grammar writer.The second characteristic feature of rules like theones shown in figure 3 is the massive use of complexdisjunctions over feature structures (indicated by the{\ and \} pairs).
Although the ALEP formalism sup-ports disjunctions over complex feature structures,due to problems in the implementation available atthe time of the experiment, they had to be multipliedout into a possibly large number of separate rules.The next example (figure 4) shows a typical exicalentry from the source grammar.bietet: V, (~ OBJ AGR CAS) =acc(" PLIED) = "bieten <(" SUBJ)(" OBJ)>"(" SUBJ AGE Bq/M) = sg(" SUBJ AGR CAS = nora(" TENSE) = present(" INF) =-(" FORM) =c an <---(" VERBTYPE) = particle.Figure 4: Sample lexicon entry from the source de-scriptionThe basic part of the annotations ofthe LFG rulesand lexicon, i.e.
the defining equations, are mappedeasily into ALEP.
The work here is divided betweenthe CHARON preprocessor which converts feature de-scriptions (the equations) into feature terms, and theoutput routine which maps feature terms into ALEPrules and lexicon entries.In LFG, path specifications in equations can bevariables, as in the (" (v PCASE)) case, where the at-tribute under which the f-structure associated with vis determined by the value of a feature inside v. ALEPdoes not support variable path expressions, thereforewe have to enumerate all possible paths in a large dis-junction which adds another factor to the multiplica-tive expansion of the rule set.
Similar facts hold forthe implementation f functional uncertainty, wherewe have to deal with regular expressions over paths, sLFG permits "special" types of equation besidesthe standard efining ones.
Constraining (=c type)equations in our source grammar typically occur inlexical entries as the one shown in figure 4, wherea given form of e.g.
a verb has to be distinguished,because it is only used in particular contexts.
Theequation is then typically a specification of a specialsubclass of a more general class of verbs (here a verbwhich can occur with a separable prefix).
Where thisis the case, in the migrated escription the relevantdistinction can be made in the type system, ensur-ing that non-membership in the particular subtypeis explicitly stated for all (relevant) members of thesupertype.Another, potentially very powerful expressive de-vice in the LFG formalism is the use of existentialand negative xistential constraints (in the CHARONnotation expressed as !
(" INF) and "("  INF), re-spectively).
Current implementations of LFG delaythe evaluation of such constraints, because in gen-eral, they can only be tested at the end of the pro-cessing of a whole utterance.
It turns out, however,that quite often existential and negative xistentialconstraints can be disposed of, if a full type sys-tem is available.
Careful examination of the sourcegrammars reveals that the prevalent use of such con-straints is exactly to model what feature appropriate-ness conditions in a type system do: they restrict heapplication of particular ule types to feature struc-tures where a given set of features is either present orabsent.
To model this by using the type system in-stead, we introduce subtypes of the structure wherethe path has to or must not exist.If the source grammar only uses negative xisten-tial constraints for atomic valued features, we couldeasily formulate a proper type system, and do awaywith ' - ' ,  and '!'
in a rather straightforward manner.Typical uses of e.g.
negative xistential constraintsare shown in the rule and lexical entry in figure 5.LFG uses set values for collecting e.g.
adjunctswhich do not have any other distinguishing functionon the f-structure level.
ALEP does not support thedirect expression of sets as values.
Given the factsof German word order, generation would seem to re-quire sets of ADJUNCTS as values, rather than lists.Here we do in fact loose some expressivity if we tryto model adjuncts in ALEP using lists, because thecanonical set operations are not available.Finally, we have to be able to express the (non-monotonic) global completeness and coherence con-Sin a recent exper iment,  the implementors  of theCHARON system added support for functional uncer-tainty modelled via an interpretation of paths as se-quences and general operations on these sequences.17C ->V V{ / ( "  VTYPE) = v2/ ( "  VTYPE) ffi v l  /}" ( "  INF).kennen: V, (" PRED) ffi "kennen<("  SUBJ)(* 0BJ)>"(" OBJ AGR CAS) = ace( /  (" SUBJ AGR ~OM) ffi p l(" SUBJ AGR CIS) = nora(" TENSE) -- present" ( -  I~F)/ (" INF PEPS) - - -(" U~ACC) = - /}.Figure 5: Examples for negative existential con-straints in the rules and the lexiconstraints which help to control subcategorisation.
Ofthese two, the coherence condition can be easily con-trolled by defining types with the appropriate num-ber of features, one for each of the subcategorisedfunctions.
The introduction of additional syntacticfunctions which are not subcategorised for is thenprevented by the type system.
The completenesscondition, however, which is supposed to guaranteethat all syntactic functions in the subcategorisationframe are filled, can not be handled that easily.
Themain problem here is, that while we are able to re-quire that a certain feature be present in a featurestructure, we cannot express restrictions on the de-gree of instantiation of the value of that feature.There is, of course, another option: If we modelsubcategorisation more explicitly, introducing 'sub-cat lists' as data structures in much the same wayas HPSG does, we can add the requirement that PSrules consume lements of the subcat list.
Besidesthe question whether such a modelling is still com-patible with the spirit of LFG theory as it stands,the proposed solution does not solve the problemfor a German LFG grammar: in order to modelthe variability of German word order, we have tobe able to pick arbitrary elements from the subcatlist, rather than relying on a fixed order in which ele-ments are picked.
Since list operations (or functionalconstraints in general) are not available in ALEP, thiscan currently not be modelled perspiciously.In summary, then, the philosophy of the grammarcan be maintained, and a type system can be pro-vided.
To a certain extent, it can express LFG'snon-monotonic devices such as existential, negativeexistential and constraining equations and the globalwellformedness constraints of completeness and co-herence.
The target grammar is less compact, be-cause generalisations are lost, through the multi-plicatory effect of spelling out optionalities, Kleenestars and variables over attribute names.2.5 Technica l  descr ip t ion  o f  the  automat icconvers ion  procedureThe automatic onversion has to accomplish threebasic tasks:?
A conversion of the grammar ules into ALEPformat?
A conversion of lexical entries into the ALEPlexicon format?
The extraction of a certain amount of type in-formation from the LFG grammar to be used inthe ALEP descriptions.
9We will not go into details of the CHARON pre-compilation, since the techniques employed are stan-dard (expansion of optionality and Kleene star con-stituents, as well as compilation of feature descrip-tions into feature terms).
As regards the extractionof type information from the untyped LFG descrip-tion, more explanation is needed, however.In the current incarnation of the conversion rou-tine, the following strategies are used:?
each attribute is assigned (at least) one typename?
atomic-valued features and PREDS are used dur-ing compilation to compute value ranges fortheir corresponding types?
features with complex values have their possi-ble values (and the attributes therein) collectedduring compilation, and the compiler then de-termines the corresponding types at the end ofthe compilation.?
the output routines take care of the fact thattypes that represent atomic values or terms arespelt out correctly (i.e.
that they do not showup as type definitions, but are inserted irectly)?
if we encounter more than one type name forthe value of a given attribute, further processingis necessary, because reentrancies are involvedor we have an interaction with the e-structureskeleton which has to be handled separately.In all those cases, where the compilation cannot pro-duce satisfactory results, the intermediate structuresare printed out instead, together with a commentsaying which steps failed indicating where furtherhand-tuning is required.In particular,?
sets are encoded as open ended lists, thus notsolving the free order problem mentioned above?
the uniqueness condition is marked through theuse of a term for the value of PRED?
for compilation steps which modify the originalstructure of the grammar (e.g.
turning inequa-tions in finite domains into disjunctions, map-ping constraining equations onto defining ones,if the automatic inference of the proper subtypes?We also have to provide the ALEP runtime sys-tem with information about headness in grammar rules,which is crucial for the proper operation of at least oneof the parser modules provided with the system.18is not yet possible, etc.)
a warning is issued inthe resulting ALEP code in the form of a com-ments headness information is selected according tothe following heuristics:- derivation to e have no head informationassociated (naturally)- unary-branching odes have a trivial head- for non-unary-branching rules* those categories that can rewrite to e areeliminated from the list of head candi-dates (if all daughter nodes are elimi-nated this way, the first daughter is se-lected as the head, and a comment ap-pears with the rule)* if pure preterminal nodes are among theremaining ones, the first one is selectedas the head.
otherwise, all left-recursive nodes areeliminated (with a similar strategy fortaking the remaining leftmost node, ifall nodes would be eliminated).
among the remaining nodes, again theleftmost node is selected as the head* if everything is left-recursive, the left-most node is selected, and a comment isgenerated accordingly in the output.Compiling out the rule given in figure 3 yields(among others) the ALEP structure in figure 6, theresult of the compilation of the lexical entry fromfigure 5 is shown in figure 7 (again, only one of thedisjuncts is shown).vp2_vp_v  =ld: { spec => get_Specifier_t: { },syn => vp2_Syntax_t: { },f s  => QV_FS vp_Cat_t:{ vcomp -> Vp_I_FS},pho => phones: { s t r ing  -> Vp_Str,res t  => Rest } }->\[ ld: { syn => vp_Syntax t :  { },f s  => Vp_I_FS,pho => phones :{  s t r ing  => Vp_Str,rest => V_Str } }ld: { syn => v_Syntax_t: { },f s  => V_FS,pho => phones: { s t r ing  => V_Str,res t  => Rest } }\]head 2.Figure 6: Compiled rule from figure 13 ConclusionOur experiments have demonstrated that migrationsof various sorts can be performed with a reasonabledegree of success.kennen "Id: {spec => get_Specifier_t: {},pho => phones:{string-> \[kennen \[ R\],rest => R},syn => v_Syntax_t: { },subcat =>\ [ ld :{syn => alp_Syntax_t: {},f s  => Subj},ld:{ syn => dp_Syntax_t: {} ,f s  => Obj}\] ,f s  => cpl_Cat_t:{ pred -> pred_FS_t:{semuame => kennen,semargs => suhj_obj},subj "> @Subj dp_Cat_t:{pred "> _},obj -> @Obj dp_Cat_t:{pred => _,asr  -> agr_FS_t :{ cas -> ace}},inf -> inf_FS_t_kv: {perf => -},unacc  => -}}.Figure 7: Compiled lexical entry from figure 3As regards the general questions about migrationposed at the beginning, we can formulate some (par-tial) answers.?
Successful migration obviously involves morethan just I /O equivalence of source and targetdescriptions.
One also looks for similar degreesof 'descriptive adequacy' (i.e.
compactness, per-spicuity, maintainability etc.).
Clearly reusabil-ity implies usability.
However, this is not an ab-solute property, and a small loss of such proper-ties can be acceptable.
It is clear, however, thatthe loss of maintainability hat we have experi-enced in some of the migration activities aboveis unacceptable.?
How conceptually close must source and targetbe for migration to be successful?
We have seenthat in principle it is possible to migrate re-sources across certain formal/ideological divides- -  for example, from ttPSG, which has no rules,but uses types extensively, to ALE\]', which has aweaker type system, and is CF-PSG rule based;and from LFG (which does not use typed featurestructures) to ALEP.
The migration of IIPSGspecifications into the rule based ALEP entailsa considerable degree of fragmentation a d par-ticularisation of the linguistic information en-coded in the original specification.
To a certainextent this can be recaptured if the target for-malism provides an integrated template facilitywhich is not restricted to simple lexical expan-sion.
We have also suggested that good docu-mentation can alleviate the effects of distance19between formalisms.?
With respect o the migration of descriptions us-ing richer expressive devices, it is clear that it issometimes possible to dispense with the richerdevices, and that some descriptions couched inricher formalims do not use them in any crucialway.
The HPSG conversion experiment, how-ever, has clearly shown that for set valued fea-tures, and operations on sets, a naive encodingis simply unacceptable.?
We have seen that the effect of non-monotonicdevices in a source formMism can be serious, es-pecially when it is combined with unclear rulesemantics (c.f.
the ETS conversion experiment).However, the existence of an 'object' formalismwhere the non-monotonic devices are compiledout (like in the case of the ALVEY grammars) isan asset, and again, good documentation helps.Particularly in the case of the LFG conversionexperiment i became clear that often there is acrucial difference between the availability of cer-tain non-monotonic devices and their actuM use.E.g.
it was found that existential constraints areoften used to express ubtype information.
Ifthe type system is rich enough, this informationcan be modelled in the type system specificationin the target formalism.?
As expected, we have found macros and pre-processors a useful tool, especially in the semi-automatic migration of lexical resources.
Inorder to approximate a principles based styleof linguistic description like in HPSG the tar-get formalism should be extended with an in-tegrated template facility which determines sat-isfiability of templates (principles) in terms ofunification.References\[Alshawi et al 1991\] Hiyan Alshawi, Arnold D J,Backofen It, Carter D M, Lindop J, Netter K,Pulman S G, Tsujii J & Uszkoreit H, (1991), Eu-rotra ETa/l: Rule Formalism and Virtual Ma-chine Design Study (Final Report), CEC 1991.\[Bresnan 1982\] Joan Bresnan (ed.
), (1982).
TheMental Representation of Grammatical Rela-tions.
MIT Press, Cambridge, Massachusetts,1982\[Carroll 1991\] J. Carroll, E. Briscoe & C. Grover(1991).
A Development Environment for LargeNatural Language Grammars, distributed withthe Third Release.\[Meier 1992\] Meier, J.
(1992).
"Eine Grammatikdes Deutschen im Formalismus der LexikalisehFunktionalen Grammatik unter Beriicksichti-gung funktionaler Kategorien".
Iteport, Univer-sit,it Stuttgart.\[Mellish 1988\] Chris Mellish (1988) "ImplementingSystemic Classification by Unification", Com-putational Linguistics, 14, pp 40-51.\[Pollard& Sag 1992\] Carl Pollard & Ivan Sag,(1992).
Head Driven Phrase Structure Gram-mar, Chicago University Press, forthcoming.\[Shieber 1988\] Stuart M. Shieber (1988), "Separat-ing Linguistic Analyses from Linguistic The-ories", in U. Reyle and C. l~hrer NaturalLanguage Parsing and Linguistics Theories,D.
Reidel Publishing Co. Dordrecht, pp 33-68.20
