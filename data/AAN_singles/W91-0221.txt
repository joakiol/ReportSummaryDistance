Lexicon, Ontology and Text MeaningBoyan A. OnyshkevychU.S.
Department of Defense andComputational Linguistics Program,Carnegie Mellon Universitybao@a, hi.
es.
cmu.
eduSergei NirenburgCenter for Machine TranslationSchool of Computer ScienceCarnegie Mellon Universitysergei @nl.
cs.
cmu.
eduAbstractA computationally relevant theory of lexical semantics must take into considerationboth the form and the content of three different static knowledge sources -- thelexicon, the ontological domain model and a text meaning representation language.Meanings of lexical units axe interpreted in terms of their mappings into the ontologyand/or their contributions to the text meaning representation.
We briefly describeone such theory.
Its precepts have been used in mONYSUS, a machine translationsystem prototype.1 IntroductionA comprehensive natural anguage processing system (NLP) must be able to analyzenatural anguage texts, and, having understood their content, generate other naturallanguage texts, depending on the nature of the underlying reasoning system.
Thus, in amachine translation system this "other" NL text will be a text in a different language butwith the same meaning; in a NL front end to a database, it will be the response to a query.In order to produce an appropriate NL output, the NLP system must "understand" theinput text.
In some systems this understanding is modeled as an acceptable match for apre-existing structural or literal pattern.
In knowledge-based systems it is customary tomodel understanding through representing the results of input text analysis as a set ofwell-formed structures in a specially-designed formal artificial anguage.
Such languagescome in a number of varieties and we are not arguing here about which ones are moreappropriate or promising.
The crucial point is that in order to have any explanatorypower, the atoms of this meaning representation language must be interpreted in termsof an independently motivated model of the world.
Moreover, if any realistic experimentshave to be performed with such an NLP system, this world model (sometimes calledontology) must be actually built, not only defined algebraically.
The process of NL analysisis then interpreted as putting lexical, syntactic, and prosodic units of the source textin correspondence with elements of the text meaning representation language.
Duringgeneration, the representation language units serve as input and the target language units,as output.
(This view of language processing is, of course, highly schematic - -  as will beseen from the more detailed iscussion which follows; but this is exactly the level of detailneeded at this point.
)238In our understanding, the purpose of the lexicon is to facilitate the above linking.Of course, the lexicon contains not only mappings into the ontology.
It also containsinformation about morphological, syntactic, pragmatic, and collocational properties ofthe lexical unit - -  since all and any of these components serve as clues at various tagesof the process of mapping text into representation r vice versa.
But the semantics ofmost of the open-class lexical items is described in terms of their mappings into instancesof ontological concepts.A generic view of the data flow in a system of the above class is given in Figure 1.
Theexperiences described in this paper elate to our work on DIONYSUS, a machine translationsystem.
The interaction between the ontology, the text meaning representation, and thelexicon in this system was the central point of our study.
This interaction takes place intwo spheres - -  both during actual processing of text and during knowledge acquisitionphase.
In what follows, we first briefly describe these three knowledge sources and theirinteractions, as they are implemented in DIONYSUS.
Next, we discuss some issues ofdistinguishing lexical and non-lexical knowledge and their co-existence in a comprehensiveNLP application.Justifying particular epresentation choices, details of coverage of specific phenom-ena and comparisons with other semantic and pragmatic NLP processors are beyond thescope of this paper.
See Nirenburg and Defrise, forthcoming, a and b; Carlson and Niren-burg, 1990; Meyer et al, 1990; Nirenburg, 1989; and Nirenburg and Goodman, 1990 foradditional details.Each of the three knowledge sources have both content and form - -  that is, a specialknowledge representation language has been developed for each of the knowledge sources(TAMERLAN for text meaning representation, a constraint language for representing ontol-ogy, and the structure of the lexicon entry for the lexicon).
These languages are necessarilyconnected in many ways (and in the implementation f DIONYSUS all are based on thesingle underlying knowledge representation system FRAMEKIT (Nyberg, 1988).
Our com-ments will touch upon features from both the content and the form facets of tile knowledgesources.2 OntologyIn formal semantics, one of the most widely accepted methodologies is that of model-theoretic semantics in which syntactically correct utterances in a language are given se-mantic interpretation in terms of truth values with respect to a certain model (in Montaguesemantics, a "possible world") of reality.
Such models are in practice never constructedin detail but rather delineated through a typically underspecifying set of constraints.
Inorder to build large and useful natural language processing systems one has to go furtherand actually commit oneself to a detailed version of a "constructed reality" (Jackendoff'sterm).
Interpreting the meanings of textual units is really feasible only in the presence ofa detailed world model; elements of this model may be linked to the various textual units(either directly or indirectly, individually or in combinations) via is-a meaning-of links.World model elements will be densely interconnected through a large set of well-definedontological links - properties- which will enable the world modeler to build descriptionsof complex objects and processes in a compositional fashion, using as few basic primitiveconcepts as possible.Knowledge bases in FRAMEKIT take the form of a collection of frames.
A frame is239NL InputI AnalyzerMeaningrepmsentmion I ~.~.~ )JRessonlng SystemMeaning mpr~ent~ionOntology +domainmodelsGmmmmrsGeneratorTranslationsAbstractsDialog turnsUpdates of DB or KSMTDsFigure 1: A Knowledge-Based NLP System.240a named set of slots.
A slot is a named set of facets.
A facet is a named set of viewsand a view is a named set of fillers.
A filler can be any symbol or a Lisp functioncall.
The above is the basic set of constraints and features of FRAMEKIT.
ThoughFRAMgKITactually specifies ome e~tensions to this basic expressive power, it remains,by design, quite general and semantically underspecified.
The actual interpretation andtyping of its basic entities is supposed to take place in a particular application, in our case,world modeling.
The ONTOS constraint language is built on top of FRAMEKIT.
Thisstrategy is deliberate and is different from many knowledge representation languages andenvironments, in which the basic representation language is made much more expressiveat the expense of its relative unwieldiness, difficulty in learning and some format-relatedconstraints on application development.In the ontology module of DIONYSUS FRAMEKIT  frames are used to represent concepts.A concept is the basic building block of our ontology.
Examples of concepts are house,four-wheebdrive-car, volunta~-olfacto~-event or specific.gravity.
FRAMEKIT slots areinterpreted as a subset of concepts called properties.
In practice some properties recordedin concepts do not relate to the domain model but rather serve as administrative andexplanatory material for the human users (see examples below).
The FRAMEKIT viewsare used to mask parts of the information from a certain users.
This mechanism is usefulwhen working with very large domain models serving more than one domain so that someinformation will be different depending on whether a data element belongs to the domainof, say, chemistry or the domain of software ngineering.
FRAMEKIT fillers are constrainedto be names of atomic elements of the ontology, expressions referring to modified elementsof the ontology, collections of the above, or special-purpose ymbols and strings used bythe knowledge acquirers.The example concepts from the ontology serve to illustrate some aspects of the con-straint language used.
(MAKE-FLJ.MEMACIKTOSH( IS-A(VALUE(COMMOB PERSORAL-COMPUTER))(PRODUCED-BY(SEN(COMMOB APPLE) ))(SUBCLASSES(SEM(COMMOK PLUS SE I I  I IFX)))(HAS-AS-PART(SEH(COMMOK DISK-DRIVE SYSTEM-U|IT MORITOR CPU MEMORYEXTERKAL-D I SKETTE-DRI VE IRTERMAL-DI SKETTE-DRIVE) ) ) )Other slot values inherit from PERSONAL-COMPUTER (e.g., MAXIMUM-NUMBER-OF-USERS), or from COMPUTER, INDEPENDENT-DEVICE, DEVICE, ARTIFACT,etc.
In the above example, MACINTOSH is a frame name, IS-A is a slot name, VALUEand SEM are examples of facet names, COMMON is the view name, and APPLE andMEMORY are fillers, for example.
(MAKE-FRAMEVOLUMTARY-OLFACTORY-EVEKT(IS-A(VALUE241(COMN0| VOLUITARY-PERCEPTUAL-EVEIT)))(AGE|T(SEA(COMM01 MAMXAL BIRD REPTILE A~PHIBIA|)))(I|STRUME|T(SEN(COMMO| OLFACTORY-0RGA|))))Additional slots such as EXPERIENCER and BENEF IC IARY would be inheritedfrom among the ancestors of this concept, e.g., VOLUNTARY-PERCEPTUAL-EVENTor EVENT.3 Representation of Text MeaningResults of source text analysis in DIONYSUS are represented in a formal, frame-basedlanguage, TAMERLAN (Nirenburg and Defrise, forthcoming).
The types of knowledgewhich are represented in TAMERLAN include the meanings of natural language units andknowledge about the speech situation, including speaker attitudes.
Meaning proper isrepresented through instantiating, combining, and constraining concepts available in theontology.
These processes crucially rely on lexical-semantic information in the appropriatelexicon entries.
This information relates not only to ambiguity resolution in "regular"compositional semantics (i.e., straightforward monotonic dependency structure building),but also the identification of idioms, treatment of metonymy and metaphor, and resolutionof reference ambiguities.It is well known, however, that the intent of a text is typically not capturahle byjust instantiating ontological concepts; what is additionally needed is the representationof pragmatic and discourse-related aspects of language -- speech acts, deictic references,speaker attitudes and intentions, relations among text units, the prior context, the physi-cal context, etc.
As most of the knowledge underlying realizations of these phenomena isnot society-general but is rather dependent on a particular cognitive agent (a particularspeaker/hearer in a particular speech situation), the pragmatic and discourse knowledgeunits were not included in the ontology (which is supposed to reflect, with some vari-ability, a societal view of the world - -  indeed, if every speaker/hearer had a totally id-iosyncratic world view, communication would not be possible).
The representation f this"meta-ontological" information is thus added to the representation of meaning properto yield a representation of text meaning; a resulting representation thus reflects bothlexically-triggered ontologically-based semantic information and non-ontological informa-tion reflecting pragmatic and discourse factors.The propositional part of text meaning is obtained by instantiating relevant ontologicalconcepts, accessed through corresponding lexicon entries, which list mappings betweenword senses and ontological concepts.
In order to carry out the mappings of complexstructures with dependencies, information about argument structure of lexical units (alsostored in the lexicon) is used.However, many lexical units in the source text contribute to the nonpropositionalmeaning of the text.
The structures for the nonpropositional components of text meaningare also derived from the lexicon, where appropriate patterns are stored (see examplelexicon entries below).
The nonpropositional information is not stored in the ontology forreasons explained above.
In what follows we motivate the most important non-ontologicalcomponents of our text meaning representation formalism (for more detailed discussion242see Nirenburg and Defrise, forthcoming, a) - -  speaker attitudes, stylistic features andrhetorical relations.A critical facet of capturing the intent of a speaker in a meaning representation isrendering of the attitudes that the speaker holds toward objects or situations representedin the propositional (compositional-semantic) component of text meaning representation.Indeed, the speaker may convey attitudes about producing the text in the first place(the speech act), elements of the speech context, or even other attitudes.
An attitude isrepresented by a structure which includes the type of attitude (from the list below), avalue (a decimal value taken from the interval \[0, 1\] indicating the polarity or strengthof the attitude), an indication of to whom the attitude can be attributed (typically thespeaker), a scope (identifying the entity towards which the attitude is expressed), and atime (representing the absolute time at which the attitude was held).
Types of attitudesrecognized in TAMERLAN are: epistemic, evaluative, deontic, expectation, volition andsaliency.The stylistic overtones of a lexical entry, even if not contributing directly to the compo-sitional semantics of a text, serve a crucial role in conveying the speaker attitudes and inachieving his intent in producing the text.
Thus we identify that the stylistics of a lexemeneeds to be encoded in the lexicon entry in addition to the lexical semantic information.In encoding lexicons for languages with rich social deictics, such as Japanese, the issue ofstylistics becomes even more acute.We are utilizing a set of style indicators which is a modification of the set of pragmaticgoals from Hovy 1988.
This set consists of six stylistic indicators: formality, simplicity,color, force, directness, and respect.
In our implementation, we need to label lexical entries(including idioms, collocations, conventional utterances, etc.)
with appropriate represen-tations of values for these stylistic indicators; values for these factors are represented aspoints on the interval \[0,1\], where 0.O is low, 1.0 is high, and 0.5 represents a default,neutral value.
In NL generation, these factors are used in lexical selection; in NL analysis,the values are available for assisting in disambiguation (relying on expected values forthe factors and utilizing the heuristic that typically the stylistics will be consistent acrosswords in an utterance).Some examples of English lexical entries that would need to include style features are:upside:de l i c ious :drop by:great:one:fo rmal i ty  - l owco lo r  - h ighfo rmal i ty  - somewhat  h ighco lo r  - h ighfo rmal i ty  - l owfo rmal i ty  - l owpersona l - re fe rence  - l ow (pronomina l  sense)fo rmal i ty  - h ighfo rce  - l owRelations in TAMERLAN are a mixed bag - some of them refer to real-world connectionsand are, therefore, defined in the ontology while some others (such as rhetorical relations,e.g., conjunction and contrast) refer to properties of text itself and are, therefore, not apart of the world model.
At present, the major classes of relations in TAMERLAN includecausal, conjunction, alternation, coreference, temporal, spatial, textual, reformulation a ddomain-text relations.2434 The  LexiconAn entry in the DIONYSUS lexicon is comprised of a number of zones (each possibly hav-ing multiple fields), integrating various levels of lexical information.
The zones are CAT(syntactic ategory), ORTH (orthography - abbreviations and variants), PHON (phonol-ogy), MORPH (morphological irregular forms or class information), SYN (syntactic fea-tures such as attributive), SYN-STRUC (indication of sentence- or phrase-level syntacticinter-dependencies such as subcategorization), SEM (lexical semantics / meaning repre-sentation), LEXICAL-RELATIONS (collocations, etc.
), PRAGM (pragmatics hooks fordeictics, for example, and stylistic factors), and STUFF (user information such as modi-fication audit trail, example sentences, etc.
)In this paper we concentrate on the SEM zone of the lexicon, since it is the locus oflexical-semantic analysis.
This zone contains two fields - -  MEAN-PROC and LEX-MAP.The MEAN-PROC field invokes procedural semantic functions.
One such function is"intensify-range" used to realize the meaning of intensifiers uch as very.
This functionoperates on scalar attribute ranges as input, returning compressions of the input ranges.For example, the English word old may involve a range (> 0.8) of the AGE attribute.
Theintensify-range function would be invoked in the phrase very old, for example, returning(> 0.9).
Similarly, for very young this function would return (< 0.1), when given (< 0.2).For very average (perhaps (0.44< x < 0.6)), this function would return (0.45 < x< 0.55).The LEX-MAP field contains mappings indicating the links between lexical units andontological concepts.
The simplest version of such a mapping is the straightforward linkbetween a concept in the ontology and the meaning of the lexical unit in question.
Inanalysis the link identifies which ontological concept o instantiate as the representation fa lexical unit.
So, for example, the lexical semantics for the primary sense of the Englishword clog would be a pointer or link to the concept of "dog" in the ontology: (marked,by convention, *dog).
In DIONYSUS, the semantic analyzer instantiates an instance of thedog concept (e.g., ~dog3~) when processing a sentence containing the word "dog" or areference to it.
This mechanism works only in the case of one-to-one mapping betweenwords and ontological concepts, so that the ontology becomes essentially a collection ofword senses.There is no consensus in the field with respect o size and composition of the onto-logical world model.
The "word-sense" view of the ontology, in addition to the obviousdisadvantage of ontology size, leads to a problems in multilingual applications - -  oftenroughly comparable words in different languages do not "line up" the same way, whichleads to proliferation of new concepts with every new language.
This makes the trans-lation process difficult.
Another well-known approach prefers a small restricted set ofprimitives which are combined or constrained in an attempt o render the meaning of anylexical unit.
This decision has been amply criticized as it leads to difficulty in buildinglarge-scale world models and capturing shades of meaning; additionally, this approach canyield enormous, unmaintainable l xicon entries for complex concepts.
Further discussionof this issue (and pointers to the literature on this subject) can be found in Meyer et al,1990.The approach taken in DIONYSUS lies somewhere in between the two extremist positionsoutlined above.
Therefore, in some cases, it is possible to find one-to-one correspondencesbetween lexeme and concept.
Unfortunately, in the majority of cases, this is not possiblewithout excessive proliferation of concepts.
Therefore, mappings are allowed to conceptswith "similar" but not identical meanings - to the most specific concept hat is still more244general than (i.e., that subsumes) the meaning of the lexeme in question.
Once the mostdirectly corresponding concept is determined, additional information is specified (thusconstraining the general concept) in the LEX-MAP field in the lexicon.
This modifiedmapping may either add information to the concept as it is specified in the ontology,override certain constraints (e.g., a selectional restriction), or indicate relationships withother concepts expected in the sentence.Before proceeding to illustrate the constrained mappings, we first introduce the knowl-edge representation tools used to express them.
In the DIONYSUS formalism, ontologicalconcepts are interpreted as frames, and their properties, as slots (see the discussion ofFRAMEKITabove).
It is natural, then, to use the facet mechanism to encode constraintsintroduced in the LEX-MAP mappings.
The constraining or "specialization" facets usedin the DIONYSUS lexicon representations are as follows:.
VALUE - a specific value (e.g., number of sides for a triangle = 3, sex of a man =male).
This is the facet where actual information is represented.
When this meaningpattern is instantiated by use in a sentence, semantic dependency structure links willbe indicated typically in a VALUE facet.2.
DEFAULT - usual (i.e., typical, expected) value (e.g., color of diapers = white).3.
SEM - akin to a traditional selectional restriction (e.g., color of diapers has to be aCOLOR), this is essentially a constraint on what VALUE may be.4.
RELAXABLE-TO - maximum relaxability, if any, of SEM restrictions.. SALIENCE - a scalar value in the range \[0.0, 1.0\] designating the significance of aspecific attribute slot or role (partly reflecting the notion of "defining properties"vs. "incidental properties").The structure below, for the lexeme "eat-v1" (the primary transitive verb sense) illus-trates a simple case of lexical semantic mapping.
The SYN-STRUC zone of the lexicalentry establishes the subcategorization f the verb, and the structure is used in parsingor generation.
In the course of parsing, the variables Svar l  and Svar2 are bound toa "placeholder" for the lexical semantics of the subject and object of the verb, respec-tively.
Once the lexical semantics of the syntactic onstituents in those syntactic roles isdetermined, it becomes available for the compositional purposes - -  to build a semanticrepresentation for a higher-level text component (e.g., a sentence).
(~ ingeet(AGE|T (va lue  "Snar l )  ; sub jec t  o f  lexeme v i i i  get  bound to(eem *an imal ) )  ; Snar l ,  uh ich  ?or responde to; AGE|T s lo t  o f  the  onto log ica l  concept; INGEST(THEME (va lue  "$var2)  ; ob jec t  o f  lexeme u i l l  get  bound to  $var2 ,(sem * ingest ib le )  ; uh ich  must cor respond to  the  THEME s lo t; o f  I |6EST( re laxab le - to  *phys ica l -ob jec t ) ) ) )  ; ind icat ion  o f;ex tent  of  a l louab le  semant ic  const ra in t; re laxat ionAs an illustration of the process of semantic dependency structure building, considerthe analysis of the sentence The man visited the store.
This analysis will involve the estab-lishing (among others) of TAMEFtLAN entities ~visit132 and ~human135 (the numbers are245added for unique reference, the percent sign marks an instance of an ontological concept),which are instances of the ontological concepts *visit and *haman.
This is made possi.ble through the content of the LEX-MAP fields of lexicon entries "for (the correspondingsenses of) the English words "visit" and "man."
The semantics of the entire sentence willinclude the instantiated concepts, connected by using Shaman135 to fill the AGENT slotin ~visit18~.
The knowledge necessary for establishing this dependency is found in thesyntactic omponent of the lexical entry for "visit" (where the tvar  variables would beshown as corresponding tosubject and object positions); this information is then linked tothe semantic sphere using the following notation in the LEX-MAP field of the appropriatesense of "visit:"(~vis i t  (AOEI!
(VALUE "$var l ) ) .
.
.
)The caret is an operator (akin to an intension operator) which retrieves the meaningof the syntactic onstituent bound to the variable.
The resulting TAMEItLAN structure inwill, thus, include the following:(~visit132 (AQE|T (VALUE ~human135)) .
.
.
)At this point we are ready to illustrate constrained mapping between word senses andontological concepts.
An example of constraining the sense of an ontological concept isthe lexeme taxi-d, identifying the sense of taxi as an instance of the ontological concept*move-on-surface, but with important further constraints - -  the theme can be only anaircraft, (e.g., The plane taxied to the terminal).
The LEX-MAP field for taxi-v1 is, then,as follows:(~move-on-surfac*(SURFACE (SEN *uater *ground))(THEKE (SEN *a i rcraf t )(RELAXABLE-TO *vehic le)))))In this example the thing that is moving-on-the-surface is being constrained to be anaircraft, possibly relaxable to include any vehicle (perhaps in more florid speech).
Notethat there may be second-order constraints (i.e., constraints on constraints) in additionto the above: jet-vl (the literal sense of 'to travel by jet', e.g., The presidential candidatespent most of the year jetting across the country from one campaign rally to another.
)(~mov@(IISTRUME|T (SEM *a i rcraf t(PROPELLED-BY(value ~jet-ens ine)) ) ) ) ) )This constrains the vehicle used in jetting to be a jet-propelled vehicle.There does not need to be a regular correspondence b tween the syntactic ategory(part of speech) of the lexeme and the general high-level partition into which the corre-sponding ontological concept falls.
The highest node in the ontology, ALL, is partitionedinto the subclasses EVENT, OBJECT and PROPERTY (the latter being partitioned intoATTRIBUTE and RELATION), which one might expect to correspond to verbs, nouns,and adjectives or prepositions, respectively.
However, there is a great deal of variability inthe correspondence b tween ontological partition and linguistic part of speech.
See Meyeret al, 1990 for further discussion of this issue.246In some cases, the constraint of an ontological concept may be achieved through theuse of scalar attributes: SHOP ==> STORE of a certain size; CHILD ==> HUMANof a certain age; FRESH-BREWED ==> modifies COFFEE or TEA of a certain age.The RANGE facet is used to access particular information about scalar attributes inthe ontology, such as AGE, TEMPERATURE, LUMINANCE, and SIZE.
Any attributewhich can be measured on a scale can also be described in relative terms.
For example,we can say That house is 4000 square feet or That house is very large; That water is 200degrees (F) or That water is very hot.
By means of the RANGE facet, we can establish acorrespondence b tween measured and relative values for various ontological concepts.5 Integration of Multiple Knowledge Sources in Lex-icon EntriesAs is evident from the brief discussion above, the lexicon can be seen as the nexus throughwhich a number of knowledge sources are integrated in order to produce an appropriaterepresentation f the "meaning" of the input.
The clearest case of this is the triggeringof instantiation of ontological concepts by a "meaning template" in the LEX-MAP fieldof the lexicon entry.
Furthermore, the additional information (augmenting and constrain-ing information) presented in the LEX-MAP field provides a mechanism of tailoring thecross-linguistic ontological (world model) information to language-specific, lexeme-specific,representation f a conceptual notion.In some lexicon entries LEX-MAP contains a mapping not into an ontological conceptbut rather into the representation f a pragmatic or discourse ntity, such as a relationor an attitude.
In other cases, lexical units have mixed ontological and non-ontologicalmeaning components.
In both cases, this is a mechanism for providing for the integrationof non-ontologicM (hence "non-semantic") information with ontological, as triggered bylexical entries.
The following examples will illustrate such phenomena.The following is an example of how an evaluative attitude can be used for describingthe meaning of a lexeme:excs l lent -ad j l(ATTITUDE(type (va lue  eva luat ive) )(a t t i tude-va lue  (va lue  1))(scope "$var l ) )  ; $var l  corresponds to the object  for  which the; a t t i tude  i s  held,  as ident i f ied  syntact i ca l ly(a t t r ibuted- to  (va lue  \ [$SS\ ] .de ic t i c - ind ices .speaker ) ); the holder of the a t t i tude  is  the speaker ( i .e .
,  the; p roducer  of the text )The entry for smell-v5 (defined as perceive something negative intuitively, as in I couldsmell trouble brewing or Everyone could smell the hostility in the air) demonstrates theintegration of ontological and non-ontological structures:(~perceptual-event(EXPERIE|CER (va lue  "$var l )  ; l i nk  to  the  syntact i c  subject(sem *human))(THEME (va lue  "$var2)  ; l i nk  to the syntact i c  ob jec t(sem *menta l -ob ject ) ) )(ATTITUDE(type (va lue  eva luat ive) )247(va lue  (va lue  (< 0 .2 ) ) )  ; l ess  than .5 ,  so negat ive  fee l ings( scope  (Zporceptua l -event .
theme) )  ; l i nk  to  the  contents  of; the  ind icated  s lo t  in  the  onto log ica l; concept  ~perceptua l -event  re fe renced  above.
(a t t r ibuted- to(va lue  \ [$SS\ ] .de ic t i c - ind ices .speaker ) ) ) ) )  ; u po in ter; to  the  de ic t i c  indQx in  the  context  frluaeHere there is a restriction on the EXPERIENCER, who must be a human, and on theTHEME, which must be a MENTAL-OBJECT.
A further item of information, however,is that there is a negative attitude towards the theme (e.g., one does not normally saythings like I could smell happiness in the air, Everyone could smell the positive attitude shehad, etc.)
The attribution of the attitude is a hook into the deictic indices of the speechsituation of the utterance - the formula in the attribution identifies that the speaker ofthe current speech situation be identified, and that the speaker be linked in as the holderof attitude.The semantic mapping mechanism as a representation language in the LEX-MAP fieldof the lexicon (outlined above) allows for a fluent integration of encyclopedic knowledgeinto the framework without "corrupting" the linguistic lexicon with this type of infor-mation.
The approach in question is the formation of an "episodic memory" knowledgesource, consisting of a set of data structures identical to lexicon entries.
However, theperson Ronald Reagan would be represented in the episodic memory as a named instanceof the concept *human, or some more specific concept, along with other informationknown about him rendered in various slots of the concept instantiation, ot by a triggerto produce a new instantion of the concept as would be the case by a linguistic lexiconentry.6 Status and Future WorkAll three static knowledge sources described briefly above are still under development.In fact, only when the ontology and the lexicon reach nontrivial size, can one put acomputationally relevant lexical-semantic heory to a real test in a large-scale application.A complete theory of lexical semantics must, of course, include the description of theactual processes which lead from a natural anguage text to its meaning representation(NL analysis) and in the opposite direction (NL generation).
We continue to develop theseprocesses, in the tradition of knowledge-based NLP.AcknowledgementsWe gratefully acknowledge the contributions ofChristine Defrise, Ingrid Meyer, and LynnCarlson.ReferencesCarlson, Lynn and Sergei Nirenburg.
1990.
World Modeling for NLP.
Technical ReportCMU-CMT-90-121.
Center for Machine Translation.
Carnegie Mellon University.Goodman, Kenneth and Sergei Nirenburg (eds.)
1989.
KBMT-89.
CMU-CMT ProjectReport.248Hirst, Graeme.
1988.
Semantic Interpretation and the Resolution of Ambiguity.
Cam-bridge: Cambridge University Press.Hirst, Graeme.
1989.
Ontological Assumptions in Knowledge Representation.
In Pro-ceedings of the First International Conference on Principles of Knowledge Representationand Reasoning (Toronto, May 1989).Hovy, Edward.
1988.
Generating Natural Language Under Pragmatic Constraints.
Ph.D.Yale University.Meyer, Ingrid and James Steele.
1990.
The Presentation ofan Entry and of a Super-entryin an Explanatory Combinatorial Dictionary.
In James Steele (ed.
), The Meaning-TextTheory of Language: Linguistics, Lexicography, and Practical Implications.
Ottawa,Canada: University of Ottawa Press.Meyer, Ingrid, Boyan Onyshkevych, and Lynn Carlson.
1990.
Lexieographic Principlesand Design for Knowledge-Based Machine Translation.
Technical Report CMU-CMT-90-118.
Center for Machine Translation.
Carnegie Mellon University.Monarch, I. and S. Nirenburg.
1988.
ONTOS: An Ontology-Based Knowledge Acquisitionand Maintenance System.
Proceedings of the Second Workshop on Knowledge Acquisi-tion.
Banff, Canada.Nirenburg, Sergei, and Christine Defrise (forthcoming, a).
Practical Computational Lin-guistics.
In R. Johnson and M. Rosner (eds.
), Computational Linguistics and FormalSemantics.
Cambridge: Cambridge University Press.Nirenburg, Sergei, and Christine Defrise (forthcoming, b).
Lexical and Conceptual Struc-ture for Knowledge-Based Machine Translation.
In: J. Pustejovsky (ed.
), Semantics andthe Lexicon.
Dordrecht, Holland: Kluwer.Nirenburg, Sergei and Kenneth Goodman.
1990.
Treatment of Meaning in MT Systems.Proceedings of the Third International Conference on Theoretical and Methodological Is-sues in Machine Translation of Natural Language.
Linguistic Research Center, Universityof Texas at Austin.
June 1990.Nyberg, Eric.
1988.
The FrameKit User's Guide, Version 2.0.
CMU-CMT-MEMO.
Centerfor Machine Translation.
Carnegie Mellon University.249
