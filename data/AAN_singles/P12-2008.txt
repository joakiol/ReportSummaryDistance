Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 38?42,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsJoint Learning of a Dual SMT System for Paraphrase GenerationHong Sun?School of Computer Science and TechnologyTianjin Universitykaspersky@tju.edu.cnMing ZhouMicrosoft Research Asiamingzhou@microsoft.comAbstractSMT has been used in paraphrase generationby translating a source sentence into another(pivot) language and then back into the source.The resulting sentences can be used as candi-date paraphrases of the source sentence.
Exist-ing work that uses two independently trainedSMT systems cannot directly optimize theparaphrase results.
Paraphrase criteria espe-cially the paraphrase rate is not able to be en-sured in that way.
In this paper, we proposea joint learning method of two SMT systemsto optimize the process of paraphrase genera-tion.
In addition, a revised BLEU score (callediBLEU ) which measures the adequacy anddiversity of the generated paraphrase sentenceis proposed for tuning parameters in SMT sys-tems.
Our experiments on NIST 2008 test-ing data with automatic evaluation as well ashuman judgments suggest that the proposedmethod is able to enhance the paraphrase qual-ity by adjusting between semantic equivalencyand surface dissimilarity.1 IntroductionParaphrasing (at word, phrase, and sentence levels)is a procedure for generating alternative expressionswith an identical or similar meaning to the origi-nal text.
Paraphrasing technology has been appliedin many NLP applications, such as machine trans-lation (MT), question answering (QA), and naturallanguage generation (NLG).1This work has been done while the author was visiting Mi-crosoft Research Asia.As paraphrasing can be viewed as a transla-tion process between the original expression (as in-put) and the paraphrase results (as output), bothin the same language, statistical machine transla-tion (SMT) has been used for this task.
Quirk et al(2004) build a monolingual translation system us-ing a corpus of sentence pairs extracted from newsarticles describing same events.
Zhao et al (2008a)enrich this approach by adding multiple resources(e.g., thesaurus) and further extend the method bygenerating different paraphrase in different applica-tions (Zhao et al, 2009).
Performance of the mono-lingual MT-based method in paraphrase generationis limited by the large-scale paraphrase corpus it re-lies on as the corpus is not readily available (Zhao etal., 2010).In contrast, bilingual parallel data is in abundanceand has been used in extracting paraphrase (Ban-nard and Callison-Burch, 2005; Zhao et al, 2008b;Callison-Burch, 2008; Kok and Brockett, 2010;Kuhn et al, 2010; Ganitkevitch et al, 2011).
Thusresearchers leverage bilingual parallel data for thistask and apply two SMT systems (dual SMT system)to translate the original sentences into another pivotlanguage and then translate them back into the orig-inal language.
For question expansion, Duboue?
andChu-Carroll (2006) paraphrase the questions withmultiple MT engines and select the best paraphraseresult considering cosine distance, length, etc.
Max(2009) generates paraphrase for a given segment byforcing the segment being translated independentlyin both of the translation processes.
Context featuresare added into the SMT system to improve trans-lation correctness against polysemous.
To reduce38the noise introduced by machine translation, Zhao etal.
(2010) propose combining the results of multiplemachine translation engines?
by performing MBR(Minimum Bayes Risk) (Kumar and Byrne, 2004)decoding on the N-best translation candidates.The work presented in this paper belongs tothe pivot language method for paraphrase genera-tion.
Previous work employs two separately trainedSMT systems the parameters of which are tunedfor SMT scheme and therefore cannot directly op-timize the paraphrase purposes, for example, opti-mize the diversity against the input.
Another prob-lem comes from the contradiction between two cri-teria in paraphrase generation: adequacy measuringthe semantic equivalency and paraphrase rate mea-suring the surface dissimilarity.
As they are incom-patible (Zhao and Wang, 2010), the question ariseshow to adapt between them to fit different applica-tion scenarios.
To address these issues, in this paper,we propose a joint learning method of two SMT sys-tems for paraphrase generation.
The jointly-learneddual SMT system: (1) Adapts the SMT systems sothat they are tuned specifically for paraphrase gener-ation purposes, e.g., to increase the dissimilarity; (2)Employs a revised BLEU score (named iBLEU , asit?s an input-aware BLEU metric) that measures ad-equacy and dissimilarity of the paraphrase results atthe same time.
We test our method on NIST 2008testing data.
With both automatic and human eval-uations, the results show that the proposed methodeffectively balance between adequacy and dissimi-larity.2 Paraphrasing with a Dual SMT SystemWe focus on sentence level paraphrasing and lever-age homogeneous machine translation systems forthis task bi-directionally.
Generating sentential para-phrase with the SMT system is done by first trans-lating a source sentence into another pivot language,and then back into the source.
Here, we call thesetwo procedures a dual SMT system.
Given an En-glish sentence es, there could be n candidate trans-lations in another language F , each translation couldhavem candidates {e?
}which may contain potentialparaphrases for es.
Our task is to locate the candi-date that best fit in the demands of paraphrasing.2.1 Joint Inference of Dual SMT SystemDuring the translation process, it is needed to selecta translation from the hypothesis based on the qual-ity of the candidates.
Each candidate?s quality canbe expressed by log-linear model considering dif-ferent SMT features such as translation model andlanguage model.When generating the paraphrase results for eachsource sentence es, the selection of the best para-phrase candidate e??
from e?
?
C is performed by:e??
(es, {f}, ?M ) =argmaxe??C,f?
{f}M?m=1?mhm(e?|f)t(e?, f)(1)where {f} is the set of sentences in pivot languagetranslated from es, hm is the mth feature value and?m is the corresponding weight.
t is an indicatorfunction equals to 1 when e?
is translated from f and0 otherwise.The parameter weight vector ?
is trained byMERT (Minimum Error Rate Training) (Och, 2003).MERT integrates the automatic evaluation metricsinto the training process to achieve optimal end-to-end performance.
In the joint inference method, thefeature vector of each e?
comes from two parts: vec-tor of translating es to {f} and vector of translating{f} to e?, the two vectors are jointly learned at thesame time:(?
?1, ?
?2) = arg max(?1,?2)S?s=1G(rs, e??
(es, {f}, ?1, ?2))(2)where G is the automatic evaluation metric for para-phrasing.
S is the development set for training theparameters and for each source sentence several hu-man translations rs are listed as references.2.2 Paraphrase Evaluation MetricsThe joint inference method with MERT enables thedual SMT system to be optimized towards the qual-ity of paraphrasing results.
Different applicationscenarios of paraphrase have different demands onthe paraphrasing results and up to now, the widelymentioned criteria include (Zhao et al, 2009; Zhaoet al, 2010; Liu et al, 2010; Chen and Dolan, 2011;Metzler et al, 2011): Semantic adequacy, fluency39and dissimilarity.
However, as pointed out by (Chenand Dolan, 2011), there is the lack of automatic met-ric that is capable to measure all the three criteria inparaphrase generation.
Two issues are also raisedin (Zhao and Wang, 2010) about using automaticmetrics: paraphrase changes less gets larger BLEUscore and the evaluations of paraphrase quality andrate tend to be incompatible.To address the above problems, we propose a met-ric for tuning parameters and evaluating the qualityof each candidate paraphrase c :iBLEU(s, rs, c) = ?BLEU(c, rs)?
(1?
?
)BLEU(c, s) (3)where s is the input sentence, rs represents the ref-erence paraphrases.
BLEU(c, rs) captures the se-mantic equivalency between the candidates and thereferences (Finch et al (2005) have shown the ca-pability for measuring semantic equivalency usingBLEU score); BLEU(c, s) is the BLEU score com-puted between the candidate and the source sen-tence to measure the dissimilarity.
?
is a parametertaking balance between adequacy and dissimilarity,smaller ?
value indicates larger punishment on self-paraphrase.
Fluency is not explicitly presented be-cause there is high correlation between fluency andadequacy (Zhao et al, 2010) and SMT has alreadytaken this into consideration.
By using iBLEU , weaim at adapting paraphrasing performance to differ-ent application needs by adjusting ?
value.3 Experiments and Results3.1 Experiment SetupFor English sentence paraphrasing task, we utilizeChinese as the pivot language, our experiments arebuilt on English and Chinese bi-directional transla-tion.
We use 2003 NIST Open Machine Transla-tion Evaluation data (NIST 2003) as developmentdata (containing 919 sentences) for MERT and testthe performance on NIST 2008 data set (containing1357 sentences).
NIST Chinese-to-English evalua-tion data offers four English human translations forevery Chinese sentence.
For each sentence pair, wechoose one English sentence e1 as source and usethe three left sentences e2, e3 and e4 as references.The English-Chinese and Chinese-English sys-tems are built on bilingual parallel corpus contain-Joint learning BLEUSelf-BLEUiBLEUNo Joint 27.16 35.42 /?
= 1 30.75 53.51 30.75?
= 0.9 28.28 48.08 20.64?
= 0.8 27.39 35.64 14.78?
= 0.7 23.27 26.30 8.39Table 1: iBLEU Score Results(NIST 2008)Adequacy(0/1/2)Fluency(0/1/2)Variety(0/1/2)Overall(0/1/2)No Joint 30/82/88 22/83/95 25/117/58 23/127/50?
= 1 33/53/114 15/80/105 62/127/11 16/128/56?
= 0.9 31/77/92 16/93/91 23/157/20 20/119/61?
= 0.8 31/78/91 19/91/90 20/123/57 19/121/60?
= 0.7 35/105/60 32/101/67 9/108/83 35/107/58Table 2: Human Evaluation Label Distributioning 497,862 sentences.
Language model is trainedon 2,007,955 sentences for Chinese and 8,681,899sentences for English.
We adopt a phrase based MTsystem of Chiang (2007).
10-best lists are used inboth of the translation processes.3.2 Paraphrase Evaluation ResultsThe results of paraphrasing are illustrated in Table 1.We show the BLEU score (computed against ref-erences) to measure the adequacy and self-BLEU(computed against source sentence) to evaluate thedissimilarity (lower is better).
By ?No Joint?, itmeans two independently trained SMT systems areemployed in translating sentences from English toChinese and then back into English.
This result islisted to indicate the performance when we do notinvolve joint learning to control the quality of para-phrase results.
For joint learning, results of ?
from0.7 to 1 are listed.From the results we can see that, when the valueof ?
decreases to address more penalty on self-paraphrase, the self-BLEU score rapidly decayswhile the consequence effect is that BLEU scorecomputed against references also drops seriously.When ?
drops under 0.6 we observe the sentencesbecome completely incomprehensible (this is thereason why we leave out showing the results of ?
un-der 0.7).
The best balance is achieved when ?
is be-tween 0.7 and 0.9, where both of the sentence qual-ity and variety are relatively preserved.
As ?
value ismanually defined and not specially tuned, the exper-40SourceTorrential rains hit western india ,43 people deadNo JointRainstorms in western india ,43 deathsJoint(?
= 1)Rainstorms hit western india ,43 people deadJoint(?
= 0.9)Rainstorms hit western india43 people deadJoint(?
= 0.8)Heavy rain in western india ,43 deadJoint(?
= 0.7)Heavy rain in western india ,43 killedTable 3: Example of the Paraphrase Resultsiments only achieve comparable results with no jointlearning when ?
equals 0.8.
However, the resultsshow that our method is able to effectively controlthe self-paraphrase rate and lower down the score ofself-BLEU, this is done by both of the process ofjoint learning and introducing the metric of iBLEUto avoid trivial self-paraphrase.
It is not capable withno joint learning or with the traditional BLEU scoredoes not take self-paraphrase into consideration.Human evaluation results are shown in Table 2.We randomly choose 100 sentences from testingdata.
For each setting, two annotators are asked togive scores about semantic adequacy, fluency, vari-ety and overall quality.
The scales are 0 (meaningchanged; incomprehensible; almost same; cannot beused), 1 (almost same meaning; little flaws; con-taining different words; may be useful) and 2 (samemeaning; good sentence; different sentential form;could be used).
The agreements between the anno-tators on these scores are 0.87, 0.74, 0.79 and 0.69respectively.
From the results we can see that humanevaluations are quite consistent with the automaticevaluation, where higher BLEU scores correspondto larger number of good adequacy and fluency la-bels, and higher self-BLEU results tend to get lowerhuman evaluations over dissimilarity.In our observation, we found that adequacy andfluency are relatively easy to be kept especially forshort sentences.
In contrast, dissimilarity is not easyto achieve.
This is because the translation tablesare used bi-directionally so lots of source sentences?fragments present in the paraphrasing results.We show an example of the paraphrase resultsunder different settings.
All the results?
sententialforms are not changed comparing with the input sen-tence and also well-formed.
This is due to the shortlength of the source sentence.
Also, with smallervalue of ?, more variations show up in the para-phrase results.4 Discussion4.1 SMT Systems and Pivot LanguagesWe have test our method by using homogeneousSMT systems and a single pivot language.
As themethod highly depends on machine translation, anatural question arises to what is the impact whenusing different pivots or SMT systems.
The jointlearning method works by combining both of theprocesses to concentrate on the final objective so itis not affected by the selection of language or SMTmodel.In addition, our method is not limited to a ho-mogeneous SMT model or a single pivot language.As long as the models?
translation candidates canbe scored with a log-linear model, the joint learningprocess can tune the parameters at the same time.When dealing with multiple pivot languages or het-erogeneous SMT systems, our method will take ef-fect by optimizing parameters from both the forwardand backward translation processes, together withthe final combination feature vector, to get optimalparaphrase results.4.2 Effect of iBLEUiBLEU plays a key role in our method.
The firstpart of iBLEU , which is the traditional BLEUscore, helps to ensure the quality of the machinetranslation results.
Further, it also helps to keepthe semantic equivalency.
These two roles unify thegoals of optimizing translation and paraphrase ade-quacy in the training process.Another contribution from iBLEU is its abilityto balance between adequacy and dissimilarity as thetwo aspects in paraphrasing are incompatible (Zhaoand Wang, 2010).
This is not difficult to explain be-cause when we change many words, the meaningand the sentence quality are hard to preserve.
Asthe paraphrasing task is not self-contained and willbe employed by different applications, the two mea-sures should be given different priorities based onthe application scenario.
For example, for a query41expansion task in QA that requires higher recall, va-riety should be considered first.
Lower ?
value ispreferred but should be kept in a certain range as sig-nificant change may lead to the loss of constraintspresented in the original sentence.
The advantageof the proposed method is reflected in its ability toadapt to different application requirements by ad-justing the value of ?
in a reasonable range.5 ConclusionWe propose a joint learning method for pivotlanguage-based paraphrase generation.
The jointlylearned dual SMT system which combines the train-ing processes of two SMT systems in paraphrasegeneration, enables optimization of the final para-phrase quality.
Furthermore, a revised BLEU scorethat balances between paraphrase adequacy and dis-similarity is proposed in our training process.
In thefuture, we plan to go a step further to see whetherwe can enhance dissimilarity with penalizing phrasetables used in both of the translation processes.ReferencesColin J. Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In ACL.Chris Callison-Burch.
2008.
Syntactic constraintson paraphrases extracted from parallel corpora.
InEMNLP, pages 196?205.David Chen and William B. Dolan.
2011.
Collectinghighly parallel data for paraphrase evaluation.
In ACL,pages 190?200.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Pablo Ariel Duboue?
and Jennifer Chu-Carroll.
2006.
An-swering the question you wish they had asked: The im-pact of paraphrasing for question answering.
In HLT-NAACL.Andrew Finch, Young-Sook Hwang, and EiichiroSumita.
2005.
Using machine translation evalua-tion techniques to determine sentence-level semanticequivalence.
In In IWP2005.Juri Ganitkevitch, Chris Callison-Burch, CourtneyNapoles, and Benjamin Van Durme.
2011.
Learningsentential paraphrases from bilingual parallel corporafor text-to-text generation.
In EMNLP, pages 1168?1179.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In HLT-NAACL, pages 145?153.Roland Kuhn, Boxing Chen, George F. Foster, and EvanStratford.
2010.
Phrase clustering for smoothingtm probabilities - or, how to extract paraphrases fromphrase tables.
In COLING, pages 608?616.Shankar Kumar and William J. Byrne.
2004.
Minimumbayes-risk decoding for statistical machine translation.In HLT-NAACL, pages 169?176.Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng.
2010.Pem: A paraphrase evaluation metric exploiting paral-lel texts.
In EMNLP, pages 923?932.Aurelien Max.
2009.
Sub-sentential paraphrasing bycontextual pivot translation.
In Proceedings of the2009 Workshop on Applied Textual Inference, ACLI-JCNLP, pages 18?26.Donald Metzler, Eduard H. Hovy, and Chunliang Zhang.2011.
An empirical evaluation of data-driven para-phrase generation techniques.
In ACL (Short Papers),pages 546?551.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In ACL, pages 160?167.Chris Quirk, Chris Brockett, and William B. Dolan.2004.
Monolingual machine translation for paraphrasegeneration.
In EMNLP, pages 142?149.Shiqi Zhao and Haifeng Wang.
2010.
Paraphrases andapplications.
In COLING (Tutorials), pages 1?87.Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and ShengLi.
2008a.
Combining multiple resources to improvesmt-based paraphrasing model.
In ACL, pages 1021?1029.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008b.
Pivot approach for extracting paraphrase pat-terns from bilingual corpora.
In ACL, pages 780?788.Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven statistical paraphrase generation.In ACL/AFNLP, pages 834?842.Shiqi Zhao, Haifeng Wang, Xiang Lan, and Ting Liu.2010.
Leveraging multiple mt engines for paraphrasegeneration.
In COLING, pages 1326?1334.42
