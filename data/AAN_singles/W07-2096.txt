Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 430?433,Prague, June 2007. c?2007 Association for Computational LinguisticsUPV-SI: Word Sense Induction using Self Term Expansion?David Pinto(1,2) and Paolo Rosso11Polytechnic University of ValenciaDSIC, Valencia, Spain, 460222B.
Autonomous University of PueblaFCC, Puebla, Mexico, 72570{dpinto, prosso}@dsic.upv.esHe?ctor Jime?nez-SalazarAutonomous Metropolitan UniversityDepartment of Information TechnologiesCuajimalpa, DF, Mexico, 11850hgimenezs@gmail.comAbstractIn this paper we are reporting the re-sults obtained participating in the ?Eval-uating Word Sense Induction and Dis-crimination Systems?
task of Semeval2007.
Our totally unsupervised systemperformed an automatic self-term expan-sion process by mean of co-ocurrenceterms and, thereafter, it executed theunsupervised KStar clustering method.Two ranking tables with different eval-uation measures were calculated by thetask organizers, every table with twobaselines and six runs submitted by dif-ferent teams.
We were ranked thirdplace in both ranking tables obtaining abetter performance than three differentbaselines, and outperforming the averagescore.1 IntroductionWord Sense Disambiguation (WSD) is a partic-ular problem of computational linguistics whichconsists in determining the correct sense for agiven ambiguous word.
It is well-known that su-pervised algorithms have obtained the best re-sults in public evaluations, but their accuracyis close related with the amount of hand-taggeddata available.
The construction of that kindof training data is difficult for real applications.The unsupervised WSD overcomes this draw-back by using clustering algorithms which do?This work has been partially supported by the MCyTTIN2006-15265-C06-04 project, as well as by the BUAP-701 PROMEP/103.5/05/1536 grantnot need training data in order to determine thepossible sense for a given ambiguous word.This paper describes a simple technique forunsupervised sense induction for ambiguouswords.
The approach is based on a self term ex-pansion technique which constructs a set of co-ocurrence terms and, thereafter, it uses this setto expand the target dataset.
The implementedsystem was performed in the task ?SemEval-2007 Task 2: Evaluating Word Sense Induc-tion and Discrimination Systems?
(Agirre andA., 2007).
The aim of the task was to per-mit a comparison across sense-induction and dis-crimination systems.
Moreover, the comparisonwith other supervised and knowledge-based sys-tems may be also done, since the test corpus wasborrowed from the well known ?English lexical-sample?
task in SemEval-2007, with the usualtraining + test split.The self term expansion method consists inreplacing terms of a document by a set of co-related terms.
The goal is to improve natu-ral language processing tasks such as cluster-ing narrow-domain short texts.
This processmay be done by mean of different ways, of-ten just by using a knowledge database.
Ininformation retrieval, for instance, the expan-sion of query terms is a very investigated topicwhich has shown to improve results with respectto when query expansion is not employed (Qiuand Frei, 1993; Ruge, 1992; R.Baeza-Yates andRibeiro-Neto, 1999; Grefenstette, 1994; Rijsber-gen, 1979).The availability of Machine Readable Re-sources (MRR) like ?Dictionaries?, ?Thesauri?and ?Lexicons?
has allowed to apply term ex-430pansion to other fields of natural language pro-cessing like WSD.
In (Banerjee and Pedersen,2002) we may see the typical example of usinga external knowledge database for determiningthe correct sense of a word given in some con-text.
In this approach, every word close to theone we would like to determine its correct senseis expanded with its different senses by usingthe WordNet lexicon (Fellbaum, 1998).
Then,an overlapping factor is calculated in order todetermine the correct sense of the ambiguousword.
Different other approaches have made useof a similar procedure.
By using dictionaries,the proposals presented in (Lesk, 1986; Wilks etal., 1990; Nancy and Ve?ronis, 1990) are the mostsucessful in WSD.
Yarowsky (Yarowsky, 1992)used instead thesauri for their experiments.
Fi-nally, in (Sussna, 1993; Resnik, 1995; Baner-jee and Pedersen, 2002) the use of lexicons inWSD has been investigated.
Although in somecases the knowledge resource seems not to beused strictly for term expansion, the aplicationof co-occurrence terms is included in their algo-rithms.
Like in information retrieval, the appli-cation of term expansion in WSD by using co-related terms has shown to improve the baselineresults if we carefully select the external resourceto use, with a priori knowledge of the domainand the broadness of the corpus (wide or nar-row domain).
Evenmore, we have to be sure thatthe Lexical Data Base (LDB) has been suitableconstructed.
Due to the last facts, we considerthat the use of a self automatically constructedLDB (using the same test corpora), may be ofhigh benefit.
This assumption is based on theintrinsic properties extracted from the corpus it-self.
Our proposal is related somehow with theinvestigations presented in (Schu?tze, 1998) and(Purandare and Pedersen, 2004), where wordsare also expanded with co-ocurrence terms forword sense discrimination.
The main differenceconsists in the use of the same corpora for con-structing the co-ocurrence list.Following we describe the self term expan-sion method used and, thereafter, the resultsobtained in the task #2 of Semeval 2007 com-petition.2 The Self Term Expansion MethodIn literature, co-ocurrence terms is the mostcommon technique used for automatic construc-tion of LDBs (Grefenstette, 1994; Frakes andBaeza-Yates, 1992).
A simple approach may usen-grams, which allows to predict a word fromprevious words in a sample of text.
The fre-quency of each n-gram is calculated and thenfiltered according to some threshold.
The re-sulting n-grams constitutes a LDB which maybe used as an ?expansion dictionary?
for eachterm.On the other hand, an information theory-based co-ocurrence measure is discussed in(Manning and Schu?tze, 2003).
This measureis named pointwise Mutual Information (MI),and its applications for finding collocations areanalysed by determining the co-ocurrence de-gree among two terms.
This may be done by cal-culating the ratio between the number of timesthat both terms appear together (in the samecontext and not necessarily in the same order)and the product of the number of times thateach term ocurrs alone.
Given two terms X1and X2, the pointwise mutual information be-tween X1 and X2 can be calculated as follows:MI(X1,X2) = log2P (X1X2)P (X1)?
P (X2)The numerator could be modified in order totake into account only bigrams, as presentedin (Pinto et al, 2006), where an improvementof clustering short texts in narrow domains hasbeen obtained.We have used the pointwise MI for obtaininga co-ocurrence list from the same target dataset.This list is then used to expand every term of theoriginal data.
Since the co-ocurrence formulacaptures relations between related terms, it ispossible to see that the self term expansion mag-nifies less the noisy than the meaninful informa-tion.
Therefore, the execution of the clusteringalgorithm in the expanded corpus should out-perform the one executed over the non-expandeddata.In order to fully appreciate the self term ex-pansion method, in Table 1 we show the co-431ocurrence list for some words related with theverb ?kill?
of the test corpus.
Since the MIis calculated after preprocessing the corpus, wepresent the stemmed version of the terms.Word Co-ocurrence termssoldier killrape women think shoot peopl old mankill death beatgrenad todai live guerrilla fight exploddeath shoot run rape person peopl outsidmurder life lebanon kill convict...temblor tuesdai peopl least kill earthquakTable 1: An example of co-ocurrence termsFor the task #2 of Semeval 2007, a set of 100ambiguous words (35 nouns and 65 verbs) wereprovided.
We preprocessed this original datasetby eliminating stopwords and then applying thePorter stemmer (Porter, 1980).
Thereafter,when we used the pointwise MI, we determinedthat the single ocurrence of each term shouldbe at least three (see (Manning and Schu?tze,2003)), whereas the maximum separation amongthe two terms was five.
Finally, we selectedthe unsupervised KStar clustering method (Shinand Han, 2003) for our experiments, defining theaverage of similarities among all the sentencesfor a given ambiguous word as the stop criterionfor this clustering method.
The input similaritymatrix for the clustering method was calculatedby using the Jaccard coefficient.3 EvaluationThe task organizers decided to use two differ-ent measures for evaluating the runs submittedto the task.
The first measure is called unsuper-vised one, and it is based on the Fscore measure.Whereas the second measure is called supervisedrecall.
For further information on how thesemeasures are calculated refer to (Agirre et al,2006a; Agirre et al, 2006b).
Since these mea-sures give conflicting information, two differentevaluation results are reported in this paper.In Table 2 we may see our ranking and the Fs-core measure obtained (UPV-SI).
We also showthe best and worst team Fscores; as well as thetotal average and two baselines proposed by thetask organizers.
The first baseline (Baseline1)assumes that each ambiguous word has only onesense, whereas the second baseline (Baseline2) isa random assignation of senses.
We are rankedas third place and our results are better scoredthan the other teams except for the best teamscore.
However, given the similar values withthe ?Baseline1?, we may assume that that teampresented one cluster per ambiguous word as itsresult as the Baseline1 did; whereas we obtained9.03 senses per ambiguous word in average.Name Rank All Nouns VerbsBaseline1 1 78.9 80.7 76.8Best Team 2 78.7 80.8 76.3UPV-SI 3 66.3 69.9 62.2Average - 63.6 66.5 60.3Worst Team 7 56.1 65.8 45.1Baseline2 8 37.8 38.0 37.6Table 2: Unsupervised evaluation (Fscore per-formance).In Table 3 we show our ranking and the super-vised recall obtained (UPV-SI).
We again showthe best and worst team recalls.
The total av-erage and one baseline is also presented (theother baseline obtained the same Fscore).
Inthis case, the baseline tags each test instancewith the most frequent sense obtained in a trainsplit.
We are ranked again in third place andour score is slightly above the baseline.Name Rank All Nouns VerbsBest Team 1 81.6 86.8 76.2UPV-SI 3 79.1 82.5 75.3Average - 79.1 82.8 75.0Baseline 4 78.7 80.9 76.2Worst Team 6a 78.5 81.8 74.9Worst Team 6b 78.5 81.4 75.2Table 3: Supervised evaluation (Recall).The results show that the technique employedhave learned, since our simple approach ob-tained a better performance than the baselines,especially the one that have chosen the most fre-quent sense as baseline.4324 ConclusionsWe have reported the performance of a singleapproach based on self term expansion.
Thetechnique uses the pointwise mutual informationfor calculating a set of co-ocurrence terms whichthen are used to expand the original dataset.Once the expansion has been done, the unsu-pervised KStar clustering method was used toinduce the sense for the different ocurrences ofeach ambiguous word.
We obtained the thirdplace in the two measures proposed in the task.We will further investigate whether an improve-ment may be obtained by applying term selec-tion methods to the expanded corpus.ReferencesE.
Agirre and Soroa A.
2007.
SemEval-2007 Task 2:Evaluating Word Sense Induction and Discrimina-tion Systems.
In SemEval-2007.
Association forComputational Linguistics.E.
Agirre, O. Lopez de Lacalle Lekuona, D. Mar-tinez, and A. Soroa.
2006a.
Evaluating and opti-mizing the parameters of an unsupervised graph-based WSD algorithm.
In Textgraphs 2006 work-shop, NAACL06, pages 89?96.E.
Agirre, O. Lopez de Lacalle Lekuona, D. Mar-tinez, and A. Soroa.
2006b.
Two graph-basedalgorithms for state-of-the-art WSD.
In EMNLP,pages 585?593.
ACL.S.
Banerjee and T. Pedersen.
2002.
An AdaptedLesk Algorithm for Word Sense DisambiguationUsing WordNet.
In CICLing 2002 Conference,volume 3878 of LNCS, pages 136?145.
Springer-Verlang.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.W.
B. Frakes and R. A. Baeza-Yates.
1992.
Infor-mation Retrieval: Data Structures & Algorithms.Prentice-Hall.G.
Grefenstette.
1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic.M.
Lesk.
1986.
Automatic sense disambiguation:How to tell a pine cone from an ice cream cone.In ACM SIGDOC Conference, pages 24?26.
ACMPress.D.
C. Manning and H. Schu?tze.
2003.
Foundationsof Statistical Natural Language Processing.
MITPress.
Revised version May 1999.I.
Nancy and J.
Ve?ronis.
1990.
Mapping dictionar-ies: A spreading activation approach.
In 6th An-nual Conference of the Centre for the New OxfordEnglish Dictionary, pages 52?64.D.
Pinto, H. Jime?nez-Salazar, and P. Rosso.
2006.Clustering abstracts of scientific texts using thetransition point technique.
In CICLing, volume3878 of LNCS, pages 536?546.
Springer-Verlang.M.
F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3).A.
Purandare and T. Pedersen.
2004.
Word sensediscrimination by clustering contexts in vector andsimilarity spaces.
In Proceedings of the Confer-ence on Computational Natural Language Learn-ing, pages 41?48, Boston, MA.Y.
Qiu and H. P. Frei.
1993.
Concept based QueryExpansion.
In ACM SIGIR on R&D in informa-tion retrieval, pages 160?169.
ACM Press.R.Baeza-Yates and B. Ribeiro-Neto.
1999.
Mod-ern information retrieval.
New York: ACM Press;Addison-Wesley.P.
Resnik.
1995.
Disambiguating Noun Groupingswith Respect to WordNet Senses.
In 3rd Work-shop on Very Large Corpora, pages 54?68.
ACL.C.
J.
Van Rijsbergen.
1979.
Information Retrieval,2nd edition.
Dept.
of Computer Science, Univer-sity of Glasgow.G.
Ruge.
1992.
Experiments on linguistically-based term associations.
Information Processing& Management, 28(3):317?332.H.
Schu?tze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24(1):97?123.K.
Shin and S. Y. Han.
2003.
Fast clustering algo-rithm for information organization.
In CICLing,volume 2588 of LNCS, pages 619?622.
Springer-Verlang.M.
Sussna.
1993.
Word sense disambiguation forfree-test indexing using a massive semantic net-work.
In 2nd International Conference on Infor-mation and Knowledge Management, pages 67?74.Y.
Wilks, D. Fass, C. Guo, J. McDonald, T. Plate,and B. Slator.
1990.
Providing machine tractabledictionary tools.
Machine Translation, 5(2):99?154.D.
Yarowsky.
1992.
Word-sense disambiguation us-ing statistical models of Rogets categories trainedon large corpora.
In 14th Conference on Compu-tational Linguistics, pages 454?460.
ACL.433
