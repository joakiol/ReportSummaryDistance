Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637?643,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsAutomatic Keyword Extraction on TwitterLu?
?s Marujo1,2,3, Wang Ling1,2,3, Isabel Trancoso2,3, Chris Dyer1, Alan W. Black1,Anatole Gershman1, David Martins de Matos2,3, Jo?ao P. Neto2,3, and Jaime Carbonell11Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA2Instituto Superior T?ecnico, Universidade de Lisboa, Lisbon, Portugal;3INESC-ID, Lisbon, Portugal{luis.marujo,wang.ling,isabel.trancoso,david.matos,joao.neto}@inesc-id.pt{cdyer,awb,anatoleg,jgc}@cs.cmu.edu,AbstractIn this paper, we build a corpus of tweetsfrom Twitter annotated with keywords us-ing crowdsourcing methods.
We iden-tify key differences between this domainand the work performed on other domains,such as news, which makes existing ap-proaches for automatic keyword extractionnot generalize well on Twitter datasets.These datasets include the small amount ofcontent in each tweet, the frequent usageof lexical variants and the high variance ofthe cardinality of keywords present in eachtweet.
We propose methods for addressingthese issues, which leads to solid improve-ments on this dataset for this task.1 IntroductionKeywords are frequently used in many occasionsas indicators of important information containedin documents.
These can be used by human read-ers to search for their desired documents, but alsoin many Natural Language Processing (NLP) ap-plications, such as Text Summarization (Pal et al.,2013), Text Categorization (?Ozg?ur et al., 2005),Information Retrieval (Marujo et al., 2011a; Yangand Nyberg, 2015) and Question Answering (Liuand Nyberg, 2013).
Many automatic frame-works for extracting keywords have been pro-posed (Riloff and Lehnert, 1994; Witten et al.,1999; Turney, 2000; Medelyan et al., 2010; Lit-vak and Last, 2008).
These systems were built formore formal domains, such as news data or Webdata, where the content is still produced in a con-trolled fashion.The emergence of social media environments,such as Twitter and Facebook, has created a frame-work for more casual data to be posted online.These messages tend to be shorter than web pages,especially on Twitter, where the content has to belimited to 140 characters.
The language is alsomore casual with many messages containing or-thographical errors, slang (e.g., cday), abbrevia-tions among domain specific artifacts.
In many ap-plications, that existing datasets and models tendto perform significantly worse on these domains,namely in Part-of-Speech (POS) Tagging (Gim-pel et al., 2011), Machine Translation (Jelh et al.,2012; Ling et al., 2013), Named Entity Recogni-tion (Ritter et al., 2011; Liu et al., 2013), Infor-mation Retrieval (Efron, 2011) and Summariza-tion (Duan et al., 2012; Chang et al., 2013).As automatic keyword extraction plays an im-portant role in many NLP tasks, building an accu-rate extractor for the Twitter domain is a valuableasset in many of these applications.
In this pa-per, we propose an automatic keyword extractionsystem for this end and our contributions are thefollowing ones:1.
Provide a annotated keyword annotateddataset consisting of 1827 tweets.
Thesetweets are obtained from (Gimpel et al.,2011), and also contain POS annotations.2.
Improve a state-of-the-art keyword extractionsystem (Marujo et al., 2011b; Marujo et al.,2013) for this domain by learning additionalfeatures in an unsupervised fashion.The paper is organized as follows: Section 2describes the related work; Section 3 presents theannotation process; Section 4 details the architec-ture of our keyword extraction system; Section 5presents experiments using our models and weconclude in Section 6.6372 Related WorkBoth supervised and unsupervised approacheshave been explored to perform key word extrac-tion.
Most of the automatic keyword/keyphraseextraction methods proposed for social mediadata, such as tweets, are unsupervised meth-ods (Wu et al., 2010; Zhao et al., 2011;Bellaachia and Al-Dhelaan, 2012).
However,the TF-IDF across different methods remainsa strong unsupervised baseline (Hasan and Ng,2010).
These methods include adaptations tothe PageRank method (Brin and Page, 1998) in-cluding TextRank (Mihalcea and Tarau, 2004),LexRank (Erkan and Radev, 2004), and TopicPageRank (Liu et al., 2010).Supervised keyword extraction methods for-malize this problem as a binary classification prob-lem of two steps (Riloff and Lehnert, 1994; Wit-ten et al., 1999; Turney, 2000; Medelyan et al.,2010; Wang and Li, 2011): candidate generationand filtering of the phrases selected before.
MAUItoolkit-indexer (Medelyan et al., 2010), an im-proved version of the KEA (Witten et al., 1999)toolkit including new set of features and more ro-bust classifier, remains the state-of-the-art systemin the news domain (Marujo et al., 2012).To the best of our knowledge, only (Li etal., 2010) used a supervised keyword extractionframework (based on KEA) with additional fea-tures, such as POS tags to performed keyword ex-traction on Facebook posts.
However, at that timeFacebook status updates or posts did not containedeither hashtags or user mentions.
The size of Face-book posts is frequently longer than tweets and hasless abbreviations since it is not limited by numberof character as in tweets.3 DatasetThe dataset1contains 1827 tweets, which are POStagged in (Gimpel et al., 2011).
We used Ama-zon Mechanical turk, an crowdsourcing market,to recruit eleven annotators to identify keywordsin each tweet.
Each annotator highlighted wordsthat he would consider a keyword.
No specificinstructions about what words can be keywords(e.g., ?urls are not keywords?
), as we wish to learnwhat users find important in a tweet.
It is alsoacceptable for tweets to not contain keywords, assome tweets simply do not contain important in-1The corpus is submitted as supplementary material.formation (e.g., retweet).
The annotations of eachannotator are combined by selecting keywords thatare chosen by at least three annotators.
We also di-vided the 1827 tweets into 1000 training samples,327 development samples and 500 test samples,using the splits as in (Gimpel et al., 2011).4 Automatic Keyword ExtractionThere are many methods that have been proposedfor keyword extraction.
TF-IDF is one of the sim-plest approaches for this end (Salton et al., 1975).The k words with the highest TF-IDF value arechosen as keywords, where k is optimized on thedevelopment set.
This works quite well in textdocuments, such as news articles, as we wish tofind terms that occur frequently within that docu-ment, but are not common in the other documentsin that domain.
However, we found that this ap-proach does not work well in Twitter as tweetstend to be short and generally most terms occuronly once, including their keywords.
This meansthat the term frequency component is not very in-formative as the TF-IDF measure will simply ben-efit words that rarely occur, as these have a verylow inverse document frequency component.A strong baseline for Automatic Key-word Extraction is the MAUI toolkit-indexertoolkit (Medelyan et al., 2010).
The systemextracts a list of candidate keywords from adocument and trains a decision tree over a largeset of hand engineered features, also includingTF-IDF, in order to predict the correct keywordson the training set.
Once trained, the toolkitextracts a list of keyword candidates from a tweetand returns a ranked list of candidates.
The top kkeywords are selected as answers.
The parameterk is maximized on the development set.From this point, we present two extensions tothe MAUI system to address many challengesfound in this domain.4.1 Unsupervised Feature ExtractionThe first problem is the existence of many lexicalvariants in Twitter (e.g., ?cats vs.
catz?).
Whilevariants tend to have the same meaning as theirstandardized form, the proposed model does nothave this information and will not be able to gen-eralize properly.
For instance, if the term ?John?
islabelled as keyword in the training set, the modelwould not be able to extract ?Jooohn?
as keywordas it is in a different word form.
One way to ad-638dress this would be using a normalization systemeither built using hand engineered rules (Gouwset al., 2011) or trained using labelled data (Hanand Baldwin, 2011; Chrupa?a, 2014).
However,these systems are generally limited as these needsupervision and cannot scale to new data or datain other languages.
Instead, we will used unsu-pervised methods that leverage large amounts ofunannotated data.
We used two popular methodsfor this purpose: Brown Clustering and Continu-ous Word Vectors.4.1.1 Brown ClusteringIt has been shown in (Owoputi et al., 2013) thatBrown clusters are effective for clustering lexi-cal variants.
The algorithm attempts to find aclusters distribution to maximize the likelihoodof each cluster predicting the next one, under theHMM assumption.
Thus, words ?yes?, ?yep?
and?yesss?
are generally inserted into the same clus-ter as these tend occur in similar contexts.
It alsobuilds an hierarchical structure of clusters.
For in-stance, the clusters 11001 and 11010, share thefirst three nodes in the hierarchically 110.
Sharingmore tree nodes tends to translate into better sim-ilarity between words within the clusters.
Thus,a word a 11001 cluster is simultaneously in clus-ters 1, 11, 110, 1100 and 11001, and a featurecan be extracted for each cluster.
In our experi-ments, we used the dataset with 1,000 Brown clus-ters made available by Owoputi et al.
(Owoputi etal., 2013)2.4.1.2 Continuous Word VectorsWord representations learned from neural lan-guage models are another way to learn more gen-eralizable features for words (Collobert et al.,2011; Huang et al., 2012).
In these models, ahidden layer is defined that maps words into acontinuous vector.
The parameters of this hiddenlayer are estimated by maximizing a goal func-tion, such as the likelihood of each word predict-ing surrounding words (Mikolov et al., 2013; Linget al., 2015).
In our work, we used the structuredskip-ngram goal function proposed in (Ling et al.,2015) and for each word we extracted its respec-tive word vector as features.4.2 Keyword Length PredictionThe second problem is the high variance in termsof number of keywords per tweet.
In larger doc-2http://www.ark.cs.cmu.edu/TweetNLP/clusters/50mpaths2uments, such as a news article, contain approx-imately 3-5 keywords, so extracting 3 keywordsper document is a reasonable option.
However,this would not work in Twitter, since the numberof keywords can be arbitrary small.
In fact, manytweets contain less than three words, in which casethe extractor would simply extract all words askeywords, which would be incorrect.
One alter-native is to choose a ratio between the number ofwords and number of keywords.
That is, we definethe number of keywords in a tweet as the ratio be-tween number of words in the tweet and k, whichis maximized on the development set.
That is, ifwe set k = 3, then we extract one keyword forevery three words.Finally, a better approach is to learn a model topredict the number of keywords using the trainingset.
Thus, we introduced a model that attemptsto predict the number of keywords in each tweetbased on a set of features.
This is done using lin-ear regression, which extracts a feature set from aninput tweet f1, ..., fnand returns y, the expectednumber of keywords in the tweet.
As features weselected the number of words in the input tweetwith the intuition that the number of keywordstends to depend on the size of the tweet.
Further-more, (2) we count the number of function wordsand non-function words in the tweet, emphasizingthe fact that some types of words tend to contributemore to the number of keywords in the tweet.
Thesame is done for (3) hashtags and at mentions.
Fi-nally, (4) we also count the number of words ineach cluster using the trained Brown clusters.5 ExperimentsExperiments are performed on the annotateddataset using the train, development and test splitsdefined in Section 3.
As baselines, we reportedresults using a TF-IDF, the default MAUI toolkit,and our own implementation of (Li et al., 2010)framework.
In all cases the IDF component wascomputed over a collection of 52 million tweets.Results are reported on rows 1 and 2 in Table 1,respectively.
The parameter k (column Nr.
Key-words) defines the number of keywords extractedfor each tweet and is maximized on the devel-opment set.
Evaluation is performed using F-measure (column F1), where the precision (col-umn P) is defined as the ratio of extracted key-words that are correct and the number of ex-tracted keywords, and the recall (column R) is de-639Dev TestSystem Nr.
Keywords P R F1 P R F11 TF-IDF 15 19.31 83.58 29.97 20.21 85.17 31.162 (Li et al., 2010) 4 48.81 50.05 49.42 51.78 50.92 51.353 MAUI (Default) 4 51.31 52.47 51.88 53.97 53.15 53.564 MAUI (Word Vectors) 4 52.70 53.50 53.10 55.80 54.45 55.125 MAUI (Brown) 4 68.08 74.11 70.97 71.95 75.01 73.456 MAUI (Brown+Word Vectors) 4 68.46 75.05 71.61 72.05 75.16 73.577 MAUI (Trained on News) 4 49.12 49.71 49.41 52.40 51.19 51.79Table 1: F-measure, precision and recall results on the Twitter keyword dataset using different featuresets.Dev TestSelection Nr.
Keywords P R F1 P R F11 Fixed 4 68.46 75.05 71.61 72.05 75.16 73.572 Ratio N//3 65.70 82.69 73.22 69.48 83.8 75.973 Regression y + k 67.55 80.9 73.62 71.81 82.55 76.81Table 2: F-measure, precision and recall results on the Twitter keyword dataset using different keywordselection methods.fined as the ratio between the number of keywordscorrectly extracted and the total number of key-words in the dataset.
We can see that the TF-IDF, which tends to be a strong baseline for key-word/keyphrase extraction (Hasan and Ng, 2010),yields poor results.
In fact, the best value for k is15, which means that the system simply retrievesall words as keywords in order to maximize re-call.
This is because most keywords only occuronce3, which makes the TF component not veryinformative.
On the other hand, the MAUI base-line performs significantly better, this is because ofthe usage of many hand engineered features usinglists of words and Wikipedia, rather than simplyrelying on word counts.Next, we introduce features learnt using an un-supervised setup, namely, word vectors and brownclusters in rows 3 and 4, respectively.
These weretrained on the same 52 million tweets used forcomputing the IDF component.
Due to the largesize of the vocabulary, word types with less than40 occurrences were removed.
We observe thatwhile both features yield improvements over thebaseline model in row 2, the improvements ob-tained using Brown clustering are far more sig-nificant.
Combining both features yields slightlyhigher results, reported on row 5.
Finally, we alsotest training the system with all features on an out-36856 out of 7045 keywords are singletonsof-domain keyword extraction corpus composedby news documents (Marujo et al., 2012).
Resultsare reported on row 6, where we can observe a sig-nificant domain mismatch problem between thesetwo domains as results drop significantly.We explored different methods for choosing thenumber of keywords to be extracted in Table 2.The simplest way is choosing a fixed number ofkeywords k and tune this value in the developmentset.
Next, we can also define the number of key-words as the ratioNk, where N is the number ofwords in the tweet, and k is the parameter that wewish to optimize.
Finally, the number of keywordscan also be estimated using a linear regressor asy = f1w1, ..., fnwn, where f1, ..., fndenote thefeature set and w1, ..., wnare the parameters of themodel trained on the training set.
Once the modelis trained, the number of keywords selected foreach tweet is defined as y + k, where k is insertedto adjust y to maximize F-measure on the devel-opment set.
Results using the best system usingBrown clusters and word vectors are described inTable 2.
We can observe that defining the numberof keywords as a fraction of the number of wordsin the tweet, yields better results (row 2) yieldsbetter overall results than fixing the number of ex-tracted keywords (row 1).
Finally, training a pre-dictor for the number of keywords yields furtherimprovements (row 3) over a simple ratio of the640number of input words.6 ConclusionsIn this work, we built a corpus of tweets annotatedwith keywords, which was used to built and evalu-ate a system to automatically extract keywords onTwitter.
A baseline system is defined using exist-ing methods applied to our dataset and improve-ment significantly using unsupervised feature ex-traction methods.
Furthermore, an additional com-ponent to predict the number of keywords in atweet is also built.
In future work, we plan touse the keyword extraction to perform numerousNLP tasks on the Twitter domain, such as Docu-ment Summarization.AcknowledgementsThis work was partially supported by Fundac?
?aopara a Ci?encia e Tecnologia (FCT) through thegrants CMUP-EPB/TIC/0026/2013, SFRH/BD/51157/2010, and the Carnegie Mellon PortugalProgram.
The authors also wish to thank theanonymous reviewers for their helpful comments.ReferencesAbdelghani Bellaachia and Mohammed Al-Dhelaan.2012.
Ne-rank: A novel graph-based keyphrase ex-traction in twitter.
In Proceedings of the The 2012IEEE/WIC/ACM International Joint Conferences onWeb Intelligence and Intelligent Agent Technology -Volume 01, WI-IAT ?12, pages 372?379, Washing-ton, DC, USA.
IEEE Computer Society.Sergey Brin and Lawrence Page.
1998.
The anatomyof a large-scale hypertextual Web search engine.Computer Networks and ISDN Systems, 30:107?117.Yi Chang, Xuanhui Wang, Qiaozhu Mei, and Yan Liu.2013.
Towards twitter context summarization withuser influence models.
In Proceedings of the SixthACM International Conference on Web Search andData Mining, WSDM ?13, pages 527?536, NewYork, NY, USA.
ACM.Grzegorz Chrupa?a.
2014.
Normalizing tweets withedit scripts and recurrent neural embeddings.
InProceedings of the 52nd Annual Meeting of the As-sociation for Computational Linguistics (Volume 2:Short Papers), pages 680?686, Baltimore, Mary-land, June.
Association for Computational Linguis-tics.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
The Journal of Machine Learning Re-search, 12.Yajuan Duan, Zhumin Chen, Furu Wei, Ming Zhou,and Heung-Yeung Shum.
2012.
Twitter topic sum-marization by ranking tweets using social influenceand content quality.
In Proceedings of COLING2012, pages 763?780.
The COLING 2012 Organiz-ing Committee.Miles Efron.
2011.
Information search and re-trieval in microblogs.
J.
Am.
Soc.
Inf.
Sci.
Technol.,62(6):996?1008, June.G?unes?
Erkan and Dragomir R. Radev.
2004.
LexRank:Graph-based Centrality as Salience in Text Summa-rization.
Journal of Artificial Intelligence Research,22:457?479.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: annotation, features, and experiments.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies: short papers - Volume 2, HLT?11, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Stephan Gouws, Dirk Hovy, and Donald Metzler.2011.
Unsupervised mining of lexical variants fromnoisy text.
In Proceedings of the First Workshopon Unsupervised Learning in NLP, EMNLP ?11,pages 82?90, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Bo Han and Timothy Baldwin.
2011.
Lexical normal-isation of short text messages: Makn sens a #twit-ter.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies - Volume 1, HLT ?11,pages 368?378, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Kazi Saidul Hasan and Vincent Ng.
2010.
V.: Conun-drums in unsupervised keyphrase extraction: Mak-ing sense of the state-of-the-art.
In In: COLING,pages 365?373.Eric H Huang, Richard Socher, Christopher D Man-ning, and Andrew Y Ng.
2012.
Improving wordrepresentations via global context and multiple wordprototypes.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics: Long Papers-Volume 1, pages 873?882.
Asso-ciation for Computational Linguistics.Laura Jelh, Felix Hiebel, and Stefan Riezler.
2012.Twitter translation using translation-based cross-lingual retrieval.
In Proceedings of the Sev-enth Workshop on Statistical Machine Translation,Montr?eal, Canada, June.
Association for Computa-tional Linguistics.641Zhenhui Li, Ding Zhou, Yun-Fang Juan, and JiaweiHan.
2010.
Keyword extraction for social snippets.In Proceedings of the 19th International Conferenceon World Wide Web, WWW ?10, pages 1143?1144,New York, NY, USA.
ACM.Wang Ling, Guang Xiang, Chris Dyer, Alan Black, andIsabel Trancoso.
2013.
Microblogs as parallel cor-pora.
In Proceedings of the 51st Annual Meetingon Association for Computational Linguistics, ACL?13.
Association for Computational Linguistics.Wang Ling, Chris Dyer, Alan Black, and IsabelTrancoso.
2015.
Two/too simple adaptations ofword2vec for syntax problems.
In Proceedings ofthe 2015 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies.
Associationfor Computational Linguistics.Marina Litvak and Mark Last.
2008.
Graph-basedkeyword extraction for single-document summariza-tion.
In Proceedings of the Workshop on Multi-source Multilingual Information Extraction andSummarization, MMIES ?08, pages 17?24, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Rui Liu and Eric Nyberg.
2013.
A phased rankingmodel for question answering.
In Proceedings of the22Nd ACM International Conference on Informa-tion & Knowledge Management, CIKM ?13, pages79?88, New York, NY, USA.
ACM.Zhiyuan Liu, Wenyi Huang, Yabin Zheng, andMaosong Sun.
2010.
Automatic keyphrase extrac-tion via topic decomposition.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?10, pages 366?376,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Xiaohua Liu, Furu Wei, Shaodian Zhang, and MingZhou.
2013.
Named entity recognition for tweets.ACM Transactions on Intelligent Systems and Tech-nology (TIST), 4(1):3.Lu?
?s Marujo, Miguel Bugalho, Jo?ao P. Neto, AnatoleGershman, and Jaime Carbonell.
2011a.
Hourlytraffic prediction of news stories.
In Proceedings ofthe 3rdInternational Workshop on Context- AwareRecommender Systems held as part of the 5thACMRecSys Conference, October.Lu?
?s Marujo, M?arcio Viveiros, and Jo?ao P. Neto.2011b.
Keyphrase Cloud Generation of BroadcastNews.
In Proceedings of the 12thAnnual Con-ference of the International Speech CommunicationAssociation (INTERSPEECH 2011).
ISCA, Septem-ber.Lu?
?s Marujo, Anatole Gershman, Jaime Carbonell,Robert Frederking, and Jo?ao P. Neto.
2012.
Super-vised topical key phrase extraction of news storiesusing crowdsourcing, light filtering and co-referencenormalization.
In Proceedings of the 8thInterna-tional Conference on Language Resources and Eval-uation (LREC 2012).Lu?
?s Marujo, Ricardo Ribeiro, David Martinsde Matos, Jo?ao Paulo Neto, Anatole Gershman, andJaime G. Carbonell.
2013.
Key phrase extractionof lightly filtered broadcast news.
In Proceedings ofthe 15thInternational Conference on Text, Speechand Dialogue (TSD).Olena Medelyan, Vye Perrone, and Ian H. Witten.2010.
Subject metadata support powered by maui.In Jane Hunter, Carl Lagoze, C. Lee Giles, andYuan-Fang Li, editors, JCDL, pages 407?408.
ACM.Rada Mihalcea and Paul Tarau.
2004.
Textrank:Bringing order into texts.
In Dekang Lin and DekaiWu, editors, Proceedings of EMNLP 2004, pages404?411, Barcelona, Spain, July.
Association forComputational Linguistics.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems, pages 3111?3119.Olutobi Owoputi, Brendan O?Connor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah ASmith.
2013.
Improved part-of-speech tagging foronline conversational text with word clusters.
InHLT-NAACL, pages 380?390.Arzucan?Ozg?ur, Levent?Ozg?ur, and Tunga G?ung?or.2005.
Text categorization with class-based andcorpus-based keyword selection.
In Proceedingsof the 20th International Conference on Computerand Information Sciences, ISCIS?05, pages 606?615, Berlin, Heidelberg.
Springer-Verlag.Alok Ranjan Pal, Projjwal Kumar Maiti, and DigantaSaha.
2013.
An approach to automatic text summa-rization using simplified lesk algorithm and word-net.
International Journal of Control Theory &Computer Modeling, 3.Ellen Riloff and Wendy Lehnert.
1994.
Informationextraction as a basis for high-precision text classifi-cation.
ACM Transactions on Information Systems(TOIS), 12(3):296?333, July.Alan Ritter, Sam Clark, Oren Etzioni, et al.
2011.Named entity recognition in tweets: an experimentalstudy.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages1524?1534.
Association for Computational Linguis-tics.G.
Salton, A. Wong, and C. S. Yang.
1975.
A VectorSpace Model for Automatic Indexing.
Communica-tions of the ACM, 18(11):613?620.Peter D. Turney.
2000.
Learning algorithmsfor keyphrase extraction.
Information Retrieval,2(4):303?336.642Chen Wang and Sujian Li.
2011.
Corankbayes:Bayesian learning to rank under the co-trainingframework and its application in keyphrase extrac-tion.
In Proceedings of the 20th ACM InternationalConference on Information and Knowledge Man-agement, CIKM ?11, pages 2241?2244, New York,NY, USA.
ACM.Ian H. Witten, Gordon W. Paynter, Eibe Frank, CarlGutwin, and Craig G. Nevill-Manning.
1999.
Kea:practical automatic keyphrase extraction.
In Pro-ceedings of the 4thACM conference on Digital li-braries, DL ?99, pages 254?255, New York, NY,USA.
ACM.Wei Wu, Bin Zhang, and Mari Ostendorf.
2010.
Au-tomatic generation of personalized annotation tagsfor twitter users.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, HLT ?10, pages 689?692, Stroudsburg, PA,USA.
Association for Computational Linguistics.Zi Yang and Eric Nyberg.
2015.
Leveraging proce-dural knowledge base for task-oriented search.
InProceedings of the 38th international ACM SIGIRconference on Research & development in informa-tion retrieval.
ACM.Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song,Palakorn Achananuparp, Ee-Peng Lim, and Xiaom-ing Li.
2011.
Topical keyphrase extraction fromtwitter.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies - Volume 1,HLT ?11, pages 379?388, Stroudsburg, PA, USA.Association for Computational Linguistics.643
