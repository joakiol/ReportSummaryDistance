Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 73?83,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsSMT Helps Bitext Dependency ParsingWenliang Chen?
?, Jun?ichi Kazama?, Min Zhang?, Yoshimasa Tsuruoka?
?,Yujie Zhang?
?, Yiou Wang?, Kentaro Torisawa?
and Haizhou Li?
?Human Language Technology, Institute for Infocomm Research, Singapore?National Institute of Information and Communications Technology (NICT), Japan?School of Information Science, JAIST, Japan?Beijing Jiaotong University, China{wechen, mzhang, hli}@i2r.a-star.edu.sg{kazama, torisawa, yujie, wangyiou}@nict.go.jptsuruoka@jaist.ac.jpAbstractWe propose a method to improve the accuracyof parsing bilingual texts (bitexts) with thehelp of statistical machine translation (SMT)systems.
Previous bitext parsing methods usehuman-annotated bilingual treebanks that arehard to obtain.
Instead, our approach uses anauto-generated bilingual treebank to producebilingual constraints.
However, because theauto-generated bilingual treebank contains er-rors, the bilingual constraints are noisy.
Toovercome this problem, we use large-scaleunannotated data to verify the constraints anddesign a set of effective bilingual features forparsing models based on the verified results.The experimental results show that our newparsers significantly outperform state-of-the-art baselines.
Moreover, our approach is stillable to provide improvement when we use alarger monolingual treebank that results in amuch stronger baseline.
Especially notableis that our approach can be used in a purelymonolingual setting with the help of SMT.1 IntroductionRecently there have been several studies aiming toimprove the performance of parsing bilingual texts(bitexts) (Smith and Smith, 2004; Burkett and Klein,2008; Huang et al, 2009; Zhao et al, 2009; Chenet al, 2010).
In bitext parsing, we can use the in-formation based on ?bilingual constraints?
(Burkettand Klein, 2008), which do not exist in monolingualsentences.
More accurate bitext parsing results canbe effectively used in the training of syntax-basedmachine translation systems (Liu and Huang, 2010).Most previous studies rely on bilingual treebanksto provide bilingual constraints for bitext parsing.Burkett and Klein (2008) proposed joint models onbitexts to improve the performance on either or bothsides.
Their method uses bilingual treebanks thathave human-annotated tree structures on both sides.Huang et al (2009) presented a method to train asource-language parser by using the reordering in-formation on words between the sentences on twosides.
It uses another type of bilingual treebanksthat have tree structures on the source sentences andtheir human-translated sentences.
Chen et al (2010)also used bilingual treebanks and made use of treestructures on the target side.
However, the bilingualtreebanks are hard to obtain, partly because of thehigh cost of human translation.
Thus, in their experi-ments, they applied their methods to a small data set,the manually translated portion of the Chinese Tree-bank (CTB) which contains only about 3,000 sen-tences.
On the other hand, many large-scale mono-lingual treebanks exist, such as the Penn EnglishTreebank (PTB) (Marcus et al, 1993) (about 40,000sentences in Version 3) and the latest version of CTB(over 50,000 sentences in Version 7).In this paper, we propose a bitext parsing ap-proach in which we produce the bilingual constraintson existing monolingual treebanks with the help ofSMT systems.
In other words, we aim to improvesource-language parsing with the help of automatictranslations.In our approach, we first use an SMT systemto translate the sentences of a source monolingualtreebank into the target language.
Then, the targetsentences are parsed by a parser trained on a tar-get monolingual treebank.
We then obtain a bilin-gual treebank that has human annotated trees on thesource side and auto-generated trees on the targetside.
Although the sentences and parse trees on the73target side are not perfect, we expect that we canimprove bitext parsing performance by using thisnewly auto-generated bilingual treebank.
We buildword alignment links automatically using a wordalignment tool.
Then we can produce a set of bilin-gual constraints between the two sides.Because the translation, parsing, and word align-ment are done automatically, the constraints are notreliable.
To overcome this problem, we verify theconstraints by using large-scale unannotated mono-lingual sentences and bilingual sentence pairs.
Fi-nally, we design a set of bilingual features based onthe verified results for parsing models.Our approach uses existing resources includingmonolingual treebanks to train monolingual parserson both sides, bilingual unannotated data to trainSMT systems and to extract bilingual subtrees,and target monolingual unannotated data to extractmonolingual subtrees.
In summary, we make the fol-lowing contributions:?
We propose an approach that uses an auto-generated bilingual treebank rather thanhuman-annotated bilingual treebanks used inprevious studies (Burkett and Klein, 2008;Huang et al, 2009; Chen et al, 2010).
Theauto-generated bilingual treebank is built withthe help of SMT systems.?
We verify the unreliable constraints by usingthe existing large-scale unannotated data anddesign a set of effective bilingual features overthe verified results.
Compared to Chen et al(2010) that also used tree structures on the tar-get side, our approach defines the features onthe auto-translated sentences and auto-parsedtrees, while theirs generates the features bysome rules on the human-translated sentences.?
Our parser significantly outperforms state-of-the-art baseline systems on the standard testdata of CTB containing about 3,000 sentences.Moreover, our approach continues to achieveimprovement when we build our system us-ing the latest version of CTB (over 50,000 sen-tences) that results in a much stronger baseline.?
We show the possibility that we can improvethe performance even if the test set has no hu-man translation.
This means that our proposedapproach can be used in a purely monolingualsetting with the help of SMT.
To our knowl-edge, this paper is the first one that demon-strates this widened applicability, unlike theprevious studies that assumed that the parser isapplied only on the bitexts made by humans.Throughout this paper, we use Chinese as thesource language and English as the target language.The rest of this paper is organized as follows.
Sec-tion 2 introduces the motivation of this work.
Sec-tion 3 briefly introduces the parsing model used inthe experiments.
Section 4 describes a set of bilin-gual features based on the bilingual constraints andSection 5 describes how to use large-scale unanno-tated data to verify the bilingual constraints and de-fine another set of bilingual features based on theverified results.
Section 6 explains the experimentalresults.
Finally, in Section 7 we draw conclusions.2 MotivationHere, bitext parsing is the task of parsing source sen-tences with the help of their corresponding transla-tions.
Figure 1-(a) shows an example of the inputof bitext parsing, where ROOT is an artificial roottoken inserted at the beginning and does not dependon any other token in the sentence, the dashed undi-rected links are word alignment links, and the di-rected links between words indicate that they havea dependency relation.
Given such inputs, we builddependency trees for the source sentences.
Figure1-(b) shows the output of bitext parsing for the ex-ample in 1-(a).ROOT!?
??
??
?
?
??
??
?
??
?
?ta gaodu pingjia le yu lipeng zongli de huitan jieguo!!
!!
!ROOT H hi hl d d h l f h f i h P Li!!
e!
g y!commen e !t e!resu ts!
!o !!
!t e!con erence!!!
!w t !!
eng(a)ROOT!?
??
??
?
?
??
??
?
??
?
?ta gaodu pingjia le yu lipeng zongli de huitan jieguo!!
!!
(b)Figure 1: Input and output of our approachIn bitext parsing, some ambiguities exist on thesource side, but they may be unambiguous on the74target side.
These differences are expected to helpimprove source-side parsing.Suppose we have a Chinese sentence shown inFigure 2-(a).
In this sentence, there is a nomi-nalization case (Li and Thompson, 1997) in whichthe particle ??(de)/nominalizer?
is placed after theverb compound ???(peiyu)??
(qilai)/cultivate?to modify ???(jiqiao)/skill?.
This nominaliza-tion is a relative clause, but does not have a clueabout its boundary.
That is, it is very hard to deter-mine which word is the head of ???
(jiqiao)/skill?.The head may be ???(fahui)/demonstrate?
or ???
(peiyu)/cultivate?, as shown in Figure 2-(b) and-(c), where (b) is correct.?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaoPN!!!!!!!VV!!!!!!!!!DT!!!!!!!!!!!!!!!NN!!!!!!!!!!!!!!!AD!!!!!!!!!!!!!!VV!!!!!!AD!!!!!!!VV!!!
!VV DEC NN!!!!CC!!!NN(a)?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiao(b)?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiao(c)Figure 2: Example of an ambiguity on the Chinese sideIn its English translation (Figure 3), word ?that?
isa clue indicating the relative clause which shows therelation between ?skill?
and ?cultivate?, as shown inFigure 3.
The figure shows that the translation canprovide useful bilingual constraints.
From the de-pendency tree on the target side, we find that theword ?skill?
corresponding to ???
(jiqiao)/skill?depends on the word ?demonstrate?
correspondingto ???
(fahui)/demonstrate?, while the word ?cul-tivate?
corresponding to ???(peiyu)/cultivate?
is agrandchild of ?skill?.
This is a positive evidence forsupporting ???(fahui)/demonstrate?
as being thehead of ???
(jiqiao)/skill?.The above case uses the human translation onthe target side.
However, there are few human-annotated bilingual treebanks and the existing bilin-gual treebanks are usually small.
In contrast, thereare large-scale monolingual treebanks, e.g., the PTBand the latest version of CTB.
So we want to useexisting resources to generate a bilingual treebankwith the help of SMT systems.
We hope to improvesource side parsing by using this newly built bilin-gual treebank.?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaoHe!hoped!that!all!the!athletes!would!
!fully!demonstrate!the!strength!and!skill!that!they!cultivate!dailyFigure 3: Example of human translation?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaohe!expressed!the!hope!that!all!athletes!used!to!give!full!play!to!the!country!
's!strength!and!skills!Figure 4: Example of Moses translationFigure 4 shows an example of a translation us-ing a Moses-based system, where the target sen-tence is parsed by a monolingual target parser.
Thetranslation contains some errors, but it does containsome correct parts that can be used for disambigua-tion.
In the figure, the word ?skills?
correspondingto ???(jiqiao)/skill?
is a grandchild of the word?play?
corresponding to ???
(fahui)/demonstrate?.This is a positive evidence for supporting ???(fahui)/demonstrate?
as being the head of ???
(jiqiao)/skill?.From this example, although the sentences andparse trees on the target side are not perfect, westill can explore useful information to improve bitextparsing.
In this paper, we focus on how to designa method to verify such unreliable bilingual con-straints.3 Parsing modelIn this paper, we implement our approach basedon graph-based parsing models (McDonald andPereira, 2006; Carreras, 2007).
Note that our ap-proach can also be applied to transition-based pars-ing models (Nivre, 2003; Yamada and Matsumoto,2003).The graph-based parsing model is to search forthe maximum spanning tree (MST) in a graph (Mc-Donald and Pereira, 2006).
The formulation definesthe score of a dependency tree to be the sum of edgescores,75s(x, y) =?g?yscore(w, x, g) =?g?yw ?f(x, g) (1)where x is an input sentence, y is a dependencytree for x, and g is a spanning subgraph of y. f(x, g)can be based on arbitrary features of the subgraphand the input sequence x and the feature weightvector w are the parameters to be learned by usingMIRA (Crammer and Singer, 2003) during training.In our approach, we use two types of featuresfor the parsing model.
One is monolingual fea-tures based on the source sentences.
The mono-lingual features include the first- and second- orderfeatures presented in McDonald and Pereira (2006)and the parent-child-grandchild features used in Car-reras (2007).
The other one is bilingual features (de-scribed in Sections 4 and 5) that consider the bilin-gual constraints.We call the parser with the monolingual featureson the source side Parsers, and the parser with themonolingual features on the target side Parsert.4 Original bilingual featuresIn this paper, we generate two types of bilingual fea-tures, original and verified bilingual features.
Theoriginal bilingual features (described in this section)are based on the bilingual constraints without beingverified by large-scale unannotated data.
And theverified bilingual features (described in Section 5)are based on the bilingual constraints verified by us-ing large-scale unannotated data.4.1 Auto-generated bilingual treebankAssuming that we have monolingual treebanks onthe source side, an SMT system that can translatethe source sentences into the target language, and aParsert trained on the target monolingual treebank.We first translate the sentences of the sourcemonolingual treebank into the target language usingthe SMT system.
Usually, SMT systems can outputthe word alignment links directly.
If they can not, weperform word alignment using some publicly avail-able tools, such as Giza++ (Och and Ney, 2003) orBerkeley Aligner (Liang et al, 2006; DeNero andKlein, 2007).
The translated sentences are parsed bythe Parsert.
Then, we have a newly auto-generatedbilingual treebank.
?4.2 Bilingual constraint functionsIn this paper, we focus on the first- and second-order graph models (McDonald and Pereira, 2006;Carreras, 2007).
Thus we produce the constraintsfor bigram (a single edge) and trigram (adjacentedges) dependencies in the graph model.
For the tri-gram dependencies, we consider the parent-siblingand parent-child-grandchild structures described inMcDonald and Pereira (2006) and Carreras (2007).We leave the third-order models (Koo and Collins,2010) for a future study.Suppose that we have a (candidate) dependencyrelation rs that can be a bigram or trigram de-pendency.
We examine whether the correspondingwords of the source words of rs have a dependencyrelation rt in the target trees.
We also consider thedirection of the dependency relation.
The corre-sponding word of the head should also be the headin rt.
We define a binary function for this bilingualconstraint: Fbn(rsn : rtk), where n and k refers tothe types of the dependencies (2 for bigram and 3 fortrigram).
For example, in rs2 : rt3, rs2 is a bigramdependency on the source side and rt3 is a trigramdependency on the target side.4.2.1 Bigram constraint function: Fb2For rs2, we consider two types of bilingual con-straints.
The first constraint function, denoted asFb2(rs2 : rt2), checks if the corresponding wordsalso have a direct dependency relation rt2.
Figure5 shows an example, where the source word ???(quanti)?
depends on ????
(yundongyuan)?and word ?all?
corresponding to ???(quanti)?
de-pends on word ?athletes?
corresponding to ????(yundongyuan)?.
In this case, Fb2(rs2 : rt2) =+.
However, when the source words are ??
(ta)?and ???
(xiwang)?, this time their correspondingwords ?He?
and ?hope?
do not have a direct depen-dency relation.
In this case, Fb2(rs2 : rt2)=?.The second constraint function, denoted asFb2(rs2 : rt3), checks if the corresponding wordsform a parent-child-grandchild relation that oftenoccurs in translation (Koehn et al, 2003).
Figure 6shows an example.
The source word ???
(jiqiao)?depends on ???(fahui)?
while its correspondingword ?skills?
indirectly depends on ?play?
whichcorresponds to ???(fahui)?
via ?to?.
In this case,Fb2(rs2 : rt3)=+.76?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaohe!expressed!the!hope!that!all!athletes!used!to!give!full!play!to!the!country!
's!strength!and!skills!Figure 5: Example of bilingual constraints (2to2)?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaohe!expressed!the!hope!that!all!athletes!used!to!give!full!play!to!the!country!
's!strength!and!skills!Figure 6: Example of bilingual constraints (2to3)4.2.2 Trigram constraint function: Fb3For a second-order relation on the source side,we consider one type of constraint.
We have threesource words that form a second-order relation andall of them have the corresponding words.
Wedefine function Fb3(rs3 : rt3) for this constraint.The function checks if the corresponding wordsform a trigram dependencies structure.
An exam-ple is shown in Figure 7.
The source words ???
(liliang)?, ??
(he)?, and ???(jiqiao)?
form aparent-sibling structure, while their correspondingwords ?strength?, ?and?, and ?skills?
also form aparent-sibling structure on the target side.
In thiscase, function Fb3(rs3 : rt3)=+.?
??
??
???
??
??
??
??
??
?
??
?
?
?ta xiwang quanti yundongyuan chongfeng fahui pingshi peiyu qilai de!
!liliang he!jiqiaohe!expressed!the!hope!that!all!athletes!used!to!give!full!play!to!the!country!
's!strength!and!skills!Figure 7: Example of bilingual constraints (3to3)4.3 Bilingual reordering function: FroHuang et al (2009) proposed features based onreordering between languages for a shift-reduceparser.
They define the features based on word-alignment information to verify whether the corre-sponding words form a contiguous span to resolveshift-reduce conflicts.
We also implement similarfeatures in our system.
For example, in Figure 1-(a) the source span is [??
(huitan), ??
(jieguo)],which maps onto [results, conference].
Because noword within this target span is aligned to a sourceword outside of the source span, this span is a con-tiguous span.
In this case, function Fro =+, other-wise Fro=?.4.4 Original bilingual featuresWe define original bilingual features based on thebilingual constraint functions and the bilingual re-ordering function.Table 1 lists the original features, where Dirrefers to the directions1 of the source-side dependen-cies, Fb2 can be Fb2(rs2 : rt2) and Fb2(rs2 : rt3),and Fb3 is Fb3(rs3 : rt3).
Each line of the tabledefines a feature template that is a combination offunctions.First-order features Second-order features?Fro?
?Fb2, Dir?
?Fb3, Dir?
?Fb2, Dir, Fro?
?Fb3, Dir, Fro?Table 1: Original bilingual featuresWe use an example to show how to generate theoriginal bilingual features in practice.
In Figure 4,we want to define the bilingual features for the bi-gram dependency (rs2) between ???(fahui)?
and???(jiqiao)?.
The corresponding words form a tri-gram relation rt3 in the target dependency tree.
Thedirection of the bigram dependency is right.
Thenwe have feature ?
?Fb2(rs2 : rt3)=+, RIGHT ??
forthe second first-order feature template in Table 1.5 Verified bilingual featuresHowever, because the bilingual treebank is gener-ated automatically, using the bilingual constraintsalone is not reliable.
Therefore, in this section weverify the constraints by using large-scale unanno-tated data to overcome this problem.
More specifi-cally, rtk of the constraint is verified by checking alist of target monolingual subtrees and rsn : rtk isverified by checking a list of bilingual subtrees.
Thesubtrees are extracted from the large-scale unanno-tated data.
The basic idea is as follows: if the de-pendency structures of a bilingual constraint can befound in the list of the target monolingual subtrees1For the second order features, Dir is the combination ofthe directions of two dependencies.77or bilingual subtrees, this constraint will probably bereliable.We first parse the large-scale unannotated mono-lingual and bilingual data.
Subsequently, we ex-tract the monolingual and bilingual subtrees fromthe parsed data.
We then verify the bilingual con-straints using the extracted subtrees.
Finally, wegenerate the bilingual features based on the verifiedresults for the parsing models.5.1 Verified constraint functions5.1.1 Monolingual target subtreesChen et al (2009) proposed a simple method toextract subtrees from large-scale monolingual dataand used them as features to improve monolingualparsing.
Following their method, we parse largeunannotated data with the Parsert and obtain the sub-tree list (STt) on the target side.
We extract twotypes of subtrees: bigram (two words) subtree andtrigram (three words) subtree.H b ht b h b kROOT!!He!!!!!bought!!!!!a!!!!booke!!!!!
oug oug t!!
oo !a book b ht b k!!!!!
(a) (b)oug !!!a!!!!!
oo !Figure 8: Example of monolingual subtree extractionFrom the dependency tree in Figure 8-(a), we ob-tain the subtrees shown in Figure 8-(b) where thefirst three are bigram subtrees and the last one isa trigram subtree.
After extraction, we obtain thesubtree list STt that includes two sets, one for bi-gram subtrees, and the other one for trigram sub-trees.
We remove the subtrees occurring only oncein the data.
For each set, we assign labels to theextracted subtrees according to their frequencies byusing the same method as that of Chen et al (2009).If the frequency of a subtree is in the top 10% in thecorresponding set, it is labeled HF.
If the frequencyis between the top 20% and 30%, it is labeled MF.We assign the label LF to the remaining subtrees.We use Type(stt) to refer to the label of a subtree,stt.5.1.2 Verified target constraint function:Fvt(rtk)We use the extracted target subtrees to verify thertk of the bilingual constraints.
In fact, rtk is a can-didate subtree.
If the rtk is included in STt, func-tion Fvt(rtk) = Type(rtk), otherwise Fvt(rtk) =ZERO.
For example, in Figure 5 the bigram struc-ture of ?all?
and ?athletes?
can form a bigram sub-tree that is included STt and its label is HF.
In thiscase, Fvt(rt2)= HF .5.1.3 Bilingual subtreesWe extract bilingual subtrees from a bilingualcorpus, which is parsed by the Parsers and Parserton both sides.
We extract three types of bilingualsubtrees: bigram-bigram (stbi22), bigram-trigram(stbi23), and trigram-trigram (stbi33) subtrees.
Forexample, stbi22 consists of a bigram subtree on thesource side and a bigram subtree on the target side.?
?
?
??
?
?
?
??ROOT!
?ta shi yi ming xueshengROOT!!He!!!!!is!!!!!a!!!!
!student He!!!!
!is is!!!!
!student(a) (b)Figure 9: Example of bilingual subtree extractionFrom the dependency tree in Figure 9-(a), weobtain the bilingual subtrees shown in Figure 9-(b).
Figure 9-(b) shows the extracted bigram-bigrambilingual subtrees.
After extraction, we obtain thebilingual subtrees STbi.
We remove the subtrees oc-curring only once in the data.5.1.4 Verified bilingual constraint function:Fvb(rbink)We use the extracted bilingual subtrees to verifythe rsn : rtk (rbink in short) of the bilingual con-straints.
rsn and rtk form a candidate bilingual sub-tree stbink.
If the stbink is included in STbi, functionFvb(rbink)=+, otherwise Fvb(rbink)=?.5.2 Verified bilingual featuresThen, we define another set of bilingual features bycombining the verified constraint functions.
We callthese bilingual features ?verified bilingual features?.78Table 2 lists the verified bilingual features used inour experiments, where each line defines a featuretemplate that is a combination of functions.We use an example to show how to generate theverified bilingual features in practice.
In Figure 4,we want to define the verified features for the bi-gram dependency (rs2) between ???(fahui)?
and???(jiqiao)?.
The corresponding words form atrigram relation rt3.
The direction of the bigramdependency is right.
Suppose we can find rt3 inSTt with label MF and can not find the candidatebilingual subtree in STbi.
Then we have feature?
?Fb2(rs2 : rt3) = +, Fvt(rt3) = MF,RIGHT ?
?for the third first-order feature template and feature?
?Fb2(rs2 : rt3)=+, Fvb(rbi23)=?, RIGHT ??
forthe fifth in Table 2.First-order features Second-order features?Fro?
?Fb2, Fvt(rtk)?
?Fb3, Fvt(rtk)?
?Fb2, Fvt(rtk), Dir?
?Fb3, Fvt(rtk), Dir?
?Fb2, Fvb(rbink)?
?Fb3, Fvb(rbink)?
?Fb2, Fvb(rbink), Dir?
?Fb3, Fvb(rbink), Dir?
?Fb2, Fro, Fvb(rbink)?Table 2: Verified bilingual features6 ExperimentsWe evaluated the proposed method on the translatedportion of the Chinese Treebank V2 (referred to asCTB2tp) (Bies et al, 2007), articles 1-325 of CTB,which have English translations with gold-standardparse trees.
The tool ?Penn2Malt?2 was used to con-vert the data into dependency structures.
Followingthe studies of Burkett and Klein (2008), Huang etal.
(2009) and Chen et al (2010), we used the ex-act same data split: 1-270 for training, 301-325 fordevelopment, and 271-300 for testing.
Note that wedid not use human translation on the English sideof this bilingual treebank to train our new parsers.For testing, we used two settings: a test with hu-man translation and another with auto-translation.To process unannotated data, we trained a first-orderParsers on the training data.To prove that the proposed method can work onlarger monolingual treebanks, we also tested our2http://w3.msi.vxu.se/?nivre/research/Penn2Malt.htmlmethods on the CTB7 (LDC2010T07) that includesmuch more sentences than CTB2tp.
We used arti-cles 301-325 for development, 271-300 for testing,and the other articles for training.
That is, we eval-uated the systems on the same test data as CTB2tp.Table 3 shows the statistical information on the datasets.Train Dev TestCTB2tp 2,745 273 290CTB7 50,747 273 290Table 3: Number of sentences of data sets usedWe built Chinese-to-English SMT systems basedon Moses3.
Minimum error rate training (MERT)with respect to BLEU score was used to tune the de-coder?s parameters.
The translation model was cre-ated from the FBIS corpus (LDC2003E14).
We usedSRILM4 to train a 5-gram language model.
The lan-guage model was trained on the target side of theFBIS corpus and the Xinhua news in English Gi-gaword corpus (LDC2009T13).
The developmentand test sets were from NIST MT08 evaluation cam-paign5.
We then used the SMT systems to translatethe training data of CTB2tp and CTB7.To directly compare with the results of Huanget al (2009) and Chen et al (2010), we also usedthe same word alignment tool, Berkeley Aligner(Liang et al, 2006; DeNero and Klein, 2007), toperform word alignment for CTB2tp and CTB7.We trained a Berkeley Aligner on the FBIS corpus(LDC2003E14).
We removed notoriously bad linksin {a, an, the}?{?(de),?
(le)} following the workof Huang et al (2009).To train an English parser, we used the PTB(Marcus et al, 1993) in our experiments and thetool ?Penn2Malt?
to convert the data.
We split thedata into a training set (sections 2-21), a develop-ment set (section 22), and a test set (section 23).We trained first-order and second-order Parsert onthe training data.
The unlabeled attachment score(UAS) of the second-order Parsert was 91.92, in-dicating state-of-the-art accuracy on the test data.We used the second-order Parsert to parse the auto-translated/human-made target sentences in the CTB3http://www.statmt.org/moses/4http://www.speech.sri.com/projects/srilm/download.html5http://www.itl.nist.gov/iad/mig//tests/mt/2008/79data.To extract English subtrees, we used the BLLIPcorpus (Charniak et al, 2000) that contains about43 million words of WSJ texts.
We used the MX-POST tagger (Ratnaparkhi, 1996) trained on train-ing data to assign POS tags and used the first-orderParsert to process the sentences of the BLLIP cor-pus.
To extract bilingual subtrees, we used the FBIScorpus and an additional bilingual corpus contain-ing 800,000 sentence pairs from the training data ofNIST MT08 evaluation campaign.
On the Chineseside, we used the morphological analyzer describedin (Kruengkrai et al, 2009) trained on the trainingdata of CTBtp to perform word segmentation andPOS tagging and used the first-order Parsers to parseall the sentences in the data.
On the English side, weused the same procedure as we did for the BLLIPcorpus.
Word alignment was performed using theBerkeley Aligner.We reported the parser quality by the UAS, i.e.,the percentage of tokens (excluding all punctuationtokens) with correct HEADs.6.1 Experimental settingsFor baseline systems, we used the monolingual fea-tures mentioned in Section 3.
We called these fea-tures basic features.
To compare the results of (Bur-kett and Klein, 2008; Huang et al, 2009; Chen etal., 2010), we used the test data with human trans-lation in the following three experiments.
The tar-get sentences were parsed by using the second-orderParsert.
We used PAG to refer to our parsers trainedon the auto-generated bilingual treebank.6.2 Training with CTB2tpOrder-1 Order-2Baseline 84.35 87.20PAGo 84.71(+0.36) 87.85(+0.65)PAG 85.37(+1.02) 88.49(+1.29)ORACLE 85.79(+1.44) 88.87(+1.67)Table 4: Results of training with CTB2tpFirst, we conducted the experiments on the stan-dard data set of CTB2tp, which was also used inother studies (Burkett and Klein, 2008; Huang et al,2009; Chen et al, 2010).
The results are given inTable 4, where Baseline refers to the system withthe basic features, PAGo refers to that after addingthe original bilingual features of Table 1 to Baseline,PAG refers to that after adding the verified bilingualfeatures of Table 2 to Baseline, and ORACLE6 refersto using human-translation for training data withadding the features of Table 1.
We obtained an ab-solute improvement of 1.02 points for the first-ordermodel and 1.29 points for the second-order model byadding the verified bilingual features.
The improve-ments of the final systems (PAG) over the Baselineswere significant in McNemar?s Test (p < 0.001 forthe first-order model and p < 0.0001 for the second-order model).
If we used the original bilingual fea-tures (PAGo), the system dropped 0.66 points for thefirst-order and 0.64 points for the second-order com-pared with system PAG.
This indicated that the ver-ified bilingual constraints did provide useful infor-mation for the parsing models.We also found that PAG was about 0.3 pointslower than ORACLE.
The reason is mainly dueto the imperfect translations, although we usedthe large-scale subtree lists to help verify the con-straints.
We tried adding the features of Table 2 tothe ORACLE system, but the results were worse.These facts indicated that our approach obtained thebenefits from the verified constraints, while usingthe bilingual constraints alone was enough for OR-ACLE.6.3 Training with CTB70.830.840.850.860.870.880.890.90.910.925  10  20  30  40  50UASAmount of training data (K)Baseline1PAG1Baseline2PAG2Figure 10: Results of using different sizes of training dataHere, we demonstrate that our approach is stillable to provide improvement, even if we use larger6Note that we also used the tool to perform the word align-ment automatically.80Baseline D10 D20 D50 D100 GTranBLEU n/a 14.71 15.84 16.92 17.95 n/aUAS 87.20 87.63 87.67 88.20 88.49 88.58Table 5: Results of using different translationstraining data that result in strong baseline systems.We incrementally increased the training sentencesfrom the CTB7.
Figure 10 shows the results of us-ing different sizes of CTB7 training data, where thenumbers of the x-axis refer to the sentence numbersof training data used, Baseline1 and Baseline2 re-fer to the first- and second-order baseline systems,and PAG1 and PAG2 refer to our first- and second-order systems.
The figure indicated that our sys-tem always outperformed the baseline systems.
Forsmall data sizes, our system performed much betterthan the baselines.
For example, when using 5,000sentences, our second-order system provided a 1.26points improvement over the second-order baseline.Finally, when we used all of the CTB7 trainingdata, our system achieved 91.66 for the second-ordermodel, while the baseline achieved 91.10.6.4 With different settings of SMT systemsWe investigated the effects of different settings ofSMT systems.
We randomly selected 10%, 20%,and 50% of FBIS to train the Moses systems andused them to translate CTB2tp.
The results are inTable 5, where D10, D20, D50, and D100 refer tothe system with 10%, 20%, 50%, and 100% data re-spectively.
For reference, we also used the Google-translate online system7, indicated as GTran in thetable, to translate the CTB2tp.From the table, we found that our system outper-formed the Baseline even if we used only 10% of theFBIS corpus.
The BLEU and UAS scores becamehigher, when we used more data of the FBIS corpus.And the gaps among the results of D50, D100, andGTran were small.
This indicated that our approachwas very robust to the noise produced by the SMTsystems.6.5 Testing with auto-translationWe also translated the test data into English usingthe Moses system and tested the parsers on the new7http://translate.google.com/test data.
Table 6 shows the results.
The resultsshowed that PAG outperformed the baseline systemsfor both the first- and second-order models.
Thisindicated that our approach can provide improve-ment in a purely monolingual setting with the helpof SMT.Order-1 Order-2Baseline 84.35 87.20PAG 84.88(+0.53) 87.89(+0.69)Table 6: Results of testing with auto-translation (trainingwith CTB2tp)6.6 Comparison resultsWith CTB2tp With CTB7Type System UAS System UASM Baseline 87.20 Baseline 91.10HAHuang2009 86.3 n/aChen2010BI 88.56Chen2010ALL 90.13AG PAG 88.49 PAG 91.66PAG+STs 89.75Table 7: Comparison of our results with other pre-vious reported systems.
Type M denotes training onmonolingual treebank.
Types HA and AG denote trainingon human-annotated and auto-generated bilingual tree-banks respectively.We compared our results with the results reportedpreviously for the same data.
Table 7 lists the re-sults, where Huang2009 refers to the result of Huanget al (2009), Chen2010BI refers to the result ofusing bilingual features in Chen et al (2010), andChen2010ALL refers to the result of using all ofthe features in Chen et al (2010).
The resultsshowed that our new parser achieved better accuracythan Huang2009 and comparable to Chen2010BI .To achieve higher performance, we also added thesource subtree features (Chen et al, 2009) to oursystem: PAG+STs.
The new result is close toChen2010ALL.
Compared with the approaches of81Huang et al (2009) and Chen et al (2010), ourapproach used an auto-generated bilingual treebankwhile theirs used a human-annotated bilingual tree-bank.
By using all of the training data of CTB7, weobtained a more powerful baseline that performedmuch better than the previous reported results.
Ourparser achieved 91.66, much higher accuracy thanthe others.7 ConclusionWe have presented a simple yet effective approachto improve bitext parsing with the help of SMT sys-tems.
Although we trained our parser on an auto-generated bilingual treebank, we achieved an accu-racy comparable to the systems trained on human-annotated bilingual treebanks on the standard testdata.
Moreover, our approach continued to pro-vide improvement over the baseline systems whenwe used a much larger monolingual treebank (over50,000 sentences) where target human translationsare not available and very hard to construct.
We alsodemonstrated that the proposed approach can be ef-fective in a purely monolingual setting with the helpof SMT.AcknowledgmentsThis study was started when Wenliang Chen, Yu-jie Zhang, and Yoshimasa Tsuruoka were membersof Language Infrastructure Group, National Insti-tute of Information and Communications Technol-ogy (NICT), Japan.
We would also thank the anony-mous reviewers for their detailed comments, whichhave helped us to improve the quality of this work.ReferencesAnn Bies, Martha Palmer, Justin Mott, and Colin Warner.2007.
English Chinese Translation Treebank V 1.0,LDC2007T02.
Linguistic Data Consortium.David Burkett and Dan Klein.
2008.
Two languages arebetter than one (for syntactic parsing).
In Proceedingsof EMNLP 2008, pages 877?886, Honolulu, Hawaii,October.
Association for Computational Linguistics.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of theCoNLL Shared Task Session of EMNLP-CoNLL 2007,pages 957?961, Prague, Czech Republic, June.
Asso-ciation for Computational Linguistics.Eugene Charniak, Don Blaheta, Niyu Ge, Keith Hall,John Hale, and Mark Johnson.
2000.
BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43.
LinguisticData Consortium.Wenliang Chen, Jun?ichi Kazama, Kiyotaka Uchimoto,and Kentaro Torisawa.
2009.
Improving dependencyparsing with subtrees from auto-parsed data.
In Pro-ceedings of EMNLP 2009, pages 570?579, Singapore,August.Wenliang Chen, Jun?ichi Kazama, and Kentaro Torisawa.2010.
Bitext dependency parsing with bilingual sub-tree constraints.
In Proceedings of ACL 2010, pages21?29, Uppsala, Sweden, July.
Association for Com-putational Linguistics.Koby Crammer and Yoram Singer.
2003.
Ultraconser-vative online algorithms for multiclass problems.
J.Mach.
Learn.
Res., 3:951?991.John DeNero and Dan Klein.
2007.
Tailoring wordalignments to syntactic machine translation.
In Pro-ceedings of ACL 2007, pages 17?24, Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.Bilingually-constrained (monolingual) shift-reduceparsing.
In Proceedings of EMNLP 2009, pages 1222?1231, Singapore, August.
Association for Computa-tional Linguistics.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofNAACL 2003, pages 48?54.
Association for Computa-tional Linguistics.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of ACL2010, pages 1?11, Uppsala, Sweden, July.
Associationfor Computational Linguistics.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichiKazama, Yiou Wang, Kentaro Torisawa, and HitoshiIsahara.
2009.
An error-driven word-character hybridmodel for joint Chinese word segmentation and POStagging.
In Proceedings of ACL-IJCNLP2009, pages513?521, Suntec, Singapore, August.
Association forComputational Linguistics.Charles N. Li and Sandra A. Thompson.
1997.
Man-darin Chinese - A Functional Reference Grammar.University of California Press.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of NAACL 2006,pages 104?111, New York City, USA, June.
Associa-tion for Computational Linguistics.Yang Liu and Liang Huang.
2010.
Tree-based and forest-based translation.
In Tutorial Abstracts of ACL 2010,page 2, Uppsala, Sweden, July.
Association for Com-putational Linguistics.82Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguisticss, 19(2):313?330.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing algo-rithms.
In Proceedings of EACL 2006, pages 81?88.Joakim Nivre.
2003.
An efficient algorithm forprojective dependency parsing.
In Proceedings ofIWPT2003, pages 149?160.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In Proceedings of EMNLP1996, pages 133?142.David A. Smith and Noah A. Smith.
2004.
Bilingualparsing with factored estimation: Using English toparse Korean.
In Proceedings of EMNLP 2004, pages49?56.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT 2003, pages 195?206.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009.
Cross language dependency parsing us-ing a bilingual lexicon.
In Proceedings of ACL-IJCNLP2009, pages 55?63, Suntec, Singapore, Au-gust.
Association for Computational Linguistics.83
