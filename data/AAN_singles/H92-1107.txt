Spoken Language Recognition and UnderstandingVictor Zue and Lynette HirschmanSpoken Language Systems GroupLaboratory  for Computer  ScienceMassachusetts  Inst i tute of TechnologyCambridge,  Massachusetts  021391.
PROJECT GOALSThe goal of this research is to demonstrate spoken lan-guage systems in support of interactive problem solving.The system accepts continuous speech input and handlesmultiple speakers without explicit speaker enrollment.The MIT spoken language system combines SUMMIT, asegment-based speech recognition system, and TINA, aprobabilistic natural anguage system, to achieve speechunderstanding.
The system engages in interactive dia-logue with the user, providing output in the form of tab-ular displays, as well as spoken and written output.
Thesystem has been demonstrated on several applications,including travel planning and direction assistance.2.
RECENT RESULTS?
Reduced spontaneous speech recognition word er-ror rate by more than a factor of two since theFebruary 1991 evaluation through the use of lowperplexity language models and context-dependentphonetic models.?
Reduced natural anguage weighted error by almosta factor of 2 on class A sentences through the useof a robust parsing mechanism, which integratesparsed phrases into a single semantic representation,using a slight extension of the existing discourse pro-cessing.?
Demonstrated a near real-time interactive spokenlanguage system, running on a Sun SPARCstationor an IBM RX6000.?
Developed and experimented with alternative met-rics for the evaluation of interactive spoken languagesystems, including use of task completion and time-to-completion for air travel planning tasks, as wellas a log file based evaluation procedure.?
Collected nearly 20,000 sentences for the Wall StreetJournal pilot corpus in support of research and de-velopment in large-vocabulary speech recognitionsystems.?
Chaired the MADCOW multi-site ATIS data collec-tion effort, contributed over 5000 sentences of spon-taneous ATIS data, and participated in the commonevaluation for speech, spoken language and text in-put.3.
PLANS FOR THE COMINGYEARImprove SUMMIT recognition performance by devel-oping phonetic and language models for silence andfilled pauses, and mechanisms todetect and "repair"false starts and repeats.Continue experimentation on low perplexity lan-guage models (N-gram, LR parser, probablisticparsing) to improve speech recognition performance.Model discourse and dialogue, including the use oferror and clarification messages, to improve bothrecognition performance and the interactive natureof spoken language systems.Develop evaluation metrics for interactive spokenlanguage systems based on experiments using thereal-time ATIS spoken language system.Experiment with alternative user interaction strate-gies using near real-time data collection system.474
