Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 23?27,Uppsala, July 2010.Does Negation Really Matter?Ira GoldsteinUniversity at Albany, SUNYAlbany, NY USAig4895@albany.edu?zlem UzunerUniversity at Albany, SUNYAlbany, NY USAouzuner@albany.eduAbstractWe explore the role negation and speculationidentification plays in the multi-label docu-ment-level classification of medical reports fordiseases.
We identify the polarity of assertionsmade on noun phrases which reference dis-eases in the medical reports.
We experimentwith two machine learning classifiers: onebased upon Lucene and the other based uponBoosTexter.
We find the performance of thesesystems on document-level classification ofmedical reports for diseases fails to show im-provement when their input is enhanced by thepolarity of assertions made on noun phrases.We conclude that due to the nature of our ma-chine learning classifiers, information on thepolarity of phrase-level assertions does notimprove performance on our data in a multi-label document-level classification task.1 IntroductionIn the medical domain, a substantial amount ofpatient data is stored as free text in patient medi-cal report narratives (Spat et al 2008) and needsto be processed in order to be converted to morewidely-useful structured information.
These nar-ratives contain a variety of useful informationthat can support syndromic surveillance (Shapiro2004), decision support (Fiszman et al 2000),and problem list generation (Sibanda et al 2006).Physicians often assert negative or speculativediagnoses in medical reports (Rao et al 2003) tokeep track of all potential diagnoses that havebeen considered and to provide information thatcontrasts with the positive diagnoses (Kim andPark 2006).
The noun phrases (NP) associatedwith negative and speculative assertions in medi-cal reports may be confused with positively as-serted NPs, thereby adversely affecting auto-mated classification system performance.
In themedical domain, verbs often play a reduced roleor are implied in assertions.
We therefore focusour investigation of assertions on NPs.In this paper, we describe the polarity of anassertion as being positive, speculative, or nega-tive.
Assertion classification is a generally ac-cepted means for resolving problems caused bynegation and speculation.
Averbuch et al (2004)use context to identify negative/positive in-stances of various symptoms.
Mutalik et al(2001) show that the Unified Medical LanguageSystem (UMLS) Metathesaurus can be used toreliably detect negated concepts in medical nar-ratives.
Harkema et al (2009) develop ConTextto determine not only positive and negative as-sertions, but also assertions referencing someoneother than the patient.The literature is filled with reports of systemswhich employ assertion classification (e.g.,Google Scholar lists 134 documents citingChapman et al?s (2001) NegEx).
However, fewreports describe how much assertion classifica-tion contributes to the final system performance.Two exceptions are Goldstein et al (2007) andAmbert and Cohen (2009).Goldstein et al develop a hand-crafted rulebased system to classify radiological reportsfrom the 2007 Computational Medicine Center(CMC) Challenge (Pestian et al 2007).
Theyshow that negation and speculation play keyroles in classifying their reports.
Ambert and Co-hen apply a machine learning (ML) approach toclassifying discharge summaries from the 2008i2b2 Obesity Challenge (Uzuner 2008).
Theyreport that due to ?false negations,?
simply add-ing negation detection to their base system doesnot consistently improve performance.
Promptedby these contradicting results in the literature, weexplore the role assertion classification plays inthe multi-label classification of medical reportsfrom both the CMC and i2b2 challenges.We attempt to improve document-level classi-fication performance of two multi-label ML clas-sifiers by identifying the polarity of assertions onNPs.
We experiment with medical reports fromtwo different corpora.
We detect NPs which ref-erence diseases.
We then identify the polarity ofthe assertion made for each NP.
We show thatenriching reports with the polarity of the asser-tions does not improve performance for multi-label document-level classification of medical23reports into diseases in our corpora.
Our findingsimply that, despite common practice, the contri-bution of assertion classification may be limitedwhen employing ML approaches to predictingdocument-level labels of medical reports.2 DataThe data were provided by the CMC challenge(Pestian et al 2007) and the i2b2 Obesity Chal-lenge (Uzuner 2008).
Both data sets had been de-identified (anonymized) and, where appropriate,re-identified with surrogates.
Our task is to de-termine the presence of diseases in the patientbased upon medical report narratives.
The insti-tutional review boards of the SUNY Albany andPartners HealthCare approved this study.2.1 CMC Data SetThe CMC data set consists of a training set of978 radiology reports and a test set of 976 radi-ology reports.
Each report is labeled withICD-9-CM (National Center for Health Statistics2010) standard diagnostic classification codes.The reports have been hand labeled with 45ICD-9-CM.
Each code represents a distinct dis-ease present in the patient.
The codes reflect onlythe definite diagnoses mentioned in that report.At least one code is assigned to each report.
Mul-tiple codes per report are allowed.
For each re-port in the test set, we predict which diseases arepresent in the patient and label the report withthe ICD-9-CM code for that disease.
Any codenot assigned to a report implies that the corre-sponding disease is not present in the patient.2.2 i2b2 Data SetThe i2b2 data set consists of a training set of 720discharge summaries and a test set of 501 dis-charge summaries.
These medical reports rangein size from 133 words to more than 3000 words.The reports have been labeled for information onobesity and 15 of its most frequent co-morbidities.
For each report, each disease is la-beled as being present, absent, or questionable inthe patient, or unmentioned in the narrative.
Mul-tiple codes per report are allowed.Since we are interested in those diseases pre-sent in the patient, we retain the present class andcollapse the absent, questionable, andunmentioned categories into a not present class.For each report in the test set we predict whethereach of the 16 diseases is present or not presentin the patient.
We label each report with our pre-diction for each of the 16 diseases.3 MethodsWe preprocess the medical report narrativeswith a Noun Phrase Detection Pre-processor(NPDP) to detect noun phrases referencing dis-eases.
We implement our own version of Con-Text (Harkema et al 2009), enhance it to alsodetect speculation, and employ it to identify thepolarity of assertions made on the detected NPs.We expand the text of the medical reports withasserted NPs.
We conflate lexical variations ofwords.
We train two different types of classifierson each of the training sets.
We apply labels toboth the expanded and non-expanded reports us-ing two ML classifiers.
We evaluate and reportresults only on the test sets.3.1 Noun Phrase and Assertion DetectionWe detect noun phrases via an NPDP.
We buildour NPDP based on MetaMap (Aronson 2001).The NPDP identifies NPs which reference dis-eases in medical reports.
We select 17 UMLSsemantic types whose concepts can assist in theclassification of diseases.
First, NPDP maps NPsin the text to UMLS semantic types.
If themapped semantic type is one of the target seman-tic types, NPDP then tags the NP.NPDP uses the pre-UMLS negation phrases ofExtended NegEx (Sibanda et al 2006) to identifyadjectives indicating the absence or uncertaintyof each tagged NPs.
It differentiates these adjec-tives from all other adjectives modifying taggedNPs.
For example, possible in possible reflux isexcluded from the tagged NP, whereas severe insevere reflux is retained.
We then identify thepolarity of the assertion made on each NP.
Inorder to distinguish the polarity of the assertionsfrom one another, we do not modify the positiveassertions, but transform the negative and specu-lative assertions in the following manner: Sen-tences containing negative assertions are re-peated and modified with the NP pre-pendedwith ?abs?
(e.g., ?Patient denies fever.?
is re-peated as ?Patient denies absfever.?).
Similarly,sentences containing speculative assertions arerepeated and modified with the NP pre-pendedwith ?poss?.
We refer to these transformed termsas asserted noun phrases.
We assert NPs for theunmodified text of both the data sets.
Table 1provides a breakdown of the assertions for eachof the detected NPs for each of the data sets.We examine the performance of our enhancedimplementation of ConText by comparing itsresults against CMC test set NPs manually anno-tated by a nurse librarian and author IG.
Table 224shows the performance for each of the three po-larities.
We find these results to be comparable tothose reported in the literature: Mutalik et al?s(2001) NegFinder finds negated concepts with arecall of .957; Chapman et al?s (2001) NegExreport a precision of .8449 and a recall of .8241.CMC i2b2 Assertion Training Test Training TestPositive 2,168 2,117 47,860 34,112Speculative 312 235 3,264 2,166Negative 351 353 8,202 5,654Table 1 - Distribution of Asserted Noun Phrases forboth the CMC and i2b2 data sets.Assertion Precision Recall F1-MeasurePositive 0.991 0.967 0.979Speculative 0.982 0.946 0.964Negative 0.770 0.983 0.864Table 2 - Assertion Performance on the CMC test set.3.2 Lucene ClassifierWe follow the k-Nearest Neighbor (Cover andHart 1967) process previously described in Gold-stein et al (2007) to build our Lucene-basedclassifier.
Classification is based on the nearesttraining samples, as determined by the featurevectors.
This approach assumes that similartraining samples will cluster together in the fea-ture vector space.
The nearest training samplesare considered to be those that are most similarto the data sample.We build our Lucene-based classifier usingApache Lucene (Gospodneti?
and Hatcher 2005).We use the Lucene library to determine the simi-larity of medical report narratives.
We determinewhich training reports are similar to the targetreport based upon their text.
For each target re-port we retrieve the three most similar trainingreports and assign to the target report any codesthat are used by the majority of these reports.
Incases where the retrieved reports do not providea majority code, the fourth nearest training reportis used.
If a majority code is still not found, aNULL code is assigned to the target report.We first run the Lucene Classifier on lowercase, stemmed text of the medical reports.
Werefer to this as the Base Lucene Classifier run.We next run the Lucene Classifier on the textexpanded with asserted noun phrases.
We referto this as the Asserted Lucene Classifier run.3.3 BoosTexter ClassifierBoosTexter (Schapire and Singer 2000) buildsclassifiers from textual data by performing mul-tiple iterations of dividing the text into subsam-ples upon which weak decision-stub learners aretrained.
Among these weak learners, BoosTexterretains those that perform even marginally betterthan chance.
After a set number of iterations, theretained weak learners are combined into the fi-nal classifier.
BoosTexter classifies text usingindividual words (unigrams), strings of consecu-tive words (n-grams), or strings of non-consecutive words, without considering seman-tics.We cross-validate BoosTexter (tenfold) on theCMC training set.
We establish the optimal pa-rameters on the CMC training set to be 1100 it-erations, with n-grams of up to four words.
Wefind the optimal parameters of the i2b2 trainingset to be similar to those of the CMC training set.For consistency, we apply the parameters of1100 iterations and n-grams of up to four wordsto both data sets.
In addition, we apply unigramsto BoosTexter in order to provide BoosTexterclassifier results that are comparable to those ofthe Lucene classifiers.We create two classifiers with BoosTexter us-ing the lower case, stemmed text of the medicalreports: one with unigrams and one withn-grams.
We refer to these as Base BoosTexterClassifier runs.
For each of unigrams andn-grams, we create runs on the text expandedwith the asserted noun phrases.
We refer to theseas Asserted BoosTexter Classifier runs.4 EvaluationWe evaluate our classifiers on both the plain textof the reports and on text expanded with assertedNPs.
We present results in terms of micro-averaged precision, recall, and F1-measure(?zg?r et al 2005).
We check the significance ofclassifier performance differences at ?=0.10.
Weapply a two-tailed Z test, with Z = ?1.645.5 Results and DiscussionTable 3 and Table 4 show our systems?
perform-ances.
We predict ICD-9-CM codes for each ofthe 976 CMC test reports.
We predict whether ornot each of 16 diseases is present in the patientfor each of the 501 i2b2 test set reports.Negative Reports Positive ReportsRunPreci-sionRe-callF1-Meas-urePreci-sionRe-callF1-MeasureCMC Base 0.991 0.993 0.992 0.717 0.664 0.690CMC Asserted 0.991 0.992 0.992 0.712 0.668 0.690i2b2 Base 0.905 0.886 0.896 0.612 0.660 0.635i2b2 Asserted 0.904 0.890 0.897 0.618 0.651 0.634Table 3 - Lucene Classifier?s Performance.25The Asserted Lucene and BoosTexter Classi-fier runs show no significant difference in per-formance from their Base runs on either corpus.These results indicate that asserted noun phrasesdo not contribute to the document-level classifi-cation of our medical reports5.1 Contribution of Asserted Noun PhrasesThrough analysis of the Base and Asserted runs,we find enough similarities in the text of thetraining and test reports for a given class to allowour ML classifiers to correctly predict the labelswithout needing to identify the polarity of theassertions made on individual NPs.
For example,for the CMC target report 97729923:5-year-9-month - old femalewith two month history ofcough.
Evaluate for pneumonia.No pneumonia.the Base Lucene Classifier retrieves report97653364:Two - year-old female withcough off and on for a month(report states RSV nasalwash).No radiographic features ofpneumonia.which allows the system to classify the targetreport with the ICD-9-CM code for cough.
Whileidentifying the polarity of the assertions forpneumonia strengthens the evidence for coughand not pneumonia, it cannot further improve thealready correct document-level classification.These unenhanced assertions do not stand in theway of correct classification by our systems.5.2  Approach, Data, and TaskHand-crafted rule-based approaches usuallyencode the most salient information that the ex-perts would find useful in classification andwould therefore benefit from explicit assertionclassification subsystems, e.g., Goldstein et al,(2007).
On the other hand, ML approaches havethe ability to identify previously undetected pat-terns in data (Mitchell et al 1990).
This enablesML approaches to find patterns that may not beobvious to experts, while still performing correctclassification.
Therefore, the contribution of as-serted NPs appears to be limited when applied toML approaches to document-level classificationof medical reports.
This is not to say that an MLapproach to document-level classification willnever benefit from identifying the polarity ofNPs; only that on our data we find no improve-ment.Negative Reports Positive ReportsRunPreci-sionRe-callF1-MeasurePreci-sionRe-callF1-MeasureBase 0.993 0.995 0.994 0.812 0.747 0.778CMCuni-gram Asserted 0.993 0.996 0.995 0.837 0.767 0.800Base 0.995 0.996 0.996 0.865 0.812 0.838CMCn-gram Asserted 0.995 0.996 0.996 0.866 0.812 0.839Base 0.970 0.973 0.917 0.902 0.889 0.895i2b2uni-gram Asserted 0.970 0.975 0.973 0.908 0.891 0.899Base 0.971 0.976 0.974 0.911 0.895 0.903i2b2n-gram Asserted 0.974 0.977 0.975 0.914 0.903 0.908Table 4 - BoosTexter Classifier?s Performance.The CMC and i2b2 data sets can each be de-scribed as being homogenous; they come from arelatively small communities and limited geo-graphic areas.
In these data, variation in vocabu-lary that might arise from the use of regional ex-pressions would be limited.
This would be espe-cially true for the CMC data since it comes froma single medical department at a single hospital.It would not be surprising for colleagues in agiven department who work together for a periodof time to adopt similar writing styles and to em-ploy consistent terminologies (Suchan 1995).Our task is one of multi-label document-levelclassification.
Working at the document level,each negative and speculative assertion wouldplay only a small role in predicting class labels.The homogeneity of the text in our data sets,and the task of document-level classification mayhave been factors in our results.
Future researchshould examine how the characteristics of thedata and the nature of the task affect the role ofassertion classification.6 ConclusionIdentifying the polarity of phrase-level assertionsin document-level classification of medical re-ports may not always be necessary.
The specifictask and approach applied, along with the charac-teristics of the corpus under study, should beconsidered when deciding the appropriateness ofassertion classification.
The results of this studyshow that on our data and task, identifying thepolarity of the assertions made on noun phrasesdoes not improve machine learning approachesto multi-label document-level classification ofmedical reports.26ReferencesKyle H. Ambert and Aaron M. Cohen.
2009.
A Sys-tem for Classifying Disease Comorbidity Statusfrom Medical Discharge Summaries Using Auto-mated Hotspot and Negated Concept Detection.Journal of the American Medical Informatics As-sociation 16(4):590-95.Alan R. Aronson.
2001.
Effective Mapping of Bio-medical Text to the UMLS Metathesaurus: TheMetamap Program.
Proceedings of the AMIA sym-posium.
17-21.Mordechai Averbuch, Tom H. Karson, BenjaminBen-Ami, Oded Maimon, and Lior Rokach.
2004.Context-Sensitive Medical Information Retrieval.Medinfo.
MEDINFO 11(Pt 1):282-86.Wendy W. Chapman, Will Bridewell, Paul Hanbury,Gregory F. Cooper, and Bruce G. Buchanan.
2001.A Simple Algorithm for Identifying Negated Find-ings and Diseases in Discharge Summaries.
Jour-nal of Biomedical Informatics 34(5):301-10.Thomas M. Cover and Peter E. Hart.
1967.
NearestNeighbor Pattern Classification.
IEEE Transac-tions on Information Theory 13(1):21-27.Marcelo Fiszman, Wendy W. Chapman, DominikAronsky, and R. Scott Evans.
2000.
Automatic De-tection of Acute Bacterial Pneumonia from ChestX-Ray Reports.
Journal of the American MedicalInformatics Association 7:593-604.Ira Goldstein, Anna Arzumtsyan, and ?zlem Uzuner.2007.
Three Approaches to Automatic Assignmentof ICD-9-CM Codes to Radiology Reports.
Pro-ceedings of the AMIA symposium.
279-83.Otis Gospodneti?
and Erik Hatcher.
2005.
Lucene inAction.
Greenwich, CT: Manning.Henk Harkema, John N. Dowling, Tyler Thornblade,and Wendy W. Chapman.
2009.
Context: An Algo-rithm for Determining Negation, Experiencer, andTemporal Status from Clinical Reports.
Journal OfBiomedical Informatics 42(5):839-51.Jung-Jae Kim and Jong C. Park.
2006.
ExtractingContrastive Information from Negation Patterns inBiomedical Literature.
ACM Transactions on AsianLanguage Information Processing (TALIP)5(1):44-60.Tom Mitchell, Bruce Buchanan, Gerald DeJong,Thomas Dietterich, Paul Rosenbloom, and AlexWaibel.
1990.
Machine Learning.
Annual Reviewof Computer Science.
Vol.4.
Eds.
Joseph  F. Traub,Barbara J. Grosz, Butler W. Lampson and Nils J.Nilsson.
Palo Alto, CA: Annual Reviews.Pradeep G. Mutalik, Aniruddha Deshpande, andPrakash M. Nadkarni.
2001.
Use of General-Purpose Negation Detection to Augment ConceptIndexing of Medical Documents: A QuantitativeStudy Using the UMLS.
Journal of the AmericanMedical Informatics Association 8(6):598-609.National Center for Health Statistics.
2010.
ICD -ICD-9-CM - International Classification of Dis-eases, Ninth Revision, Clinical Modification.
Ac-cessed: May 1, 2010.<www.cdc.gov/nchs/icd/icd9cm.htm>.Arzucan ?zg?r, Levent ?zg?r, and Tunga G?ng?r.2005.
Text Categorization with Class-Based andCorpus-Based Keyword Selection.
ISCIS 2005.Eds.
P?nar Yolum, Tunga G?ng?r, Fikret G?rgenand Can ?zturan.
Istanbul, Turkey: Springer.
606-15 of Lecture Notes in Computer Science.John P. Pestian, Christopher Brew, PawelMatykiewicz, D. J. Hovermale, Neil Johnson, K.Bretonnel Cohen, and W?odzis?aw Duch.
2007.
AShared Task Involving Multi-Label Classificationof Clinical Free Text.
ACL:BioNLP.
Prague: Asso-ciation for Computational Linguistics.
97-104.R.
Bharat Rao, Sathyakama Sandilya, Radu StefanNiculescu, Colin Germond, and Harsha Rao.
2003.Clinical and Financial Outcomes Analysis with Ex-isting Hospital Patient Records.
Proceedings of theNinth ACM SIGKDD International Conference onKnowledge Discovery and Data Mining: ACMPress New York, NY, USA.
416-25.Robert E. Schapire and Yoram Singer.
2000.
Boostex-ter: A Boosting-Based System for Text Categoriza-tion.
Machine Learning 39(2):135-68.Alan R. Shapiro.
2004.
Taming Variability in FreeText: Application to Health Surveillance.
MMWR.Morbidity And Mortality Weekly Report 53Suppl:95-100.Tawanda Carleton Sibanda, T. He, Peter Szolovits,and ?zlem Uzuner.
2006.
Syntactically-InformedSemantic Category Recognition in DischargeSummaries.
Proceedings of the AMIA symposium.714-8.Stephan Spat, Bruno Cadonna, Ivo Rakovac, ChristianG?tl, Hubert Leitner, G?nther Stark, and PeterBeck.
2008.
Enhanced Information Retrieval fromNarrative German-Language Clinical Text Docu-ments Using Automated Document Classification.Studies In Health Technology And Informatics136:473-78.Jim Suchan.
1995.
The Influence of OrganizationalMetaphors on Writers' Communication Roles andStylistic Choices.
Journal of Business Communica-tion 32(1):7-29.?zlem Uzuner.
2008.
Second I2b2 Workshop onNatural Language Processing Challenges for Clini-cal Records.
Proceedings of the AMIA sympo-sium:1252-53.27
