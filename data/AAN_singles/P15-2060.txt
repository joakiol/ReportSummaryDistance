Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 365?371,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsEvent Detection and Domain Adaptationwith Convolutional Neural NetworksThien Huu NguyenComputer Science DepartmentNew York UniversityNew York, NY 10003 USAthien@cs.nyu.eduRalph GrishmanComputer Science DepartmentNew York UniversityNew York, NY 10003 USAgrishman@cs.nyu.eduAbstractWe study the event detection problem us-ing convolutional neural networks (CNNs)that overcome the two fundamental limi-tations of the traditional feature-based ap-proaches to this task: complicated featureengineering for rich feature sets and er-ror propagation from the preceding stageswhich generate these features.
The experi-mental results show that the CNNs outper-form the best reported feature-based sys-tems in the general setting as well as thedomain adaptation setting without resort-ing to extensive external resources.1 IntroductionWe address the problem of event detection (ED):identifying instances of specified types of eventsin text.
Associated with each event mention is aphrase, the event trigger (most often a single verbor nominalization), which evokes that event.
Ourtask, more precisely stated, involves identifyingevent triggers and classifying them into specifictypes.
For instance, according to the ACE 2005annotation guideline1, in the sentence ?A policeofficer was killed in New Jersey today?, an eventdetection system should be able to recognize theword ?killed?
as a trigger for the event ?Die?.
Thistask is quite challenging, as the same event mightappear in the form of various trigger expressionsand an expression might represent different eventsin different contexts.
ED is a crucial componentin the overall task of event extraction, which alsoinvolves event argument discovery.Recent systems for event extraction have em-ployed either a pipeline architecture with separateclassifiers for trigger and argument labeling (Ji andGrishman, 2008; Gupta and Ji, 2009; Patwardhan1https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-events-guidelines-v5.4.3.pdfand Rilof, 2009; Liao and Grishman, 2011; Mc-Closky et al, 2011; Huang and Riloff, 2012; Liet al, 2013a) or a joint inference architecture thatperforms the two subtasks at the same time to ben-efit from their inter-dependencies (Riedel and Mc-Callum, 2011a; Riedel and McCallum, 2011b; Liet al, 2013b; Venugopal et al, 2014).
Both ap-proaches have coped with the ED task by elabo-rately hand-designing a large set of features (fea-ture engineering) and utilizing the existing super-vised natural language processing (NLP) toolkitsand resources (i.e name tagger, parsers, gazetteersetc) to extract these features to be fed into sta-tistical classifiers.
Although this approach hasachieved the top performance (Hong et al, 2011;Li et al, 2013b), it suffers from at least two issues:(i) The choice of features is a manual processand requires linguistic intuition as well as domainexpertise, implying additional studies for new ap-plication domains and limiting the capacity toquickly adapt to these new domains.
(ii) The supervised NLP toolkits and resourcesfor feature extraction might involve errors (eitherdue to the imperfect nature or the performanceloss of the toolkits on new domains (Blitzer et al,2006; Daum?e III, 2007; McClosky et al, 2010)),probably propagated to the final event detector.This paper presents a convolutional neural net-work (LeCun et al, 1988; Kalchbrenner et al,2014) for the ED task that automatically learnsfeatures from sentences, and minimizes the depen-dence on supervised toolkits and resources for fea-tures, thus alleviating the error propagation andimproving the performance for this task.
Dueto the emerging interest of the NLP communityin deep learning recently, CNNs have been stud-ied extensively and applied effectively in vari-ous tasks: semantic parsing (Yih et al, 2014),search query retrieval (Shen et al, 2014), seman-tic matching (Hu et al, 2014), sentence modelingand classification (Kalchbrenner et al, 2014; Kim,365Figure 1: Convolutional Neural Network for Event Detection.2014), name tagging and semantic role labeling(Collobert et al, 2011), relation classification andextraction (Zeng et al, 2014; Nguyen and Grish-man, 2015).
However, to the best of our knowl-edge, this is the first work on event detection viaCNNs so far.First, we evaluate CNNs for ED in the generalsetting and show that CNNs, though not requir-ing complicated feature engineering, can still out-perform the state-of-the-art feature-based meth-ods extensively relying on the other supervisedmodules and manual resources for features.
Sec-ond, we investigate CNNs in a domain adaptation(DA) setting for ED.
We demonstrate that CNNssignificantly outperform the traditional feature-based methods with respect to generalization per-formance across domains due to: (i) their capac-ity to mitigate the error propagation from the pre-processing modules for features, and (ii) the useof word embeddings to induce a more general rep-resentation for trigger candidates.
We believe thatthis is also the first research on domain adaptationusing CNNs.2 ModelWe formalize the event detection problem as amulti-class classification problem.
Given a sen-tence, for every token in that sentence, we want topredict if the current token is an event trigger: i.e,does it express some event in the pre-defined eventset or not (Li et al, 2013b)?
The current tokenalong with its context in the sentence constitutean event trigger candidate or an example in multi-class classification terms.
In order to prepare forthe CNNs, we limit the context to a fixed windowsize by trimming longer sentences and paddingshorter sentences with a special token when nec-essary.
Let 2w + 1 be the fixed window size,and x = [x?w, x?w+1, .
.
.
, x0, .
.
.
, xw?1, xw] besome trigger candidate where the current token ispositioned in the middle of the window (token x0).Before entering the CNNs, each token xiis trans-formed into a real-valued vector by looking up thefollowing embedding tables to capture differentcharacteristics of the token:- Word Embedding Table (initialized by somepre-trained word embeddings): to capture the hid-den semantic and syntactic properties of the tokens(Collobert and Weston, 2008; Turian et al, 2010).- Position Embedding Table: to embed the rel-ative distance i of the token xito the current tokenx0.
In practice, we initialize this table randomly.- Entity Type Embedding Table: If we furtherknow the entity mentions and their entity types2in the sentence, we can also capture this informa-tion for each token by looking up the entity typeembedding table (initialized randomly) using theentity type associated with each token.
We em-ploy the BIO annotation scheme to assign entitytype labels to each token in the trigger candidate2For convenience, when mentioning entities in this paper,we always include ACE timex and values.366using the heads of the entity mentions.For each token xi, the vectors obtained from thethree look-ups above are concatenated into a sin-gle vector xito represent the token.
As a result,the original event trigger x is transformed into amatrix x = [x?w,x?w+1, .
.
.
,x0, .
.
.
,xw?1,xw]of size mt?
(2w+1) (mtis the dimensionality ofthe concatenated vectors of the tokens).The matrix representation x is then passedthrough a convolution layer, a max pooling layerand a softmax at the end to perform classifica-tion (like (Kim, 2014; Kalchbrenner et al, 2014)).In the convolution layer, we have a set of featuremaps (filters) {f1, f2, .
.
.
, fn} for the convolutionoperation.
Each feature map ficorresponds tosome window size k and can be essentially seenas a weight matrix of size mt?
k. Figure 1 illus-trates the proposed CNN.The gradients are computed using back-propagation; regularization is implemented by adropout (Kim, 2014; Hinton et al, 2012), andtraining is done via stochastic gradient descentwith shuffled mini-batches and the AdaDelta up-date rule (Zeiler, 2012; Kim, 2014).
During thetraining, we also optimize the weights of the threeembedding tables at the same time to reach an ef-fective state (Kim, 2014).3 Experiments3.1 Dataset, Hyperparameters and ResourcesAs the benefit of multiple window sizes in the con-volution layer has been demonstrated in the previ-ous work on sentence modeling (Kalchbrenner etal., 2014; Kim, 2014), in the experiments below,we use window sizes in the set {2, 3, 4, 5} to gen-erate feature maps.
We utilize 150 feature mapsfor each window size in this set.
The window sizefor triggers is set to 31 while the dimensionality ofthe position embeddings and entity type embed-dings is 503.We inherit the values for the other pa-rameters from Kim (2014), i.e, the dropout rate?
= 0.5, the mini-batch size = 50, the hyperpa-rameter for the l2norms = 3.
Finally, we em-ploy the pre-trained word embeddings word2vecwith 300 dimensions from Mikolov et al (2013)for initialization.We evaluate the presented CNN over the ACE2005 corpus.
For comparison purposes, we uti-lize the same test set with 40 newswire articles3These values are chosen for their best performance onthe development data.
(672 sentences), the same development set with30 other documents (836 sentences) and the sametraining set with the remaning 529 documents(14,849 sentences) as the previous studies on thisdataset (Ji and Grishman, 2008; Liao and Grish-man, 2010; Li et al, 2013b).
The ACE 2005 cor-pus has 33 event subtypes that, along with oneclass ?None?
for the non-trigger tokens, consti-tutes a 34-class classification problem.In order to evaluate the effectiveness of the posi-tion embeddings and the entity type embeddings,Table 1 reports the performance of the proposedCNN on the development set when these embed-dings are either included or excluded from the sys-tems.
With the large margins of performance, it isvery clear from the table that the position embed-dings are crucial while the entity embeddings arealso very useful for CNNs on ED.Systems P R F-Entity Types -Position 16.8 12.0 14.0+Position 75.0 63.0 68.5+Entity Types -Position 17.0 15.0 15.9+Position 75.6 66.4 70.7Table 1: Performance on the Development Set.For the experiments below, we examine theCNNs in two scenarios: excluding the entity typeembeddings (CNN1) and including the entity typeembeddings (CNN2).
We always use position em-beddings in these two scenarios.3.2 Performance ComparisonThe state-of-the-art systems for event detection onthe ACE 2005 dataset have followed the traditionalfeature-based approach with rich hand-designedfeature sets, and statistical classifiers such as Max-Ent and perceptron for structured prediction in ajoint architecture (Hong et al, 2011; Li et al,2013b).
In this section, we compare the proposedCNNs with these state-of-the-art systems on theblind test set.
Table 2 presents the overall per-formance of the systems with gold-standard entitymention and type information4.As we can see from the table, considering thesystems that only use sentence level information,CNN1 significantly outperforms the MaxEnt clas-sifier as well as the joint beam search with localfeatures from Li et al (2013b) (an improvementof 1.6% in F1 score), and performs comparably4Entity mentions and types are used to introduce morefeatures into the systems.367Methods P R FSentence-level in Hong et al(2011)67.6 53.5 59.7MaxEnt with local features inLi et al (2013b)74.5 59.1 65.9Joint beam search with localfeatures in Li et al (2013b)73.7 59.3 65.7Joint beam search with localand global features in Li et al(2013b)73.7 62.3 67.5Cross-entity in Hong et al(2011) ?72.9 64.3 68.3CNN1: CNN without anyexternal features71.9 63.8 67.6CNN2: CNN augmented withentity types71.8 66.4 69.0Table 2: Performance with Gold-Standard Entity Mentionsand Types.
?
beyond sentence level.with the joint beam search approach using both lo-cal and global features (Li et al, 2013b).
This isremarkable since CNN1 does not require any ex-ternal features5, in contrast to the other feature-based systems that extensively rely on such exter-nal features to perform well.
More interestingly,when the entity type information is incorporatedinto CNN1, we obtain CNN2 that still only needssentence level information but achieves the state-of-the-art performance for this task (an improve-ment of 1.5% over the best system with only sen-tence level information (Li et al, 2013b)).Except for CNN1, all the systems reported inTable 2 employ the gold-standard (perfect) entitiesmentions and types from manual annotation whichmight not be available in reality.
Table 3 comparesthe performance of CNN1 and the feature-basedsystems in a more realistic setting, where entitymentions and types are acquired from an auto-matic high-performing name tagger and informa-tion extraction system (Li et al, 2013b).
Note thatCNN1 is eligible for this comparison as it does notutilize any external features, thus avoiding usageof the name tagger and the information extractionsystem to identify entity mentions and types.3.3 Domain Adaptation ExperimentIn this section, we aim to further compare the pro-posed CNNs with the feature-based systems underthe domain adaptation setting for event detection.The ultimate goal of domain adaptation re-search is to develop techniques taking training5External features are the features generated from the su-pervised NLP modules and manual resources such as parsers,name tagger, entity mention extractors (either automatic ormanual), gazetteers etc.Methods FSentence level in Ji and Grishman (2008)59.7MaxEnt with local features in Li et al (2013b)64.7Joint beam search with local features in Li etal.
(2013b)63.7Joint beam search with local and globalfeatures in Li et al (2013b)65.6CNN1: CNN without any external features67.6Table 3: Performance with Predicted Entity Mentions andTypes.data in some source domain and learning modelsthat can work well on target domains.
The targetdomains are supposed to be so dissimilar from thesource domain that the learning techniques wouldsuffer from a significant performance loss whentrained on the source domain and applied to thetarget domains.
To make it clear, we address theunsupervised DA problem in this section, i.e notraining data in the target domains (Blitzer et al,2006; Plank and Moschitti, 2013).
The fundamen-tal reason for the performance loss of the feature-based systems on the target domains is twofold:(i) The behavioral changes of features acrossdomains: As domains differ, some features mightbe informative in the source domain but becomeless relevant in the target domains and vice versa.
(ii) The propagated errors of the pre-processingtoolkits for lower-level tasks (POS tagging, nametagging, parsing etc) to extract features: Thesepre-processing toolkits are also known to degradewhen shifted to target domains (Blitzer et al,2006; Daum?e III, 2007; McClosky et al, 2010),introducing noisy features into the systems forhigher-level tasks in the target domains and even-tually impairing the performance of these higher-level systems on the target domains.For ED, we postulate that CNNs are more use-ful than the feature-based approach for DA for tworeasons.
First, rather than relying on the symbolicand concrete forms (i.e words, types etc) to con-struct features as the traditional feature-based sys-tems (Ji and Grishman, 2008; Li et al, 2013b)do, CNNs automatically induce their features fromword embeddings, the general distributed repre-sentation of words that is shared across domains.This helps CNNs mitigate the lexical sparsity,learn more general and effective feature represen-tation for trigger candidates, and thus bridge thegap between domains.
Second, as CNNs mini-mize the reliance on the supervised pre-processingtoolkits for features, they can alleviate the error368System In-domain(bn+nw) bc cts wlP R F P R F P R F P R FMaxEnt 74.5 59.4 66.0 70.1 54.5 61.3 66.4 49.9 56.9 59.4 34.9 43.9Joint beam search in Li et al (2013b)Joint+Local 73.5 62.7 67.7 70.3 57.2 63.1 64.9 50.8 57.0 59.5 38.4 46.7Joint+Local+Global 72.9 63.2 67.7 68.8 57.5 62.6 64.5 52.3 57.7 56.4 38.5 45.7CNN1 70.9 64.0 67.3 71.0 61.9 66.1?
64.0 55.0 59.1 53.2 38.4 44.6CNN2 69.2 67.0 68.0 70.2 65.2 67.6?
68.3 58.2 62.8?
54.8 42.0 47.5Table 4: In-domain (first column) and Out-of-domain Performance (columns two to four).
Cells marked with ?designateCNN models that significantly outperform (p < 0.05) all the reported feature-based methods on the specified domain.propagation and be more robust to domain shifts.3.3.1 DatasetWe also do the experiments in this part over theACE 2005 dataset but focus more on the differencebetween domains.
The ACE 2005 corpus comeswith 6 different domains: broadcast conversation(bc), broadcast news (bn), telephone conversation(cts), newswire (nw), usenet (un) and webblogs(wl).
Following the common practice of domainadaptation research on this dataset (Plank andMoschitti, 2013; Nguyen and Grishman, 2014),we use news (the union of bn and nw) as thesource domain and bc, cts, wl as three differenttarget domains.
We take half of bc as the devel-opment set and use the remaining data for testing.We note that the distribution of event subtypes andthe vocabularies of the source and target domainsare quite different (Plank and Moschitti, 2013).3.3.2 Domain Adaptation ResultsTable 4 presents the performance of five systems:the MaxEnt classifier with the local features fromLi et al (2013b) (called MaxEnt); the state-of-the-art joint beam search systems with: (i) only localfeatures (called Joint+Local); and (ii) both localand global features (called Joint+Local+Global)in Li et al (2013b) (the baseline systems); CNN1and CNN2 via 5-fold cross validation.
For eachsystem, we train a model on the training set of thesource domain and report the performance of thismodel on the test set of the source domain (in-domain performance) as well as the performanceof the model on the three target domains bc, ctsand wl (out-of-domain performance)6.The main conclusions from the table include:(i) The baseline systems MaxEnt, Joint+Local,Joint+Local+Global achieve high performance onthe source domain, but degrade dramatically on6The performance of the feature-based systems MaxEnt,Joint+Local and Joint+Local+Global are obtained from theactual systems in Li et al (2013b).the target domains due to the domain shifts.
(ii)Comparing CNN1 and the baseline systems, wesee that CNN1 performs comparably with thebaseline systems on the source domain (in-domainperformance) (as expected), substantially outper-form the baseline systems on two of the three tar-get domains (i.e, bc and cts), and is only less ef-fective than the joint beam search approach onthe wl domain; (iii) Finally and most importantly,we consistently achieve the best adaptation perfor-mance across all the target domains with CNN2by only introducing entity type information intoCNN1.
In fact, CNN2 significantly outperformsthe feature-based systems with p < 0.05 and largemargins of about 5.0% on the domains bc and cts,clearly confirming our argument in Section 3.3 andtestifying to the benefits of CNNs on DA for ED.4 ConclusionWe present a CNN for event detection that auto-matically learns effective feature representationsfrom pre-trained word embeddings, position em-beddings as well as entity type embeddings andreduces the error propagation.
We conducted ex-periments to compare the proposed CNN with thestate-of-the-art feature-based systems in both thegeneral setting and the domain adaptation setting.The experimental results demonstrate the effec-tiveness as well as the robustness across domainsof the CNN.
In the future, our plans include: (i)to explore the joint approaches for event extrac-tion with CNNs; (ii) and to investigate other neuralnetwork architectures for information extraction.AcknowledgmentsWe would like to thank Qi Li for providing the per-formance of the feature-based systems on the do-main adaptation experiments.
Thank you to YifanHe, Kai Cao, and Xiang Li for useful discussionson the task as well as the anonymous reviewers fortheir valuable feedback.369ReferencesJohn Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain Adaptation with Structural Corre-spondence Learning.
In Proceedings of EMNLP.Ronan Collobert and Jason Weston.
2008.
A Uni-fied Architecture for Natural Language Processing:Deep Neural Networks with Multitask Learning.
InProceedings of ICML.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu and Pavel Kuksa.2011.
Natural Language Processing (Almost) fromScratch.
Journal of Machine Learning Research12:24932537.Hal Daum?e III.
2007.
Frustratingly Easy DomainAdaptation.
In Proceedings of ACL.Prashant Gupta and Heng Ji.
2009.
Predicting Un-known Time Arguments Based on Cross-Event Prop-agation.
In Proceedings of ACL-IJCNLP.Geoffrey E. Hinton, Nitish Srivastava, AlexKrizhevsky, Ilya Sutskever, and Ruslan Salakhut-dinov.
2012.
Improving Neural Networks byPreventing Co-Adaptation of Feature Detectors.CoRR, abs/1207.0580.Yu Hong, Jianfeng Zhang, Bin Ma, Jian-Min Yao,Guodong Zhou, and Qiaoming Zhu.
2011.
UsingCross-entity Inference to Improve Event Extraction.In Proceedings of ACL.Baotian Hu, Zhengdong Lu, Hang Li, Qingcai Chen.2014.
Convolutional Neural Network Architecturesfor Matching Natural Language Sentences.
In Pro-ceedings of NIPS.Ruihong Huang and Ellen Riloff.
2012.
Modeling Tex-tual Cohesion for Event Extraction.
In Proceedingsof AAAI.Heng Ji and Ralph Grishman.
2008.
Refining EventExtraction through Cross-Document Inference.
InProceedings of ACL.Nal Kalchbrenner, Edward Grefenstette and Phil Blun-som.
2014.
A Convolutional Neural Network forModeling Sentences.
In Proceedings of ACL.Yoon Kim.
2014.
Convolutional Neural Networks forSentence Classification.
In Proceedings of EMNLP.Yann LeCun, L?eon Bottou, Yoshua Bengio and PatrickHaffner.
1988.
Gradient-based Learning Applied toDocument Recognition.
In Proceedings of the IEEE,86(11):22782324.Peifeng Li, Qiaoming Zhu, and Guodong Zhou.
2013a.Argument Inference from Relevant Event Mentionsin Chinese Argument Extraction.
In Proceedings ofACL.Qi Li, Heng Ji, and Liang Huang.
2013b.
Joint EventExtraction via Structured Prediction with GlobalFeatures.
In Proceedings of ACL.Shasha Liao and Ralph Grishman.
2010.
Using Doc-ument Level Cross-event Inference to Improve EventExtraction.
In Proceedings of ACL.Shasha Liao and Ralph Grishman.
2011.
AcquiringTopic Features to Improve Event Extraction: in Pre-selected and Balanced Collections.
In ProceedingsRANLP.David McClosky, Eugene Charniak, and Mark John-son.
2010.
Automatic Domain Adaptation for Pars-ing.
In Proceedings of HLT-NAACL.David McClosky, Mihai Surdeanu, and Chris Manning.2011.
Event Extraction as Dependency Parsing.
InProceedings of ACL-HLT.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-rado, and Jeffrey Dean.
2013.
Distributed Repre-sentations of Words and Phrases and their Compo-sitionality.
In Proceedings of NIPS.Thien Huu Nguyen and Ralph Grishman.
2014.
Em-ploying Word Representations and Regularizationfor Domain Adaptation of Relation Extraction.
InProceedings of ACL.Thien Huu Nguyen and Ralph Grishman.
2015.
Re-lation Extraction: Perspective from ConvolutionalNeural Networks.
In Proceedings of the NAACLWorkshop on Vector Space Modeling for NLP(VSM).Siddharth Patwardhan and Ellen Rilof.
2009.
A Uni-fied Model of Phrasal and Sentential Evidence forInformation Extraction.
In Proceedings of EMNLP.Barbara Plank and Alessandro Moschitti.
2013.
Em-bedding Semantic Similarity in Tree Kernels for Do-main Adaptation of Relation Extraction.
In Proceed-ings of ACL.Sebastian Riedel and Andrew McCallum.
2011.
Fastand Robust Joint Models for Biomedical Event Ex-traction.
In Proceedings of EMNLP.Sebastian Riedel and Andrew McCallum.
2011.
Ro-bust Biomedical Event Extraction with Dual Decom-position and Minimal Domain Adaptation.
In Pro-ceedings of the BioNLP Shared Task 2011 Work-shop.Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng andGr?egoire Mesnil.
2014.
Learning Semantic Repre-sentations Using Convolutional Neural Networks forWeb Search.
In Proceedings of WWW.Joseph Turian, Lev Ratinov, and Yoshua Bengio.2010.
Word Representations: A Simple and GeneralMethod for Semi-supervised Learning.
In Proceed-ings of ACL.Deepak Venugopal, Chen Chen, Vibhav Gogate andVincent Ng.
2014.
Relieving the ComputationalBottleneck: Joint Inference for Event Extractionwith High-Dimensional Features.
In Proceedings ofEMNLP.370Wen-tau Yih, Xiaodong He, and Christopher Meek.2014.
Semantic Parsing for Single-Relation Ques-tion Answering.
In Proceedings of ACL.Matthew D. Zeiler.
2012.
ADADELTA: An AdaptiveLearning Rate Method.
CoRR, abs/1212.5701.Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhouand Jun Zhao.
2014.
Relation Classification viaConvolutional Deep Neural Network.
In Proceed-ings of COLING.371
