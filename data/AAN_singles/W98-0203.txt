Core ference  as the  Foundat ions  for L ink Ana lys i s  over Free TextDatabasesBreck BaldwinInstitute for Research in Cognitive ScienceUniversity of Pennsylvania3401 Walnut St. 400CPhiladelphia, PA 19104.
USAPhone: (215) 898-0329Email: breckQlinc.cis.upenn.eduAmit  BaggaBox 90129Dept.
of Computer ScienceDuke UniversityDurham, NC 27708-0129.
USAPhone: (919) 660-6507Email: amit@cs.duke.eduAbstractCoreference annotated data has the potential to sub-stantially increase the domain over which link anal-ysis can be applied.
We have developed corefer-ence technologies which relate individuals and eventswithin and across text documents.
This in turnleverages the first step in mapping the informationin those texts into a more data-base like format suit-able for visualization with link driven software.1 Introduct ionCoreference is in some sense nature's own hyperlink.For example, the phrase 'Alan Turing', 'the fatherof modern computer science', or 'he' can refer to thesame individual in the world.
The communicativefunction of coreference is the ability to link informa-tion about entities across many sentences and doc-uments.
In data base terms, individual sentencesprovide entry records which are organized aroundentities, and the method of indicating which entitythe record is about is coreference.Link analysis is well suited to visualizing largestructured atabases where generalizations emergefrom macro observations of relatedness.
Unfortu-nately, free text is not sufficiently organized for sim-ilar fidelity observations.
Coreference in its simplestform has the potential to organize free text suffi-ciently to greatly expand the domain over which linkanalysis can be fruitfully applied.Below we will illustrate the kinds of coreferencethat we currently annotate in the CAMP softwaresystem and give an idea of our system performance.Then we will illustrate what kinds of observationscould be pulled via visualization from coreferenceannotated ocument collections.2 CAMP Natural  LanguageProcessing SoftwareThe foundation of our system is the CAMP NLPsystem.
This system provides an integrated envi-ronment in which one can access many levels of lin-guistic information as well as world knowledge.
Itsmain components include: named entity recognition,tokenization, sentence detection, part-of-speech tag-ging, morphological nalysis, parsing, argument de-tection, and coreference r solution as described be-low.
Many of the techniques used for these tasks per-form at or near the state of the art and are describedin more depth in (Wacholder 97), (Collins 96),(Baldwin 95), (Reynar 97), (Baldwin 97), (Bagga,98b).3 With in  Document CoreferenceWe have been developing the within document coref-erence component of CAMP since 1995 when thesystem was developed to participate in the SixthMessage Understanding Conference (MUC-6) coref-erence task.
Below we will illustrate the classes ofcoreference that the system annotates.Coreference breaks down into several readily iden-tified areas based on the form of the phrase beingresolved and the method of calculating coreference.We will proceed in the approximate ordering of thesystems execution of components.
A more detailedanalysis of the classes of coreference an be found in(Bagga, 98a).3.1 Highly Syntact ic  CoreferenceThere are several readily identified syntactic on-structions that reliably indicate coreference.
Firstare appositive relations as holds between 'JohnSmith' and ~chairman of General Electric' in:John Smith, chairman of General Electric,resigned yesterday.Identifying this class of coreference r quires somesyntactic knowledge of the text and property anal-ysis of the individual phrases to avoid finding coref-erence in examples like:John Smith, 47, resigned yesterday.Smith, Jones, Woodhouse and Fife an-nounced a new partner.To avoid these sorts of errors we have a mutual exclu-sion test that applies to such positings of coreferenceto prevent non-sensical nnotations.Another class of highly syntactic oreference existsin the form of predicate nominal constructions as19between ' John'  and 'the finest juggler in the world'in:John is the finest juggler in the world.Like the appositive case, mutual exclusion tests arerequired to prevent incorrect resolutions as in:John is tall.They are blue.These classes of highly syntactic coreference canplay a very important role in bridging phrases thatwe would normally be unable to relate.
For example,it is unlikely that our software would be able to relatethe same noun phrases in a text likeThe finest juggler in the world visitedPhiladelphia this week.
John Smithpleased crowds every night in the Annen-berg theater.This is because we do not have sufficiently sophis-ticated knowledge sources to determine that jug-glers are very likely to be in the business of pleasingcrowds.
But the recognition of the predicate nomi-nal will allow us to connect a chain of ' John Smith','Mr.
Smith', 'he' with a chain of 'the finest jugglerin the world', 'the juggler' and 'a juggling expert'.3.2 P roper  Noun Core ferenceNames of people, places, products and companiesare referred to in many different variations.
In jour-nalistic prose there will be a full name of an entity,and throughout the rest of the article there will beellided references to the same entity.
Some namevariations are:?
Mr. James Dabah <- James <- Jim <- Dabah?
Minnesota Mining and Manufacturing <- 3MCorp.
<- 3M?
Washington D.C. <- WASHINGTON <- Wash-ington <- D.C. <- Wash.?
New York <- New York City <- NYC <- N.Y.C.This class of coreference forms a solid foundationover which we resolve the remaining coreference inthe document.
One reason for this is that we learnimportant properties about the phrases in virtue ofthe coreference r solution.
For example, we may notknow whether 'Dabah'  is a person name, male name,female name, company or place, but upon resolutionwith 'Mr.
James Dabah'  we then know that it refersto a male person.We resolve such coreferences with partial stringmatching subroutines coupled with lists of hon-orifics, corporate designators and acronyms.
A sub-stantial problem in resolving these names is avoidingovergeneration like relating 'Washington' the placewith the name 'Consuela Washington'.
We controlthe string matching with a range of salience func-tions and restrictions of the kinds of partial stringmatches we are willing to tolerate.3.3 Common Noun CoreferenceA very challenging area of coreference annotationinvolves coreference between common nouns like 'ashady stock deal' and 'the deal'.
Fundamentally theproblem is that very conservative approaches to ex-act and partial string matches overgenerate badly.Some examples of actual chains are:?
his dad's trophies <- those trophies?
those words <- the last words?
the risk <- the potential risk?
its accident investigation <- the investigationWe have adopted a range of matching heuristicsand salience strategies to try and recognize a small,but accurate, subset of these coreferences.3.4 Pronoun CoreferenceThe pronominal resolution component of the systemis perhaps the most advanced of all the components.It features a sophisticated salience model designedto produce high accuracy coreference in highly am-biguous texts.
It  is capable of noticing ambiguityin text, and will fail to resolve pronouns in such cir-cumstances.
For example the system will not resolve'he' in the following example:Earl and Ted were working together whensuddenly he fell into the threshing machine.We resolve pronouns like 'they', 'it', 'he', 'hers','themselves' to proper nouns, common nouns andother pronouns.
Depending on the genre of databeing processed, this component can resolve 60-90%of the pronouns in a text with very high accuracy.3.5 The  Overa l l  Nexus  of  Core ference  in aDocumentOnce all the coreference in a document has beencomputed, we have a good approximation of whichsentences are strongly related to other sentences inthe document by counting the number of corefer-ence links between the sentences.
We know whichentities are mentioned most often, and what otherentities are involved in the same sentences or para-graphs.
This sort of information has been used togenerate very effective summaries of documents andas a foundation for a simple visualization interfaceto texts.4 Cross  Document  Core ferenceCross-document coreference occurs when the sameperson, place, event, or concept is discussed in morethan one text source.
Figure 1 shows the archi-tecture of the cross-document module of CAMP.20Coreference Chains for doc.O ICross-Document Coreference ChainsiIJ I VSM-I Disambiguate~ summary.O1 1 J" ~ J  summary.nn I ~Figure 1: Architecture of the Cross-Document Coreference SystemJohn Perry, of lVeston Golf Club, an-nounced his resignation yesterday.
He wasthe President of the Massachusetts GolfAssociation.
During his two years in of-rice, Perry guided the MGA into a closerrelationship with the Women's Golf Asso-ciation of Massachusetts.Figure 2: Extract from doc.36,'!
@ ,IFigure 3: Coreference Chains for doc.36This module takes as input the coreference chainsproduced by CAMP's within document coreferencemodule.
Details about each of the main steps ofthe cross-document coreference algorithm are givenbelow.?
First, for each article, the within documentcoreference module of CAMP is run on thatarticle.
It produces coreference chains for allthe entities mentioned in the article.
For exam-ple, consider the two extracts in Figures 2 and4.
The coreference hains output by CAMP forthe two extracts are shown in Figures 3 and 5.?
Next, for the coreference hain of interest withineach article (for example, the coreference hainthat contains "John Perry"), the Sentence Ex-tractor module extracts all the sentences thatcontain the noun phrases which form the coref-erence chain.
In other words, the SentenceEx-tractor module produces a "summary" of the ar-ticle with respect to the entity of interest.
Thesesun~maries are a special case of the query sensi-tive techniques being developed at Penn usingCAMP.
Therefore, for doc.36 (Figure 2), sinceat least one of the three noun phrases ("JohnPerry," "he," and "Perry") in the coreferencechain of interest appears in each of the threesentences in the extract, the summary producedby SentenceExtractor is the extract itself.
Onthe other hand, the summary produced by Sen-tenceExtractor for the coreference chain of in-terest in doc.38 is only the first sentence of theextract because the only element of the corefer-ence chain appears in this sentence.?
Finally, for each article, the VSM-Disambiguatemodule uses the summary extracted by the Sen-tenceExtractor and computes its similarity with2101iver "Biff" Kelly of Weymouth suc-ceeds John Perry as president of the Mas-sachusetts Golf Association.
"We win havecontinued growth in the future," said Kelly,who will serve for two years.
"There's beena lot of changes and there win be continuedchanges as we head into the year 2000.
"Figure 4: Extract from doc.38I IIIIFigure 5: Coreference Chains for doc.38100908070g 6o~ 5o~.
40{30Precision/Recall vs Threshold~ u r A I g :  Precision o\~,n _ Our AIg:" Recall -~--Atg: F-Measure -~--\] " \ ~."
/ ;~  ~*~ ~'~"  O' "~" O - Q--O- G--O-..E\]-- O--O-.\[~.
_ i:-e/ ",.,,.
c~20'100 I I I I I l 1 1 I0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9ThresholdFigure 7: Precision, Recall, and F-Measure UsingOur Algorithm for the John Smith Data Setthe summaries extracted from each of the otherarticles.
The VSM-Disambiguate module uses astandard vector space model (used widely in in-formation retrieval) (Salton, 89) to compute thesimilarities between the summaries.
Summarieshaving similarity above a certain threshold areconsidered to be regarding the same entity.4.1 Exper iments  and Resu l tsWe tested our cross-document system on two highlyambiguous test sets.
The first set contained 197articles from the 1996 and 1997 editions of theNew York Times, while the second set contained219 articles from the 1997 edition of the New YorkTimes.
The sole criteria for including an article inthe two sets was the presence of a string matchingthe "/ John.
*?Smith/", and the "/resign/" regularexpressions respectively.The goal for the first set was to identify cross-document coreference chains about the same JohnSmith, and the goal for the second set was to identifycross-document coreference chains about the same"resign" event.
The answer keys were manually cre-ated, but the scoring was completely automated.There were 35 different John Smiths in the firstset.
Of these, 24 were involved in chains of size 1.The other 173 articles were regarding the 11 remain-ing John Smiths.
Descriptions of a few of the JohnSmiths are: Chairman and CEO of General Motors,assistant rack coach at UCLA, the legendary ex-plorer, and the main character in Disney's Pocahon-tas, former president of the Labor Party of Britain.In the second set, there were 97 different "resign"events.
Of these, 60 were involved in chains of size1.
The articles were regarding resignations ofseveraldifferent people including Ted Hobart of ABC Corp.,Dick Morris, Speaker Jim Wright, and the possibleresignation of Newt Gingrich.4.2 Scor ing and Resu l tsIn order to score the cross-document coreferencechains output by the system, we had to map thecross-document coreference scoring problem to awithin-document coreference scoring problem.
Thiswas done by creating a meta document consistingof the file names of each of the documents that thesystem was run on.
Assuming that each of the doc-uments in the two data sets was about a single JohnSmith, or about a single "resign" event, the cross-document coreference hains produced by the systemcould now be evaluated by scoring the correspond-ing within-document coreference chains in the metadocument.Precision and recall are the measures used to eval-uate the chains output by the system.
For an entity,i, we define the precision and recall with respect othat entity in Figure 6.The final precision and recall numbers are com-puted by the following two formulae:NFinal Precision = Z wi * Precision~i= lNFinal Recall = ~ wl * Recall~i= lwhere N is the number of entities in the document,and wi is the weight assigned to entity i in the docu-ment.
For the results discussed in this paper, equalweights were assigned to each entity in the meta doc-ument.
In other words, wi = -~ for all i.
Full detailsabout the scoring algorithm can be found in (Bagga,98).Figure 7 shows the Precision, Recall, and the F-Measure (the average of precision and recall withequal weights for both) statistics for the John Smithdata set.
The best precision and recall achieved by22number of correct elements in the output chain containing entityiPrecisioni =Recalli =number of elements in the output chain containing entityinumber of correct elements in the output chain containing entityinumber of elements in the truth chain containing entityiFigure 6: Definitions for Precision and Recall for an Entity iE CDD-1009080706050403020100 I I I I I I I I I0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9ThresholdPrecision/Recall vs Threshold"'~, ~ Our Alg: Precision"~-,'O--E~.
Our AIg: Recall ---~---?
~' \,% ~-G. .
Our AIg: F-Measure -o---.,\]/ ' -~ .
13"" O..D. (3.. Q,,'~ ~-..,% "E3"" O'-O-.E3.. 13.. O.+,,.
4.. ,4,,.
?Figure 8: Precision, Recall, and F-Measure UsingOur Algorithm for the "resign" Data Setthe system on this data set was 93% and 77% re-spectively (when the threshold for the vector spacemodel was set to 0.15).
Similarly, Figure 8 showsthe same three statistics for the "resign" data set.The best precision and recall achieved by the sys-tem on this data set was 94% and 81% respectively.This occurs when the threshold for the vector spacemodel was set to 0.2.
The results show that the sys-tem was very successful in resolving cross-documentcoreference.5 Poss ib le  Genera l i za t ions  AboutLarge  Data  Co l lec t ions  Der ivedF rom Core ference  Annotat ionsCrucial to the entire process of visualizing large doc-ument collections is relating the same individual orevent across multiple documents.
This single aspectof our system establishes its viability for large col-lection analysis.
It allows the drops of informationheld in each document o be merged into a largerpool that is well organized.5.1 The  Pr imary  D isp lay  of InformationTwo display techniques immediately suggest hem-selves for accessing the coreference annotations in adocument collection, the first is to take the identi-fied entities as atomic and link them to other entitieswhich co-occur in the same document.
This mightreveal a relation between individuals and events, orindividuals and other individuals.
For example, sucha linking might indicate that no newspaper articleever mentioned both Clark Kent and Superman inthe same article, but that most all other famous in-dividuals tended to overlap in some article or an-other.
On the positive case, individuals, over time,may tend to congregate in media stories or eventsmay tend to be more tightly linked than otherwiseexpected.The second technique would be to take as atomicthe documents and relate via links other documentsthat contain mention of the same entity.
With a tem-poral dimension, the role of individuals and eventscould be assessed as time moved forward.5.2 F iner  Gra ined  Ana lys i s  o f  theDocumentsThe fact that two entities coexisted in the same sen-tence in a document is noteworthy for correlationalanalysis.
Links could be restricted to those betweenentities that co-existed in the same sentence or para-graph.
Additional filterings are possible with con-straints on the sorts of verbs that exist in the sen-tence.A more sophisticated version of the above is toaccess the argument structure of the document.CAMP software provides a limited predicate argu-ment structure that allows subjects/verbs/objectsto be identified.
This ability moves our annotationcloser to the fixed record data structure of a tra-ditional data base.
One could select an event andits object, for instance 'X sold arms to Iraq' andsee what the fillers for X were in a link analysis.There are limitations to predicate argument struc-ture matching-for instance getting the correct pat-tern for all the selling of arms variations is quitedifficult.In any case, there appear to be a myriad of appli-cations for link analysis in the domain of large textdata bases.6 Conc lus ionsThe goal of this paper has been to articulate a novelinput class for link based visualization techniques-coreference.
We feel that there is tremendous poten-tial for collaboration between researchers in visual-ization and in coreference annotation given the new23space of information provided by coreference analy-sis.formation by Computer, 1989, Reading, MA:Addison-Wesley.7 AcknowledgmentsThe second author was supported in part by a Fel-lowship from IBM Corporation, and in part by theUniversity of Pennsylvania.
Part of this work wasdone when the second author was visiting the Insti-tute for Research in Cognitive Science at the Uni-versity of Pennsylvania.ReferencesBagga, Amit, and Breck Baldwin.
Algorithms forScoring Coreference Chains.
Proceedings of thethe Linguistic Coreference Workshop at The FirstInternational Conference on Language Resourcesand Evaluation, May 1998.Bagga, Amit.
Evaluation of Coreferences and Coref-erence Resolution Systems.
Proceedings of theFirst Language Resource and Evaluation Confer-ence, pp.
563-566, May 1998.Bagga, Amit, and Breck Baldwin.
Entity-BasedCross-Document Coreferencing Using the Vec-tor Space Model.
To appear at the 17th Inter-national Conference on Computational Linguis-tics and the 36th Annual Meeting of the Asso-ciation for Computational Linguistics (COLING-ACL'98), August 1998.Baldwin, Breck.
CogNIAC: A Discourse ProcessingEngine.
University of Pennsylvania Department ofComputer and Information Sciences Ph.D. Thesis,1995.Baldwin, B., C. Doran, J. Reynar, M. Niv, andM.
Wasson.
EAGLE: An Extensible Architecturefor General Linguistic Engineering.
ProceedingsRIA O, Computer-Assisted Information Searchingon Internet, Montreal, Canada, 1997.Collins, Michael.
A New Statistical Parser Based onBigram Lexical Dependencies.
Proceedings of the34 th Meeting of the Association for ComputationalLinguistics, 1996.Ratnaparkhi, Adwait.
A Maximum Entropy Modelfor Part-Of-Speech Tagging.
Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pp.
133-142, May 1996.Wacholder, Nina, Yael Ravin, and Misook Choi.
Dis-ambiguation f Proper Names in Text.
Proceedingsof the Fifth Conference on Applied Natural Lan-guage Processing, pp.
202-208, 1997.Reynar, Jeffrey, and Adwait Ratnaparkhi.
A Max-imum Entropy Approach to Identifying SentenceBoundaries.
Proceedings of the Fifth Conferenceon Applied Natural Language Processing, pp.
16-19, 1997.Salton, Gerard.
Automatic Text Processing: TheTransformation, Analysis, and Retrieval of In-24
