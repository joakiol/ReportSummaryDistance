Proceedings of the Fourth International Natural Language Generation Conference, pages 63?70,Sydney, July 2006. c?2006 Association for Computational LinguisticsAlgorithms for Generating Referring Expressions:Do They Do What People Do?Jette ViethenCentre for Language TechnologyMacquarie UniversitySydney NSW 2109jviethen@ics.mq.edu.auRobert DaleCentre for Language TechnologyMacquarie UniversitySydney NSW 2109robert.dale@mq.edu.auAbstractThe natural language generation litera-ture provides many algorithms for thegeneration of referring expressions.
Inthis paper, we explore the question ofwhether these algorithms actually producethe kinds of expressions that people pro-duce.
We compare the output of three ex-isting algorithms against a data set consist-ing of human-generated referring expres-sions, and identify a number of significantdifferences between what people do andwhat these algorithms do.
On the basis ofthese observations, we suggest some waysforward that attempt to address these dif-ferences.1 IntroductionThe generation of referring expressions (hence-forth GRE) ?
that is, the process of workingout what properties of an entity should be usedto describe it in such a way as to distinguishit from other entities in the context ?
is a re-current theme in the natural language generationliterature.
The task is discussed informally insome of the earliest work on NLG (in particular,see (Winograd, 1972; McDonald, 1980; Appelt,1981)), but the first formally explicit algorithmwas introduced in (Dale, 1989); this algorithm,often referred to as the Full Brevity (FB) algo-rithm, has served as a starting point for many sub-sequent GRE algorithms.
To overcome its limita-tion to one-place predicates, Dale and Haddock(1991) introduced a constraint-based procedurethat could generate referring expressions involv-ing relations; and as a response to the computa-tional complexity of ?greedy?
algorithms like FB,Reiter and Dale (Reiter and Dale, 1992; Dale andReiter, 1995) introduced the psycholinguisticallymotivated Incremental Algorithm (IA).
In recentyears there have been a number of important ex-tensions to the IA.
The Context-Sensitive exten-sion (Krahmer and Theune, 2002) is able to gen-erate referring expressions for the most salient en-tity in a context; the Boolean Expressions algo-rithm (van Deemter, 2002) is able to derive ex-pressions containing boolean operators, as in thecup that does not have a handle; and the Setsalgorithm (van Deemter, 2002) extends the ba-sic approach to references to sets, as in the redcups.
Some approaches reuse parts of other al-gorithms: the Branch and Bound algorithm (Krah-mer et al, 2003) uses the Full Brevity algorithm,but is able to generate referring expressions withboth attributes and relational descriptions using agraph-based technique.
There are many other al-gorithms described in the literature: see, for exam-ple, (Horacek, 1997; Bateman, 1999; Stone, 2000;Gardent, 2002).
Their general aim is to producenaturalistic referring expressions, often explicitlyby means of an attempt to follow the same kindsof principles that we believe people might be fol-lowing when they produce language ?
such as theGricean maxims (Grice, 1975).
However, the al-gorithms have rarely been tested against real datafrom human referring expression generation.1In this paper, we present a data set containinghuman-produced referring expressions in a limiteddomain.
Focussing specifically on the algorithms1The only exceptions we know of to this deficit are notdirectly concerned with the kinds of properties people select,but with phenomena such as how people group entities to-gether (Funakoshi et al, 2004; Gatt, 2006), or with multi-modal referring expressions where the linguistic part is notnecessarily distinguishing by itself (van der Sluis and Krah-mer, 2004).63presented in (Dale, 1989), (Dale and Haddock,1991) and (Reiter and Dale, 1992), we explorehow well these algorithms perform in the samecontext.
There are significant differences betweenthe referring expressions produced by humans,and those produced by the algorithms; we explorethese differences and consider what it means forwork in the generation of referring expressions.The remainder of this paper is structured as fol-lows.
In Section 2, we introduce the data setof human-produced referring expressions we use;in Section 3, we introduce the representationalframework we use to model the domain underly-ing this data; in Section 4 we introduce the threealgorithms considered in this paper; in Section 5we discuss the results of using these algorithmson the data that represents the model of our do-main; in Section 6 we discuss the differences be-tween the output of the algorithms and the human-produced data; and in Section 7 we draw someconclusions and suggest some steps towards ad-dressing the issues we have identified.2 The DataOur human-produced referring expressions aredrawn from a physical experimental setting con-sisting of four filing cabinets, each of which isfour drawers high, located in a fairly typical aca-demic office.
The cabinets are positioned directlynext to each other, so that the drawers form a four-by-four grid; each drawer is labelled with a num-ber between 1 and 16 and is coloured either blue,pink, yellow, or orange.
There are four drawers ofeach colour which are distributed randomly overthe grid, as shown in Figure 1.Subjects were given a randomly generated num-ber between 1 and 16, and asked to produce a de-scription of the numbered drawer using any prop-erties other than the number.
There were 20 partic-ipants in the experiment, resulting in a total of 140referring expressions.
Here are some examples ofthe referring expressions produced:(1) the top drawer second from the right [d3](2) the orange drawer on the left [d9](3) the orange drawer between two pink ones[d12](4) the bottom left drawer [d16]Since the selection of which drawer to describewas random, we do not have an equal number ofFigure 1: The filing cabinetsdescriptions of each drawer; in fact, the data setranges from two descriptions of Drawer 1 to 12 de-scriptions of Drawer 16.
One of the most obviousthings about the data set is that even the same per-son may refer to the same entity in different wayson different occasions, with the differences beingsemantic as well as syntactic.We are interested in comparing how algorithmsfor referring expression generation differ in theiroutputs from what people do; since these al-gorithms produce distinguishing descriptions, wetherefore removed from the data set 22 descrip-tions which were ambiguous or referred to a set ofdrawers.
This resulted in a total of 118 distinct re-ferring expressions, with an average of 7.375 dis-tinct referring expressions per drawer.As the algorithms under scrutiny here are notconcerned with the final syntactic realisation ofthe referring expression produced, we also nor-malised the human-produced data to remove su-perficial variations such as the distinction betweenrelative clauses and reduced relatives, and betweendifferent lexical items that were synonymous incontext, such as column and cabinet.Four absolute properties used for describing thedrawers can be identified in the natural data pro-duced by the human participants.
These are thecolour of the drawer; its row and column; and inthose cases where the drawer is situated in one ofthe corners of the grid, its cornerhood.2 A numberof the natural descriptions also made use of the2A question we will return to below is that of how wedecide whether to view a particular property as a one-placepredicate or as a relation.64Property Count % (out of possible)Row 95 79.66% (118)Column 88 73.73% (118)Colour 63 53.39% (118)Corner 11 40.74% (27)Relation 15 12.71% (118)Table 1: The properties used in descriptionsfollowing relational properties that hold betweendrawers: above, below, next to, right of, left of andbetween.
In Table 1, Count shows the number ofdescriptions using each property, and the percent-ages show the ratio of the number of descriptionsusing each property to the number of descriptionsfor drawers that possess this property (hence, only27 of the descriptions referred to corner drawers).We have combined all uses of relations into onerow in this table to save space, since, interestingly,their overall use is far below that of the other prop-erties: 103 descriptions (87.3%) did not use rela-tions.Most algorithms in the literature aim at gen-erating descriptions that are as short as possi-ble, but will under certain circumstances pro-duce redundancy.
Some authors, for example(van Deemter and Halldo?rsson, 2001), have sug-gested that human-produced descriptions are of-ten not minimal, and this is an intuition that wewould generally agree with.
However, a strongtendency towards minimality is evident in thehuman-produced data here: only 29 out of 118 de-scriptions (24.6%) contain redundant information.Here are a few examples:?
the yellow drawer in the third column fromthe left second from the top [d6]?
the blue drawer in the top left corner [d1]?
the orange drawer below the two yellowdrawers [d14]In the first case, either the colour or column proper-ties are redundant; in the second, colour and corner,or only the grid information, would have been suf-ficient; and in the third, it would have been suffi-cient to mention one of the two yellow drawers.3 Knowledge RepresentationIn order to use an algorithm to generate referringexpressions in this domain, we must first decidehow to represent the domain.
It turns out that thisraises some interesting questions.We use the symbols {d1, d2 .
.
.
d16} as ourunique identifying labels for the 16 drawers.Given some di, the goal of any given algorithmis then to produce a distinguishing description ofthat entity with respect to a context consisting ofthe other 15 drawers.As is usual, we represent the properties of thedomain in terms of attribute?value pairs.
Thus wehave, for example:?
d2: ?colour, orange?, ?row, 1?, ?column, 2?,?right-of, d1?, ?left-of, d3?, ?next-to, d1?, ?next-to,d3?, ?above, d7?This drawer is in the top row, so it does not have aproperty of the form ?below, d2?.The four corner drawers additionally possessthe property ?position, corner?.
Cornerhood canbe inferred from the row and column informa-tion; however, we added this property explicitlybecause several of the natural descriptions use theproperty of cornerhood, and it seems plausible thatthis is a particularly salient property in its ownright.This raises the question of what propertiesshould be encoded explicitly, and which shouldbe inferred.
Note that in the example above, weexplicitly encode relational properties that couldbe computed from others, such as left-of and right-of.
Since none of the algorithms explored hereuses inference over knowledge base properties, weopted here to ?level the playing field?
to enablefairer comparison between human-produced andmachine-produced descriptions.A similar question of the role of inference ariseswith regard to the transitivity of spatial relations.For example, if d1 is above d9 and d9 is aboved16 , then it can be inferred that d1 is transitivelyabove d16.
In a more complex domain, the imple-mentation of this kind of knowledge might playan important role in generating usful referring ex-pressions.
However, the uniformity of our domainresults in this inferred knowledge about transitiverelations being of little use; in fact, in most cases,the implementation of transitive inference mighteven result in the generation of unnatural descrip-tions, such as the orange drawer (two) right of theblue drawer for d12.Another aspect of the representation of relationsthat requires a decision is that of generalisation:65next-to is a generalisation of the relations left-of andright-of.
The only algorithm of those we exam-ine here that provides a mechanism for exploringa generalisation hierarchy is the Incremental Al-gorithm (Reiter and Dale, 1992), and this cannothandle relations; so, we take the shortcut of ex-plicitly representing the next-to relation for everyleft-of and right-of relation in the knowledge base.We then implement special-case handling that en-sures that, if one of these facts is used, the moregeneral or more specific case is also deleted fromthe set of properties still available for the descrip-tion.34 The AlgorithmsAs we have already noted above, there is a con-siderable literature on the generation of referringexpressions, and many papers in the area providedetailed algorithms.
We focus here on the follow-ing algorithms:?
The Full Brevity algorithm (Dale, 1989) at-tempts to build a minimal distinguishing de-scription by always selecting the most dis-criminatory property available; see Algo-rithm 1.Let L be the set of properties to be realised in ourdescription; let P be the set of properties known to betrue of our intended referent r (we assume that P isnon-empty); and let C be the set of distractors (thecontrast set).
The initial conditions are thus as follows:?
C = {?all distractors?};?
P = {?all properties true of r?};?
L = {}In order to describe the intended referent r with respectto the contrast set C, we do the following:1.
Check Success:if |C| = 0 then return L as a distinguishingdescriptionelseif P = ?
then failelse goto Step 2.2.
Choose Property:for each pi ?
P do:Ci ?
C ?
{x|pi(x)}Chosen property is pj , where Cj is the smallest set.goto Step 3.3.
Extend Description (wrt the chosen pj):L ?
L ?
{pj}C ?
CjP ?
P ?
{pj}goto Step 1.Algorithm 1: The Full Brevity Algorithm3This is essentially a hack; however, there is clearly a needfor some mechanism for handling what we might think ofas equivalence classes of properties, and this is effectively asimple approach to this question.1.
Check Successif Stack is empty then return L as a DDelseif |Cv| = 1 then pop Stack & goto Step 1elseif Pr = ?
then failelse goto Step 22.
Choose Propertyfor each property pi ?
Pr dop?i ?
[r\v]piNi ?
N ?
p?iChosen prediction is pj , where Nj containsthe smallest set Cv for v.goto Step 33.
Extend Description (w.r.t the chosen p)Pr ?
Pr ?
{p}p ?
[r\v]pfor every other constant r?
in p doassociate r?
with a new, unique variable v?p ?
[r?\v?
]ppush Describe(r?,v?)
onto Stackinitialise a set P ?r of facts true of r?N ?
N ?
pgoto Step 1Algorithm 2: The Relational AlgorithmMakeReferringExpression(r, C, P ) L ?
{}for each member Ai of list P doV = FindBestValue(r, Ai, BasicLevelValue(r, Ai))if RulesOut(?Ai, V ?)
6= nilthen L ?
L ?
{?Ai, V ?
}C ?
C ?
RulesOut(?Ai, V ?
)endifif C = {} thenif ?type, X?
?
L for some Xthen return Lelse return L ?
{?type, BasicLevelValue(r,type)?
}endifendifreturn failureFindBestValue(r, A, initial-value)if UserKnows(r, ?A, initial-value?)
= truethen value ?
initial-valueelse value ?
no-valueendifif (more-specific-value ?
MoreSpecificValue(r, A,value)) 6= nil ?
(new-value ?
FindBestValue(A,more-specific-value)) 6= nil ?
(|RulesOut(?A, new-value?
)| > |RulesOut(?A,value?
)|)then value ?
new-valueendifreturn valueRulesOut(?A, V ?
)if V = no-valuethen return nilelse return {x : x ?
C ?
UserKnows(x, ?A, V ?)
=false}endifAlgorithm 3: The Incremental Algorithm66?
The relational algorithm from (Dale and Had-dock, 1991) uses constraint satisfaction to in-corporate relational properties while avoidinginfinite regress; see Algorithm 2.?
the Incremental Algorithm (Reiter and Dale,1992; Dale and Reiter, 1995) considers theavailable properties to be used in a descrip-tion via a preference ordering over thoseproperties; see Algorithm 3.For the purpose of this study, the algorithms wereimplemented in Common LISP.
The mechanismdescribed in (Dale and Reiter, 1995) to handlegeneralisation hierarchies for values for the dif-ferent properties, referred to in the algorithm hereas FindBestValue, was not implemented since, asdiscussed earlier, our representation of the domaindoes not make use of a hierarchy of properties.5 The Output of the AlgorithmsUsing the knowledge base described in Section 3,we applied the algorithms from the previous sec-tion to see whether the referring expressions theyproduced were the same as, or similar to, thoseproduced by the human subjects.
This quicklygave rise to some situations not explicitly ad-dressed by some of the algorithms; we discussthese in Section 5.1 below.
Section 5.2 discussesthe extent to which the behaviour of the algorithmsmatched that of the human data.5.1 Preference OrderingsThe Incremental Algorithm explicitly encodes apreference ordering over the available properties,in an attempt to model what appear to be semi-conventionalised strategies for description thatpeople use.
This also has the consequence ofavoiding a problem that faces the other two algo-rithms: since the Full Brevity Algorithm and theRelational Algorithm choose the most discrimina-tory property at each step, they have to deal withthe case where several properties are equally dis-criminatory.
This turns out to be a common sit-uation in our domain.
Both algorithms implicitlyassume that the choice will be made randomly inthese cases; however, it seems to us more naturalto control this process by imposing some selectionstrategy.
We do this here by borrowing the ideaof preference ordering from the Incremental Algo-rithm, and using it as a tie-breaker when multipleproperties are equally discriminatory.Not including type information (i.e., the fact thatsome di is a drawer), which has no discrimina-tory power and therefore will never be chosen byany of the algorithms,4 there are only four differ-ent properties available for the Full Brevity Algo-rithm and the Incremental Algorithm: row, column,colour, and position.
This gives us 4!
= 24 differentpossible preference orderings.
Since some of thehuman-produced descriptions use all four proper-ties, we tested these two algorithms with all 24preference orderings.For the Relational Algorithm, we added the fiverelations next to, left of, right of, above, and below.This results in 9!
= 362,880 possible preferenceorderings; far too many to test.
Since we areprimarily interested in whether the algorithm cangenerate the human-produced descriptions, we re-stricted our testing to those preference orderingsthat started with a permutation of the propertiesused by the participants; in addition to the 24 pref-erence orderings above, there are 12 preference or-derings that incorporate the relational properties.5.2 Coverage of the Human DataOverall, the Full Brevity Algorithm is able to gen-erate 82 out of the 103 non-relational descriptionsfrom the natural data, providing a recall of 79.6%.The recall score for the Incremental Algorithm is95.1%, generating 98 of the 103 descriptions.
Asthese algorithms do not attempt to generate rela-tional descriptions, the relational data is not takeninto account in evaluating the performance here.Both algorithms are able to generate all thenon-relational minimal descriptions found in thehuman-produced data.
The Full Brevity Algo-rithm unintentionally replicates the redundancyfound in nine descriptions, and the IncrementalAlgorithm produces all but five of the 29 redun-dant descriptions.Perhaps surprisingly, the Relational Algorithmdoes not generate any of the human-produced de-scriptions.
We will return to consider why this isthe case in the next section.6 DiscussionThere are two significant differences to be consid-ered here: first, the coverage of redundant descrip-tions by the Full Brevity and Incremental Algo-4Consistent with much other work in the field, we as-sume that the head noun will always be added irrespectiveof whether it has any discriminatory power.67rithms; and second, the inability of the RelationalAlgorithm to replicate any of the human data.6.1 Coverage of RedundancyNeither the Full Brevity Algorithm nor the Incre-mental Algorithm presumes to be able to generaterelational descriptions; however, both algorithmsare able to produce each of the minimal descrip-tions from the set of natural data with at least oneof the preference orderings.
Both also generateseveral of the redundant descriptions in the nat-ural data set, but do not capture all of the human-generated redundancies.The Full Brevity Algorithm has as a primarygoal the avoidance of redundant descriptions, soit is a sign of the algorithm being consistent withits specification that it covers fewer of the redun-dant expressions than the Incremental Algorithm.On the other hand, the fact that it produces anyredundant descriptions signals that the algorithmdoesn?t quite meet its specification.
The caseswhere the Full Brevity Algorithm produces redun-dancy are when an entity shares with another en-tity at least two property-values and, after choos-ing one of these properties, the next property tobe considered is the other shared one, since it hasthe same or a higher discriminatory power than allother properties.
This is a situation that was notconsidered in the original algorithm; it is relatedto the problem of what to do when two propertieshave the same discriminatory power, as noted ear-lier.
In our domain, the situation arises for cornerdrawers with the same colour (d4 and d16), anddrawers that are not in a corner but for which thereis another drawer of the same colour in each of thesame row and column (d7 and d8).The Incremental Algorithm, on the other hand,generates redundancy when an object shares atleast two property-values with another object andthe two shared properties are the first to be con-sidered in the preference ordering.
This is pos-sible for corner drawers with the same colour (d4and d16) and for drawers for which there is anotherdrawer of the same colour in either the same row,the same column, or both (d5, d6, d7, d8, d10, d11,d13, d15).In these terms, the Incremental Algorithm isclearly a better model of the human behaviour thanthe Full Brevity Algorithm.
However, we may askwhy the algorithm does not cover all the redun-dancy found in the human descriptions.
The re-dundant descriptions which the algorithm does notgenerate are as follows:(5) the blue drawer in the top left corner [d1](6) the yellow drawer in the top right corner [d4](7) the pink drawer in the top of the column sec-ond from the right [d3](8) the orange drawer in the bottom second fromthe right [d14](9) the orange drawer in the bottom of the secondcolumn from the right [d14]The Incremental Algorithm stops selecting prop-erties when a distinguishing description has beenconstructed.
In Example (6), for example, thealgorithm would select any of the following, de-pending on the preference ordering used:(10) the yellow drawer in the corner(11) the top left yellow drawer(12) the drawer in the top left cornerThe human subject, however, has added informa-tion beyond what is required.
This could be ex-plained by our modelling of cornerhood: in Ex-amples (5) and (6), one has the intuition that thenoun corner is being added simply to provide anominal head to the prepositional phrase in anincrementally-constructed expression of the formthe blue drawer in the top right .
.
.
, in muchthe same way as the head noun drawer is added,whereas we have treated it as a distinct propertythat adds discriminatory power.
This again em-phasises the important role the underlying repre-sentation plays in the generation of referring ex-pressions: if we want to emulate what people do,then we not only need to design algorithms whichmirror their behaviour, but these algorithms haveto operate over the same kind of data.6.2 Relational DescriptionsThe fact that the Relational Algorithm generatesnone of the human-generated descriptions is quitedisturbing.
On closer examination, it transpiresthat this is because, in this domain, the discrimi-natory power of relational properties is generallyalways greater than that of any other property, soa relational property is chosen first.
As noted ear-lier, relational properties appear to be dispreferred68in the human data, so the Relational Algorithm isalready disadvantaged.
The relatively poor per-formance of the algorithm is then compounded byits insistence on continuing to use relational prop-erties: an absolute property will only be chosenwhen either the currently described drawer has nounused relational properties left, or the numberof distractors has been reduced so much that thediscriminatory power of all remaining relationalproperties is lower than that of the absolute prop-erty, or the absolute property has the same discrim-inatory power as the best relational one and the ab-solute property appears before all relations in thepreference ordering.Consequently, whereas a typical human de-scription of drawer d2 would be the orange drawerabove the blue drawer, the Relational Algorithmwill produce the description the drawer above thedrawer above the drawer above the pink drawer.Not only are there no descriptions of this form inthe human-produced data set, but they also soundmore like riddles someone might create to inten-tionally make it hard for the hearer to figure outwhat is meant.There are a variety of ways in which the be-haviour of this algorithm might be repaired.
Weare currently exploring whether Krahmer et als(2003) graph-based approach to GRE is able toprovide a better coverage of the data: this algo-rithm provides the ability to make use of differ-ent search strategies and weighting mechanismswhen adding properties to a description, and sucha mechanism might be used, for example, to coun-terbalance the Relational Algorithm?s heavy biastowards the relations in this domain.7 Conclusions and Future WorkWe have noted a number of regards in which thealgorithms we have explored here do not produceoutputs that are the same as those produced by hu-mans.
Some comments on the generalisability ofthese results are appropriate.First, our results may be idiosyncratic to thespecifics of the particular domain of our experi-ment.
We would point out, however, that the do-main is more complex, and arguably more real-istic, than the much-simplified experimental con-texts that have served as intuitions for earlier workin the field; we have in mind here in particular theexperiments discussed in (Ford and Olson, 1975),(Sonnenschein, 1985) and (Pechmann, 1989).
Inthe belief that the data provides a good test setfor the generation of referring expressions, we aremaking the data set publicly available 5, so othersmay try to develop algorithms covering the data.A second concern is that we have only exploredthe extent to which three specific algorithms areable to cover the human data.
Many of the other al-gorithms in the literature take these as a base, andso are unlikely to deliver significantly different re-sults.
The major exceptions here may be (a) vanDeemter?s (2002) algorithm for sets; recall that weexcluded from the human data used here 16 ref-erences that involved sets; and, as noted above,(b) Krahmer et als (2003) graph-based approachto GRE, which may perform better than the Re-lational Algorithm on descriptions using relations.In future work, we intend to explore to what extentour findings extend to other algorithms.In conclusion, we point to two directions wherewe believe further work is required.First, as we noted early in this paper, it is clearthat there can be many different ways of refer-ring to the same entity.
Existing algorithms areall deterministic and therefore produce exactly one?best?
description for each entity; but the human-produced data clearly shows that there are manyequally valid ways of describing an entity.
Weneed to find some way to account for this in ouralgorithms.
Our intuition is that this is likely tobe best cashed out in terms of different ?refer-ence strategies?
that different speakers adopt indifferent situations; we are reminded here of Car-letta?s (1992) distinction between risky and cau-tious strategies for describing objects in the MapTask domain.
More experimentation is required inorder to determine just what these strategies are:are they, for example, characterisable as thingslike ?Produce a referring expression that is as shortas possible?
(the intuition behind the Full BrevityAlgorithm), ?Just say what comes to mind first andkeep adding information until the description dis-tinguishes the intended referent?
(something likethe Incremental Algorithm), or perhaps a strategyof minimising the cognitive effort for either thespeaker or the hearer?
Further psycholinguisticexperiments and data analysis are required to de-termine the answers here.Our second observation is that the particular re-sults we have presented here are, ultimately, en-5The data set is publicly available fromhttp://www.ics.mq.edu.au/?jviethen/drawers69tirely dependent upon the underlying representa-tions we have used, and the decisions we havemade in choosing how to represent the propertiesand relations in the domain.
We believe it is im-portant to draw attention to the fact that preciselyhow we choose to represent the domain has an im-pact on what the algorithms will do.
If we areaiming for naturalism in our algorithms for refer-ring expression generation, then ideally we wouldlike our representations to mirror those used by hu-mans; but, of course, we don?t have direct accessto what these are.There is clearly scope for psychological exper-imentation, perhaps along the lines initially ex-plored by (Rosch, 1978), to determine some con-straints here.
In parallel, we are considering fur-ther exploration into the variety of representationsthat can be used, particularly with regard to thequestion of which properties are considered to be?primitive?, and which are generated by some in-ference mechanism; this is a much neglected as-pect of the referring expression generation task.ReferencesD.
E. Appelt.
1981.
Planning Natural Language Ut-terances to Satisfy Multiple Goals.
Ph.D. thesis,Stanford University.J.
Bateman.
1999.
Using aggregation for selectingcontent when generating referring expressions.
InProceedings of the 37th Meeting of the ACL, pages127?134.J.
C. Carletta.
1992.
Risk-taking and Recovery in Task-oriented Dialogue.
Ph.D. thesis, University of Edin-burgh.R.
Dale and N. Haddock.
1991.
Generating referringexpressions involving relations.
In Proceedings ofthe 5th Meeting of the EACL, pages 161?166, Berlin,Germany.R.
Dale and E. Reiter.
1995.
Computational interpreta-tions of the Gricean maxims in the generation of re-ferring expressions.
Cognitive Science, 19(2):233?263.R.
Dale.
1989.
Cooking up referring expressions.
InProceedings of the 27th Meeting of the ACL, pages68?75.W.
Ford and D. Olson.
1975.
The elaboration ofthe noun phrase in children?s description of objects.Journal of Experimental Child Psychology, 19:371?382.K.
Funakoshi, S. Watanabe, N. Kuriyama, and T. Toku-naga.
2004.
Generating referring expressions usingperceptual groups.
In Proceedings of the 3rd INLG,pages 51?60.C.
Gardent.
2002.
Generating minimal definite de-scriptions.
In Proceedings of the 40th Meeting ofthe ACL, pages 96?103.A.
Gatt.
2006.
Structuring knowledge for referencegeneration: A clustering algorithm.
In Proceedingsof the 11th Meeting of the EACL.H.
P. Grice.
1975.
Logic and conversation.
In P. Coleand J. Morgan, editors, Syntax and Semantics Vol-ume 3: Speech Acts, pages 43?58.
Academic Press.H.
Horacek.
1997.
An algorithm for generating ref-erential descriptions with flexible interfaces.
In Pro-ceedings of the 35th Meeting of the ACL, pages 127?134.E.
Krahmer and M. Theune.
2002.
Efficient context-sensitive generation of referring expressions.
InK.
van Deemter and R. Kibble, editors, Informa-tion Sharing: Reference and Presupposition in Lan-guage Generation and Interpretation, pages 223?264.
CSLI.E.
Krahmer, S. van Erk, and A. Verleg.
2003.
Graph-based generation of referring expressions.
Compu-tational Linguistics, 29(1):53?72.D.
D. McDonald.
1980.
Natural Language Generationas a Process of Decision-making Under Constraints.Ph.D.
thesis, Massachusetts Institute of Technology.T.
Pechmann.
1989.
Incremental speech produc-tion and referential overspecification.
Linguistics,27:89?110.E.
Reiter and R. Dale.
1992.
A fast algorithm for thegeneration of referring expressions.
In Proceedingsof the 14th Meeting of the ACL, pages 232?238.E.
Rosch.
1978.
Principles of categorization.
In Cog-nition and Categorization, pages 27?48.
LawrenceErlbaum, Hillsdale, NJ.S.
Sonnenschein.
1985.
The development of referen-tial communication skills: Some situations in whichspeakers give redundant messages.
Journal of Psy-cholinguistic Research, 14:489?508.M.
Stone.
2000.
On identifying sets.
In Proceedingsof the 1st INLG, pages 116?123.K.
van Deemter and M. M. Halldo?rsson.
2001.
Logi-cal form equivalence: The case referring expressionsgeneration.
In Proceedings of the 8th ENLG.K.
van Deemter.
2002.
Generating referring expres-sions: Boolean extensions of the incremental algo-rithm.
Computational Linguistics, 28(1):37?52.I.
van der Sluis and E. Krahmer.
2004.
Evaluatingmultimodal NLG using production experiments.
InProceedings of the 4th LREC, pages 209?212, 26-28May.T.
Winograd.
1972.
Understanding Natural Language.Academic Press.70
