Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 653?656,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEnlarged Search Space for SITG ParsingGuillem Gasc?, Joan-Andreu S?nchez, Jos?-Miguel Bened?Institut Tecnol?gic d?Inform?tica, Universitat Polit?cnica de Val?nciaCam?
de Vera s/n, Val?ncia, 46022, Spainggasco@iti.upv.es , {jandreu,jbenedi}@dsic.upv.esAbstractStochastic Inversion Transduction Grammarsconstitute a powerful formalism in MachineTranslation for which an efficient DynamicProgramming parsing algorithm exists.
In thiswork, we review this parsing algorithm andpropose important modifications that enlargethe search space.
These modifications allowthe parsing algorithm to search for more andbetter solutions.1 IntroductionSyntax Machine Translation has received great at-tention in the last few years, especially for pairs oflanguages that are sufficiently non-monotonic.
Sev-eral works have explored the use of syntax for Ma-chine Translation (Wu, 1997; Chiang, 2007).
In(Wu, 1997), Stochastic Inverse Transduction Gram-mars (SITGs) were introduced for describing struc-turally correlated pairs of languages.
SITGs can beused to simultaneously analyze two strings from dif-ferent languages and to correlate them.
An efficientDynamic Programming parsing algorithm for SITGswas presented in (Wu, 1997).
This algorithm is sim-ilar to the CKY algorithm for Probabilistic ContextFree Grammars.
The parsing algorithm does not al-low the association of two items that have the emptystring in one of their sides.
This limitation restrictsthe search space and prevents the algorithm from ex-ploring some valid parse trees.In this paper, we review Wu?s parsing algorithmfor SITGs (referred to as the original algorithm) andpropose some modifications to increase the searchspace in order to make it possible to find these validparse trees.2 SITG ParsingSITGs (Wu, 1997) can be viewed as a restrictedsubset of Stochastic Syntax-Directed TransductionGrammars (Maryanski and Thomason, 1979).
For-mally, a SITG in Chomsky Normal Form can bedefined as a set of lexical rules that are noted asA ?
x/?, A ?
?/y, A ?
x/y; direct syntac-tic rules that are noted as A ?
[BC]; and inversesyntactic rules that are noted as A ?
?BC?, whereA,B,C are non-terminal symbols, x, y are terminalsymbols, ?
is the empty string, and each rule has aprobability value p attached.
The sum of the proba-bilities of the rules with the same non-terminal in theleft side must be equal to 1.
When a direct syntacticrule is used in parsing, both strings are parsed withthe syntactic rule A ?
BC .
When an inverse rule isused in parsing, one string is parsed with the syntac-tic rule A ?
BC , and the other string is parsed withthe syntactic rule A ?
CB.An efficient Viterbi-like parsing algorithm that isbased on a Dynamic Programming Scheme was pro-posed in (Wu, 1997).
It allows us to obtain the mostprobable parse tree that simultaneously analyzes twostrings, X = x1...x|X| and Y = y1...x|Y |, i.e.
thebilingual string X/Y .
It has a time complexity ofO(|X|3|Y |3|R|), where |R| is the number of rulesof the grammar.The parsing algorithm is based on the definitionof:?ijkl(A) = P?r(A ??
xi+1 ?
?
?
xj/yk+1 ?
?
?
yl)as the maximum probability of any parsing tree thatsimultaneously generates the substrings xi+1 ?
?
?
xjand yk+1 ?
?
?
yl from the non-terminal symbol A .In (Wu, 1997), the parsing algorithm was definedas follows:6531.
Initialization?i?1,i,k?1,k(A) = p(A ?
xi/yk)1 ?
i ?
|X|, 1 ?
k ?
|Y |,?i?1,i,k,k(A) = p(A ?
xi/?
)1 ?
i ?
|X|, 0 ?
k ?
|Y |,?i,i,k?1,k(A) = p(A ?
?/yk)0 ?
i ?
|X|, 1 ?
k ?
|Y |,2.
RecursionFor all A ?
N andi, j, k, l such that??
?0 ?
i < j ?
|X|,0 ?
k < l ?
|Y |,j ?
i + l ?
k > 2,(1)?ijkl(A) = max(?
[]ijkl(A), ???ijkl(A))where?
[]ijkl(A)= maxB,C?Ni?I?j,k?K?l(I?i)(j?I)+(K?k)(l?K)>0p(A ?
[BC])?iIkK(B)?IjKl(C) (2)??
?ijkl(A)= maxB,C?Ni?I?j,k?K?l(I?i)(j?I)+(K?k)(l?K)>0p(A ?
?BC?
)?iIKl(B)?IjkK(C) (3)This algorithm cannot provide the correct parsingtree in some situations.
For example, consider theSITG shown in Fig.
1.
If the input pair is a/b,p S ?
[SS] p S ?
?SS?q S ?
?/b q S ?
a/?1?
2p?
2q S ?
a/bFigure 1: Example SITG.this SITG provides the parse tree (a) that is shown inFig.
2 with probability 1 ?
2p ?
2q.
However, theparse tree (b) is more likely if 1 ?
2p ?
2q < 2pq.The above parsing algorithm is not able to obtainthis parse tree due to the restriction j?
i+ l?k > 2in (1).
This restriction does not allow the algo-rithm to consider two subproblems in which eachsubstring has length 1 which have not been previ-ously considered in the initialization step.
Chang-ing this restriction to j ?
i + l ?
k ?
2 is notenough to tackle this situation since the restriction(b)(a)SSSSa/ba/?
?/bFigure 2: Parse tree (a) can be obtained with Wu?s algo-rithm for a/b, but parse tree (b) cannot be obtained.
(I?i)(j?I)+(K?k)(l?K) 6= 0 in expression (2)is not accomplished given that I = i or I = j, andK = k or l = K (similarly in expression (3)).From now on, we will use the term non-exploredtrees to denote the set of trees that are possible whenrules of the grammar are applied but cannot be ex-plored with Wu?s algorithm.
In fact, this situationappears for other paired strings (see Fig.
3) in whicha string in one side is associated with the emptystring in the other side through rules that are not lexi-cal rules.
For example, in Fig.
3b, substring aa couldbe associated with ?.
However,this parse tree cannotbe obtained with the algorithm due to the search re-strictions described above.(b)(a)SSSSSSSSa/ba/?a/?a/?
?/bFigure 3: Parse tree (a) can be obtained with Wu?s algo-rithm for aa/b, but parse tree (b) would be more probableif pq2 > 1?
2p?
2q.The changes needed in the algorithm to be able tofind the sort of parsing trees described above are thefollowing:?
Changing restriction j ?
i+ l?
k > 2 in (1) toj?
i+ l?k ?
2.
Note that this new restrictionis redundant and could be removed.?
Changing restriction (I?
i)(j?I)+(K?k)(l?K) 6= 0 to ((j?I)+(l?K))?
((I?i)+(K?k)) 6=0 in (2) and to ((j ?
I) + (K ?
k)) ?
((I ?
i) +(l ?
K)) 6= 0 in (3) in order to guarantee thealgorithm?s termination.3 Search under SITG ConstraintsThe modifications that have been introduced in Sec-tion 2 enlarge the search space and allow the parsing654algorithm to explore a greater number of possible so-lutions.
We illustrate this situation with an example.Consider the SITG introduced in Figure 1.
Fig.
4shows the possible complete matched trees for theinput pair a/b that are considered in the search pro-cess with the modifications introduced.
(b)(a) (c) (d) (e)SSSSSSSSSSSSSa/baaaabbbb???????
?Figure 4: Parse trees for input pair a/b that are taken intoaccount in the search process with the modifications.Without these modifications, the parsing algo-rithm only takes into account tree (a) of Fig.
4.
Forthis grammar, we have computed the growth in num-ber of complete matched trees.
Table 1 shows howthe search space grows notably with the modifica-tions introduced.n Wu?s alg.
Modified alg.
ratio1 1 5 0.2002 34 290 0.1173 1,928 34,088 0.0574 131,880 5,152,040 0.0265 10,071,264 890,510,432 0.0116 827,969,856 167,399,588,160 0.005Table 1: Growth in number of explored trees for the orig-inal and modified parsing algorithms (n is the length ofthe input pair strings and the last column represents theratio between columns two and three).As a preliminary experiment and in order to eval-uate empirically the Wu?s parsing algorithm versusthe modified algorithm, we parsed first 100K sen-tence of German-English Europarl corpus.
The lex-ical rules in the Bracketing SITG used for pars-ing were obtained from a probabilistic dictionaryby aligning with IBM3 model (NULL aligmentswere also included).
In this experiment, the modi-fied algorithm obtained a more probable parse treefor 6% of the sentences.
If we added brackets tothe sentences separately with monolingual parsers,we could use a parsing algorithm similar to the al-gorithm that is described in (S?nchez and Bened?,2006).
The monolingual brackets restricted theparse tree to those that were compatible with thebrackets.
In that case the modified algorithm ob-tained a more probable parse tree for 14% of thesentences.4 Inside ProbabilityThe parsing algorithm described above computesthe most likely parse tree for a given paired stringX/Y .
However, in some cases (Wu, 1995; Huangand Zhou, 2009), we need the inside probability(?0,|X|,0,|Y |(S)), i.e., the probability that the gram-mar assigns to the whole set of parse trees that yieldX/Y .
If the maximizations are replaced by sums,the algorithm can be used to compute the insideprobability.
However, as stated above, the origi-nal algorithm cannot find the whole set of trees fora given paired string in some cases.
These non-explored trees have a probability greater than 0.As an example, we computed the amount of prob-ability lost in the inside computation using the origi-nal algorithm with the grammar shown in Fig.
1.
Let?
be the amount of probability of the non-exploredtrees (the lost probability).
It must be noted thatsince height 1 trees are all reachable, we must accu-mulate lost probability for trees of height 2 or more.Hence, let ?
be the amount of lost probability fortrees of height 2 or more.
Note that all such treesmust have initially used the production S ?
SS in-versely or directly.
Thus, ?
= 2p ?
?.
Fig.
5 showsthe kinds of non-explored trees.
Then ?
is:?
= 4?q2+2?2p?(1?2p)?
?+(2p)2 ?(2?(1??
)+?2)The first addend is the probability of the non-explored trees of height 2 (Fig.
5a).
The second ad-dend is the probability that one of the subtrees usesa syntactic production, this new subtree producesa non-explored tree (2p ?
?)
and the other subtree(a) (b) (c)SSSSSSSSSFigure 5: Partial representation of non-explored parsetrees from the non-terminal string SS introduced afterthe first derivation step: (a) both non-terminals yield aterminal in one side and the empty string in the other;(b) one of the non-terminals uses a lexical productionand the other non-terminal yields a non-explored tree; (c)both non-terminals use a syntactic production and one (orboth) yields a non-explored tree.655Figure 6: Amount of lost probability for values of p and q.rewrites itself using a lexical production (1 ?
2p).Note that the non-explored tree can be yielded fromeither the left or the right non-terminal, (Fig.
5b).The third addend is the probability that both non-terminals use a syntactic production (2p)2 and ei-ther one (2(?)(1??))
or both (?2) subtrees are non-explored trees (Fig.
5c).
If we isolate ?, we get?
= 2p ?
1?
4p ?
?16p2 ?
8p + 1 + 64p2q24p2Since the solution with the positive square roottakes values greater than 1, we can discard it.Fig.
6 shows the probability accumulated in thenon-explored trees for values of p and q between0 and 0.25 (higher values of p produce inconsistentSITGs).
That is the amount of probability lost in theinside parsing for the whole language generated bythe grammar shown in Fig.
1.In order to prove the loss of probability producedby the original algorithm, we use the grammar inFig.
1 with p = q = 0.2.
We parse all the pairedstrings X/Y such that |X| + |Y | ?
l, where l is afixed maximum length.
We repeat the same exper-iment using the modified algorithm.
Fig.
7 showsthe accumulated inside probabilities for both origi-nal and modified algorithms and the theoretical max-imums (1??
for the original algorithm and 1 for themodified algorithm).
Note that the computed resultsapproach the theoretical maximums and the modi-fied algorithm covers the whole search space.5 ConclusionsSITGs have proven to be a powerful tool in SyntaxMachine Translation.
However, the algorithms havebeen proposed do not explore all the possible parsetrees.
This work proposes modifications of the algo-rithms to be able to explore the whole search space.Figure 7: Accumulated inside probability for the originaland modified algorithms.Using an example, we have shown that the modifi-cations allow a complete search.
As future work, weplan to proove the correctness of the modified algo-rithm and to study the impact of these modificationson the use of SITGs for Machine Translation, andthe estimation of SITGs.AcknowledgmentsWork supported by the EC (FSE), the Spanish Gov-ernment (MICINN, "Plan E") under grants MIPRCV"Consolider Ingenio 2010" CSD2007-00018, iTrans2TIN2009-14511 and the Generalitat Valenciana grantPrometeo/2009/014 and BFPI/2007/117.ReferencesD.
Chiang.
2007.
Hierarchical phrase-based translation.Computational Linguistics, 33(2):201?228.S.
Huang and B. Zhou.
2009.
An em algorithm for scfgin formal syntax-based translation.
In ICASSP, pages4813?4816, Taiwan, China, April.F.J.
Maryanski and M.T.
Thomason.
1979.
Properties ofstochastic syntax-directed tranlation schemata.
Jour-nal of Computer and Information Sciences, 8(2):89?110.J.A.
S?nchez and J.M.
Bened?.
2006.
Stochastic in-version transduction grammars for obtaining wordphrases for phrase-based statistical machine transla-tion.
In Proc.
of Workshop on Statistical MachineTranslation.
HLT-NAACL 06, pages 130?133.D.
Wu.
1995.
Trainable coarse bilingual grammars forparallel text bracketing.
In Proceedings of the ThirdAnnual Workshop on Very Large Corpora, pages 69?81.D.
Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Com-putational Linguistics, 23(3):377?404.656
