Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 248?255,New York, June 2006. c?2006 Association for Computational LinguisticsGrammatical Machine TranslationStefan Riezler and John T. Maxwell IIIPalo Alto Research Center3333 Coyote Hill Road, Palo Alto, CA 94304AbstractWe present an approach to statisticalmachine translation that combines ideasfrom phrase-based SMT and traditionalgrammar-based MT.
Our system incor-porates the concept of multi-word trans-lation units into transfer of dependencystructure snippets, and models and trainsstatistical components according to state-of-the-art SMT systems.
Compliant withclassical transfer-based MT, target depen-dency structure snippets are input to agrammar-based generator.
An experimen-tal evaluation shows that the incorpora-tion of a grammar-based generator into anSMT framework provides improved gram-maticality while achieving state-of-the-artquality on in-coverage examples, suggest-ing a possible hybrid framework.1 IntroductionRecent approaches to statistical machine translation(SMT) piggyback on the central concepts of phrase-based SMT (Och et al, 1999; Koehn et al, 2003)and at the same time attempt to improve some of itsshortcomings by incorporating syntactic knowledgein the translation process.
Phrase-based translationwith multi-word units excels at modeling local or-dering and short idiomatic expressions, however, itlacks a mechanism to learn long-distance dependen-cies and is unable to generalize to unseen phrasesthat share non-overt linguistic information.
Publiclyavailable statistical parsers can provide the syntacticinformation that is necessary for linguistic general-izations and for the resolution of non-local depen-dencies.
This information source is deployed in re-cent work either for pre-ordering source sentencesbefore they are input to to a phrase-based system(Xia and McCord, 2004; Collins et al, 2005), orfor re-ordering the output of translation models bystatistical ordering models that access linguistic in-formation on dependencies and part-of-speech (Lin,2004; Ding and Palmer, 2005; Quirk et al, 2005)1 .While these approaches deploy dependency-stylegrammars for parsing source and/or target text, a uti-lization of grammar-based generation on the outputof translation models has not yet been attempted independency-based SMT.
Instead, simple target lan-guage realization models that can easily be trainedto reflect the ordering of the reference translations inthe training corpus are preferred.
The advantage ofsuch models over grammar-based generation seemsto be supported, for example, by Quirk et al?s (2005)improvements over phrase-based SMT as well asover an SMT system that deploys a grammar-basedgenerator (Menezes and Richardson, 2001) on n-gram based automatic evaluation scores (Papineni etal., 2001; Doddington, 2002).
Another data point,however, is given by Charniak et al (2003) whoshow that parsing-based language modeling can im-prove grammaticality of translations, even if theseimprovements are not recorded under n-gram basedevaluation measures.1A notable exception to this kind of approach is Chiang(2005) who introduces syntactic information into phrase-basedSMT via hierarchical phrases rather than by external parsing.248In this paper we would like to step away fromn-gram based automatic evaluation scores for amoment, and investigate the possible contributionsof incorporating a grammar-based generator intoa dependency-based SMT system.
We present adependency-based SMT model that integrates theidea of multi-word translation units from phrase-based SMT into a transfer system for dependencystructure snippets.
The statistical components ofour system are modeled on the phrase-based sys-tem of Koehn et al (2003), and component weightsare adjusted by minimum error rate training (Och,2003).
In contrast to phrase-based SMT and to theabove cited dependency-based SMT approaches, oursystem feeds dependency-structure snippets into agrammar-based generator, and determines target lan-guage ordering by applying n-gram and distortionmodels after grammar-based generation.
The goal ofthis ordering model is thus not foremost to reflect theordering of the reference translations, but to improvethe grammaticality of translations.Since our system uses standard SMT techniquesto learn about correct lexical choice and idiomaticexpressions, it allows us to investigate the contri-bution of grammar-based generation to dependency-based SMT2.
In an experimental evaluation on thetest-set that was used in Koehn et al (2003) weshow that for examples that are in coverage ofthe grammar-based system, we can achieve state-of-the-art quality on n-gram based evaluation mea-sures.
To discern the factors of grammaticalityand translational adequacy, we conducted a man-ual evaluation on 500 in-coverage and 500 out-of-coverage examples.
This showed that an incorpo-ration of a grammar-based generator into an SMTframework provides improved grammaticality overphrase-based SMT on in-coverage examples.
Sincein our system it is determinable whether an exampleis in-coverage, this opens the possibility for a hy-brid system that achieves improved grammaticalityat state-of-the-art translation quality.2A comparison of the approaches of Quirk et al (2005) andMenezes and Richardson (2001) with respect to ordering mod-els is difficult because they differ from each other in their statis-tical and dependency-tree alignment models.2 Extracting F-Structure SnippetsOur method for extracting transfer rules for depen-dency structure snippets operates on the paired sen-tences of a sentence-aligned bilingual corpus.
Sim-ilar to phrase-based SMT, our approach starts withan improved word-alignment that is created by in-tersecting alignment matrices for both translation di-rections, and refining the intersection alignment byadding directly adjacent alignment points, and align-ment points that align previously unaligned words(see Och et al (1999)).
Next, source and target sen-tences are parsed using source and target LFG gram-mars to produce a set of possible f(unctional) de-pendency structures for each side (see Riezler et al(2002) for the English grammar and parser; Butt etal.
(2002) for German).
The two f-structures thatmost preserve dependencies are selected for furtherconsideration.
Selecting the most similar instead ofthe most probable f-structures is advantageous forrule induction since it provides for higher cover-age with simpler rules.
In the third step, the many-to-many word alignment created in the first step isused to define many-to-many correspondences be-tween the substructures of the f-structures selectedin the second step.
The parsing process maintainsan association between words in the string and par-ticular predicate features in the f-structure, and thusthe predicates on the two sides are implicitly linkedby virtue of the original word alignment.
The wordalignment is extended to f-structures by setting intocorrespondence the f-structure units that immedi-ately contain linked predicates.
These f-structurecorrespondences are the basis for hypothesizing can-didate transfer rules.To illustrate, suppose our corpus contains the fol-lowing aligned sentences (this example is taken fromour experiments on German-to-English translation):Dafu?r bin ich zutiefst dankbar.I have a deep appreciation for that.Suppose further that we have created the many-to-many bi-directional word alignmentDafu?r{6 7} bin{2} ich{1} zutiefst{3 4 5}dankbar{5}indicating for example that Dafu?r is aligned withwords 6 and 7 of the English sentence (for and that).249??????????
?PRED seinSUBJ[PRED ich]XCOMP????
?PRED dankbarADJ?????
[PRED zutiefst][PRED dafu?r]?????????????????????????????????????
?PRED haveSUBJ[PRED I]OBJ??????????
?PRED appreciationSPEC[PRED a]ADJ???????
[PRED deep]?
?PRED forOBJ[PRED that]????????????????????????????????????
?Figure 1: F-structure alignment for induction of German-to-English transfer rules.This results in the links between the predicates of thesource and target f-structures shown in Fig.
1.From these source-target f-structure alignmentstransfer rules are extracted in two steps.
In the firststep, primitive transfer rules are extracted directlyfrom the alignment of f-structure units.
These in-clude simple rules for mapping lexical predicatessuch as:PRED(%X1, ich) ==> PRED(%X1, I)and somewhat more complicated rules for mappinglocal f-structure configurations.
For example, therule shown below is derived from the alignment ofthe outermost f-structures.
It maps any f-structurewhose pred is sein to an f-structure with pred have,and in addition interprets the subj-to-subj link as anindication to map the subject of a source with thispredicate into the subject of the target and the xcompof the source into the object of the target.
Featuresdenoting number, person, type, etc.
are not shown;variables %X denote f-structure values.PRED(%X1,sein) PRED(%X1,have)SUBJ(%X1,%X2) ==> SUBJ(%X1,%X2)XCOMP(%X1,%X3) OBJ(%X1,%X3)The following rule shows how a single source f-structure can be mapped to a local configuration ofseveral units on the target side, in this case the sin-gle f-structure headed by dafu?r into one that corre-sponds to an English preposition+object f-structure.PRED(%X1,for)PRED(%X1, dafu?r) ==> OBJ(%X1,%X2)PRED(%X2,that)Transfer rules are required to only operate on con-tiguous units of the f-structure that are consistentwith the word alignment.
This transfer contiguityconstraint states that1.
source and target f-structures are each con-nected.2.
f-structures in the transfer source can only bealigned with f-structures in the transfer target,and vice versa.This constraint on f-structures is analogous to theconstraint on contiguous and alignment-consistentphrases employed in phrase-based SMT.
It preventsthe extraction of a transfer rule that would trans-late dankbar directly into appreciation since appre-ciation is aligned also to zutiefst and its f-structurewould also have to be included in the transfer.
Thus,the primitive transfer rule for these predicates mustbe:PRED(%X1,dankbar) PRED(%X1,appr.
)ADJ(%X1,%X2) ==> SPEC(%X1,%X2)in set(%X3,%X2) PRED(%X2,a)PRED(%X3,zutiefst) ADJ(%X1,%X3)in set(%X4,%X3)PRED(%X4,deep)In the second step, rules for more complex map-pings are created by combining primitive transferrules that are adjacent in the source and target f-structures.
For instance, we can combine the prim-itive transfer rule that maps sein to have with theprimitive transfer rule that maps ich to I to producethe complex transfer rule:PRED(%X1,sein) PRED(%X1,have)SUBJ(%X1,%X2) ==> SUBJ(%X1,%X2)PRED(%X2,ich) PRED(%X2,I)XCOMP(%X1,%X3) OBJ(%X1,%X3)In the worst case, there can be an exponentialnumber of combinations of primitive transfer rules,so we only allow at most three primitive transferrules to be combined.
This produces O(n2) trans-250fer rules in the worst case, where n is the number off-structures in the source.Other points where linguistic information comesinto play is in morphological stemming in f-structures, and in the optional filtering of f-structurephrases based on consistency of linguistic types.
Forexample, the extraction of a phrase-pair that trans-lates zutiefst dankbar into a deep appreciation isvalid in the string-based world, but would be pre-vented in the f-structure world because of the incom-patibility of the types A and N for adjectival dankbarand nominal appreciation.
Similarly, a transfer ruletranslating sein to have could be dispreferred be-cause of a mismatch in the the verbal types V/A andV/N.
However, the transfer of sein zutiefst dankbarto have a deep appreciation is licensed by compati-ble head types V.3 Parsing-Transfer-GenerationWe use LFG grammars, producing c(onstituent)-structures (trees) and f(unctional)-structures (at-tribute value matrices) as output, for parsing sourceand target text (Riezler et al, 2002; Butt et al, 2002).To increase robustness, the standard grammar is aug-mented with a FRAGMENT grammar.
This allowssentences that are outside the scope of the standardgrammar to be parsed as well-formed chunks speci-fied by the grammar, with unparsable tokens possi-bly interspersed.
The correct parse is determined bya fewest-chunk method.Transfer converts source into a target f-structuresby non-deterministically applying all of the inducedtransfer rules in parallel.
Each fact in the German f-structure must be transferred by exactly one trans-fer rule.
For robustness a default rule is includedthat transfers any fact as itself.
Similar to parsing,transfer works on a chart.
The chart has an edge foreach combination of facts that have been transferred.When the chart is complete, the outputs of the trans-fer rules are unified to make sure they are consistent(for instance, that the transfer rules did not producetwo determiners for the same noun).
Selection ofthe most probable transfer output is done by beam-decoding on the transfer chart.LFG grammars can be used bidirectionally forparsing and generation, thus the existing Englishgrammar used for parsing the training data canalso be used for generation of English translations.For in-coverage examples, the grammar specifies c-structures that differ in linear precedence of sub-trees for a given f-structure, and realizes the termi-nal yield according to morphological rules.
In orderto guarantee non-empty output for the overall trans-lation system, the generation component has to befault-tolerant in cases where the transfer system op-erates on a fragmentary parse, or produces non-validf-structures from valid input f-structures.
For gener-ation from unknown predicates, a default morphol-ogy is used to inflect the source stem correctly forEnglish.
For generation from unknown structures, adefault grammar is used that allows any attribute tobe generated in any order as any category, with op-timality marks set so as to prefer the standard gram-mar over the default grammar.4 Statistical Models and TrainingThe statistical components of our system are mod-eled on the statistical components of the phrase-based system Pharaoh, described in Koehn et al(2003) and Koehn (2004).
Pharaoh integrates thefollowing 8 statistical models: relative frequency ofphrase translations in source-to-target and target-to-source direction, lexical weighting in source-to-target and target-to-source direction, phrase count,language model probability, word count, and distor-tion probability.Correspondingly, our system computes the fol-lowing statistics for each translation:1. log-probability of source-to-target transferrules, where the probability r(e|f) of a rulethat transfers source snippet f into target snip-pet e is estimated by the relative frequencyr(e|f) = count(f ==> e)?e?
count(f ==> e?)2.
log-probability of target-to-source rules3.
log-probability of lexical translations fromsource to target snippets, estimated fromViterbi alignments a?
between source word po-sitions i = 1, .
.
.
, n and target word positionsj = 1, .
.
.
,m for stems fi and ej in snippetsf and e with relative word translation frequen-251cies t(ej |fi):l(e|f) =?j1|{i|(i, j) ?
a?}|?
(i,j)?a?t(ej |fi)4. log-probability of lexical translations from tar-get to source snippets5.
number of transfer rules6.
number of transfer rules with frequency 17. number of default transfer rules (translatingsource features into themselves)8. log-probability of strings of predicates fromroot to frontier of target f-structure, estimatedfrom predicate trigrams in English f-structures9.
number of predicates in target f-structure10.
number of constituent movements during gen-eration based on the original order of the headpredicates of the constituents (for example,AP[2] BP[3] CP[1] counts as two move-ments since the head predicate of CP movedfrom the first position to the third position)11. number of generation repairs12.
log-probability of target string as computed bytrigram language model13.
number of words in target stringThese statistics are combined into a log-linear modelwhose parameters are adjusted by minimum errorrate training (Och, 2003).5 Experimental EvaluationThe setup for our experimental comparison isGerman-to-English translation on the Europarl par-allel data set3.
For quick experimental turnaroundwe restricted our attention to sentences with 5 to15 words, resulting in a training set of 163,141 sen-tences and a development set of 1967 sentences.
Fi-nal results are reported on the test set of 1,755 sen-tences of length 5-15 that was used in Koehn et al(2003).
To extract transfer rules, an improved bidi-rectional word alignment was created for the train-ing data from the word alignment of IBM model 4 as3http://people.csail.mit.edu/koehn/publications/europarl/implemented by GIZA++ (Och et al, 1999).
Train-ing sentences were parsed using German and En-glish LFG grammars (Riezler et al, 2002; Butt etal., 2002).
The grammars obtain 100% coverage onunseen data.
80% are parsed as full parses; 20% re-ceive FRAGMENT parses.
Around 700,000 transferrules were extracted from f-structures pairs chosenaccording to a dependency similarity measure.
Forlanguage modeling, we used the trigram model ofStolcke (2002).When applied to translating unseen text, the sys-tem operates on n-best lists of parses, transferredf-structures, and generated strings.
For minimum-error-rate training on the development set, and fortranslating the test set, we considered 1 Germanparse for each source sentence, 10 transferred f-structures for each source parse, and 1,000 gener-ated strings for each transferred f-structure.
Selec-tion of most probable translations proceeds in twosteps: First, the most probable transferred f-structureis computed by a beam search on the transfer chartusing the first 10 features described above.
Thesefeatures include tests on source and target f-structuresnippets related via transfer rules (features 1-7) aswell as language model and distortion features onthe target c- and f-structures (features 8-10).
In ourexperiments, the beam size was set to 20 hypotheses.The second step is based on features 11-13, whichare computed on the strings that were actually gen-erated from the selected n-best f-structures.We compared our system to IBM model 4 as pro-duced by GIZA++ (Och et al, 1999) and a phrase-based SMT model as provided by Pharaoh (2004).The same improved word alignment matrix and thesame training data were used for phrase-extractionfor phrase-based SMT as well as for transfer-ruleextraction for LFG-based SMT.
Minimum-error-ratetraining was done using Koehn?s implementation ofOch?s (2003) minimum-error-rate model.
To trainthe weights for phrase-based SMT we used the first500 sentences of the development set; the weights ofthe LFG-based translator were adjusted on the 750sentences that were in coverage of our grammars.For automatic evaluation, we use the NIST metric(Doddington, 2002) combined with the approximaterandomization test (Noreen, 1989), providing the de-sired combination of a sensitive evaluation metricand an accurate significance test (see Riezler and252Table 1: NIST scores on test set for IBM model 4 (M4),phrase-based SMT (P), and the LFG-based SMT (LFG) on thefull test set and on in-coverage examples for LFG.
Results in thesame row that are not statistically significant from each other aremarked with a ?.M4 LFG Pin-coverage 5.13 *5.82 *5.99full test set *5.57 *5.62 6.40Table 2: Preference ratings of two human judges for transla-tions of phrase-based SMT (P) or LFG-based SMT (LFG) undercriteria of fluency/grammaticality and translational/semanticadequacy on 500 in-coverage examples.
Ratings by judge 1 areshown in rows, for judge 2 in columns.
Agreed-on examples areshown in boldface in the diagonals.adequacy grammaticalityj1\j2 P LFG equal P LFG equalP 48 8 7 36 2 9LFG 10 105 18 6 113 17equal 53 60 192 51 44 223Maxwell (2005)).
In order to avoid a random as-sessment of statistical significance in our three-foldpairwise comparison, we reduce the per-comparisonsignificance level to 0.01 so as to achieve a standardexperimentwise significance level of 0.05 (see Co-hen (1995)).
Table 1 shows results for IBM model4, phrase-based SMT, and LFG-based SMT, whereexamples that are in coverage of the LFG-based sys-tems are evaluated separately.
Out of the 1,755 sen-tences of the test set, 44% were in coverage of theLFG-grammars; for 51% the system had to resort tothe FRAGMENT technique for parsing and/or repairtechniques in generation; in 5% of the cases our sys-tem timed out.
Since our grammars are not set upwith punctuation in mind, punctuation is ignored inall evaluations reported below.For in-coverage examples, the difference betweenNIST scores for the LFG system and the phrase-based system is statistically not significant.
On thefull set of test examples, the suboptimal quality onout-of-coverage examples overwhelms the qualityachieved on in-coverage examples, resulting in a sta-tistically not significant result difference in NISTscores between the LFG system and IBM model 4.In order to discern the factors of grammaticalityand translational adequacy, we conducted a manualevaluation on randomly selected 500 examples thatwere in coverage of the grammar-based generator.Two independent human judges were presented withthe source sentence, and the output of the phrase-based and LFG-based systems in a blind test.
Thiswas achieved by displaying the system outputs inrandom order.
The judges were asked to indicate apreference for one system translation over the other,or whether they thought them to be of equal quality.These questions had to be answered separately un-der the criteria of grammaticality/fluency and trans-lational/semantic adequacy.
As shown in Table 2,both judges express a preference for the LFG systemover the phrase-based system for both adequacy andgrammaticality.
If we just look at sentences wherejudges agree, we see a net improvement on trans-lational adequacy of 57 sentences, which is an im-provement of 11.4% over the 500 sentences.
If thiswere part of a hybrid system, this would amount to a5% overall improvement in translational adequacy.Similarly we see a net improvement on grammat-icality of 77 sentences, which is an improvementof 15.4% over the 500 sentences or 6.7% overallin a hybrid system.
Result differences on agreed-on ratings are statistically significant, where sig-nificance was assessed by approximate randomiza-tion via stratified shuffling of the preferences be-tween the systems (Noreen, 1989).
Examples fromthe manual evaluation are shown in Fig.
2.Along the same lines, a further manual evaluationwas conducted on 500 randomly selected examplesthat were out of coverage of the LFG-based gram-mars.
Across the combined set of 1,000 in-coverageand out-of-coverage sentences, this resulted in anagreed-on preference for the phrase-based systemin 204 cases and for the LFG-based system in 158cases under the measure of translational adequacy.Under the grammaticality measure the phrase-basedsystem was preferred by both judges in 157 casesand the LFG-based system in 136 cases.6 DiscussionThe above presented evaluation of the LFG-basedtranslator shows promising results for examples thatare in coverage of the employed LFG grammars.However, a back-off to robustness techniques inparsing and/or generation results in a considerable253(1) src: in diesem fall werde ich meine verantwortung wahrnehmenref: then i will exercise my responsibilityLFG: in this case i accept my responsibilityP: in this case i shall my responsibilities(2) src: die politische stabilita?t ha?ngt ab von der besserung der lebensbedingungenref: political stability depends upon the improvement of living conditionsLFG: the political stability hinges on the recovery the conditionsP: the political stability is rejects the recovery of the living conditions(3) src: und schlie?lich mu?
dieser agentur eine kritische haltung gegenu?ber der kommission selbst erlaubt seinref: moreover the agency must be able to criticise the commission itselfLFG: and even to the commission a critical stance must finally be allowed this agencyP: finally this is a critical attitude towards the commission itself to be agency(4) src: nach der ratifizierung werden co2 emissionen ihren preis habenref: after ratification co2 emission will have a price tagLFG: carbon dioxide emissions have its price following the ratificationP: after the ratification co2 emissions are a price(5) src: die lebensmittel mu?ssen die sichere erna?hrung des menschen gewa?hrleistenref: man?s food must be safe to eatLFG: food must guarantee the safe nutrition of the peopleP: the people of the nutrition safe food must guarantee(6) src: was wir morgen beschlie?en werden ist letztlich material fu?r das vermittlungsverfahrenref: whatever we agree tomorrow will ultimately have to go into the conciliation procedureLFG: one tomorrow we approved what is ultimately material for the conciliation procedureP: what we decide tomorrow is ultimately material for the conciliation procedure(7) src: die verwaltung mu?
ku?nftig schneller reagieren ko?nnenref: in future the administration must be able to react more quicklyLFG: more in future the administration must be able to reactP: the administration must be able to react more quickly(8) src: das ist jetzt u?ber 40 jahre herref: that was over 40 years agoLFG: on 40 years ago it is nowP: that is now over 40 years ago(9) src: das ist schon eine seltsame vorstellung von gleichheitref: a strange notion of equalityLFG: equality that is even a strange ideaP: this is already a strange idea of equality(10) src: frau pra?sidentin ich beglu?ckwu?nsche herrn nicholson zu seinem ausgezeichneten berichtref: madam president i congratulate mr nicholson on his excellent reportLFG: madam president i congratulate mister nicholson on his report excellentedP: madam president i congratulate mr nicholson for his excellent reportFigure 2: Examples from manual evaluation: Preference for LFG-based system (LFG) over phrase-based system (P) under bothadequacy and grammaticality (ex 1-5), preference of phrased-based system over LFG (6-10) , together with source (src) sentencesand human reference (ref) translations.
All ratings are agreed on by both judges.loss in translation quality.
The high percentage ofexamples that fall out of coverage of the LFG-based system can partially be explained by the ac-cumulation of errors in parsing the training datawhere source and target language parser each pro-duce FRAGMENT parses in 20% of the cases.
To-gether with errors in rule extraction, this results ina large number ill-formed transfer rules that forcethe generator to back-off to robustness techniques.In applying the parse-transfer-generation pipeline totranslating unseen text, parsing errors can cause er-roneous transfer, which can result in generation er-rors.
Similar effects can be observed for errors intranslating in-coverage examples.
Here disambigua-tion errors in parsing and transfer propagate throughthe system, producing suboptimal translations.
Anerror analysis on 100 suboptimal in-coverage exam-ples from the development set showed that 69 sub-optimal translations were due to transfer errors, 10of which were due to errors in parsing.The discrepancy between NIST scores and man-ual preference rankings can be explained on the onehand by the suboptimal integration of transfer andgeneration in our system, making it infeasible towork with large n-best lists in training and applica-tion.
Moreover, despite our use of minimum-error-254rate training and n-gram language models, our sys-tem cannot be adjusted to maximize n-gram scoreson reference translation in the same way as phrase-based systems since statistical ordering models areemployed in our framework after grammar-basedgeneration, thus giving preference to grammatical-ity over similarity to reference translations.7 ConclusionWe presented an SMT model that marries phrase-based SMT with traditional grammar-based MTby incorporating a grammar-based generator into adependency-based SMT system.
Under the NISTmeasure, we achieve results in the range of thestate-of-the-art phrase-based system of Koehn etal.
(2003) for in-coverage examples of the LFG-based system.
A manual evaluation of a large setof such examples shows that on in-coverage ex-amples our system achieves significant improve-ments in grammaticality and also translational ad-equacy over the phrase-based system.
Fortunately,it is determinable when our system is in-coverage,which opens the possibility for a hybrid system thatachieves improved grammaticality at state-of-the-arttranslation quality.
Future work thus will concen-trate on improvements of in-coverage translationse.g., by stochastic generation.
Furthermore, we in-tend to apply our system to other language pairs andlarger data sets.AcknowledgementsWe would like to thank Sabine Blum for her invalu-able help with the manual evaluation.ReferencesMiriam Butt, Helge Dyvik, Tracy Holloway King, Hiroshi Ma-suichi, and Christian Rohrer.
2002.
The parallel grammarproject.
COLING?02, Workshop on Grammar Engineeringand Evaluation.Eugene Charniak, Kevin Knight, and Kenji Yamada.
2003.Syntax-based language models for statistical machine trans-lation.
MT Summit IX.David Chiang.
2005.
A hierarchical phrase-based model forstatistical machine translation.
ACL?05.Paul R. Cohen.
1995.
Empirical Methods for Artificial Intelli-gence.
The MIT Press.Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005.Clause restructuring for statistical machine translation.ACL?05.Yuan Ding and Martha Palmer.
2005.
Machine translationusing probabilistic synchronous dependency insertion gram-mars.
ACL?05.George Doddington.
2002.
Automatic evaluation of ma-chine translation quality using n-gram co-occurrence statis-tics.
ARPA Workshop on Human Language Technology.Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003.
Sta-tistical phrase-based translation.
HLT-NAACL?03.Philipp Koehn.
2004.
Pharaoh: A beam search decoder forphrase-based statistical machine translation models.
Usermanual.
Technical report, USC ISI.Dekang Lin.
2004.
A path-based transfer model for statisticalmachine translation.
COLING?04.Arul Menezes and Stephen D. Richardson.
2001.
A best-first alignment algorithm for automatic extraction of transfer-mappings from bilingual corpora.
Workshop on Data-Driven Machine Translation.Eric W. Noreen.
1989.
Computer Intensive Methods for TestingHypotheses.
An Introduction.
Wiley.Franz Josef Och, Christoph Tillmann, and Hermann Ney.
1999.Improved alignment models for statistical machine transla-tion.
EMNLP?99.Franz Josef Och.
2003.
Minimum error rate training in statisti-cal machine translation.
HLT-NAACL?03.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2001.
Bleu: a method for automatic evaluation of ma-chine translation.
Technical Report IBM RC22176 (W0190-022).Chris Quirk, Arul Menezes, and Colin Cherry.
2005.
De-pendency treelet translation: Syntactically informed phrasalSMT.
ACL?05.Stefan Riezler and John Maxwell.
2005.
On some pitfalls inautomatic evaluation and significance testing for mt.
ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measuresfor MT and/or Summarization.Stefan Riezler, Tracy H. King, Ronald M. Kaplan, RichardCrouch, John T. Maxwell, and Mark Johnson.
2002.
Parsingthe Wall Street Journal using a Lexical-Functional Grammarand discriminative estimation techniques.
ACL?02.Stefan Riezler, Tracy H. King, Richard Crouch, and Annie Za-enen.
2003.
Statistical sentence condensation using am-biguity packing and stochastic disambiguation methods forlexical-functional grammar.
HLT-NAACL?03.Andreas Stolcke.
2002.
SRILM - an extensible language mod-eling toolkit.
International Conference on Spoken LanguageProcessing.Fei Xia and Michael McCord.
2004.
Improving a statistical mtsystem with automatically learned rewrite patterns.
COL-ING?04.255
