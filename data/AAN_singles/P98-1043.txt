Alignment of Multiple Languages for Historical ComparisonMichael A. CovingtonArtificial Intelligence CenterThe University of GeorgiaAthens, GA 30602-7415 U.S.A.mc@uga.eduAbstractAn  essential step in comparative reconstructionis to align corresponding phonological segmentsin the words being compared.
To do this, onemust search among huge numbers of potentialalignments to find those that give a good pho-netic fit.
This is a hard computational prob-lem, and it becomes exponentially more difficultwhen more than two strings are being aligned.In this paper I extend the guided-search align-ment algorithm of Covington (ComputationalLinguistics, 1996) to handle more than twostrings.
The resulting algorithm has been im-plemented in Prolog and gives reasonable r sultswhen tested on data from several languages.1 BackgroundThe Comparative Method for reconstructinglanguages consists of at least the following steps:1.
Choose sets of words in the daughter lan-guages that appear to be cognate;2.
Align the phonological segments that ap-pear to correspond (e.g., skip the \[k\] whenaligning German \[kn~ with English \[niy\]'knee'); 13.
Find regular correspondence s ts (proto-allophones, Hoenigswald 1950);4.
Classify the proto-allophones into proto-phonemes with phonological rules (soundlaws).The results of each step can be used to refineguesses made at previous steps.
For example,IThese phonetic transcriptions may nor may not bephonemic.
Because of the way the Comparative Methodworks, synchronic aUophony is, in general, factored outalong with diachronic allophony as the reconstructionproceeds.275a regular correspondence, once discovered, canbe used to refine one's choice of alignments andeven putative cognates.Parts of the Comparative Method have beencomputerized by Frantz (1970), Hewson (1974),Wimbish (1989), and Lowe and Mazandon(1994), but none of them have tackled the align-ment step.
Covington (1996) presents a work-able alignment algorithm for comparing two lan-guages.
In this paper I extend that algorithm tohandle more than two languages at once.2 Multiple-string alignmentThe alignment step is hard to automate be-cause there are too many possible alignmentsto choose from.
For example, French le \[l~\] andSpanish el \[el I can be lined up at least threeways:e l  e l -  -e l12 -1~ 12-Of these, the second is etymologically correct,and the third would merit consideration if onedid not know the etymology.The number of alignments rises exponentiallywith the length of the strings and the numberof strings being aligned.
Two ten-letter stringshave anywhere from 26,797 to 8,079,453 differ-ent alignments depending on exactly what align-ments are considered istinct (Covington 1996,Covington and Canfield 1996).
As for multiplestrings, if two strings have A alignments thenn strings have roughly A '~-1 alignments, assum-ing the alignments are generated by aligning thefirst two strings, then aligning the third stringagainst the second, and so forth.
In fact, thesearch space isn't quite that large because somecombinations are equivalent to others, but it isclearly too large to search exhaustively.Table 1: Evaluation metric used by Covington(1996).Badness1030601004050ConditionsExact match of consonants or glidesExact match of vowels (nonzero so thealigner will prefer to match consonants,given a choice)Match of 2 vowels that differ only inlength, or \[i\] and \[y\], or \[u\] and \[w\]Match of 2 dissimilar vowelsMatch of 2 dissimilar consonantsMatch of 2 unrelated segmentsSkip preceded by another skip in thesame stringSkip not preceded by another skip inthe same stringFortunately the comparative linguist is notlooking for all possible alignments, only the onesthat are likely to manifest regular sound corre-spondences - that is, those with a reasonabledegree of phonetic similarity.
Thus, phoneticsimilarity can be used to constrain the search.3 App ly ing  an  eva luat ion  metr i cThe phonetic similarity criterion used by Cov-ington (1996) is shown in Table 1.
It is obviouslyjust a stand-in for a more sophisticated, per-haps feature-based, system of phonology.
Thealgorithm computes a "badness" or "penalty" foreach step (column) in the alignment, summingthe values to judge the badness of the wholealignment, thus:e 11 oi00 + i00 -- 200e 1 -150 + 0 + 50 = i00The alignment with the lowest total badness isthe one with the greatest phonetic similarity.Note that two separate skips count exactly thesame as one complete mismatch; thus the align-mentse -e1 l -are equally valued.
In fact, a "no-alternating-skips rule" prevents the second one from beinggenerated; deciding whether \[e\] and \[I\] corre-spond is left for another, unstated, part of thecomparison process.
I will explain below whythis is not satisfactory.Naturally, the alignment with the best overallphonetic similarity is not always the etymolog-ically correct one, although it is usually close;we are looking for a good phonetic fit, not nec-essarily the best one.4 Genera l i z ing  to  th ree  or  morelanguagesWhen a guided search is involved, aligningstrings from three or more languages is not sim-ply a matter of finding the best alignment ofthe first two, then adding a third, and then afourth, and so on.
Thus, an algorithm to aligntwo strings cannot be used iteratively to alignmore than two.The reason is that the best overall alignmentof three or more strings is not necessarily thebest alignment of any given pair in the set.
Fox(1995:68) gives a striking example, originallyfrom Haas (1969).
The best alignment of theChoctaw and Cree words for 'squirrel' appearsto be:Choctaw fan iCree - i !uHere the correspondence \[a\]:\[i\] is problematic.Add the Koasati word, though, and it becomesclear that the correct alignment is actually:Choctaw - fan iKoasati i p - !
uCree i - - l uoAny algorithm that started by finding the bestalignment of Choctaw against Cree would missthis solution.A much better strategy is to evaluate ach col-umn of the alignment (I'll call it a "step") beforegenerating the next column.
That is, evaluatethe first step,and then the second step,276fPand so on.
At each step, the total badness iscomputed by comparing each segment to all ofthe other segments.
Thus the total badness ofabCis badness(a, b) + badness(b, c) + badness(a, c).That way, no string gets aligned against anotherwithout considering the rest of the strings in theset.Another detail has to do with skips.
Empiri-cally, I found that the badness offPcomes out too high if computed asbadness(f,p) + badness(p,-) + badness(f,-);that is, the algorithm is too reluctant o takeskips.
The reason, intuitively, is that in thisalignment step, there is really only one skip,not two separate skips (one skipping If\] andone skipping \[p\]).
This becomes even moreapparent when more than three strings arebeing aligned.Accordingly, when computing badness I counteach skip only once (assessing it 50 points),then ignore skips when comparing the segmentsagainst each other.
I have not implemented therule from Covington (1996) that gives a reducedpenalty for adjacent skips in the same string toreflect the fact that affixes tend to be contigu-ous.5 Search ing  the  set  o f  a l ignmentsThe standard way to find the best alignment oftwo strings is a matrix-based technique knownas dynamic programming (Ukkonen 1985, Wa-terman 1995).
However, dynamic program-ming cannot accommodate rules that look aheadalong the string to recognize assimilation ormetathesis, a possibility that needs to be leftopen when implementing comparative recon-struction.
Additionally, generalization of dy-namic programming to multiple strings does notentirely appear to be a solved problem (cf.
Ke-cecioglu 1993).Accordingly, I follow Covington (1996) in re-casting the problem as a tree search.
Considerthe problem of aligning \[el\] with \[le\].
Coving-ton (1996) treats this as a process that stepsthrough both strings and, at each step, per-forms either a "match" (accepting a characterfrom both strings), a "skip-l" (skipping a char-acter in the first string), or a "skip-2" (skippinga character in the second string).
That resultsin the search tree shown in Fig.
1 (ignoring Cov-ington's "no-alternating-skips rule").The search tree can be generalized to multiplestrings by breaking up each step into a seriesof operations, one on each string, as shown inFig.
2.
Instead of three choices, match, skip-l,and skip-2, there are really 2x2: accept or skipon string 1 and then accept or skip on string2.
One of the four combinations i  disallowed -you can't have a step in which no characters areaccepted from any string.Similarly, if there were three strings, therewould be three two-way decisions, leading toeight (= 2 3) states, one of which would be dis-allowed.
Using search trees of this type, the de-cisions necessary to align any number of stringscan be strung together in a satisfactory way.6 A l te rnat ing  sk ipsCovington (1996) considers the alignmentse -e1 1 -equivalent and generates only the first of them,leaving it to some later step in the comparisonprocess to decide whether \[e\] and \[1\] really cor-respond.
The rule is:NO-ALTERNATING-SKIPS RULE: If  there isa skip in one string, there cannot be a skipin the other string at the next step.Although this tactic narrows the search space,I do not think this is linguistically satisfactory;after all, aligning \[el with \[1\] and skipping themin tandem are quite different linguistic claims.Consider for example the final segment of Span-ish \[dos\] and Italian \[due\] 'two'; it is correct toskip the \[s\] and the \[e\] in tandem because theycome from different Latin endings.
It is not his-torically correct to pair Is\] with \[e\] in a corre-spondence set.277Startro l /sk,p oo ro-1 LIoJLJ ~" ,~ng l  string2 L J\ \~,';,i~?
;\ ro :::Situations where onlyone move is possiblestring 2 oS,,,on E;'-;1 string 1Analogousto aboveFigure 1: Part of a 3-way-branching search tree for generating potential alignments (Covington1996, ignoring no-alternating-skips rule).StartAccept ~\[e l \ ]Accept \[ ?\] \ ] J U  oJ,,oce,:, .
\ [o \ ]<.
- - J -  k'J ~<,~C~--~_F~.I.._ ,.
'-J ,~,<,,:, ;,\]rl<" / ~<,-;~..~\[~_\]_.. Ll.~Processing Processing Processing Processing Processingstring 1 string 2 string I string 2 string 1...I I I I IStep 1 Step 2 Step 3...Figure 2: Search tree factored into 2-way branchings with a disallowed state at each step.
This treegeneralizes to handle more than 2 strings.278Also, the no-alternating-skips rule does notgeneralize asily to multiple strings.
I thereforereplace it with a different restriction:ORDERED-ALTERNATING-SKIPS RULE: Askip can be taken in strings i and j in suc-cessive steps only if i ~_ j.That lets us generate- e (String 1)1 - (String 2)but note --1which is undeniably equivalent.
It also ensuresthat there is only one way of skipping severalconsecutive segments; we get- - -abcde f -  - -but not-a -b -c  abc - - -d -e - f  .
.
.
.
de for numerous other equivalent combinations ofskips.7 P run ing  the  searchThe goal of the algorithm is, of course, to gen-erate not the whole search tree, but only theparts of it likely to contain the best alignments,thereby narrowing the intractably large searchspace into something manageable.Following Covington (1996), I implementeda very simple pruning strategy.
The programkeeps track of the badness of the best completealignment found so far.
Every branch in thesearch tree is abandoned as soon as its total bad-ness exceeds that value.
Thus, bad alignmentsare abandoned when they have only partly beengenerated.A second part of the strategy is that the com-puter always tries matches before it tries skips.As a result, if not much material needs to beskipped, a good alignment is found very quickly.For example, three four-character strings have10,536 alignments (generated my way), butwhen comparing Spanish tres, French trois, andTable 2: Some alignments found by the proto-type program.Spanish/Italian/French 't ree':t r -est r -e -t rwa-Spanish/Italian/French 'four':kwa - t r okwat  t rok -a - t r -Spanish/Italian/French 'five':0 i~k-oc iokwes~-k -  -Koasati / Cree / Choctaw 'squirrel':ip - !ui - - !u- fan iEnglish three, 2 the algorithm finds its "best"alignment,t r -est rwa-0 r - iyafter completing only ten other alignments, al-though it also pursues everal hundred branchesof the tree part of the way.
(Here the match of \[s\]with \[y\] is problematic, but the computer can'tknow that; it also finds a number of alternativealignments.
)8 Resu l ts  and  eva luat ionThe algorithm has been prototyped in LPA Pro-log, and Table 2 shows some of the alignmentsit found.
None of these took more than five sec-onds on a 133-MHz Pentium, and the Prologprogram was written for versatility, not speed.As comparative linguists know, the alignmentthat gives the best phonetic fit (by any crite-rion) is not always the etymologically correctone.
This is evident with my algorithm.
For2Admittedly an odd set to compare because of thedifferent depth of branching, but they are cognates andeach has four segments.279instance, comparing the Sanskrit, Greek, andLatin words for 'field,' the algorithm finds thecorrect alignment,ager - -ag - rosa\]-ras (badness = 365)but then discards it in favor of a seemingly bet-ter alignment:ager - -ag - rosa- \ ] ras  (badness = 345)It doesn't know, of course, that \[g\]:\[\]\] is a pho-netically probable correspondence.Worse, occasionally the present algorithmdoesn't consider the etymologically correctalignment at all because something that looksbetter has already been found.
For example,taking the Avestan, Greek, and Latin words for'100', the algorithm settles on- - sa tomhekatonken- tum (badness 610)without ever considering the etymologically cor-rect alignment:- - sa - tomheka- ton- -kentum (badness 690)The penalties for skips may still be too highhere, but the real problem is, of course, that thealgorithm is looking for the one best alignment,and that's not what comparative r constructionneeds.
Instead, the computer should prune thesearch tree less eagerly, pursuing any alignmentwhose badness is, say, no more than 120% ofthe lowest found so far, and delivering all solu-tions that are reasonably close to the best onefound during the entire procedure.
Indeed, theavailability of multiple potential alignments ithe keystone of Kay's (1964) proposal to imple-ment the Comparative Method, which could notbe implemented at the time Kay proposed it be-cause of the lack of an efficient search algorithm.The requisite modification is easily made and Iplan to pursue it in subsequent work.ReferencesCovington, Michael A.
(1996) An algorithm toalign words for historical comparison.
Com-putational linguistics 22:481-496.Covington, Michael A., and Canfield, E. Rodney(1996) The number of distinct alignments oftwo strings.
Unpublished manuscript, Univer-sity of Georgia.Fox, Anthony (1995) Linguistic reconstruction:an introduction to theory and method.
Oxford:Oxford University Press.Frantz, Donald G. (1970) A PL/1 program toassist the comparative linguist.
Communica-tions of the ACM 13:353-356.Haas, Mary R. (1969) The prehistory of lan-guages.
The Hague: Mouton.Hewson, John (1974) Comparative reconstruc-tion on the computer.
John M. Anderson andCharles Jones, eds., Historical linguistics I:syntax, morphology, internal and comparativereconstruction, 191-197.
Amsterdam: NorthHolland.Hoenigswald, Henry (1950) The principal stepin comparative grammar.
Language 26:357-364.
Reprinted in Martin Joos, ed., Readingsin Linguistics I, 4th ed., 298-302.
Chicago:University of Chicago Press, 1966.Kay, Martin (1964) The logic of cognate rcog-nition in historical linguistics.
(MemorandumRM-4224-PR.)
Santa Monica: The RANDCorporation.Kececioglu, John (1993) The maximum weighttrace problem in multiple sequence alignment.Combinatorial pattern matching: 4th annualsymposium, ed.
A. Apostolico et al, 106-119.Berlin: Springer.Lowe, John B., and Mazaudon, Martine (1994)The Reconstruction Engine: a computer im-plementation of the comparative method.Computational Linguistics 20:381-417.Ukkonen, Esko (1985) Algorithms for approxi-mate string matching.
Information and Con-trol 64:100-118.Waterman, Michael S. (1995) Introduction tocomputational biology: maps, sequences andgenomes.
London: Chapman & Hall.Wimbish, John S. (1989) WORDSURV: a pro-gram for analyzing language survey word lists.Dallas: Summer Institute of Linguistics.280
