Conversational ImplicaturesRobert van RooyInstitute for Logic, Language and ComputationUniversity of AmsterdamNieuwe Doelenstraat 15, 1012 CP Amsterdamvanrooy@hum.uva.nlAbstractAccording to standard pragmat-ics, we should account for conver-sational implicatures in terms ofGrice's (1975) maxims of conversa-tion.
Neo-Griceans like Atlas &Levinson (1981) and Horn (1984)seek to reduce those maxims to theso-called Q and I-principles.
Inthis paper I want to argue that (i)there are major problems for reduc-ing Gricean pragmatics to these twoprinciples, and (ii) that, in fact, we'dbetter account for implicatures interms of the principles of (a) opti-mal relevance and (b) optimal cod-ing.
To formulate both, I will makeuse of Shannon's (1948) mathemat-ical theory of communication.1 IntroductionNatural language is e?cient in the sense thata single message can convey dierent seman-tic contents in dierent contexts.
And indeed,recent trends in semantics (e.g.
optimalitytheoretic semantics) suggest that the actualinterpretation of an utterance is highly un-derspecied by the conventional meanings ofthe sentence that is used.
This requires, how-ever, that language users have robust waysto resolve the underspecication and/or am-biguity.
In this paper I will discuss two waysThis research has been made possible by a fellow-ship of the Royal Netherlands Academy of Arts andSciences.of doing this.
First, one where the particularconversational situation is important; second,one which depends on more general conven-tions.2 The Q and I principleNeo-Gricean pragmatics seeks to reduceGrice's maxims of conversation to the so-called Q and I principles.
Both are usedto account for many conversational implica-tures.
The Q-principle (implementing Grice'srst maxim of Quantity) advises the speakerto say as much as he can to fulll his com-municative goals, while the I-principle (im-plementing Grice's other maxims, except forquality) advises the speaker to say no morethan he must to fulll these goals.
Both prin-ciples help to strengthen what is communi-cated by a sentence.
The Q-principle inducesinferences from the use of one expression tothe assumption that the speaker did not in-tend to communicate a contrasting, and in-formationally stronger, one.
This principleis thus essentially metalinguistic in kind, andaccounts for both `scalar' and `clausal' impli-catures.
It allows us, for instance, to concludefrom \John ate some of the cookies" to \Johndidn't eat all of the cookies" (scalar implica-ture), and from \A or B" to \A or B, but notboth" (clausal + scalar implicature).
The I-principle allows us to infer from the use of anexpression to its most informative or stereo-typical interpretation.
It is used, for instance,to enrich the interpretation of a conjunctionto a temporal sequential, or causal, relation,and it allows us to interpret a conditional like`John walks, if Mary walks' as the bicondi-tional `John walks if and only Mary walks'.3 Problems for the Q and Iprinciples3.1 Too generalAlthough the Q and I principles are intu-itively appealing, they give rise to a num-ber of conceptual and empirical problems.Let's start with some cases where it is pre-dicted that Q-implicatures arise, although infact they don't.
First, at least when imple-mented as Gazdar (1979) did, we can derivefrom the existential \Someone is sick" as aQ-implicature that (the speaker knows that)a is not sick, for any individual a. Second,on the assumption that scales are dened interms of entailment, it is predicted that wecan infer from `B, if A' to the conclusion thatit is not the case that the stronger `B if andonly if A' holds, although in a lot of situa-tions this is exactly what we can conclude.Third, on the same assumption, it is incor-rectly predicted that we can infer `not regretA' from `know A'.
Horn, Levinson and oth-ers have argued that these problems can beprevented by (i) weakening the force of Q-implicatures from know-not to not-know (forthe rst problem), and by putting constraintson what counts as contrastive expressions:contrastive expressions must be lexical items(second problem) and must have the samepresuppositions (for the third).
Although itcan be argued that for the biconditional in-terpretation this { somewhat ad hoc { solu-tion solves the second problem, Gazdar (1979)argued that the constraints doesn't solve thethird one.
Moreover, the most serious prob-lematic cases where Q-implicatures overgen-erate cannot be explained away in this way:The Horn/Gazdar/Levinson/Atlas analysis ofQ-implicatures as generalized conversationalimplicatures (PCIs) triggered solely by lexi-cal expressions cannot explain why from A'sanswer \John has 2 children" to Q's question\Who has 2 children?"
the implicature \Johnhas only 2 children" does not even arise as adefault (cf.
van Kuppevelt).
This latter ex-ample seems to suggest that these so-calledQ-implicatures are, after all, dependent onthe conversational situation, in particular onthe question being asked.
Proponents of theQ and I pragmatics (Horn, Levinson), fol-lowed by Matsumoto (1995), argue that insuch particular conversational situations thegeneralized conversational implicature is can-celled, for reasons of relevance: The answeris already informative enough for the purposeof the conversation.
I will argue, however,that informativity is, in general, not the cru-cial issue, and that it is much more natural toassume that { for reasons of relevance in thisparticular situation { the (potential) implica-ture does not even arise.3.2 Not general enoughNot only does the standard analysis of Q-implicatures overgeneralize, it also doesn'tseem to be general enough.
First, as discussedextensively by Hirschberg (1985), the stan-dard analysis is of no help to account for cer-tain examples that intuitively should be an-alyzed as scalar implicatures.
If Mary's po-tential new boss asks her at her job-interviewwhether she speaks French, and she answersby saying \My sister does", he can concludethat Mary herself does not.
The standardanalysis fails to account for this, because (a)scalar implicatures are all analyzed in terms ofthe Q-principle, (b) the Q-principle is statedin terms of informativity, but (c) the propo-sition that Mary speaks French is not moreinformative (i.e.
entails) than the proposi-tion that her sister does.
This example sug-gests (i) that scalar implicatures should notexclusively be accounted for in terms of infor-mativity, and (ii) that just like in the previ-ous example, also here the relevant implica-ture crucially depends on the conversationalsituation (i.e.
the beliefs and preferences ofthe agents involved).
Second, as discussed byMcCawley (1993), the implicatures generatedby the hand, ori scale cannot account for thefact that a sentence of the form `A or B orC' gives rise to the inference that only one ofthe three is true.
A nal example where thestandard analysis of Q-implicatures isn't gen-eral enough was discussed by Groenendijk &Stokhof (1984).
They observe that when Aanswers Q's question \Who comes?"
by say-ing \Peter comes", we typically interpret theanswer as being exhaustive.
That is, we inter-pret A's answer as \Only Peter comes".
Theyclaim that this kind of inference should intu-itively be accounted for in terms of Grice'smaxim of Quantity (as a Q-implicature), butnote that the standard implementation doesnot predict the exhaustivity of the answer.Still, it seems that the exhaustive interpre-tation of the answer should be derived byGricean pragmatics on the assumption thatanswers are as informative as the question re-quires.I conclude that the scales relevant for theimplicatures depend on the conversational sit-uation (i.e.
question asked) and the beliefsand preferences of the agents involved is incorrespondence with Hirschberg's claim thatscales are dependent on context.
However, wewould like to say something more; we wouldalso like to say how the relevant scale dependson the question asked and the relevant beliefsand desires.4 RelevanceIn this respect, important progress has beenmade recently by Merin (1997).
Following thelead of Anscombre & Ducrot (1983), Merin ar-gues that scales should be dened not in termsof informativity, but rather in terms of a no-tion of relevance.
The relevance of a propo-sition is determined in terms of the argu-mentative force the proposition would have inthat particular conversational situation.
Therelevance of an assertion is then dened ininformation/decision/game theoretical terms,based on the assumption that the partici-pants of the conversation have strictly oppos-ing preferences, i.e.
that the participants playa zero-sum game.Although Merin convincingly shows thatsome scalar implicatures (in particular theHirschberg examples) can be accounted forappropriately on the assumption that play-ers argue for particular hypotheses, and thattheir contribution should be interpreted in themost relevant way (i.e.
strongest argument),it is intuitively clear that not all conversa-tions can, and should, be modeled as zero-sumgames.
It makes little sense, for instance, toassume that the exhaustive interpretation of\John has 2 children" as answer to the ques-tion \How many children does John have?
"can be explained in terms of opposing pref-erences between questioner and answerer, forthe latter typically cooperates with the for-mer.
What is called for, then, is a gener-alization of Merin's notion of relevance thatalso measures the relevance of propositionsin cooperative conversational situations.
Itseems only natural, on the assumption thatspeakers are relevance optimizers, that oncewe can dene such a measure, not only thetypical Q-implicatures can be accounted for interms of relevance, but also the I-implicaturesfrom conditional to biconditional, and Groe-nendijk & Stokhof's (1984) observation thatanswers are normally interpreted in an ex-haustive way.
As we will see in the next sec-tion, Groenendijk & Stokhof (1984) show thatalmost all typical Q-implicatures can be an-alyzed alternatively in terms of their explicitexhaustivity-operator, without giving rise tothe above discussed overgeneralizations, whenthe clause that gives rise to the implicature isused as an answer to a question.5 Exhaustied answersGroenendijk & Stokhof (1984) propose to ac-count for the intuition that answer Petercomes to question Who comes?
should nor-mally be read exhaustively by introducing anexplicit exhaustivity operator that is appliedto answers and the abstracts underlying thequestions to derive the exhaustive interpreta-tion.exh = RP [R(P )^:9P0[R(P0)^P 6=P0^ 8x[P0(x) !
P (x)]]]This exhaustivity operator accounts formany of the implicatures traditionally ac-counted for in terms of Grice's maxim ofquantity.
First, it obviously accounts for thefact that when Who comes?
is answered byJohn we conclude that only John comes.
Sec-ond, when answer A man is given we can con-clude that not all men come, an implicaturestandardly triggered by the hall, somei scale.In contrast to Gazdar's analysis of scalar im-plicatures, however, our analysis does not giverise to the wrong prediction that John is notcoming: the exhaustive reading of A man iscoming as answer to question Who comes?
iscompatible with the fact that John is.
Notethat this analysis, in distinction with the stan-dard analysis of scalar implicatures, worksalso well when more than one item gives riseto an implicature.
From the exhaustive inter-pretation of the term Some of the bacon andsome of the eggs given as answer to the ques-tion What did Mary ate?
we can concludethat Mary didn't eat all of the bacon, andthat she didn't eat all of the beans, just likewe should.Notice that our exhaustication analysisnot only predicts intuitions standardly ac-counted for in terms of the Q principle; alsosome I-implicatures are accounted for.
If thequestion is Who quacks?
the answer Everyduck quacks is predicted to mean that everyquacker is a duck.
Horn (2000) calls this in-ference conversion and explicitly proposes toaccount for it in terms of the I-principle.Similarly, if we allow for explicit quanti-cation over worlds, we can account for the in-ference from (1b) to (1c), when the former isgiven as answer to (1a):(1) a. Q: Did John walk?b.
A: If Mary talked.c.
John walked i Mary talked.We assume that the property underlyinga question like (1a) is w:Walk(j)(w), andthat answer (1b) should be represented byP:8w[Talk(m)(w) !
P (w)] which after ex-haustication means that Mary talked iJohn walked.11This inference is accounted for by Groenendijk &Stokhof (1984) in terms of their generalized exhaustiv-ity operator without using explicit quantication overworlds.
Such an analysis cannot account, however,for the exclusive reading of disjunctive sentences withmore than two disjuncts, to be discussed below.Our approach also predicts that (2a) shouldbe read as (2b) when the color of theag isat issue.
(2) a. Theag is red.b.
Theag is all red.This inference is normally (e.g.
Atlas &Levinson, 1981) accounted for by assumingthat (2a) should be interpreted as informativeas possible.
But then it should be explainedwhy in certain circumstances the inference isabsent.
When 3ags are mutually known byus to be all white except for a small block ofsome other distinguishing color (being eitherred, yellow or green), and I ask you to identifytheag you hold behind your back, your an-swer (2a) satises me, and I do not imply that(2b) is true.
The standard analysis has to as-sume that in these cases the triggered general-ized implicature are cancelled, while we don'teven generate the implicature because we canassume that the implicit question was some-thing like What is the color of the small block?Indeed, our topic-dependent analysis of`scalar' implicatures prevents us from trig-gering implicatures to be cancelled later forreasons of relevance (see also van Kuppevelt(1997) and Carstyn (ms)).
Consider the fol-lowing example again:(3) a. Q: Who has 2 children?b.
A: John has 2 children.c.
John doesn't have more than 2 chil-dren.Instead of saying that (3b) triggers the po-tential implicature (3c) that is cancelled whenthe former is given as answer to question (3a),our analysis predicts that the implicature isnot even triggered, because (3b) completelyanswers (3a).A similar analysis can be given for the factthat a disjunctive sentence sometimes gets anexclusive reading and sometimes not.
If weallow for explicit quantication over worlds,we can represent an answer like A or B orC in terms of an existential quantier as fol-lows: P:9w[(A(w)_B(w)_C(w))^P (w)].
Ifwe now assume that this sentence is given asanswer to the question `What proposition(s)is/are true?
', exhaustivity has the eect thatonly worlds count that make just one of thethree propositions true, resulting in the ex-clusive reading.However, this analysis does not have the re-sult that a disjunctive sentence should alwayshave the exclusive reading.
In particular thisis rightly predicted not to be the case in (4),where the complex sentence is given as an (ex-haustive) polar answer:(4) Q: Are the cookies or the chocolates inthe box?A: Yes, the cookies or the chocolates arein the box.Something similar is the case with condi-tional answers.
Also after exhausticationthey don't get a bi-conditional interpretationwhen they are used as complete answers topolar questions:(5) Q: Did John walk, if Mary talked?A: Yes, John walked if Mary talked.6 Relevance and ExhaustivityIn the previous section we have seen thatmany so-called `quantity' implicatures trig-gered by sentences can be accounted for byassuming that these sentences should be in-terpreted as exhaustive answers to questions.However, we would like to say somethingmore; we would also like to give an inde-pendent motivation for why answers shouldnormally be interpreted exhaustively.
Noticethat Groenendijk & Stokhof's (1984) stipu-lation that answers should always be inter-preted exhaustivily would not only be ad hoc,it would also give rise to counterexamples.Most importantly, it would predict incorrectlyfor so-called mention-some questions.
Some-times an assertion intuitively answers a ques-tion completely without being read exhaus-tively.
To illustrate, when I ask you (6a) andyou answer by saying (6b), I am satised, al-though I don't interpret your answer as claim-ing that this is the only place where I can buyan Italian newspaper.
(6) a.
Where can I buy an Italian newspa-per?b.
Around the corner.6.1 Topic dependent relevanceIn cooperative dialogues the relevance of com-municative acts can be determined with re-spect to decision problems (cf.
van Rooy(2001).
A decision problem Using commu-nication theory we can model these decisionproblems by partitions of the logical space {, i.e., the semantic questions of Groenendijk& Stokhof (1984).
One proposition will thenbe more relevant than another when it helpsmore to resolve the question.Intuitively, we would like to say that asser-tions are relevant with respect to this decisionproblem if the decision is easier to make af-ter an assertion is learned.
But to accountfor this, we have to measure the di?culty ofthe decision.
A standard way to do this is interms of entropy.Given a probability function P , we can de-ne the entropy of decision problem Q as fol-lows:E(Q) =Xq2QP (q) log2P (q)When our agent learns proposition A, wecan determine the entropy of decision prob-lem Q conditional on learning A, EA(Q), asfollows:EA(Q) =Xq2QP (q=A)  log2P (q=A)In terms of this notion we can now dene whatmight be called the Relevance of propositionA, with respect to partition Q, RQ(A), asthe reduction of entropy, or uncertainty, ofQ when A is learned:2RQ(A) = E(Q) EA(Q)Relevance will be used to determine the ac-tual interpretation of a sentence underspeci-ed by its conventional meaning.
We will say2This notion was used by Lindley (1956) already tomeasure the informational value of a particular resultof an experiment.that interpretation A is better than interpre-tation B, A > B, i RQ(A) > RQ(B) withrespect to all probability functions for whichQ has maximal entropy.It might be, of course, that for some proba-bility distributions A is better, while for oth-ers B is.
Which one is then preferred?
Inthose cases, I propose, interpretation A is bet-ter if the sentence `gives rise' to a new ques-tion, Q0, which is orthogonal to Q, such thatafter learning A, but not after learning B, ev-ery complete answer to Q0also completely an-swers Q.
This indirect notion of relevance willbe crucial to account for the implicatures ofdisjunctive and conditional sentences.6.2 Why ExhaustifyConsider question (7):(7) Whom of John and Bill are sick?This question gives rise to a partition with4 cells.
Assuming that the probability thatJohn is sick equals the probability that Bill issick, but that the sickness of the one is inde-pendent of the other, it is easy to see that theentropy of the question is 2: the question im-plicitly asks for answers to two independentbinary questions.
Notice that after learningthat (At least) John is sick the entropy of thequestion reduces to 1, which means that therelevance of this answer is 2 - 1 = 1.
Af-ter learning of each of John and Bill whetherthey are sick, however, the question/decisionproblem is resolved: the entropy reduces to 0,and the reduction of entropy, the relevance ofan answer like John and Bill are sick, is 2 -0 = 2.
Thus, for an answer to have maximalrelevance, it should say of each individual inthe domain of quantication whether that in-dividual is sick or not.
It should be obviousthat this means that complete, or exhaustive,answers to questions are always at least asrelevant as partial answers.Now consider answers (8a) and (8b) toquestion (7)(8) a. John is sick.b.
A man is sick.What is the relevance of these answers,i.e., in how far do these answers reduce theentropy of the question?
That depends onhow we interpret them.
If we interpret themnon-exhaustively, the conditional entropy of(7) given (8a) is (P (J ^ B=J)   log2P (J ^B=J))+(P (J^:B=J) log2P (J^:B=J)) =((12 log212)+(12 log212)) =  Log212= 1.Similarly, given that John and Bill are theonly men, the conditional entropy of (7) given(8b) is (P (J ^B=J _B) log2P (J ^B=J _B))+(P (J^:B=J_B) log2(P (J^:B=J_B)) + (P (:J ^ B=J _ B)   log2(P (:J ^B=J _B)) = 3 (13 log213) =  log213< 1.The relevance of these two answers accord-ing to their non-exhaustive interpretation arethus 1 and something less than 1, respec-tively.
What if we interpret the answers ex-haustively?
That is, what is the reductionof entropy if we assume that the propositionsexpressed by the answers are determined af-ter we have applied the exhaustivity operatorto (8a) and (8b), respectively?
After exhaus-tication, answer (8a) really means John issick and Bill is not, and after this informa-tion is received the entropy reduces from 2to 0; its relevance is thus 2.
Similarly, an-swer (8b) really means that either only Johnis sick or that only Bill is sick, and this new in-formation reduces the entropy of the originalquestion from 2 to 1.
The important fact tonote here is that in both cases the reductionof entropy of the answer under its exhaustiveinterpretation is higher than the reduction ofentropy under its non-exhaustive interpreta-tion.
And this is in general the case: mostanswers have a higher relevance on their ex-haustive reading than on their non-exhaustivereading.
On the assumption that speakers arerelevance maximizers this means that in caseanswerers are expected to be cooperative weshould interpret these answers exhaustively.For disjunctive and conditional sentenceswe have to look at our indirect method.
If thequestion is whether A is the case, A?, and theanswer Yes, or B, it might be the case thatthe entropy decreases more on the inclusivereading than on the exclusive reading.
Some-thing similar happens with respect to the con-ditional and biconditional interpretations ofanswer If B.
It is natural to assume, how-ever, that both questions `give rise' to anotherquestion: B?.
Only on the exclusive and bi-conditional interpretation of the two answersevery answer to the second question will alsoresolve the original question whether A is thecase.
For this reason, the exclusive and bi-conditional interpretations are preferred.Above, we have criticized Groenendijk &Stokhof's (1984) assumption that in case an-swers are not explicitly marked as being par-tial answers, we should always read them ex-haustively.
One complaint was that this as-sumption is just an ad hoc stipulation.
Groe-nendijk & Stokhof agree, and explicitly regretthat they see no way to derive exhaustica-tion from the Gricean maxims of conversa-tion, in particular not from Grice's maxim ofquantity.
This complaint can now be met: Ihave shown in this section that we can mo-tivate the assumption that answers shouldbe read exhaustively by deriving it from themuch more general assumption that speakersare relevance optimizers.What about the other complaint I men-tioned earlier?
As noted above, an answer likeAround the corner intuitively resolves ques-tion Where can I buy an Italian newspaper?although it does not suggest that you can buyan Italian newspaper around the corner only.Fortunately, however, also the problematicmention-some phenomena can be accountedfor when we assume that speakers are rele-vance optimizers.
In van Rooy (to appear) Iargue that mention-some questions are asked,or mention-some answers are given, only invery particular circumstances, and show thatin these circumstances the utility, or rele-vance, of mention-some questions/answers co-incide with their mention-all alternatives.
Forreasons of economy, mention-some readingsare in these circumstances preferred.
Wecan conclude that although in normal circum-stances the exhaustive reading of an answer ismore relevant than its non-exhaustive coun-terpart, in special circumstances it is not.
Asa result, we can explain that for reasons of op-timizing relevance, exhaustication does notalways take place.7 Explaining markedness7.1 Horn's division of laborConsider a typical case of communicationwhere two meanings m1and m2can beexpressed by two linguistic representationsr1and r2.
In principle this gives rise totwo possible codings: fhr1;m1i; hr2;m2ig andfhr1;m2i; hr2;m1ig.
In many communicativesituations, however, the underspecicationdoes not really exist, and is resolved due tothe general pragmatic principle that a lighterform will be interpreted by a more salient,or stereotypical, meaning: (i) It is a generaldefeasible principle, for instance, in centeringtheory that if a certain object/expression isreferred to be a pronoun, another more salientobject/expression should be referred to by apronoun too; (ii) Reinhard (1983) and Levin-son (1987) seek to reduce Chomsky's B and Cprinciples of the binding theory to pragmat-ics maxims.
In particular, disjoint referenceof lexical NPs throughout the sentence is ex-plained by pointing to the possibility of theuse of a lighter expression, viz.
an anaphoror pronoun; (iii) The preference for bridging(Clark & Haviland, 1977) and stereotypicalinterpretations (Atlas & Levinson, 1981); (iv)and perhaps most obviously, Horn's (1984) di-vision of pragmatic labor according to whichmarked expression (morphologically complexand less lexicalized) typically get a markedmeaning (cf.
John made the car stop versusJohn stopped the car and consider also the factthat stressed pronouns can pick up less salientobjects).
In neo-Gricean pragmatics proposedby Atlas, Horn and Levinson, this principle isexplained through the interaction of the so-called Q and I principles, and has recentlybeen incorporated in (bi-directional) optimal-ity theory by Blutner (2000) and reformulatedin terms of game theory by Dekker & vanRooy (2000).
However, as we have seen above,explanations based on the Q and I princi-ples are very shaky: these principles tend toclash with one another, and it is not alwaysclear how to resolve this clash.
In particular,it's unclear under which circumstances whichprinciple should be used to explain the phe-nomena.
I will show that by thinking of lan-guage as an e?cient coding system the princi-ple that lighter expressions get a more salientmeaning can be given a straightforward ex-planation.7.2 Optimal coding of informationThe question that started information the-ory was: how can we send messages over achannel as quickly as possible without distor-tion?
The answer is: by looking for the opti-mal coding; to represent the data in a way ascomprehensive as possible.
Suppose we havea source (without memory) that sends mes-sages from a set U = fu1; :::; ung in termsof codes built up from codesymbols belong-ing to the code-alphabet S = fs1; :::; sng.
Asource code, or coding system, C, is dened asa function from U to S, where `' is Kleene'sstar.
For example, C(red) = 00; C(white) =11; C(blue) = 10; C(orange) = 01 is a sourcecode for U = fred, white, blue, orangeg withalphabet S = f0; 1g.
Of course, the sourceand alphabet alow for many dierent codes.Intuitively, however, some codings are moree?cient than others.
What is the best codingsystem?
The coding system with the short-est expected length.
The crucial insight ofShannon (1948) was that this expected lengthdepends not only on the length of the mes-sages after encoding, but also on the proba-bility with which the messages are sent.
Sup-pose that function P assigns numbers to theelements of U such thatPu2UP (u) = 1, i.e.suppose that P is a probability distributionover U .
Suppose, moreover, that l(C(u)) isthe length of the codeword associated with u.In that case, the expected length of a sourcecode C for U and P is given by:L(C) =Xu2UP (u) l(C(u))To illustrate, let us extend our example byassuming that the probability distribution ofU is P (red) =12, P (white) =14, P (blue) =18,P (orange) =18.
Then we can easily seethat the coding C0(red) = 0; C0(white) =10; C0(blue) = 110; C0(orange) = 111 hasa shorter expected length than the codinggiven above: 1.75 to 2.
A crucial dierencebetween the two codings is that in distinc-tion with C, C0does not encode all elementsof U with the same length: the more prob-able elements of U get an encoding with ashorter length.3This holds in general: in caseP (ui) > P (uj) the optimal coding C will besuch that l(C(ui))  l(C(uj)) (cf.
Cover &Thomas, 1991).
Thus, the messages that aremore likely to be sent will be encoded witha smaller length.
This fact can now be usedto account for Horn's division of pragmaticlabor.
Suppose that speakers have the follow-ing set of contents/meanings that they mightwant to communicate: M = fm1; :::;mng.On average, we might assume that the proba-bilities with which they want to communicatethese contents/meanings are correlated withthe probabilities with which these contentsare true: if miis more likely to be the case,or more stereotypical, than mj, the probabil-ity that speakers want to communicate miishigher than that of mj.
In other communica-tive situations the probability with which theelements of M are communicated depends onhow salient the elements of M are.4Speakerscannot send the contents without represent-ing them.
Let us assume that speakers canuse the elements of R (the representations),R = fr1; :::; rkg, to encode the elements of M .The elements of R might be varied: some aremore complex than others.
Codings are nowfunctions from M to R. Just as before we canask: what is the best coding?
Following stan-dards in data comprehension, the answer is:the coding that minimizes average complex-ity.
Average complexity of coding system C3There exists a close connection with entropy too:for coding C0, but not for C, the expected length,L(C0) is equal to the entropy of U , E(U).
It turnsout that this is the optimal one can reach for w.r.t.uniquely decodable codes.
Notice that this meansthat the optimal codelength for each uiis equal to log2P (ui), the surprise value of ui.4In yet others, the probabilities depend even moreon the conversational situation and correlate with rel-evance.is dened as follows:Compl(C) =Xm2MP (m)Compl(C(m))Now it is easy to show that the assump-tion of optimal coding accounts for Horn'sobservation that simple expressions geta salient/stereotypical interpretation, whilecomplex expressions a marked one.
Supposethat the conventional meanings of represen-tations riand rjare such that they bothcould express miand mj.
For instance, withboth words kill and cause to die we could de-note situations of direct (stereotypical) andindirect (marked) killing, and with both un-stressed he and stressed HE we could refer toboth salient and non-salient male individualsin the discourse.
Still, the less complex killwill typically be interpreted as direct stereo-typical killing, an the other way around forcomplex cause to die.
And this follows fromthe assumption that speakers use a languagethat optimally encodes the relevant informa-tion.
In this case we have two relevantly dif-ferent coding systems: C, which assigns mitoriand mjto rj, and C0, which assigns mitorjand mjto ri.
The probabilities and com-plexities are such that P (mi) > P (mj) andCompl(ri) > Comp(rj).
A standard proofshowing that Compl(C0)   Compl(C) > 0demonstrates then that C is a more optimalcoding than C0(where I abbreviate P (mi) bypi, Compl(ri) by cpli, and `' by `'):Compl(C0)  Compl(C) ==Ppi Compl(C0(i))  Ppi Compl(C(i))= (pi cpij)+ (pj cpli)  (pi cpli)  (pj cplj)= (pi  pj)  (cplj  cpli)Because pi pj> 0, C0can only be more opti-mal than C in case cplj cpli< 0.
But this isby assumption not the case, and so C is pre-ferred to C0.
The same proof shows that whenpi pj> 0 the optimal code is such that cplicplj; only then Compl(C0)   Compl(C)  0.Horn's division explained.ReferencesAnscombre J.C. and O. Ducrot (1983),L'Argumentation dans la langue, Brussels,Mardaga.Atlas, J. and S. Levinson (1981), `It-Clefts, In-formativeness and Logical Form', In: P.
Cole(ed.
), Radical Pragmatics, New York, AP.Blutner, R. (2000), `Some aspects of Optimalityin Natural Language Interpretation', Journal ofSemantics.Carston, R. (ms.), Informativeness, Relevanceand Scalar Implicature, University College Lon-don.Clarck H. H. & J. Haviland (1977), `Comprehen-sion and the given-new contract', In R.
Freedle(ed.
), Discourse production and comprehension,Hillsdale, NJ: Lawrence Erlbaum, pp.
1-40.Cover, T.M.
& J.A.
Thomas (1991), Elements ofInformation Theory, Wiley: New York.Dekker, P. & R. van Rooy (2000), `BidirectionalOptimality Theory: an application of GameTheory', Journal of Semantics.Gazdar, G. (1979), Pragmatics, London: Aca-demic Press.Groenendijk, J. and M. Stokhof (1984), Studies inthe Semantics of Questions and the Pragmaticsof Answers, Ph.D. thesis, University of Amster-dam.Grice, H. P. (1975), `Logic and Conversation', In:P. Cole & Morgan (eds.
), Syntax and Semantics3: Speech Acts, New York: Academic Press.Hirschberg, J.
(1985), A theory of scalar implica-ture, Ph.D. thesis, UPenn.Kuppevelt, J. van (1996), `Inferring from Topics:Scalar Implicature as Topic-Dependent Infer-ences', Linguistics and Philosophy, 19, pp.
555-598.Horn.
L. (1972), The semantics of logical operatorsin English, Ph.D. thesis, Yale University.Horn, L. (1984), `Towards a new taxonomy ofpragmatic inference: Q-based and R-based im-plicature'.
In: Schirin, D.
(ed.
), Meaning,Form, and Use in Context:: Linguistic Appli-cations, GURT84, 11-42, Washington; George-town University Press.Horn, L. (2000), `From if to i: Conditional per-fection as pragmatic strengthening', Journal ofPragmatics, 32: 289-326.Levinson, S.C. (1987), `Pragmatics and the gram-mar of anaphora', Journal of Linguistics, 23:379-434.Levinson, S.C. (2000), Presumptive Meanings.The Theory of Generalized Conversational Im-plicatures, MIT Press: Cambridge, Mas-sachusetts.Lindley, D. V. (1956), `On a measure of informa-tion provided by an experiment', Ann.
Math.Stat., 29, pp.
986-1005.Matsumota, Y.
(1995), `The conversational con-dition on Horn scales', Linguistics and Philos-ophy, 18: 21- 60.McCawley, J.
(1993), Everything that Linguistsalways wanted to know about Logic, but wereafraid to ask, Chicago: Chicago UniversityPress.Merin, A.
(1997), `Information, relevance, and so-cial decisionmaking', In: L. Moss, J. Ginzburg,M.
de Rijke (eds.
), Logic, Language, and Com-putation, Vol.
2, Stanford.Reinhard, T. (1983), Anaphora and semantic in-terpretation, London: Croom Helm.Rooy, R. van (2001), `Relevance of communicativeacts', In Theoretical Aspects of Rationality andKnowledge; Proceedings of TARK 2001, J. vanBenthem (ed.
), San Francisco, Morgan Kauf-mann Publishers, Inc., pp.
83-96.Rooy, R. van (to appear), `Utility of mention-somequestions', Language and Computation.Shannon, C. (1948), `The Mathematical Theory ofCommunication', Bell System Technical Jour-nal, 27.
