Knowledge Sources for Constituent Parsingof German, a Morphologically Rich andLess-Configurational LanguageAlexander Fraser?Institute for NLP, University of StuttgartHelmut Schmid?
?Institute for NLP, University of StuttgartRicha?rd Farkas?Institute for NLP, University of StuttgartRenjing Wang?Institute for NLP, University of StuttgartHinrich Schu?tze?Institute for NLP, University of StuttgartWe study constituent parsing of German, a morphologically rich and less-configurationallanguage.
We use a probabilistic context-free grammar treebank grammar that has been adaptedto the morphologically rich properties of German by markovization and special features addedto its productions.
We evaluate the impact of adding lexical knowledge.
Then we examine bothmonolingual and bilingual approaches to parse reranking.
Our reranking parser is the new stateof the art in constituency parsing of the TIGER Treebank.
We perform an analysis, concludingwith lessons learned, which apply to parsing other morphologically rich and less-configurationallanguages.?
Institute for Natural Language Processing, University of Stuttgart, Pfaffenwaldring 5b, 70569 Stuttgart,Germany.
E-mail: fraser@ims.uni-stuttgart.de.??
Institute for Natural Language Processing, University of Stuttgart, Pfaffenwaldring 5b, 70569 Stuttgart,Germany.
E-mail: schmid@ims.uni-stuttgart.de.?
Institute for Natural Language Processing, University of Stuttgart, Pfaffenwaldring 5b, 70569 Stuttgart,Germany.
E-mail: farkas@ims.uni-stuttgart.de.?
Institute for Natural Language Processing, University of Stuttgart, Pfaffenwaldring 5b, 70569 Stuttgart,Germany.?
Institute for Natural Language Processing, University of Stuttgart, Pfaffenwaldring 5b, 70569 Stuttgart,Germany.Submission received: October 1, 2011; revised submission received: May 30, 2012; accepted for publication:August 3, 2012?
2013 Association for Computational LinguisticsComputational Linguistics Volume 39, Number 11.
IntroductionA large part of the methodology for parsing in natural language processing has beendeveloped for English and a majority of publications on parsing are about parsingof English.
English is a strongly configurational language.
Nearly all of the syntacticinformation needed by anyNLP application can be obtained by configurational analysis(e.g., by having a correct constituent parse).Many other languages of the world are fundamentally different from English in thisrespect.
At the other end of the configurational?nonconfigurational spectrum we find alanguage like Hungarian that has very little fixed structure on the level of the sentence.Leaving aside the issue of the internal structure of NPs, most sentence-level syntacticinformation in Hungarian is conveyed by morphology, not by configuration.In this paper, we address German, a third type of language that is intermediatebetween English and Hungarian.
German has strong configurational constraints (e.g.,main clauses are verb-second) as well as rich derivational and inflectional morphology,all of which must be modeled for high-quality parsing.
German?s intermediate statusraises a number of interesting issues in parsing that are of particular prominence for amixed configurational/morphological language, but are?as we will argue?of generalrelevance for morphologically rich languages.
Partly this is the case because there arefew (if any) languages archetypical of being purely configurational and purely noncon-figurational (e.g., morphology is also important for English and even Hungarian hasconfigurational constraints).
For lack of a better termwe refer to intermediate languagesas typified by German as MR&LC for morphologically rich and less-configurational.Part of the motivation for this special issue is that most work on parsing to datehas been done on English, a morphologically simple language.
As computational lin-guistics broadens its focus beyond English it becomes important to take a more generalapproach to parsing that can handle languages that are typologically very different fromEnglish.
Rich morphology (RM) is one very salient characteristic of a language thataffects the design of parsing methods.
We argue that there are two other propertiesof languages that are relevant in a discussion of parsing RM languages: syncretismand configurationality.
These two properties are correlated typologically with RM andshould therefore be taken into account when we address parsing RM languages.1We first define the three properties and explain their relevance for parsing.
Thelarge number of languages for which this correlation holds can be ordered along asingle dimension that can be interpreted as degree of morphological complexity.
Wegive examples for a number of languages that are positioned at different points on thisscale.
Finally, we argue that just as languages that are at the opposite end of the spectrumfrom English (prototypical examples of morphological richness like Hungarian) requireparsing methods that can be quite different from those optimal for English, the sameis true for a language like German that is in the middle of the spectrum?and what isrequired is in some respects different from what is optimal for one extreme (English) orthe other (Hungarian).The three correlated properties are rich morphology, syncretism, and configura-tionality.
Morphological richness can be roughly measured by the number of differentmorphological forms a word of a particular syntactic category can have; for example,1 We note, however, that this relationship is not a language universal.
It is instead a frequently observedcorrelation; for Chinese, for instance, the correlation does not seem to hold as strongly.58Fraser et alKnowledge Sources for Parsing Germana typical English noun has two forms (singular and plural), a typical German nounhas eight forms (singular and plural in four different cases), and a typical Hungariannoun has several hundreds of forms.
Syncretism refers to the fact that different mor-phological forms have identical surface realization; for example, the formMann (?man?in German) can be the nominative, dative, or accusative singular of Mann dependingon context.
Configurationality refers to the degree to which the arrangement of wordsand phrases of a particular syntactic function in a sentence is fixed.
English is highlyconfigurational: it has limited flexibility in how the major phrases in a sentence (subject,verb, direct object, indirect object, etc.)
can be ordered.
Hungarian and Latin are highlyflexible: Even though there are pragmatic constraints, in principle a large number ofpossible orderings are grammatical.
German is less configurational.
It has some strictconstraints (verb second in main clauses, verb final in subordinate clauses), but alsosome properties of a nonconfigurational language; for example, ordering of phrasesin the mittelfeld (the part of the main clause enclosed by the two parts of the verbalcomplex) is very flexible.It is obvious why configurationality and rich morphology are typologically (neg-atively) correlated.
Rich morphology specifies the syntactic role of a phrase in thesentence, so fixing a position is not required, and many morphologically rich languagestherefore do not fix the position.
Conversely, simple morphology gives little specificinformation about the role of words and phrases in the sentence.
One device often usedby morphologically simple languages to address this problem and reduce widespreadambiguity is to fix the order of words and phrases in the sentence.Syncretism has an effect that is similar to simplification of complex morphology.Simple morphology is unspecific about grammatical function because it uses a smallnumber of morphological categories.
Syncretism is unspecific about grammatical func-tion because it suffers from a high degree of ambiguity.
Even though the number ofdifferent morphological categories is potentially large, syncretic forms conflate many ofthese categories, so that these forms are much less helpful in determining grammaticalfunction than forms in a nonsyncretic language with the same number of categories.Again, to counteract the communicative difficulties that lack of morphological speci-ficity would create, stricter constraints on ordering and configuration are often used bysyncretic languages.We have used English and Hungarian as examples for the extremes and Germanfor the middle of the spectrum.
We now give examples of other languages and theirpositions on the scale.
Dutch is similar to German in that it also is verb second in mainclauses and verb final in subordinate clauses.
The order of arguments in the mittelfeld ismuch more restricted than in German, however.
At the same time, Dutch morphologyhas been much more simplified in the last centuries than German morphology.
Thisnicely confirms the correlation between RM and configurationality.
Thus, Dutch ispositioned between English and German on the scale.Classical Arabic is somewhat similar to German: The number of different morpho-logical forms is roughly comparable to German and it allows a number of differentword orders.
Modern Standard Arabic speakers rarely mark case, however, at least notin spontaneous speech.
At the same time, Modern Standard Arabic speakers use SVOorder much more frequently and consistently than is the case in Classical Arabic.
Thus,Classical Arabic is roughly at the same position as German on the scale whereas spokenModern Standard Arabic may be more comparable to Dutch.Finally, Modern Greek is a language that is intermediate between German andHungarian.
It has richer morphology than German, but it has a fair amount of syn-cretism and therefore more morphological ambiguity than Hungarian.
SVO is the59Computational Linguistics Volume 39, Number 1predominant word order in modern Greek, but other word orders can be used.
Theorder within the noun phrase is more flexible than in German: Adjectives can precedeor follow the noun.In the examples we have given, the amount of information conveyed by a mor-phological form is negatively correlated with the amount of information conveyed byconfiguration.
If morphology conveys a lot of information (due to a large number ofdistinctions and the lack of syncretism), then word order is freer and conveys lessinformation.
If morphology conveys less information (due to fewer distinctions or moresyncretism), then configuration is fixed and provides more information to the speaker.This suggests that RM and configuration are important variables that should be takeninto account in the design of parsing methods.
In addition to looking at the extremes ofthe spectrum that are exemplified by English andHungarian, we should also investigatethe middle: morphologically (somewhat) rich languages that are less configurational.
Inthis article, we look at the example of German.One key question for MR&LC parsing is which type of parsing formalism to adopt,constituency or dependency.
It is a widely held belief that dependency structures arebetter suited to represent syntactic analyses for morphologically rich languages becausethey allow non-projective structures (the equivalent of discontinuous constituents inconstituency parsing).
As Tsarfaty et al(2010) point out, however, this is not the sameas proving that dependency parsers function better than constituency parsers for pars-ing morphologically rich languages.
In fact, most state-of-the-art dependency parsers(McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al2010a) generate purelyprojective dependency structures that are optionally transformed into non-projectivestructures in a post-processing step.
Comparable post-processing techniques have beenused in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006;Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents andmight workfor other languages, as well.The overview paper of the Parsing German Shared Task (Ku?bler 2008) reportshigher accuracies for detecting grammatical functions with dependency parsers thanwith constituent parsers, but the direct comparison is not fair as it required phraseboundaries to be correct on the constituent side while the tokens were the unit ofevaluation on the dependency side.2 How to carry out an absolutely fair comparisonof the two representations is still an open research question.3Constituent parses often provide more information than dependency parses.
Anexample is the coordination ambiguity in old men and women versus old men and children.The correct constituent parse for the first expression contains a coordination at thenoun level whereas the parse for the second expression coordinates at the level ofNPs.
The dependency structures of both expressions, on the other hand, are usuallyidentical and thus unable to reflect the fact that oldmodifies women but not children.
It ispossible, in principle, to encode the difference in dependency trees (cf.
Rambow 2010),2 This is due to how the evalb tool used to calculate PARSEVAL works.
If a constituent is not perfectlymatched, the grammatical function is considered to be wrong, even if there was a partial match (at thetoken level).
This is not a problem with dependency-based evaluation.
For further discussion of thePARSEVAL metric and dependency-based evaluation see, for example, Rehbein and van Genabith (2007)and Tsarfaty, Nivre, and Andersson (2012).3 Two possible solutions are to use TedEval (Tsarfaty, Nivre, and Andersson 2012), or to conduct an analysisof grammatical functions at the token level in a consistent fashion for both dependency and constituentparsers.
In our case, the latter would require a high quality conversion from the Tiger constituencyrepresentation to a dependency representation, which we hope to implement in future work.60Fraser et alKnowledge Sources for Parsing Germanfor example, by enriching the edge labels, but the constituent representation is simplerfor this phenomenon.Finally, there are some applications that need constituent parses rather than depen-dency parses.
For instance, many hierarchical statistical machine translation systemsuse constituency parses, requiring the output of a dependency parser to be transformedinto a constituent parse.4 We conclude that there is no clear evidence for preferringdependency parsing over constituency parsing in analyzing languages with RM andinstead argue that research in both frameworks is important.We view the detailed description of a constituency parsing system for a mor-phologically rich language, a system that addresses the major problems that arise inconstituency parsing for MR&LC, as one of our main contributions in this paper.The first problem we address is the proliferation of phrase structure rules inMR&LC languages.
For example, there are a large number of possible orderings of thephrases in the German mittelfeld, and many orderings are exceedingly rare.
A standardconstituency parser cannot estimate probabilities for the corresponding rules reliably.The solution we adopt here is markovization?complex rules are decomposedinto small unidirectional rules that can be modeled and estimated more reliably thancomplex rules.
Although markovization in itself is not new, we stress its importance forMR&LC languages here and present a detailed, reproducible account of how we use itfor German.
Markovization combines the best of both worlds for MR&LC languages:Preferential configurational information can be formalized and exploited by the parserwithout incurring too large of a performance penalty due to sparse data problems.The second problem that needs to be addressed in parsingmanyMR&LC languagesis widespread syncretism.
We mainly address syncretism by using a high performancefinite-state automata-based morphological analyzer.
Such an analyzer is of obviousimportance for any morphologically rich language because the productivity of mor-phologically rich languages significantly increases the unknown-word rate in new textversus morphologically poor languages.
So the parser cannot simply memorize thegrammatical properties of words in the Treebank used for training.
Instead we incorpo-rate a complex guesser into our parser that, based on the input from the morphologicalanalyzer, predicts the grammatical properties of new words and (equally important)unobserved grammatical properties of known words.
With prevailing syncretism, thistask is muchmore complex than in a language where case, gender, number, and so forth,can be deterministically deduced from morphology.The morphological analyzer is based on (i) a finite state formalization of Germanmorphology and (ii) a large lexicon of morphologically analyzed German words.
Werefer to these two components together as lexical knowledge.
We show that lexicalknowledge is beneficial for parsing performance for an MR&LC language like German.In addition to lexical knowledge, there is a second important aspect of syncretismthat needs to be addressed in MR&LC languages.
Syntactic disambiguation in theselanguages must always involve both systems of grammatical encoding, morphologyand configuration, acting together.
The most natural way of doing this in a languagelike German is to perform this integration of the two knowledge sources directly as partof parsing.We do this by annotating constituent labels with grammatical functionwhereappropriate.
In contrast with syntactic parses of strongly configurational languageslike English, syntactic parses of German are not useful for most tasks without having4 We do note, however, that there are a few translation systems which use a dependency representationdirectly (e.g., Quirk, Menezes, and Cherry 2005; Shen, Xu, and Weischedel 2008; Tu et al2010).61Computational Linguistics Volume 39, Number 1grammatical functions indicated.
It is not even possible to access the basic subcatego-rization of the verb (such as determining the subject) without grammatical functions.We argue that MR&LC languages like German should always be evaluated on labels-cum-grammatical-function.Our last main contribution in this paper concerns the fact that we believe thatMR&LC languages give rise to more ambiguity than languages that are predominantlyconfigurational or morphological.
As an example consider the German sentence ?Die[the] Katze [cat] jagt [hunts] die [the] Schlange [snake].?
In German either the cat or thesnake can be the hunter.
This type of ambiguity neither occurs in a strongly configu-rational language like English (where configuration determines grammatical function)nor in a morphologically rich language like Hungarian that has no or little syncretism(where morphology determines grammatical function).
Although morphology andconfiguration in MR&LC languages often work hand in hand for complete disambigua-tion, there are also many sentences where neither of the two provides the necessaryinformation for disambiguation.
We believe that this distinguishing characteristic ofMR&LC languages makes it necessary to tap additional knowledge sources.
In thispaper, we look at two such knowledge sources: monolingual reranking (which capturesglobal properties of well-formed parses for additional disambiguation) and bilingualreranking (which exploits parallel text in a different language for disambiguation).For monolingual reranking, we define a novel set of rich features based on sub-categorization frames.
We compare our compact feature set with a sparse feature setdesigned for German previously by Versley and Rehbein (2009).
We show that thericher subcategorization-based framework for monolingual reranking is effective; it hascomparable performance to the sparse feature set?moreover, they complement eachother.For bilingual reranking, we present our approach to bitext parsing, where a Germanparse is found that minimizes syntactic divergence with an automatically generatedparse of its English translation.
We pursue this approach for a number of reasons.
First,one limiting factor for syntactic approaches to statistical machine translation is parsequality (Quirk and Corston-Oliver 2006).
Improved parses of bitext should result inimproved machine translation.
Second, as more and more texts are available in severallanguages, it will be increasingly the case that a text to be parsed is itself part of abitext.
Third, we hope that the improved parses of bitext can serve as higher qualitytraining data for improving monolingual parsing using a process similar to self-training(McClosky, Charniak, and Johnson 2006a).We show that the three different knowledge sources we use in this paper (lexicalknowledge, monolingual features, and bilingual features) are valuable separately.
Wealso show that the gain of the two sets of reranking features (monolingual and bilingual)is additive, suggesting that they capture different types of information.The resulting parser is currently the best constituent parser for German (with orwithout bilingual features).
In particular, we show that the baseline parser withoutreranking is competitive with the previous state of the art (the Berkeley parser) andthat the re-ranking can add an important gain.2.
Previous WorkConstituent parsing for English is well studied.
The best generative constituent parsersare currently the Brown reranking parser (Charniak and Johnson 2005), the exten-sion of this parser with self training by McClosky, Charniak, and Johnson (2006b),and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic62Fraser et alKnowledge Sources for Parsing Germancontext-free grammar (PCFG) parser with latent feature annotations.
Charniak andJohnson (2005) and Huang (2008) have introduced a significant improvement byfeature-rich discriminative reranking as well.The number of treebank constituent parsers for German is smaller.
Dubey andKeller (2003) adapted Collins?s (1997) lexicalized parser to German.
An unlexicalizedPCFG parser similar to our generative parser was presented by Schiehlen (2004).
Thebest constituent parser participating in the ACL-08 Workshop on Parsing German(Ku?bler 2008) was the Berkeley parser (Petrov and Klein 2008).
The Stanford parserwas also adapted to German (Rafferty andManning 2008).
German dependency parsershave been developed by Menzel and Schro?der (1998), Duchier and Debusmann (2001),Hall and Nivre (2008), Henderson et al(2008), and Seeker et al(2010a), to namea few.There is also some previous work on German parse reranking.
Forst (2007) pre-sented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) appliedreranking to German dependency parsing.
Versley and Rehbein (2009) developed areranking method for German constituent parsers.
The work by Versley and Rehbeinand by Schiehlen (2004) is closest to ours.
Like them, we rerank the unlexicalized BitParparser.
We also refine treebank labels to increase parsing performance, but add moreinformation and achieve a larger improvement.
We use the monolingual feature set ofVersley and Rehbein in our reranker, but add further monolingual features as well asbilingual features.3.
Generative Parsing FrameworkOur generative parser is an unlexicalized PCFG parser which is based on the BitParparser (Schmid 2004).
BitPar uses a fast bitvector-based implementation of the well-known Cocke-Younger-Kasami algorithm and stores the chart as a large bit vector.This representation is memory efficient and allows full parsing (without search spacepruning) with large treebank grammars.
BitPar is also quite fast because the basicparsing operations are parallelized by means of (single-instruction) and-operations onbitvectors.
BitPar can either be used to compute the most likely parse (Viterbi parse), orthe full set of parses in the form of a parse forest, or the n-best parse trees.3.1 GrammarThe grammar and lexicon used by our generative parser are extracted from the Tiger2Treebank (Brants et al2002).
Similar to Johnson (1998) andKlein andManning (2003) weimprove the accuracy of the unlexicalized parser by refining the non-terminal symbolsof the grammar to encode relevant contextual information.
This refinement weakensthe strong independence assumptions of PCFGs and improves parsing accuracy.
Theextraction of the grammar and lexicon involves the following steps:1.
Discontinuous constituents are eliminated (Section 3.2).2.
Treebank annotations are transformed (Section 3.4) and augmented(Section 3.5).3.
Grammar rules, lexical rules, and their frequencies are extracted from theannotated parse trees.4.
The grammar is markovized (Section 3.6).63Computational Linguistics Volume 39, Number 1.S-TOPPROPAV-OP-1DarausThis-fromVMFIN-HDkanncanVP-OCVP-OCPROAV-OP*T*-1VVPP-HDgefolgertconcludedVAINF-HDwerdenbeFigure 1Projectivized parse tree for the sentence: Daraus kann gefolgert werden [From this can beconcluded].3.2 Raising for Non-ProjectivityThe Tiger2 Treebank that we used in our experiments contains discontinuous con-stituents.
As in other work on German parsing using the Tiger2 Treebank (Dubeyand Keller 2003; Schiehlen 2004; Ku?bler, Hinrichs, and Maier 2006), we eliminateddiscontinuous constituents by raising those parts of the discontinuous constituent thatdo not contain the head to the child position of an ancestor node of the discontinuousconstituent.
Hsu (2010) compared three different Tiger2 conversion schemes and foundraising to be the most effective.
The projective parse tree in Figure 1, for instance, isobtained from a Tiger parse tree where the pronominal adverb Daraus was a dis-continuous child of the lower VP-OC node.The parse tree in Figure 1 shows a trace node and coreference indices (similar tothe Penn Treebank annotation style for discontinuous constituents).
If slash featuresare added to the nodes on the path between the PROAV node and its trace within theVP, it is possible to restore discontinuous constituents (Schmid 2006).
Due to sparsedata problems caused by the added slash features, however, the parsing accuracydrops by 1.5% compared with the version without slash features (when evaluated onprojectivized parse trees).
Traces are recognized with a precision of 53% and a recall of33%.
The correct antecedents are identified with a precision of 48% and a recall of 30%.These figures indicate that the identification of discontinuous constituents in Tiger parsetrees is a harder task than in English Penn Treebank parses, considering the 84% F-scorefor the recognition of empty constituents and the 77% F-score for the identification ofantecedents reported in Schmid (2006) for an analogous approach.As the example in Figure 1 shows, the precise attachment point of constituentsis often not required: We can simply assume that all constituents appearing at the Slevel are dependents of the main verb of the clause.
Only for modifiers with scopeambiguities (e.g., negation particles) is it relevant whether they are attached at the Sor VP level.
These considerations suggest that it is better to recognize discontinuousconstituents in a post-processing step as in Johnson (2001), Campbell (2004), and Levyand Manning (2004).
In the rest of the paper, we will only work with parse trees fromwhich coreference indices and trace nodes have been removed.3.3 Morphological Features and Grammatical FunctionsThe Tiger2 Treebank annotates non-terminals not only with syntactic categories butalso with grammatical function labels such as SB (subject), OA (accusative object), or64Fraser et alKnowledge Sources for Parsing GermanMO (modifier).
These labels provide important information that is necessary in order toderive a semantic representation from a parse.
It is not possible to infer the grammaticalrole of a constituent from its position in the parse tree alone (as can be done in English,for instance).
Case information is needed in addition in order to help determine thecorrect grammatical role.
The Tiger2 Treebank provides case, number, degree (positive,comparative, superlative), and gender information at the part-of-speech (POS) level.Our parser concatenates the grammatical function labels as well as the case infor-mation of the POS tags to the base labels similarly to Dubey (2004) and Versley (2005).Our earlier experiments showed that adding case information increases F-score by 2.1%absolute.
Further enriching the grammar with morphological features, however, hurtsperformance.
Adding number features decreased F-score by 0.5%.
Adding number,gender, and degree decreased F-score by 1.6%.
When grammatical functions are takeninto account in the evaluation, the performance drops by 1.5% when number, gender,and degree features are incorporated.
It seems that the additional information suppliedby the agreement features is not useful enough to outweigh sparse data problemscaused by the more fine-grained label set.
Therefore we only use case, but designinga smoothing procedure allowing us to use number, gender, and degree is interestingfuture work.3.4 Tree TransformationsSimilarly to Schiehlen (2004), we automatically augment the Tiger2 annotation with ad-ditional feature annotations.
Our feature annotation set is larger than that of Schiehlen.In addition to making feature annotations, we also perform some tree transformationsthat reduce the complexity of the grammar.
In all evaluations, we use the original(projectivized) Tiger parse trees as gold standard and convert the parse trees generatedby our parser to the same format by undoing the transformations and removing theadditional features.
In the rest of this section, we explain the tree transformations thatwe used.
The following section describes the feature annotations.5Unary branching rules.
The Tiger Treebank avoids unary branching nodes.
NPsand other phrasal categories which dominate just a single node are usually omitted.The sentence Sie zo?gern [They hesitate], for instance, is analyzed as (S-TOP (PPER-SBSie) (VVFIN-HD zo?gern)) without an explicit NP or VP.
The lack of unary branchingnodes increases the number of rules because now a rule S-TOP?
PPER-SB VVFIN-HDis needed in addition to the rule S-TOP?
NP-SB VVFIN-HD, for instance.In order to reduce sparse-data problems, we insert unary branching nodes andtransform this parse to (S-TOP (NP-SB (PPER-HD Sie)) (VVFIN-HD zo?gern)) by addingan NP node with the grammatical function (GF) of the pronoun.
The GF of the pronoun,in turn, is replaced by HD (head).
Such unary branching NPs are added on top of nouns(NN), pronouns (PPER, PDS, PIS, PRELS), cardinals (CARD), and complex propernames (PN) that are dominated by S, VP, TOP, or DL6 nodes.7 The transformation isreversible, which allows the original annotation to be restored.5 Descriptions of the different symbols used in the Tiger annotation scheme are available athttp://www.ims.uni-stuttgart.de/tcl/RESOURCES/CL.html.6 DL is a discourse level constituent.7 If a single proper name (NE) forms a noun phrase, we first add a PN node and then an NP node on top.If a simple noun (NN) with a GF other than NK appears inside of an NP, PP, CNP, CO, or AP, we also addan NP node on top of it.
Similarly, we add a PN node on top of proper names (NE) in the same context.65Computational Linguistics Volume 39, Number 1.CPP-MOKON-CDwederneitherPP-CJAPPR-ACininNE-NKBerlinBerlinKON-CDnochnorPP-CJAPPR-ACininNE-NKFrankfurtFrankfurt.CPP-MOKON-CD/wederwederneitherPP-MOAPPR-AC/inininNE-HDBerlinBerlinKON-CD/nochnochnorPP-MOAPPR-AC/inininNE-HDFrankfurtFrankfurtFigure 2Parse of the phrase weder in Berlin noch in Frankfurt [neither in Berlin nor in Frankfurt] beforeand after selective lexicalization of prepositions and conjunctions.
This example also shows thereplacement of the grammatical function features CJ and NK discussed in the previous section.The modified parts are printed in boldface.By adding a unary-branching NP-SB node, for instance, we introduce an additionalindependence assumption, namely, we assume that the expansion of the subject NP isindependent of the other arguments and adjuncts of the verb (a plausible assumptionthat is confirmed by a performance improvement).Elimination of NK.
Tiger normally uses the grammatical function HD to mark thehead of a phrase.
In case of NPs and PPs, however, the GF of the head is NK (nounkernel).
The same GF is also assigned to the adjectives and determiners of the nounphrase.
We replace NK by HD in order to reduce the set of symbols.8Elimination of CJ.
Tiger annotates each conjunct in a coordination with the spe-cial grammatical function label CJ.
We replace CJ by the grammatical function of thecoordinated phrase.
This transformation is also reversible.3.5 Additional Feature AnnotationsSelective lexicalization.
We mark the POS tags of the frequent prepositions in [in], von[from, of], auf [on], durch [through, by means of], unter [under], um [around, at] andtheir variants regarding capitalization (e.g., Unter) and incorporation of articles (e.g.,unters, unterm) with a feature which identifies the preposition.
This can be seen as arestricted form of lexicalization.
In the same way, we also ?lexicalize?
the coordinatingconjunctions (KON-CD) sowohl [as well], als [as], weder [neither], noch [nor], entweder[either], and oder [or] if preceded by entweder.
Figure 2 shows an example.Sentence punctuation.
If a clause node (S) has a sibling node labeled with POS tag?$.?
that dominates a question mark or exclamation mark, then the clause node and thePOS tag are annotated with quest or excl, so the grammar models different clause types.8 The original annotation can be restored: HD never occurs in NP or PP children in original Tiger parses.66Fraser et alKnowledge Sources for Parsing German.CS-RCS-RCNP-SB/relPRELS-HD-NomdiewhoNP-OANN-HD-ACCSurfensurfingVVFIN-HDsagensayKON-CDundandS-RC/norel/nosubjNP-OANN-HD-AccFreiheitfreedomVVFIN-HDmeinenmeanFigure 3Parse of the phrase die Surfen sagen und Freiheit meinen [who say surfing and mean freedom] beforeand after annotation with relative clause features.
This example also shows the nosubj feature,which will be discussed later.Adjunct attachment.
Adjuncts often differ with respect to their preferred attach-ment sites.
Therefore, we annotate PPs and adverbials (AVP, ADV, ADJD) with one ofthe features N, V, or 0 which indicate a nominal parent (NP or PP), a verbal parent(VP, S), or anything else, respectively.
In case of adverbial phrases (AVP), the label ispropagated to the head child.Relative clause features.
In many relative clauses (S-RC), the relative pronoun(PRELS, PRELAT, PWAV, PWS) is embedded inside of another constituent.
In this case,all nodes on the path between the pronoun and the clause node are marked with thefeature rel.
Furthermore, we add a feature norel to relative clauses if no relative pronounis found.
Figure 3 shows an example.Wh features.
Similar to the feature rel assigned to phrases that dominate a relativepronoun, we use a feature wh which is assigned to all NPs and PPs which immediatelydominate a wh-pronoun (PWAT, PWS, PWAV).
This feature better restricts the positionswhere such NPs and PPs can occur.Noun sequence feature.
If two nouns occur together within a GermanNP (as in dreiLiter Milch [three liters (of) milk] or Ende Januar [end (of) January]), then the first nounis usually a kind of measure noun.
We mark it with the feature seq.Proper name chunks.
Some noun phrases such as Frankfurter Rundschau, JungeUnion, Die Zeit are used as proper names.
In this case, the grammatical function of theNP is PNC.
In order to restrict the nouns and adjectives that can occur inside of suchproper name chunks, we mark their POS tags with the feature name.Predicative APs.
Complex adjectival phrases (AP) are either attributively used asnoun modifiers inside of an NP or PP, or predicatively elsewhere.
In order to bettermodel the two types of APs, we mark APs that dominate a predicative adjective (ADJD)with the feature pred.9Nominal heads of APs.
Sometimes the head of an AP is a noun as in (AP dreiMillionen) Mark [three million Marks] or ein (AP politisch Verfolgter) [a politicallypersecuted-person].
We mark these APs with the feature nom.Year numbers.Years such as 1998 can appear in places where other numbers cannot.Therefore POS tags of numbers between 1900 and 2019 are marked with year.10Clause type feature for conjunctions.
The type of a subordinate clause and thesubordinating conjunction are highly correlated.
German object clauses (S-OC) usually9 We also mark an AP parent of a node with the label AP-HD/pred in the same way.10 For some texts, it might be advantageous to use a broader definition of year numbers.67Computational Linguistics Volume 39, Number 1start with dass [that] or ob [whether]; modifier clauses (S-MO) often start with wenn[if], weil [because], or als [when].
We mark subordinating conjunctions of argumentclauses (S-OC), modifier clauses (S-MO), subject clauses (S-SB), and dislocated clauses(S-RE) with a feature (OC,MO, SB, or RE) identifying clause type.
Without this feature,argument clauses of nouns, for instance, are often misanalyzed as modifiers of the mainclause.VP features.
VPs that are headed by finite verbs, infinitives, past participles, imper-atives, and zu infinitives are all used in different contexts.
Therefore we mark object VPs(VP-OC) with a corresponding feature.
When parsing the sentence Alle Ra?ume mu?ssenmehrfach gesa?ubert und desinfiziert werden [all rooms must multiply cleaned and disin-fected be; all rooms must be ...], this feature allows the parser to correctly coordinate thetwo past participle VPs mehrfach gesa?ubert and desinfiziert instead of the past participleVP mehrfach gesa?ubert and the infinitival VP desinfiziert werden.Phrases without a head.
Some phrases in the Tiger corpus lack a head.
This isfrequent in coordinations.
All phrases that do not have a child node with one of thegrammatical functions HD, PNC, AC, AVC, NMC, PH, PD, ADC, UC, or DH aremarkedwith the feature nohead.Clauses without a subject.
We also mark conjunct clauses with the feature nosubjif they are neither headed by an imperative nor contain a child node with the gram-matical function SB (subject) or EP (expletive).
This is useful in order to correctly parsecoordinations where the subject is dropped in the second conjunct.3.6 MarkovizationThe Tiger Treebank uses rather flat structures where nodes have up to 25 child nodes.This causes sparse data problems because only some of the possible rules of that lengthactually appear in the training corpus.
The sparse data problem is solved bymarkoviza-tion (Collins 1997; Klein and Manning 2003), which splits long rules into a set of shorterrules.
The shorter rules generate the child nodes of the original rule one by one.
First,the left siblings of the head child of the rule are generated from left to right, then theright siblings are generated from right to left.
Finally, the head is generated.
Figure 4shows the markovization of the rule NP?
NMNN PP PP.The auxiliary symbols that are used here encode information about the parent cat-egory, the head child, and previously generated children.
Because all auxiliary symbolsencode the head category, the head is already selected by the first rule, but only lateractually generated by the last rule..NPNM ?L:NP[NN]NN|NM??M:NP[NN]??R:NP[NN]PP|PP?
?R:NP[NN]NN|PP?NNPPPPFigure 4Markovization of the rule NP?
NMNN PP PP.68Fraser et alKnowledge Sources for Parsing GermanThe general form of the auxiliary symbols is ?direction:parent[head]next|previous?where direction is either L, M, or R, parent is the symbol on the left hand side of therule, head is the head on the right hand side of the rule, next is the symbol which willbe generated next, and previous is the symbol that was generated before.
Auxiliariesstarting with L generate the children to the left of the head.
Auxiliaries starting withR similarly generate the children to the right of the head and the head itself.
Theauxiliary starting with M is used to switch from generating left children to generatingright children.
Each rule contains information about the parent, the head, and (usually)three child symbols (which may include an imaginary boundary symbol).
The first ruleencodes the trigram left-boundary NM NN.
The second rule is an exception which onlyencodes the bigram NM NN.
The third rule encodes the trigram PP PP right-boundary.The last rule is an exception, again, and only encodes NN PP.
There is no rule whichcovers the trigram consisting of the head and its two immediate neighbors.Our markovization strategy only transforms rules that occur less than 10 times inthe training data.
If one of the auxiliary symbols introduced by the markovization (suchas ?L:NP[NN]NN?NM?)
is used less than 20 times (the values of the two thresholdswere optimized on part of the development data) overall, it is replaced by a simplersymbol ?L:NP[NN]NN?
that encodes less context.
In this way, we switch from a trigrammodel (where the next child depends on the two preceding children) to a bigrammodel(where it only depends on the preceding child) in order to avoid sparse data problems.Themethod is similar to the markovization strategy of Klein andManning (2003) exceptthat they markovize all rules.
We simulated their strategy by raising the rule frequencythreshold to a larger value, but obtained worse results.
We also tried an alternativemarkovization strategy that generates all children left to right (the auxiliary symbolsnow lack the direction flag, and the rules cover all possible trigrams), but again obtainedworse results.
A disadvantage of our markovization method are spurious ambiguities.They arise because some of the rules which are not markovized are also covered bymarkovization rules.3.7 Dealing with Unknown Words and Unseen POS TagsBitPar includes a sophisticated POS guesser that uses several strategies to deal withunknown words and unseen POS tags of known words.
Unknown words are dividedinto eight classes11 based on regular expressions that are manually defined.
Theseclasses distinguish between lower-case words, capitalized words, all upper-case words,hyphenated words, numbers, and so forth.
For each word class, BitPar builds a suffixtree (Weischedel et al1993; Schmid 1995; Brants 2000) from the suffixes of all words inthe lexicon up to a length of 7.
At each node of the suffix tree, it sums up the conditionalPOS probabilities (given the word) over all known words with that suffix.
By summingPOS probabilities rather than frequencies, all words have the same weight, which isappropriate here because we need to model the POS probabilities of infrequent words.BitPar computes POS probability estimates for each node using the sum of probabilitiesas a pseudo-frequency for each tag.
The estimates are recursively smoothed with theWitten-Bell method using the smoothed POS probabilities of the parent node as abackoff probability distribution.12 The suffix trees are pruned by recursively removing11 We also experimented with more complex classifications, but they failed to improve the results.12 The number of ?observed?
POS tags, which is needed by Witten-Bell smoothing, is defined as thenumber of POS tags with a pseudo-frequency larger than 0.5.69Computational Linguistics Volume 39, Number 1leaf nodes whose pseudo-frequency is below 5 or whose weighted information gain13is below a threshold of 1.Whenever an unknown word is encountered during parsing, BitPar determines theword class and obtains the tag probability distribution from the corresponding suffixtree.
BitPar assumes that function words are completely covered by the lexicon andnever guesses function word POS classes for unknown words.BitPar uses information from the unknown word POS guesser and (if available)information from an external lexicon (generated by a computational morphology, forinstance, as we will discuss in Section 5.1) in order to predict unobserved POS tagsfor known words.
First the external lexicon and the lexicon extracted from the trainingcorpus are merged.
Then smoothed probabilities are estimated using Witten-Bellsmoothing with a backoff distribution.
The backoff distribution is the average of:(1) the probability distribution returned by the unknown word POS guesserif at least one possible POS tag of the word according to the lexicon is anopen-class POS tag,(2) the average POS probability distribution of all words with exactly the sameset of possible POS tags as the given word14 if at least one of the possibletags is unseen, and(3) the prior POS probability distribution if no other word in the lexicon hasthe same set of possible POS tags and at least one of the word?s possiblePOS tags is unseen.4.
Evaluation of the Generative ParserAs we present each knowledge source, we would like to evaluate it against manuallyannotated Treebanks.
Our first evaluation shows that our generative parser introducedin the previous section is comparable with the Berkeley generative parser.
Before wepresent this comparison in Section 4.1 we discuss evaluating parse accuracy.In our evaluations, we use the Tiger Treebank (Brants et al2002) and a smallEuroparl Treebank (Pado?
and Lapata 2009).
We take the first 40,474 sentences of theTiger Treebank as training data (Tiger train), the next 5,000 sentences as developmentdata (Tiger dev), and the last 5,000 sentences as test data (Tiger test).
The Europarldata consists of 662 sentences15 and are either completely used as test data and not di-vided up or we carried out seven-fold cross-validation experiments with our rerankingmodels.All parsers are evaluated on projectivized parse trees.
This means that we applystep 1 of the grammar extraction process described in Section 3.1 to the test parsesand use the result as the gold standard (except for the Pado?
set, which is alreadyprojectivized).
The test sentences are parsed and the resulting parse trees are converted13 The weighted information gain is the difference between the entropy of the parent node and the entropyof the current node, multiplied by the total frequency of the current node and divided by the number of?observed?
POS tags of the current node.14 A similar pooling of lexicon entries was previously used in the POS tagger of Cutting et al(1992).15 We use only the sentences in this set which had a single sentence as a translation, so that they couldbe used in bilingual reranking, which will be discussed later.70Fraser et alKnowledge Sources for Parsing Germanto the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1.This conversion involves four steps:1.
Demarkovization removes all the auxiliary nodes introduced bymarkovization and raises their children to the next non-auxiliary node.2.
The added unary-branching nodes are eliminated.3.
The original grammatical function labels NK inside of NPs and PPs,and CJ inside of coordinated phrases, are restored.4.
All feature annotations are deleted.We use PARSEVAL scores (Black et al1991) and the standard evaluation tool evalb16to compare the converted parse trees with the gold standard parse trees using labeledF-score.
We report accuracies for all test sentences and not just sentences of length up to40.
We do not evaluate parsers with gold standard POS tags, but instead automaticallyinfer them.
These considerations make our evaluation setting as close to the real-worldsetting as possible.We report results for evaluations with and without grammatical functions.
Wereport PARSEVAL scores with grammatical functions inside parentheses after theresults using only basic constituent categories.
We believe that grammatical functionsare an important part of the syntactic analysis for any downstream applications in less-configurational languages such as German because crucial distinctions (e.g., the distinc-tion between subject and object) are not feasible without them.
We should mention thatour results are not directly comparable to previously published results on the Tiger2corpus (Ku?bler 2008; Versley and Rehbein 2009; Seeker et al2010b), because each ofthe previous studies used different portions of the corpus and there are differences inthe evaluation metric as well.
The transformed corpus (in our train, development, andtest split format) and the evaluation scripts we used are available,17 which we hope willenable direct comparison with our results.4.1 Comparison of BitPar and BerkeleyThe best constituent parser participating in the Parsing German Shared Task (Ku?bler2008) was the Berkeley parser (Petrov and Klein 2008) and to the best of our knowledgeit has achieved the best published accuracy for German constituency parsing so far.The Berkeley parser takes an automated approach, in which each constituent symbol issplit into subsymbols applying an expectation-maximization method.
We compare ourmanually enriched grammar to this automatic approach.We trained the Berkeley parser on Tiger train using the basic constituent categoriesconcatenated to the grammatical function labels as starting symbols.
We found that itachieved the best PARSEVAL scores on Tiger dev after the fourth iteration.
This modelwas used for parsing Tiger dev, Tiger test, and the Europarl corpus.BitPar achieved 82.51 (72.46), 76.67 (65.61), and 77.13 (66.06), and the Berkeleyparser achieved 82.76 (73.20), 76.37 (65.66), and 75.51 (63.3) on the three corpora,respectively.
In general, these results indicate that these two parsers are competitive.On the other hand, the fact that the results of the Berkeley parser are much worse than16 http://nlp.cs.nyu.edu/evalb/, 2008 version.17 See http://www.ims.uni-stuttgart.de/tcl/RESOURCES/CL.html.71Computational Linguistics Volume 39, Number 1BitPar on the out-of-domain Europarl corpus indicates that it overfits to the domainof the training corpus (Tiger2).
Following a reviewer suggestion, we looked at thesentences containing many words not occurring in the training data, and observed thatour lexical resource is strongly helpful for these sentences.
Another disadvantage ofthe automatic approach of the Berkeley parser is that the resulting subsymbols are noteasily interpretable, which can hinder defining features for parse reranking using them.Based on these considerations, we decided to use BitPar in our reranking experiments.The combination of the two radically different approaches (linguistically motivatedgrammar extensions and automatic symbol splitting) is a rather promising area ofresearch for improving parsing accuracy, which we plan to address in future work.5.
Impact of Our Lexical Resource5.1 Integration of SMOR with BitParThere are a large number of inflectedword forms formanyGerman lemmas.
This causessparse data problems if some forms are not observed in the training data.
BitPar appliesthe heuristics described in Section 3.7 to obtain POS probabilities for unseen words.Although these heuristics seem to work quite well, we expect better results if the parserhas access to information from a morphological analyzer.We use the German finite-state morphology SMOR (Schmid, Fitschen, and Heid2004) to provide sets of possible POS tags for all words.
SMOR covers inflection, deriva-tion, and compounding and achieves good coverage in combination with the stemlexicon IMSLex (Lezius, Dipper, and Fitschen 2000).
SMOR is integrated into the parserin the following way.
We create a combined word list from the training and testingdata18 and analyze it with SMOR.
The SMOR analyses are then mapped to the POStag set used by the parser, and supplied to BitPar as an external lexicon (see Section 3.7).Consider the example word erlischt [goes out], which did not appear in the train-ing corpus.
SMOR produces the analysis erlo?schen.V.3.Sg.Pres.Ind, which is mappedto VVFIN-HD and added to the lexicon.
Using this entry, BitPar correctly parsedthe sentence Die Anzeige erlischt [The display goes out].
Without using SMOR, theparser analysed erlischt as a past participle because scht is a frequent past participleending.5.2 Effect on In-Domain and Out-of-Domain ParsingIn order to measure the effect of the integration of a German morphology on parsingaccuracy (see Section 5.1), we tested the BitPar parser on the Tiger data and on Europarldata.
The results are summarized in Table 1.
They show that the morphology helps onout-of-domain data (Europarl), but not so much on in-domain data (Tiger).
The POStagging accuracy, however, also increases on Tiger data by 0.13%.
When grammaticalfunctions are included in the evaluation, the performance improvement more thandoubles on Europarl data.
As a result, we decided to use the finite-state morphologyin the rest of the experiments we conducted.Table 1 also shows that the Tiger test data is harder to parse than the dev data.
Weexamined the two subcorpora and found that the test data contains longer sentences18 Because we are only using the words here, and not their POS labels, this approach is methodologicallysound and could be applied to any unparsed data in the same way.72Fraser et alKnowledge Sources for Parsing GermanTable 1Effect of using finite-state morphology on parsing accuracy.
The values in parentheses arelabeled F-scores from the evaluation with grammatical functions.morphology Tiger dev Tiger test Europarlwithout 82.51 (72.46) 76.67 (65.61) 76.81 (65.31)with 82.42 (72.36) 76.84 (65.91) 77.13 (66.06)difference ?0.09 (?0.10) +0.17 (+0.30) +0.32 (+0.75)(18.4 vs. 15.3 words on average) and that the ratio of unknown words is higher (10.0%vs.
7.6%).6.
Parse RerankingThe most successful supervised phrase-structure parsers are feature-rich discriminativeparsers that heavily depend on an underlying PCFG grammar (Charniak and Johnson2005; Huang 2008).
These approaches consist of two stages.
At the first stage they applya PCFG grammar to extract possible parses.
The full set of possible parses cannot beiterated through in practice, and is usually pruned as a consequence.
The n-best listparsers keep just the 50?100 best parses according to the PCFG.
Other methods removenodes and edges from the packed parse forest whose posterior probability is under apre-defined threshold (Charniak and Johnson 2005).The task of the second stage is to select the best parse from the set of possibleparses (i.e., rerank this set).
These methods use a large feature set (usually a fewmillion features) (Collins 2000; Charniak and Johnson 2005).
The n-best list approachescan straightforwardly use local and non-local features as well because they decide atthe sentence-level (Charniak and Johnson 2005).
Involving non-local features is morecomplicated in the forest-based approaches.
The conditional random field methodsusually use only local features (Yusuke and Jun?ichi 2002; Finkel, Kleeman, andManning 2008).
Huang (2008) introduced a beam-search and average perceptron-basedprocedure incorporating non-local features in a forest-based approach.
His empiricalresults show only a minor improvement from incorporating non-local features,however.In this study, we experiment with n-best list reranking using a maximum entropymachine learning model for (re)ranking along with local and non-local features.
Ourreranking framework follows Charniak and Johnson (2005).
At the first-stage of parsing,we extract the 100 best parses for a sentence according to BitPar?s probability model.At parsing time, a weight vector w is given for the feature vectors (which numericallyrepresent one possible parse) and we select the parse with the highest inner productof these two vectors.
The goal of training is to adjust w. In the maximum entropyframework, this is achieved by solving the optimization problem of maximizing theposterior probability of the oracle parse?the parse with the highest F-score.19 Ourmethod aims to select the oracle, as the gold standard parse is often not present inthe 100-best parses.20 Our preliminary experiments showed that parse candidates close19 Ties are broken using the PCFG probabilities of the parses.20 The oracle F-score (i.e., the upper limit of 100-best reranking on the Tiger development corpus) is 90.17.73Computational Linguistics Volume 39, Number 1to the oracle confuse training.
Hence during training, we removed all parses whoseF-score is closer than 1.0 to the score of the oracle.21As we discussed in Section 1, the parsing output of morphologically rich languagesis useful only when it is additionally annotated with grammatical functions.
The oracleparses often change if the grammatical function labels are also taken into considerationat the PARSEVAL score calculation.
Hence slightly different objective functions are usedin the two cases.
We will report results achieved by reranking models where the oracleselection for training agrees with the evaluation metric utilized?that is, we traineddifferent models (which differ in the oracle selection) for the basic constituent labelevaluation and for the evaluation on grammatical functions.During training we followed an eight-fold cross validation technique for candidateextraction (Collins 2000).
Here, one-eighth of the training corpus was parsed with aPCFG extracted from seven-eighths of the data set.
This provides realistic trainingexamples for the reranker as these parses were not seen during grammar extraction.
Weused the ranking MaxEnt implementation of MALLET (McCallum 2002) with defaultparameters.7.
Monolingual Reranking7.1 Subcategorization-Based Monolingual Reranking FeaturesWe introduce here several novel subcategorization-based features for monolingualreranking.
For this, we first describe our algorithm for extracting subcategorization(subcat) information.
We use our enriched version of the Tiger2 training set.
In orderto extract verbal subcat frames we find all nodes labeled with the category S (clause)or VP-MO (modifying VP) and extract their arguments.
Arguments22 are nodes of thecategories shown in Table 2.
The arguments of nouns are obtained by looking for NNnodes which are either dominated by an NP or a PP, and which take a following nodeof category PP, VP-OC, or S-OC as argument.The feature functions we present are mostly lexicalized.
This means we need accessto the head words of the arguments.
The argument heads are extracted as follows: AsNP headwe take the last nodewhose function label is either HD,NK, or PH.
If this nodeis of category NP or PN, we recursively select the head of that constituent.
Similarly, thehead of an AP is the last node with functional label HD.
If it is an AP, the head issearched inside of it.
In the case of PPs, we extract two heads, namely, the preposition(or postposition) as well as the nominal head of the PP, which is found using similarrules as for NPs.
We also extract the case of the nominal head.The extraction of verbal heads is somewhat more complicated.
In order to obtainthe correct verbal head of a clause irrespective of the verb position (verb-first, verb-second, verb-final), we extract all verbs that are dominated by the clause and a possiblyempty sequence of VP-OC or VP-PD (statal passive) nodes and an optional VZ-HDnode.
Then we take the first non-finite verb, or alternatively the first finite verb if allverbs were finite.
In order to avoid sparse data problems caused by the many differentinflections of German verbs, we lemmatize the verbs.21 In Fraser, Wang, and Schu?tze (2009) we used Minimum Error Rate Training.
Once we made this changeto maximum entropy the results on small feature sets became similar (details omitted).22 An exception to this is that if a PP argument dominates a node of category PROAV-PH, it is considereda PROAV-PH argument.
An example is the sentence Er [he] wartet [waits] (PP-OP (PROAV-PH darauf[for this]), (S-RE dass [that] sie [she] kommt [comes])).74Fraser et alKnowledge Sources for Parsing GermanTable 2Arguments used in extracted subcategorization frames.NP-SB, PN-SB, CNP-SB, S-SB, VP-SB subjectsNP-OA, PN-OA, CNP-OA direct objectsNP-DA, PN-DA, CNP-DA indirect objectsPRF-OA reflexive direct objectsPRF-DA reflexive indirect objectsNP-PD, CNP-PD predicative NPsADJD-PD, AP-PD, CAP-PD predicative adjectivesS-OC, CS-OC argument clausesPP-OP, CPP-OP PP argumentsVP-OC/zu infinitival complement clausesPROAV-OP pronominal adverbs serving as PP proxies such asdaraus [out of this]NP-EP expletive subjectsVP-RE, NP-RE VP/NP appearing in expletive constructionsIn the case of coordinated phrases, we take the head of the first conjunct.
Argumentsare sorted to put them in a well-defined order.
An example is that given the correctparse of the sentence Statt [instead of] Details [details] zu [to] nennen [name], hat [has]er [he] unverdrossen [assiduously] die [the] ?Erfolgsformel?
[formula of success] wiederholt[repeated], meaning ?instead of naming the details, he assiduously repeated the formulaof success,?
we extract the two subcat frames:VP-MO OBJ:Details VZ-HD:zu:nennenS-TOP VP-MO SUBJ:er OBJ:Erfolgsformel VVPP-HD:wiederholtWe can now describe our features.
The features focus on subcat frames taken fromS nodes (VP-MO is treated as S), and on attachment of prepositions and conjunctions tonouns.
We define conditional probability and mutual information (MI) features.The two conditional probability features are ProbPrepAttach and ProbAdverb-Attach, which calculate the probability for each preposition or adverb to be attachedto its governor, given the label of the governor.
We estimate this from the trainingdata as follows, for the example of the PP feature.
In the feature scoring, we giveeach preposition attachment a score which is the negative log10 of the probabil-ity p(lex prep|label governor) = f (lex prep, label governor)/f (label governor) (with acutoff of 5).For all of our other monolingual features, we use (negative) pointwise mutualinformation: ?log10(p(a, b)/p(a)p(b)) (here we use cutoffs of 5 and ?5).MI NounP and MI NounConj give an assessment of a preposition or a conjunctionbeing attached to a noun (given the lexicalized preposition and the lexicalized noun).For the MI VSubcat feature, we use as a the frame (without lexicalization), and asb the head verb.
p(a) is estimated as the relative frequency of this frame over all framesextracted from Tiger2 train.
MI VSimpleSubcat is a simpler version of MI VSubcat.PP is excluded from frames because PP is often an adjunct rather than an argument.For the MI VArg feature, we use as a the argument function and the head wordof the argument (e.g., OBJ:Buch, which is ?book?
used as an object).
As b we againuse the head verb.
The estimate of p(a) is frequency(OBJ:Buch)/(total number ofextracted frames).23 In addition, this feature is refined into individual features for23 We make the assumption that every frame has an object, but that this object can be NULL.75Computational Linguistics Volume 39, Number 1different kinds of arguments: MI VSubj, MI VObj, MI VIobj, MI VPP, MI VPRF,MI VS OC, MI VVP, and MI VerbPROAV.
As an example, the MI of ?lesen, OBJ:Buch?
(reading, object:Book) would be used for the MI VArg features and for the MI VObjfeature.
For functions such as MI VPP which are headed by both a function word (here,a preposition) and a content word, only the function word is used (and no case).The last MI feature is MI VParticle.
Some German verbs contain a separable parti-cle, which can also be analyzed as an adverb but will then have a different meaning.
Forthe sentence ?Und [and] Frau [Mrs.] Ku?nast [(proper name)] bringt [brings] das [that] auch[also] nicht [not] ru?ber [across],?
if ?ru?ber?
is analyzed as an adverb, the verb means tocarry/take/bring over [to another physical location], but if it is viewed as a particle, thesentence means Frau Ku?nast is not able to explain this.
The feature MI VParticle helpswith this kind of disambiguation.7.2 The Versley and Rehbein Feature SetWe also carried out experiments with the feature set of Versley and Rehbein (2009),which is specially designed for German.
It consists of features constructed from thelexicalized parse tree along with features based on external statistical information.The features here are local in the sense that their values can be computed at theconstituent in question, its daughters, and its spanning words.
All features exceptthe external statistical information are binary and indicate that a lexicalized pattern ispresent in the parse.
They were originally designed for forest-based reranking (Versleyand Rehbein 2009).
Following Charniak and Johnson (2005) we sum up these localfeature values in the parse tree.
Thus our versions count the number of times that aparticular pattern occurs in the entire parse tree.The patterns used can be further subcategorized into three groups.
The wordform-based patterns are token?POS (e.g., one pattern is ?lesen-VVINF?)
and the word classof the token in question (word class comes from an automatic clustering of words basedon contextual features).
The constituent-based patterns are the size of the constituent,the constituent label, and the right-hand side of the derivational rule applied at the nodein question.
The last and biggest group of the pattern features is formed by the bilexicaldependencies.
They are based on the head word of the constituent node in questionand its daughters.
Versley and Rehbein (2009) have also introduced features that exploitstatistical information gathered from an external data set and aim to resolve PP attach-ment ambiguity.
Mutual information values were gathered on the association betweennouns and immediately following prepositions, as well as between prepositions andclosely following verbs on the DE-WaC corpus (Baroni and Kilgarriff 2006).
Thesefeature values were then used at NP?PP and VP?PP daughter attachments.A total of 2.7 million features fired in the Tiger train.
We ignored features firingin less than five sentences for computational efficiency, resulting in 117,000 extremelysparse features.7.3 Monolingual Reranking ExperimentsWe rerank 100-best lists from BitPar (Schmid 2004), which uses the grammar extractionprocedure and lexical resources introduced in Section 3.
In each of the experiments weextracted the grammar from the Tiger train and used it to obtain the 100-best parses forthe sentences of the evaluation corpus.We trained reranking models on the Tiger train as described in Section 6 using oursubcategorization-based features, the Versley09 feature set, and the union of these two76Fraser et alKnowledge Sources for Parsing GermanTable 3The PARSEVAL score of monolingual features to rerank the parses of Europarl (seven-waycross-validation on 662 sentences) and Tiger2 (development and test sets).Tiger dev Tiger test Europarl CROSS Europarl INBaseline 82.42 (72.36) 76.84 (65.91) 77.13 (66.06)subcat 83.19 (73.63) 77.65 (67.21) 77.23 (66.13) 77.73 (66.95)Versley09 83.56 (73.89) 78.57 (68.42) 77.82 (66.87) 77.62 (66.05)subcat+Versley09 84.19 (74.96) 78.86 (69.04) 77.76 (66.84) 77.93 (66.75)sets.
We evaluated the models on Tiger dev, Tiger test, and Europarl.
As the domainsof Tiger and Europarl are quite different, besides this cross-domain parser evaluation(CROSS) we carried out an in-domain (IN) evaluation as well.
In the latter we followedthe seven-fold cross-validation approach, that is, the reranking models were trained onsix-sevenths of Europarl.
The results are presented in Table 3.The results presented in Table 3 show that the reranking models achieve an im-provement over the baseline parser using both our and the Versley09 feature sets.
TheVersley09 feature set achieved better results than our monolingual features when atraining dataset with sufficient size is given (Tiger).
On the other hand using our 16rich features (compared with 117,000 sparse features) is more suitable for the settingswhere only a limited amount of training instances are available (the training sets consistof 567 sentences of Europarl in seven-fold cross-validation).
The rerankingmodels usingthe union of the feature sets obtain close to the sum of the improvements of the two in-dividual feature sets.
The subcategorization features model rich non-local information,and the fine-grained features capture local distinctions well and the features based onthe Web corpus access additional knowledge.We performed an experiment adding one feature at a time, and found that themost effective features were ProbAdverbAttach, MI VPP, MI VPRF, MI VSubj, andMI VArg.
After this the variation caused by numeric instability was too high to see aconsistent incremental gain from the rest of the features.
We conclude that these featurescan be robustly estimated and have more discriminative power than the others, but weemphasize that we used all features in our experiments.Figure 5 shows a parse tree produced by the BitPar parser in which the noun phrasediese Finanzierung is incorrectly classified as an accusative object.
The monolingualsubcategorization features MI VSubcat, MI VSimpleSubcat, and MI VArg enable thereranker to correctly analyze the noun phrase as a subject and to move it from the VPlevel to the S level..S-TOPPWAV-MOWoherwhere-fromVMFIN-HDsollshouldVP-OCNP-OAPDAT-HDdiesethisNN-HDFinanzierungfinancingVVINF-HDkommencomeFigure 5Erroneous parse produced by BitPar that is corrected by monolingual features.77Computational Linguistics Volume 39, Number 18.
Bilingual RerankingWe now present our bilingual reranking framework.
This follows our previous work(Fraser, Wang, and Schu?tze 2009), which defined feature functions for rerankingEnglish parses, but now we will use these same feature functions (and three additionalfeature functions introduced to capture phenomena higher in the syntactic tree) torerank German parses.
The intuition for using this type of bitext projection feature isthat ambiguous structures in one language often correspond to unambiguous structuresin another.
Our feature functions are functions on the hypothesized English parse e,the German parse g, and the word alignment a, and they assign a score (varyingbetween 0 and infinity) that measures syntactic divergence.
The alignment of a sentencepair is a function that, for each English word, returns a set of German words withwhich the English word is aligned.
Feature function values are calculated either bytaking the negative log of a probability, or by using a heuristic function which scalessimilarly.24The bilingual feature functions we define are functions that measure differ-ent types of syntactic divergence between an English parse and a German parse.Charniak and Johnson (2005) defined the state of the art in discriminative n-bestconstituency parsing of English syntax (without the use of self-training).
The n-bestoutput of their generative parser is reranked discriminatively by a reranker.
We callthis CJRERANK.
We will use an array of feature functions measuring the syntacticdivergence of candidate German parses with the projection of the English parseobtained from CJRERANK.In our experiments we use the English text of the parallel Treebank extracted fromthe Europarl corpus and annotated by Pado?
and Lapata (2009).
There are 662 Germansentences that are aligned to single English sentences; this is the set that we use.
Due tothe limited number of trees, we perform cross-validation to measure performance.The basic idea behind our feature functions is that any constituent in a sentenceshould play approximately the same syntactic role and have a similar span as the corre-sponding constituent in a translation.
If there is an obvious disagreement, it is probablycaused by wrong attachment or other syntactic mistakes in parsing.
Sometimes intranslation the syntactic role of a given semantic constituent changes; we assume thatour model penalizes all hypothesized parses equally in this case.To determine which features to describe here we conducted a greedy feature addi-tion experiment (adding one feature at a time), on top of our best monolingual system(combining both subcat and Versley09 feature sets).
All bilingual experiments use all ofthe features (not just the features we describe here).
Definitions are available.25BitParLogProb (the only monolingual feature used in the bilingual-only experi-ment) is the negative log probability assigned by BitPar to the German parse.8.1 Count Feature FunctionsCount feature functions count projection constraint violations.Feature CrdBin counts binary events involving the heads of coordinated phrases.
Ifwe have a coordination where the English CC is aligned only with a German KON, and24 A probability of 1 is a feature value of 0, whereas a low probability is a feature value which is0.25 See http://www.ims.uni-stuttgart.de/tcl/RESOURCES/CL.html.78Fraser et alKnowledge Sources for Parsing GermanTable 4Other projection features selected; see the previously mentioned Web page25 for precisedefinitions.POSParentPrjWordPerG2E Computes the span difference between all the parent constituentsof POS tags in a German parse and their respective coveragein the corresponding English parse, measured using percentagecoverage of the sentence in words.
The feature value is the sumof all the differences.
The projection direction is from German toEnglish.AbovePOSPrjPer Projection direction is from English to German, and measured inpercentage sentence coverage using characters, not words.
Thefeature value is calculated over all constituents above the POSlevel in the English tree.AbovePOSPrjWord Calculates a length-based difference using words.POSPar2Prj Only applies when the POS tag?s parent has two children (thePOS tag has only one sibling).
Projects from English to Germanand calculates a length-based difference in characters.POSPar2PrjPer Calculates a percentage-based difference based on characters.POSPar2PrjG2E Like POSPar2Prj except projects from German to English.POSPar2PrjWordG2E Like POSPar2PrjG2E except uses word-based differences.both have two siblings, then the value contributed toCrdBin is 1 (indicating a constraintviolation) unless the head of the English left conjunct is aligned with the head of theGerman left conjunct and likewise the right conjuncts are aligned.Feature Q simply captures a mismatch between questions and statements.
If aGerman sentence is parsed as a question but the parallel English sentence is not, orvice versa, the feature value is 1; otherwise the value is 0.Feature S-OC considers that a clausal object (OC) in a German parse should beprojected to a simple declarative clause in English.
This feature counts violations.EngPPinSVP checks whether a PP inside of a S or VP in English attaches to thesame (projected) constituent in German.
If an English PP follows immediately a VP ora single verb, and the whole constituent is labeled ?S?
or ?VP,?
then the PP should beidentified as governed by the VP.
In this case the corresponding German PP shouldattach as well to the German VP to which the English VP is projected (attachment inGerman can be to the left or to the right).
If the governor in German does not turn out tobe a VP or have a tag starting with ?V,?
a value of 1 will be added to the feature for thisGerman parse.EngLeftSVP checks whether the left sibling of S or VP in English attaches to thesame (projected) constituent in German (where attachment can be left or right).
Thisfeature counts violations.Span Projection Feature Functions.
Span projection features calculate an absolute orpercentage difference between a constituent?s span and the span of its projection.
Spansize is measured in characters or words.
To project a constituent in a parse, we use theword alignment to project all word positions covered by the constituent and then lookfor the smallest covering constituent in the parse of the parallel sentence.PPParentPrjWord checks the correctness of PP attachment.
It projects all the parentsof PP constituents in an English parse to German, and sums all the span differences.
It ismeasured in words.
In addition to PPParentPrjWord we implement two bonus features,NonPPWord and NonPPPer.
The former simply calculates the number of words that79Computational Linguistics Volume 39, Number 1do not belong to PP phrases in the sentence, and the latter computes the non-PPproportion in a character-based fashion.
These can be thought of as tunable parameterswhich adjust PPParentPrjWord to not disfavor large PPs.
The other selected projectionfeatures are described in Table 4.Probabilistic Feature Functions.
We use Europarl (Koehn 2005), from which weextract a parallel corpus of approximately 1.22 million sentence pairs, to estimatethe probabilistic feature functions described in this section.We describe the feature PTag, despite the fact that it was not selected by the featureanalysis, because several variations (described next) were selected.
PTag measurestagging inconsistency based on estimating the probability for each English word thatit has a particular POS tag, given the aligned German word?s POS tag.
To avoid noisyfeature values due to outliers and parse errors, we bound the value of PTag at 5.26 Weuse relative frequency to estimate this feature.
When an English word is aligned withtwo words, estimation is more complex.
We heuristically give each English and Germanpair one count.
The value calculated by the feature function is the geometric mean27 ofthe pairwise probabilities.The feature PTagEParent measures tagging inconsistency based on estimating theprobability that the parent of the English word at position i has a particular tag, giventhe aligned German word?s POS label.
PTagBiGLeft measures tagging inconsistencybased on estimating the probability for each English word that it has a particular POStag, given the aligned German word?s label and the word to the left of the alignedGerman word?s label.
PTagBiGParent measures tagging inconsistency based on esti-mating the probability for each English word that it has a particular POS tag, given thealigned German word?s label and the German word?s parent?s label.8.2 Bilingual Reranking ExperimentsWe performed experiments looking at bilingual reranking performance.
To train theparameters of the probabilistic feature functions, we use 1-best parses of the largeEuroparl parallel corpus (from CJRERANK and BitPar).
We work on the same 100-bestlist (of the German sentences in the small Pado?
set) as was used in the previous section.We parse the English sentences of the small Europarl set with CJRERANK; this parse isused as our bilingual knowledge source.
Finally we rerank using the bilingual features(results in the first row of Table 5).We then combine the monolingual features with the bilingual features.
We rerankusing both the monolingual and the bilingual features together, and the results arepresented in Table 5.
The bilingual feature-based reranker achieved 1 percentage pointimprovement over the baseline.
This advantage was just slightly decreasedwhenmono-lingual features are also present.
This indicates again that themonolingual and bilingualfeatures can capture different linguistic phenomena and their information content israther different.
As in the Europarl IN setting, using the large sparse Versley09 featureset the reranker could not learn a meaningful model from a moderate-sized trainingdata set.26 Throughout this paper, assume log(0) = ?
?.27 Each English word has the same weight regardless of whether it was aligned with one or with moreGerman words.80Fraser et alKnowledge Sources for Parsing GermanTable 5PARSEVAL scores of bi+monolingual features to rerank the parses of Europarl (seven-waycross-validation) and the added value of bilingual features over the results achieved by thecorresponding monolingual feature set.Mono features without bilingual with bilingual added valueNONE 77.13 (66.06) 78.10 (67.12) +0.97 (+1.06)subcat 77.73 (66.95) 78.54 (67.95) +0.78 (+1.00)Versley09 77.62 (66.05) 77.71 (66.06) +0.09 (+0.01)subcat+Versley09 77.93 (66.75) 78.70 (67.45) +0.78 (+0.70)The parse tree in Figure 6 demonstrates the value of bilingual features.
It wasproduced by the monolingual reranker and it incorrectly combines the two adverbs aberand ebenso into an adverbial phrase and places this under the VP.
The bilingual rerankerinstead attaches the two adverbs separately at the S level.
The attachment to the S nodeindicates that the two adverbs modify the modal verb kann and not the full verb sagen.This is triggered by the feature POSPar2Prj.8.3 Previous Work on Bitext ParsingBitext parsing was also addressed by Burkett and Klein (2008).
In that work, they usefeature functions defined on triples of (English parse tree, Chinese parse tree, alignment)which are combined in a log-linear model, much as we do.
In later work (Burkett,Blitzer, and Klein 2010), they developed a unified joint model for solving the sameproblem using a weakly synchronized grammar.
To train these models they use a smallparallel Treebank that contains gold standard trees for parallel sentences in Chineseand English, whereas we only require gold standard trees for the language we arereranking.
Another important difference is that Burkett and Klein (2008) use a largenumber of automatically generated features (defined in terms of feature generationtemplates) whereas we use a small number of carefully designed features that we foundby linguistic analysis of parallel corpora.
Burkett, Blitzer, and Klein (2010) use a subsetof the features of Burkett and Klein (2008) for synchronization, along with monolin-gual parsing and alignment based features.
Finally, self-training (McClosky, Charniak,and Johnson 2006b) is another differentiator of our work.
We use probabilities esti-mated from aligned English CJRERANK parses and German BitPar parses of the largeEuroparl corpus in our bilingual feature functions.
These feature functions are used to.S-TOPPIS-SBManoneVMFIN-HDkanncanVP-OCAVP-MOADV-MOaberbutADV-HDebensojust-as-wellVVINF-HDsagensay,,S-OCKOUS-CPdassthatPPER-SBsietheyADJD-PDanspruchsvolldemandingVAFIN-HDsindareFigure 6Erroneous parse produced by the reranker using only monolingual features, which is correctedby bilingual features.
The sentence means One can, however, just as well say that they are demanding.81Computational Linguistics Volume 39, Number 1improve ranking of German BitPar parses in the held-out test sets, which is a form ofself-training.Two other interesting studies in this area are those of Fossum and Knight (2008)and of Huang, Jiang, and Liu (2009).
They improve English prepositional phrase at-tachment using features from a Chinese sentence.
Unlike our approach, however, theydo not require a Chinese syntactic parse as the word order in Chinese is sufficient tounambiguously determine the correct attachment point of the prepositional phrase inthe English sentence without using a Chinese syntactic parse.We know of no other work that has investigated to what extent monolingual andbilingual features in parse reranking are complementary.
In particular, the work on bi-text parsing by Burkett and Klein (2008) does not address the question as to whether theeffect of monolingual and bilingual features in parse reranking is (partially) additive.We demonstrate bilingual improvement for a strong parser of German.
Previously,we showed bilingual improvement for parsing English with an unlexicalized parser(Fraser, Wang, and Schu?tze 2009), using 34 of the 37 bilingual feature functions we usein this work.9.
ConclusionIn this paper, we have focused on MR&LC languages like German?languages thatare morphologically rich, but also have a strong configurational component.
We haveargued that constituency parsing is, perhaps contrary to conventional wisdom, an ap-propriate parsing formalism for MR&LC because constituents capture configurationalconstraints in a transparent way and because for many applications constituency pars-ing is preferable to dependency parsing.
Our detailed description of a constituencyparsing system for a morphologically rich language, a system that addresses the majorproblems that arise in constituency parsing for MR&LC, is one main contribution of thispaper.
Two of these problems are rule proliferation and syncretism.
We have addressedrule proliferation bymarkovization and syncretism by (i) deploying a high performancefinite-state-based morphological analyzer that is based on rich lexical knowledge and(ii) encoding grammatical functions directly as part of the phrase labels.
This directencoding allows us to directly combine morphological and configurational informa-tion in parsing and arrive at a maximally disambiguated parse.
We argued that thisis the right setup for MR&LC languages because applications must have access togrammatical functions.A large part of this paper was concerned with making available and evaluatingadditional knowledge sources for improved parsing of the MR&LC language German.Our motivation was that (as we argued) MR&LC languages have in general higher am-biguity than purely configurational and purely morphological languages, in particularwith respect to grammatical functions.
Apart from the lexical knowledge embeddedin the morphological analyzer, we presented work on two other knowledge sources toaddress this type of additional ambiguity: monolingual reranking (which looks at globalsentence-wide constraints for disambiguation) and bitext reranking (which exploitsparallel text for disambiguation).
We were able to improve the performance of a strongbaseline parser using these three knowledge sources and we showed that they arelargely complementary: Performance improvements were additive when we used themtogether.
The resulting parser is currently the best constituent parser for German (withor without bilingual features).New languages and even new domains can require new treebanks.
To create sucha treebank for a MR&LC language, we would first annotate a small number of gold82Fraser et alKnowledge Sources for Parsing Germanstandard trees, using parallel text with English or another language if such text isavailable.
Next, wewould consider how to quickly differentiate constituents of the sametype using constituent labels plus grammatical functions, as we outlined in Section 3.Following this, we would use BitPar to build a parser in the same way as we presentedhere, and to determine the optimal level of markovization, which we assume would bevery high with a small number of gold standard training trees.
Next, as more trees areannotated in an active learning framework, we would begin to develop morphologicalanalysis.
We would implement the bilingual framework following this (if we haveaccess to bitext).
Then we would implement basic subcategorization extraction and addmonolingual features.
Finally, as more gold standard trees are annotated, the rerankingframework should be constantly retrained.
In particular, we expect that the effect of theknowledge sources we have presented will be much stronger when starting with lesstraining data.Our work in this paper will be of use to developers of German syntactic parsersas we have state-of-the-art performance using linguistically motivated features that areeasy to understand.
We also hope that our work can serve as a cookbook of ideas to tryfor others working on parsers for other morphologically rich languages.AcknowledgmentsWe would like to thank Sandra Ku?bler andYannick Versley.
We gratefully acknowledgeDeutsche Forschungsgemeinschaft (DFG)for funding this work (grants SCHU 2246/6-1Morphosyntax for MT and SFB 732D4Modular lexicalization of PCFGs).
Thiswork was supported in part by the ISTProgramme of the European Community,under the PASCAL2 Network of Excellence,IST-2007-216886.
This publication onlyreflects the authors?
views.ReferencesBaroni, Marco and Adam Kilgarriff.
2006.Large linguistically processed Webcorpora for multiple languages.In EACL: Posters & Demonstrations,pages 87?90, Trento.Black, E., S. Abney, S. Flickenger,C.
Gdaniec, C. Grishman, P. Harrison,D.
Hindle, R. Ingria, F. Jelinek,J.
Klavans, M. Liberman, M. Marcus,S.
Roukos, B. Santorini, andT.
Strzalkowski.
1991.
Procedure forquantitatively comparing the syntacticcoverage of English grammars.
InProceedings of the Workshop on Speechand Natural Language, HLT ?91,pages 306?311, Pacific Grove, CA.Brants, Sabine, Stefanie Dipper, SilviaHansen, Wolfgang Lezius, and GeorgeSmith.
2002.
The TIGER Treebank.In Proceedings of the Workshop onTreebanks and Linguistic Theories,pages 24?41, Sozopol.Brants, Thorsten.
2000.
TnT?a statisticalpart-of-speech tagger.
In ANLP,pages 224?231, Seattle, WA.Burkett, David, John Blitzer, and Dan Klein.2010.
Joint parsing and alignmentwith weakly synchronized grammars.In HLT-NAACL, pages 127?135,Los Angeles, CA.Burkett, David and Dan Klein.
2008.
Twolanguages are better than one (for syntacticparsing).
In EMNLP, pages 877?886,Honolulu, HI.Cai, Shu, David Chiang, and Yoav Goldberg.2011.
Language-independent parsing withempty elements.
In ACL, pages 212?216,Portland, OR.Campbell, Richard.
2004.
Using linguisticprinciples to recover empty categories.In ACL, pages 645?652, Barcelona.Charniak, Eugene and Mark Johnson.
2005.Coarse-to-fine n-best parsing and MaxEntdiscriminative reranking.
In ACL,pages 173?180, Ann Arbor, MI.Collins, Michael.
1997.
Three generative,lexicalized models for statistical parsing.In ACL, pages 16?23, Madrid.Collins, Michael.
2000.
Discriminativereranking for natural language parsing.In ICML, pages 25?70, Stanford, CA.Cutting, Doug, Julian Kupiec, Jan Pedersen,and Penelope Sibun.
1992.
A practicalpart-of-speech tagger.
In ANLP,pages 133?140, Trento.Dreyer, Markus, David A. Smith, andNoah A. Smith.
2006.
Vine parsing andminimum risk reranking for speed andprecision.
In CoNLL, pages 201?205,New York, NY.83Computational Linguistics Volume 39, Number 1Dubey, Amit.
2004.
Statistical Parsing forGerman: Modeling Syntactic Propertiesand Annotation Differences.
Ph.D. thesis,Saarland University.Dubey, Amit and Frank Keller.
2003.Probabilistic parsing for German usingsister-head dependencies.
In ACL,pages 96?103, Sapporo.Duchier, Denys and Ralph Debusmann.2001.
Topological dependency trees:a constraint-based account of linearprecedence.
In ACL, pages 180?187,Toulouse.Finkel, Jenny Rose, Alex Kleeman, andChristopher D. Manning.
2008.
Efficient,feature-based, conditional randomfield parsing.
In ACL, pages 959?967,Columbus, OH.Forst, Martin.
2007.
Filling statisticswith linguistics?property designfor the disambiguation of GermanLFG parses.
In Proceedings of the ACLWorkshop on Deep Linguistic Processing,pages 17?24, Prague.Fossum, Victoria and Kevin Knight.
2008.Using bilingual Chinese?English wordalignments to resolve PP-attachmentambiguity in English.
In AMTA,pages 48?53, Honolulu, HI.Fraser, Alexander, Renjing Wang,and Hinrich Schu?tze.
2009.
Richbitext projection features for parsereranking.
In EACL, pages 282?290,Athens.Gabbard, Ryan, Mitchell Marcus, and SethKulick.
2006.
Fully parsing the PennTreebank.
In HLT-NAACL, pages 184?191,Morristown, NJ.Hall, Johan and Joakim Nivre.
2008.A dependency-driven parser forGerman dependency and constituencyrepresentations.
In Proceedings of theWorkshop on Parsing German, pages 47?54,Columbus, OH.Henderson, James, Paola Merlo, GabrieleMusillo, and Ivan Titov.
2008.
A latentvariable model of synchronous parsingfor syntactic and semantic dependencies.In CoNLL, pages 178?182, Manchester.Hsu, Yu-Yin.
2010.
Comparing conversionsof discontinuity in PCFG parsing.
In TLT,pages 103?113, Tartu.Huang, Liang.
2008.
Forest reranking:Discriminative parsing with non-localfeatures.
In ACL, pages 586?594,Columbus, OH.Huang, Liang, Wenbin Jiang, andQun Liu.
2009.
Bilingually constrained(monolingual) shift-reduce parsing.In EMNLP, pages 1,222?1,231,Singapore.Johnson, Mark.
1998.
PCFG modelsof linguistic tree representations.Computational Linguistics, 24(4):613?632.Johnson, Mark.
2001.
A simple pattern-matching algorithm for recovering emptynodes and their antecedents.
In ACL,pages 136?143, Philadelphia, PA.Klein, Dan and Christopher D. Manning.2003.
Accurate unlexicalized parsing.In ACL, pages 423?430, Sapporo.Koehn, Philipp.
2005.
Europarl: a parallelcorpus for statistical machine translation.InMT Summit X, pages 79?86, Phuket.Ku?bler, Sandra.
2008.
The PaGe 2008 sharedtask on parsing German.
In Proceedingsof the Workshop on Parsing German,pages 55?63, Columbus, OH.Ku?bler, Sandra, Erhard W. Hinrichs, andWolfgang Maier.
2006.
Is it really thatdifficult to parse German?
In EMNLP,pages 111?119, Sydney.Levy, Roger and Christopher D. Manning.2004.
Deep dependencies from context-freestatistical parsers: Correcting the surfacedependency approximation.
In ACL,pages 327?334, Barcelona.Lezius, Wolfgang, Stefanie Dipper, and ArneFitschen.
2000.
IMSLex?representingmorphological and syntactical informationin a relational database.
In EURALEX,pages 133?139, Stuttgart.McCallum, Andrew Kachites.
2002.
Mallet:A machine learning for language toolkit.http://mallet.cs.umass.edu.McClosky, David, Eugene Charniak,and Mark Johnson.
2006a.
Effectiveself-training for parsing.
In HLT-NAACL,pages 152?159, Morristown, NJ.McClosky, David, Eugene Charniak,and Mark Johnson.
2006b.
Rerankingand self-training for parser adaptation.In COLING-ACL, pages 337?344,Sydney.McDonald, Ryan and Fernando Pereira.2006.
Online learning of approximatedependency parsing algorithms.In EACL, pages 81?88, Trento.Menzel, Wolfgang and Ingo Schro?der.1998.
Decision procedures for dependencyparsing using graded constraints.In COLING-ACL Workshop on Processingof Dependency-Based Grammars,pages 78?87, Montreal.Pado?, Sebastian and Mirella Lapata.
2009.Cross-lingual annotation projection ofsemantic roles.
Journal of ArtificialIntelligence Research, 36:307?340.84Fraser et alKnowledge Sources for Parsing GermanPetrov, Slav and Dan Klein.
2007.
Improvedinference for unlexicalized parsing.In HLT-NAACL, pages 404?411,Rochester, NY.Petrov, Slav and Dan Klein.
2008.
ParsingGerman with latent variable grammars.In Proceedings of the Workshop on ParsingGerman, pages 33?39, Columbus, OH.Quirk, Chris and Simon Corston-Oliver.2006.
The impact of parse quality onsyntactically-informed statisticalmachine translation.
In EMNLP,pages 62?69, Sydney.Quirk, Chris, Arul Menezes, andColin Cherry.
2005.
Dependency treelettranslation: Syntactically informedphrasal SMT.
In ACL, pages 271?279,Oxford.Rafferty, Anna and Christopher D. Manning.2008.
Parsing three German Treebanks:Lexicalized and unlexicalized baselines.In Proceedings of the Workshop on ParsingGerman, pages 40?46, Columbus, OH.Rambow, Owen.
2010.
The simple truthabout dependency and phrase structurerepresentations: an opinion piece.In HLT-NAACL, pages 337?340,Los Angeles, CA.Rehbein, Ines and Josef van Genabith.2007.
Evaluating evaluation measures.In NODALIDA, pages 372?379, Tartu.Schiehlen, Michael.
2004.
Annotationstrategies for probabilistic parsing inGerman.
In COLING, pages 390?396,Geneva.Schmid, Helmut.
1995.
Improvements inpart-of-speech tagging with an applicationto German.
In Proceedings of the ACLSIGDAT-Workshop, pages 47?50, Dublin.Schmid, Helmut.
2004.
Efficient parsingof highly ambiguous context-freegrammars with bit vectors.
In COLING,pages 162?168, Geneva.Schmid, Helmut.
2006.
Trace predictionand recovery with unlexicalized PCFGsand slash features.
In COLING-ACL,pages 177?184, Sydney.Schmid, Helmut, Arne Fitschen, andUlrich Heid.
2004.
SMOR: A Germancomputational morphology coveringderivation, composition and inflection.In LREC, pages 1,263?1,266, Lisbon.Seeker, Wolfgang, Bernd Bohnet, Lilja?vrelid, and Jonas Kuhn.
2010a.Informed ways of improving data-drivendependency parsing for German.
InCOLING: Posters, pages 1,122?1,130,Beijing.Seeker, Wolfgang, Ines Rehbein, Jonas Kuhn,and Josef Van Genabith.
2010b.
Hardconstraints for grammatical functionlabelling.
In ACL, pages 1,087?1,097,Uppsala.Shen, Libin, Jinxi Xu, and Ralph Weischedel.2008.
A new string-to-dependencymachine translation algorithm with atarget dependency language model.
InACL-HLT, pages 577?585, Columbus, OH.Tsarfaty, Reut, Joakim Nivre, and EvelinaAndersson.
2012.
Cross-frameworkevaluation for statistical parsing.In EACL, pages 44?54, Avignon.Tsarfaty, Reut, Djame?
Seddah, YoavGoldberg, Sandra Kuebler, YannickVersley, Marie Candito, Jennifer Foster,Ines Rehbein, and Lamia Tounsi.
2010.Statistical parsing of morphologicallyrich languages (SPMRL) what, how andwhither.
In Proceedings of the NAACL HLT2010 First Workshop on Statistical Parsing ofMorphologically-Rich Languages, pages 1?12,Los Angeles, CA.Tu, Zhaopeng, Yang Liu, Young-SookHwang, Qun Liu, and Shouxun Lin.
2010.Dependency forest for statistical machinetranslation.
In COLING, pages 1,092?1,100,Beijing.Versley, Yannick.
2005.
Parser evaluationacross text types.
In Fourth Workshop onTreebanks and Linguistic Theories (TLT),pages 209?220, Barcelona.Versley, Yannick and Ines Rehbein.
2009.Scalable discriminative parsing forGerman.
In IWPT, pages 134?137, Paris.Weischedel, Ralph, Marie Meteer, RichardSchwartz, Lance Ramshaw, and JeffPalmucci.
1993.
Coping with ambiguityand unknown words through probabilisticmodels.
Computational Linguistics,19(2):359?382.Yusuke, Miyao and Tsujii Jun?ichi.
2002.Maximum entropy estimation forfeature forests.
In HLT, pages 292?297,San Diego, CA.85
