QCS: A Tool for Querying, Clustering, and Summarizing DocumentsDaniel M. DunlavyUniversity of Marylandddunlavy@cs.umd.eduJohn ConroyIDA/CCSconroy@super.orgDianne P. O?LearyUniversity of Marylandoleary@cs.umd.eduAbstractThe QCS information retrieval (IR) system ispresented as a tool for querying, clustering, andsummarizing document sets.
QCS has been de-veloped as a modular development framework,and thus facilitates the inclusion of new tech-nologies targeting these three IR tasks.
Detailsof the system architecture, the QCS interface,and preliminary results are presented.1 IntroductionQCS is a software tool and development framework forefficient, organized, and streamlined IR from genericdocument sets.
The system is designed to match a queryto relevant documents, cluster the resulting subset of doc-uments by topic, and produce a single summary for eachtopic.
Using QCS for IR, the amount of redundant infor-mation presented to a user is reduced and the results arecategorized by content.A survey of previous work using a combination of clus-tering and summarization to improve IR can be found inRadev et al (2001b).
Of existing IR systems employ-ing this combination, QCS most resembles the NewsIn-Essence system (Radev et al, 2001a) in that both sys-tems can produce multi-document summaries from doc-ument sets clustered by topic.
However, NewsInEssenceis designed for IR from HTML-linked document sets andQCS has been designed for IR from generic documentsets.
Furthermore, one of the most important aspects ofQCS is its modularity, with the ability to plug in alterna-tive implementations of query-based retrieval, documentclustering, and summarization algorithms.2 Querying, Clustering, SummarizingQCS employs a vector space model (Salton et al, 1975)to represent a set of documents.
Choices for the termweighting currently include the following:?
Local: term frequency, log, binary?
Global: none, normal, idf, idf2, entropy?
Normalization: none, normalizedDetailed descriptions of each of these weighting factorsas well as strategies for using each of these are presentedby Dumais (1991) and Kolda and O?Leary (1998).The current computational methods used for retrievinga set of documents that best match a query, clustering aset of documents by topic, and creating a summary ofmultiple documents are as follows:?
Querying: Latent Semantic Indexing (LSI)?
Clustering: spherical k-means?
Summarization: a hidden Markov model (HMM)and pivoted QRDetailed descriptions of these methods presented in Deer-wester et al (1990), Dhillon and Modha (2001), andSchlesinger et al (2002), respectively.The interface to QCS (see Figure 1) consists of a col-lection of JavaTM 1 servlets which format input to andoutput from QCS via dynamic HTML documents.
Thisapproach allows all of the computation and formatting totake place on a JavaTM server, with the only requirementon the users?
systems being that of an HTML-enabledbrowser application (e.g., Netscape R?
7.0 ).3 ResultsQCS was tested using data from the 2002 Document Un-derstanding Conference (http://duc.nist.gov/),a conference focusing on summarization and the evalu-ation of summarization systems.
The data consisted of567 news articles categorized into four types, with onetype consisting of articles covering a single natural disas-ter event reported within a seven day window.Results of one test producing 100-word extract sum-maries can be seen in Figure 1, where the query consistedof the words, ?hurricane?
and ?earthquake?.
The topthree scoring clusters contained a total 55 articles (32, 11,and 12, respectively), producing the summaries shownin the figure.
The topics of these three summaries werea hurricane near Jamaica, catastrophe insurance, and anearthquake in California, respectively.
Despite the lim-itations of automatic summarization, this example illus-1 JavaTM is a trademark of Sun Microsystems, Inc.Edmonton, May-June 2003Demonstrations , pp.
11-12Proceedings of HLT-NAACL 2003Figure 1: The interface to the QCS system includes 1) an input section for the query and choice of document set,2) a navigation section with links to clustered documents (Q: top documents retrieved for the query and their scores,C: documents from which summary sentences were drawn and the sentence indices, S: links to multiple or singledocument summaries), and 3) an output viewing section, which here contains the default output of multiple documentsummaries for the topic clusters.trates the utility of summarizing by cluster rather thanproducing a single summary of the retrieved documents.Further results are planned for the demonstration, in-cluding results of using QCS against the data from the2003 Document Understanding Conference.AcknowledgementsThe authors would like to thank C. David Levermore andWilliam D. Dorland of the University of Maryland fortheir helpful remarks concerning the QCS system.ReferencesScott C. Deerwester, Susan T. Dumais, Thomas K. Lan-dauer, George W. Furnas, and Richard A. Harshman.1990.
Indexing by latent semantic analysis.
JASIS,41(6):391?407.Inderjit S. Dhillon and Dharmendra S. Modha.
2001.Concept decompositions for large sparse text data us-ing clustering.
Machine Learning, 42(1):143?175.Susan T. Dumais.
1991.
Improving the retrieval of infor-mation from external sources.
Behav.
Res.
Meth.
Instr.,23(6):229?326.Tamara G. Kolda and Dianne P. O?Leary.
1998.
Asemidiscrete matrix decomposition for latent seman-tic indexing in information retrieval.
ACM Trans.
Inf.Sys., 16(4):322?346.Dragomir R. Radev, Sasha Blair-Goldensohn, ZhuZhang, and Revathi Sundara Raghavan.
2001a.Newsinessence: A system for domain-independent,real-time news clustering and multi-document summa-rization.
In Human Language Technology Conference,San Diego, CA.Dragomir R. Radev, Weiguo Fan, and Zhu Zhang.2001b.
Webinessence: A personalized web-basedmulti-document summarization and recommendationsystem.
In NAACL Workshop on Automatic Summa-rization, Pittsburgh, PA.Gerard Salton, A. Wong, and C.S.
Yang.
1975.
A vec-tor space model for information retrieval.
Communi-cations of the ACM, 18(11):613?620.Judith D. Schlesinger, Mary Ellen Okurowski, John M.Conroy, Dianne P. O?Leary, Anthony Taylor, JeanHobbs, and Wilson Harold T. Wilson.
2002.
Under-standing machine performance in the context of hu-man performance for multi-document summarization.In Proc.
of the Workshop on Automatic Summarization.
