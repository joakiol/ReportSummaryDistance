Transformation-Based Error-DrivenLearning and Natural LanguageProcessing: A Case Study inPart-of-Speech TaggingEric Brill*The Johns Hopkins UniversityRecently, there has been a rebirth of empiricism in the field of natural anguage processing.
Man-ual encoding of linguistic information is being challenged by automated corpus-based learningas a method of providing a natural language processing system with linguistic knowledge.
Al-though corpus-based approaches have been successful in many different areas of natural anguageprocessing, it is often the case that these methods capture the linguistic information they aremodelling indirectly in large opaque tables of statistics.
This can make it difficult to analyze,understand and improve the ability of these approaches tomodel underlying linguistic behavior.In this paper, we will describe a simple rule-based approach to automated learning of linguisticknowledge.
This approach as been shown for a number of tasks to capture information in a clearerand more direct fashion without a compromise in performance.
We present adetailed case studyof this learning method applied to part-of-speech tagging.1.
IntroductionIt has recently become clear that automatically extracting linguistic information froma sample text corpus can be an extremely powerful method of overcoming the linguis-tic knowledge acquisition bottleneck inhibiting the creation of robust and accuratenatural anguage processing systems.
A number of part-of-speech taggers are readilyavailable and widely used, all trained and retrainable on text corpora (Church 1988;Cutting et al 1992; Brill 1992; Weischedel et al 1993).
Endemic structural ambiguity,which can lead to such difficulties as trying to cope with the many thousands of possi-ble parses that a grammar can assign to a sentence, can be greatly reduced by addingempirically derived probabilities to grammar ules (Fujisaki et al 1989; Sharman, Je-linek, and Mercer 1990; Black et al 1993) and by computing statistical measures oflexical association (Hindle and Rooth 1993).
Word-sense disambiguation, a problemthat once seemed out of reach for systems without a great deal of handcrafted lin-guistic and world knowledge, can now in some cases be done with high accuracywhen all information is derived automatically from corpora (Brown, Lai, and Mercer1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994).
Aneffort has recently been undertaken to create automated machine translation systemsin which the linguistic information eeded for translation is extracted automaticallyfrom aligned corpora (Brown et al 1990).
These are just a few of the many recentapplications of corpus-based techniques in natural anguage processing.?
Department of Computer Science, Baltimore, MD 21218-2694.
E-mail: brill@cs.jhu.edu.?
1995 Association for Computational LinguisticsComputational Linguistics Volume 21, Number 4Along with great research advances, the infrastructure is in place for this line ofresearch to grow even stronger, with on-line corpora, the grist of the corpus-basednatural language processing rindstone, getting bigger and better and becoming morereadily available.
There are a number of efforts worldwide to manually annotate largecorpora with linguistic information, including parts of speech, phrase structure andpredicate-argument structure (e.g., the Penn Treebank and the British National Corpus(Marcus, Santorini, and Marcinkiewicz 1993; Leech, Garside, and Bryant 1994)).
A vastamount of on-line text is now available, and much more will become available in thefuture.
Useful tools, such as large aligned corpora (e.g., the aligned Hansards (Galeand Church 1991)) and semantic word hierarchies (e.g., Wordnet (Miller 1990)), havealso recently become available.Corpus-based methods are often able to succeed while ignoring the true complex-ities of language, banking on the fact that complex linguistic phenomena can often beindirectly observed through simple epiphenomena.
For example, one could accuratelyassign a part-of-speech tag to the word race in (1-3) without any reference to phrasestructure or constituent movement: One would only have to realize that, usually, aword one or two words to the right of a modal is a verb and not a noun.
An excep-tion to this generalization arises when the word is also one word to the right of adeterminer.
(1)(2)(3)He will race/VERB the car.He will not race/VERB the car.When will the race/NOUN end?It is an exciting discovery that simple stochastic n-gram taggers can obtain veryhigh rates of tagging accuracy simply by observing fixed-length word sequences, with-out recourse to the underlying linguistic structure.
However, in order to make progressin corpus-based natural anguage processing, we must become better aware of justwhat cues to linguistic structure are being captured and where these approximationsto the true underlying phenomena f il.
With many of the current corpus-based ap-proaches to natural anguage processing, this is a nearly impossible task.
Considerthe part-of-speech tagging example above.
In a stochastic n-gram tagger, the informa-tion about words that follow modals would be hidden deeply in the thousands ortens of thousands of contextual probabilities (P(Tagi I Zagi-lZagi-2) and the result ofmultiplying different combinations of these probabilities together.Below, we describe a new approach to corpus-based natural language processing,called transformation-based error-driven learning.
This algorithm has been applied to anumber of natural language problems, including part-of-speech tagging, prepositionalphrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill1993b; Brill and Resnik 1994; Brill 1994).
We have also recently begun exploring theuse of this technique for letter-to-sound generation and for building pronunciationnetworks for speech recognition.
In this approach, the learned linguistic informationis represented in a concise and easily understood form.
This property should maketransformation-based learning a useful tool for further exploring linguistic modelingand attempting to discover ways of more tightly coupling the underlying linguisticsystems and our approximating models.544Brill Transformation-Based Error-Driven LearningUNANNOTATEDTEXTSTATE/~kI~INOTETAx.T ~D TRUTHFigure 1Transformation-Based Error-Driven Learning.RULES2.
Transformation-Based Error-Driven LeamingFigure I illustrates how transformation-based error-driven learning works.
First, unan-notated text is passed through an initial-state annotator.
The initial-state annotator canrange in complexity from assigning random structure to assigning the output of asophisticated manually created annotator.
In part-of-speech tagging, various initial-state annotators have been used, including: the output of a stochastic n-gram tagger;labelling all words with their most likely tag as indicated in the training corpus; andnaively labelling all words as nouns.
For syntactic parsing, we have explored initial-state annotations ranging from the output of a sophisticated parser to random treestructure with random nonterminal labels.Once text has been passed through the initial-state annotator, it is then comparedto the truth.
A manually annotated corpus is used as our reference for truth.
Anordered list of transformations is learned that can be applied to the output of theinitial-state annotator to make it better esemble the truth.
There are two componentsto a transformation: a rewrite rule and a triggering environment.
An example of arewrite rule for part-of-speech tagging is:Change the tag from modal to noun.and an example of a triggering environment is:The preceding word is a determiner.Taken together, the transformation with this rewrite rule and triggering environ-ment when applied to the word can would correctly change the mistagged:The~determiner can~modal rusted~verb ./.545Computational Linguistics Volume 21, Number 4to:The~determiner can~noun rusted~verb ./.An example of a bracketing rewrite rule is: change the bracketing of a subtreefrom:AB Cto:CA Bwhere A, B and C can be either terminals or nonterminals.
One possible set of trigger-ing environments is any combination of words, part-of-speech tags, and nonterminallabels within and adjacent to the subtree.
Using this rewrite rule and the triggeringenvironment A = the, the bracketing:( the ( boy ate ) )would become:( ( the boy ) ate )In all of the applications we have examined to date, the following greedy search isapplied for deriving a list of transformations: at each iteration of learning, the transfor-mation is found whose application results in the best score according to the objectivefunction being used; that transformation is then added to the ordered transforma-tion list and the training corpus is updated by applying the learned transformation.Learning continues until no transformation can be found whose application results inan improvement tothe annotated corpus.
Other more sophisticated search techniquescould be used, such as simulated annealing or learning with a look-ahead window,but we have not yet explored these alternatives.Figure 2 shows an example of learning transformations.
In this example, we as-sume there are only four possible transformations, T1 through T4, and that the ob-jective function is the total number of errors.
The unannotated training corpus isprocessed by the initial-state annotator, and this results in an annotated corpus with5,100 errors, determined by comparing the output of the initial-state annotator withthe manually derived annotations for this corpus.
Next, we apply each of the possibletransformations in turn and score the resulting annotated corpus.
1 In this example,1 In the real implementation, the search is data driven, and therefore not all transformations eed to beexamined.546Brill Transformation-Based Error-Driven LearningUnannotatedCorpusIInitial StateAnnotatorAnnotatedCorpusErrors = 5,100TIIAnnotatedCorpusErrors = 5,100AnnotatedCorpusErrors = 3,145AnnotatedCorpusErrors = 3,910T1AnnotatedCorpusAnnotatedT2 CorpusErrors = 2,110AnnotatedCorpusErrors = 1,231W4 Ano ted 4 IAnnotate'Corpus Corpus /Errors = 6,300 Errors = 4 ,25~Figure 2An Example of Transformation-Based Error-Driven Learning.T11"2T3T4AnnotatedCorpusErrors = 1,410AnnotatedCorpusErrors = 1,251AnnotatedCorpusErrors = 1,231AnnotatedCorpusErrors = 1,231applying transformation T2 results in the largest reduction of errors, so T2 is learnedas the first transformation.
T2 is then applied to the entire corpus, and learning con-tinues.
At this stage of learning, transformation T3 results in the largest reduction oferror, so it is learned as the second transformation.
After applying the initial-stateannotator, followed by T2 and then T3, no further eduction in errors can be obtainedfrom applying any of the transformations, so learning stops.
To annotate fresh text,this text is first annotated by the initial-state annotator, followed by the application oftransformation T2 and then by the application of T3.To define a specific application of transformation-based learning, one must specifythe following:.2..The initial state-annotator.The space of allowable transformations (rewrite rules and triggeringenvironments).The objective function for comparing the corpus to the truth andchoosing a transformation.In cases where the application of a particular transformation in one environmentcould affect its application in another environment, two additional parameters mustbe specified: the order in which transformations are applied to a corpus, and whethera transformation is applied immediately or only after the entire corpus has been ex-amined for triggering environments.
For example, take the sequence:AAAAAAand the transformation:547Computational Linguistics Volume 21, Number 4Change the label from A to B if the preceding label is A.If the effect of the application of a transformation is not written out until the entirefile has been processed for that one transformation, then regardless of the order ofprocessing the output will be:ABBBBB,since the triggering environment of a transformation is always checked before thattransformation is applied to any surrounding objects in the corpus.
If the effect of atransformation is recorded immediately, then processing the string left to right wouldresult in:ABABAB,whereas processing right to left would result in:ABBBBB.3.
A Comparison With Decision TreesThe technique mployed by the learner is somewhat similar to that used in decisiontrees (Breiman et al 1984; Quinlan 1986; Quinlan and Rivest 1989).
A decision treeis trained on a set of preclassified entities and outputs a set of questions that can beasked about an entity to determine its proper classification.
Decision trees are builtby finding the question whose resulting partition is the purest, 2splitting the trainingdata according to that question, and then recursively reapplying this procedure oneach resulting subset.We first show that the set of classifications that can be provided via decision treesis a proper subset of those that can be provided via transformation lists (an orderedlist of transformation-based rules), given the same set of primitive questions.
We thengive some practical differences between the two learning methods.3.1 Decision Trees c_ Transformation ListsWe prove here that for a fixed set of primitive queries, any binary decision tree canbe converted into a transformation list.
Extending the proof beyond binary trees isstraightforward.Proof (by induction)Base Case:Given the following primitive decision tree, where the classification is A if theanswer to the query X?
is yes, and the classification is B if the answer is no:X?B A2 One possible measure for purity is entropy reduction.548this tree can be converted into the following transformation list:.2.3.X?Label with S / *  Start State Annotation */If X, then S --* AS --* B / *  Empty Tagging Environment--Always Applies To EntitiesCurrently Labeled With S */Induction:Assume that two decision trees T1 and T2 have corresponding transformation listsL1 and L2.
Assume that the arbitrary label names chosen in constructing L1 are notused in L2, and that those in L2 are not used in L1.
Given a new decision tree T3constructed from T1 and T2 as follows:Brill Transformation-Based Error-Driven Learningwe construct a new transformation list L3.
Assume the first transformation i  L1 is:Label with S'and the first transformation i  L2 is:Label with S"The first three transformations in L3 will then be:1.
Label with S2.
If X then S --* S'3.
S --+ S"followed by all of the rules in L1 other than the first rule, followed by all of the rulesin L2 other than the first rule.
The resulting transformation list will first label an itemas S' if X is true, or as S" if X is false.
Next, the tranformations from L1 will be appliedif X is true, since S' is the initial-state label for L1.
If X is false, the transformationsfrom L2 will be applied, because S" is the initial-state label for L2.
\[\]3.2 Decision Trees # Transformation ListsWe show here that there exist transformation lists for which no equivalent decisiontrees exist, for a fixed set of primitive queries.
The following classification problem isone example.
Given a sequence of characters, classify a character based on whetherthe position index of a character is divisible by 4, querying only using a context oftwo characters to the left of the character being classified.549Computational Linguistics Volume 21, Number 4Assuming transformations are applied left to right on the sequence, the aboveclassification problem can be solved for sequences of arbitrary length if the effect ofa transformation is written out immediately, or for sequences up to any prespecifiedlength if a transformation is carried out only after all triggering environments in thecorpus are checked.
We present he proof for the former case.Given the input sequence:A A A A A A A A A A0 1 2 3 4 5 6 7 8 9the underlined characters should be classified as true because their indices are 0, 4,and 8.
To see why a decision tree could not perform this classification, regardless oforder of classification, ote that, for the two characters before both A3 and A4, both thecharacters and their classifications are the same, although these two characters shouldbe classified ifferently.
Below is a transformation list for performing this classification.Once again, we assume transformations are applied left to right and that the result of atransformation is written out immediately, sothat the result of applying transformationx to character ai will always be known when applying transformation x to ai+l.1.
Label with SRESULT: A/S A/S A/S A/S2.
If there is no previous character,RESULT: A/F A/S A/S A/S3.
If the character two to the left isRESULT: A/F A/S A/F A/S4.
If the character two to the left isRESULT: A/F  A/S A/S A/S5.
F --+ yes6.
S--* noA/S A/S A/S A/S A/S A/S A/Sthen S ~ FA/S A/S A/S A/S A/S A/S A/Slabelled with F, then S --* FA/F A/S A/F A/S A/F  A/S A/Flabelled with F, then F ~ SA/F A/S A/S A/S A/F  A/S A/SRESULT: A/yes A/no A/no A/no A/yes A/no A/no A/no A/yesA/no A/noThe extra power of transformation lists comes from the fact that intermediateresults from the classification of one object are reflected in the current label of thatobject, thereby making this intermediate information available for use in classifyingother objects.
This is not the case for decision trees, where the outcome of questionsasked is saved implicitly by the current location within the tree.3.3 Some Practical Di f ferences Between Dec is ion  Trees and Transformation ListsThere are a number of practical differences between transformation-based error-drivenlearning and learning decision trees.
One difference is that when training a decisiontree, each time the depth of the tree is increased, the average amount of training mate-rial available per node at that new depth is halved (for a binary tree).
In transformation-based learning, the entire training corpus is used for finding all transformations.
There-fore, this method is not subject o the sparse data problems that arise as the depth ofthe decision tree being learned increases.Transformations are ordered, with later transformations being dependent uponthe outcome of applying earlier transformations.
This allows intermediate r sults in550Brill Transformation-Based Error-Driven Learningclassifying one object o be available in classifying other objects.
For instance, whetherthe previous word is tagged as to-infinitival or to-preposition may be a good cue for de-termining the part of speech of a word.
3 If, initially, the word to is not reliably taggedeverywhere in the corpus with its proper tag (or not tagged at all), then this cue willbe unreliable.
The transformation-based l arner will delay positing a transformationtriggered by the tag of the word to until other transformations have resulted in a morereliable tagging of this word in the corpus.
For a decision tree to take advantage ofthis information, any word whose outcome is dependent upon the tagging of to wouldneed the entire decision tree structure for the proper classification of each occurrenceof to built into its decision tree path.
If the classification of to were dependent upon theclassification of yet another word, this would have to be built into the decision tree aswell.
Unlike decision trees, in transformation-based l arning, intermediate classifica-tion results are available and can be used as classification progresses.
Even if decisiontrees are applied to a corpus in a left-to-right fashion, they are allowed only one passin which to properly classify.Since a transformation list is a processor and not a classifier, it can readily beused as a postprocessor to any annotation system.
In addition to annotating fromscratch, rules can be learned to improve the performance of a mature annotationsystem by using the mature system as the initial-state annotator.
This can have theadded advantage that the list of transformations learned using a mature annotationsystem as the initial-state annotator provides a readable description or classification ofthe errors the mature system makes, thereby aiding in the refinement of that system.The fact that it is a processor gives a transformation-based l arner greater than theclassifier-based decision tree.
For example, in applying transformation-based l arningto parsing, a rule can apply any structural change to a tree.
In tagging, a rule such as:Change the tag of the current word to X, and of the previous word to Y, if Z holdscan easily be handled in the processor-based system, whereas it would be difficult tohandle in a classification system.In transformation-based l arning, the objective function used in training is thesame as that used for evaluation, whenever this is feasible.
In a decision tree, using sys-tem accuracy as an objective function for training typically results in poor performance 4and some measure of node purity, such as entropy reduction, is used instead.
The di-rect correlation between rules and performance improvement in transformation-basedlearning can make the learned rules more readily interpretable than decision tree rulesfor increasing population purity, s4.
Part of Speech Tagging: A Case Study in Transformation-Based Error-DrivenLearningIn this section we describe the practical application of transformation-based l arningto part-of-speech tagging.
6 Part-of-speech tagging is a good application to test the3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the PennTreebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not.4 For a discussion of why this is the case, see Breiman et al (1984, 94-98).5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus(1994).6 All of the programs described herein are freely available with no restrictions on use or redistribution.For information on obtaining the tagger, contact he author.551Computational Linguistics Volume 21, Number 4learner, for several reasons.
There are a number of large tagged corpora available,allowing for a variety of experiments to be run.
Part-of-speech tagging is an activearea of research; a great deal of work has been done in this area over the past few years(e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo1994; Brill 1992; Black et al 1992; Cutting et al 1992; Kupiec 1992; Charniak et al 1993;Weischedel et al 1993; Schutze and Singer 1994).Part-of-speech tagging is also a very practical application, with uses in many areas,including speech recognition and generation, machine translation, parsing, informationretrieval and lexicography.
Insofar as tagging can be seen as a prototypical problemin lexical ambiguity, advances in part-of-speech tagging could readily translate toprogress in other areas of lexical, and perhaps structural, ambiguity, such as word-sense disambiguation and prepositional phrase attachment disambiguation.
7 Also, it ispossible to cast a number of other useful problems as part-of-speech tagging problems,such as letter-to-sound translation (Huang, Son-Bell, and Baggett 1994) and buildingpronunciation networks for speech recognition.
Recently, a method has been proposedfor using part-of-speech tagging techniques as a method for parsing with lexicalizedgrammars (Joshi and Srinivas 1994).When automated part-of-speech tagging was initially explored (Klein and Sim-mons 1963; Harris 1962), people manually engineered rules for tagging, sometimeswith the aid of a corpus.
As large corpora became available, it became clear that simpleMarkov-model based stochastic taggers that were automatically trained could achievehigh rates of tagging accuracy (Jelinek 1985).
Markov-model based taggers assign to asentence the tag sequence that maximizes Prob(word I tag),Prob(tag I previous n tags).These probabilities can be estimated irectly from a manually tagged corpus, s Thesestochastic taggers have a number of advantages over the manually built taggers, in-cluding obviating the need for laborious manual rule construction, and possibly cap-turing useful information that may not have been noticed by the human engineer.However, stochastic taggers have the disadvantage that linguistic information is cap-tured only indirectly, in large tables of statistics.
Almost all recent work in developingautomatically trained part-of-speech taggers has been on further exploring Markov-model based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Meri-aldo 1994; Cutting et al 1992; Kupiec 1992; Charniak et al 1993; Weischedel et al 1993;Schutze and Singer 1994).4.1 Transformation-based Error-driven Part-of-Speech TaggingTransformation-based part of speech tagging works as follows.
9 The initial-state an-notator assigns each word its most likely tag as indicated in the training corpus.
Themethod used for initially tagging unknown words will be described in a later section.An ordered list of transformations is then learned, to improve tagging accuracy basedon contextual cues.
These transformations alter the tagging of a word from X to Y iff7 In Brill and Resnik (1994), we describe an approach to prepositional phrase attachment disambiguationthat obtains highly competitive performance ompared to other corpus-based solutions to this problem.This system was derived in under two hours from the transformation-based part of speech taggerdescribed in this paper.8 One can also estimate these probabilities without a manually tagged corpus, using a hidden Markovmodel.
However, it appears to be the case that directly estimating probabilities from even a very smallmanually tagged corpus gives better esults than training a hidden Markov model on a large untaggedcorpus (see Merialdo (1994)).9 Earlier versions of this work were reported in Brill (1992, 1994).552Brill Transformation-Based Error-Driven Learningeither:1.
The word was not seen in the training corpus OR2.
The word was seen tagged with ?
at least once in the training corpus.In taggers based on Markov models, the lexicon consists of probabilities of thesomewhat counterintuitive but proper form P(WORD I TAG).
In the transformation-based tagger, the lexicon is s imply a list of all tags seen for a word in the trainingcorpus, with one tag labeled as the most likely.
Below we show a lexical entry for theword half in the transformation-based tagger.
1?half: CD DT JJ NN PDT RB VBThis entry lists the seven tags seen for half in the training corpus, with NN markedas the most likely.
Below are the lexical entries for half in a Markov model tagger,extracted from the same corpus:P(half l CD ) = 0.000066P(half l DT ) = 0.000757P(half I J J) = 0.000092P(half INN) = 0.000702P(half l PDT ) = 0.039945P(half l RB ) = 0.000443P(half I VB ) = 0.000027It is difficult to make much sense of these entries in isolation; they have to be viewedin the context of the many contextual probabilities.First, we will describe a nonlexicalized version of the tagger, where transformationtemplates do not make reference to specific words.
In the nonlexicalized tagger, thetransformation templates we use are:Change tag a to tag b when:1.
The preceding (following) word is tagged z.2.
The word two before (after) is tagged z.3.
One of the two preceding (following) words is tagged z.4.
One of the three preceding (following) words is tagged z.5.
The preceding word is tagged z and the following word is tagged w.6.
The preceding (following) word is tagged z and the word two before(after) is tagged w.where a, b, z and w are variables over the set of parts of speech.To learn a transformation, the learner, in essence, tries out every possible trans-formation, 1I and counts the number  of tagging errors after each one is applied.
After10 A description of the partoof-speech tags is provided in Appendix A.11 All possible instantiations of transformation templates.553Computational Linguistics Volume 21, Number 41. apply initial-state annotator to corpus2.
while transformations can still be found do3.
for from_tag = tag1 to tagn4.
for to_tag = tag1 to tagn5.
for corpus_position = 1 to corpus_size6.
if (correct_tag(corpus_position) --= to_tag&& current_tag(corpus_position) == from_tag)7. num_good_transformations(tag(corpus_position -1))++8.
else if (correct_tag(corpus_position) == from_tag&& current_tag(corpus_position) == from_tag)9. num_bad_transformations(tag(corpus_position-1 ))++10.
find maxT (num_good_transformations(T) - num_bad_transformations(T))11. if this is the best-scoring rule found yet then store as best rule:Change tag from from_tag to to_tag if previous tag is T12.
apply best rule to training corpus13.
append best rule to ordered list of transformationsFigure 3Pseudocode for learning transformations.all possible transformations have been tried, the transformation that resulted in thegreatest error reduction is chosen.
Learning stops when no transformations can befound whose application reduces errors beyond some prespecified threshold.In the experiments described below, processing was done left to right.
For eachtransformation application, all triggering environments are first found in the corpus,and then the transformation triggered by each triggering environment is carried out.The search is data-driven, so only a very small percentage of possible transfor-mations really need be examined.
In figure 3, we give pseudocode for the learningalgorithm in the case where there is only one transformation template:Change the tag from X to Y if the previous tag is Z.In each learning iteration, the entire training corpus is examined once for every pairof tags X and Y, finding the best transformation whose rewrite changes tag X to tag Y.For every word in the corpus whose environment matches the triggering environment,if the word has tag X and X is the correct ag, then making this transformation willresult in an additional tagging error, so we increment the number of errors causedwhen making the transformation given the part-of-speech tag of the previous word(lines 8 and 9).
If X is the current ag and Y is the correct ag, then the transformationwill result in one less error, so we increment the number of improvements causedwhen making the transformation given the part-of-speech tag of the previous word(lines 6 and 7).In certain cases, a significant increase in speed for training the transformation-based tagger can be obtained by indexing in the corpus where different transformationscan and do apply.
For a description of a fast index-based training algorithm, seeRamshaw and Marcus (1994).In figure 4, we list the first twenty transformations learned from training on thePenn Treebank Wall Street Journal Corpus (Marcus, Santorini, and Marcinkiewicz1993).
12 The first transformation states that a noun should be changed to a verb if12 Version 0.5 of the Penn Treebank was used in all experiments reported in this paper.554Brill Transformation-Based Error-Driven LearningChange Tag# From To1 NN VB2 VBP VB3 NN VB4 VB NN5 VBD VBN6 VBN VBD7 VBN VBD8 VBD VBN9 VBP VB10 POS VBZ11 VB VBP12 VBD VBN13 IN WDT14 VBD VBN15 VB VBP16 IN WDT17 IN DT18 JJ NNP19 IN WDT20 JJR RBRFigure 4ConditionPrevious tag is TOOne of the previous three tags is MDOne of the previous two tags is MDOne of the previous two tags is DTOne of the previous three tags is VBZPrevious tag is PRPPrevious tag is NNPPrevious tag is VBDPrevious tag is TOPrevious tag is PRPPrevious tag is NNSOne of previous three tags is VBPOne of next two tags is VBOne of previous two tags is VBPrevious tag is PRPNext tag is VBZNext tag is NNNext tag is NNPNext tag is VBDNext tag is JJThe first 20 nonlexicalized transformations.the previous tag is TO, as in: to~TO conflict/NN--.VB with.
The second transforma-tion fixes a tagging such as: might/MD vanish/VBP--.VB.
The third fixes might/MD notreply/NN--.VB.
The tenth transformation is for the token's, which is a separate tokenin the Penn Treebank.
's is most frequently used as a possessive nding, but after apersonal pronoun, it is a verb (John's, compared to he 's).
The transformations chang-ing IN to WDT are for tagging the word that, to determine in which environments hatis being used as a synonym of which.4.2 Lexicalizing the TaggerIn general, no relationships between words have been directly encoded in stochas-tic n-gram taggers.
13 In the Markov model typically used for stochastic tagging, statetransition probabilities (P(Tagi I Tagi_l... Tagi-n)) express the likelihood of a tag im-mediately following n other tags, and emit probabilities (P(Wordj I Tagi)) express thelikelihood of a word, given a tag.
Many useful relationships, uch as that between aword and the previous word, or between a tag and the following word, are not di-rectly captured by Markov-model based taggers.
The same is true of the nonlexicalizedtransformation-based tagger, where transformation templates do not make referenceto words.To remedy this problem, we extend the transformation-based tagger by adding13 In Kupiec (1992), alimited amount of lexicalization is introduced by having astochastic agger withword states for the 100 most frequent words in the corpus.555Computational Linguistics Volume 21, Number 4contextual transformations that can make reference to words as well as part-of-speechtags.
The transformation templates we add are:Change tag a to tag b when:.2.3.4.5.6.7..TheTheTheThet.The preceding (following) word is w.The word two before (after) is w.One of the two preceding (following) words is w.current word is w and the preceding (following) word is x.current word is w and the preceding (following) word is tagged z.current word is w.preceding (following) word is w and the preceding (following) tag isThe current word is w, the preceding (following) word is w2 and thepreceding (following) tag is t.where w and x are variables over all words in the training corpus, and zand t are variables over all parts of speech.BelOw we list two lexicalized transformations that were learned, training onceagain on the Wall Street Journal.Change the tag:(12) From IN to RB if the word two positions to the right is as.
(16) From VBP to VB if one of the previous two words is n' t .
TMThe Penn Treebank tagging style manual specifies that in the collocation as ... as,the first as is tagged as an adverb and the second is tagged as a preposition.
Since as ismost frequently tagged as a preposition in the training corpus, the initial-state taggerwill mistag the phrase as tall as as:as / IN  tall/JJ as / INThe first lexicalized transformation corrects this mistagging.
Note that a bigram taggertrained on our training set would not correctly tag the first occurrence of as.
Althoughadverbs are more likely than prepositions to follow some verb form tags, the factthat P(as \] IN) is much greater than P(as \] RB), and P(JJ \] IN) is much greater thanP(JJ \] RB) lead to as being incorrectly tagged as a preposition by a stochastic tagger.
Atrigram tagger will correctly tag this collocation in some instances, due to the fact thatP(IN \] RB JJ) is greater than P(IN \] IN JJ), but the outcome will be highly dependentupon the context in which this collocation appears.The second transformation arises from the fact that when a verb appears in acontext such as We do n't eat or We did n't usually drink, the verb is in base form.
Astochastic trigram tagger would have to capture this linguistic information indirectlyfrom frequency counts of all trigrams of the form shown in figure 5 (where a star canmatch any part-of-speech tag) and from the fact that P(n't \] RB) is fairly high.14 In the Penn Treebank, n't is treated as a separate token, so don't becomes do/VBP n't/RB.556Brill Transformation-Based Error-Driven Learning* RB VBP* RB VBRB * VBPRB * VBFigure 5Trigram Tagger Probability Tables.In Weischedel et al (1993), results are given when training and testing a Markov-model based tagger on the Penn Treebank Tagged Wall Street Journal Corpus.
They citeresults making the closed vocabulary assumption that all possible tags for all words inthe test set are known.
When training contextual probabilities on one million words,an accuracy of 96.7% was achieved.
Accuracy dropped to 96.3% when contextual prob-abilities were trained on 64,000 words.
We trained the transformation-based tagger onthe same corpus, making the same closed-vocabulary assumption.
15 When trainingcontextual rules on 600,000 words, an accuracy of 97.2% was achieved on a separate150,000 word test set.
When the training set was reduced to 64,000 words, accuracydropped to 96.7%.
The transformation-based learner achieved better performance, de-spite the fact that contextual information was captured in a small number of simplenonstochastic rules, as opposed to 10,000 contextual probabilities that were learnedby the stochastic tagger.
These results are summarized in table 1.
When training on600,000 words, a total of 447 transformations were learned.
However, transformationstoward the end of the list contribute very little to accuracy: applying only the first 200learned transformations to the test set achieves an accuracy of 97.0%; applying the first100 gives an accuracy of 96.8%.
To match the 96.7% accuracy achieved by the stochas-tic tagger when it was trained on one million words, only the first 82 transformationsare needed.To see whether lexicalized transformations were contributing to the transformation-based tagger accuracy rate, we first trained the tagger using the nonlexical transfor-mation template subset, then ran exactly the same test.
Accuracy of that tagger was97.0%.
Adding lexicalized transformations resulted in a 6.7% decrease in the error rate(see table 1).
16We found it a bit surprising that the addition of lexicalized transformations didnot result in a much greater improvement in performance.
When transformations areallowed to make reference to words and word pairs, some relevant information isprobably missed due to sparse data.
We are currently exploring the possibility ofincorporating word classes into the rule-based learner, in hopes of overcoming thisproblem.
The idea is quite simple.
Given any source of word class information, such15 In both Weischedel et al (1993) and here, the test set was incorporated into the lexicon, but was notused in learning contextual information.
Testing with no unknown words might  seem like anunrealistic test.
We have done so for three reasons: (1) to allow for a comparison with previouslyquoted results, (2) to isolate known word accuracy from unknown word accuracy, and (3) in somesystems, such as a closed vocabulary speech recognition system, the assumpt ion that all words areknown is valid.
(We show results when unknown words are included later in the paper.
)16 The training we did here was slightly suboptimal, in that we used the contextual rules learned withunknown words (described in the next section), and filled in the dictionary, rather than training on acorpus without unknown words.557Computational Linguistics Volume 21, Number 4Table 1Comparison of Tagging Accuracy With No Unknown WordsTraining # of RulesCorpus or Context.
Acc.Method Size (Words) Probs.
(%)Stochastic 64 K 6,170 96.3Stochastic 1 Million 10,000 96.7Rule-BasedWith Lex.
Rules 64 K 215 96.7Rule-BasedWith Lex.
Rules 600 K 447 97.2Rule-Basedw/o  Lex.
Rules 600 K 378 97.0as WordNet (Miller 1990), the learner is extended such that a rule is al lowed to makereference to parts of speech, words, and word classes, allowing for rules such asChange the tag from X to Y if the following word belongs to word class Z.This approach as already been successfully applied to a system for preposit ionalphrase attachment disambiguation (Brill and Resnik 1994).4.3 Tagging Unknown WordsSo far, we have not addressed the problem of unknown words.
As stated above, theinitial-state annotator for tagging assigns all words their most likely tag, as indicatedin a training corpus.
Below we show how a transformation-based approach can betaken for tagging unknown words, by automatically learning cues to predict the mostlikely tag for words not seen in the training corpus.
If the most likely tag for unknownwords can be assigned with high accuracy, then the contextual rules can be used toimprove accuracy, as described above.In the transformation-based unknown-word tagger, the initial-state annotator naivelyassumes the most likely tag for an unknown word is "proper noun" if the word iscapitalized and "common noun" otherwise.
17Below, we list the set of allowable transformations.Change the tag of an unknown word (from X) to Y if:1..3..5.Deleting the prefix (suffix) x, Ixl < 4, results in a word (x is any string oflength 1 to 4).The first (last) (1,2,3,4) characters of the word are x.Adding the character string x as a prefix (suffix) results in a word(Ixl ~ 4).Word w ever appears immediately to the left (right) of the word.Character z appears in the word.17 If we change the tagger to tag all unknown words as common ouns, then a number of rules arelearned of the form: change tag to proper noun if the prefix is "E', "A", "B', etc., since the learner isnot provided with the concept of upper case in its set of transformation templates.558Brill Transformation-Based Error-Driven LearningChange Tag# From To Condition1 NN NNS Has suffix -s2 NN CD Has character.3 NN JJ Has character -4 NN VBN Has suffix -ed5 NN VBG Has suffix -ing6 ??
RB Has suffix -ly7 ??
JJ Adding suffix -ly results in a word.8 NN CD The word $ can appear to the left.9 NN JJ Has suffix -al10 NN VB The word would can appear to the left.11 NN CD Has character 012 NN JJ The word be can appear to the left.13 NNS JJ Has suffix -us14 NNS VBZ The word it can appear to the left.15 NN JJ Has suffix -ble16 NN JJ Has suffix -ic17 NN CD Has character 118 NNS NN Has suffix -ss19 ??
JJ Deleting the prefix un-  results in a word20 NN JJ Has suffix - ireFigure 6The first 20 transformations for unknown words.An unannotated text can be used to check the conditions in all of the above trans-formation templates.
Annotated text is necessary in training to measure the effect oftransformations on tagging accuracy.
Since the goal is to label each lexical entry fornew words as accurately as possible, accuracy is measured on a per type and not aper token basis.Figure 6 shows the first 20 transformations learned for tagging unknown words inthe Wall Street Journal corpus.
As an example of how rules can correct errors generatedby prior rules, note that applying the first transformation will result in the mistaggingof the word actress.
The 18th learned rule fixes this problem.
This rule states:Change a tag from p lura l  common noun to s ingu lar  common noun if the word hasSUffiX ss.Keep in mind that no specific affixes are prespecified.
A transformation can makereference to any string of characters up to a bounded length.
So while the first rulespecifies the English suffix "s', the rule learner was not constrained from consideringsuch nonsensical rules as:Change a tag to adjective if the word has suffix "xhqr'.Also, absolutely no English-specific information (such as an affix list) need beprespecified in the learner.
TM18 This learner has also been applied to tagging Old English.
See Brill (1993b).
Although the559Computational Linguistics Volume 21, Number 4J==i i E i i0 100 200 300 400Transformation NumberFigure 7Accuracy vs.
Transformation NumberWe then ran the following experiment using 1.1 million words of the Penn Tree-bank Tagged Wall Street Journal Corpus.
Of these, 950,000 words were used for trainingand 150,000 words were used for testing.
Annotations of the test corpus were not usedin any way to train the system.
From the 950,000 word training corpus, 350,000 wordswere used to learn rules for tagging unknown words, and 600,000 words were usedto learn contextual rules; 243 rules were learned for tagging unknown words, and 447contextual tagging rules were learned.
Unknown word accuracy on the test corpus was82.2%, and overall tagging accuracy on the test corpus was 96.6%.
To our knowledge,this is the highest overall tagging accuracy ever quoted on the Penn Treebank Corpuswhen making the open vocabulary assumption.
Using the tagger without lexicalizedrules, an overall accuracy of 96.3% and an unknown word accuracy of 82.0% is ob-tained.
A graph of accuracy as a function of transformation number on the test set forlexicalized rules is shown in figure 7.
Before applying any transformations, test set ac-curacy is 92.4%, so the transformations reduce the error rate by 50% over the baseline.The high baseline accuracy is somewhat misleading, as this includes the tagging ofunambiguous words.
Baseline accuracy when the words that are unambiguous in ourlexicon are not considered is 86.4%.
However, it is difficult to compare taggers usingthis figure, as the accuracy of the system depends on the particular lexicon used.
Forinstance, in our training set the word the was tagged with a number of different ags,and so according to our lexicon the is ambiguous.
If we instead used a lexicon wherethe is listed unambiguously asa determiner, the baseline accuracy would be 84.6%.For tagging unknown words, each word is initially assigned a part-of-speech tagbased on word and word-distribution features.
Then, the tag may be changed basedon contextual cues, via contextual transformations that are applied to the entire cor-pus, both known and unknown-words.
When the contextual rule learner learns trans-formations, it does so in an attempt o maximize overall tagging accuracy, and notunknown-word tagging accuracy.
Unknown words account for only a small percent-age of the corpus in our experiments, typically two to three percent.
Since the distribu-tional behavior of unknown words is quite different from that of known words, andtransformations are not English-specific, the set of transformation templates would have to be extendedto process languages with dramatically different morphology,560Brill Transformation-Based Error-Driven LearningTable 2Tagging Accuracy on Different CorporaCorpus AccuracyPenn WSJ 96.6%Penn Brown 96.3%Orig Brown 96.5%since a transformation that does not increase unknown-word tagging accuracy canstill be beneficial to overall tagging accuracy, the contextual transformations learnedare not optimal in the sense of leading to the highest agging accuracy on unknownwords.
Better unknown-word accuracy may be possible by training and using twosets of contextual rules, one maximizing known-word accuracy and the other maxi-mizing unknown-word accuracy, and then applying the appropriate transformationsto a word when tagging, depending upon whether the word appears in the lexicon.We are currently experimenting with this idea.In Weischedel et al (1993), a statistical approach to tagging unknown words isshown.
In this approach, a number of suffixes and important features are prespecified.Then, for unknown words:p(W I T) -= p(unknown word I T) ?
p(Capitalize-feature I T) * p(suffixes, hyphenation I T)Using this equation for unknown word emit probabilities within the stochastic tagger,an accuracy of 85% was obtained on the Wall Street Journal corpus.
This portion ofthe stochastic model has over 1,000 parameters, with 108 possible unique emit proba-bilities, as opposed to a small number of simple rules that are learned and used in therule-based approach.
In addition, the transformation-based method learns pecific uesinstead of requiring them to be prespecified, allowing for the possibility of uncover-ing cues not apparent to the human language ngineer.
We have obtained comparableperformance on unknown words, while capturing the information in a much moreconcise and perspicuous manner, and without prespecifying any information specificto English or to a specific corpus.In table 2, we show tagging results obtained on a number of different corpora, ineach case training on roughly 9.5 x 10 s words total and testing on a separate test setof 1.5-2 x 10 s words.
Accuracy is consistent across these corpora and tag sets.In addition to obtaining high rates of accuracy and representing relevant linguisticinformation in a small set of rules, the part-of-speech tagger can also be made torun extremely fast.
Roche and Schabes (1995) show a method for converting a listof tagging transformations into a deterministic finite state transducer with one statetransition taken per word of input; the result is a transformation-based tagger whosetagging speed is about ten times that of the fastest Markov-model tagger.4.4 K-Best TagsThere are certain circumstances where one is willing to relax the one-tag-per-wordrequirement in order to increase the probability that the correct ag will be assigned toeach word.
In DeMarcken (1990) and Weischedel t al.
(1993), k-best ags are assignedwithin a stochastic tagger by returning all tags within some threshold of probabilityof being correct for a particular word.561Computational Linguistics Volume 21, Number 4Table 3Results from k-best agging.# of Rules Accuracy Avg.
# of tags per word0 96.5 1.0050 96.9 1.02100 97.4 1.04150 97.9 1.10200 98.4 1.19250 99.1 1.50We can modify the transformation-based tagger to return multiple tags for a wordby making a simple modification to the contextual transformations described above.The initial-state annotator is the tagging output of the previously described one-besttransformation-based tagger.
The allowable transformation templates are the same asthe contextual transformation templates listed above, but with the rewrite rule: changetag X to tag Y modif ied to add tag X to tag Y or add tag X to word W. Instead of changingthe tagging of a word, transformations ow add alternative taggings to a word.When allowing more than one tag per word, there is a trade-off between accuracyand the average number  of tags for each word.
Ideally, we would like to achieve aslarge an increase in accuracy with as few extra tags as possible.
Therefore, in trainingwe find transformations that maximize the function:Number  of corrected errorsNumber  of additional tagsIn table 3, we present results from first using the one-tag-per-word transforma-tion-based tagger described in the previous section and then applying the k-best tagtransformations.
These transformations were learned from a separate 240,000 wordcorpus.
As a baseline, we did k-best tagging of a test corpus.
Each known word in thetest corpus was tagged with all tags seen with that word in the training corpus andthe five most likely unknown-word tags were assigned to all words not seen in thetraining corpus.
19 This resulted in an accuracy of 99.0%, with an average of 2.28 tagsper word.
The transformation-based tagger obtained the same accuracy with 1.43 tagsper word, one third the number  of additional tags as the baseline tagger.
2?5.
Conclus ionsIn this paper, we have described a new transformation-based approach to corpus-basedlearning.
We have given details of how this approach has been applied to part-of-speech tagging and have demonstrated that the transformation-based approach obtains19 Thanks to Fred Jelinek and Fernando Pereira for suggesting this baseline xperiment.20 Unfortunately, it is difficult o find results to compare these k-best ag results to.
In DeMarcken (1990),the test set is included in the training set, and so it is difficult o know how this system would do onfresh text.
In Weischedel t al.
(1993), a k-best ag experiment was run on the Wall Street Journalcorpus.
They quote the average number of tags per word for various threshold settings, but do notprovide accuracy results.562Brill Transformation-Based Error-Driven Learningcompetitive performance with stochastic taggers on tagging both unknown and knownwords.
The transformation-based tagger captures linguistic information in a smallnumber of simple nonstochastic rules, as opposed to large numbers of lexical andcontextual probabilities.
This learning approach as also been applied to a numberof other tasks, including prepositional phrase attachment disambiguation (Brill andResnik 1994), bracketing text (Brill 1993a) and labeling nonterminal nodes (Brill 1993c).Recently, we have begun to explore the possibility of extending these techniques toother problems, including learning pronunciation networks for speech recognition andlearning mappings between syntactic and semantic representations.Appendix A: Penn Treebank Part-of-Speech Tags (Excluding Punctuation)1.
CC Coordinating conjunction2.
CD Cardinal number3.
DT Determiner4.
EX Existential "there"5.
FW Foreign word6.
IN Preposition or subordinating conjunction7.
JJ Adjective8.
JJR Adjective, comparative9.
JJS Adjective, superlative10.
LS List item marker11.
MD Modal12.
NN Noun, singular or mass13.
NNS Noun, plural14.
NNP Proper noun, singular15.
NNPS Proper noun, plural16.
PDT Predeterminer17.
POS Possessive nding18.
PP Personal pronoun19.
PP$ Possessive pronoun20.
RB Adverb21.
RBR Adverb, comparative22.
RBS Adverb, superlative23.
RP Particle24.
SYM Symbol25.
TO "to"26.
UH Interjection27.
VB Verb, base form28.
VBD Verb, past tense29.
VBG Verb, gerund or present participle30.
VBN Verb, past participle31.
VBP Verb, non-3rd person singular present32.
VBZ Verb, 3rd person singular present33.
WDT Wh-determiner34.
WP Wh-pronoun35.
WP$ Possessive wh-pronoun36.
WRB Wh-adverb563Computational Linguistics Volume 21, Number 4AcknowledgmentsThis work was funded in part by NSF grantIRI-9502312.
In addition, this work wasdone in part while the author was in theSpoken Language Systems Group atMassachusetts Institute of Technologyunder ARPA grant N00014-89-J-1332, andby DARPA/AFOSR grant AFOSR-90-0066 atthe University of Pennsylvania.
Thanks toMitch Marcus, Mark Villain, and theanonymous reviewers for many usefulcomments on earlier drafts of this paper.ReferencesBlack, Ezra; Jelinek, Fred; Lafferty, John;Magerman, David; Mercer, Robert; andRoukos, Salim (1993).
"Towardshistory-based grammars: Using richermodels for probabilistic parsing."
InProceedings, 31st Annual Meeting of theAssociation for Computational Linguistics.Columbus, OH.Black, Ezra; Jelinek, Fred; Lafferty, John;Mercer, Robert, and Roukos, Salim (1992).
"Decision tree models applied to thelabeling of text with parts-of-speech."
InDarpa Workshop on Speech and NaturalLanguage.
Harriman, NY.Breiman, Leo; Friedman, Jerome; Olshen,Richard; and Stone, Charles (1984).Classification and regression trees.Wadsworth and Brooks.Brill, Eric (1992).
"A simple rule-based partof speech tagger."
In Proceedings, ThirdConference on Applied Natural LanguageProcessing, ACL, Trento, Italy.Brill, Eric (1993a).
"Automatic grammarinduction and parsing free text: Atransformation-based approach."
InProceedings, 31st Meeting of the Association ofComputational Linguistics, Columbus, OH.Brill, Eric (1993b).
A Corpus-Based Approach toLanguage Learning.
Doctoral dissertation,Department ofComputer and InformationScience, University of Pennsylvania.Brill, Eric (1993c).
"Transformation-basederror-driven parsing."
In Proceedings, ThirdInternational Workshop on ParsingTechnologies, Tilburg, The Netherlands.Brill, Eric (1994).
"Some advances inrule-based part of speech tagging."
InProceedings, Twelfth National Conference onArtificial Intelligence (AAAI-94), Seattle,WA.Brill, Eric and Resnik, Philip (1994).
"Atransformation-based approach toprepositional phrase attachmentdisambiguation."
In Proceedings, FifteenthInternational Conference on ComputationalLinguistics (COLING-1994), Kyoto, Japan.Brown, Peter; Cocke, John; Della Pietra,Stephen; Della Pietra, Vincent; Jelinek,Fred; Lafferty, John; Mercer, Robert; andRoossin, Paul (1990).
"A statisticalapproach to machine translation.
"Computational Linguistics, 16(2).Brown, Peter; Lai, Jennifer; and Mercer,Robert (1991).
"Word-sensedisambiguation using statisticalmethods."
In Proceedings, 29th AnnualMeeting of the Association for ComputationalLinguistics, Berkeley, CABruce, Rebecca nd Wiebe, Janyce (1994).
"Word-sense disambiguation usingdecomposable models."
In Proceedings,32nd Annual Meeting of the Association forComputational Linguistics, Las Cruces, NMCharniak, Eugene; Hendrickson, Curtis;Jacobson, Neil; and Perkowitz, Michael(1993).
"Equations for part of speechtagging."
In Proceedings, Conference oftheAmerican Association for ArtificialIntelligence (AAAI-93), Washington, DC.Church, Kenneth (1988).
"A stochastic partsprogram and noun phrase parser forunrestricted text."
In Proceedings, SecondConference on Applied Natural LanguageProcessing, ACL, Austin, TX.Cutting, Doug; Kupiec, Julian; Pedersen,Jan; and Sibun, Penelope (1992).
"Apractical part-of-speech tagger."
InProceedings, Third Conference on AppliedNatural Language Processing, ACL, Trento,Italy.DeMarcken, Carl (1990).
"Parsing the lobcorpus."
In Proceedings, 1990 Conference ofthe Association for Computational Linguistics,Pittsburgh, PA.Derose, Stephen (1988).
"Grammaticalcategory disambiguation by statisticaloptimization."
Computational Linguistics,14.Francis, Winthrop Nelson and Kucera,Henry (1982).
Frequency analysis of Englishusage: Lexicon and grammar.
HoughtonMifflin, Boston.564Brill Transformation-Based Error-Driven LearningFujisaki, Tetsu; Jelinek, Fred; Cocke, John;and Black, Ezra (1989).
"Probabilisticparsing method for sentencedisambiguation."
In Proceedings,International Workshop on ParsingTechnologies, Carnegie Mellon University,Pittsburgh, PA.Gale, William and Church, Kenneth (1991).
"A program for aligning sentences inbilingual corpora."
In Proceedings, 29thAnnual Meeting of the Association forComputational Linguistics, Berkeley, CA.Gale, William; Church, Kenneth; andYarowsky, David (1992).
"A method fordisambiguating word senses in a largecorpus."
Computers and the Humanities.Leech, Geoffrey; Garside, Roger; andBryant, Michael (1994).
"Claws4: Thetagging of the British National Corpus.
"In Proceedings, 15th International Conferenceon Computational Linguistics, Kyoto, Japan.Harris, Zellig (1962).
String Analysis ofLanguage Structure.
Mouton and Co., TheHague.Hindle, Donald (1989).
"Acquiringdisambiguation rules from text."
InProceedings, 27th Annual Meeting of theAssociation for Computational Linguistics,Vancouver, BC.Hindle, D. and Rooth, M. (1993).
"Structuralambiguity and lexical relations.
"Computational Linguistics, 19(1):103-120.Huang, Caroline; Son-Bell, Mark; andBaggett, David (1994).
"Generation ofpronunciations from orthographies u ingtransformation-based error-drivenlearning."
In International Conference onSpeech and Language Processing (ICSLP),Yokohama, Japan.Jelinek, Fred (1985).
Self-Organized LanguageModelling for Speech Recognition.
Dordrecht.In Impact of Processing Techniques onCommunication, J. Skwirzinski, ed.Joshi, Aravind and Srinivas, B.
(1994).
"Disambiguation f super parts of speech(or supertags): Almost parsing."
InProceedings, 15th International Conference onComputational Linguistics, Kyoto, Japan.Klein, Sheldon and Simmons, Robert (1963).
"A computational pproach togrammatical coding of English words.
"\]ACM, 10.Kupiec, Julian (1992).
"Robustpart-of-speech tagging using a hiddenMarkov model."
Computer Speech andLanguage, 6.Marcus, Mitchell; Santorini, Beatrice; andMarcinkiewicz, Maryann (1993).
"Building a large annotated corpus ofEnglish: the Penn Treebank.
"Computational Linguistics, 19(2).Merialdo, Bernard (1994).
"Tagging Englishtext with a probabilistic model.
"Computational Linguistics.Miller, George (1990).
"Wordnet: an on-linelexical database."
International Journal ofLexicography, 3(4).Quinlan, J. Ross (1986).
"Induction ofdecision trees."
Machine Learning,1:81-106.Quinlan, J. Ross and Rivest, Ronald (1989).
"Inferring decision trees using theminimum description length principle.
"Information and Computation, 80.Ramshaw, Lance and Marcus, Mitchell(1994).
"Exploring the statisticalderivation of transformational ru esequences for part-of-speech tagging."
InThe Balancing Act: Proceedings ofthe ACLWorkshop on Combining Symbolic andStatistical Approaches toLanguage, NewMexico State University, July.Roche, Emmanuel and Schabes, Yves (1995).
"Deterministic part of speech taggingwith finite state transducers.
"Computational Linguistics, 21(2), 227-253.Schutze, Hinrich and Singer, Yoram (1994).Part of speech tagging using a variablememory Markov model.
In Proceedings,Association for Computational Linguistics,Las Cruces, NM.Sharman, Robert; Jelinek, Fred; and Mercer,Robert (1990).
"Generating a grammar forstatistical training."
In Proceedings, 1990Darpa Speech and Natural LanguageWorkshop.Weischedel, Ralph; Meteer, Marie; Schwartz,Richard; Ramshaw, Lance; and Palmucci,Jeff (1993).
"Coping with ambiguity andunknown words through probabilisticmodels."
Computational Linguistics.Yarowsky, David (1992).
"Word-sensedisambiguation using statistical models ofRoget's categories trained on largecorpora."
In Proceedings ofCOLING-92,pages 454-460, Nantes, France, July.565
