Using Argumentation Strategies in Automated ArgumentGenerationI ngr id  Zukerman,  R ichard  McConachy  and  Kev in  B .
KorbSchool  o f  Computer  Science and  Sof tware  Engineer ingMonash  Un ivers i tyC layton ,  V ic tor ia  3800, AUSTRAL IAemai l :  { ingr id ,  r i cky ,  korb}@csse ,  monash,  edu .
auAbst ractDuring argumentation, people persuade their au-dience using a variety of strategies, e.g., hypo-thetical reasoning, reasoning by cases and ordinarypremise-to-goal rguments.
In this paper, we of-fer an operational definition of the conditions forpursuing these strategies, and incorporate into aBayesian argument-generation system a mechanismfor proposing applicable argumentation strategies,generating specific arguments based on these strat-egies, and selecting a final argument.1 In t roduct ionDuring argumentation, people persuade their audi-ence using a variety of strategies, e.g., hypotheticalreasoning, reasoning by cases and premise to goal.Although the use of different strategies i common inhuman argumentation, the argumentation and dis-course planning systems developed to date offer littleinsight into the problem of proposing different argu-mentation strategies and selecting among them.In this paper, we extend our previous work onargument generation (Zukerman et al, 1998; Zuker-man et al, 1999) to address this problem.
In thisextension, we provide an operational definition ofpromising conditions for pursuing different argumen-tation strategies, and incorporate the procedure forselecting an argumentation strategy into the contentplanning process.
The integration of strategy selec-tion and content planning is necessary due to theinterplay between argumentation strategy and con-tent: the strategy influences the content hat is rele-vant to an argument, while the information gatheredearly in the content planning process determines theapplicability of the different strategies.The argumentation strategies discussed in thispaper are premise to goal,.~hypothetiddl ~red~ctio" ....ad absurdum and inference to the best explanation)and reasoning by cases (exclusive and non-exclusive)(Figure 1).
Premise to goal starts from believedpremises and proceeds to the goal.
Reductio ad ab-surdum assumes the negation of the goal, leading toan argulnent which results in a contradiction witha believed premise and requires the assertion of thePremise to goal: Corrective lenses are re-quired.
"Being unable to see far objects is evidence formyopia, which indicates that corrective lensesare required.
"Reduct io  ad absurdum:  There has alwaysbeen matter.
"There could never have been a time whennothing existed, for, if there were \[hypotheti-cal assumption\], then nothing would exist now,since from nothing comes nothing."
(from St.Thomas Aquinas)In ference  to the best  exp lanat ion:  Patienthas the flu.
"If she had the flu \[hypothetical assumption\],she would be tired, achy.
and feverish, whichare all true.
Hence, she probably has the flu"Reason ing  by cases (exclusive):  There can-not be a utopian society.
"Having checks on procreation leads to miseryand vice, which in turn results in a non-utopiansociety.Having no checks on procreation leads to a pop-ulation explosion, which in turn leads to star-vation.
This also results in a non-utopian soci-ety."
(from Malthus, 1798)Reason ing  by cases (non-exclusive):  Fail-ing a test.
"I don't know whether he is stupid or lazy.
Buteither way, he is likely to fail the test.
"Figure 1: Examples of Argumentation Strategiesgoal to resolve this contradiction.
Inference to the.best.
explanation (Lipton,, 1991) assumes&he goal,leading to an argument hat supports a believedpremise (which would be disbelieved in the absence~,of ,thia, assmnption)~ ~Reasoning,,by casesmnumeratesa set of exhaustive conditions and establishes that adesired conclusion would follow regardless of whichcase is true.
~ In particular, we consider two typesof reasoning-by-cases trategies: exclusive and non-1 Reasoning by cases is not related to case-based reasoning,which involves problem solving based upon some stereotypicalcase-55exclusive.
The exclusive strategy is applicable to sit- choice, on argument persuasiveness.
The mecha-uations where the belief in a proposition is unknown nisms developed by these researchers, which are ap-or not agreed upon by the conversational partners, plicable after an argumentation strategy has beenIn this case, two separate arguments for the goal are selected, are expected to complement our future in-generated, one assuming the truth of this proposi- vestigation on modeling the effect of rhetorical fac-tion and the other assuming its falsity.
2 The non- tots on an addressee's beliefs.exclusive strategy applies to situations where at leastone of several propositions i  known to be true, but 3 The  Argument  Generat ion  Processit is not known which.
This strategy produces epa-rate arguments in support o f  the goal, each of which The platform for our investigation is the argumenta-assumes the truth of one of these propositions, tion system NAG (Nice Argument Generator) (Zuk-In the following sectiiSfi,~we " discuss r~l~ged-"~~: ...... ~erma~:~ec.~etl.,.~.1998i..Zukermar~,.et.
aL~A-999:)..NAG ... .
.
.search.
Next, we present an overview of NAG's argu- generates nice arguments, that is, arguments thatare both normatively correct and persuasive for a ment generation process.
We then describe our pro-cedure for proposing argumentation strategies, and target audience.
To this effect, it tests the effectsfor generating and selecting specific arguments.
Fi- of prospective arguments on two models: (1) a nor-nally, we illustrate the operation of our mechanism mative model, which represents NAG's beliefs, andwith an example, discuss results from our prelimi- (2) a user model, which represents a user's presumedbeliefs.
Each model incorporates a Bayesian net- nary evaluation and present concluding remarks.
work (BN) (Pearl, 1988) as its main representation2 Re la ted  Research  formalism (BNs were chosen because of their abil-ity to represent normatively correct reasoning un-A general introduction to hypothetical reasoning, in- der uncertainty).
An argument is represented as ancluding a discussion of counterfactual reasoning and Argument Graph, which is a network of nodes thatmodality, may be found in (Rescher, 1964).
The represent propositions, and links that represent theuse of suppositions in hypothetical reasoning to cre- inferences connecting these propositions.
This Ar-ate reductio ad absurdum arguments i described in gument Graph is obtained from the structural in-(Freeman, 1991), and their use in the analysis of tersection of relevant portions of the normative andsuch arguments is discussed in (Fisher, 1988).
Fis- user BNs.
By considering the Argument Graph rel-cher also illustrates how suppositions can lead to ar- ative to both models we are able to assess both itsguments that explain observed outcomes, a weaker normative correctness and its persuasiveness.version of inference to the best explanation.
Condi- NAG receives as input a goal proposition to betional argumentation, a weaker form of reasoning by argued for, an initial argument context, and a tar-cases, where not all the cases must be examined and get range for the belief to be achieved in the goalthe beginning of each case does not have to be proven (as a result of the argument) in the user model BNwithin the argument i self, is described in Freeman's and the normative model BN.
Initially, the context iswork.
These works provide theoretical insights into composed of the goal proposition and salient propo-the field of dialectics.
However, they do not present sitions and concepts mentioned in the preceding dis-implementable computational mechanisms, cussion.
During argument generation, the context isIn the area of discourse planning, few systems expanded to include the current Argument Graph.deal with the selection of argumentation strategies.
Figure 2 shows the main modules of NAG (theCerbah (1992) considers three discourse strategies: modules in double boxes contain the new argulnen-CausaIChain, which is a special case of our premise tation strategy mechanisms).
After receiving a goalto goal strategy'; Parallel, which assigns a paral- proposition, the Strategist activates a sequence oflel structure to part of the text.
; and Concessive.
focusing-generation-analysis cycles as follows.
First:These strategies reflect specific patterns of argumen- the Attentional Mechanism is invoked to focus onration which may be incorporated in our higher level parts of the normative and user BNs that are likelystrategies.
Elhadad (1995) considers the use of at- to be useful in the argument.
This is performed bygumentative features at several stages of the dis- spreading activation from the initial context.
Thiscourse planning process, but none of his stages deals process generates an initial Argument Graph, and inwith high-level argumentation.st.mtegies...Reed and .
.
tater~ cycles extends-the exist ing ArgumentGraph.Long (1997) use ordering heuristics to model the el- The Strategist hen calls the Generator to continuefect of presentation order on argument persnasive- the argument building process by finding additionalness, and Mareu (1996) considers the effect of vari- information to incorporate in the Argument Graphous stylistic factors, including ordering and lexical (Zukerman et al, 1998).
The extended Argument2The generalization of this strategy to N propositions re- Graph is returned to the Strategist,  which invokesquires the presentation of 2 \" cases: in the current implemen- the Analyzer to deternfine the beliefs in the uodestation, only individual proposit.ions are considered, in the Argnnlent Graph under a variety of condi-56Argument 1 H Argu~Generator | , ~....A.m,al,yzer- - ' - ' -~- ' -~  Argument ~ Argument?
~ Goal Analysis ~ a  .
.
.
.
.
.
.
~",.....~A n aly sisArgument ~"'-,.,,,,P ro p osi t ion s / /  ~k~u-,y,~ ~, Mechanism,Figure 2: System Architecturetions (Section 4.1).
The Analyzer uses a constrainedBayesian propagation scheme on the normative anduser BNs, limiting the updates to the subnetworksrepresented in the Argument Graph.
For the pur-poses of Bayesian updating, propositions which areprovided in the preamble are treated as "observa-tions"; that is, their degrees of belief are used assources during Bayesian propagation.
Based c,n thebeliefs resulting from the Bayesian propagation, theStrategist determines which argumentation strate-gies are worth pursuing (Sections 4.2 and 4.3).
If nostrategy ields a nice enough argument, i.e., the be-lief in the goal is outside the target range in one orboth models, the context is expanded, and anothergeneration-analysis cycle is performed: the Strate-gist re-activates the focusing mechanism, followedby the re-activation of the Generator and then theAnalyzer.
This process iterates until a successfulArgument Graph is built, or NAG is unable to con-tinue, e.g., because it failed to find further evidence.If one or more strategies yield a nice enough ar-gument, the Strategist selects one of the more con-cise arguments (Section 4.4).
The corresponding Ar-gument Graph and an ordering of the nodes to bepresented are then passed to the Presenter, whichremoves easily inferred propositions from the argu-ment.
After each removal, the Presenter activatesthe Analyzer to check whether the argument remainsnice enough, and the Attentional Mechanism to de-termine whether the argument can still be followedby the user.
After the Presenter determines that nomore propositions can be removed from the argu-ment, it extracts Bayesian reasoning patterns fromthe final Argument Graph and passes them to the in-terface, which renders the argument in English (Zuk-erman et al, 1999).This procedure is implemented by the followingalgorithm, which is executed by the Strategist)aA previous version of this procedure which generates onlypremise-to-goal arguments is described in (Zukerman et al,1998).
In this paper, we focus on Steps 4 and 5, which havebeen modified to support the consideration of different argu-mentation strategies during the content planning process.Generat ion -Ana lys i s  A lgor i thm1.
Perform spreading activation starting from theitems in the current context.2.
Identify new subgoals in the current ArgumentGraph.3.
Pass the subgoals identified in Step 2 to theGenerator, which adds to the current ArgumentGraph new information related to these sub-goals.4.
Pass the Argument Graph generated in Step 3to the Analyzer for evaluation under differentconditions.5.
If (based on the Analyzer's report) some of theargumentation strategies eem promising then(a) Inspect specific arguments based on thesestrategies, and(b) Pass to the Presenter the portion of the Ar-gument Graph corresponding to a conciseargument which achieves the intended be-lief in the goal.6.
Otherwise, add to the current context newnodes that were connected to the goal or be-came salient during this cycle, and go to Step 1.4 Us ing  Argumentat ion  S t ra teg iesDuring the argument generation process, the Strat-egist performs the following actions: (1) determinethe potential applicabihty of the different .argumen-tation strategies based on the beliefs in the nodesin the Argument Graph, (2) propose specific candi-dates for each apphcable.strategy, and.
(3) select aconcise argument among these candidates.4.1 Ant ic ipat ing  the effect  o f  a nodeThe Strategist selects an argumentation strategybased on the Analyzer's assessment of the effect ofthe nodes in the Argmnent Graph on the goal propo-sition (and vice versa).
This effect is determined bymeans of a constrained Bayesian propagation scheme572"in both the user model BN and the normative modelBN.
Specifically, for each node a t  the '!edge" of theArgument Graph, each new node (i.e., one addedin the last generation step), and each previous nodeto which new links were added in the last step, theAnalyzer calculates its positive and negative ffecton the goal, and the positive and negative ffect ofthe goal on this node.
4 The positive~negative effectof a node X on a node Y is the hypothetical be-lief in node Y after propagating a high/low belief innode X (which represents a true/false belief in thecorresponding proposition).
TheTositive/negativeeffect of a node on the goal is required to generatearguments by cases, and the positive/negative effectof the goal on a node is required to generate hy-pothetical arguments, viz reductio ad absurdum andinference to the best explanation.
When computingpositive/negative effects for a particular node, theBayesian propagation process uses the prior beliefsof the other nodes in the Argument Graph.4.2 Determin ing  app l i cab le  a rgumentat ions t ra teg iesAfter receiving the Analyzer's report, the Strategistchecks the following conditions to determine the po-tential applicability of each argumentation strategy.
5Reductio ad absurdum - The negation of the goalG undermines a proposition Q which is firmlybelieved independently of the goal (i.e., P(Q) =High, where Q is a premise or inferred frompremises).
Hence, P(QI~G) = Low (where Q istemporari ly treated as if it were not a premise,so that its value may change when the goal isnegated).Inference to the best explanation - The assertionof the goal G supports a proposition Q whichis firmly believed (i.e., P(Q) = High, whereQ is a premise or inferred from premises), butwhich would be unexplained (improbable) with-out supposing the truth of the goal.
Hence,whereas P(Q\[G) = High, in the absence of in-formation about G, the belief in Q is low (whereQ is temporarily treated as if it were not apremise).Reasoning by cases (exclusive) - A proposition Qsatisfies one of the following conditions: (1) ithas-an indeterminate l vel of belief in both thenormative and user models (i.e., its probabilityis within an interval \[0:5=t:O\]); or (2)it has highly4Previous nodes with new links are reconsidered becausetheir effect on the goal node (and tile goal node's effect onthem) is more likely to have changed ue to these links thanthe effects of nodes with an unchanged local topology.5For clarity of presentation, these conditions and the sub-sequent discussion assume apositive bias, i.e., the propositionunder consideration is believed: for a negative bias some ex-pressions will be altered accordingly.divergent levels of belief in the user model andthe normative model.,: For either condition, thebelief in the goal must be high both when a highlevel of belief is ascribed to Q and when a lowlevel of belief is ascribed.Reasoning by cases (non-exclusive) - There ex-ists a set of propositions {Q1,..-,Q,~}, eachof which leads to a strong belief in the goal(i.e., P(GIQi ) = High for i = 1 , .
.
.
,n ) ,  andthe disjunction of these propositions i stronglybel ieved (i.e., P(Vi  Qi) :--High) "6 .
.
.
.
.
.
.
.
.Premise to goal- This is the default strategy andrequires only that given the current beliefs inthe premises, the belief in the goal will be inthe target range in both the normative and userBNs.Since the conditions for the reasoning by casesstrategies consider nodes in the Argument Graphseparately, they do not guarantee that all opportu-nities to argue by cases will be found.
For instance,two particular nodes may not satisfy the conditionsfor the exclusive strategy when considered separately(because when a node is ascribed a high or low levelof belief, the prior beliefs of the other nodes are usedfor Bayesian propagation).
However, when consid-ered jointly, the four permutations ofextreme beliefsin these nodes, viz high-high, high-low, low-high andlow-low, may satisfy the applicability conditions ofthe exclusive strategy.
At present, these opportuni-ties are missed by NAG.
However, this may be anappropriate outcome, since such complex argumentsby cases are quite rare.4.3 P ropos ing  specif ic a rguments  for eachs t ra tegyIn this step, the Strategist considers the propositionsor sets of propositions that satisfy the conditions foreach applicable argumentation strategy, and gener-ates a specific argument based on each of these prop-ositions (or sets of propositions).
This is done asfollows for each argumentation strategy.Reduct io  ad absurdum and In ference to thebest  exp lanat ion .
For each proposition Q whichsatisfies the conditions for reductio ad absurdum, theStrategist extracts from the Argument Graph the?
subgraph whicbcorresponds to the line of reasoninggoing from the goal node (which was ascribed a lowlevel of belief) to Q (which has been contradicted6This situation may be generalized so that any Qi consistsof a subset of propositions which lead to the goal.
However,in the current implementation, each Qi consists of one propo-sition only.
Further, owing to practicality considerations, atpresent NAG implements a limited version of the applicabilityconditions for the non-exclusive strategy whereby only pairsof nodes that are relatively close to tile goal and to observablenodes are inspected.
This last requirement is necessary inor-der to determine which combinations of beliefs are possiblefor the inspected pairs of nodes.58as a result of this line of reasoning).
Each line of When choosing its final argument, the Strate-reasoning is obtained by  treating themegation of;the: .
: ~.
gis.t considers;only~=ice arguments, i.e., those thatgoal as a premise and ~Q as a goal.A similar process is applied for the inference to thebest explanation strategy, but the goal is ascribed ahigh level of belief, and Q is expected to achieve ahigh level of belief as a result of the argument.
Ingeneral, when using the reductio ad absurdum strat-egy, people identify only one target proposition tobe contradicted when the goal is negated.
In con-trast, for inference to the best explanation, the goalis often used to explain several propositions.
In thecurrent implementation, only one target propositionis being considered for both strategies.Reason ing  by cases (exclus ive) .
If propositionQ satisfies the conditions for the exclusive strategy,then a copy of the Argument Graph is made for thecase where a high belief is ascribed to Q and anothercopy is made for the case where a low belief is as-cribed to Q.
Both copies have the same structure,but the propagated values are different.
The argu-ment by cases consists of a pair of Argument Graphs,one graph for each case.
These graphs do not re-quire further analysis, since the results of propagat-ing these beliefs through the Argument Graph werepreviously returned by the Analyzer (Section 4.1),and according to the applicability conditions for theexclusive strategy, the argument for each case is suf-ficiently nice.Reasoning by cases (non-exc lus ive) .
If a setof nodes {Q1,---,  Qn } satisfies the applicability con-ditions of the non-exclusive strategy, an ArgumentGraph is generated for each of the n cases by ascrib-ing a high level of belief to each Qi in turn (the rest ofthe nodes retain their existing degrees of belief).
Ifthe Analyzer reports that the argument correspond-ing to each graph is sufficiently nice, an argument bycases is constructed by listing each graph in turn.Premise to goal.
Finally, the Strategist considersa premise to goal argument by inspecting the beliefin the goal in both the normative and user modelsafter propagation from the premises (this belief wascomputed by the Analyzer).
If the argument is niceenough, then it is retained as a possible candidate.If upon completion of this process, none of theseargumentation strategies has yielded a nice enoughargument, the reasoning context is updated withnodes that were connected to the goal or becamesalient during the current cycle.
The Strategist thenre-invokes the spreading activation process, and re-activates the Generator to expand the ArgumentGraph (Section 3).
After expansion, the analysisand strategy proposal processes are repeated.
If oneor more candidate argunmnts were generated, theStrategist selects a concise argument as described inthe next section.achieve a degree of belief in the goal which lies in-side the target range in both the user model and thenormative model.
However, we do not have a directmeans for determining the belief in the goal in theuser model as a result of a hypothetical rgument oran argument by cases.
This is because the rhetori-cal force of these strategies affects the user's beliefsin a manner that deviates from the effect modeledby means of  Bayesian propagation, as illustrated bythe sample arguments in Section 5.
The problem ofincorporating a model of the rhetorical force of anargument into a Bayesian propagation scheme is yetto be addressed.
Nonetheless, in order to test the op-eration of our mechanism, we currently approximatethe effect of an argument (regardless of its strategy)on the user's beliefs by performing Bayesian propa-gation in the user model BN.
In the future, as a firststep in modeling rhetorical factors, we intend to in-vestigate how the beliefs in our user models deviatefrom users' actual (reported) beliefs.4.4 Selecting a concise argumentHere the Strategist removes long arguments, o thata final selection is made among (shorter) argumentsof similar length.
7 NAG does not simply select themost concise argument, because as shown in Sec-tion 6, the choice of strategy has a greater influenceon the addressee's beliefs than any (small) remainingdifferences in argument length.The Strategist initially performs coarse pruningon the Argument Graphs that were generated by thepremise to goal or reasoning by cases trategies.
Thiscoarse-grained pruning examines eparately the im-pact of each individual line of reasoning contribut-ing to the belief in the goal, removing entire linesthat are not strictly necessary to achieve a belief inthe goal that falls inside the target range (the ar-guments generated using the reductio ad absurdumand inference to the best explanation strategies arenot coarsely pruned, since those arguments alreadycomprise a single line of reasoning).
Sometimes, theimpact of certain lines of reasoning cannot, be as-sessed in isolation, since two or more lines may con-tribute jointly towards the belief in a proposition in amutually dependent manner.
Often however, someof the contributing lines of reasoning are indepen-dent or nearly so, and coarse pruning can proceed.Next, the Strategist drops from consideration thearguments that a re  significa~ntly longer than theshortest argument (where length is measured innumber of nodes),8 and selects one of the remaining7Other factors, such as the structural complexity of thearguments, will be considered in the future.SAlthough an Argument Graph is further pruned beforepresenting its corresponding argument to the user (Section 3),it is reasonable toconsider lhe length of each candidate graph59(A benevolent and omnipotent) God exists j< , , \  .
.
.
.
.God is benevolent God is omnipotent(2) (3)1 1God wants to prevent evil God can prevent evil(4) (5)S?
There- is evit~in'the~world .
.
.
.
.
.
- '(6)Figure 3: Argument Graph for the Problem of Evilarguments according to the following order of prefer-ence: reasoning by cases, premise to goal, inferenceto the best explanation and reductio ad absurdum.This ordering is consistent with the results of ourevaluation (Section 6).5 Example  - The  Prob lem o f  Ev i lWe now illustrate our argumentation mechanismwith "The Problem of Evil".
Given a preamblethat establishes that there is evil in the world, andthe goal to prove that there is no God, NAG ob-tains the Argument Graph in Figure 3 after onefocusing-generation cycle, and produces the Argu-ment Graphs corresponding to the arguments in Fig-ure 4 (the adverbs that indicate level of belief andthe conjunctive xpressions are italicized in the ar-guments for ease of comparison).9 These argumentsare based on a definition of God that requires Godto be both omnipotent and benevolent.P remise  to goal.
Bayesian propagation of the be-lief in node 6 results in the denial of the combinationof nodes 4 and 5, but yields a moderate probabilityfor each of these nodes and for their respective par-ents, node 2 and node 3.
Still, the probability ofnode 1 is quite low (i.e., there is a high belief in itsnegation).Reduct io  ad absurdum.
The conditions for re-ductio ad absurdum are also met by this ArgumentGraph.
That is, the negation of the goal underminesthe belief in the premise (the existence of evil).Reason ing  by cases (exclusive) .
The condi-tions for exclusive reasoning by cases are met byboth node 4 and node 5, since they obtain mid-dling degrees of belief duringpropagation.
We 'illus- ' -trate here only the argument which hinges on node 4(the argument which hinges on node 5 is symmetri-cal).
The two cases in the generated argument are:at this stage, because it is indicative of the length of theargument  obtained after finer pruning.9The English versions of these arguments  were hand gen-erated from NAG's output.node 4 is true or node 4 is false.
The case which.........
assumes.
:the.negation.ofr~ode 4 leads:to a.straight~forward argument hat achieves the goal.
The casewhich asserts node 4 achieves the goal through anexplain away relationship which involves nodes 4, 5and 6 (Pearl, 1988).
This relationship requires that ?P(61-~4) > P(6) and P(61-~5) > P(6), which meansthat the negation of nodes 4 and 5 are potential ex-planations for node 6, and that P(416 & 5) < P(416)and P(516 & 4) < P(516), which means that givennode 6, node 5 explains away node 4 and vice versa(Zukerman et al; "'1999)':" -'Tl~at is~ ~ ~'sei~ir/g':'the "proposition in node 5 in light of node 6 greatly weak-ens the belief in node 4.Reason ing  by cases (non-exc lus ive) .
TheStrategist identifies nodes 4 and 5 as possible sourcesfor a non-exclusive argument by cases, since thenegation of each of these nodes leads to a strongbelief in the goal, and P(-~4 V-~5) is high (becauseof their relation to node 6).
The cases in the gen-erated argument are: node 4 is false or node 5 isfalse.Since all these arguments are nice, the Strategistretains all of them for further processing.
As statedin Section 4.4, the arguments that are substantiallylonger than the shortest argument (in number ofnodes) are dropped from consideration.
In our ex-ample, the premise to goal argument is the short-est, as it threads a path through the 6 nodes in theArgument Graph; the exclusive reasoning by casesargument is the longest, requiring 9 nodes (3 forthe case where node 4 is false, 5 for the case wherenode 4 is true, and 1 for stating the conclusion); thenon-exclusive reasoning by cases argument requires8 nodes (3 for each case, 1 for node 6, which in-troduces the cases, and 1 for the conclusion); andthe reductio ad absurdum argument requires 7 nodes(the 6 nodes in the Argument Graph plus 1 node forstating the conclusion).
The exclusive reasoning bycases argument is dropped from consideration sinceit is 1.5 times longer than the shortest argument,and the non-exclusive argument is select.ed amongthe remaining arguments by applying our preferenceordering.6 P re l iminary  Eva luat ionIn order to determine the users' preferences Yor dif-ferent argumentation strategies, we performed a pre-liminary evaluation where we presented two setsof arguments to subjects.
One set contained thepremise to goal and reasoning by cases argumentsfor the problem of evil shown in Figure 4.
The sec-ond set contained a preamble which presented somebackground information, and a premise to goal, areductio ad absurdum and an inference to the bestexplanation argument for a large asteroid strikingEarth 65 million years BC (Figure 5).
The argu-60Premise to goal: I"Evil in the world (6) implies.that God may not want to prevent evil (-~4) and that GQd:maynot ........ Ibe able to preveiat- egil (-45).
God possibly not wantingto prevent evil (-~)t) im~liesthdl~ God ?ndb,not be benevolent (-~2).
God possibly not being able to prevent evil (--,5) implies that God maynot be omnipotent (-~3).
The fact that God may not be benevolent (-~2) and ,that God may notbe omnipotent (-~3) implies that it is very likely that God does not exist (-,1).
'Reductio ad absurdum:"Assume that God exists (1).
This implies that God is benevolent (2) and that God is omnipotent(3).
God being benevolent (2) implies that God wants to prevent evil (4).
God being omnipotent(3) implies that God can prevent evil (5).
The fact that Godwants  to prevent evil (4) and thatGod can prevent evil (5) implies that there is no evil in the world (-~6).
But there is evil in theworld (6): ,Therefore~.Go:d:doesmot exist.
"Reasoning by cases  (exclusive):"Consider the following cases: God wants to prevent evil (4), and God does not want to preventevil (--14).God wants to prevent evil (4).
This, together with the existence of evil (6) implies that God isnot able to prevent evil (~5), which in turn implies that God is not omnipotent (-~3).
This impliesthat God does not exist (~1).God does not want to prevent evil (~4).
This implies that God is not benevolent (-~2), which inturn implies that God does not exist (~1).Either way, God does not exist (-~1).
"Reasoning by cases (non-exclusive}:"Since there is evil in the world (6), God does not want to prevent evil (-~4) or God cannot preventevil (-~5).God does not want to prevent evil (-,4).
This implies that God is not benevolent (~2), which inturn implies that God does not exist (~1).God cannot prevent evil (-~5).
This implies that God is not omnipotent (-~3), which in turn impliesthat God does not exist (-11).Either way, God does not exist (--1).
"Figure 4: Argumentsments in each set were presented in two differentorders.
40 subjects read the 'problem of evil' ar-guments, and 35 the 'asteroid' arguments.
In theformer set, the distribution of preferences was uni-form among the three strategies.
In the latter set,premise to goal was preferred, followed by inferenceto the best explanation and then reductio ad absur-dum (these results, which were not affected by theorder of presentation, were supported by X 2 testswhich were significant at the 0.01 level).At first glance it appears that premise to goalis the preferred argmnentation strategy.
However,the participants' comments indicate that further ex-periments are required to determine the conditionsunder which different argumentation strategies areappropriate.
For exarnple,several participants in:dicated that reductio ad absurdum arguments areappropriate when the ensuing contradiction is com-pelling, which tile3" did not find to be the case in theasteroid example.
Further.
they stated that theyliked the premise to goal argument because it con-tained inorc information than the other argunmnts(which have one line of reasoning only).
However.for the Problem of Evilthis additional information may be less appealingfor arguments that are longer than one paragraph.7 Conc lus ionWe have offered an operational definition of theconditions for pursuing three types of argumenta-tion strategies: hypothetical, reasoning by cases andpremise to goal.
We have also presented a mecha-nism that proposes applicable argumentation strate-gies based on these conditions, and generates specificarguments based on these strategies.
This mecha-nism has been implemented in a Bayesian argument-generation system.
Our evaluation also brings tonotice tile need to investigate additional aspects ofargumentation strategies.8 ?
~ :AcknowledgmentsThis work was supported in part bv Australian Re-search Council grant A49531227.ReferencesCerbah, F. (1992).
Generating causal explana-tions: From qualitative models to natural lan-guage texts.
In ECAI92 - Proceedings of the61Preamble :"Approximately 65 million years BC the dinosaurs, large reptiles that dominated the Earth formany millions ofwears,~becameextinct.
At aboutthe sametime,-the-nnmber:of giant Sequoias inCalifornia greatly increased.
"P r ~  to goaT:"65 million years ago, dinosaurs became xtinctand giant sequoias proliferated.
These events mayhave been caused by a cooling of the Earth, which in turn may have been caused by materialobstructing the sun.Lots of 65 million year old iridium deposits have been found.
This may have been caused bywidespread iridium being deposited 65 million years ago, which together with the material ob-structing the sun may have been caused by an explosion which threw up material.
This explosionmay have been:caused.b~.a tar.ge.iridium~rich~astexoid~.~trikiag~.E~.th~65,,million.~years BC.
'~ ... ......\ [ ' ~ r o i d  had not struck Earth 65 million years BC, there wouldn't be aI large explosion that up throws material.
Therefore, iridium would not have spread around, andI widespread 65 million year old iridium deposits would not have been found.I However, widespread 65 million year old iridium deposits were found.
Therefore, a large iridium-I rich asteroid struck Earth about 65 million years BC.
"In fe rence  to the  best  exp lanat ion :"If an iridium-rich asteroid had struck Earth 65 million years BC, there would have been anexplosion that throws up material, hence widespread iridium would have been deposited.
Therefore,lots of 65 million year old iridium deposits would be found.Since widespread 65 million year old iridium deposits were found, then an iridium-rich asteroidstruck Earth 65 million years BC.
"Figure 5: Arguments for an Asteroid Striking Earth 65 Million Years BCTenth European Conference on Artificial Intelli-gence, pages 490-494, Vienna, Austria.Elhadad, M. (1995).
Using argumentation i textgeneration.
Journal of Pragmatics, 24:189-200.Fisher, A.
(1988).
The logic of real arguments.
Cam-bridge University Press, Cambridge: England.Freeman, J.
(1991).
Dialectics and the macrostruc-ture of arguments: a theory of argument structure.Foris Publications, Berlin.Lipton, P. (1991).
Inference to the best explanation.Routledge, London; New York.Malthus, T. (1798).
Essay on the Principle of Pop-ulation as it affects the Future Improvement ofSociety with Remarks on the Speculations of Mr.Godwin, Mr. Condorcet and other Writers.Marcu, D. (1996).
The conceptual and linguisticfacets of persuasive arguments.
In Proceedings ofECAI-96 Workshop - Gaps and Bridges: New Di-rections in Planning and NLG, pages 43-46, Bu-dapest, Hungary.Pearl, J.
(1988).
~ Probabilistic .Reasoning in Intelli-gent Systems.
Morgan Kauflnann Publishers, SanMateo, California.Reed, C. and Long, D. (1997).
Content orderingin the generation of persuasive discourse.
In IJ-CAI97 - Proceedings of the Fifteenth Interna-tional Joint Conference on Artificial Intelligence.pages 1022-1027, Nagoya, Japan.Rescher, N. (1964).
Hypothetical reasoning.
NorthHolland, Amsterdam.Zukerman, I., McConachy, R., and Korb, K.
B.(1998).
Bayesian reasoning in an abductive mech-anism for argument generation and analysis.
InAAAI98 - Proceedings of the Fifteenth NationalConference on Artificial Intelligence, pages 833-838, Madison, Wisconsin.Zukerman, I., McConachy, R., Korb, K. B., andPickett, D. A.
(1999).
Exploratory interactionwith a Bayesian argumentation system.
In IJ-CAI99 - Proceedings of the Sixteenth Interna-tional Joint Conference on Artificial Intelligence,pages 1294-1299, Stockholm, Sweden.62
