CATEGORY STRUCTURESGera ld  GazdarCognitive Studies Programme, University of Sussex, Brighton BN1 9QN, U.K.Geoffrey K. Pu l lumCowell College, University of California, Santa Cruz, Santa Cruz, California 95064, USARober t  Carpenter ,  Ewan KleinCentre for Cognitive Science, University of Edinburgh, Edinburgh EH8 9LW, U.K.Thomas  E. Hukar iDepartment of Linguistics, University of Victoria, Victoria, B.C., Canada V8W 2Y2Rober t  D. LevineDepartment of Linguistics, University of British Columbia, Vancouver, B.C., Canada V6T lW5This paper outlines a simple and general notion of syntactic ategory on a metatheoretical level,independent of the notations and substantive claims of any particular grammatical framework.
Wedefine a class of formal objects called "category structures" where each such object provides aconstructive definition for a space of syntactic ategories.
A unification operation and subsumption andidentity relations are defined for arbitrary syntactic ategories.
In addition, a formal anguage for thestatement of constraints on categories i provided.
By combining a category structure with a set ofconstraints, we show that one can define the category systems of several well-known grammaticalframeworks: phrase structure grammar, tagmemics, augmented phrase structure grammar, elationalgrammar, transformational grammar, generalized phrase structure grammar, systemic grammar,categorial grammar, and indexed grammar.
The problem of checking a category for conformity toconstraints i shown to be solvable in linear time.
This work provides in effect a unitary class of datastructures for the representation f syntactic ategories in a range of diverse grammatical frameworks.Using such data structures hould make it possible for various pseudo-issues in natural anguageprocessing research to be avoided.
We conclude by examining the questions posed by set-valued featuresand sharing of values between distinct feature specifications, both of which fall outside the scope of theformal system developed in this paper.The notion syntactic ategory is a central one in mostgrammatical frameworks.
As Karttunen and Zwicky(1985) observe, traditional "parsing" as taught for lan-guages like Latin involved little more than supplying adetailed escription of the grammatical category of eachword in the sentence to be parsed.
Phrase structuregrammars are entirely concerned with assigning termi-nal strings to categories and determining dominance andprecedence between constituents on the basis of theircategories.
In a classical transformational grammar(TG), the objects transformations manipulate are pri-marily strings of syntactic ategories (and, to a lesserextent, of terminal symbols).
This is just as true ofrecent TG work.Although the use of syntactic ategories is not alogical prerequisite of generative grammar (see Levyand Joshi (1978)), no linguistic approach known to usdispenses with them altogether.
In view of this, it isperhaps urprising that linguists have not attempted toexplicate the concept "syntactic ategory" in any gen-Copyright 1988 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material is granted providedthat he copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, orto republish, requires a fee and/or specific permission.0362-613X/88/010001-19503.00Computational Linguistics, Volume 14, Number I, Winter 1988 1Gerald Gazdar et al Category Structureseral way, i.e., independently of particular systems ofnotation and the associated substantive assumptionsabout grammar.In this paper we offer an explicit metatheoreticalframework in which a notion of "syntactic ategory"receives aprecise definition.
The framework is intendedto facilitate analysis and comparison of the underlyingconcepts of different theories, freed from the notationaland sociological baggage that sometimes encumbers theoriginal presentations in the literature.
Viewed from thestandpoint of implementation, it can be regarded asproviding aunitary data structure for categories that canbe used in the implementation f a number of superfi-cially different grammatical frameworks.We begin by defining in section 1 a space of catego-ries broad enough to encompass the objects employedas syntactic ategories in a range of diverse types ofgenerative grammar.
Then, in section 2, we present thesyntax and semantics for L c, a formal language fordefining constraints on categories.
In the succeedingsection we provide illustrative definitions of the gram-matical categories used in a number of frameworks.
Wecover simple phrase structure grammar in section 3.1;tagmemics in section 3.2; Harman's (1963) augmentedphrase structure grammar in section 3.3; relationalgrammar and arc pair grammar in section 3.4; X syntax,TG, and the government-binding (GB) framework insection 3.5; generalized phrase structure grammar(GPSG) in section 3.6; systemic grammar in section 3.7;categorial grammar in section 3.8; and Aho's (1968)indexed grammar in section 3.9.
We then go on toconsider some relevant computational complexity mat-ters (section 4).
Finally, we discuss two issues that donot arise in any of these approaches, and which falloutside the scope of the simple theory that we present,namely the use of sets as values of features (section 5)and values shared between distinct feature specifica-tions (section 6).
These issues are important in thecontext of the category systems employed in functionalunification grammar (FUG), lexical functional grammar(LFG), and the PATR II grammar formalism.Our goal in this paper is not an empirical one, butrather one which is analogous to that of Montague's"Universal Grammar" (1970) (see Halvorsen and La-dusaw (1977) for a useful introduction) which attemptsto give a general definition of the notion "possiblelanguage" in terms applicable to, but not limited to, thestudy of human languages.
We have the much moremodest goal of characterizing one rather simple andgeneral notion of "possible syntactic ategory", and ofexploring the range of linguistic approaches that it willgeneralize to, its formal properties, and its limitations.As will become vident below, our exercise is comple-mentary in certain respects to that of Pereira andShieber (1984) and Shieber (1987) and to recent work ofRounds and his associates on the development of a logicfor the description of the notions of syntactic ategorythat are embodied in functional unification grammar andPATR II (see Kasper and Rounds (1986), Moshier andRounds (1987), Rounds and Kasper (1986)).We do not concern ourselves with the appearance orrepresentational details of a given theory of categories(or any of the other aspects of the linguistic frameworkin question, e.g., its rule system), but only with itsunderlying semantics--the issue of what set-theoretic(or other nonlinguistic) objects provide categories withtheir interpretation.
We are content with being able toexhibit an isomorphism between one of the theories ofcategories permitted by our framework and the concreteexample we are considering; we need not demonstrateidentity.
Hence we have deliberately refrained fromspecifying a formal anguage for representing categoriesand features.
To the extent hat we need to produceexemplificatory features or categories for inspection,we may use the conventional notation of the approachin question, or the ordinary notations of set theory, oran informal abeled graph notation introduced below,but we do not offer a representational formalism forcategories that has a significance of its own.In the framework we provide, it is possible to definethe category systems of a wide variety of apparentlyvery different approaches to natural anguage syntaxsimply by defining two primitive typing functions, andby varying the constraints stated on the categories thatthey induce.
The exercise of expressing the content ofvarious specific linguistic approaches in such termsimmediately calls attention to certain interesting formalissues.
For example, we reconstruct below the notion ofa list-valued (or stack-valued) feature in terms of cate-gory-valued features, which automatically allows oper-ations defined on categories such as unification to applyto lists without special redefinition.An interesting fact that emerges from the view takenhere is that on the matter of syntactic ategories, thereis somewhat more commonality among the diverseapproaches currently being pursued than there appearsto be when those approaches are viewed in the formal-isms used by their practitioners.
The various syntacticframeworks that we examine below can be seen to sharea great deal of their underlying substantive claims aboutthe information content of the category label of aconstituent.
Our explication of these underlying com-monalities may make somewhat easier the task of thecomputational linguist attempting to implement a sys-tem on the basis of some grammatical framework, orattempting to decide which approach to implement inthe first place.In order to prepare for some of the definitions thatfollow, we will briefly and informally sketch some ofour assumptions about features and categories and theterminology we shall use for talking about them.
Acategory is a set of feature specifieations meeting certainconditions to be defined below.
A feature specificationis an attribute-value pair (f, v) where the attributef(thefeature) is atomic (i.e., given by some finite list, andregarded as unanalyzable) and the value v is either2 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category Structuresatomic or complex.
Here we shall assume just one typeof complex value, namely a category (but see below insection 5).An example of an atom-valued feature specificationwould be (SINGULAR,+) (which many grammarianswould write as \[+SINGULAR\]); intuitively, it might marksingular number (though, of course, the interpretation itactually has depends on the role it plays in the gram-mar).
An example of a complex feature specification,with a category as the value, would be (AGREEMENT,{(SINGULAR, +), (GENDER, FEM), (PERSON, 3)}); intuitively, itmight be used to convey that the value of the AGREEMENTfeature is a category representing the combination ofsingular number, feminine gender, and third person.
Inthe following sections, we will always use SMALL CAPI-TALS for feature names, and we will generally replace" - "  and "+" ,  which are standard usage in the linguis-tic literature for the atomic values of a binary feature,by 0 and 1 respectively.As we have said, a category is a set of featurespecifications meeting certain conditions.
We will nowspecify these.
We do not require that every featurename be represented in each category, but we dorequire that each occurrence of a feature be paired withexactly one value in any set of specifications; thus{(SINGULAR,+>, (SINGULAR,-->} could not be a category.Hence a category can be modeled as a partial functionC:F--> V, where F is a set of features and V is the set ofvalues.
An equivalent alternative would be to treatcategories as total functions into a range that includesan element ?
that can stand as the value where thecorresponding partial functions would fail to assign avalue.
Note that we use the term 'range' here, andsubsequently, to refer to a set that includes all thevalues that a partial function or family of partial func-tions might take given appropriate domain elements,rather than just the set of values that it does take whenwe fix a particular domain for a function.It may be helpful to think of a category as having thestructure of an unordered tree, and we will introduce atype of diagram below which exhibits this structureovertly.
Often, however, the idea of categories aspartial functions will be crucial, so it should be kept inmind throughout.Since the set V of values may include categories, thedefinition of the entire set of categories has to be givenrecursively.
Moreover, it has to allow for the possibilitythat not all values are compatible with all features.Thus, for example, in a given feature system, (GENDER,0 )  and (PERSON, plural) might be coherent objects butmnemonically perverse, whereas in another featuresystem, they might simply be ill-formed.
We shall showhow these issues can be resolved in the coming sec-tions.
We will not, however, give a constructive defini-tion of the set of categories for each grammaticalframework we consider.
Instead, given our comparativeand metatheoretical goals, it turns out to be moreconvenient to define a category system as a pair (~, C>where ~ is a category structure, which defines a set ofpotential categories (see section 8), and C is a set ofconstraints expressed in L c, a language for which thecategory structure defines the models (see section 9).The actual categories in the system are then to beconstrued as that subset of the potential categoriesdefined in ~, each member of which satisfies everyconstraint listed in C.1 DEFINING CATEGORY STRUCTURESIn this section we define the notion of a categorystructure, which is basically a choice of primitives: a listof features, and a range of possible values for each.Here and throughout the paper we will frequently use"2"  to denote the set {0, l} (the context will make itclear when "2"  represents an integer and when itrepresents a set).
We will write A B for the set of totalfunctions from B into A,A  (m for the set of partialfunctions from B into A, @(A) for the power set of A,IAIfor the cardinality of A, and Aft) for the domain of a(partial) function f ( i f f  is a partial function than A(f) isthe set of items to which f assigns a value).A category structure E is a quadruple (F, A, r, p)where F is a finite set of features, A is a finite set ofatoms, r is a function in 2 F, and p is a function from{flW.D = 0} into ~(A).
The function r partitions F intotwo sets: the set of type 0 features F ?
= {fir(f) = 0}, andthe set of type 1 features F l = {fir(f) = 1}.
We will writer as r 0 when F = F ?.
Type 0 features take atomic valuesand type 1 features take categories as values.
Thefunction p assigns a range of atomic values to eachfeature of type 0.The set of categories K is recursively defined interms of (F, A, r, p), in a way very similar to that usedin Pollard (1984, p. 299ff), though Pollard's assumptionsdiffer on some important details.
A relatively informalpresentation will suffice here.
We will refer to the set ofpartial functions from F ?
into A that are consistent withp as the type 0 categories.
We first define the set of puretype 0 categories of ~ as those containing only type 0feature specifications.
Then we build up K via a seriesof approximations we will refer to as levels, finallytaking the infinite union of all the levels to obtain Kitself:(1) a. O is a category at level 0b.
If a is a type 0 category and fl is a categorycontaining only type 1 features whose values arecategories at level n, then a U fl is a category atlevel n + 1.c.
K is the set of all categories at all levels n -> 0.Given the way K is built up, the induction step in (Ib)being restricted to union of finite partial functions, itshould be clear that K is a recursive set.We can define certain relations and operations on thespace K of possible categories.
Thus, we can give aComputational Linguistics, Volume 14, Number I, Winter 1988Gerald Gazdar et aL Category Structuresconstructive definition for unification (symbolized U) asa binary operation on categories.
(2) Definition: unification(i) if (f, v) E a but/300 is undefined, then (f, v)E aU/3;(ii) if (f, v) E/3 but a(f) is undefined, then (f, v)E ~U/3;(iii) if (f, v;) e a and (f, b) e /3 and ~-(\]) = 1, theni f  vi U b is undefined, a U/3 is also undefined,else (f, v i U vj) @ a U/3;(iv) if (f, vi) E a and (f, 5) E /3 and T(j') = 0, thenif vi = vj, (f ,  vi) E /3 U/3, else a U/3 isundefined.
(v) nothing else is in a U/3.We can then use unification to define the subsumesrelation between categories (where 'subsumes' means'is more general/underspecified than', or 'is extendedby').
We symbolize 'subsumes' with 'E_', and define it asfollows.
(3) Definition: subsumptiono~ subsumes/3 (a E_/3) if and only if/3 = a U/3.Thus a subsumes/3 if and only if/3 is the unificationof a and/3.
When a subsumes/3 then we may refer to/3as an extens ion  of a.
If a U/3 is undefined, then/3 = aU/3 fails, and a does not subsume/3.
From this it followsthat, if a and/3 are categories, then a =/3 if and only ifa E_/3 and/3 E_ a.
The following theorem is provable byinduction on category levels.
(4) Theorem:a subsumes/3 if and only if(i) Vf E (A(a) fq F ?)
\[a(f) = /3(f)\] and(ii) Vf E (A(a) tq F 1) \[a(f) F"/3(f)\].2 THE CONSTRAINT LANGUAGE L cWe now provide an interpreted formal anguage, L C, forexpressing specific constraints on categories.
Con-straints are statements that can be true or false of acategory.
By requiring satisfaction of the constraint, aconstraint can be used to delimit a subspace within theset K induced by a given category structure E, to serveas the grammatical categories for a particular type ofgrammar.It should be noted that our goals in formulating L care slightly different from those of Rounds and hisassociates: Lc  is a language for formulating constraintson well-formed categories, not a language whose ex-pressions are intended for use in place of categories.
Toput it rather crudely, our language is for categorydefinition whereas Rounds' is (in part) for categorymanipulation.
However, the languages look rather sim-ilar syntactically, and where they overlap, the seman-tics is essentially the same.We define two types of constraint: basic and complex.If f is an element of F, and a is an element of A, thenthere are just two distinct types of well-formed basicconstraint:(5) a. fb.
32a (where ~-(f) = 0)Informally, (5a) constrains a category to contain somespecification for the feature f; thus, the constraint"BAR" says that every syntactic ategory satisfying ithas as one of its elements a pair (BAR, n).
This does notentail that every value of every category-valued featurecontained in the category must contain BAR; a basicconstraint applies to the "top level" of the tree-likestructure of a category.
Likewise, (5b) says of a cate-gory satisfying it that it has as one of its elements thepair (f, a).
Note that the only thing a basic constraintcan require of a type 0 feature beyond saying that itmust be present (defined) is that it have a particularatomic value, and that a basic constraint cannot requireanything of a type 1 feature at all beyond demanding itspresence.Turning to complex constraints, we now continue thelist (5), giving the syntax for each type of complexconstraint ogether with an informal indication of itssemantics.
Assume that f is  an element of F 1, and 05 andare themselves well-formed basic or complex con-straints, and that we are considering the interpretationof the constraints with respect o some fixed categorystructure Y and some category a.
(5) c. 32 05 ' f  is defined in a and its value satisfies 05'd.
-7 05 'a  does not satisfy 05'e.
05 V ~O 'a satisfies either 05 or ~O'f.
05 A @ 'a satisfies both 05 and ~0'g.
05 --> ~0 'either a does not satisfy 05 or a doessatisfy ~0'h.
05 ~ ~0 'a satisfies either both or neither of 05 andi.
D05 'a  satisfies 05, and all values of type 1features in a satisfy 1~05'j.
?
05 'either a satisfies 05 or some value of a type1 feature in a satisfies O 05'Constraints of the forms (5a) through (5h) are fairlystraightforward, but constraints like those shown in (5i)and (5j) need a little more discussion.
They introducemodality into our language.
Their purpose is to allow forrecursive constraints to be imposed on successivelyembedded layers of category values.
As indicated, acategory a satisfies r-\]05 provided that, firstly, a satisfies05 and secondly, whenever a assigns a category/3 to atype 1 feature f,  /3 satisfies D05.
This may appear tointroduce a circularity, but it does not: categories arefinite, and within any category there will be a level sodeeply embedded in the tree structure that there are nomore category values within it; at that point \[~05 is trueif 05 is, thus ending the recursion.Our choice of notation in (5i) is quite deliberate: ineffect, constraints of the form (50 express universalquantification over embedded accessible' categories in4 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category Structuresthe way that the familiar necessity operator \[\] of modallogic enforces universal quantification over accessibleworlds in the standard semantics.
The possibility oper-ator in (5j) is, as usual, the dual of the necessityoperator: O 4, says of a category a satisfying it thateither a satisfies tO, or there exists a category-value/3assigned to a type 1 feature fby  a such that/3 satisfies<>tO.As a simple example of the sort of work a complexconstraint in Lc might do in a grammatical theory,consider the constraint hat is known as the "Casefilter" in recent TG (see Chomsky 1980, p. 25).
Statedinformally as "*N,  where N has no Case",  the con-straint appears to require every occurrence of thefeature complex characterizing the category N, i.e.,every occurrence of \ [+N, -V \ ] ,  to co-occur with afeature called "Case" .
The constraint can be stated inLc as (6).
(6) \[\](((N: I) A (v: 0)) ~ CASE)Here and from now on, we use parentheses in theobvious way wherever it is necessary prevent ambiguityin the statement of constraints.The account of L c given thus far will suffice for areading of this paper, but those readers who would liketo see the semantics given more formally may turn tothe appendix.To recapitulate, a theory of categories ?
in our senseis a pair (E, C), where I?
is a category structure and C isa set of sentences of Lo  The set of categories deter-mined by ?
is the maximal subset Kc of K determinedby E such that each member of K c satisfies everymember of C.3 ILLUSTRATIVE APPLICATIONSWe will now illustrate the application of the apparatusdeveloped thus far by reconstructing the category sys-tems used in a number of well-known grammaticalframeworks that linguists have developed, most of themframeworks that have been used in natural languageprocessing systems at one time or another.3.1 SIMPLE PHRASE STRUCTURE GRAMMARThe case of simple phrase structure grammar is trivial,but will serve as an introduction to the form of latersections, and as a straightforward example of the use ofa type 0 feature.The set of categories used in a simple phrase struc-ture grammar is just some finite set of atomic categories{al .
.
.
.
.
a,}, for example, {S, NP, VP, Det, N, V}.
Sowe fix values for F, A, z, and p as in (7):(7) a. F = {LABEL}b.
A = {a 1 .
.
.
.
.
a,}c. ~'od.
p = {<LABEL, A)}Thus, for example, we might have A = {S, NP, VP, Det,N, V}, and thus have /~LABEL) as the same set.
Inaddition, we need the following constraint, o make surethat every category does indeed have a specification forthe solitary type 0 feature LABEL, i.e., to exclude theempty set from counting as a category:(8) LABELObviously, we can now show that the category inven-tory for any simple phrase structure grammar is repre-sentable.
We let 0 be the bijection defined by 0(a/) ={(LABEL, ai)}, and the result is immediate.
Thus there is abijection from the set of simple phrase structure gram-mar categories to the categories admitted by the cate-gory structure (7) under the constraint (8).
As is evident,the set of categories induced is finite, and of cardinalityn = IAI.3.2 TAGMEMICSIt may be that there are more published syntacticanalyses of languages in the framework of tagmemicsthan in any other theoretical framework ever devel-oped.
Since the early 1960s, those who have followedthe work of Kenneth Pike, including a very largenumber of field linguists working for the Summer Insti-tute of Linguistics, have produced analyses of hundredsof languages, mostly non-Indo-European.
Moreover,Postal (1964, p. 33) remarks that "these languages are,for the most part, exotic enough so that the tagmemicdescriptions of them may very well be the only onesdone.
"Tagmemics describes yntactic structure in terms ofTAGMEMES, which are notated in the form A:b, where A issaid to represent a SLOT and b a FILLER.
For example,Elson and Pickett (1962) represent (part of) the structureof English prepositional phrases and intransitive clauseswith tagmemic formulm (i.e., rules) similar to the fol-lowing (we simplify very slightly):(9) a. L raPhr - -  +R:prep +A:mNcb.
mNc -- +Lim:ar --M:aj +H:ncc.
iCl = +S:mNc +iP:v 3The informal explication of these is: (9a) one type oflocation relater-axis phrase consists of an obligatoryrelater slot filled by a preposition followed by anobligatory axis slot filled by a modified count nounphrase; (9b) one type of modified count noun phraseconsists of an obligatory limiter slot filled by an articlefollowed by an optional modifier slot filled by anadjective followed by an obligatory head slot filled by acount noun; (9c) one type of intransitive clause consistsof an obligatory subject slot filled by a modified com-mon noun phrase followed by an obligatory intransitivepredicate slot filled by a verb of class 3.
Thus the lefthand side of a formula (before the equality sign) consistsof an atomic label, and the right hand side is a string oftagmemes, which are ordered triples (a, b, c) where a isan indication of optional (-+) or obligatory (+) status, bis a slot or function name, and c is a filler or categorylabel.Computational Linguistics, Volume 14, Number 1, Winter 1988 5Gerald Gazdar et al Category StructuresOne way of representing tagmemes in our terms is toemploy a type 0 feature bearing the slot name, taking asvalue an atomic label identifying the filler.
Thus we setup correspondences like the following:(10) a. R:prep {(R, prep)}b.
A:mNc {(A, mNc)}c. Lim:ar {(him, ar)}d. M:aj {(M, aj)}e. H:nc {(H, nc)}f. S:mNc {(s, mNc)}g. P:v 3 {(P, v3)}Left hand sides of formulae can be seen as implicitschematizations over slot names.
For example, (9b)says that for any slot name o-, a constituent labelled {(o-,mNc)} may have the immediate constituent analysisseen on the right hand side of the equation.A category structure representing a set of categoriesincluding all those seen in the above illustrative xam-ples is given in (11).
(II) a. F = {R,A,LIM,M,H,S,P}b.
A = {LraPhr ,p rep ,mNc,ar ,a j ,nc ,v l ,v2 ,v3}c .
"r 0d.
p = {(R,{prep}),(A,{mNc}),(LIM,{ar}),(m,{aj}),(H,{nc}),(s,{mNc}),(p,{Vl,V2,V3})}This artificially tiny fragment does not show much ofthe structure that would be revealed in a larger frag-ment, with more word classes and phrases types, but itwill suffice to show how we could set up a categorystructure that provided isomorphic orrespondents tothe categories employed in a tagmemic description.Moreover, there is an unclarity about whether there ismore to a tagmemic formula than has been illustratedhere; as discussed by Postal (1964), there are someremarks about he treatment of agreement in Elson andPickett (1962) that imply either finite schematization radditional representational devices of an unclarifiedsort.
We will not explore this topic here.Postal (1964) is probably right in saying that tagme-mics appears to be only notationally distinct fromcontext-free phrase structure grammar.
Longacre (1965)claims that "\[b\]y bringing together function and set inthe tagmeme" tagmemics ensures that "function is atonce kept in focus and made amenable to formal anal-ysis."
Under our reconstruction, "functions" like"subject" or"modif ier" are "made amenable to formalanalysis" simply by incorporating them into the featurestructure of categories, making it clear that little was atstake in the debate between Postal and Longacre overthe content of tagmemics.
It is clear that the number ofcategories defined by a category structure for tagme-mics will be bounded from above by IFI ?
IAI, and thusfinite.
The question of whether tagmemics reduces tocontext-free grammar therefore turns on whether tag-memic formulae can in all cases be reduced to context-free rules.
This seems likely, but such issues are not thefocus of our attention in this paper.3.3 HARMAN'S  AUGMENTED PHRASE STRUCTUREGRAMMARHarman (1963) presents a proposal that involves aug-menting the ordinary category inventory (S, NP, VP,etc.)
of simple phrase structure grammar by attaching"an unordered sequence of zero or more (up to N forsome finite N) subscripts" to a category.
Abbreviatoryconventions are then used to manage large sets of rulesover the resultant vocabulary.
Note that the indicesstand for the members of a set rather than a sequence,and that there is only a finite number of them.To formalize Harman's proposal in the presentframework, we again use LABEL as the feature thatidentifies major syntactic ategories in the traditionalsense, and we set up a finite number of type 0 features~'1 .
.
.
.
.
~', to correspond to the presence (value 1) orabsence (value 0) of each of the n different subscripts.The set of feature specifications for these featuresreconstructs the characteristic function of the set ofindices.
The category structure is as follows:(12) a. F = {LABEL, F 1 .
.
.
.
.
Fn}b.
A = {al .
.
.
.
.
a,,} tA 2c.
"r 0d.
p = {(LABEL, {a 1 .
.
.
.
.
am}), (FI, 2) .
.
.
.
.
(Fn, 2)}We now have to guarantee that every category has avalue for LABEL and a value for each ,.
in F. Wetherefore impose the following constraint:(13) LABEL /~ F I /~  .
.
.
/~  F nThe resultant specification i duces a finite set of cate-gories, of cardinality m ?
2 n.Harman's ystem is more than just a historical curi-osity.
More recent works are found that use almostexactly the same sort of syntactic ategories.
For ex-ample, the use made of syntactic features in one influ-ential variety of augmented phrase structure grammar,the Prolog-based efinite clause grammar (DCG) for-malism of Pereira and Warren (1980) closely resemblesthat of Harman.
However, it is clear that the full powerof the DCG formalism can, in principle, be used toexploit features with structured values and value-sharing (see section 6 on the latter).3.4 RELAT IONAL AND ARC PA IR  GRAMMARRelational grammar (RG) Perlmutter and Postal (1977)and arc pair grammar (APG) Johnson and Postal (1980),(henceforth J&P)  appear to make relatively little use ofgrammatical category information, expressing mostgrammatical rules as conditions on arcs representinggrammatical relations between nodes (in RG) or asconditions on relations between such arcs (in APG)rather than on the labeling of nodes.
Nonetheless, J&Pmake clear that nodes are assigned grammatical cate-gory labels in APG, and since APG is essentially aformalized elaboration of RG ideas, we will assume thatmuch the same is true in RG, though the RG literatureso far has not made such aspects of the approach6 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et ai.
Category Structuresexplicit.
Syntactic ategory labels are not entirely with-out utility in RG and APG, since, for example, agree-ment rules crucially make reference to categorial prop-erties like number, gender, and person, and the properformulation of agreement rules has been a topic of someinterest in RG and APG research.As defined in J&P, an arc is an ordered pair (R((a,b)), c I .
.
.
CA) where R((a, b)) indicates that b (thesecond or head node) bears the grammatical relationnamed by the "relational sign" R to a (the first or tailnode), and cl through ck are the representational strataLadusaw (1985) at which this holds.
In APG, categoriesare assigned to nodes by means of arcs in which therelational sign is L; such arcs are referred to as L arcs.The head of an L arc is simply an atomic label from a setof "grammatical category nodes" (called GNo by J&P)that is given by listing.Two types of grammatical category are recognized inAPG: Major categories uch as CI (clause), Nom (nom-inal), and V (verb), and minor categories such asFeminine, Singular, Third-Person, etc.
A general con-straint (Pair Network Law 31, the Major CategoryExclusiveness Law) prevents a node from being the tailof two distinct arcs with heads in the set Major (J&P,202), i.e., the set of grammatical category nodes thatrepresent major categories.
We can obtain the effect ofthis law simply by assuming a type 0 feature LABELwhich takes values in the set of Major categories.In the case of minor categories, APG permits multi-ple atomic elements from GNo to be attached by L arcsto a single tail node (J&P).
Thus a node might be the tailof L arcs whose head nodes are the atoms Nom,Feminine, Singular, and Third-Person, representing athird person singular feminine noun or noun phrase.
It iseasy to represent such sets of labels attached to a singlenode using type 0 features.
We can represent the set ofelements of GNo assigned to a given tail node byincluding a category corresponding to the characteristicfunction of that set, as with the indices in Harman'ssystem.
So we fix values for F, A, T, and p as shown in(14):(14) a. F = {LABEL, F I .
.
.
.
.
Fn}b.
A = {al .
.
.
.
.
am} U 2c.
~'od.
p = {(LABEL, {a I .
.
.
.
.
am}), (F1, 2) .
.
.
.
.
(Fn, 2)}Here Major = {?l .
.
.
.
.
?n}, and GNo = {?
1 .
.
.
.
.
~,} U{a I .
.
.
.
.
am}.
The constraint needed is the following:(15) ~ ' IA .
.
.AF .This has the effect of requiring every category toinclude the characteristic function of a set (of minorcategories, in the APG sense).
However, we do notneed to guarantee that every category has a specifica-tion for LABEL, as J&P specifically leaves it openwhether there are nonterminal nodes with no associatedgrammatical categories; the absence of any grammaticalcategory node will be reconstructed in our terms as thatfunction ~" that is undefined for LABEL and which assigns0 to each ~'i E F.It can be shown that the category system just definedadequately represents category labelling in APG, in thesense that there exists a bijection 0 between (a) nonter-minal nodes together with their grammatical category Larcs in an admissible APG syntactic representation a d(b) admissible categories induced by the category struc-ture in (14) and the constraint in (15).From an arbitrary well-formed APG pair network wecan extract he set X of arcs it contains (J&P), and theset N of nodes associated with X.
Since we are notconcerned with coordinates, we can discard the coordi-nate sequences and consider just the incomplete arcs towhich the arcs in X correspond.
By Theorem I (J&P),all and only the terminal nodes in N are heads of L arcs.Extracting just the arcs with terminal nodes as headsgives us the set of L arcs from X; and discarding thosewith heads not in GNo gives us just the L arcs withgrammatical category labels as their heads.
The mem-bers of this set can be partitioned into equivalenceclasses having the same tail node (since by definition oarc has more than one tail).
For convenience of refer-ence we can call these equivalence classes category-labelled nodes.Theorem.
There is a bijection from APG category-labelled nodes to categories admitted by (14) and (15).Proof.
Consider an arbitrary category-labelled node Kwith tail n. By PN Law 31, the Major Category Exclu-siveness Law, exactly one arc in K has a head which isin Major.
Let 01 be the bijection established by 01(L(n,a)) = t~, and let 02 be the bijection established by 0(a) =(LABEL, O~) iff a E Major and (a, 1) otherwise.
Thecategory corresponding to K will be the smallest set thatcontains 0102(A) for all arcs A in K and contains (Fi, 0) forall vi in F that are not in the range of 01.
Since 01 and 02are bijections, their product 0102 is a bijection.
Thecorrespondence in the opposite direction is obvious.
Anode that is the tail of no L arcs will be mapped by 0102to ~, and other nodes will be mapped onto categories inwhich the values of the features record the details of thecategory-labelling L arcs in r together with (redun-dantly) information about which one is the major cate-gory, the mapping yielding a unique result in eachcase.l lThe set of APG (and, we assume, RG) categoriesinduced is finite, and ceteris paribus is of cardinalitym ?
2"; it will be much smaller once further conditionson coocurrence of minor categories are imposed (Mas-culine and Feminine presumably cannot both bemapped to 1 in a category, for example).
It is of interestthat despite the utterly different grammatical formalismand theoretical background associated with it, the APGnotion of syntactic ategory can be seen to be almostidentical to that of Harman's augmented phrase struc-Computational Linguistics, Volume 14, Number I, Winter 1988 7Gerald Gazdar et al Category Structuresture grammar, nodes without LABEL values contributingthe only relevant difference.3.5 X SYNTAX, TRANSFORMATIONAL GRAMMAR,GOVERNMENT-BINDINGIn the great majority of contemporary works in trans-formational grammar (TG), including those representingwhat is known as "government-binding" (GB)Chomsky (1981), the conception of grammatical catego-ries follows what is called "the X-bar convention"Jackendoff (1974) Hornstein (1977) or "X-bar syntax".
"X-bar" is often notated X or X', or as X 1, X 2, etc., thesuperscript numeral denoting the number of bars or barlevel.)
The central idea of X-bar syntax is that phrasalcategories are "projected" from lexical categories.Given a lexical category X, the related phrasal nodesare assumed to be X(= X' = X1), X(= X" = X2), and soon.Representing phrasal categories as founded on lexi-cal categories in this way amounts to treating categoriesas non-atomic, the distinction between lexical catego-ries and the various levels of phrasal category beingtantamount to a feature specification distinction.
Barlevel is not treated in terms of features in most worksusing X-bar notation, probably because of the traditionin TG (and related work in segmental phonology) re-stricting features to the values {-,  +}.
Thus Bresnan(1975) treats categories as ordered pairs (i, M) where i isa natural number epresenting the bar level and M is amatrix of feature specifications, and the same formal-ization is used by Lasnik and Kupin (1977).
Here wesimply integrate bar level information with the rest ofthe feature system.Although the origins of the X-bar proposal (Harris1951) do not take such a feature analysis of categoriesany further, but treat lexical categories as atomic, it isalways assumed in current instantiations of X-bar syn-tax that lexical categories themselves have a featureanalysis.
In much TG, it is presupposed that the lexicalcategories N, A, V, and P are to be analyzed in terms oftwo binary features Nand v. 1 Lasnik and Kupin (1977) isa fairly explicit formulation of this type of categorysystem.
They assume a maximum bar level of three.
Tocharacterize their system of categories, we fix ourvalues for F, A, ~-, and p as in (16), and impose theconstraint in (17).
(16) a. F = {N, V, BAR}b. a = {0, 1,2,3}C. ~od.
p = {iN, 2), (V, 2>, (BAR, a)}(17) N/% v/% BARThis yields a system of 16 categories, four at each barlevel.Jackendoff (1977) proposes a version of X-bar syntaxin which lexical categories are distinguished from oneanother by means of the features \[-----SUBJ\], \[--0BJ\],\[-----C0MP\], and \[--+DET\] rather than by I-----N\] and \[-+v\].
Hedoes not provide an explicit definition of his full set ofcategories, but he gives enough detail for it to bededucible.
To define Jackendoff's ystem of categories,we fix our values for F, A, ~', and p in the manner shownbelow:(18) a. F = {SUBJ, C0MP, DET, 0BJ, BAR}b. a = {0, 1,2,3}C. 7 0d.
p = {(SUBJ, 2), (C0MP, 2), (DET, 2), (0BJ, 2),<BAR, A)}To get the exact set of permissible categories, we needto make sure that SUBJ, 0BJ, COMP, and BAR are defined inall categories, and that DET is only specified in \[-C0MP\],\[-0BJ\] categories.
The following set of L c constraintswill achieve this.
(19) a. SUBJ A OSJ A COMP /%, BARb.
DET --) ((COMP:0) /~ (0BJ:0))We can now obtain a bijection between Jackendoff'sX-bar categories and the admissible categories inducedby F, A, and the constraints listed in (19).
We define amapping 0 between the Jackendoff's own categoryabbreviations and the admissible categories with re-spect to (19a) and (19b), as follows (we schematize bywriting X with n bars as X n, 0 <-- n <- 3):(20) a.
0(V") = {(SUBJ, 1), (0BJ, 1>, (C0MP, 1), (BAR, n)}b.
0(M") = (SUBJ, 1), (0BO, I), (C0MP, 0>, (bar, n)}c. 0(P") = {(SUBJ, 0), (0BJ, I), (C0MP, 1), (BAR, n)}d. 0(Prt n) = {(SUBJ, 0), (OBJ, 1), <C0MP, 0), (BAR, n)}e. 0(N n) = {(SUBJ, 1), (0BJ, 0>, (C0MP, 1), (BAR, n)}f. 0(Art") = {(SUBJ, 1), (0BJ, 0>, <C0MP, 0), (DET, 1),(BAR, n)}g. 0(Q") = {(SUBJ, 1), (0BJ, 0), (COMe, 0), (DET, 0>,(BAR, n)}h. 0(A n) = {(SUBJ, 0), (OBJ, 0), (C0MP, 1), (BAR, n)}i.
0(Deg") = {(SUBJ, 0), (0BJ, 0), (COMP, 0), (DET, 1),(BAR, n>}j. O(Adv") = {(SUBJ, 0), <OBJ, 0), (COMP, 0), (DET,0), (BAR, ~}An example of a category admitted in Jackendoff'ssystem would be {(BAR, 3), (SUBJ, 1), (0BJ, 0), (C0MP, 1)},which can be more perspicuously presented in thegraphic form given in (21).BAR 3SUBJ 1OBJ 0COMP 1As is evident, the set of categories induced by Jacken-doffs system has a cardinality of 40, ten at each barlevel.8 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category StructuresSets of categories as small as this are clearly insuffi-cient for the description of natural languages.
All trans-formational grammarians seem to agree that referencesto distinctions of tense, mood, voice, person, number,gender, case, pronominality, definiteness, wh-ness, andmany other morphological nd syntactic distinctions arein fact needed in a grammar.
As pointed out by PuUum(1985), some statements in the TG literature suggest thatfurther features are provided for the expression of suchdistinctions but are restricted to lexical (<BAR, 0)) cate-gories.
However, it is easy to find examples in theliterature of additional features like definiteness, case,wh-ness, and many others, being assigned to phrasalnodes as well.
In marked contrast o a work such asStockwell, Schachter and Partee (1973), recent TG hasnot been explicit about such matters.
Allowing fortwenty binary morphosyntactic features (a modest esti-mate if any serious effort at coverage is to be made) andallowing them only on lexical categories would increasethe cardinality of the set of categories to about 4 ?
106 inthe case of Lasnik and Kupin's system and to over 107in the case of Jackendoff's.In one respect, what we have said so far may notadequately capture the conception of categories foundin recent TG and GB works.
These works generallymake considerable and crucial use of co-indexing ofnodes, using indices taken from an infinite set such asthe integers.
If the index on a node is taken to be part ofthe structure of the category labelling that nodeChomsky (1970), which is not the only view one couldtake, then the number of distinct categories becomesinfinite.
This does not mean it becomes difficult torepresent.
Indexing of this sort can be representeddirectly in the present framework without adding aninfinite set of additional atoms such as the naturalnumbers.
We add a type 0 feature 0e (with p(0e) = {0})and a type 1 feature SUCCESSOR to the feature system anduse this to build the set of indices.
Thus the index "3"would be represented asshown in (22), where category-valued feature specifications are shown with pointers tocategories in their value positions.In some recent TG, more than one indexing system isemployed.
Thus Rouveret and Vergnaud (1980, p. 160)"postulate that each verbal complex in a structure isidentified by some integer p and each \[-N\] element in theverbal complex p bears the superscript ."
This super-scripting system is distinct from the subscripting systemmaintained toindicate anaphoric linkage or binding, andneither places an upper bound on the number of indices.Hence it would not be sufficient to have a single type 1feature.
Two further type 1 features SUBSCRIPT andSUPERSCRIPT could be used, each taking category valuesrepresenting indices with SUCCESSOR and OF.It may seem implausible to suppose that anyonewould choose in practice to handle indexing via afeature system such as that just suggested?
Nonetheless,it would clearly be possible, which shows that one canincorporate integer indices into the structure of catego-ries in terms of a finite number of features and a finitenumber of atoms, which might not initially have beenevident?3.6 GENERALIZED PHRASE STRUCTURE GRAMMARThe generalized phrase structure grammar framework(GPSG), as set out in Gazdar, Klein, Pullum, and Sag(1985), (henceforth GKPS), differs from the examplesconsidered so far in that it makes extensive use offeatures that are permitted to have categories as theirvalues.
2For concreteness, we suggest how the set of catego-ries for the GKPS version of GPSG would be recon-structed in the framework presented here (see GKPSpp.
245-6, for the complete lists where we abbreviatewith " .
.
. "
) .
(24) a. F = {SUBJ, N, C0MP, BAR .
.
.
.
.
AGR, SLASH}b.
A = {0, 1, 2, .
.
.
.
for, that .
.
.
.
}C. ~" = {(SUBJ, 0), <N, 0), <V, 0), <COMP, 0), (BAR, 0),.
.
.
<AGR, 1), <SLASH, 1)}d. p = {(SUBJ, 2), <N, 2), <V, 2), <C0MP, {for, that,?
.
.}
) , .
.
.
,  <BAR, {0, 1, 2})}We add to this, for each feature f E F ~, the following(22)Constraints are necessary to ensure that the value ofSUCCESSOR does not contain anything but SUCCESS0ROr 0especifications.
To this end, we constrain each feature fE F ?
(except 0e) as shown in (23a), and in addition weimpose (23b) and (23c):(23) a.
\[\] --1 (SUCCESSOR: 39b.
\[\] --1 (SUCCESSOR A OF)C. \ [ \ ]  --1 (SUCCESSOR: --1 OF --I SUCCESSOR)constraint:(25) \[\] -~ (f: of)This prevents a category-valued feature f from beingspecified anywhere within the value of an occurrence off.
An example of a moderately complex category withmore than one category-valued feature that nonethelessobeys (25) is shown in (26).Computational Linguistics, Volume 14, Number 1, Winter 1988 9Gerald Gazdar et al Category Structures(,,t~The constraint (25) restricts us to exactly the set of legalGKPS categories.
3 The total GKPS category set isfinite, but naturally, it is extremely large (Ristad (1986)calculates that it is in excess of 10774).
I t  is clear that theset of GKPS categories i vastly too large to be precom-piled and stored-and indeed, no implementation that weknow of has attempted this.3.7 SYSTEMIC GRAMMARSystemic grammar, originally known as "scale andcategory" grammar, has its origins in the work ofHalliday (1961) and is widely known among computa-tional linguists through Winograd (1972) and otherworks, and it has recently received rigorous formaliza-tion in the hands of Patten and Ritchie (1987).
Treestructures in systemic grammar tend to be fiat, morestructural information being expressed through catego-ries than in most other approaches Hudson (1971).Categories in systemic grammar are simply bundles offeature specifications: there is "nothing in systemictheory corresponding to the distinction between "fea-tures"--such as \[+past\] --and "categories"--such asNP and S---in TG theory" Hudson (1971, p. 48).
A setof well-formed categories in a systemic grammar isdefined by a system network, which "is in effect a bodyof rules, in symbolic form, which specify precisely howfeatures can combine with each other: in other words,which features can appear together in the paradigmaticdescription of a single item, and which cannot" Hudson(1971).We will not discuss rules for forming systemic net-works (and hence categories) here, but will instead referthe reader to the presentation in Winograd (1983),where a system network expressing category informa-tion for the English pronominal form is provided as anexample of the notational techniques used in systemicgrammar for specifying a set of categories.
We repro-duce this in Figure 1.The content of Figure 1 can be reconstructedstraightforwardly asa category structure subject o a setof L c constraints (for a closely related analysis of this10{~ AnimateQuestion _ _  -- SubjectiveCase ObjectiveReflex vePossessive Possessive-Determ ner_ I FirstPersonal ~_ .P__~ Second _ _ I FeminineIngu la r - -  J Neuterf \[ | PluralDemonstrative - - l~  Near/ FarFigure 1: Systemic Network for English Pronounsexample, developed independently, see Mellish (1986).The following is the category structure that we need:(27) a. F = {PRONOUN, CASE, PERSON, GENDER, NUMBER,ANIMACY, PROXIMITY}b.
A = {question, personal, demonstrative, subjec-tive, objective, reflexive, possessive, posses-sive-determiner, first, second, third, femininemasculine, neuter, singular, plural}C. T Od.
p = {<PRONOUN, {question, personal,demonstrative}),<CASE, {subjective, objective, reflexive, posses-sive, possessive-determiner}),<PERSON, {first, second third}),<GENDER, {feminine, masculine, neuter}),<NUMBER, {singular, plural}),<ANIMACY, 2>,<PROXIMITY, 2>}The constraints that must be imposed are the following:(28) a. PRONOUNb.
(PRONOUN:question) ~ (CASE /~ -'-I PERSON /'k ---INUMBER /~ ANIMACY /~ 7 PROXIMITY)C. (PRONOUN:personaD <--> (CASE /~ PERSON /~ NUMBER/k -q ANIMACY /~ "7 PROXIMITY)d. (PRONOUN:demonstrative) <--) (7 CASE /~ 7 PERSON/~ NUMBER /~ -3 ANIMACY /~ PROXIMITY)e. GENDER ~ (PRONOUN A (PERSON:thirD A (NUMBER:singular))Note that this description of the pronominal system ofEnglish is artificially complicated by its isolation fromthe rest of the grammar.
If it were embedded in thecontext of a definition of a wider class of categories (forexample, the English noun class network given byWinograd (1983), it would be modified by the elimina-tion of (28a) and the relaxation of (28b-d) to simpleconditionals.Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category StructuresThe structure seen in this example mploys only type0 features.
For example, the category it defines for apronoun like herse l f  would be (29).
(29) PRONOUNCASEPERSONNUMBERGENDERpersonalreflexivethirdsingularfeminineInterestingly, however, systemic grammar as formal-ized by Hudson (1971), at least is not limited to type 0features.
Hudson explicitly permits recursive growth offeature structures inorder to count constituents (see pp.60-62).
This could be reconstructed here by using a type1 feature in roughly the manner we employed SUCCES-SOR, above.
Such a use of type 1 features immediatelymakes the size of the category set infinite.3.8 CATEGORIAL GRAMMARCategorial grammar originates with work by Lesniewskiand Adjukiewicz in the 1940s (see van Benthem, Busz-kowski and Marciszewski (1986), Haddock, Klein andMorrill (1987) and Oehrle, Bach and Wheeler (1987) forrecent work and references tothe earlier literature).
Theset of categories used is infinite.
It is often defined asthe smallest set containing some set of basic categories{al .
.
.
.
.
a,}, and closed under the operation of formingfrom two categories a and/3 a new category al/3.To reconstruct the category system for categorialgrammar, we define E as shown in (30).
(30) a. F = {LABEL, DOMAIN, RANGE}b.
A = {a, .
.
.
.
.
a.}C.
"/" = {<LABEL, 0), <DOMAIN, I), <RANGE, 1>}d. p = {<LABEL, A>}We then add the following:(31) a.
\[-\](DOMAIN <--> --l LABEL)b.
\[-\](DOMAIN <--> RANGE)We can now represent any category allowed in thesimple form of categorial grammar considered so far.For example, the category (StNP)I(SINP) can be repre-sented as shown graphically in (32).
(32)DOMAINDOMAINRANGEDOMAINRANGEComputational Linguistics, Volume 14, Number 1, Winter 1988To show formally that we have captured the contentof the category system of categorial grammar, we canexhibit a bijection between the categorial grammarcategories and the admissible categories induced by F,A, and the constraints defined above.
We define amapping 0 between the categorial grammar categoriesand the admissible categories with respect o (31a) and(31b), as follows:(33) a. O(a i) = <LABEL, ai) where a i e Ab.
0(al/3) = {<DOMAIN, 0(/3)), <RANGE, 0(o0> } where aand/3 are categories.A simple structural induction argument suffices to showthat 0 is indeed bijective.
The smallest category will beof the type ai, and corresponds to{<LABEL, ai) }.
The nextstep up yields a category of the form ailaj, whichcorresponds to:(34) {<DOMAIN, {<LABEL, aj)}), <RANGE, {<LABEL, ai)}>}.Each further step replaces a i or aj by a non-basiccategory and will clearly yield a unique result.
It can beseen immediately that the mapping 0 has an inverse.The categories defined thus far are non-directional,in the sense that a complex category can combine withan argument either to its left or its right.
However, mostdefinitions assume directional categories Bach (1984).This further specification can be easily incorporated byintroducing a new feature name DIRECTION which takesvalues in 2.
We then add a constraint that categoriestaking values for DOMAIN also take a value for DIRECTION,thus determining the directionality of the category.
(35) \[-\](DOMAIN ~ DIRECTION)The translation function is then:(36) a. O(a i) = {<LABEL, ai)}b.
0(og/3) = {<DOMAIN, 0(/3)>, <RANGE, 0(a)>,<DIRECTION, I)}C. 0(a//3) = {<DOMAIN, 0(/3)>, <RANGE, 0(iX)),<DIRECTION, 0)}This translation function is again a bijection, for thesame reasons as before.
Clearly we could employ ananalogous move to subsume the od/3 vs. od//3 categorydistinction employed in Montague (1973).In some recent work on categorial grammar, it makessense to think of expressions being assigned to infinitesets of categories rather than to a single category, butwe will not pursue the implications of such a move here(see van Benthem (1986c) for relevant discussion).3.9 INDEXED GRAMMARIndexed grammars are a generalization f phrase struc-ture grammars due originally to Aho (1968).
Like cate-gorial grammar and some of the other frameworkspreviously mentioned, it uses an infinite category set.
Inthe formulation presented in Gazdar (1985), an indexedgrammar category consists of an atomic label and a11Gerald Gazdar et al Category Structurespossibly empty list (or stack) of atomic indices drawnfrom a finite set.There is a familiar technique for encoding lists orstacks in a notation which relies on the fact that lists canbe decomposed into an initial element and the residuallist (see, for example, Shieber (1984)).
Thus, we addnew elements INDEX and LIST to the set F:(37) a. F = {LABEL, INDEX, LIST}b.
A = {a 1 .
.
.
.
.
am} tO {0, i, .
.
.
.
.
i,}C. 7" = {(LABEL, 0>, (INDEX, 0>, (LIST, I>}d. p -- {(LABEL, {a I .
.
.
.
.
am}), (INDEX, {0, i I .
.
.
.
.i,}>}A list of indices of the form (38a) is represented as (38b).
(38) a.
\[J0, Jl .
.
.
.
.
J Jb.
{(LIST, {<INDEX,jo> , (LIST, {<INDEX,jl) , (LIST .
.
.
.
{(INDEX, Jk), (LIST, {(INDEX, 0>})} .
.
.>}In addition, we need the following constraints:(39) a. LABEL /% LISTb.
\[\] --1 (LABEL /~ INDEX)C. \ [ \ ]  --I (LIST: --I INDEX)d. \[\] --I (LIST /~ INDEX:0)The first requires that at the top level, an indexedcategory has a label and a list of indices.
The seconddisallows INDEX from co-occurring with LABEL, enforcingthe constraint recursively downward.
The third requiresthat if LIST is defined anywhere, then INDEX is defined inits value.
And the last, also enforced recursively down-ward, requires that if INDEX has the value 0, LIST is notdefined (so the end of the list of indices is unambig-uously flagged by INDEX having the value 0).
A categorybearing an "empty"  list of indices is thus one whosevalue for LIST is {(INDEX, 0)}.
An example of a categoryallowed by these constraints is shown in (40).defined, since the distinction between atomic indicesand indices taken from a finite set of categories has nolanguage-theoretic implications.Given the representability of list-valued features ascategory-valued features in the present framework, thedefinitions of subsumption and unification automati-cally apply to lists without he need for any redefinition.If the empty category is used as the end marker for liststhen two lists of different lengths will unify if one is aprefix of the other.
Depending upon the linguistic inter-pretation of lists, this may or may not be what onewants.
In our illustration, we use an atomic end markerthat will block prefix unification.4 COMPUTATIONAL COMPLEXITY OF CATEGORYCHECKING 4The checking problem for categories is the problem ofdetermining whether a category is legal given a fixed setof constraints, or more precisely, of determining for anarbitrary category oz and a fixed formula 4' of L cwhether o~ satisfies 4'.
It is a special case of the problemof determining whether some arbitrary model satisfiessome fixed formula of a logic.Theorem.
The checking problem for categories is solv-able in linear time.Proof.
Assuming a category structure E = <F, A, ~-, p),we represent a category in K as a partially labelled,unordered tree with all nodes except the root labelledfrom F tO A, all nodes labelled from A being terminals.The category  corresponds to a single unlabelled node;</, a) for f E F ?
and a E A corresponds to a nodelabel ledfwith daughter labelled a; and (\[, {~q .
.
.
.
.
o-k}>for f E F ~ and n - 0 corresponds to a node labelled fwith the first elements of oq through o- k as its daugh-(40) I LAB ?
I D II LIS  I __li  xlal L IST  ~" I  li rs:Xl:!LIST l 0 IIndexed grammar as originally formalized by Ahouses lists of atomic indices as part of the composition ofcategories.
It is also possible in the framework we havedefined to allow features to have lists of categories astheir values.
This is in fact proposed in the literature byShieber (1984) and Pollard (1985).
To extend an indexedgrammar to permit GKPS-s ty le  categories in place ofatomic indices, one can simply make INDEX a type 1feature, add the GKPS category structure and con-straints to the indexed grammar category structure andconstraints, and then exempt LIST (but, crucially, notINDEX) from being subject to the constraint schema in(25).
The resultant ype of grammar, assuming that thelimitations on rules in indexed grammars are main-tained, is equivalent o indexed grammar as originallyLeT(s).
Let T be such a tree, and let 4' be a fixed formulaof L c. We check T for satisfaction of 4' by annotatingeach node of T with the complete list of all subexpres-sions of 4', and working from the frontier to the rootrecording at each node which subexpressions are satis-fied by the subtree rooted there.
At each point thechecking is local: only the current node and its daugh-ters (if any) need be examined.
Even for a subformulalike \[-q?, all that must be verified at a node q as we workup the tree is that q, is satisfied at q and 7q?
is recordedas satisfied at each daughter node.
The conclusion ofthe procedure will be to determine whether or not 4'itself is true at the root of T, and thus whether T iswell-formed.
If 4' has s subformul~e and T has n nodes,the time taken is bounded by sn (the number of steps12 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category Structuresrequired if every subformula is evaluated at everynode), and thus linear in n, the size of the input.
?Of somewhat less interest than the checking problemis the universal checking problem, that of determiningfor an arbitrary input pair (tk, a), ~b a formula and a acategory, whether a satisfies 4).
The difference is thathere ~b is not held constant; he task is analogous not tochecking the legality of a category within a selectedgrammatical framework, but rather to a kind of frame-work-design oversight role, switching frameworks withevery input and evaluating the given category relative tothe proffered constraint.
We note, however, that theuniversal checking problem only calls for, at worst,quadratic time.
To see this, simply note that we can usethe algorithm sketched above, and take account of s aswell as n as part of the size of the input.
The worst caseis where s and n contribute about equally to the size ofthe product sn, i.e., where s -~ n. Then sn -~ ((s + n)/2) 2= (s + n)2/4, which varies with the square of the inputsize s + n.For some special cases, both the checking problemand the universal checking problem are of course mucheasier.
For example, if only type 0 features are permit-ted, checking is decidable in real time by a simpleinspection of the finite number of (f, a) pairs, regardlessof whether ~b is part of the input or not.Note that the much harder satisfiability problem, thatof determining for an arbitrary formula ~b whether thereexists a category a that satisfies it, is of even lessinterest in the present context.
When a grammaticalframework intended for practical use is devised, theconstraints on its category system are formulated todelimit a particular set of categories already well under-stood and exemplified.
There is no practical interest inquestions about arbitrary formulae of L c for which noone has ever considered what a satisfying categorywould be like.We would expect he satisfiability problem for Lc tobe PSPACE-complete, like the satisfiability problem formost modal logics.
Ristad (1986, p. 33-4) proves aPSPACE-hardness result for what he calls "GPSGCategory-Membership", specifically with respect to theGKPS framework, and this can immediately be seen tobe extendable to the satisfiability result for L c (asmentioned in footnote 3, L c is in effect a language forthe statement of feature cooccurrence r strictions, andcan be used in the same way that Ristad uses the GKPSFCR formalism).
The problem he considers, despite themisleading name he gives it, is the analog of satisfiabil-ity, not of checking; it asks whether there exists anextension of a given category that satisfies agiven set ofFCRs, and since the given category might be O, this isequivalent to satisfiability.
Satisfiability is NP-completeeven for simple propositional logic, so as soon as it isappreciated that a language for stating constraints oncategories is in effect a logic with categories as itsmodels, the complexity of satisfiability for categoryconstraints comes as no surprise.
Checking of GKPScategories, on the other hand, which Ristad does notconsider, can be done very fast, as a corollary of thetheorem above.5 SETS AS VALUESAll the syntactic approaches that we have considered sofar distinguish syntactic ategories from structural de-scription of expressions in a fairly transparent fashion.In FUG Kay (1979, 1985), LFG Kaplan and Bresnan(1982), and work by Shieber and others on PATR IIShieber (1984), this traditional distinction disappearsalmost entirely.
Thus, in LFG, syntactic ategories andthe structural descriptions known as f-structures areexactly the same kind of object.
In FUG, not only isthere no formal distinction between categories andstructural descriptions, but even the distinction be-tween structural descriptions and grammars disappears.At first sight, LFG f-structures eem likely to be thetrivial case of a set of categories observing no con-straints on admissibility at all.
We simply take F to bethe LFG set of f-structure attribute names, and A to bethe LFG set of atomic f-structure values (the "simplesymbols" and "semantic forms").
So, following thisreasoning, the set of LFG f-structures would be just K,modulo the appropriate yping.
However, this is not thecase, for reasons that will emerge below.The first problem we consider is that at least two ofthe frameworks just mentioned permit sets as featurevalues.
In one sense we already permit sets as valuessince type 1 features have categories as their values,and categories are sets.
Categories are a rather specialkind of set, however, namely partial function fromfeatures to values.
Suppose we merely wanted to havea model for a set of atoms.
Then, as we saw in ourdiscussion of APG, we can model such a set by con-structing the set's characteristic function.
But modellinga set that way, whilst perfectly adequate for APGcategories, has a consequence that may not always beacceptable: two sets on the same domain will unify justin case they are exactly the same set.
Given certainquite natural interpretations of a feature system makinguse of sets, this may not be what we want.An alternative strategy then, and one which is alsoconsistent with our framework, is to model sets aspartial functions into a single value range (as opposed tototal functions into a two value range).
For example, thesubset of the authors of this paper with British ad-dresses could be represented asa partial function on thedomain {Gazdar, Pullum, Carpenter, Klein, Hukari,Levine}, namely the function {(Carpenter, 1), (Gazdar,1), (Klein, 1),} instead of the following total (character-istic) function on the same domain: {(Carpenter, 1),(Gazdar, 1), (Hukari, 0), (Klein, 1), (Levine, 0),(Pullum, 0)}.
Then unification of the partial functionsamounts to union of the corresponding sets.This is fine if our intended interpretation f the set isComputational Linguistics, Volume 14, Number 1, Winter 1988 13fGerald Gazdar et al Category Structuresconjunctive, i.e., if {a, b, c} means that a holds and bholds and c holds (Carpenter has a British address andKlein has a British address and Gazdar has a Britishaddress).
But if our intended interpretation is disjunc-tive, then we want the unification operation to give usintersection, ot union.
FUG actually uses set-valuedattributes with a disjunctive interpretation Kay (1979).And, in a discussion of possible enhancements to thePATR II formalism, Karttunen (1984) provides a num-ber of very relevant examples that illustrate the issuesthat arise when a unification-based formalism is aug-mented in order to encompass disjunction.As Chris Barker has pointed out to us, a perversevariant of the approach to conjunctively interpreted setsoutlined above serves to handle the disjunctive inter-pretation of sets of atoms.
We map the set {Accusative,Dative} into the partial function {(NOMINATIVE, 0>,(ABLATIVE, 0}, (GENITIVE, 0)} on the domain {ACCUSATIVE,DATIVE, NOMINATIVE, ABLATIVE, GENITIVE}.
NOW unifica-tion (and hence union) of such complement-specifyingpartial functions gives us an operation equivalent tointersection applied to the original sets.
Thus the unifi-cation of {(NOMINATIVE, 0), (ABLATIVE, 0), (GENITIVE, 0>}(standing for {Accusative, Dative}) with {(NOMINATIVE,0), (ACCUSATIVE, 0), (GENITIVE, 0)} (standing for{Ablative, Dative}) gives us {(NOMINATIVE, 0>, (ABLATIVE,0), (GENITIVE, 0), (ACCUSATIVE, 0>} which stands for{Dative}.Clearly, the present approach could be generalized todirectly allow a type of feature that would take sets ofatoms as values.
The price to be paid for this, in ametatheoretical exercise such as the one we are engagedin, would be that the definition of unification becomesdependent on the intended interpretation of such fea-tures: the relevant clause needs to use union if theinterpretation is conjunction, and intersection if theinterpretation is disjunction.An altogether more serious issue arises when weconsider the possibility of attributes taking sets ofcategories as values.
We could represent such sets in amanner analogous to the treatment of lists, but with aspecial marking (given in terms of special attribute-value pairs) indicating that the list representation iquestion is to be interpreted as a set.
The trouble withthis is that the identity conditions for the resultingobjects are no longer transparent.
Two structurallydistinct lists may or may not count as identical, depend-ing on whether or not they are both representing sets,and that in turn will depend on whether particularattributes appear in certain relevant structural posi-tions.
Likewise, our existing definitions of unificationand subsumption would simply fail to provide one withintuitively reasonable results, and its seems unlikelythat they could be made to do so without further formalcontortions.
This whole strategy seems contrived andinelegant.The alternative is, again, to introduce a new type offeature, one taking sets of categories as its values, andsome recent works have done just this.
Sabimana (1986)proposes afeature ARG which takes a set of categories asits value.
The feature appears on elements that corre-spond semantically topredicates, and its value is the setcontaining the categories that correspond semanticallyto the arguments ofthat predicate.
The Japanese PhraseStructure Grammar (JPSG) of Gunji (in press) goesfurther in that it restricts itself entirely to such features(together with atom-valued features, of course) anddoes not employ simple category-valued features at all.Both FUG and LFG also permit category-set values,in effect, though the interpretation they assign to theresulting objects is, once again, different.
FUG's inter-pretation is, as with atom sets, disjunctive.
On thisinterpretation, unification of two sets of categories canbe defined as the set of categories each of whosemembers is the unification of a pair in their Cartesianproduct (again, see Karttunen (1984) for relevant dis-cussion of this kind of approach).
In LFG, sets ofcategories acting as values for single attributes are usedin the analysis of adjuncts (and possibly coordination)and the interpretation is intendedly conjunctive Kaplanand Bresnan (1982).
Under this interpretation, there is,in general, no unique unification to be had, although onecan define an operation to provide one with a set ofpossible unifications.
In Gunji (in press), where a con-junctive interpretation is assigned to category-set val-ues, the non-uniqueness problem is sidestepped bydefining unify as a predicate of category pairs, ratherthan as an operation.In view of all these considerations, we have opted forsimplicity over generality and simply excluded set val-ued features from our purview.6 SHARED VALUESOne property that FUG and PATR II have in common,which sets them apart from the simpler grammar typediscussed earlier in this paper, is the option of lettingtwo or more distinct features hare the same value.Thus, FUG functional descriptions allow one instanceof a value to simultaneously bethe value of more thanone (instance of an) attribute.
Consequently, the im-plicit hierarchy, represented graphically, does not re-spect the single-mother requirement that is built deepinto our definitions.
Of course, two category-valuedfeatures within a category may contingently have iden-tical values, but this is not the same as sharing the samevalue (except in common parlance, perhaps).
Kasperand Rounds (1986) refer to the distinction as one of typeidentity versus token identity.
If we take a category,containing two contingently identical category-values,and unify it with a second category, then the contingentidentity may not be preserved in the result.
Consider,for example, the result of unifying these two categories:14 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category Structureswhere the values of F and H are identical in the first butnot in the second.
The result is:d eand here the values of ~" and H are no longer identical.
Ifthe original common value had been genuinely shared,then no unification would have been possible (see alsoShieber (1985) where the term "reentrancy" is used inthis connection).There is an alternative way of thinking about theproblem of shared values, and that is to reconstruct it interms of indexing: every value carries an index, and twostructurally identical values are the very same thing ifand only if they bear the same index.
An integerindexing of this sort can be represented in the presentframework as we have already see in section 4.5 above.However, a coindexing reconstruction would not be asensible way of thinking about shared values in thepresent context since such a use of indices makesnonsense of structurally defined unification, subsump-tion, and so on.
For two intuitively identical structuresto unify, it would not be sufficient for them to exhibitthe same internal patterns of coindexed values.
Rather,they would need in addition to manifest the very samechoice of indices.
Clearly, this is not what one wants, aschoice of index is completely arbitrary, and structuresdiffering only in identity of the integers selected asindices should be regarded as equivalent.To achieve a semantics for shared-value categoryformalisms, it is necessary to move beyond the partialfunction-based category structures that provide thebasis for our semantics, and thus depart from theparticular category constraint logic that it induces.
Likeset values, shared values are simply beyond the scopeof the rather parsimonious theory of categories devel-oped here.
5 The reader interested in pursuing richerapproaches should consult Pereira and Shieber (1984)for a domain-theoretic a count of the semantics ofcategories in LFG, PATR II, and GPSG; Ait-Kaci andNasr (1986), who capture shared values with a corefer-ence relation on the nodes of the tree; Kasper andRounds (1986), Moshier and Rounds (1987), and Roundsand Kasper (1986) for a finite state automaton-basedlogic and semantics for categories inFUG and PATR II;and van Benthem (1986a, b) for an interesting founda-tional discussion and application of such an automaton-based semantics.7 CONCLUSIONWe have developed and applied a general framework fordefining syntactic ategories, including categories inwhich features can have categories as their value, whichlatter possibility turns out to subsume the possibility ofa feature taking as its value a list of indices or catego-ries, drawn from either a finite or an infinite set.
Theunitary way in which we have characterized thesediverse systems is intended to assist in the explorationand comparison of grammatical formalisms.
Questionsconcerning whether particular rule types and operationson categories that are familiar from one approach togrammar can be carried over unproblematically to an-other approach, and questions concerning the imple-mentation difficulties that arise when a given formalismis adopted, can in many cases be settled in a straight-forward and familiar way, namely by reducing them topreviously encountered types of question.The grammatical frameworks we have considered asexamples fall into a five-class typology which we cannow explicate.
The first class contains the frameworksthat use only atom-valued features (simple phrase struc-ture grammar, Harman's augmented phrase structuregrammar; RG and APG); the second contains the spe-cial case of GKPS,  which uses category-valued featuresbut imposes a constraint which prevents them fromhaving effects on expressive power that could notultimately by simulated by atom-valued features; thethird contains the frameworks that use just a singlecategory-valued f ature (our key example being indexedgrammar); the fourth contains frameworks making useof more than one category-valued feature (an examplebeing categorial grammar); and the fifth includes thoseframeworks that fall outside the scheme we have devel-oped in that their categories are not representable asfinite partial functions constrained by statements in L c(LFG, FUG, PATR II, etc.
).It is not at all clear which of these five classes ofapproaches will prove the most suitable for implement-ing natural language processing systems in the longterm.
In this paper, we hope to have made somewhatclearer the nature of the issues at stake.
We hope also tohave done something more: for the first four classes, wehave provided what is in effect a unitary type of datastructure for the representation f their syntactic ate-gories.
Thinking in terms of such data structures shouldmake it possible for pseudo-issues in natural anguageprocessing research to be avoided in a large class ofcircumstances, to the point that even a decision inmid-project to change the grammatical framework fromone linguistic approach to another need not entail anyfundamental redesign of what are in most frameworksthe basic objects of syntactic representation.APPENDIXIn this appendix we restate the semantic rules for L cmore precisely.
All well-formed expressions of L c haveComputational Linguistics, Volume 14, Number 1, Winter 1988 15Gerald Gazdar et aL Category Structuresthe same kind of denotat ion~they denote truth values(i.e., members of 2) relative to the category structureand a category a determined by E. If 05 is a well-formedexpression of L o then we use f105flx,~ to stand for thedenotation of 05 with respect o the category structureand category a.
If  005(\]z~,, ~ = 1 then we shall say that t~SATISFIES 05.
The formal statement of our semantic rulesis the following, where a, f, 05, and q~ are as above.
(AI) a.
0fl~.~ = 1 iff s0') is defined.b.
Of:aD~,,~ = 1 iff a(J) = a.c. Uf:05fl~.~ = 1 iff 0050~.,~0~ = I.d.
D~050~.~ = 1 iff 0050~.~ = 0.e.
005 V q~.~ = 1 iff D05D~,~ = 1 or 0q~:,,~ = 1.f.
005 A ~, ,~ = 1 iff 005~,,~ = 1 and 0q~,,~ = 1.g.
005 ---* q~,,~ = 1 iff 005~,,~ = 0 or 0q~x,,~ = 1.h.
105 <-> ~1:~,~ = 1 iff 1050:~,~ = lqA~,~.i.
1\[\]051~,~ = 1 iff 1051:~,~ = 1 and for all f in  F ~ n~(a),lD051:,,,~00 = 1.j.
I 0 051:, ~ = 1 iff 1051:, ~ = 1 or for some f in  F ~ n~(a),l ~ 4>0:~,=00 = 1.Note that if a ~_ fl and a satisfies 05, it does ~0T followin L c that 3 satisfies 05 (compare Rounds and Kasper(1986), Theorem 6).
For example, we have ~ ~_ {(F, a)}and ~ satisfies --1 F, but {(F, a)} does not.
Likewise, thefact that both a and/3 satisfy some constraint 05 does notentail that a U/3 will satisfy 05, even if a IA/3 is defined.The desire to incorporate negation whilst maintaining anupward closure property lead Moshier and Rounds(1987) to set aside a classical semantics for their featuredescription language and postulate an intuitionistic semantics that, in effect, quantifies over possible exten-sions.We will write ~ 05 to mean that for every categorystructure \]i and category a in 11, a satisfies 05.
Giventhis, we can list some valid formula: and valid formulaschemata of the logic of category constraints.
(A2) a.
~a)  --> f (for all a E p(\]), f E F ?
)This simply says that if a feature has an atomic value,then it has a value.
We also have all the valid formula:of the standard propositional calculus, which we willnot list here.
Furthermore, we have the following famil-iar valid modal formula:.
(A2) b.
~1-\]05 ~- -10  7 05c.
~(05- - - ,  05)d. ~05 ~ 05e.
~05~ <)05f.
PD(05 A q,) ~ (05 A \[\]q,)g. t=~(05V ~b),~-~(O05V O~b)h. ~D05 ~ ?DO5Here, (A2h) shows us that our logic at least contains $4(we follow the nomenclature of Hughes and Cresswell(1968) throughout).
But we do not have ~ <> 05--~ \[\] 0 05,and so our logic does not contain $5.
To see this,consider the following category, assuming F is a cate-gory-valued feature: {(F, O)}.
This category satisfies 0 Fbut not \[ \]  OF.The category {(F, {(G, a)}), (H, {(G, b)})} (graphicallyrepresented in (50), below) provides us with an analo-gous falsifying instance for ~ O 1-105 ~ \[\]  O 05 when weset 05 = (~:a).This shows that our logic does not contain $4.2.
Inter-estingly, the converse of this constraint zs valid, hence:(A2) i.
~F-1005---~ OD05This is easy to demonstrate: if o~ satisfies \[ \]  O 05 then 0 05must hold in all the categories that terminate a, and ifO 05 holds in those categories, then 4, and I-\]05 hold inthem as well.
So r-\]05 holds in at least one category in o~,and thus a must satisfy O D05.
This shows that our logicat least contains K1 and, as a consequence, is notcontained by SS.However, our logic cannot contain K2, since thelatter contains S4.2.
Nor does it contain K1.2 since thelatter's characteristic axiom, namely ~ 05 ~ 1-1( O 05 ~ 05)is shown to be invalid by the category {(G, a), (F, {(G, b),(F, {(G, a)})})} (shown in (51), below) when set set 05 = (c:a).IIn fact, our logic does not merely contain K1, it alsocontains KI.1, whose characteristic axiom is:(A2) j.
~Fq(D(05 --> D05) ---> 05) -o 05)Hughes and Cresswell note that KI.1 'is characterizedby the class of all finite partial orderings, i.e., finiteframes in which R \[the accessibility relation\] is reflex-ive, transitive, and antisymmetrical' Hughes and Cress-well ((1984), p. 162).
So it should be no surprise, giventhe basis for our semantics, that our logic turns out toinclude KI.1.
This logic, also known as S4Grz (afterGrzegorczyk (1967)), 'is decidable, for every nontheo-rem of S4Grz is invalid in some finite weak partialordering' (Boolos (1979, p. 167).Two further valid formula schemata of Lc have someinterest, before we conclude the list of valid formula: in(A2):(A2) k. ~0 -Tf  (for a l l fE  F I)1.
~(f.'05)--> 005 ( fo ra l l fEF  1)The first of these follows from the fact that categoriesare finite in size and thus ultimately grounded in cate-gories that contain no category-valued features: f mustbe false of these terminating embedded categories, andhence O --1 f must be true of the category as a whole.16 Computational Linguistics, Volume 14, Number 1, Winter 1988Gerald Gazdar et al Category StructuresThe second states that if a category is defined for acategory-valued feature whose value satisfies 4,, thenthe category as a whole satisfies O 4'.
(A2) m. ~(f:th) ---~f (for a l l fE  F I)n. ~( ( f :4 , )A( f :~) )~t f .
'4 ,A0)  ( fo ra l l fEF  ~)o. P((i2~b)V~q0)~--~(f:thVq0 ( fo ra l l fEF  l)It is worth considering the valid formulae one wouldget in certain restricted classes of category structures.Suppose we consider category structures which containonly atom-valued features (i.e., F = F?).
In this case, asone would expect, the modal logic collapses into thepropositional calculus and the relevant notion of valid-ity (call it Po) gives us the following:(A5) moth ,o ruthThe converse case, where we only permit category-valued features (i.e.
F = F1), is uninteresting, since it isnot distinct from the general case.
We can alwaysencode atom-valued features as (sets of) category-valued features and subject the latter to appropriateconstraints, as follows.
For every feature specification(f, a) such that fE  F ?
and a E p(f), we introduce a newtype 1 feature fa  and use the presence of 0Ca, 0 )  toencode the presence of (f, a) and likewise absence toencode absence.
Then, for each pair of atoms a and b inp(f), we require the new features to satisfy \[\] -7 (fa Afb).
And to constrain each new feature fa  to have theempty set as its value, we stipulate \[\] -7 (fa:g) for everyfeature g.However, consider validity in category structurescontaining at most one category-valued feature (call thiskind of validity ~ 1)- With this restriction, the $4.2 axiomconsidered earlier becomes valid:(A6) ~10\[N~b--~ \ [ \ ]O4,In addition, we get (A7).
(A7) ~ ~\[\](\[\]t h ~ \[-\]~) V \[-l(f--\]q~--~ \[ th)This means that this restricted logic at least containsK3, but it cannot contain K4, since ~1~)~ (0\[~(~ "-->D~b) is falsified by the category {(G, a), (~" {(G, b), (~', {(G,a)})})} when we set ~b = (G: a).In fact it must also contain K3.1, in view of the validityof (A2j) above, and this logic, also known as S4.3Grz, ischaracterized by finite linear orderings Hughes andCresswell (1984).
This is the characterization we wouldexpect given the character of the ~1 restriction on theform of permissible categories, since with only onecategory-valued feature, there is at most one paththrough the structure of a category and so the partialorder becomes a linear order.
These observations con-cerning the logic induced by category structures whereIFll = 1 are of some potential relevance to the study ofindexed grammars whose categories can be- construedas being restricted in just this way (see section 4.9,above).ACKNOWLEDGMENTSChris Barker has contributed substantively to the re-search reported here, and we offer him our gratitude.We are also grateful to Edward Briscoe, Jeremy Carroll,Roger Evans, Joseph Halpern, David J. Israel, RonaldM.
Kaplan, William Keller, James Kilbury, William A.Ladusaw, Christopher Mellish, Richard E. Otte, Fer-nando Pereira, P. Stanley Peters, Carl J. Pollard, Ste-phen Pulman, William Rounds, Stuart M. Shieber,Henry Thompson and Manfred Warmuth for their gen-erous assistance during the research reported in thispaper.
Though in some respects they have contributedsubstantially, they should not be associated with anyerrors that the paper may contain.
In addition, we thankCalvin J. Pullum, who is responsible for the diagrams,and we acknowledge partial research support from thefollowing sources: the UCSC Syntax Research Center(Gazdar, Hukari, Levine, Pullum); grants from the(U.K.) SERC and ESRC (Gazdar); NSF Graduate Fel-lowship RCD-8651747 (Carpenter); NSF grants BNS-8511687 and BNS-85 19708 (Pullum).REFERENCESAho, Alfred V. 1968 Indexed Grammars.
Journal of the Associationfor Computing Machinery 15: 647-671.Ait-Kaci, Hassan; and Nasr, Roger.
1986 Proceedings of the 13thAnnual ACM Conference on Principles of Programming Lan-guages: 219-228.
Association for Computing Machinery.Bach, Emmon.
1984 Some Generalizations of Categoilal Grammar.
InLandman, Fred; and Veltman, Frank, Eds., Varieties of FormalSemantics: Proceedings of the 4th Amsterdam Colloquium, Sep-tember 1982, Foils, Dordrecht, Holland: 1-23.van Benthem, Johan.
1986a Semantic Automata.
In Groenendijk,Joroen; de Jongh, Dick; and Stokhof, Martin, Eds., Information,Interpretation and Inference.
Foils, Dordrecht, Holland.
Re-printed in van Benthem, Johan.
1986 Essays in Logical Semantics.D.
Reidel, Dordrecht, Holland: 151-176.
\[Also published as CSLIReport 85-27, Center for the Study of Language and Information,Stanford, 1985\]van Benthem, Johan.
1986b Towards a Computational Semantics: InCooper, Robin; Engdahl, Elisabet; and Gardenfors, P., Eds.,Proceedings of a Workshop on Generalized Quantifiers, Lund1985.
D. Reidel, Dordrecht, Holland.van Benthem, Johan.
1986c Categoilal Grammar.
In Johan vanBenthem.
1986 Essays in Logical Semantics.
D. Reidel, Dor-drecht, Holland: 123-150.van Benthem, Johan; Buszkowski, W.; and Marciszewski, W., Eds.,Categorial Grammar.
John Benjamin, Amsterdam, Holland.Boolos, George.
1979 The Unprovability of Consistency.
CambridgeUniversity Press, Cambridge, England.Bresnan, Joan W. 1975 Transformations and Categories inSyntax.
InButts, Ronald; and Hintikka, Jaakko, Eds., Basic Problems inMethodology and Linguistics.
D. Reidel, Dordrecht, Holland:283-304.Chomsky, Noam.
1970 Remarks on Nominalization.
I  Jacobs, R.;and Rosenbaum, P., Eds., Readings in English TransformationalGrammar.
Ginn, Waltham, Massachusetts: 11-61.Computational Linguistics, Volume 14, Number I, Winter 1988 17Gerald Gazdar et al Category StructuresChomsky, Noam.
1980 On Binding.
Linguistic Inquiry 11: 1--46.Chomsky, Noam.
1981 Lectures on Government and Binding.
Dor-drecht: Foris.Elson, Benjamin; and Pickett, Velma.
1962 An Introduction to Mor-phology and Syntax.
Summer Institute of Linguistics, Santa Ana,California.Gazdar, Gerald.
1985 Applicability of Indexed Grammars to NaturalLanguages.
Center for the Study of Language and Information,Stanford, California: Report No.
CSLI-85-34.Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey K.; and Sag, Ivan A.1985 Generalized Phrase Structure Grammar.
Harvard UniversityPress, Cambridge, Massachusetts.Grzegorczyk, Andrzej.
1967 Some Relational Systems and the Asso-ciated Topological Spaces.
Fundamentae Mathematicae 60: 223-231.Haddock, Nicholas; Klein, Ewan; and Morrill, Glyn, Eds., 1987Categorial Grammar, Unification Grammar and Parsing.
Edin-burgh Working Papers in Cognitive Science 1, Edinburgh, Scot-land.Halliday, Michael A. K. 1961 Categories of the Theory of Grammar.Word 17:241-292.Halvorsen, Per-Kristian; and Ladusaw, William A.
1979 Montague's'Universal Grammar': an Introduction for the Linguist.
Linguis-tics and Philosophy 3: 185-223.Harman, Gilbert H. 1963 Generative Grammars without Transforma-tion Rules: a Defense of Phrase Structure.
Language 39: 597-616.Harris, Zellig S. 1951 Methods in Structural Linguistics.
University ofChicago Press, Chicago, Illinois.Hendriks, Herman.
1986 Foundations of GPSG Syntax.
Doctoraal-scriptie Wijsbegeerte, University of Amsterdam, Amsterdam,Holland.Hornstein, Norbert.
1977 S and X' Convention.
Linguistic Analysis 3:137-176.Hudson, Richard A.
1971 English Complex Sentences.
North Hol-land, Amsterdam, Holland.Hughes, G. E.; and Cresswell, Max J.
1968 An Introduction to ModalLogic.
Methuen, London, England.Hughes, G. E.; and Cresswell, Max J.
1984 A Companion to ModalLogic.
Methuen, London, England.Jackendoff, Ray.
1974 Introduction to the X Convention.
IndianaUniversity Linguistics Club, Bloomington, Indiana.Jackendoff, Ray.
1977 X Syntax: A Study of Phrase Structure.
MITPress, Cambridge, Massachusetts.Johnson, David E.; and Postal, Paul M. 1980 Arc Pair Grammar.Princeton University Press, Princeton, New Jersey.Kaplan, Ronald; and Bresnan, Joan.
1982 Lexical-Functional Gram-mar: a Formal System for Grammatical Representation.
In J. W.Bresnan, Ed., The Mental Representation of Grammatical Rela-tions.
MIT Press, Cambridge, Massachusetts: 173-281.Karttunen, Lauri.
1984 Features and Values.
Proceedings of the lOthInternational Conference on Computational Linguistics and the22nd Annual Meeting of the Association for Computational Lin-guistics.
Stanford University, California: 28-33.Karttunen, Lauri; and Zwicky, Arnold M. 1985 Introduction toDowty, D.R.
; Karttunen, L.; and Zwicky, A.M., Eds., NaturalLanguage Parsing.
Cambridge University Press, Cambridge, En-gland: 1-25.Kasper, Robert T.; and Rounds, William C. 1986 A Logical Semanticsfor Feature Structures.
In Proceedings of the 24th Annual Meetingof the Association for Computational Linguistics: 257-266.Kay, Martin.
1979 Functional Grammar.
In Chiarrello, Christine etal., Eds., Proceedings of the 5th Annual Meeting of the BerkeleyLinguistics Society: 142-158.Kay, Martin.
1985 Parsing in Functional Unification Grammar.
InDowty, D.R.
; Karttunen, L.; and Zwicky, A.M., Eds., NaturalLanguage Parsing.
Cambridge University Press, Cambridge, En-gland: 251-278.Ladusaw, William A.
1985 A Proposed Distinction Between Levelsand Strata.
Presented to the Annual Meeting of the LinguisticSociety of America, Seattle, Washington.
Memo no.
SRC-85-04,Syntax Research Center, University of California, Santa Cruz,California.Lasnik, Howard; and Kupin, Joseph J.
1977 A Restrictive Theory ofTransformational Grammar.
Theoretical Linguistics 4: 173-196.Levy, Leon S.; and Joshi, Aravind, K. 1978 Skeletal StructuralDescriptions.
Information and Control 39:192-211.Longacre, Robert E. 1965 Some Fundamental Insights of Tagmemics.Language 41:65-76.Mellish, Christopher.
1986 Implementing Systemic Classification byUnification.
Manuscript, University of Sussex.Montague, Richard.
1970 Universal Grammar.
In Thomason, Rich-mond H., Ed., Formal Philosophy.
Yale University Press, NewHaven, Connecticut: 222-246.Montague, Richard.
1973 The Proper Treatment of Quantification inOrdinary English.
In Thomason, Richmond H., Ed., FormalPhilosophy.
Yale University Press, New Haven, Connecticut:247-270.Moshier, M. D., and Rounds, William C. 1987 A Logic for PartiallySpecified Data Structures.
Proceedings of the ACM Conferenceon Principles of Programming Languages, Munich.Oehrle, Richard T.; Bach, Emmon; and Wheeler, Deirdre W., Eds.,1987 Categorial Grammars and Natural Language Structures, D.Reidel, Dordrecht, Holland.Patten, Terry; and Ritchie, Graeme.
1987 A Formal Model of Sys-temic Grammar.
In Kempen, Gerard, Ed., Natural LanguageGeneration: Recent Advances in AI, Psychology and Linguistics.Kluwer, Amsterdam, Holland.Pereira, Fernando C. N.; and Shieber, Stuart M. 1984 The Semanticsof Grammar Formalisms Seen as Computer Languages.
In Pro-ceedings of the lOth International Conference on ComputationalLinguistics and the 22nd Annual Meeting of the Association forComputational Linguistics: 123-129.Pereira, Fernando C. N.; and Warren, David H. D. 1980 DefiniteClause Grammars for Language Analysis--a Survey of the For-malism and a Comparison with Augmented Transition Networks.Artificial Intelligence 13: 231-278.Perlmutter, David M.; and Postal, Paul M. 1977 Toward a UniversalCharacterization of Passivization.
In Whistler, Kenneth et al,Eds., Proceedings of the 3rd Annual Meeting of the BerkeleyLinguistics Society 394--417.
Reprinted in: Perlmutter, David M.,Ed., Studies in Relational Grammar 1.
University of ChicagoPress, Chicago, Illinois.Pollard, Carl J.
1984 Generalized Phrase Structure Grammars, HeadGrammars, and Natural Languages.
Ph.D. dissertation, StanfordUniversity.Pollard, Carl.
1985 Phrase Structure Grammar Without Metarules.Goldberg, Jeffrey; MacKaye, Susannah; and Wescoat, Michael,Eds., Proceedings of the West Coast Conference on FormalLinguistics, Volume Four.
Stanford Linguistics Association, Stan-ford, California: 246-261.Postal, Paul M. 1964 Constituent Structure: A Study of ContemporaryModels of Syntactic Description.
Publication 30 of the IndianaUniversity Research Center in Anthropology, Folklore, and Lin-guistics, Bloomington, Indiana.Pullum, Geoffrey K. 1985 Assuming Some Version of X-Bar Theory.In Eilfort, William D.; Kroeber, Paul D.; Peterson, Karen L.,Eds., CLS 21, Part 1: Papers from the General Session at theTwenty-First Regional Meeting.
Chicago Linguistic Society, Chi-cago, Illinois: 323-353.Ristad, Eric Sven.
1986 Computational Complexity of Current GPSGTheory.
Proceedings of the 24th Annual Meeting of the Associa-tion for Computational Linguistics: 30-39.Rounds, William C.; and Kasper, Robert T. 1986 A Complete LogicalCalculus for Record Structures Representing Linguistic Informa-18 Computational Linguistics, Volume 14, Number I, Winter 1988Gerald Gazdar et al Category Structurestion.
Proceedings of the 15th Annual Symposium on Logic inComputer Science.
Cambridge, Massachusetts.Rouveret, Alain; and Vergnaud, Jean-Roger.
1980 Specifying Refer-ence to the Subject: French Causatives and Conditions on Repre-sentations.
Linguistic Inquiry 11: 97-202.Sabimana, Firmard.
1986 The Relational Structure of the KirundiVerb.
D.Phil.
dissertation, Indiana University, Bloomington, In-diana.Shieber, Stuart.
1984 The Design of a Computer Language forLinguistic Information.
In Proceedings of the lOth InternationalConference on Computational Linguistics and the 22nd AnnualMeeting of the Association for Computational Linguistics: 362-366.Shieber, Stuart.
1985 Criteria for Designing Computer Facilities forLinguistic Analysis.
Linguistics 23:189-211.Shieber, Stuart.
1987 Separating Linguistic Analyses from LinguisticTheories.
In Whitelock, Peter J. et ai., Eds., Linguistic Theory andComputer Applications.
Academic Press, London.Stockwell, Robert P.; Schacter, Paul; Partee, Barbara H. 1973 TheMajor Syntactic Structures of English.
Holt, Rinehart and Win-ston, New York, New York.Winograd, Terry.
1972 Understanding Natural Language.
AcademicPress, New York, New York.Winograd, Terry.
1983 Language as a Cognitive Process: Volume 1Syntax.
Addison-Wesley, Reading, Massachusetts.NOTES1.
Bresnan (1975) correctly attributes the \[-+N, -+V\] feature system tolectures delivered by Chomsky at the 1974 Linguistic Institute inAmherst, Massachusetts.
In some works, e.g., Jackendoff (1977)and Gazdar, Klein, Pullum, and Sag (1985), Chomsky (1970) iswrongly given as the source.
The latter work does, however,contain the following relevant comment: "we might just as welleliminate the distinction of feature and category, and regard allsymbols of the grammar as sets of features" (p. 208).2.
As Hendriks (1986) has noted, the definition of categories given inGKPS "is a bit of a mess from a formal point of view" (1986, p.19).
Definition 1 reads as follows: ,,po is a function from F toPOW(A) such that for a l l f~  (F-Atom), p?00 = {{}}" (GKPS, p.36).
But {{}} is not in the power set of A; "POW(A)" should bereplaced by "POW(A) O {{{}}}".
Parts of the text and examplesfollowing Definition l assume correctly that it ends ,,pO(f) = {{}},,,but other parts assume incorrectly that it ends ,,po(f) = {},,.
If thelatter version were adopted, Definition 4 would fail to addcategory-valued feature specifications in the desired way (sincethe condition "3C'  E ff'-~(t)\[C' C_ C\]" would never be satisfiedwheren = 1.
)3 The "feature cooccurrence restrictions" (FCRs) of GKPS formpart of the definition of admissible tree rather than being part of thedefinition of categories.
However, every GKPS FCR can beexpressed in L c, and the translation is trivial.4.
We are indebted to Joseph Haipern for his help with the materialin this section.5.
One of our referees has suggested that our semantics can be madeto handle sharing by introducing an equality predicate into L c,marking shared value situations with special nonce features, andthen using conditional constraints triggered by these features toimpose identical values on the relevant features.
But we havebeen unable to get any scheme of this kind to work in the generalcase.
There appears to be no upper bound to the number of noncefeatures that may be required, and moreover, unification ceasesto behave in an intuitively reasonable manner.Computational Linguistics, Volume 14, Number 1, Winter 1988 19
