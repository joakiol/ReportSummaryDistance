A MODEL OF SPEECH ACT PLANNER ADAPTED TO MULTIAGENT UNIVERSESDaniel Rousseau, Guy LapalmeDepartment of Computer Science and Operational ResearchUniversity of Montreal, Montreal, CanadaE-mail: roussead@iro.umontreal.ca, lap lme@iro.umontreal.caBernard MoulinDepartment of Computer ScienceLaval University, Quebec, CanadaE-mail: moulin@vm.ulaval.caA multiagent universe is characterized by many agents who cooperate (i.e.
share acommon goal) or compete (i.e.
have conflictual goals).
With cooperation, an agent may takeadvantage of other agent's abilities and increase her chance to reach her goals.
Butcompetition between agents decreases the opportunities to reach her own goals, because oneagent's action might interfere with the ones of the other agent.
So, it is very important tocooperate when it is possible and to negotiate when there are conflictual goals.Conversation is a form of cooperation by means of interrelated speech acts, also calledillocutionary or linguistic acts, between two or more agents.
Each speech act is not executedimmediately, but is planned by an agent in order to reach some goal in the conversationcontext.
In fact, a speech act is for an agent he best mean to transmit her mental states toother agents, to try to change their mental states and to affect their behavior in the samedirection that she wants.
A minimal evel of cooperation is necessary to achieve a coherentand satisfying conversation between all participants.
Before executing a speech act, an agentmust take into consideration many factors such as the context of utterance, including previousspeech acts of the current conversation and the participants' mental states, and shared rules ofcommunication such as Gnce's (1975) conversational maxims.
During a conversation, it isalso possible for an agent o execute non-linguistic speech acts.In this context, we propose a model of speech act planner to be used in a cooperativeresponses generation system.
The model can explain an agent's general behavior during aconversation i volving two agents or more.
It deals with the reasoning process between theperception of a situation and with the execution of a linguistic or non-linguistic action.
Itreasons about mental states belonging to herself or to other agents uch as goals, intentions,beliefs, low-level actions and plans containing linguistic and non-linguistic actions.
Itintegrates ideas from the following domains: intent ion in speech acts, structure ofconversation and planning.Some people (Searle and Vanderveken 1985, Cohen and Levesque 1990) have assumedthat the recognition of the speaker's intention and other mental states in producing an utteranceis extremely important to understand its meaning, but have limited their work on one singlespeech act.
Because a conversation is a temporal sequence of connected illocutionary acts110(Moulin, Rousseau and Vanderveken 1991) where each speech act plays a precise role in thecontext of other speech acts, some researchers have studied the structure of a conversation andthey all agreed that there are several interrelated components in it and many subconversationsof different types (Grosz and Sidner 1986, Litman and Allen 1987).
The planning approachhas been used by some scientists to produce speech acts in the context of a dialogue (Allen1983, Appelt 1985, Litman and Allen 1987, Lambert and Carberry 1992).Starting from the approaches mentioned above, the model of speech act planner wepropose takes into consideration the following problems: multiagent planning, reasoning onother agents' mental states and on one's own mental states, recognition of intentions behinddirect and indirect speech acts, use of plans integrating linguistic and non-linguistic actions,coherence of the conversation between two or more agents, handling of subeonversations andmodeling of the conversational context.We assume that a conversation is a task shared by many agents that is the result of"reactive distributed planning" A conversational participant cannot control all the content of aconversation, but adapts its behavior by reacting to what has just been said.
An agent hatcannot reach a goal without communicating with another agent initiates a conversation byexecuting a planned speech act.
In reaction to a speech act, at any time during a conversation,a participant must process it in many steps before executing an action, usually a speech act.
Itmust interprete it by recognizing the intention of the speaker and update its beliefs.
It mustrevise its goals, particularly when it must take turn according to the conversational state.
Inthis case, it has a new communication goal, like answenng a question or clarifying the lastspeech act, for which it constructs a plan to reach it.
This plan generally specify one or morespeech acts to execute.
The conversation is ended when there is no more reason to continue it,i.
e. when the goal for which it was initiated has been reached or cannot be reached anymore.We will illustrate the planning process during a conversation i  the context of amultiagent universe with the following example.
Four cooperative robots, that cancommunicate with another obot and execute a particular task, are in a working shop.
Onerobot can lift and move an object, including another robot, unless it weights too much.
In thatcase, two robots can join forces to lift and move it.
When there is a breakdown, a robot has togo to the repair station.Suppose that a robot, called Dartagnan, cannot move anymore.
So, Dartagnan must goto the repair station after taking an appointment, but it cannot move.
It has to ask anotherrobot for help to reach the repair station.
A sollicited robot that cannot lift and moveDartagnan will have to ask for help before declining assistance, unless it is already too busy.Taking an appointment and asking help take the form of speech acts in the context of aconversation.
For each conversation, there is a goal that an initiator conversational agent alesto satisfy.
For example, suppose that Dartagnan already has an appointment with the repairstation.
A conversation between Dartagnan and another robot, Portos, may look like this:Dartagnan: Portos, please carry me to the repair station by 10 o'clock.Portos: Sorry, I cannot help you.Dartagnan: OK, I will ask another robot to help me.111This quite simple conversation i volves a lot of problems to be solved by the twoconversational gents.
Before initiating the conversation, Dartagnan has to decide which robotto talk to.
Then, it has to choose what to say to initiate the conversation i order to allowPortos to recognize its intentions.
After receiving the request, Portos must recognizeDartagnan's intention and update its knowledge base.
Then, it has to decide if it can helpDartagnan or if not.
In the example, Portos is too busy.
Dartagnan, after receiving theresponse from Portos, must identify Portos' mental states and decide if it accepts this responseor if it proposes a compromise.
Here Dartagnan accepts the response and therefore nds theconversation.So, before and after each speech act, a lot of reasoning about mental states is necessaryfor all the conversational gents involved in a conversation.
The speech act planner wepropose tries to model all this necessary reasoning to get a conversation such as the above.We assume that we must take into account in our planner the general script of aconversation to generate coherent ones.
A conversation is an evolving object.
At a globallevel, each conversation follows the same conversational script that describes the possiblestates of a conversation and the possible transitions between them.
A transition is insured bythe application of a private plan by an agent.
According to DeVito (1992), there are fivepossible states for a conversation: opening, feedforward (the general goal of the conversationis given), business (the substance of the conversation), feedback (synthesis of the discussion)and closing.
Note that the feedback state is not always present in an instance of conversation.At these five basic states, we add two other ones, interruption and reopening, because weconsider the cases when a conversation is interrupted by an agent.
For instance, an agent mayinterrupt a conversation before answering a request.Each state can be considered as a conversational goal and be focalised into lower levelconversational states during the conversation.
These states may be different, depending of theconversation.
A question is asked or a promise is done are examples of states.
We cannotfind these states in any order to have a coherent conversation.
So, we assume that there aresome rules to respect when we are in some conversational state.
These rules precise thepossible and necessary transitions between conversational states, the agent hat is responsibleof the transitions and the conditions, expressed in terms of mental states, associated withthem.
For example, when a question has just been asked to an agent, it has to answer it if itknows the answer and has no reason to hide it.
If the question is not clear for it, it can initiatea clarification subdialogue by asking for some clarification.
But it was not very conventionalto give an order to the other agent at this time.
Therefore, a conversation is like a constructionmade of LEGO TM blocks, where you can put a block of a certain type at a few places only.Each conversation has global parameters that respond to the following questions: who?
(the conversational participants), why?
(the goal behind the conversation), when?
(the time),where?
(the place) and how?
(the type of the conversation).
The answer to the question 'what?
'is composed of the surface linguistic acts themselves and the corresponding speech acts.
Allthese information is part of the conversational context, like all the knowledge and mentalsstates of the conversational participants.
In fact, the conversational context contains all theinformation that is important for a speech act planner to participate to a conversation.112So the model of speech act planner we propose deals with two aspects of aconversation: its planning and its structure.
Up to now, we have established the globalframework of the theoretical model and tested it on dialogues like the one between Dartagnanand Portos.
In the future, we will describe in more detail the different steps of the planningprocess, the necessary data structures and the acceptable transitions between conversationalstates.
To handle conversations involving more than two agents, we expect o reduce them tomany partially ordered ialogues (conversations between two agents only), where one agentparticipating to the conversation is conscious of all the dialogues.
Finally, we will test ourmodel by integrating it in a prototype that will simulate the behavior of many agents that willparticipate to a conversation i a given situation by producing speech acts from their mentalstates and their knowledge.REFERENCESALLEN J. F. (1983), "Recognizing Intentions from Natural Language Utterances", in M.Bradie ad R. C. Berwick editors, Computational Models of Discourse, MIT Press, Cambridge,Massachusetts, chap.
2 pp.
108-166.APPELT D. E. (1985), "Planning English Sentences", Cambridge University Press,Cambridge, Great Britain.COHEN P. R., LEVESQUE H. J.
(1990), "Rational Interaction as the Basis forComuunication", in P. R. Cohen, J. Morgan and M. E. Pollack editors, Intentions inCommunication, MIT Press, Cambridge, Massachustetts, Chap.
12, pp.
221-255.DEVITO J.
A.
(1992), "The Interpersonal Book", Sixth edition, HarperCollins Publishers,New York.GRICE H. P. (1975), "Logic and Conversation", in P. Cole and J. L. Morgan editors, "Syntaxand Semantics, vol.
III: Speech Acts", Academic Press, New York, pp.
41-58.GROSZ B. J., SIDNER C. L. (1986), "Attention, Intentions and the Structure of Discourse", inComputational Linguistics, Vol.
12, No 3, July-September 1986, pp.
175-204.LAMBERT L., CARBERRY S. (1992), "Modeling Negotiation Subdialogues", inProceedings of the Conference of the 30th Annual Meeting of the Association forComputational Linguistics, Newark, Delaware, pp.
193-200, June 1992.LITMAN D. J., ALLEN J. F. (1987), "A Plan Recognition Model for Subdialogues inConversations", in Cognitive Science, Vol.
11, pp.
163-200.MOULIN B., ROUSSEAU D., VANDERVEKEN D. (1991), "Speech Acts in a ConnectedDiscourse: A Computational Representation Based on Conceptual Graph Theory", inProceedings of the Sixth Annual Workshop on Conceptual Graphs, July 1991, Binghamton,New York, pp.
269-282.SEARLE J. R., VANDERVEKEN D. (1985), "Foundations of Illocutionary Logic",Cambridge University Press, Cambridge, Great Britain.113
