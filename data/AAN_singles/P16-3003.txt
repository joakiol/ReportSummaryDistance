Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ?
Student Research Workshop, pages 15?21,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsIdentifying Potential Adverse Drug Events in Tweets Using BootstrappedLexiconsEric BenzschawelBrandeis Universityericbenz@brandeis.eduAbstractAdverse drug events (ADEs) are medicalcomplications co-occurring with a periodof drug usage.
Identification of ADEsis a primary way of evaluating availablequality of care.
As more social mediausers begin discussing their drug experi-ences online, public data becomes avail-able for researchers to expand existingelectronic ADE reporting systems, thoughnon-standard language inhibits ease ofanalysis.
In this study, portions of a newcorpus of approximately 160,000 tweetswere used to create a lexicon-driven ADEdetection system using semi-supervised,pattern-based bootstrapping.
This methodwas able to identify misspellings, slangterms, and other non-standard languagefeatures of social media data to drive acompetitive ADE detection system.1 BackgroundPharmacovigilance is tasked with detecting, as-sessing, understanding, and preventing adverseeffects or other drug-related medical problems(Organization, 2002).
Adverse effects in post-approval drugs constitute a major public healthissue, representing the fourth leading cause ofdeath in the United States and an overall treat-ment cost higher than those of cardiovascularand diabetes care combined (Chee et al, 2011).In the United States alone, over 700,000 yearlyhospital admissions?between 2 and 5% of totaladmissions?result from moderate to severe ad-verse effects (Honigman et al, 2001), underscor-ing the need to identify and prevent these seriousmedical complications.Adverse effects from drug usage are bro-ken down further into two categories?adversedrug events (ADEs) and adverse drug reactions(ADRs).
ADRs are a subset of ADEs, wherecausality between a drug treatment program andnegative medical reaction has been establishedsuch that the negative reactions occur in withinstandard dosages (Organization, 1972).
ADEsmore loosely define any overlapping period ofdrug treatment and adverse medical effects.
Im-portantly, ADEs do not imply causation betweenthe drug use and co-occurring negative event(Eriksson et al, 2013).
Timely, accurate identifi-cation of these medical complications therefore fa-cilitates improvements in patient health and helpsdecrease both manpower and monetary costs to ahealthcare system and is considered a key qualityof medical care (Honigman et al, 2001).Existing systems of ADE documentation typi-cally rely on automatic reporting systems hostedby national or international public health organi-zations, electronic health records, or data fromother high-quality resources.
Social media wasan untapped resource until recently, despite evi-dence that suggests nearly 31% of patients suffer-ing from chronic illness and 38% of medical care-givers consult drug reviews posted online to vari-ous social media sites (Harpaz et al, 2014).Twitter has recently been used as an ADRdetection resource in numerous research studieswithin the last five years, with methodologiesranging from lexicon matching to supervised ma-chine learning (Sarker et al, 2015).
Tweets can beused to supplement existing electronic ADE/ADRmonitoring systems by providing real-world, real-time clinical narratives from users posted in thepublic domain.
Because many electronic monitor-ing systems underreport the prevalence of minorADEs/ADRs, typically due to their absence frommedical records and clinical studies (Eriksson etal., 2013), Twitter presents a valuable resource forproviding data on a wide range of negative medi-15cal events.Social media data presents unique challengesto clinical NLP studies in ways analogous toelectronic medical records?non-standard syntax,jargon, and misspellings handicap many exist-ing NLP systems (Eriksson et al, 2013).
Han-dling these areas of non-standard language usagecomplicates lexicon-based attempts at retrievingTweets containing potential ADEs/ADRs.
Manyrecently published systems handle this by map-ping annotated ADEs/ADRs to entries in med-ical ontologies (Sarker et al, 2015).
Annota-tion is a time-consuming process and limits thesize of training data sets.
Many problems withnon-standard language usage can be addressedwith semi-supervised, pattern-based bootstrappingwhich, after sufficient analysis, yields high-qualitylexicons with competitive ADE/ADR detectioncapabilities.2 DataThe largest existing publicly available dataset forthis domain is Arizona State University?s DIEGOLab data, containing over 7,500 tweets annotatedfor presence or absence of an ADR (Ginn et al,2014; Nikfarjam et al, 2015).
Roughly 2,000 ofthe tweets contain annotated ADR relations.
Thisdata set has been used in both machine learningand lexicon-based approaches to ADR detectionin social media (O?Connor et al, 2014).In order to take advantage of semi-supervisedlearning methods and real-time data, Twitter-Drugs, a new corpus of 166,551 tweets, was gener-ated from public tweets mined from mid-Januaryto mid-February 2016 using 334 different drugs.Drugs were compiled from those used in theDIEGO data and supplemented with the New YorkState Department of Health?s 150 Most FrequentlyPrescribed Drugs1, and those listed in Chemicaland Engineering News?
Top 50 Drugs of 20142.After collecting approximately 700K query re-sults, each tweet was heuristically screened forrelevance.
Tweets were considered irrelevant ifthey contained an external URL, any of a setof 16 salesmanship terms such as promo or freeshipping, and whether the tweet text itself con-tained the queried drug string.
Screening removedroughly 76.1% of mined tweets.
The corpus is1apps.health.ny.gov/pdpw/DrugInfo/DrugInfo.action2CEN-supplement092014.pdfFigure 1: Riloff and Jones (1999)?s meta-bootstrapping algorithmavailable online3for future use or expansion andrepresents the largest available data set for Twitter-based clinical NLP tasks.3 MethodologyIdentifying potential ADEs required extractionof both drug mentions and negative medicalevents, for instance oxycontin and made medizzy.
Novel mentions were identified using aset of extraction patterns and a lexicon.
Extrac-tion patterns are flexible regular expressions capa-ble of identifying both known and novel mentions.For instance, the pattern took three <DRUG>might identify oxycontin, ibuprofen, orbenzos.
made me <REACTION>, similarly,might identify dizzy, hungry, or throw up.Newly identified items are added to lexiconswhich are in turn used to identify new items.Two separate lexicons for drugs and med-ical events were generated using the meta-bootstrapping algorithm detailed in Riloff andJones (1999), which uses a pre-defined set of pat-terns to identify novel lexicon items occurring insimilar environments as known lexicon items.
Toidentify novel mentions, the algorithm relies on aninitial set of extraction patterns and a small num-ber of seed words to define the semantic categoryof interest, as seen in Figure 1.
Though boot-strapped lexicons contain noise, manually screen-ing for relevant items results in robust, automat-ically generated lexicons well suited to the taskof identifying potential ADEs.
Importantly, thismethod does not require expensive manual anno-tation and is capable of handling the colloquialterms and misspellings commonly found in socialmedia data even though it is not specifically tai-lored for non-standard usage.3github.com/ericbenz/TwitterDrugs16Meta-bootstrapping first identifies relevant ex-traction contexts from an input corpus and lists ofknown category items.
This, in turn, results ina list of context patterns.
Contexts were gener-ated by taking combinations of one to three wordspreceding or following the known category item.Table 1 shows how known drug names and med-ical events present in each context pattern wereanonymized with regular expressions capable ofextracting one or many words.Table 1: Extraction patterns and possible matchesCandidate Pattern Extracted Entitiestook (\S+) tablet ibuprofen, xanax,one, 25mgmade me (\S\s+)+ throw up, feel likedying, super happyEach candidate pattern was subsequently scoredon the basis of how many new category items itextracts relative to the number of existing lexiconitems.
Scoring is initially spurred by the relat-edness of extracted entities to a handful of seedwords defining the semantic category of interest.Each pattern is scored with the functionscore(pattern) = R ?
log2F (1)where F is the number of unique entities gener-ated by the pattern which are already present inthe semantic lexicon and R =FN, where N is thetotal number of words the pattern extracted.
R ishigh when patterns extract numerous items that arealready contained in the semantic lexicon, as thisreflects a high likelihood that all entities producedby this pattern are semantic category items.This scoring function, however, is incapable ofappropriately addressing the robustness of multi-word medical events.
In some cases, an extractedentity contains multiple unique reactions, such asgave me vertigo and really badnauseawhere vertigo and nausea should be consid-ered independently.
Judging the above examplebased on the whole string as an indivisible entitywill score it too low to be considered semanticallyrelevant.
This is because the string as an indi-visible whole is unlikely to ever occur again orbear strong semblance to the provided seed wordsor existing lexicon items.
Only portions of thisstring are important potential category items andare likely to be included in seed words or easilyidentified by patterns extracting single words.Reranking this pattern to favor extractions con-taining these two substrings can allow the the en-tire extraction to enter the medical event lexiconwhere each relevant bit can be manually identifiedin post-processing.
To do this, the scoring functionwas modified asscore(pattern) = ?
(R ?
log2F ) (2)where F is re-evaluated as the number of rele-vant substrings, and ?
is a penalty term where?
=clog2(avg words), where c is a constant andavg words is the average number of tokens perextraction per pattern.
All other terms remain thesame between both scoring functions.Because the F values grow increasingly large asthe semantic lexicons grow, the ?
penalty is intro-duced to control the balance of single and multipleword entities.
Shorter strings containing more rel-evant entities are penalized less than longer onespotentially containing lots of noise.
The c constantmust grow in proportion to the number of data in-stances being used in the training set.
Too small ac value will result in lexicons comprised mostly ofsingle-word extractions.
Too large a c value willresult in lexicons comprised mostly of multi-wordextractions.Following the scoring of each pattern, each en-tity is evaluated with the scoring functionscore(entity) =N?k=11+(0.1 ?
score(patternk))(3)where N is the number of different patterns whichfound the entity being scored.
This function scoreseach entity on the basis of how many patterns wereable to identify it, as words extracted by numerouspatterns are more likely to be true members of thesemantic lexicon.
The five highest scoring patternsare added to the semantic lexicon, serving as ad-ditional seed words for subsequent bootstrappingiterations.
This process continues until end condi-tions are reached.4 ResultsSix different training sets were used in the boot-strapping tasks to explore the influence of unanno-tated data during lexicon generation.
Each train-ing set contained the full DIEGO Lab training17corpus and an increasingly large amount of non-overlapping TwitterDrugs data.
The bootstrappingprocedure outlined above continued until lexiconscontained maximally 5000+i items, where i is thenumber of seed words.
Bootstrapping terminatedearly if new items were not added for five consec-utive iterations.The resulting lexicons were used to flag tweetsin held-out test sets where an extracted drug co-occurred with an extracted reaction.
The DIEGOtest set was used to compare flagged tweets usingthis methodology to O?Connor et al (2014), whichutilized a different lexicon-based ADR detectionalgorithm on the same DIEGO data set.
Tweetsflagged using bootstrapped lexicons increased pre-cision, recall, and F1in most cases, suggesting theviability of this method.4.1 Generating Drug LexiconsDrug lexicons were generated using 10-20 seedwords.
As the number of training instances in-creased, additional seed words were required tospur the bootstrapping algorithm to add lexiconitems in early iterations.
Seed words were takenfrom the most frequently occurring drugs in theDIEGO training corpus.Using only the DIEGO training data resulted in1907 candidate patterns, 1312 extracted entities,and 113 relevant identified drugs.
The best per-forming training set added 5K tweets from Twit-terDrugs to those in the DIEGO training set, re-sulting in 355 relevant extracted entities of whichnearly 60% were neither in the DIEGO data northe list of drugs used to generate the TwitterDrugscorpus.
Included in these lexicons are numerousmisspellings, slang terms, and hashtags.44.2 Generating Medical Event LexiconsDue to the challenges associated with multi-wordextractions, only three training sets were exploredfor reaction extraction.
30 seed word were used forall bootstrapping procedures, taken from the mostfrequent annotated ADRs in the DIEGO datasetprovided they were less than five words long.Using only the DIEGO training data resultedin 32,879 candidate patterns, producing a lexiconwith 1321 items.
To balance single and multi-word expressions, where c = 0.25 for this smalldataset.
Manual analysis of each lexicon item4Twitter permits the use of the # ?hashtag?
to prefix stringsfor searching, indexing, and statistical analysis such as in#adderall or #mighthaveaheartattackyielded 500 medical events after complex, multi-word entities were broken down.
The largestlexicon contained 783 medical events extractedfrom 177,494 patterns generated by appending 5Ktweets from TwitterDrugs to the DIEGO trainingset.
c = 0.75 in this case.
Over 87% of this lexi-con contained novel entities.4.3 Identifying Potential ADEsTweets were flagged as ?potentially containingan ADE?
by identifying those in which a termfrom a drug lexicon co-occurred with one froma medical event lexicon.
The effects of increas-ing the amount of training data can be seen in Ta-ble 2, which shows that an increasing proportionof tweets are flagged as the amount of training dataincreases.
This suggests that the composition ofthe resulting lexicons contains drugs and reactionsthat more frequently co-occur.The low proportion of flagged tweets is unsur-prising, as most Twitter users rarely discuss thephysical effects of their drug use.
It is importantto emphasize that the proportion of true ADEs isnot identical to the proportion flagged.
Discussionof drug indications?why a drug was taken?andbeneficial effects are much more common thanADEs or ADRs.
Of the proportion of flaggedtweets, roughly 25.2% contained obvious ADEs.This is roughly 16% more than the 9.3% capturedin the O?Connor et al (2014) study which usedonly the DIEGO data.In order to better evaluate the composition offlagged tweets using the bootstrapped lexicons, re-sults were directly compared to the O?Connor etal.
(2014) study using the 317 tweets distributedin the DIEGO Lab test set.
O?Connor et al (2014)reported precision, recall, and F1scores of 0.62,0.54, and 0.58, respectively.
In nearly all cases,bootstrapped lexicons have higher precision andF1score as Table 3 shows.Adding small amounts of data helped increaseperformance mostly through increases in preci-sion.
Larger datasets hurt performance becausethe bootstrapped lexicons were tuned more ap-propriately to the composition of drugs and reac-tions present in the TwitterDrugs corpus which arenot guaranteed to overlap exactly with the DIEGOdata despite the shared source (Twitter).Flagged tweets must be manually reviewedfor potential ADE/ADR relations.
Becauseflagged tweets were simply captured by mere co-18Table 2: Proportions of flagged tweets as ?potentially containing ADE relation?
increases as largeramounts of TwitterDrugs data is used for bootstrapping.
(*?lexicon generated from DIEGO +5K TD dataset)Training Corpus Held-out Test Set #Drugs # ADEs Num.
Flagged % FlaggedDIEGO TwitterDrugs (TD) 113 500 7,993/166,551 4.80%DIEGO +1K TD 165K TD 235 702 22,981/165,868 13.85%DIEGO +5K TD 160K TD 355 783 25,135/161,868 15.53%DIEGO +10K TD 155K TD 343 783* 24,661/156,868 15.72%DIEGO +25K TD 140K TD 311 783* 22,668/141,868 15.98%DIEGO +50K TD 115K TD 287 783* 19,091/116,868 16.34%Table 3: Precision, recall, and F1score for bootstrapped lexicons using different training set combina-tions using larger portions of TwitterDrugs data, best results in boldDrug Train SetDIEGO +1K +5K +10K +25K +50KMed.EventTrainSetDIEGOP = .7321 .7182 .7297 .7156 .7170 .7142R = .5125 .4938 .5062 .4875 .4750 .4688F1= .6029 .5852 .5978 .5799 .5714 .5660+1K.7419 .7177 .7280 .7154 .7167 .7167.5750 .5563 .5688 .5500 .5375 .5373.6479 .6267 .6386 .6219 .6143 .6142+5K.7368 .7130 .7241 .7105 .7112 .7112.5250 .5125 .5250 .5063 .4938 .4938.6131 .5964 .6087 .5912 .5830 .5830occurrence of terms, numerous captured tweetscontain discussions of beneficial effects or whya drug was taken.
For instance, no obviousADE/ADR exists in the flagged tweetThat ibuprofen 800 knocked myheadache right outContrast this withtook this vicodin and it isseriously hard to breathe all ofa suddenwhich clearly documents a potentially dangerousco-occurrence of VicodinR?and breathing difficul-ties.
Untangling beneficial effects and drug in-dications remains a problem area for automaticADE/ADR detection especially given that similarlanguage is used for both.5 DiscussionThough social media represents a rich source ofdata, ADE detection with lexicon-based methodsremains vulnerable to data sparsity?a low per-centage of tweets containing drug names actu-ally include ADEs.
However, the results dis-cussed above show that bootstrapping can in-crease the proportion of true ADEs in returneddatasets.
Meta-bootstrapped lexicons do not re-quire extensive manual annotation unlike other re-cent lexicon-based systems.
Because of the scor-ing function, bootstrapped lexicons are able to eas-ily capture variations in spelling and slang phrasesprovided they occur in contexts similar to thewords present in the growing semantic lexicon.In the drug lexicon, several misspellings orslang variations of numerous drugs were iden-tified, such as bendaryl (BenadrylR?)
orxannies (XanaxR?
), addressing a problem areafor social media data.
If one were to simply ap-ply existing drug lexicons against this dataset, anyslang terms or misspellings would be missed with-out additional processing.
Meta-bootstrappingcan easily retrieve this data, with the only post-processing being quick manual sifting of gener-ated lexicons for relevant category items.Medical event lexicons tended to robustly in-clude slang descriptions for medical issues rang-ing from intoxication (tweakin, turnt up,smashed) to mental states (got me up likezombies), to descriptions of body processesand fluids (barf, urine contains blood).These cannot be identified with existing medicalontologies and several are liable to change dramat-19ically as drug users modify the ways they describetheir experiences.
Importantly, manual analysiscan easily capture these potential ADE indicationswithout robust medical training.Taken together, misspellings and common slangdescriptions can be used to identify potentially se-vere ADEs, such asThe ER gave me percs andflexeril, I?m high af lmaowhere percs is a slang term for PercocetR?, andhigh a common generic description for any num-ber of abnormal sensory events.
PercocetR?andFlexerilR?have a high potential for drug interac-tion causing drowsiness, lightheadedness, confu-sion, dizziness, and vision problems5?all poten-tial adverse events contained within the genericslang term.
Within slang-driven social media data,this drug interaction and its associated side ef-fect would be difficult to capture without the flex-ible lexicons generated by the bootstrapping pro-cedure.Because the bootstrapped lexicons requiremanual pruning of irrelevant results, meta-bootstrapping is unlikely to save large amountsof time compared to existing research methods.However, the ease at which novel, relevant, non-standard lexicon items are identified and added tothe lexicon and the competitive abilities of known-ADE identification in a small test set emphasizesthe applicability of this approach for this task.6 Future WorkThe lexicons generated by meta-bootstrappingprovide numerous opportunities for research ex-tension.
For instance, lexicons may be easily ap-plied across a drug class, allowing for fast identi-fication of ADE discussion in social media acrossa particular class of interest, such as the ongoingcrisis surrounding the abuse of prescription-onlynarcotic painkillers.
After flagging a tweet con-taining an ADE/ADR resulting from opioid use,researchers could utilize tweet metadata to helpcrisis managers identify demographic areas of in-terest for more targeted care.Outside pharmacovigilance, the lexicons canalso be used to ?bootstrap?
corpus generation.
Be-cause novel extractions represented roughly 60%of the generated drug lexicon, these new entries5umm.edu/health/medical/drug-interaction-toolcan be used to expand the search query set, return-ing a more diverse set of tweets than the original334 drug names.
This, in turn, is likely to leadto identification of more novel items, allowing theprocess to be repeated.
Doing so allows for easyidentification of slang terms as they are createdand enter common use.Lastly, the TwitterDrugs corpus represents arich resource for subsequent research.
It maybe easily annotated for supervised techniques, orcan be explored with different semi- and unsuper-vised methods for lexicon generation, relation ex-traction, or ADE/ADR classification.
The boot-strapping procedure itself can be modified to in-clude additional standardization techniques whichmay diminish the number of patterns by simplify-ing linguistic complexities.
Lemmatization wouldbe highly effective here, allowing patterns differ-entiated by only inflectional morphology to becombined.
However, many of these standardiza-tion techniques still perform poorly on the non-standard language found in social media data.AcknowledgmentsSpecial thanks to Prof. Nianwen Xue, the advi-sor for this work, which presents a portion of amasters thesis on the same topic titled IdentifyingAdverse Drug Events in Twitter Data Using Semi-Supervised Bootstrapped Lexicons and availableelectronically at the Brandeis Institutional Reposi-tory6.
Thanks also to Prof. Sanda Harabagiu (UT-Dallas), Prof. James Pustejovsky, Dr. Marc Verha-gen, Dr. Keith Plaster, and Nikhil Krishnaswamyfor additional help and input.ReferencesBrant W Chee, Richard Berlin, and Bruce Schatz.2011.
Predicting adverse drug events from personalhealth messages.
In AMIA Annual Symposium Pro-ceedings.
American Medical Informatics Associa-tion.Robert Eriksson, Peter Bj?dstrup Jensen, SuneFrankild, Lars Juhl Jensen, and S?ren Brunak.
2013.Dictionary construction and identification of possi-ble adverse drug events in Danish clinical narrativetext.
Journal of the American Medical InformaticsAssociation, 20(5):947?953.Rachel Ginn, Pranoti Pimpalkhute, Azadeh Nikfarjam,Apurv Patki, Karen O?Connor, Abeed Sarker, Karen6bir.brandeis.edu/handle/10192/3225320Smith, and Graciela Gonzalez.
2014.
Mining twit-ter for adverse drug reaction mentions: a corpusand classification benchmark.
In Proceedings ofthe fourth workshop on building and evaluating re-sources for health and biomedical text processing.Rave Harpaz, Alison Callahan, Suzanne Tamang, YenLow, David Odgers, Sam Finlayson, Kenneth Jung,Paea LePendu, and Nigam H Shah.
2014.
Text min-ing for adverse drug events: the promise, challenges,and state of the art.
Drug Safety, 37(10):777?790.Benjamin Honigman, Patrice Light, Russel M Pulling,and David W Bates.
2001.
A computerized methodfor identifying incidents associated with adversedrug events in outpatients.
International Journal ofMedical Informatics, 61(1):21?32.Azadeh Nikfarjam, Abeed Sarker, Karen O?Connor,Rachel Ginn, and Graciela Gonzalez.
2015.
Phar-macovigilance from social media: mining adversedrug reaction mentions using sequence labelingwith word embedding cluster features.
Journalof the American Medical Informatics Association,22(3):671?681.Karen O?Connor, Pranoti Pimpalkhute, Azadeh Nik-farjam, Rachel Ginn, Karen L Smith, and GracielaGonzalez.
2014.
Pharmacovigilance on twitter?mining tweets for adverse drug reactions.
In AMIAAnnual Symposium Proceedings.
American MedicalInformatics Association.World Health Organization.
1972.
Internationaldrug monitoring: the role of national centres.World Health Organization Technical Report Series,498:1?25.World Health Organization.
2002.
The importance ofpharmacovigilance.Ellen Riloff and Rosie Jones.
1999.
Learning dic-tionaries for information extraction by multi-levelbootstrapping.
In AAAI/IAAI, pages 474?479.Abeed Sarker, Rachel Ginn, Azadeh Nikfarjam, KarenO?Connor, Karen Smith, Swetha Jayaraman, Te-jaswi Upadhaya, and Graciela Gonzalez.
2015.
Uti-lizing social media data for pharmacovigilance: areview.
Journal of biomedical informatics, 54:202?212.21
