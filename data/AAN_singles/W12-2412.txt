Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 100?108,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsNew Resources and Perspectives for Biomedical Event ExtractionSampo Pyysalo1, Pontus Stenetorp2, Tomoko Ohta1, Jin-Dong Kim3 and Sophia Ananiadou11National Centre for Text Mining and University of Manchester,Manchester Interdisciplinary Biocentre, 131 Princess Street, Manchester, UK2Tokyo University, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan3Database Center for Life Science, 2-11-16 Yayoi, Bunkyo-ku, Tokyo, JapanAbstractEvent extraction is a major focus of re-cent work in biomedical information extrac-tion.
Despite substantial advances, many chal-lenges still remain for reliable automatic ex-traction of events from text.
We introduce anew biomedical event extraction resource con-sisting of analyses automatically created bysystems participating in the recent BioNLPShared Task (ST) 2011.
In providing for thefirst time the outputs of a broad set of state-of-the-art event extraction systems, this resourceopens many new opportunities for studyingaspects of event extraction, from the identifi-cation of common errors to the study of ef-fective approaches to combining the strengthsof systems.
We demonstrate these opportuni-ties through a multi-system analysis on threeBioNLP ST 2011 main tasks, focusing onevents that none of the systems can success-fully extract.
We further argue for new per-spectives to the performance evaluation of do-main event extraction systems, considering adocument-level, ?off-the-page?
representationand evaluation to complement the mention-level evaluations pursued in most recent work.1 IntroductionBiomedical information extraction efforts are in-creasingly focusing on event extraction using struc-tured representations that allow associations of arbi-trary numbers of participants in specific roles (e.g.Theme, Cause) to be captured (Ananiadou et al,2010).
Domain event extraction has been advancedin particular by the BioNLP Shared Task (ST) events(Kim et al, 2011a; Kim et al, 2011b), which haveintroduced common task settings, datasets, and eval-uation criteria for event extraction.
Participants inthese shared tasks have introduced dozens of sys-tems for event extraction, and the resulting methodshave been applied to automatically analyse the entireavailable domain literature (Bjo?rne et al, 2010) andapplied in support of applications such as semanticliterature search (Ohta et al, 2010; Van Landeghemet al, 2011b) and pathway curation support (Kemperet al, 2010).It is possible to assess recent advances in event ex-traction through results for a task considered both inthe BioNLP ST 2009 and 2011.
By the primary eval-uation criteria, the highest performance achieved inthe 2009 task was 51.95% F-score, and a 57.46% F-score was reached in the comparable 2011 task (Kimet al, 2011b).
These results demonstrate significantadvances in event extraction methods, but also indi-cate that the task continues to hold substantial chal-lenges.
This has led to a call from task participantsfor further analysis of the data and results, accompa-nied by a proposal to release analyses from individ-ual systems to facilitate such analysis (Quirk et al,2011).In this study, we explore new perspectives into theanalyses and performance of event extraction meth-ods.
We build primarily on a new resource compiledwith the support of the majority of groups participat-ing in the BioNLP ST 2011, consisting of analysesfrom systems for the three main tasks sharing thetext-bound event representation.
We demonstratethe use of this resource through an evaluation fo-cusing on events that cannot be extracted even bythe union of combined systems, identifying partic-ular remaining challenges for event extraction.
Wefurther propose and evaluate an alternate, document-level perspective to event extraction, demonstrat-ing that when only unique events are considered for100Figure 1: Example event annotations.
The ?crossed-out?
event type identifies an event marked as negated.
Eventillustrations created using the STAV visualization tool (Stenetorp et al, 2011).each document, the measured performance and evenranking of systems participating in the shared task isnotably altered.2 BackgroundIn this work, we focus on the definition of theevent extraction task first introduced in the BioNLPShared Task 2009.1 The task targets the extrac-tion of events, represented as n-ary associations ofparticipants (entities or other events), each markedas playing a specific role such as Theme or Causein the event.
Each event is assigned a type suchas BINDING or PHOSPHORYLATION from a fixed,task-specific set.
Events are further typically associ-ated with specific trigger expressions that state theiroccurrence in text.
As physical entities such as pro-teins are also identified in the setting with specificspans referring to the real-world entities in text, theoverall task is ?text-bound?
in the sense of requiringnot only the extraction of targeted statements fromtext, but also the identification of specific regions oftext expressing each piece of extracted information.Events can further be marked with modifiers iden-tifying additional features such as being explicitlynegated or stated in a speculative context.
Figure 1shows an illustration of event annotations.This BioNLP ST 2009 formulation of the eventextraction task was followed also in three 2011 maintasks: the GE (Kim et al, 2011c), ID (Pyysalo et al,2011a) and EPI (Ohta et al, 2011) tasks.
A vari-ant of this representation that omits event triggerswas applied in the BioNLP ST 2011 bacteria track(Bossy et al, 2011), and simpler, binary relation-type representations were applied in three support-ing tasks (Nguyen et al, 2011; Pyysalo et al, 2011b;Jourde et al, 2011).
Due to the challenges of con-sistent evaluation and processing for tasks involv-1While far from the only formulation proposed in the litera-ture, this specific task setting is the most frequently consideredand arguably a de facto standard for domain event extraction.ing different representations, we focus in this workspecifically on the three 2011 main tasks sharing auniform representation: GE, ID and EPI.3 New Resources for Event ExtractionIn this section, we present the new collection of au-tomatically created event analyses and demonstrateone use of the data through an evaluation of eventsthat no system could successfully extract.3.1 Data CompilationFollowing the BioNLP ST 2011, the MSR-NLPgroup called for the release of outputs from variousparticipating systems (Quirk et al, 2011) and madeanalyses of their system available.2 Despite the ob-vious benefits of the availability of these resources,we are not aware of other groups following this ex-ample prior to the time of this publication.To create the combined resource, we approachedeach group that participated in the three targetedBioNLP ST 2011 main tasks to ask for their supportto the creation of a dataset including analyses fromtheir event extraction systems.
This suggestion metwith the support of all but a few groups that wereapproached.3 The groups providing analyses fromtheir systems into this merged resource are summa-rized in Table 1, with references to descriptions ofthe systems used to create the included analyses.
Wecompiled for each participant and each task both thefinal test set submission and a comparable submis-sion for the separate development set.As the gold annotations for the test set are onlyavailable for evaluation through an online interface(in order to avoid overfitting and assure the compa-rability of results), it is important to provide also de-velopment set analyses to permit direct comparison2http://research.microsoft.com/bionlp/3We have yet to hear back from a few groups, but none hasyet explicitly denied the release of their data.
Should any re-maining group accept the release of their data, we will release anew, extended version of the resource.101Task SystemTeam GE EPI ID BB BI CO REL REN descriptionUTurku 1 1 1 1 1 1 1 1 Bjo?rne and Salakoski (2011)ConcordU 1 1 1 1 1 1 Kilicoglu and Bergler (2011)UMass 1 1 1 Riedel and McCallum (2011)Stanford 1 1 1 McClosky et al (2011)FAUST 1 1 1 Riedel et al (2011)MSR-NLP 1 1 Quirk et al (2011)CCP-BTMG 1 1 Liu et al (2011)BMI@ASU 1 Emadzadeh et al (2011)TM-SCS 1 Bui and Sloot (2011)UWMadison 1 Vlachos and Craven (2011)HCMUS 1 1 Le Minh et al (2011)PredX 1 -VIBGhent 1 Van Landeghem et al (2011a)Table 1: BioNLP ST 2011 participants contributing to the combined resource.EventsTask Gold FN RecallGE (task 1) 3250 1006 69.05%EPI (CORE task) 601 129 78.54%ID (CORE task) 691 183 73.52%Table 2: Recall for the union of analyses from systemsincluded in the combined dataset.against gold annotations.
The inclusion of both de-velopment and test set annotations also allows e.g.the study of system combination approaches wherethe combination parameters are estimated on devel-opment data for final testing on the test set (Kim etal., 2011a).3.2 EvaluationWe demonstrate the use of the newly compileddataset through a manual evaluation of GE, EPI andID main task development set gold standard eventsthat are not extracted by any of the systems forwhich analyses were available.4 We perform eval-uation on the GE subtask 1 and the EPI and IDtask CORE subtasks, as all participating systems ad-dressed the extraction targets of these subtasks.We first evaluated each of the analyses against thedevelopment set of the respective task using the of-ficial shared task evaluation software, using optionsfor the evaluation tools to list the sets of true posi-tive (TP), false positive (FP) and false negative (FN)4The final collection includes analyses from the systems oftwo groups that agreed to the release of their data after the com-pletion of this analysis, but we expect the results to largely holdalso for the final collection.events.
We then selected for each of the three tasksthe set of events that were included in the FN listfor all systems.
This gives the results for the re-call of the union of all systems shown in Table 2.The recall of the system union is approximately 30%points higher than that of any individual GE system(Kim et al, 2011c) and 25% points higher for EPIand ID (Ohta et al, 2011; Pyysalo et al, 2011a),suggesting potential remaining benefits from systemcombination.
Nevertheless, a substantial fraction ofthe total set of gold events remains inaccessible alsoto this system union.We then selected a random set of 100 events fromeach of the three sets of events that were not re-covered by any system (i.e.
300 events in total) andperformed a manual evaluation to identify frequentproperties of these events that could contribute toextraction failures.
In brief, we first performed abrief manual evaluation to identify common charac-teristics of these events, and then evaluated the 300events individually to identify the set of these char-acteristics that apply to each event.The results of the evaluation for common casesare shown in Table 3.
We find that the most fre-quent property of the unrecoverable events is thatthey involve implicit arguments (Gerber and Chai,2010), a difficult challenge that has not been ex-tensively considered in domain event extraction.
Aclosely related issue are events involving argumentsin a sentence different from that containing the trig-ger (?cross-sentence?
), connected either implicitlyor through explicit coreference (?coreference?).
Al-102Type GE EPI ID TotalImplicit argument 18 33 15 66Cross-sentence 14 40 4 58Weak trigger 28 14 11 53Coreference 12 20 18 50Static Relation 6 28 6 40Error in gold 17 4 9 30Ambiguous type 2 9 11 22Shared trigger 2 12 1 15Table 3: Manual evaluation results for features of eventsthat could not be recovered by any system.though coreference was considered as as separatetask in BioNLP ST 2011 (Nguyen et al, 2011), it isclear that it involves many remaining challenges forevent extraction systems.
Similarly, events whereexplicit arguments are connected to other argumentsthrough ?static?
relations such as part-of (e.g.
?Abinds the X domain of B?)
represent a known chal-lenge (Pyysalo et al, 2011b).
These results sug-gest that further advances in event extraction perfor-mance could be gained by the integration of systemsfor the analysis of coreference and static relations,approaches for which some success has already beendemonstrated in recent efforts (Van Landeghem etal., 2010; Yoshikawa et al, 2011; Miwa et al, 2012).?Weak?
trigger expressions that must be inter-preted in context to determine whether they expressan event, as well as a related class of events whosetype must be disambiguated with reference to con-text (?ambiguous type?)
are comparatively frequentin the three tasks, while EPI in particular involvesmany cases where a trigger is shared between mul-tiple events ?
an issue for approaches that assumeeach token can be assigned at most a single class.Finally, we noted a number of cases that we judgedto be errors in the gold annotation; the numberis broadly in line with the reported inter-annotatoragreement for the data (see e.g.
Ohta et al (2011)).While there is an unavoidable subjective com-ponent to evaluations such as this, we note that asimilar evaluation performed following the BioNLPShared Task 2009 using test set data reached broadlycomparable results (Kim et al, 2011a).
The newlycompiled dataset represents the first opportunity forthose without direct access to the test set data andsubmissions to directly assess the task results, asdemonstrated here.
We hope that this resource willencourage further exploration of both the data, thesystem analyses and remaining challenges in eventextraction.4 New Perspectives to Event ExtractionAs discussed in Section 2, the BioNLP ST event ex-traction task is ?text-bound?
: each entity and eventannotation is associated with a specific span of text.Contrasted to the alternative approach where anno-tations are document-level only, this approach hasa number of important benefits, such as allowingmachine learning methods for event extraction tobe directly trained on fully and specifically anno-tated data without the need to apply frequently error-prone heuristics (Mintz et al, 2009) or develop ma-chine learning methods addressing the mapping be-tween text expressions and document-level annota-tions (Riedel et al, 2010).
Many of the most suc-cessful event extraction approaches involve directtraining of machine learning methods using the text-bound annotations (Riedel and McCallum, 2011;Bjo?rne and Salakoski, 2011; McClosky et al, 2011).However, while the availability of text-bound anno-tations in data provided to task participants is clearlya benefit, there are drawbacks to the choice of ex-clusive focus on text-bound annotations in systemoutput, including issues relating to evaluation andthe applicability of methods to the task.
In the fol-lowing section, we discuss some of these issues andpropose alternatives to representation and evaluationaddressing them.4.1 EvaluationThe evaluation of the BioNLP ST is instance-basedand text-bound: each event in gold annotation andeach event extracted by a system is considered in-dependently, separating different mentions of the?same?
real-world event.
This is the most detailed(sensitive) evaluation setting permitted by the data,and from a technical perspective a reasonable choicefor ranking systems performing the task.However, from a practical perspective, this eval-uation setting arguably places excessively strict de-mands on systems, and may result in poor correla-tion between measured performance and the practi-cal value of systems.
Our motivating observationsare that specific real-world events tend to be men-103tioned multiple times in a single publication ?
espe-cially the events that are of particular importance inthe study ?
and that there are few practical applica-tions for which it is necessary to find each such re-peated mention.
For example, in literature search fore.g.
pathway or database curation support, one typi-cal information need is to identify biomolecular re-actions involving a specific protein.
Event extractioncan support such needs either by summarizing allevents involving the protein that could be extractedfrom the literature (Van Landeghem et al, 2011b), orby retrieving documents (perhaps showing relevanttext snippets) containing such events (Ohta et al,2010).
For the former to meet the information need,it may be sufficient that each different event is ex-tracted once from the entire literature; for the latter,once from each relevant document.
For uses suchas these, there is no obvious need for, or, indeed,no very obvious benefit from the ability of extrac-tion systems to separately enumerate every mentionof every event in every publication.
It is easy to en-vision other practical use cases where instance-levelextraction performance is at best secondary and, weargue, difficult to identify ones where it is of criticalimportance.For applications such as these, the importantquestion is the reliability of the system at identify-ing events either on the level of documents or on thelevel of (a relevant subset of) the literature, ratherthan on the level of individual mentions.
For a morecomplete and realistic picture of the practical valueof event extraction methods, measures other thaninstance-level should thus also be considered.4.2 Task settingWhile applications can benefit from the ability ofIE systems to identify a specific span of text sup-porting extracted information,5 the requirement ofthe BioNLP ST setting that the output of event ex-traction systems must identify specific text spans foreach entity and event makes it complex or impossi-ble to address the task using a number of IE methodsthat might otherwise represent feasible approachesto event extraction.5For example, for curation support tasks, this allows the hu-man curator to easily check the correctness of extracted infor-mation and helps to select ?evidence sentences?, as included inmany databases.For example, Patwardhan and Riloff (2007) andChambers and Jurafsky (2011) consider an IE ap-proach where the extraction targets are MUC-4 styledocument-level templates (Sundheim, 1991), theformer a supervised system and the latter fully un-supervised.
These methods and many like them fortasks such as ACE (Doddington et al, 2004) workon the document level, and can thus not be readilyapplied or evaluated against the existing annotationsfor the BioNLP shared tasks.
Enabling the appli-cation of such approaches to the BioNLP ST couldbring valuable new perspectives to event extraction.4.3 Alternative evaluationWe propose a new mode of evaluation that otherwisefollows the primary BioNLP ST evaluation criteria,but incorporates the following two exceptions:1. remove the requirement to match trigger spans2.
only require entity texts, not spans, to matchThe first alternative criterion has also been previ-ously considered in the GE task evaluation (Kim etal., 2011c); the latter has, to the best of our knowl-edge, not been previously considered in domainevent extraction.
We additionally propose to con-sider only the minimal set of events that are uniqueon the document level (under the evaluation criteria),thus eliminating effects from repeated mentions of asingle event on evaluated performance.
We createdtools implementing this mode of evaluation with ref-erence to the BioNLP ST 2011 evaluation tools.While this type of evaluation has, to the best ofour knowledge, not been previously applied specif-ically in biomedical event extraction, it is closelyrelated (though not identical) to evaluation criteriaapplied in MUC, ACE, and the in-domain PPI re-lation extraction tasks in BioCreative (Krallinger etal., 2008).4.4 Alternative representationA true conversion to a document-level, ?off thepage?
representation would require manual anno-tation efforts to identify the real-world entities andevents referred to in text (Doddington et al, 2004).However, it is possible to reasonably approximatesuch a representation through an automatic heuristicconversion.104BioNLP Shared TaskT1 Protein 0 5 CIITAT2 Protein 21 28 TAFII32T3 Binding 6 15 interactsE1 Binding:T3 Theme:T1 Theme2:T2T4 Protein 54 61 TAFII32T5 Protein 66 71 CIITAT6 Binding 33 45 interactionsE2 Binding:T6 Theme:T4 Theme2:T5Document levelT1 Protein CIITAT2 Protein TAFII32E1 Binding Theme:T1 Theme2:T2CIITA interacts with TAFII32 ... interactions between TAFII32 and CIITA arePro Binding Protein Binding Protein ProTh Th2 ThemeTheme2...Figure 2: Illustration of BioNLP Shared Task annotation format and the proposed document-level (?off-the-page?
)format.We first introduce a non-textbound annotation for-mat that normalizes over differences in e.g.
argu-ment order and eliminates duplicate events.
The for-mat largely follows that of the shared task but re-moves any dependencies and references to text off-sets (see Figure 2).
The conversion process into thisrepresentation involves a number of steps.
First, wemerge duplicate pairs of surface strings and types,as different mentions of the same entity in differentparts of the text are no longer distinguishable in therepresentation.
In the original format, equivalencerelations (Kim et al, 2011a) are annotated only forspecific mentions.
When ?raising?
the annotationsto the document level, equivalence relations are rein-terpreted to cover the full document by extendingthe equivalence to all mentions that share the surfaceform and type with members of existing equivalenceclasses.
Finally, we implemented an event equiv-alence comparison to remove duplicate annotationsfrom each document.
The result of the conversionto this alternate representation is thus an ?off-the-page?
summary of the unique set of events in thedocument.This data can then be used for training and com-parison of methods analogously to the original anno-tations, but without the requirement that all analysesinclude text-bound annotations.4.5 Experimental ResultsWe next present an evaluation using the alternativedocument-level event representation and evaluation,comparing its results to those for the primary sharedtask evaluation criteria.
As comparatively few of thePrimary criteria New criteriaGroup Rec.
Prec.
F Rec.
Prec.
FFAUST 49.41 64.75 56.04 53.10 67.56 59.46UMass 48.49 64.08 55.20 52.55 66.57 58.74UTurku 49.56 57.65 53.30 54.23 60.11 57.02MSR-NLP 48.64 54.71 51.50 53.55 58.24 55.80ConcordU 43.55 59.58 50.32 47.42 60.85 53.30UWMadison 42.56 61.21 50.21 46.09 62.50 53.06Stanford 42.36 61.08 50.03 46.48 63.22 53.57BMI@ASU 36.91 56.63 44.69 41.15 61.44 49.29CCP-BTMG 31.57 58.99 41.13 34.82 66.89 45.80TM-SCS 32.73 45.84 38.19 38.02 50.87 43.51HCMUS 10.12 27.17 14.75 14.50 40.05 21.29Table 4: Comparison of BioNLP ST 2011 GE task 1 re-sults.shared task participants attempted subtasks 2 and 3for GE or the FULL task setting for EPI and ID, weconsider only GE subtask 1 and the EPI and ID taskCORE extraction targets in these experiments.
Werefer to the task overviews for the details of the sub-tasks and the primary evaluation criteria (Kim et al,2011c; Pyysalo et al, 2011a; Ohta et al, 2011).Tables 4, 5 and 6 present the results for theGE, EPI and ID tasks, respectively.
For GE, wesee consistently higher F-scores for the new crite-ria, in most cases reflecting primarily an increasein recall, but also involving increases in precision.The F-score differences range between 3-4% formost high-ranking systems, with more substantialincreases for lower-ranking systems.
Notable in-creases in precision are seen for some systems (e.g.HCMUS), indicating that the systems comparativelyfrequently extract correct information, but associ-ated with the wrong spans of text.105Primary criteria New criteriaGroup Rec.
Prec.
F Rec.
Prec.
FUTurku 68.51 69.20 68.86 74.20 69.14 71.58FAUST 59.88 80.25 68.59 67.04 76.82 71.60MSR-NLP 55.70 77.60 64.85 59.24 77.66 67.21UMass 57.04 73.30 64.15 65.76 69.65 67.65Stanford 56.87 70.22 62.84 62.74 67.12 64.86CCP-BTMG 45.06 63.37 52.67 54.62 63.17 58.58ConcordU 40.28 76.71 52.83 48.41 76.57 59.32Table 5: Comparison of BioNLP ST 2011 EPI COREtask results.For EPI (Table 5), we find comparable differencesin F-score to those for GE, but there is a signifi-cant difference in the precision-recall balance: themajority of systems show over 5% points higher re-call under the new criteria, but many show substan-tial losses in precision, while for GE precision wasalso systematically increased.
This effect was notunexpected: we judge this to reflect primarily theincreased number of opportunities to extract eachunique event (higher recall) combined with the com-paratively higher effect from errors from the reduc-tion in the total number of unique correct extractiontargets (lower precision).
It is not clear from ouranalysis why a comparable effect was not seen forGE.
Interestingly, most systems show a better pre-cision/recall balance under the new criteria than theold, despite not optimizing for these criteria.For ID (Table 6), we find a different effect also onF-score, with all but one system showing reducedperformance under the new criteria, with some veryclear drops in performance; the only system to ben-efit is UTurku.
Analysis suggests that this effecttraces primarily to a notable reduction in the numberof simple PROCESS events that take no arguments6when considering unique events on the documentlevel instead of each event mention independently.7Conversely, the Stanford system, which showed thehighest instance-level performance in the extractionof PROCESS type events (see Pyysalo et al (2011a)),shows a clear loss in precision.6The ID task annotation criteria call for mentions of somehigh-level biological processes such as ?infection?
to be anno-tated as PROCESS even if no explicit participants are mentioned(Pyysalo et al, 2011a).7It is interesting to note that there was an error in theUTurku system implementation causing it to fail to output anyevents without arguments (Jari Bjo?rne, personal communica-tion), likely contributing to the effect seen here.Primary criteria New criteriaGroup Rec.
Prec.
F Rec.
Prec.
FFAUST 50.84 66.35 57.57 50.11 65.33 56.72UMass 49.67 62.39 55.31 49.34 60.98 54.55Stanford 49.16 56.37 52.52 42.00 50.80 45.98ConcordU 50.91 43.37 46.84 43.42 37.18 40.06UTurku 39.23 49.91 43.93 48.03 51.84 49.86PredX 23.67 35.18 28.30 20.94 30.69 24.90Table 6: Comparison of BioNLP ST 2011 ID CORE taskresults.The clear differences in performance and themany cases in which the system rankings under thetwo criteria differ demonstrate that the new evalua-tion criteria can have a decisive effect in which ap-proaches to event extraction appear preferred.
Whilethere may be cases for which the original shared taskcriteria are preferred, there is at the very minimuma reasonable argument to be made that the emphasisthese criteria place on the extraction of each instanceof simple events is unlikely to reflect the needs ofmany practical applications of event extraction.While these experimental results demonstrate thatthe new evaluation criteria emphasize substantiallydifferent aspects of the performance of the systemsthan the original criteria, they cannot per se serveas an argument in favor of one set of criteria overanother.
We hope that these results and the accom-panying tools will encourage increased study anddiscussion of evaluation criteria for event extractionand more careful consideration of the needs of spe-cific applications of the technology.5 Discussion and ConclusionsWe have presented a new resource combining analy-ses from the systems participating in the GE, ID andEPI main tasks of the BioNLP Shared Task 2011,compiled with the collaboration of groups partic-ipating in these tasks.
We demonstrated one useof the resource through an evaluation of develop-ment set events that none of the participating sys-tems could recover, finding that events involvingimplicit arguments, coreference and participants inmore than once sentence continue to represent chal-lenges to the event extraction systems that partici-pated in these tasks.We further argued in favor of new perspectives tothe evaluation of domain event extraction systems,106emphasizing in particular the need for document-level, ?off-the-page?
representations and evaluationto complement the text-bound, instance-level eval-uation criteria that have so far been applied in theshared task evaluation.
We proposed a variant ofthe shared task standoff representation for support-ing such evaluation, and introduced evaluation toolsimplementing the proposed criteria.
An evaluationsupported by the introduced resources demonstratedthat the new criteria can in cases provide substan-tially different results and rankings of the systems,confirming that the proposed evaluation can serveas an informative complementary perspective intoevent extraction performance.In future work, we hope to further extend the cov-erage of the provided system outputs as well as theiranalysis to cover all participants of all tasks in theBioNLP Shared Task 2011.
We also aim to use thecompiled resource in further study of appropriatecriteria for the evaluation of event extraction meth-ods and deeper analysis of the remaining challengesin event extraction.To encourage further study of all aspects of eventextraction, all resources and tools introduced in thisstudy are provided freely to the community fromhttp://2011.bionlp-st.org.AcknowledgmentsWe wish to thank the members of all groups con-tributing to the combined resource, and in particularthe members of the MSR-NLP group for providingboth the initial suggestion for its creation as well asthe first publicly released analyses from their sys-tem.
We would also like to thank the anonymousreviewers for their many insightful comments.This work was funded in part by UK Biotechnol-ogy and Biological Sciences Research Council (BB-SRC) under project Automated Biological Event Ex-traction from the Literature for Drug Discovery (ref-erence number: BB/G013160/1), by the Ministry ofEducation, Culture, Sports, Science and Technologyof Japan under the Integrated Database Project andby the Swedish Royal Academy of Sciences.ReferencesSophia Ananiadou, Sampo Pyysalo, Jun?ichi Tsujii, andDouglas B. Kell.
2010.
Event extraction for sys-tems biology by text mining the literature.
Trends inBiotechnology, 28(7):381?390.Jari Bjo?rne and Tapio Salakoski.
2011.
Generalizingbiomedical event extraction.
In Proceedings of theBioNLP Shared Task 2011 Workshop.Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsujii,and Tapio Salakoski.
2010.
Complex event extractionat PubMed scale.
Bioinformatics, 26(12):i382?390.Robert Bossy, Julien Jourde, Philippe Bessie`res, Maartenvan de Guchte, and Claire Ne?dellec.
2011.
BioNLPShared Task 2011 - Bacteria Biotope.
In Proceedingsof BioNLP Shared Task 2011 Workshop, pages 56?64.Quoc-Chinh Bui and Peter.
M.A.
Sloot.
2011.
Extract-ing biological events from text using simple syntacticpatterns.
In Proceedings of BioNLP Shared Task 2011Workshop, pages 143?146.Nathanael Chambers and Dan Jurafsky.
2011.
Template-based information extraction without the templates.
InProceedings of the ACL-HLT 2011, pages 976?986.George Doddington, Alexis Mitchell, Mark Przybocki,Lance Ramshaw, Stephanie Strassel, and RalphWeischedel.
2004.
The automatic content extraction(ACE) program?tasks, data, and evaluation.
In Pro-ceedings of LREC, volume 4, pages 837?840.Ehsan Emadzadeh, Azadeh Nikfarjam, and GracielaGonzalez.
2011.
Double layered learning for bio-logical event extraction from text.
In Proceedings ofBioNLP Shared Task 2011 Workshop, pages 153?154.Matthew Gerber and Joyce Chai.
2010.
Beyond nom-bank: A study of implicit arguments for nominal predi-cates.
In Proceedings of ACL 2010, pages 1583?1592.Julien Jourde, Alain-Pierre Manine, Philippe Veber,Kare?n Fort, Robert Bossy, Erick Alphonse, andPhilippe Bessie`res.
2011.
BioNLP Shared Task2011 ?
Bacteria gene interactions and renaming.
InProceedings of BioNLP Shared Task 2011 Workshop,pages 65?73.Brian Kemper, Takuya Matsuzaki, Yukiko Matsuoka,Yoshimasa Tsuruoka, Hiroaki Kitano, Sophia Anani-adou, and Jun?ichi Tsujii.
2010.
PathText: a text min-ing integrator for biological pathway visualizations.Bioinformatics, 26(12):i374?i381.Halil Kilicoglu and Sabine Bergler.
2011.
Adapting ageneral semantic interpretation approach to biologi-cal event extraction.
In Proceedings of the BioNLPShared Task 2011 Workshop.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2011a.
Extractingbio-molecular events from literature - the BioNLP?09shared task.
Computational Intelligence, 27(4):513?540.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, Ngan Nguyen, and Jun?ichi Tsujii.
2011b.107Overview of BioNLP Shared Task 2011.
In Proceed-ings of BioNLP Shared Task, pages 1?6.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and AkinoriYonezawa.
2011c.
Overview of the Genia Event taskin BioNLP Shared Task 2011.
In Proceedings of theBioNLP Shared Task 2011 Workshop.Martin Krallinger, Florian Leitner, Carlos Rodriguez-Penagos, Alfonso Valencia, et al 2008.
Overviewof the protein-protein interaction annotation extrac-tion task of BioCreative II.
Genome Biology, 9(Suppl2):S4.Quang Le Minh, Son Nguyen Truong, and Quoc Ho Bao.2011.
A pattern approach for biomedical event anno-tation.
In Proceedings of BioNLP Shared Task 2011Workshop, pages 149?150.Haibin Liu, Ravikumar Komandur, and Karin Verspoor.2011.
From graphs to events: A subgraph matchingapproach for information extraction from biomedicaltext.
In Proceedings of the BioNLP Shared Task 2011Workshop.David McClosky, Mihai Surdeanu, and Christopher Man-ning.
2011.
Event extraction as dependency parsing.In Proceedings of ACL-HLT 2011, pages 1626?1635.Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proceedings of ACL-IJCNLP2009, pages 1003?1011.Makoto Miwa, Paul Thompson, and Sophia Ananiadou.2012.
Boosting automatic event extraction from theliterature using domain adaptation and coreferenceresolution.
Bioinformatics.Ngan Nguyen, Jin-Dong Kim, and Jun?ichi Tsujii.2011.
Overview of BioNLP 2011 Protein CoreferenceShared Task.
In Proceedings of BioNLP Shared Task2011 Workshop, pages 74?82.Tomoko Ohta, Takuya Matsuzaki, Naoaki Okazaki,Makoto Miwa, Rune S?tre, Sampo Pyysalo, andJun?ichi Tsujii.
2010.
Medie and info-pubmed: 2010update.
BMC Bioinformatics, 11(Suppl 5):P7.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP Shared Task 2011Workshop.Siddharth Patwardhan and Ellen Riloff.
2007.
Effec-tive information extraction with semantic affinity pat-terns and relevant regions.
In Proceedings of EMNLP-CoNLL 2007, pages 717?727.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011a.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings of theBioNLP Shared Task 2011 Workshop.Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.2011b.
Overview of the entity relations (REL) sup-porting task of BioNLP Shared Task 2011.
In Pro-ceedings of BioNLP Shared Task 2011 Workshop,pages 83?88.Chris Quirk, Pallavi Choudhury, Michael Gamon, andLucy Vanderwende.
2011.
MSR-NLP entry inBioNLP Shared Task 2011.
In Proceedings of BioNLPShared Task 2011 Workshop, pages 155?163.Sebastian Riedel and Andrew McCallum.
2011.
Fast androbust joint models for biomedical event extraction.
InProceedings of EMNLP 2011, pages 1?12.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions withoutlabeled text.
Machine Learning and Knowledge Dis-covery in Databases, pages 148?163.Sebastian Riedel, David McClosky, Mihai Surdeanu, An-drew McCallum, and Chris Manning.
2011.
Modelcombination for event extraction in BioNLP 2011.
InProceedings of the BioNLP Shared Task 2011 Work-shop.Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, TomokoOhta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011.BioNLP Shared Task 2011: Supporting Resources.
InProceedings of the BioNLP Shared Task 2011 Work-shop.Beth M. Sundheim.
1991.
Third message understandingevaluation and conference (MUC-3): Phase 1 statusreport.
In Proceedings of the Speech and Natural Lan-guage Workshop, pages 301?305.Sofie Van Landeghem, Sampo Pyysalo, Tomoko Ohta,and Yves Van de Peer.
2010.
Integration of static re-lations to enhance event extraction from text.
In Pro-ceedings of BioNLP 2010, pages 144?152.Sofie Van Landeghem, Thomas Abeel, Bernard De Baets,and Yves Van de Peer.
2011a.
Detecting entity rela-tions as a supporting task for bio-molecular event ex-traction.
In Proceedings of BioNLP Shared Task 2011Workshop, pages 147?148.Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,and Tapio Salakoski.
2011b.
Evex: a pubmed-scaleresource for homology-based generalization of textmining predictions.
In Proceedings of BioNLP 2011Workshop, pages 28?37.Andreas Vlachos and Mark Craven.
2011.
Biomedicalevent extraction from abstracts and full papers usingsearch-based structured prediction.
In Proceedings ofBioNLP Shared Task 2011 Workshop, pages 36?40.Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-rao, Masayuki Asahara, and Yuji Matsumoto.
2011.Coreference based event-argument relation extractionon biomedical text.
Journal of Biomedical Semantics,2(Suppl 5):S6.108
