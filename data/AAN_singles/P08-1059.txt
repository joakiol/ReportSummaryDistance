Proceedings of ACL-08: HLT, pages 514?522,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsApplying Morphology Generation Models to Machine TranslationKristina ToutanovaMicrosoft ResearchRedmond, WA, USAkristout@microsoft.comHisami SuzukiMicrosoft ResearchRedmond, WA, USAhisamis@microsoft.comAchim RuoppButler Hill GroupRedmond, WA, USAv-acruop@microsoft.comAbstractWe improve the quality of statistical machinetranslation (SMT) by applying models thatpredict word forms from their stems usingextensive morphological and syntactic infor-mation from both the source and target lan-guages.
Our inflection generation models aretrained independently of the SMT system.
Weinvestigate different ways of combining the in-flection prediction component with the SMTsystem by training the base MT system onfully inflected forms or on word stems.
Weapplied our inflection generation models intranslating English into two morphologicallycomplex languages, Russian and Arabic, andshow that our model improves the quality ofSMT over both phrasal and syntax-based SMTsystems according to BLEU and human judge-ments.1 IntroductionOne of the outstanding problems for further improv-ing machine translation (MT) systems is the diffi-culty of dividing the MT problem into sub-problemsand tackling each sub-problem in isolation to im-prove the overall quality of MT.
Evidence for thisdifficulty is the fact that there has been very littlework investigating the use of such independent sub-components, though we started to see some success-ful cases in the literature, for example in word align-ment (Fraser and Marcu, 2007), target language cap-italization (Wang et al, 2006) and case marker gen-eration (Toutanova and Suzuki, 2007).This paper describes a successful attempt to in-tegrate a subcomponent for generating word inflec-tions into a statistical machine translation (SMT)system.
Our research is built on previous work inthe area of using morpho-syntactic information forimproving SMT.
Work in this area is motivated bytwo advantages offered by morphological analysis:(1) it provides linguistically motivated clustering ofwords and makes the data less sparse; (2) it cap-tures morphological constraints applicable on thetarget side, such as agreement phenomena.
This sec-ond problem is very difficult to address with word-based translation systems, when the relevant mor-phological information in the target language is ei-ther non-existent or implicitly encoded in the sourcelanguage.
These two aspects of morphological pro-cessing have often been addressed separately: forexample, morphological pre-processing of the inputdata is a common method of addressing the first as-pect, e.g.
(Goldwater and McClosky, 2005), whilethe application of a target language model has al-most solely been responsible for addressing the sec-ond aspect.
Minkov et al (2007) introduced a wayto address these problems by using a rich feature-based model, but did not apply the model to MT.In this paper, we integrate a model that predictstarget word inflection in the translations of Englishinto two morphologically complex languages (Rus-sian and Arabic) and show improvements in the MToutput.
We study several alternative methods for in-tegration and show that it is best to propagate un-certainty among the different components as shownby other research, e.g.
(Finkel et al, 2006), and insome cases, to factor the translation problem so thatthe baseline MT system can take advantage of thereduction in sparsity by being able to work on wordstems.
We also demonstrate that our independentlytrained models are portable, showing that they canimprove both syntactic and phrasal SMT systems.5142 Related workThere has been active research on incorporatingmorphological knowledge in SMT.
Several ap-proaches use pre-processing schemes, includingsegmentation of clitics (Lee, 2004; Habash and Sa-dat, 2006), compound splitting (Nie?en and Ney,2004) and stemming (Goldwater and McClosky,2005).
Of these, the segmentation approach is dif-ficult to apply when the target language is morpho-logically rich as the segmented morphemes must beput together in the output (El-Kahlout and Oflazer,2006); and in fact, most work using pre-processingfocused on translation into English.
In recentwork, Koehn and Hoang (2007) proposed a generalframework for including morphological features ina phrase-based SMT system by factoring the repre-sentation of words into a vector of morphologicalfeatures and allowing a phrase-based MT system towork on any of the factored representations, whichis implemented in the Moses system.
Though ourmotivation is similar to that of Koehn and Hoang(2007), we chose to build an independent compo-nent for inflection prediction in isolation rather thanfolding morphological information into the maintranslation model.
While this may lead to search er-rors due to the fact that the models are not integratedas tightly as possible, it offers some important ad-vantages, due to the very decoupling of the compo-nents.
First, our approach is not affected by restric-tions on the allowable context size or a phrasal seg-mentation that are imposed by current MT decoders.This also makes the model portable and applicableto different types of MT systems.
Second, we avoidthe problem of the combinatorial expansion in thesearch space which currently arises in the factoredapproach of Moses.Our inflection prediction model is based on(Minkov et al, 2007), who build models to predictthe inflected forms of words in Russian and Arabic,but do not apply their work to MT.
In contrast, wefocus on methods of integration of an inflection pre-diction model with an MT system, and on evaluationof the model?s impact on translation.
Other workclosely related to ours is (Toutanova and Suzuki,2007), which uses an independently trained casemarker prediction model in an English-Japanesetranslation system, but it focuses on the problem ofgenerating a small set of closed class words ratherthan generating inflected forms for each word intranslation, and proposes different methods of inte-gration of the components.3 Inflection prediction modelsThis section describes the task and our model for in-flection prediction, following (Minkov et al, 2007).We define the task of inflection prediction as thetask of choosing the correct inflections of given tar-get language stems, given a corresponding sourcesentence.
The stemming and inflection operationswe use are defined by lexicons.3.1 Lexicon operationsFor each target language we use a lexicon L whichdetermines the following necessary operations:Stemming: returns the set of possible morpholog-ical stems Sw = {s1, ..., sl} for the word w accord-ing to L. 1Inflection: returns the set of surface word formsIw = {i1, ..., im} for the stems Sw according to L.Morphological analysis: returns the set of possiblemorphological analyses Aw = {a1, ..., av} for w. Amorphological analysis a is a vector of categoricalvalues, where each dimension and its possible valuesare defined by L.For the morphological analysis operation, weused the same set of morphological features de-scribed in (Minkov et al, 2007), that is, seven fea-tures for Russian (POS, Person, Number, Gender,Tense, Mood and Case) and 12 for Arabic (POS,Person, Number, Gender, Tense, Mood, Negation,Determiner, Conjunction, Preposition, Object andPossessive pronouns).
Each word is factored intoa stem (uninflected form) and a subset of these fea-tures, where features can have either binary (as inDeterminer in Arabic) or multiple values.
Some fea-tures are relevant only for a particular (set of) part-of-speech (POS) (e.g., Gender is relevant only innouns, pronouns, verbs, and adjectives in Russian),while others combine with practically all categories(e.g., Conjunction in Arabic).
The number of possi-ble inflected forms per stem is therefore quite large:as we see in Table 1 of Section 3, there are on av-erage 14 word forms per stem in Russian and 24 in1Alternatively, stemming can return a disambiguated stemanalysis; in which case the set Sw consists of one item.
Thesame is true with the operation of morphological analysis.515Arabic for our dataset.
This makes the generation ofcorrect forms a challenging problem in MT.The Russian lexicon was obtained by intersectinga general domain lexicon with our training data (Ta-ble 2), and the Arabic lexicon was obtained by run-ning the Buckwalter morphological analyser (Buck-walter, 2004) on the training data.
Contextual dis-ambiguation of morphology was not performed ineither of these languages.
In addition to the formssupposed by our lexicon, we also treated capitaliza-tion as an inflectional feature in Russian, and definedall true-case word variants as possible inflections ofits stem(s).
Arabic does not use capitalization.3.2 TaskMore formally, our task is as follows: given a sourcesentence e, a sequence of stems in the target lan-guage S1, .
.
.
St, .
.
.
Sn forming a translation of e,and additional morpho-syntactic annotations A de-rived from the input, select an inflection yt from itsinflection set It for every stem set St in the targetsentence.3.3 ModelsWe built a Maximum Entropy Markov model for in-flection prediction following (Minkov et al, 2007).The model decomposes the probability of an inflec-tion sequence into a product of local probabilities forthe prediction for each word.
The local probabilitiesare conditioned on the previous k predictions (k isset to four in Russian and two in Arabic in our ex-periments).
The probability of a predicted inflectionsequence, therefore, is given by:p(y | x) =n?t=1p(yt | yt?1...yt?k, xt), yt ?
It,where It is the set of inflections corresponding to St,and xt refers to the context at position t. The con-text available to the task includes extensive morpho-logical and syntactic information obtained from thealigned source and target sentences.
Figure 1 showsan example of an aligned English-Russian sentencepair: on the source (English) side, POS tags andword dependency structure are indicated by solidarcs.
The alignments between English and Russianwords are indicated by the dotted lines.
The de-pendency structure on the Russian side, indicated bysolid arcs, is given by a treelet MT system (see Sec-tion 4.1), projected from the word dependency struc-NN+sg+nom+neuttheDETallocation of resources has completedNN+sg PREP NN+pl AUXV+sg VERB+pastpart?????????????NN+pl+gen+masc????????VERB+perf+pass+neut+sg????????
?raspredelenie resursov zavershenoFigure 1: Aligned English-Russian sentence pair withsyntactic and morphological annotation.ture of English and word alignment information.The features for our inflection prediction modelare binary and pair up predicates on the context(x?, yt?1...yt?k) and the target label (yt).
The fea-tures at a certain position t can refer to any wordin the source sentence, any word stem in the tar-get language, or any morpho-syntactic informationin A.
This is the source of the power of a modelused as an independent component ?
because it doesnot need to be integrated in the main search of anMT decoder, it is not subject to the decoder?s local-ity constraints, and can thus make use of more globalinformation.3.4 Performance on reference translationsTable 1 summarizes the results of applying the in-flection prediction model on reference translations,simulating the ideal case where the translations in-put to our model contain correct stems in correctorder.
We stemmed the reference translations, pre-dicted the inflection for each stem, and measured theaccuracy of prediction, using a set of sentences thatwere not part of the training data (1K sentences wereused for Arabic and 5K for Russian).2 Our modelperforms significantly better than both the randomand trigram language model baselines, and achievesan accuracy of over 91%, which suggests that themodel is effective when its input is clean in its stemchoice and order.
Next, we apply our model in themore noisy but realistic scenario of predicting inflec-tions of MT output sentences.2The accuracy is based on the words in our lexicon.
Wedefine the stem of an out-of-vocabulary (OOV) word to be it-self, so in the MT scenario described below, we will not predictthe word forms for an OOV item, and will simply leave it un-changed.516Russian ArabicRandom 16.4 8.7LM 81.0 69.4Model 91.6 91.0Avg | I | 13.9 24.1Table 1: Results on reference translations (accuracy, %).4 Machine translation systems and dataWe integrated the inflection prediction model withtwo types of machine translation systems: systemsthat make use of syntax and surface phrase-basedsystems.4.1 Treelet translation systemThis is a syntactically-informed MT system, de-signed following (Quirk et al, 2005).
In this ap-proach, translation is guided by treelet translationpairs, where a treelet is a connected subgraph of asyntactic dependency tree.
Translations are scoredaccording to a linear combination of feature func-tions.
The features are similar to the ones used inphrasal systems, and their weights are trained us-ing max-BLEU training (Och, 2003).
There arenine feature functions in the treelet system, includ-ing log-probabilities according to inverted and directchannel models estimated by relative frequency, lex-ical weighting channel models following Vogel etal.
(2003), a trigram target language model, two or-der models, word count, phrase count, and averagephrase size functions.The treelet translation model is estimated usinga parallel corpus.
First, the corpus is word-alignedusing an implementation of lexicalized-HMMs (He,2007); then the source sentences are parsed into adependency structure, and the dependency is pro-jected onto the target side following the heuristicsdescribed in (Quirk et al, 2005).
These aligned sen-tence pairs form the training data of the inflectionmodels as well.
An example was given in Figure 1.4.2 Phrasal translation systemThis is a re-implementation of the Pharaoh trans-lation system (Koehn, 2004).
It uses the samelexicalized-HMM model for word alignment as thetreelet system, and uses the standard extractionheuristics to extract phrase pairs using forward andbackward alignments.
In decoding, the system usesa linear combination of feature functions whoseweights are trained using max-BLEU training.
Thefeatures include log-probabilities according to in-verted and direct channel models estimated by rel-ative frequency, lexical weighting channel models,a trigram target language model, distortion, wordcount and phrase count.4.3 Data setsFor our English-Russian and English-Arabic experi-ments, we used data from a technical (computer) do-main.
For each language pair, we used a set of paral-lel sentences (train) for training the MT system sub-models (e.g., phrase tables, language model), a setof parallel sentences (lambda) for training the com-bination weights with max-BLEU training, a set ofparallel sentences (dev) for training a small numberof combination parameters for our integration meth-ods (see Section 5), and a set of parallel sentences(test) for final evaluation.
The details of these setsare shown in Table 2.
The training data for the in-flection models is always a subset of the training set(train).
All MT systems for a given language pairused the same datasets.Dataset sent pairs word tokens (avg/sent)English-RussianEnglish Russiantrain 1,642K 24,351K (14.8) 22,002K (13.4)lambda 2K 30K (15.1) 27K (13.7)dev 1K 14K (13.9) 13K (13.5)test 4K 61K (15.3) 60K(14.9)English-ArabicEnglish Arabictrain 463K 5,223K (11.3) 4,761K (10.3)lambda 2K 22K (11.1) 20K (10.0)dev 1K 11K (11.1) 10K (10.0)test 4K 44K (11.0) 40K (10.1)Table 2: Data set sizes, rounded up to the nearest 1000.5 Integration of inflection models with MTsystemsWe describe three main methods of integration wehave considered.
The methods differ in the extent towhich the factoring of the problem into two subprob-lems ?
predicting stems and predicting inflections?
is reflected in the base MT systems.
In the firstmethod, the MT system is trained to produce fullyinflected target words and the inflection model canchange the inflections.
In the other two methods, the517MT system is trained to produce sequences of tar-get language stems S, which are then inflected bythe inflection component.
Before we motivate thesemethods, we first describe the general framework forintegrating our inflection model into the MT system.For each of these methods, we assume that theoutput of the base MT system can be viewed as aranked list of translation hypotheses for each sourcesentence e. More specifically, we assume an out-put {S1,S2,.
.
.
,Sm} of m-best translations whichare sequences of target language stems.
The transla-tions further have scores {w1,w2,.
.
.
,wm} assignedby the base MT system.
We also assume that eachtranslation hypothesis Si together with source sen-tence e can be annotated with the annotation A, asillustrated in Figure 1.
We discuss how we convertthe output of the base MT systems to this form in thesubsections below.Given such a list of candidate stem sequences, thebase MT model together with the inflection modeland a language model choose a translation Y?
asfollows:(1) Yi = argmaxY ?i ?Infl(Si)?1logPIM (Y ?i |Si)+?2logPLM (Y ?i ), i = 1 .
.
.
n(2) Y ?
= argmaxi=1...n ?1logPIM (Yi|Si) +?2logPLM (Yi) + ?3wiIn these formulas, the dependency on e and Ais omitted for brevity in the expression for theprobability according to the inflection model PIM .PLM (Y ?i ) is the joint probability of the sequenceof inflected words according to a trigram languagemodel (LM).
The LM used for the integration is thesame LM used in the base MT system that is trainedon fully inflected word forms (the base MT systemtrained on stems uses an LM trained on a stem se-quence).
Equation (1) shows that the model first se-lects the best sequence of inflected forms for eachMT hypothesis Si according to the LM and the in-flection model.
Equation (2) shows that from thesen fully inflected hypotheses, the model then selectsthe one which has the best score, combined withthe base MT score wi for Si.
We should note thatthis method does not represent standard n-best re-ranking because the input from the base MT systemcontains sequences of stems, and the model is gen-erating fully inflected translations from them.
Thusthe chosen translation may not be in the provided n-best list.
This method is more similar to the one usedin (Wang et al, 2006), with the difference that theyuse only 1-best input from a base MT system.The interpolation weights ?
in Equations (1) and(2) as well as the optimal number of translations nfrom the base MT system to consider, given a maxi-mum of m=100 hypotheses, are trained using a sep-arate dataset.
We performed a grid search on thevalues of ?
and n, to maximize the BLEU score ofthe final system on a development set (dev) of 1000sentences (Table 2).The three methods of integration differ in the waythe base MT engine is applied.
Since we always dis-card the choices of specific inflected forms for thetarget stems by converting candidate translations tosequences of stems, it is interesting to know whetherwe need a base MT system that produces fully in-flected translations or whether we can do as wellor better by training the base MT systems to pro-duce sequences of stems.
Stemming the target sen-tences is expected to be helpful for word alignment,especially when the stemming operation is definedso that the word alignment becomes more one-to-one (Goldwater and McClosky, 2005).
In addition,stemming the target sentences reduces the sparsityin the translation tables and language model, and islikely to impact positively the performance of an MTsystem in terms of its ability to recover correct se-quences of stems in the target.
Also, machine learn-ing tells us that solving a more complex problemthan we are evaluated on (in our case for the baseMT, predicting stems together with their inflectionsinstead of just predicting stems) is theoretically un-justified (Vapnik, 1995).However, for some language pairs, stemming onelanguage can make word alignment worse, if itleads to more violations in the assumptions of cur-rent word alignment models, rather than making thesource look more like the target.
In addition, using atrigram LM on stems may lead to larger violations ofthe Markov independence assumptions, than using atrigram LM on fully inflected words.
Thus, if we ap-ply the exact same base MT system to use stemmedforms in alignment and/or translation, it is not a pri-ori clear whether we would get a better result than ifwe apply the system to use fully inflected forms.5185.1 Method 1In this method, the base MT system is trained inthe usual way, from aligned pairs of source sen-tences and fully inflected target sentences.
The in-flection model is then applied to re-inflect the 1-bestor m-best translations and to select an output trans-lation.
The hypotheses in the m-best output from thebase MT system are stemmed and the scores of thestemmed hypotheses are assumed to be equal to thescores of the original ones.3 Thus we obtain input ofthe needed form, consisting of m sequences of targetlanguage stems along with scores.For this and other methods, if we are workingwith an m-best list from the treelet system, everytranslation hypothesis contains the annotations Athat our model needs, because the system maintainsthe alignment, parse trees, etc., as part of its searchspace.
Thus we do not need to do anything furtherto obtain input of the form necessary for applicationof the inflection model.For the phrase-based system, we generated theannotations needed by first parsing the source sen-tence e, aligning the source and candidate transla-tions with the word-alignment model used in train-ing, and projected the dependency tree to the targetusing the algorithm of (Quirk et al, 2005).
Note thatit may be better to use the word alignment main-tained as part of the translation hypotheses duringsearch, but our solution is more suitable to situationswhere these can not be easily obtained.For all methods, we study two settings for integra-tion.
In the first, we only consider (n=1) hypothesesfrom the base MT system.
In the second setting, weallow the model to use up to 100 translations, andto automatically select the best number to use.
Asseen in Table 3, (n=16) translations were chosen forRussian and as seen in Table 5, (n=2) were chosenfor Arabic for this method.5.2 Method 2In this method, the base MT system is trained to pro-duce sequences of stems in the target language.
Themost straightforward way to achieve this is to stemthe training parallel data and to train the MT sys-tem using this input.
This is our Method 3 described3It may be better to take the max of the scores for a stemsequence occurring more than once in the list, or take the log-sum-exp of the scores.below.
We formulated Method 2 as an intermedi-ate step, to decouple the impact of stemming at thealignment and translation stages.In Method 2, word alignment is performed us-ing fully inflected target language sentences.
Afteralignment, the target language is stemmed and thebase MT systems?
sub-models are trained using thisstemmed input and alignment.
In addition to thisword-aligned corpus the MT systems use anotherproduct of word alignment: the IBM model 1 trans-lation tables.
Because the trained translation tablesof IBM model 1 use fully inflected target words, wegenerated stemmed versions of the translation tablesby applying the rules of probability.5.3 Method 3In this method the base MT system produces se-quences of target stems.
It is trained in the same wayas the baseline MT system, except its input paralleltraining data are preprocessed to stem the target sen-tences.
In this method, stemming can impact wordalignment in addition to the translation models.6 MT performance resultsBefore delving into the results for each method, wediscuss our evaluation measures.
For automaticallymeasuring performance, we used 4-gram BLEUagainst a single reference translation.
We also reportoracle BLEU scores which incorporate two kinds oforacle knowledge.
For the methods using n=1 trans-lation from a base MT system, the oracle BLEUscore is the BLEU score of the stemmed translationcompared to the stemmed reference, which repre-sents the upper bound achievable by changing onlythe inflected forms (but not stems) of the words in atranslation.
For models using n > 1 input hypothe-ses, the oracle also measures the gain from choos-ing the best possible stem sequence in the provided(m=100-best) hypothesis list, in addition to choos-ing the best possible inflected forms for these stems.For the models in the tables, even if, say, n=16 waschosen in parameter fitting, the oracle is measuredon the initially provided list of 100-best.6.1 English-Russian treelet systemTable 3 shows the results of the baseline and themodel using the different methods for the treeletMT system on English-Russian.
The baseline is the519Model BLEU Oracle BLEUBase MT (n=1) 29.24 -Method 1 (n=1) 30.44 36.59Method 1 (n=16) 30.61 45.33Method 2 (n=1) 30.79 37.38Method 2 (n=16) 31.24 48.48Method 3 (n=1) 31.42 38.06Method 3 (n=32) 31.80 49.19Table 3: Test set performance for English-to-Russian MT(BLEU) results by model using a treelet MT system.treelet system described in Section 4.1 and trainedon the data in Table 2.We can see that Method 1 results in a good im-provement of 1.2 BLEU points, even when usingonly the best (n = 1) translation from the baseline.The oracle improvement achievable by predictinginflections is quite substantial: more than 7 BLEUpoints.
Propagating the uncertainty of the baselinesystem by using more input hypotheses consistentlyimproves performance across the different methods,with an additional improvement of between .2 and.4 BLEU points.From the results of Method 2 we can see that re-ducing sparsity at translation modeling is advanta-geous.
Both the oracle BLEU of the first hypothe-sis and the achieved performance of the model im-proved; the best performance achieved by Method 2is .63 points higher than the performance of Method1.
We should note that the oracle performance forMethod 2, n > 1 is measured using 100-best lists oftarget stem sequences, whereas the one for Method1 is measured using 100-best lists of inflected targetwords.
This can be a disadvantage for Method 1,because a 100-best list of inflected translations actu-ally contains about 50 different sequences of stems(the rest are distinctions in inflections).
Neverthe-less, even if we measure the oracle for Method 2using 40-best, it is higher than the 100-best oracleof Method 1.
In addition, it appears that using a hy-pothesis list larger than n > 1=100 is not be helpfulfor our method, as the model chose to use only up to32 hypotheses.Finally, we can see that using stemming at theword alignment stage further improved both the or-acle and the achieved results.
The performance ofthe best model is 2.56 BLEU points better than thebaseline.
Since stemming in Russian for the mostpart removes properties of words which are not ex-pressed in English at the word level, these resultsare consistent with previous results using stemmingto improve word alignment.
From these results, wealso see that about half of the gain from using stem-ming in the base MT system came from improvingword alignment, and half came from using transla-tion models operating at the less sparse stem level.Overall, the improvement achieved by predictingmorphological properties of Russian words with afeature-rich component model is substantial, giventhe relatively large size of the training data (1.6 mil-lion sentences), and indicates that these kinds ofmethods are effective in addressing the problemsin translating morphology-poor to morphology-richlanguages.6.2 English-Russian phrasal systemFor the phrasal system, we performed integrationonly with Method 1, using the top 1 or 100-best translations.
This is the most straightforwardmethod for combining with any system, and we ap-plied it as a proof-of-concept experiment.Model BLEU Oracle BLEUBase MT (n=1) 36.00 -Method 1 (n=1) 36.43 42.33Method 1 (n=100) 36.72 55.00Table 4: Test set performance for English-to-Russian MT(BLEU) results by model using a phrasal MT system.The phrasal MT system is trained on the samedata as the treelet system.
The phrase size and dis-tortion limit were optimized (we used phrase size of7 and distortion limit of 3).
This system achieves asubstantially better BLEU score (by 6.76) than thetreelet system.
The oracle BLEU score achievableby Method 1 using n=1 translation, though, is still6.3 BLEU point higher than the achieved BLEU.Our model achieved smaller improvements for thephrasal system (0.43 improvement for n=1 transla-tions and 0.72 for the selected n=100 translations).However, this improvement is encouraging given thelarge size of the training data.
One direction forpotentially improving these results is to use wordalignments from the MT system, rather than usingan alignment model to predict them.520Model BLEU Oracle BLEUBase MT (n=1) 35.54 -Method 1 (n=1) 37.24 42.29Method 1 (n=2) 37.41 52.21Method 2 (n=1) 36.53 42.46Method 2 (n=4) 36.72 54.74Method 3 (n=1) 36.87 42.96Method 3 (n=2) 36.92 54.90Table 5: Test set performance for English-to-Arabic MT(BLEU) results by model using a treelet MT system.6.3 English-Arabic treelet systemThe Arabic system also improves with the use of ourmode: the best system (Method 1, n=2) achievesthe BLEU score of 37.41, a 1.87 point improve-ment over the baseline.
Unlike the case of Rus-sian, Method 2 and 3 do not achieve better resultsthan Method 1, though the oracle BLEU score im-proves in these models (54.74 and 54.90 as opposedto 52.21 of Method 1).
We do notice, however, thatthe oracle improvement for the 1-best analysis ismuch smaller than what we obtained in Russian.We have been unable to closely diagnose why per-formance did not improve using Methods 2 and 3so far due to the absence of expertise in Arabic, butone factor we suspect is affecting performance themost in Arabic is the definition of stemming: theeffect of stemming is most beneficial when it is ap-plied specifically to normalize the distinctions notexplicitly encoded in the other language; it may hurtperformance otherwise.
We believe that in the caseof Arabic, this latter situation is actually happen-ing: grammatical properties explicitly encoded inEnglish (e.g., definiteness, conjunction, pronominalclitics) are lost when the Arabic words are stemmed.This may be having a detrimental effect on the MTsystems that are based on stemmed input.
Furtherinvestigation is necessary to confirm this hypothesis.6.4 Human evaluationIn this section we briefly report the results of humanevaluation on the output of our inflection predictionsystem, as the correlation between BLEU scores andhuman evaluation results is not always obvious.
Wecompared the output of our component against thebest output of the treelet system without our com-ponent.
We evaluated the following three scenarios:(1) Arabic Method 1 with n=1, which correspondsto the best performing system in BLEU according toTable 5; (2) Russian, Method 1 with n=1; (3) Rus-sian, Method 3 with n=32, which corresponds to thebest performing system in BLEU in Table 3.
Notethat in (1) and (2), the only differences in the com-pared outputs are the changes in word inflections,while in (3) the outputs may differ in the selectionof the stems.In all scenarios, two human judges (native speak-ers of these languages) evaluated 100 sentences thathad different translations by the baseline system andour model.
The judges were given the referencetranslations but not the source sentences, and wereasked to classify each sentence pair into three cate-gories: (1) the baseline system is better (score=-1),(2) the output of our model is better (score=1), or (3)they are of the same quality (score=0).human eval score BLEU diffArabic Method 1 0.1 1.9Russian Method 1 0.255 1.2Russian Method 3 0.26 2.6Table 6: Human evaluation resultsTable 6 shows the results of the averaged, aggre-gated score across two judges per evaluation sce-nario, along with the BLEU score improvementsachieved by applying our model.
We see that in allcases, the human evaluation scores are positive, indi-cating that our models produce translations that arebetter than those produced by the baseline system.
4We also note that in Russian, the human evaluationscores are similar for Method 1 and 3 (0.255 and0.26), though the BLEU score gains are quite differ-ent (1.2 vs 2.6).
This may be attributed to the factthat human evaluation typically favors the scenariowhere only word inflections are different (Toutanovaand Suzuki, 2007).7 Conclusion and future workWe have shown that an independent model of mor-phology generation can be successfully integratedwith an SMT system, making improvements in bothphrasal and syntax-based MT.
In the future, wewould like to include more sophistication in the de-sign of a lexicon for a particular language pair basedon error analysis, and extend our pre-processing toinclude other operations such as word segmentation.4However, the improvement in Arabic is not statistically sig-nificant on this 100 sentence set.521ReferencesTim Buckwalter.
2004.
Buckwalter arabic morphologicalanalyzer version 2.0.Ilknur Durgar El-Kahlout and Kemal Oflazer.
2006.
Ini-tial explorations in English to Turkish statistical ma-chine translation.
In NAACL workshop on statisticalmachine translation.Jenny Finkel, Christopher Manning, and Andrew Ng.2006.
Solving the problem of cascading errors: ap-proximate Bayesian inference for linguistic annotationpipelines.
In EMNLP.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine transla-tion.
Computational Linguistics, 33(3):293?303.Sharon Goldwater and David McClosky.
2005.
Improv-ing statistical MT through morphological analysis.
InEMNLP.Nizar Habash and Fatiha Sadat.
2006.
Arabic prepro-cessing schemes for statistical machine translation.
InHLT-NAACL.Xiaodong He.
2007.
Using word-dependent transitionmodels in HMM based word alignment for statisticalmachine translation.
In ACL Workshop on StatisticalMachine Translation.Philipp Koehn and Hieu Hoang.
2007.
Factored transla-tion models.
In EMNLP-CoNNL.Philipp Koehn.
2004.
Pharaoh: a beam search decoder forphrase-based statistical machine translation models.
InAMTA.Young-Suk Lee.
2004.
Morphological analysis for statis-tical machine translation.
In HLT-NAACL.Einat Minkov, Kristina Toutanova, and Hisami Suzuki.2007.
Generating complex morphology for machinetranslation.
In ACL.Sonja Nie?en and Hermann Ney.
2004.
Statistical ma-chine translation with scarce resources using morpho-syntactic information.
Computational Linguistics,30(2):181?204.Franz Och.
2003.
Minimum error rate training for statis-tical machine translation.
In ACL.Chris Quirk, Arul Menezes, and Colin Cherry.
2005.Dependency tree translation: Syntactically informedphrasal SMT.
In ACL.Kristina Toutanova and Hisami Suzuki.
2007.
Generatingcase markers in machine translation.
In NAACL-HLT.Vladimir Vapnik.
1995.
The nature of Statistical Learn-ing Theory.
Springer-Verlag.Wei Wang, Kevin Knight, and Daniel Marcu.
2006.
Cap-italizing machine translation.
In HLT-NAACL.522
