Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 51?54,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA Method for Unsupervised Broad-CoverageLexical Error Detection and CorrectionNai-Lung Tsao David WibleGraduate Institute of Learning and Instruction Graduate Institute of Learning and InstructionNational Central University National Central UniversityJhongli City, Taoyuan County 32001, Taiwan Jhongli City, Taoyuan County 32001, Taiwanbeaktsao@gmail.com Wible45@yahoo.comAbstractWe describe and motivate an unsupervisedlexical error detection and correction algo-rithm and its application in a tool called Lex-bar appearing as a query box on the Webbrowser toolbar or as a search engine inter-face.
Lexbar accepts as user input candidatestrings of English to be checked for accept-ability and, where errors are detected, offerscorrections.
We introduce the notion of hy-brid n-gram and extract these from BNC asthe knowledgebase against which to compareuser input.
An extended notion of edit dis-tance is used to identify most likely candi-dates for correcting detected errors.
Resultsare illustrated with four types of errors.1 IntroductionWe describe and motivate an unsupervised lexicalerror detection and correction algorithm and itsapplication in a tool called Lexbar appearing as aquery box in a web-based corpus search engine oron the Web browser toolbar.
The tool is intendedas a proxy for search engines in the common prac-tice where users put search engines to use as errorcheckers.
A problem with this use of search en-gines like Google is that such searches commonlyprovide false positives, hits for strings that containerrors.
Lexbar accepts as user input candidatestrings of English to be checked for acceptabilityand, where errors are detected, offers corrections.2 Related WorkAmong the many works on error detection, re-cently unsupervised error detection approacheshave been proposed, such as [Chodorow and Lea-cock, 2000] and [Quixal and Badia 2008].
Theseuse contextual features and statistical word asso-ciation measurement to decide if the detected bi-gram or trigram is an error or not.
To ourknowledge, such unsupervised methods have notbeen applied in error correction.
[Gamon et  al2008] and [Felice and Pulman 2008] propose un-supervised approaches to build a probabilisticmodel for detecting errors (prepositions and arti-cles) and providing correct answers.
They alsotypically focus on a particular type of error, usu-ally limited to a specific word class such as prepo-sition errors, often in a pre-determinedparadigmatic slot.
Our approach reported here isunsupervised in both detection and correction andis not tailored to a specific target error subtype ortargeted to a specific position in a string.
Moregenerally the family of error types suitable for thisapproach are lexical or lexico-grammatical errorssince detection and correction are based on pat-terns of word use detected statistically.
At the coreof our approach is a bank of what we call ?hybridn-grams?
extracted from BNC to serve as the tar-get knowledge against which learner input iscompared for detection and correction.
We illus-trate the single algorithm with results on four dif-ferent categories of errors.3 Overview of the AlgorithmThe Lexbar application consists of two maincomponents: (1) the target language knowledge-base of hybrid n-grams that serves as the standardagainst which learner production is examined forerrors, and (2) the error detection and correctionalgorithm that uses this knowledgebase to evalu-51ate learner production through matching and editdistance.
Relatively broad coverage is achievedfrom one algorithm since no specific error type istargeted but violations of word behaviors patterns.Typically, n-grams are contiguous sequences oflemmas or specific word forms.
Using traditionaln-grams and string matching against them as ameans of error detection leads to weak precisionsince the absence of a specific n-gram in a stan-dard corpus does not render it an error.
To addressthis limitation, we extend the notion of n-gram toinclude in the string not only lemmas or wordforms but parts-of-speech as well.
For example,the chunk point of view can be part of a longerstring from my point of view.
Here, the prepositionfrom is non-substitutable whereas the possessivepronoun my can be replaced by others of the samePOS (his/her/your/etc.).
Hence, replacing the oneresults in an error (*in my point of view1) whilereplacing the other is fine (from her/his/their/ourpoint of view).
The purpose of hybrid n-grams isto introduce the flexibility to capture the appropri-ate level of abstraction for each slot in a lexicalchunk.
Hybrid n-grams permit any combination ofword forms, lemmas, POSs in a string (see detailsbelow).
Thus the hybrid n-gram for from my pointof view is from [dps] point of view2.For a string of input submitted for error check-ing, the algorithm first does a matching operationbetween the input string and the hybrid n-grambank.
The second step for input is finding hybridn-grams which nearly match the input, using editdistance to measure nearness or similarity.
Hybridn-grams with a distance of 1 or less from the inputstring are candidates as correction suggestions andare ranked, least distant from the input stringranked as top correction suggestion.4 The Knowledgebase: Hybrid N-gramsAs mentioned in Section 3, a hybrid n-gram bankwill be needed.
In our model, each slot has fourlevels of representation to choose from: wordform (enjoys but not enjoy or enjoying, etc);lemma (representing all word forms of that lex-eme, e.g., enjoy, enjoys, and enjoyed, etc); de-tailed POS (CLAWS5 with 46 different POSs);1We use * to represent the error part in n-gram string.2We use [] to represent POS categories.
[dps] is theCLAWS5 tag for possessive pronoun.rough POS (9 different POSs)3.
The main chal-lenge is to extract hybrid n-grams which are theoptimum combination of representations for eachslot to represent a lexical chunk or pattern.
Onekey to this is a pruning method (described below).Clearly, compared with traditional n-gram extrac-tion, the size of our hybrid n-gram bank size willbe extremely large if we save all the combinationsthat can be generated for each n-gram.
Consider-ing the example from my point of view and settingpoint as the target word, if we only extract hybrid5-gram strings for it, we will get 2*44=512 (twoforms of noun point and four forms of others) dif-ferent hybrid 5-grams.
This entails many disad-vantages, for example in storage space andprocessing time.
Therefore, we apply severalpruning approaches to keep only useful hybrid n-grams in the bank.
Another motivation for pruningthe bank is to reach optimum recall and precision.The choice of which hybrid n-grams to retain in ordiscard from the bank directly determines whichinput strings would be judged as errors and whatcandidate corrections would be generated for er-rors.
We illustrate the effects of pruning below.The first criterion for pruning is frequency.Only hybrid n-grams with a frequency greaterthan the threshold are saved.
The second criterionis called subset pruning.
There will be overlapamong different hybrid n-grams.
For example, thechunk from my point of view could be representedby dozens of hybrid n-grams.
Two of them are: (1)from [dps] point of view, and (2) from my point ofview.
Notice an input string from her point of viewwould match (1) but not (2).
Here the optimum n-gram is (1) because it includes all cases coveredby (2) but other acceptable ones as well.
Crucially,it is not the case that the more general hybrid n-gram will always yield the more optimum results,however.
This must be determined case by case.Consider the first slot in the same chunk from mypoint of view.
The following two versions couldrepresent that chunk: (3) from [dps] point of viewand (4) [prp] [dps] point of view4.
Notice here,however, that it will be the more specific ratherthan the more inclusive version that is to be pre-ferred.
(3) specifies the exact preposition for thechunk whereas (4) would accept any preposition3Rough POS includes verb, noun, adj, adv, conj, interj, prep,pron, vm0.4[prp] is the CLAWS5 tag for preposition.52(or [prp]) occurring in the first slot.
But indeedfrom is not freely substitutable in this chunk (cf*in my point of view).
Thus in each slot in eachchunk, pruning checks each potential hybrid n-gram against the target corpus to determine statis-tically the n-grams that capture the optimum de-gree of substitutability or frozenness for each slot.This creates an extremely flexible means ofrepresenting the knowledgebase.
Consider verbcomplement selection.
In examples such as Theyenjoy swimming, the level of generalization is dif-ferent for the governing verb slot (enjoy) on theone hand and the complement (swimming) on theother.
The right generalization for the complementis a specific verb form but not specific to any oneverb.
This slot is captured under the CLAWS5POS [vvg] 5 , thus permitting enjoy swim-ming/reading/sleeping, but not enjoy toswim/swam and so on.
Unlike the complement,the governing verb slot here is a specific lexeme(enjoy swimming but not hope swimming; cf hopeto swim) and moreover, it permits that lexeme inany of its word forms (enjoy/enjoying/enjoyedswimming).
A hybrid n-gram representation hasthe power to capture these different levels of gen-eralization and restriction in one representation.Here is how pruning is done.
First, we set a fil-ter factor ?, where 0<?<1.
Assume x and y aretwo hybrid n-grams and len(x)=len(y).
If x ?
y andyx  ?
?6, we will eliminate y from bank.
Forexample, for the two 5-grams x=from [dps] pointof view and y=[prp] [dps] point of view, obviouslyx ?
y because from is a kind of [prp] (preposition).If we set the filter factor ?=80% and yx >?, ywill be not included in the hybrid n-gram bank.For example from 100M-word BNC, before prun-ing, there are 110K hybrid n-grams containingtarget lemma point.
After pruning, there are only5K useful hybrid n-grams left.5 The Edit Distance Algorithm for ErrorDetection and Correction5.1 Error DetectionWe apply a simple edit distance for error detectionby comparing user input n-grams and standard5[vvg] is the CLAWS5 tag for gerund.6x  means the frequency of x in BNC.hybrid n-gram in the bank.
The approaches arebriefly summarized and short examples given inthe following:Step 1: POS tag the user input string and get alhybrid n-grams that can represent that string.
Forexample, a user inputs in my point of view andthen [prp] my point of view, [prp] [dps] point ofview, in [dps] point of view, in my point of[nn1]?
etc.
will be generated.
Let C denote theentire set of hybrid n-grams generated from aninstance of user input.Step 2: Search all hybrid n-grams in the targetknowledgebase containing point or view, whichare the content words in user input.
Let S denoteall of the target hybrid n-grams containing pointor view.Step 3: Compute the edit distance d betweenevery element in C and S. If ?
d=0 in (C, S), weassume the user input n-gram is correct.
If ?
d>1in (C, S), our system will ignore this case and pro-vide nothing.
If ?
d=1, we assume the user inputmight be wrong and the system will enter the errorcorrection procedure.For efficiency?s sake in Step 2, the hybrid n-grams are indexed by content words.
We useLevenshtein?s edit distance algorithm [Leven-shtein 1996] in Step 3.
It indicates the differencebetween user input and standard n-grams in threeways: ?substitute relation,?
i.e., two n-grams arethe same length and identical except for one slot.
?Delete relation?
and ?insert relation?
hold be-tween two different length n-grams.
In this paperwe consider only the ?substitute relation,?
such asin my point of view and from my point of view.This limits edit distance computing to pairs of n-grams of the same length (e.g.
5-gram to 5-gram).5.2 Error CorrectionThe system identifies correction candidates from Sas those with edit distance d=1 from some mem-ber(s) in C. Once the system gets several correc-tion candidates for an input string whose editdistances from user input are 1, we have to decidethe ranking of the correct candidates by a valuecalled weighted edit distance.
Weighted edit dis-tance can identify more appropriate correct n-grams for the user.
Imagine a case where an n-gram from C and an n-gram from S show a substi-tution relation.
Assume u is the differing elementin the C n-gram and v is its counterpart in the S n-53gram.
Weighted edit distance between these two iscomputed by the following rules:Rule 1: If u and v are both word-forms and aredifferent word-forms of the same lemma (for ex-ample enjoyed and enjoying), given distance ?.Rule 2: If u and v are both members ofCLAWS5 POS and their rough POS are the same,given distance ?7.Rule 3: If u and v are both function words, givedistance ?.Rule 4: If u and v are both content word, givedistance ?.We set ?<?
and ?<?.
Correct candidate withlower weighted distance makes itself more appro-priate for suggestion.
For example, before weight-ing, the error string pay attention on gets twodistance 1 correct candidates pay attention to andfocus attention on.
Weighting will give pay atten-tion to a lower weighted distance because on andto are function words whereas focus and pay arecontent words.6 Experimental ResultFour types of errors shown in Table 1 are exam-ined for our detection and correction algorithm.Error string Algorithm result Correction sug-gested to userPrepositionhave a look *of have a look at have a look atI am interested*of[pnp] be interested in I am interested in*in my point ofviewfrom [dps] point of view from my point ofviewpay attention*onpay attention topay attention topay attention toWe can discuss*about.we [vm0] discuss itwe [vm0] discuss[noun]we [vm0] discuss [av0]we can discuss itwe can discuss[noun]we can discuss{adv}Adjectival participlesHe is*confusing with[pnp] be confused [prp] He is confusedwithI am*interesting in[pnp] be interested in I am interested inI am *excitingabout[pnp] be excited [prp] I am excited aboutVerb formHe wants*reading.he wants [vvt]he want [vvt]He wants to readI enjoy *toread.i enjoy [vvg]i enjoy [vvg]I enjoy reading7Recall we use two levels of POS tagging in our hybrid n-grams: 1.
The detailed one is CLAWS5 with 46 tags.
2.
Therough or simple tag set of 9 tags.let them *tostay.let them [vvi]let them [vvi]let them staymake him *toleavemake him [vvi]make him [vvi]make him leavemust let them*to stay[vm0] let them [vvi] must let them stayspend time tounderstandspend time [vvg] spend time under-standingwill make him*to leavewill make [pnp] [vvi] will make himleaveMissing beI* afraid of be afraid of[adv] afraid of[av0] afraid ofbe afraid of[adv]afraid of[adj] afraid ofThey* aware of be aware of[av0] aware ofbe aware of[adv]aware ofTable 1: Four error types and their examples with cor-rect suggestions.7 ConclusionWe propose an algorithm for unsupervised lexicalerror detection and correction and apply it to auser tool called Lexbar.
This is a work-in-progressreport, and we have not yet run full testing with alarge data set, such as a learner corpus.
Howeverthe early stage experimental results show promise,especially its broad coverage over different errortypes compared to error-specific approaches.AcknowledgmentsThe work described in this paper was partiallysupported by the grants from the National ScienceCouncil, Taiwan (Project Nos.
96-2524-S-008-003- and 98-2511-S-008-002-MY2)ReferenceMartin Chodorow and Claudia Leacock 2000.
An un-supervised method for detecting grammatical errors.Proceedings of the 1st conference of NAACL, pages140?147.Rachele De Felice and Stephen G. Pulman 2008.Automatic detection of preposition errors in learnerwriting.
CALICO AALL Workshop.M.
Gamon, J. Gao, C. Brockett, A. Klementiev, W. B.Dolan, D. Belenko, and L. Vanderwende 2008.
Us-ing Contextual Speller Techniques and LanguageModeling for ESL Error Correction.
Proceedings ofIJCNLP.V.
I. Levenshtein 1966.
Binary codes capable of cor-recting deletions, insertions, and reversals.
SovietPhysics Doklady, 10:707?710.Mart?
Quixal and Toni Badia 2008.
Exploiting unsu-pervised techniques to predict EFL learner errors.CALICO AALL Workshop.54
