Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 70?77,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsThe CMU Machine Translation Systems at WMT 2013:Syntax, Synthetic Translation Options, and Pseudo-ReferencesWaleed Ammar Victor Chahuneau Michael Denkowski Greg HannemanWang Ling Austin Matthews Kenton Murray Nicola Segall Yulia TsvetkovAlon Lavie Chris Dyer?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 USA?Corresponding author: cdyer@cs.cmu.eduAbstractWe describe the CMU systems submit-ted to the 2013 WMT shared task in ma-chine translation.
We participated in threelanguage pairs, French?English, Russian?English, and English?Russian.
Ourparticular innovations include: a label-coarsening scheme for syntactic tree-to-tree translation and the use of specializedmodules to create ?synthetic translationoptions?
that can both generalize beyondwhat is directly observed in the paralleltraining data and use rich source languagecontext to decide how a phrase shouldtranslate in context.1 IntroductionThe MT research group at Carnegie Mellon Uni-versity?s Language Technologies Institute par-ticipated in three language pairs for the 2013Workshop on Machine Translation shared trans-lation task: French?English, Russian?English,and English?Russian.
Our French?English sys-tem (?3) showcased our group?s syntactic sys-tem with coarsened nonterminal types (Hanne-man and Lavie, 2011).
Our Russian?English andEnglish?Russian system demonstrate a new multi-phase approach to translation that our group is us-ing, in which synthetic translation options (?4)to supplement the default translation rule inven-tory that is extracted from word-aligned trainingdata.
In the Russian-English system (?5), we useda CRF-based transliterator (Ammar et al 2012)to propose transliteration candidates for out-of-vocabulary words, and used a language modelto insert or remove common function words inphrases according to an n-gram English languagemodel probability.
In the English?Russian system(?6), we used a conditional logit model to predictthe most likely inflectional morphology of Rus-sian lemmas, conditioning on rich source syntac-tic features (?6.1).
In addition to being able togenerate inflected forms that were otherwise unob-served in the parallel training data, the translationsoptions generated in this matter had features re-flecting their appropriateness given much broadersource language context than usually would havebeen incorporated in current statistical MT sys-tems.For our Russian?English system, we addition-ally used a secondary ?pseudo-reference?
transla-tion when tuning the parameters of our Russian?English system.
This was created by automaticallytranslating the Spanish translation of the provideddevelopment data into English.
While the outputof an MT system is not always perfectly gram-matical, previous work has shown that secondarymachine-generated references improve translationquality when only a single human reference isavailable when BLEU is used as an optimizationcriterion (Madnani, 2010; Dyer et al 2011).2 Common System ComponentsThe decoder infrastructure we used was cdec(Dyer et al 2010).
Only the constrained dataresources provided for the shared task were usedfor training both the translation and languagemodels.
Word alignments were generated us-ing the Model 2 variant described in Dyer et al(2013).
Language models used modified Kneser-Ney smoothing estimated using KenLM (Heafield,2011).
Translation model parameters were dis-criminatively set to optimize BLEU on a held-outdevelopment set using an online passive aggres-sive algorithm (Eidelman, 2012) or, in the case of70the French?English system, using the hypergraphMERT algorithm and optimizing towards BLEU(Kumar et al 2009).
The remainder of the paperwill focus on our primary innovations in the vari-ous system pairs.3 French-English Syntax SystemOur submission for French?English is a tree-to-tree translation system that demonstrates severalinnovations from group?s research on SCFG-basedtranslation.3.1 Data SelectionWe divided the French?English training data intotwo categories: clean data (Europarl, News Com-mentary, UN Documents) totaling 14.8 millionsentence pairs, and web data (Common Crawl,Giga-FrEn) totaling 25.2 million sentence pairs.To reduce the volume of data used, we filterednon-parallel and other unhelpful segments accord-ing to the technique described by Denkowski et al(2012).
This procedure uses a lexical translationmodel learned from just the clean data, as well assource and target n-gram language models to com-pute the following feature scores:?
French and English 4-gram log likelihood (nor-malized by length);?
French?English and English?French lexicaltranslation log likelihood (normalized bylength); and,?
Fractions of aligned words under the French?English and English?French models.We pooled previous years?
WMT news test setsto form a reference data set.
We computed thesame features.
To filter the web data, we retainedonly sentence for which each feature score wasno lower than two standard deviations below themean on the reference data.
This reduced the webdata from 25.2 million to 16.6 million sentencepairs.
Parallel segments from all parts of the datathat were blank on either side, were longer than 99tokens, contained a token of more than 30 charac-ters, or had particularly unbalanced length ratioswere also removed.
After filtering, 30.9 millionsentence pairs remained for rule extraction: 14.4million from the clean data, and 16.5 million fromthe web data.3.2 Preprocessing and Grammar ExtractionOur French?English system uses parse trees inboth the source and target languages, so tokeniza-tion in this language pair was carried out to matchthe tokenizations expected by the parsers we used(English data was tokenized with the Stanford to-kenizer for English and an in-house tokenizer forFrench that targets the tokenization used by theBerkeley French parser).
Both sides of the par-allel training data were parsed using the Berkeleylatent variable parser.Synchronous context-free grammar rules wereextracted from the corpus following the method ofHanneman et al(2011).
This decomposes eachtree pair into a collection of SCFG rules by ex-haustively identifying aligned subtrees to serve asrule left-hand sides and smaller aligned subtreesto be abstracted as right-hand-side nonterminals.Basic subtree alignment heuristics are similar tothose by Galley et al(2006), and composed rulesare allowed.
The computational complexity is heldin check by a limit on the number of RHS elements(nodes and terminals), rather than a GHKM-stylemaximum composition depth or Hiero-style max-imum rule span.
Our rule extractor also allows?virtual nodes,?
or the insertion of new nodes inthe parse tree to subdivide regions of flat struc-ture.
Virtual nodes are similar to the A+B ex-tended categories of SAMT (Zollmann and Venu-gopal, 2006), but with the added constraint thatthey may not conflict with the surrounding treestructure.Because the SCFG rules are labeled with non-terminals composed from both the source and tar-get trees, the nonterminal inventory is quite large,leading to estimation difficulties.
To deal withthis, we automatically coarsening the nonterminallabels (Hanneman and Lavie, 2011).
Labels areagglomeratively clustered based on a histogram-based similarity function that looks at what tar-get labels correspond to a particular source labeland vice versa.
The number of clusters used is de-termined based on spikes in the distance betweensuccessive clustering iterations, or by the numberof source, target, or joint labels remaining.
Start-ing from a default grammar of 877 French, 2580English, and 131,331 joint labels, we collapsedthe label space for our WMT system down to 50French, 54 English, and 1814 joint categories.11Selecting the stopping point still requires a measure ofintuition.
The label set size of 1814 chosen here roughly cor-responds to the number of joint labels that would exist in thegrammar if virtual nodes were not included.
This equivalencehas worked well in practice in both internal and published ex-periments on other data sets (Hanneman and Lavie, 2013).71Extracted rules each have 10 features associatedwith them.
For an SCFG rule with source left-hand side `s, target left-hand side `t, source right-hand side rs, and target right-hand side rt, theyare:?
phrasal translation log relative frequencieslog f(rs | rt) and log f(rt | rs);?
labeling relative frequency log f(`s, `t | rs, rt)and generation relative frequencylog f(rs, rt | `s, `t);?
lexical translation log probabilities log plex(rs |rt) and log plex(rt | rs), defined similarly toMoses?s definition;?
a rarity score exp( 1c )?1exp(1)?1 for a rule with frequencyc (this score is monotonically decreasing in therule frequency); and,?
three binary indicator features that markwhether a rule is fully lexicalized, fully abstract,or a glue rule.Grammar filtering.
Even after collapsing la-bels, the extracted SCFGs contain an enormousnumber of rules ?
660 million rule types from justunder 4 billion extracted instances.
To reduce thesize of the grammar, we employ a combination oflossless filtering and lossy pruning.
We first pruneall rules to select no more than the 60 most fre-quent target-side alternatives for any source RHS,then do further filtering to produce grammars foreach test sentence:?
Lexical rules are filtered to the sentence level.Only phrase pairs whose source sides match thetest sentence are retained.?
Abstract rules (whose RHS are all nontermi-nals) are globally pruned.
Only the 4000 mostfrequently observed rules are retained.?
Mixed rules (whose RHS are a mix of terminalsand nonterminals) must match the test sentence,and there is an additional frequency cutoff.After this filtering, the number of completely lex-ical rules that match a given sentence is typicallylow, up to a few thousand rules.
Each fully ab-stract rule can potentially apply to every sentence;the strict pruning cutoff in use for these rules ismeant to focus the grammar to the most importantgeneral syntactic divergences between French andEnglish.
Most of the latitude in grammar pruningcomes from adjusting the frequency cutoff on themixed rules since this category of rule is by far themost common type.
We conducted experimentswith three different frequency cutoffs: 100, 200,and 500, with each increase decreasing the gram-mar size by 70?80 percent.3.3 French?English ExperimentsWe tuned our system to the newstest2008 set of2051 segments.
Aside from the official new-stest2013 test set (3000 segments), we also col-lected test-set scores from last year?s newstest2012set (3003 segments).
Automatic metric scoresare computed according to BLEU (Papineni et al2002), METEOR (Denkowski and Lavie, 2011),and TER (Snover et al 2006), all computed ac-cording to MultEval v. 0.5 (Clark et al 2011).Each system variant is run with two independentMERT steps in order to control for optimizer in-stability.Table 1 presents the results, with the metricscores averaged over both MERT runs.
Quite in-terestingly, we find only minor differences in bothtune and test scores despite the large differences infiltered/pruned grammar size as the cutoff for par-tially abstract rules increases.
No system is fullystatistically separable (at p < 0.05) from the oth-ers according to MultEval?s approximate random-ization algorithm.
The closest is the variant withcutoff 200, which is generally judged to be slightlyworse than the other two.
METEOR claims fulldistinction on the 2013 test set, ranking the sys-tem with the strictest grammar cutoff (500) best.This is the version that we ultimately submitted tothe shared translation task.4 Synthetic Translation OptionsBefore discussing our Russian?English andEnglish?Russian systems, we introduce theconcept of synthetic translation options, whichwe use in these systems.
We provide a briefoverview here; for more detail, we refer the readerto Tsvetkov et al(2013).In language pairs that are typologically similar,words and phrases map relatively directly fromsource to target languages, and the standard ap-proach to learning phrase pairs by extraction fromparallel data can be very effective.
However, inlanguage pairs in which individual source lan-guage words have many different possible transla-tions (e.g., when the target language word couldhave many different inflections or could be sur-rounded by different function words that have no72Dev (2008) Test (2012) Test (2013)System BLEU METR TER BLEU METR TER BLEU METR TERCutoff 100 22.52 31.44 59.22 27.73 33.30 53.25 28.34 * 33.19 53.07Cutoff 200 22.34 31.40 59.21 * 27.33 33.26 53.23 * 28.05 * 33.07 53.16Cutoff 500 22.80 31.64 59.10 27.88 * 33.58 53.09 28.27 * 33.31 53.13Table 1: French?English automatic metric scores for three grammar pruning cutoffs, averaged over twoMERT runs each.
Scores that are statistically separable (p < 0.05) from both others in the same columnare marked with an asterisk (*).direct correspondence in the source language), wecan expect the standard phrasal inventory to beincomplete, except when very large quantities ofparallel data are available or for very frequentwords.
There simply will not be enough exam-ples from which to learn the ideal set of transla-tion options.
Therefore, since phrase based trans-lation can only generate input/output word pairsthat were directly observed in the training corpus,the decoder?s only hope for producing a good out-put is to find a fluent, meaning-preserving transla-tion using incomplete translation lexicons.
Syn-thetic translation option generation seeks to fillthese gaps using secondary generation processesthat produce possible phrase translation alterna-tives that are not directly extractable from thetraining data.
By filling in gaps in the transla-tion options used to construct the sentential trans-lation search space, global discriminative transla-tion models and language models can be more ef-fective than they would otherwise be.From a practical perspective, synthetic transla-tion options are attractive relative to trying to buildmore powerful models of translation since theyenable focus on more targeted translation prob-lems (for example, transliteration, or generatingproper inflectional morphology for a single wordor phrase).
Since they are translation options andnot complete translations, many of them may begenerated.In the following system pairs, we use syn-thetic translation options to augment hiero gram-mar rules learned in the usual way.
The syntheticphrases we include augment draw from severalsources:?
transliterations of OOV Russian words (?5.3);?
English target sides with varied function words(for example, given a phrase that translates intocat we procedure variants like the cat, a cat andof the cat); and,?
when translating into Russian, we generatephrases by first predicting the most likely Rus-sian lemma for a source word or phrase, andthen, conditioned on the English source context(including syntactic and lexical features), wepredict the most likely inflection of the lemma(?6.1).5 Russian?English System5.1 DataWe used the same parallel data for both theRussian?English and English Russian systems.Except for filtering to remove sentence pairswhose log length ratios were statistical outliers,we only filtered the Common Crawl corpus to re-move sentence pairs with less than 50% concentra-tion of Cyrillic characters on the Russian side.
Theremaining data was tokenized and lower-cased.For language models, we trained 4-gram Markovmodels using the target side of the bitext and anyavailable monolingual data (including Gigawordfor English).
Additionally, we trained 7-gram lan-guage models using 600-class Brown clusters withWitten-Bell smoothing.25.2 Baseline SystemOur baseline Russian?English system is a hierar-chical phrase-based translation model as imple-mented in cdec (Chiang, 2007; Dyer et al 2010).SCFG translation rules that plausibly match eachsentence in the development and deftest sets wereextracted from the aligned parallel data using thesuffix array indexing technique of Lopez (2008).A Russian morphological analyzer was used tolemmatize the training, development, and testdata, and the ?noisier channel?
translation ap-proach of Dyer (2007) was used in the Russian?English system to let unusually inflected surfaceforms back off to per-lemma translations.2http://www.ark.cs.cmu.edu/cdyer/ru-600/.735.3 Synthetic Translations: TransliterationAnalysis revealed that about one third of the un-seen Russian tokens in the development set con-sisted of named entities which should be translit-erated.
We used individual Russian-English wordpairs in Wikipedia parallel headlines 3 to train alinear-chained CRF tagger which labels each char-acter in the Russian token with a sequence of zeroor more English characters (Ammar et al 2012).Since Russian names in the training set were innominative case, we used a simple rule-based mor-phological generator to produce possible inflec-tions and filtered out the ones not present in theRussian monolingual corpus.
At decoding, un-seen Russian tokens are fed to the transliteratorwhich produces the most probable 20 translitera-tions.
We add a synthetic translation option foreach of the transliterations with four features: anindicator feature for transliterations, the CRF un-normalized score, the trigram character-LM log-probability, and the divergence from the averagelength-ratio between an English name and its Rus-sian transliteration.5.4 Synthetic Translations: Function WordsSlavic languages like Russian have a large numberof different inflected forms for each lemma, repre-senting different cases, tenses, and aspects.
Sinceour training data is rather limited relative to thenumber of inflected forms that are possible, we usean English language model to generate a varietyof common function word contexts for each con-tent word phrase.
These are added to the phrasetable with a feature indicating that they were notactually observed in the training data, but ratherhallucinated using SRILM?s disambig tool.5.5 SummaryTable 5.5 summarizes our Russian-English trans-lation results.
In the submitted system, we addi-tionally used MBR reranking to combine the 500-best outputs of our system, with the 500-best out-puts of a syntactic system constructed similarly tothe French?English system.6 English?Russian SystemThe bilingual training data was identical to thefiltered data used in the previous section.
Wordalignments was performed after lemmatizing the3We contributed the data set to the shared task participantsat http://www.statmt.org/wmt13/wiki-titles.ru-en.tar.gzTable 2: Russian-English summary.Condition BLEUBaseline 30.8Function words 30.9Transliterations 31.1Russian side of the training corpus.
An unpruned,modified Kneser-Ney smoothed 4-gram languagemodel (Chen and Goodman, 1996) was estimatedfrom all available Russian text (410 million words)using the KenLM toolkit (Heafield et al 2013).A standard hierarchical phrase-based systemwas trained with rule shape indicator features, ob-tained by replacing terminals in translation rulesby a generic symbol.
MIRA training was per-formed to learn feature weights.Additionally, word clusters (Brown et al 1992)were obtained for the complete monolingual Rus-sian data.
Then, an unsmoothed 7-gram languagemodel was trained on these clusters and added asa feature to the translation system.
Indicator fea-tures were also added for each cluster and bigramcluster occurence.
These changes resulted in animprovement of more than a BLEU point on ourheld-out development set.6.1 Predicting Target MorphologyWe train a classifier to predict the inflection ofeach Russian word independently given the cor-responding English sentence and its word align-ment.
To do this, we first process the Russianside of the parallel training data using a statisti-cal morphological tagger (Sharoff et al 2008) toobtain lemmas and inflection tags for each wordin context.
Then, we obtain part-of-speech tagsand dependency parses of the English side of theparallel data (Martins et al 2010), as well asBrown clusters (Brown et al 1992).
We extractfeatures capturing lexical and syntactical relation-ships in the source sentence and train structuredlinear logistic regression models to predict the tagof each English word independently given its part-of-speech.4 In practice, due to the large size ofthe corpora and of the feature space dimension,we were only able to use about 10% of the avail-able bilingual data, sampled randomly from theCommon Crawl corpus.
We also restricted the4We restrict ourselves to verbs, nouns, adjectives, adverbsand cardinals since these open-class words carry most inflec-tion in Russian.74???
????????
????????
????
??
??
????????
?she had attempted to cross the road on her bikePRP   VBD         VBN          TO    VB       DT     NN    IN  PRP$   NNnsubjauxxcompaux???????
?_V*+*mis/sfm/eC50   C473        C28          C8    C275   C37   C43  C82 C94   C331Figure 1: The classifier is trained to predict the verbal inflection mis-sfm-e based on the linear andsyntactic context of the words aligned to the Russian word; given the stem ????????
(pytat?sya), thisinflection paradigm produces the observed surface form ????????
(pytalas?
).set of possible inflections for each word to the setof tags that were observed with its lemma in thefull monolingual training data.
This was neces-sary because of our choice to use a tagger, whichis not able to synthesize surface forms for a givenlemma-tag pair.We then augment the standard hierarchicalphrase-base grammars extracted for the baselinesystems with new rules containing inflections notnecessarily observed in the parallel training data.We start by training a non-gappy phrase transla-tion model on the bilingual data where the Russianhas been lemmatized.5 Then, before translating anEnglish sentence, we extract translation phrasescorresponding to this specific sentence and re-inflect each word in the target side of these phrasesusing the classifier with features extracted fromthe source sentence words and annotations.
Wekeep the original phrase-based translation featuresand add the inflection score predicted by the clas-sifier as well as indicator features for the part-of-speech categories of the re-inflected words.On a held-out development set, these syntheticphrases produce a 0.3 BLEU point improvement.Interestingly, the feature weight learned for usingthese phrases is positive, indicating that useful in-flections might be produced by this process.7 ConclusionThe CMU systems draws on a large number ofdifferent research directions.
Techniques such asMBR reranking and synthetic phrases allow dif-ferent contributors to focus on different transla-5We keep intact words belonging to non-predicted cate-gories.tion problems that are ultimately recombined intoa single system.
Our performance, in particular,on English?Russian machine translation was quitesatisfying, we attribute our biggest gains in thislanguage pair to the following:?
Our inflection model that predicted how an En-glish word ought best be translated, given itscontext.
This enabled us to generate forms thatwere not observed in the parallel data or wouldhave been rare independent of context with pre-cision.?
Brown cluster language models seem to be quiteeffective at modeling long-range morphologicalagreement patterns quite reliably.AcknowledgmentsWe sincerely thank the organizers of the work-shop for their hard work, year after year, and thereviewers for their careful reading of the submit-ted draft of this paper.
This research work wassupported in part by the U. S. Army ResearchLaboratory and the U. S. Army Research Officeunder contract/grant number W911NF-10-1-0533,by the National Science Foundation under grantIIS-0915327, by a NPRP grant (NPRP 09-1140-1-177) from the Qatar National Research Fund (amember of the Qatar Foundation), and by com-puting resources provided by the NSF-sponsoredXSEDE program under grant TG-CCR110017.The statements made herein are solely the respon-sibility of the authors.75ReferencesWaleed Ammar, Chris Dyer, and Noah A. Smith.
2012.Transliteration by sequence labeling with lattice en-codings and reranking.
In NEWS workshop at ACL.Peter F. Brown, Peter V. deSouza, Robert L. Mer-cer, Vincent J. Della Pietra, and Jenifer C. Lai.1992.
Class-based n-gram models of natural lan-guage.
Computional Linguistics, 18(4):467?479.Stanley F. Chen and Joshua Goodman.
1996.
An em-pirical study of smoothing techniques for languagemodeling.
In Proceedings of the 34th Annual Meet-ing of the Association for Computational Linguis-tics, pages 310?318, Santa Cruz, California, USA,June.
Association for Computational Linguistics.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2):201?228.Jonathan H. Clark, Chris Dyer, Alon Lavie, andNoah A. Smith.
2011.
Better hypothesis testingfor statistical machine translation: Crontrolling foroptimizer instability.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Short Papers, pages 176?181, Portland,Oregon, USA, June.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: Automatic metric for reliable optimization andevaluation of machine translation systems.
In Pro-ceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 85?91, Edinburgh, Scot-land, UK, July.Michael Denkowski, Greg Hanneman, and Alon Lavie.2012.
The cmu-avenue french-english translationsystem.
In Proceedings of the NAACL 2012 Work-shop on Statistical Machine Translation.Chris Dyer, Adam Lopez, Juri Ganitkevitch, JohnathanWeese, Ferhan Ture, Phil Blunsom, Hendra Seti-awan, Vladimir Eidelman, and Philip Resnik.
2010.cdec: A decoder, alignment, and learning frameworkfor finite-state and context-free translation models.In Proc.
of ACL.Chris Dyer, Kevin Gimpel, Jonathan H. Clark, andNoah A. Smith.
2011.
The CMU-ARK German-English translation system.
In Proceedings of theSixth Workshop on Statistical Machine Translation.Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013.
A simple, fast, and effective reparameteriza-tion of IBM Model 2.
In Proc.
of NAACL.Chris Dyer.
2007.
The ?noiser channel?
: Translationfrom morphologically complex languages.
In Pro-ceedings of WMT.Vladimir Eidelman.
2012.
Optimization strategies foronline large-margin learning in machine translation.In Proceedings of the Seventh Workshop on Statisti-cal Machine Translation.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inference and training ofcontext-rich syntactic translation models.
In Pro-ceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the ACL, pages 961?968, Sydney, Australia,July.Greg Hanneman and Alon Lavie.
2011.
Automaticcategory label coarsening for syntax-based machinetranslation.
In Proceedings of SSST-5: Fifth Work-shop on Syntax, Semantics, and Structure in Statis-tical Translation, pages 98?106, Portland, Oregon,USA, June.Greg Hanneman and Alon Lavie.
2013.
Improvingsyntax-augmented machine translation by coarsen-ing the label set.
In Proceedings of NAACL-HLT2013, pages 288?297, Atlanta, Georgia, USA, June.Greg Hanneman, Michelle Burroughs, and Alon Lavie.2011.
A general-purpose rule extractor for SCFG-based machine translation.
In Proceedings of SSST-5: Fifth Workshop on Syntax, Semantics, and Struc-ture in Statistical Translation, pages 135?144, Port-land, Oregon, USA, June.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable modi-fied Kneser-Ney language model estimation.
In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics, Sofia, Bulgaria,August.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, Edin-burgh, Scotland, UK, July.Shankar Kumar, Wolfgang Macherey, Chris Dyer,and Franz Och.
2009.
Efficient minimum errorrate training and minimum Bayes-risk decoding fortranslation hypergraphs and lattices.
In Proc.
ofACL-IJCNLP.Adam Lopez.
2008.
Tera-scale translation models viapattern matching.
In Proc.
of COLING.Nitin Madnani.
2010.
The Circle of Meaning: FromTranslation to Paraphrasing and Back.
Ph.D. the-sis, Department of Computer Science, University ofMaryland College Park.Andre?
F. T. Martins, Noah A. Smith, Eric P. Xing, Pe-dro M. Q. Aguiar, and Ma?rio A. T. Figueiredo.
2010.Turbo parsers: Dependency parsing by approximatevariational inference.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automaticevalution of machine translation.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318, Philadelphia,Pennsylvania, USA, July.76Serge Sharoff, Mikhail Kopotev, Tomaz Erjavec, AnnaFeldman, and Dagmar Divjak.
2008.
Designing andevaluating a russian tagset.
In Proc.
of LREC.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of the Seventh Conference of the As-sociation for Machine Translation in the Americas,pages 223?231, Cambridge, Massachusetts, USA,August.Yulia Tsvetkov, Chris Dyer, Lori Levin, and ArchnaBatia.
2013.
Generating English determiners inphrase-based translation with synthetic translationoptions.
In Proceedings of the Eighth Workshop onStatistical Machine Translation.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart parsing.In Proceedings of the Workshop on Statistical Ma-chine Translation, pages 138?141, New York, NewYork, USA, June.77
