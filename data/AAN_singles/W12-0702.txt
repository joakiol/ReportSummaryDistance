Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 10?18,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsDependency-Based Open Information ExtractionPablo Gamallo and Marcos GarciaCentro de Investigac?a?o sobre Tecnologias da Informac?a?o (CITIUS)Universidade de Santiago de Compostelapablo.gamallo@usc.es marcos.garcia.gonzalez@usc.esSantiago Ferna?ndez-LanzaEscola Superior de Enxen?er?
?a Informa?ticaUniversidade de Vigosflanzal@uvigoAbstractBuilding shallow semantic representationsfrom text corpora is the first step to performmore complex tasks such as text entailment,enrichment of knowledge bases, or ques-tion answering.
Open Information Extrac-tion (OIE) is a recent unsupervised strategyto extract billions of basic assertions frommassive corpora, which can be consideredas being a shallow semantic representationof those corpora.
In this paper, we proposea new multilingual OIE system based on ro-bust and fast rule-based dependency pars-ing.
It permits to extract more precise as-sertions (verb-based triples) from text thanstate of the art OIE systems, keeping a cru-cial property of those systems: scaling toWeb-size document collections.1 IntroductionThere is an increasing interest in capturing shal-low semantic representations from large amountsof text, with the aim of elaborating more com-plex semantic tasks involved in text understand-ing, such as textual entailment, filling knowledgegaps in text, or integration of text informationinto background knowledge bases.
Two recentapproaches to text understanding are interested inshallow semantics: Machine Reading (Etzioni etal., 2006) and Learning by Reading (Barker et al,2007).
Both approaches aim at understanding textby starting with a very basic representation of thefacts conveyed by the input text.
In addition, theyrely on unsupervised strategies.
There are, how-ever, two significant differences between MachineReading and Learning by Reading:The first difference concerns the basic repre-sentation required at the beginning of the under-standing process.
While Machine Reading is fo-cused on fixed structures (triples), constituted bya relation (a verb or verb phrase) and two argu-ments, in Learning by Reading the text is rep-resented by means of more flexible predicate-argument structures (n-tuples) derived from syn-tactic dependency trees.
In Learning by Reading,on the one hand, relations with more than two ar-guments are also extracted, and on the other, rela-tions are not restricted to verb phrases but to what-ever relation expressed by a dependency basedtriple, (head, relation, modifier), also called Ba-sic Element (Hovy et al, 2005).
The second dif-ference is related to the notion of text domain.Whereas Machine Reading works on open rela-tions and unrestricted topics and domains, Learn-ing by Reading prefers being focused on domain-specific texts in order to build a semantic modelof a particular topic.One of the major contributions of MachineReading is the development of an extractionparadigm, called Open Information Extraction(OIE), which aims at extracting a large set of verb-based triples (or assertions) from unrestricted text.An OIE system reads in sentences and rapidly ex-tracts one or more textual assertions, consistingin a verb relation and two arguments, which tryto capture the main relationships in each sentence(Banko et al, 2007).
Unlike most relation ex-traction methods which are focused on a prede-fined set of target relations, OIE is not limited toa small set of target relations known in advance,but extracts all types of (verbal) binary relationsfound in the text.
The OIE system with best per-formance, called ReVerb (Etzioni et al, 2011),is a logistic regression classifier that takes as in-put PoS-tagged and NP-chunked sentences.
So,10it only requires shallow syntactic features to gen-erate semantic relations, guaranteeing robustnessand scalability with the size of the corpus.
One ofthe main critics within the OIE paradigm againstdependency based methods, such as Learning byReading, concerns the computational cost asso-ciated with rich syntactic features.
Dependencyparsing could improve precision and recall overshallow syntactic features, but at the cost of ex-traction speed (Etzioni et al, 2011).
In order tooperate at the Web scale, OIE systems needs to bevery fast and efficient.In this paper, we describe an OIE method togenerate verb-based triples by taking into accountthe positive properties of the two traditions: con-sidering Machine Reading requirements, our sys-tem is efficient and fast guaranteeing scalability asthe corpus grows.
And considering ideas behindLearning by Reading, we use a dependency parserin order to obtain fine-grained information (e.g.,internal heads and dependents) on the argumentsand relations extracted from the text.
In addition,we make extraction multilingual.
More precisely,our system has the following properties:?
Unsupervised extraction of triples repre-sented at different levels of granularity: sur-face forms and dependency level.?
Multilingual extraction (English, Spanish,Portuguese, and Galician) by making use ofa multilingual rule-based parser, called Dep-Pattern (Gamallo and Gonza?lez, 2011).Our claim is that it is possible to performOpen Information Extraction by making use ofvery conventional tools, namely rule-based de-pendency analysis and simple post-processing ex-traction rules.
In addition, we also show that wecan deal with knowledge-rich syntactic informa-tion while remaining scalable.This article is organized as follows.
Section 2introduces previous work on OIE: in particular itdescribes three of the best known OIE systems upto date.
Next, in Section 3, the proposed methodis described in detail.
Then, some experiments areperformed in Section 4, where our OIE system iscompared against ReVerb.
In 5, we sketch someapplications that use the output of our OIE sys-tem, and finally, conclusions and current work areaddressed in 6.2 Open Information Extraction SystemsAn OIE system extracts a large number of triples(Arg1, Rel, Arg2) for any binary relation found inthe text.
For instance, given the sentence ?Vigois the largest city in Galicia and is located in thenorthwest of Spain?, an OIE system should ex-tract two triples: (Vigo, is the largest city in, Galicia)and (Vigo, is located in, northwest of Spain).
Up tonow, OIE is focused only on verb-based relations.Several OIE systems have been proposed, all ofthem are based on an extractor learned from la-belled sentences.
Some of these systems are:?
TextRunner (Banko et al, 2008): the ex-tractor is a second order linear-chain CRFtrained on samples of triples generated fromthe Penn Treebank.
The input of TextRunnerare PoS-tagged and NP-chunked sentences,both processes performed with OpenNLPtools.?
WOE (Wu and Weld, 2010): the extractorwas learned by identifying the shortest de-pendency paths between two noun phrases,using training examples of Wikipedia.
Themain drawback is that extraction is 30 timesslower than TextRunner.?
ReVerb (Etzioni et al, 2011; Fader et al,2011): the extractor is a logistic regressionclassifier trained with shallow syntactic fea-tures, which also incorporates lexical con-straints to filter out over-specified relationphrases.
It takes as input the same featuresas TextRunner, i.e., PoS-tagged and NP-chunked sentences analyzed with OpenNLPtools.
It is considered to be the best OIEsystem up to now.
Its performance is 30%higher than WOE and more than twice thatof TextRunner.One of the most discussed problems of OIEsystems is that about 90% of the extracted triplesare not concrete facts (Banko et al, 2007) ex-pressing valid information about one or twonamed entities, e.g.
?Obama was born in Hon-olulu?.
However, the vast amount of high con-fident relational triples extracted by OIE systemsare a very useful startpoint for further NLP tasksand applications, such as common sense knowl-edge acquisition (Lin et al, 2010), and extrac-tion of domain-specific relations (Soderland et al,112010).
The objective of OIE systems is not to ex-tract concrete facts, but to transform unstructuredtexts into structured information, closer to ontol-ogy formats.Nevertheless, some linguistics problems arise.OIE systems were trained to identify only verbclauses within the sentences and, therefore, toextract just binary verb-based relations from theclause structure.
It follows that they cannot beeasily adapted to learn other non-clausal relationsalso found in the text.
Let us take the followingsentence: ?The soccer player of FC Barcelona,Lionel Messi, won the Fifa World Player of theYear award?.
In addition to the main verb-basedrelationship:(Lionel Messi, won, the Fifa Worlds Playerof the Year award)which could be extracted by the OIE systems in-troduced above, it should also be important to ex-tract other non-verbal relations found within thenoun phrases:(Messi, is, a soccer player of FC Barcelona)(Fifa World Player of the Year, is, an award)However, the cited systems were not trained tolearn such a basic relations.Besides, the OIE systems are not adapted toprocess clauses denoting events with many argu-ments.
Take the sentence: ?The first commercialairline flight was from St. Petersburg to Tampa in1914?.
We should extract, at least, two or threedifferent relational triples from the verb clausecontained in this sentence, for instance:(the first commercial airline flight, was from, St. Pe-tersburg)(the first commercial airline flight, was to, Tampa)(the first commercial airline flight, was in, 1914)Yet, current OIE systems are not able to performthis multiple extraction.
Even if the cited OIEsystems can identify several clauses per sentence,they were trained to only extract one triple perclause.In the following, we will describe adependency-based OIE system that overcomesthese linguistic limitations.3 A Dependency-Based Method forOpen Information ExtractionThe proposed extraction method consists of threesteps organized as a chain of commands in apipeline:Dependency parsing Each sentence of the inputtext is analyzed using the dependency-basedparser DepPattern, a multilingual tool avail-able under GPL license1.Clause constituents For each parsed sentence,we discover the verb clauses it contains and,then, for each clause, we identify the verbparticipants, including their functions: sub-ject, direct object, attribute, and preposi-tional complements.Extraction rules A set of rules is applied on theclause constituents in order to extract the tar-get triples.These three steps are described in detail below.3.1 Dependency ParsingTo parse text, we use an open-source suite of mul-tilingual syntactic analysis, DepPattern (Gamalloand Gonza?lez, 2011).
The suite includes basicgrammars for five languages as well as a compilerto build parsers in Perl.
A parser takes as input theoutput of a PoS-tagger, either, FreeLing (Carreraset al, 2004) or Tree-Tagger2.
The whole processis robust and fast.
It takes 2600 words per secondon a Linux platform with 2.4GHz CPU and 2Gmemory.
The basic grammars of DepPattern con-tain rules for many types of linguistic phenomena,from noun modification to more complex struc-tures such as apposition or coordination.
Howevertheir coverage is still not very high.
We addedseveral rules to the DepPattern grammars in En-glish, Spanish, Portuguese, and Galician, in orderto improve the coverage of our OIE system.The output of a DepPattern parser consistsof sentences represented as binary dependenciesfrom the head lemma to the dependent lemma:rel(head, dep).
Consider the sentence ?The coachof Benfica has held a press conference in Lisbon?.1htpp://gramatica.usc.es/pln/tools/deppattern.htm2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html12(have hold)vp(the coach of benfica)npsubj(a press conference)npdobj(in lisbon)ppvprepFigure 1: Constituency tree with function informationThe DepPattern dependencies are the following:spec(coach-2, the-1)nprep(coach-2, of-3)term(of-3, benfica-4)aux(hold-6, have-5)subj(hold-6, coach-2)dobj(hold-6, conference-9)spec(conference-9, a-7)modif(conference-9, press-8)vprep(hold-6, in-10)term(in-10, lisbon-11)The directed graph formed by these dependencieswill be the input of the following step.3.2 Clause ConstituentsIn the second step, we identify the clauses of eachsentence, and, for each clause, we retain the par-ticipants and their functions with regard to theverb of the clause.
A sentence can contain severalclauses, in particular, we identify the main clause,relative clauses, and that-clauses.In our example, there is just one clause consti-tuted by a verb phrase (?have hold?)
and threeparticipants: the subject ?the coach of benfica?,the direct object ?a press conference?, and aprepositional phrase ?in lisbon?.
So, the objec-tive here is to transform the dependency path builtin the first step into a partial constituency tree,where only the constituents of the clause are se-lected.
The process of constructing the clauseconstituents and the verb phrase is as follows.Given a verb dependency (namely subj, dobj,vprep, or attrib), we select the dependent lemmaof the clause verb and then we list all dependentlemmas linked to the target lemma (as a head)through the syntactic dependency path.
It resultsin the construction of the main phrases of theclause, including information about the head ofthe phrase.
We show below the three constituentsidentified from our example, where the directedarrows stand for the internal dependencies usedfor their identification (the head of each phrase isin bold):(a press conference)npspecmodif(the coach of benfica)npspec nprep term(in lisbon)pptermThe verb phrase is also built in a similar way.It contains all dependent lemmas of the verb thatare not part of the clause constituents identifiedbefore:(have hold)vpauxThe three clause constituents are also providedwith information about their function with regardto the clause verb, as Figure 1 shows.
The func-tion of a constituent inherits the name of the de-pendent relation linking the clause verb to thehead of the constituent.
For instance, the functionof (the coach of benfica)np is the name of the de-pendent relation in subj(hold-6, coach-2), that issubj.
The clause constituents as well as the verbphrase of each clause are the input of the extrac-tion rules.3.3 Extraction RulesThe third and last process consists of a small setof simple extraction rules that are applied on theclauses identified in the previous step.
The out-put of an extraction rule is a triple whose inter-nal word tokens are provided with some linguisticinformation: lemma, PoS tag, head of the con-stituent, etc.The simplest rule is applied on a clause justcontaining a subject and a direct object.
In sucha case, the two constituents are the arguments ofthe triple, while the verb phrase is the relation.13In our previous example, the clause containsthree arguments: a subject (?the coach of ben-fica?
), a direct object ( ?a press conference?
),and a prepositional complement (?in Lisbon?
).In this case, our strategy is similar to that ofReVerb system, namely to consider the relationas the verb phrase followed by a noun phraseand ending in a preposition.
For this purpose,we have defined an extraction rule that buildsthe relation of the triple using the verb phrase,the direct object, and the head preposition ofthe prepositional phrase: ?have hold a pressconference in?.
The two arguments are: ?thecoach of benfica?
and ?Lisbon?.
The triplegenerated by our rule is represented as follows:ARG1: the DT coach N-H of PRP benfica NREL: have V hold V-H a DT press N confer-ence N-H in PRPARG2: Lisbon N-Hwhich contains lemmas, PoS tags (DT, N,PRP,...), as well as the heads (tag ?H?)
of themain constituents.
In addition to this syntax-based representation, the extraction rule alsogives us a surface form of the triple with justtokens:(the coach of Benfica, has hold a press conference in,Lisbon)Table 1 shows the main rules we defined to ex-tract triples from patterns of clause arguments.The order of arguments within a pattern is notrelevant.
The argument ?vprep?
stands for aprepositional complement of the verb, whichconsists of a preposition and a nominal phrase(np).
The third row represents the extraction ruleused in our previous example.
All rules in Table1 are applied at different clause levels: mainclauses, relative clauses and that-clauses.As in the case of all current OIE systems,our small set of rules only considers verb-basedclause triples and only extract one triple perclause.
We took this decision in order to make afair comparison when evaluating the performanceof our system against ReVerb (in the next section).However, nothing prevents us from writing ex-traction rules to generate several triples from oneclause with many arguments, or to extract triplesfrom other patterns of constituents, for instance:patterns triplessubj-vp-dobj Arg1 = subjRel= vpArg2 = dobjsubj-vp-vprep Arg1 = subjRel= vp+prep (prep from vprep)Arg2 = np (from vprep)subj-vp-dobj-vprep Arg1 = subjRel= vp+dobj+prepArg2 = np (from vprep)subj-vp-attr Arg1 = subjRel= vpArg2 = attrsubj-vp-attr-vprep Arg1 = subjRel= vp+attr+prep (from vprep)Arg2 = np (from vprep)Table 1: Pattern based rules to generate final triplesvp-pp-pp, noun-prep-noun, noun-noun, adj-noun,or verb-adverb..Finally, let us note that current OIE systems,such as ReVerb, produces triples only in tex-tual, surface form.
Substantial postprocessing isneeded to derive relevant linguistic informationfrom the tuples.
By contrast, in addition to surfaceform triples, we also provide syntax-based infor-mation, PoS tags, lemmas, and heads.
If moreinformation is required, it can be easily obtainedfrom the dependency analysis.4 Experiments4.1 Wikipedia ExtractionThe system proposed in this paper, hereafterDepOE, was used to extract triples from theWikipedia in four languages: Portuguese, Span-ish, Galician, and English.3 Before applying theextractor, the xml files containing the Wikipediawere properly converted into plaintext.
The num-ber of both sentences and extracted triples areshown in Table 2.
We used PoS-tagged text withTree-Tagger as input of DepPattern for the En-glish extraction, and FreeLing for the other threelanguages.
Note that, unlike OIE systems de-scribed in previous work, DepOE can be consid-ered as being a multilingual OIE system.43Wikipedia dump files were downloaded at http://download.wikipedia.org on September 2010.4DepOE is an open source system freely available,under GPL license, at http://gramatica.usc.es/?gamallo/prototypes.htm.14Wikipedia version sentences triplesEnglish 78, 826, 696 47, 284, 799Spanish 21, 208, 089 6, 527, 195Portuguese 11, 714, 672 3, 738, 922Galician 1, 461, 705 480, 138Table 2: Number of sentences and triples from fourWikipediasIt is worth mentioning that the number of ex-tracted triples is lower than that obtained with Re-Verb, which reaches 63, 846, 865 triples (withoutconsidering a threshold for confidence scores).This is due to the fact that the DepPattern gram-mars are not complete and, then, they do not per-form deep analysis, just partial parsing.
In par-ticular, they do not consider all types of coordi-nation and do not deal with significant linguisticclausal phenomena such as interrogative, condi-tional, causal, or adversative clauses.
Preliminaryevaluations of the four parsers showed that theybehave in a similar way, yet Portuguese and Gali-cian parsers achieve the best performance, about70% f-score.In this paper, we do not report experimentalevaluation of the OIE system for languages otherthan English.4.2 EvaluationWe compare Dep-OE to ReVerb5, regarding thequantity and quality of extracted triples just in En-glish, since ReVerb only can be applied on thislanguage.
Each system is given a set of sentencesas input, and returns a set of triples as output.
Atest set of 200 sentences was created by randomlyselecting sentences from the English Wikipedia.Each test sentence was independently examinedby two judges in order to, on the one hand, iden-tify the triples actually contained in the sentence,and on the other, evaluate each extraction as cor-rect or incorrect.
Incoherent and uninformativeextractions were considered as incorrect.
Giventhe sentence ?The relationship between the Tal-iban and Bin Laden was close?, an example of in-coherent extraction is:(Bin Laden, was, close)Uninformative extractions occur when criticalinformation is omitted, for instance, when one of5http://reverb.cs.washington.edu/the arguments is truncated.
Given the sentence?FBI examined the relationship between BinLaden and the Taliban?, an OIE system couldreturn a truncated triple:(FBI, examined the relationship between, Bin Landen)We follow similar criteria to those defined inprevious OIE evaluations (Etzioni et al, 2011).Concerning the decisions taken by the judgeson the extractions made by the systems, the judgesreached a very high agreement, 93%, with anagreement score of ?
= 0.83.
They also reacheda high agreement, 86%, with regard to the num-ber of triples (gold standard) found in the test sen-tences.The precision of a system is the number of ex-tractions returned as correct by the system dividedby the number of returned extractions.
Recall isthe number of extractions returned as correct bythe system divided by the number of triples iden-tified by the judges (i.e., the size of the gold stan-dard).
Moreover, to compare our rule-based sys-tem DepOE to ReVerb, we had to select a par-ticular threshold restricting the extractions madeby ReVerb.
Let us note that this extractor is a lo-gistic regression classifier that assign confidencescores to its extractions.
We computed precisionand recall for many threshold and selected thatgiving rise to the best f-score.
Such a thresholdwas 0.15.
So, we compare DepOE to the resultsgiven by ReVerb for those extractions whose con-fidence score is higher than 0.15.As it was done in previous OIE evaluations, thejudges evaluated two different aspects of the ex-traction:?
how well the system identify correct relationphrases,?
the full extraction task, i.e., whether the sys-tem identifies correct triples (both the rela-tion and its arguments).Figures 2 and 3 represent the score average ob-tained by the two judges.
They show that DepOEsystem is more precise than ReVerb.
This is clearin the full extraction task, where DepOE achieves68% precision while ReVerb reaches 52%.
Bycontrast, as it was expected, DepOE has lowerrecall because of the low coverage of the gram-mars it depends on.
Regarding f-score, DepOE15ReVerb (<= 0.15) DepOE010203040506070precrecallf-scoreFigure 2: Evaluation of the extraction of triples (bothrelation and its arguments) performed by DepOE andReVerb (with a confidence score >= 0.15).ReVerb (<= 0.15) DepOE0102030405060708090precrecallf-scoreFigure 3: Evaluation of the relation extraction per-formed by DepOE and ReVerb (with a confidencescore >= 0.15).performs better than ReVerb in the full extractiontask, but when only relations are considered, Re-Verb achieves the highest score.We found that most of the incorrect extractionsreturned by the two systems where cases wherethe relation phrase was correctly identified, butnot one of the arguments.
However, there are sig-nificant differences between the two systems con-cerning the type of problems arising in argumentidentification.The most common errors of ReVerb are both:incorrect identification of the first argument (arg1)and extraction of only a truncated part of the sec-ond argument (arg2), as in the case of coordinat-ing conjunctions.
These two problems are crucialfor ReVerb since more than 60% of incorrect ex-tractions were cases with incorrect arguments andcorrect relations.
DepOE has more precise extrac-tions of the two arguments, in particular of arg1,since the parser is able to correctly identify thesubject.
Nevertheless, it also produces many trun-cated arg2.
Let us see an example.
Given the sen-tence ?Cities and towns in Romania can have thestatus either of municipiu or oras?, ReVerb wasnot able to identify the correct arg1 and returneda truncated arg2:(Romania, can have, the status)DepOE correctly identified the subject (arg1)but also failed to return the correct arg2:(Cities and towns in Romania, can have, the status)In general, when DepOE fails to correctly identifyan argument, it is often trivial to find the reasonof the problem.
In the example above, arg2 wastruncated because the English grammar has notany specific rule linking the particle ?either?
toa coordinate expression.
So, the improvementof DepOE depends on improving the grammarsit is based on.
Besides the low coverage of thegrammar, there are other sources of problemsconcerning the correct identification of argu-ments.
In particular, it is worth mentioning thatthe English version of DepOE is not providedwith an efficient Named Entity Recognitionsystem.
This makes it difficult to correctly iden-tify multiword arguments with Named Entities,quantities, measures, and dates.
Such a problemwas partially solved by the use of FreeLing inthe Portuguese, Spanish, and Galician DepOEversions.4.3 Extraction SpeedTo test the system?s speed, we ran each extrac-tor on the 100, 000 first lines of the EnglishWikipedia using a Linux platform with 2.4GHzCPU and 2GB memory.
The processing time ofReVerb was 4 minutes while that of DepOE was 5minutes and 19 seconds.
In this platform, ReVerbis able to process 2, 500 words per second, andDepOE 1, 650.
Concerning the use of RAM, Re-Verb requires the 27% memory of the computer,while DepOE only needs 0.1%.5 ApplicationsThe extracted triples can be used for several NLPapplications.
The first application we are devel-oping is a multilingual search engine over thetriples extracted from the Wikipedia.
All triplesare indexed with Apache Solr6, which enables itto rapidly answer queries regarding the extractedinformation, as in the query form of ReVerb7.Another application is to use the extractedtriples to discover commonsense knowledge of6http://lucene.apache.org/solr/7http://textrunner.cs.washington.edu/reverb demo.pl16team play gameteam win championshipteam win medalteam win gameteam play matchorganism have DNAorganism use energyorganism recycle detritusorganism respond to selectionorganism modify environmentTable 3: Some of the most frequent basic propositionscontaining the words ?team?
and ?organism?, discov-ered by our system from Wikipedia.specific domains.
One of the goals of Learning byReading is to enable a computer to acquire basicknowledge of different domains in order to im-prove question answering systems (Hovy et al,2011).
We assume that the head expressions ofthe most frequent triples extracted from a spe-cific domain represent basic propositions (com-mon knowledge) of that domain.To check this assumption, we built two domain-specific corpora from Wikipedia: a corpus consti-tuted by articles about sports, and another corpuswith articles about Biology.
Then, we extractedthe triples from those corpora and, for each triple,we selected just the head words of its three ele-ments: namely the main verb (and preposition ifany) of the relation and the head nouns of the twoarguments.
It resulted in a list of basic proposi-tions of a specific domain.
Table 3 shows some ofthe propositions acquired following this method.They are some of the most frequent propositionscontaining two specific words, ?team?
and ?or-ganism?, in the subject position (arg1) of thetriples.
The propositions with ?team?
were ex-tracted from the corpus about sports, while thosewith ?organism?
were acquired from the corpusof Biology.6 Conclusions and Current WorkWe have described a multilingual Open Infor-mation Extraction method to extract verb-basedtriples from massive corpora.
The methodachieves better precision than state of the art sys-tems, since it is based on deep syntactic informa-tion, namely dependency trees.
In addition, giventhat dependency analysis is performed by fast, ro-bust, and multilingual parsers, the method is scal-able and applied to texts in several languages: wemade experiments in English, Portuguese, Span-ish, and Galician.Our work shows that it is possible to performOpen Information Extraction by making use ofknowledge-rich tools, namely rule-based depen-dency parsing and pattern-based extraction rules,while remaining scalable.Even if in the experiments reported here we didnot deal with relationships that are not binary, theuse of deep syntactic information makes it easy tobuild n-ary relations from such cases, for instancecomplex events with internal (subject and object)and external (time and location) arguments: ?Thetreaty was signed by Portugal in 2003 in Lisbon?.Furthermore, the use of deep syntactic informa-tion will also be useful to find important relation-ships that are not expressed by verbs.
For in-stance, from the noun phrase ?Nobel Prize?, weshould extract the basic proposition: (Nobel, is a,prize).In current work, we are working on synonymyresolution for two different cases found in the ex-tracted triples: first, the case of multiple propernames for the same named entity and, second,the multiple ways a relationship can be expressed.Concerning the latter case, to solve relationshipsynonymy, we are making use of classic methodsfor relation extraction.
Given a predefined set oftarget relations, a set of lexico-syntactic patternsis learned and used to identify those triples ex-pressing the same relationship.
This way, tradi-tional closed information extraction could be per-ceived as a specific task aimed at normalizing andsemantically organizing the results of open infor-mation extraction.AcknowledgmentsThis work has been supported by the MICINN,within the projects with reference FFI2010-14986and FFI2009-08828, as well as by Diputacio?n deOurense (INOU11A-04).ReferencesMichele Banko, Michael J Cafarella, Stephen Soder-land, Matt Broadhead, and Oren Etzioni.
2007.Open information extraction from the web.
In Inter-national Joint Conference on Artificial Intelligence.Michele Banko, , and Oren Etzioni.
2008.
The trade-offs between open and traditional relation extrac-17tion.
In Annual Meeting of the Association for Com-putational Linguistics.K.
Barker, B. Agashe, S. Chaw, J.
Fan, N. Friedland,M.
Glass, J. Hobbs, E. Hovy, D. Israel, D.S.
Kim,et al 2007.
Learning by reading: A prototype sys-tem, performance baseline and lessons learned.
InProceeding of Twenty-Second National Conferenceof Artificial Intelligence (AAAI 2007).X.
Carreras, I. Chao, L.
Padro?, and M. Padro?.
2004.An Open-Source Suite of Language Analyzers.In 4th International Conference on Language Re-sources and Evaluation (LREC?04), Lisbon, Portu-gal.Oren Etzioni, Michele Banko, and Michael J. Ca-farella.
2006.
Machine reading.
In AAAI Confer-ence on Artificial Intelligence.Oren Etzioni, Anthony Fader, Janara Christensen,Stephen Soderland, and Mausam.
2011.
Openinformation extraction: the second generation.
InInternational Joint Conference on Artificial Intelli-gence.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In Conference on Empirical Methods inNatural Language Processing.Pablo Gamallo and Isaac Gonza?lez.
2011.
A gram-matical formalism based on patterns of part-of-speech tags.
International Journal of Corpus Lin-guistics, 16(1):45?71.Eduard Hovy, Chin yew Lin, and Liang Zhou.
2005.A BE-based Multi-document Summarizer with Sen-tence Compression.
In Proceedings of Multilin-gual Summarization Evaluation (ACL workshop).Ann Arbor, MI.Dirk Hovy, Chunliang Zhang, Eduard Hovy, andAnselmo Pe nas.
2011.
Unsupervised discovery ofdomain-specific knowledge from text.
In Proceed-ings of 49th Annual Meeting of the Association forComputational Linguistics, Portland, Oregon, USA.Thomas Lin, Mausman, and Oren Etzioni.
2010.Identifying functional relations in web text.
In Con-ference on Empirical Methods in Natural LanguageProcessing.Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu,Mausam, and Oren Etzioni.
2010.
Adapting openinformation extraction to domain-specific relations.AI Magazine, 31(3):93?102.Fei Wu and Daniel S. Weld.
2010.
Open informationextraction using wikipedia.
In Annual Meeting ofthe Association for Computational Linguistics.18
