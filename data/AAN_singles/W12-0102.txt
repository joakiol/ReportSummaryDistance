Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 10?19,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsMeasuring Comparability of Documents in Non-Parallel Corpora forEfficient Extraction of (Semi-)Parallel Translation EquivalentsFangzhong SuCentre for Translation StudiesUniversity Of LeedsLS2 9JT, Leeds, UKsmlfs@leeds.ac.ukBogdan BabychCentre for Translation StudiesUniversity Of LeedsLS2 9JT, Leeds, UKb.babych@leeds.ac.ukAbstractIn this paper we present and evaluate threeapproaches to measure comparability ofdocuments in non-parallel corpora.
We de-velop a task-oriented definition of compa-rability, based on the performance of auto-matic extraction of translation equivalentsfrom the documents aligned by the pro-posed metrics, which formalises intuitivedefinitions of comparability for machinetranslation research.
We demonstrate ap-plication of our metrics for the task ofautomatic extraction of parallel and semi-parallel translation equivalents and discusshow these resources can be used in theframeworks of statistical and rule-basedmachine translation.1 IntroductionParallel corpora have been extensively exploitedin different ways in machine translation (MT)?
both in Statistical (SMT) and more recently,in Rule-Based (RBMT) architectures: in SMTaligned parallel resources are used for buildingtranslation phrase tables and calculating transla-tion probabilities; and in RBMT, they are usedfor automatically building bilingual dictionariesof translation equivalents and automatically deriv-ing bilingual mappings for frequent structural pat-terns.
However, large parallel resources are notalways available, especially for under-resourcedlanguages or narrow domains.
Therefore, in re-cent years, the use of cross-lingual comparablecorpora has attracted considerable attention inthe MT community (Sharoff et al, 2006; Fungand Cheung, 2004a; Munteanu and Marcu, 2005;Babych et al, 2008).Most of the applications of comparable cor-pora focus on discovering translation equivalentsto support machine translation, such as bilinguallexicon extraction (Rapp, 1995; Rapp, 1999;Morin et al, 2007; Yu and Tsujii, 2009; Li andGaussier, 2010; Prachasson and Fung, 2011), par-allel phrase extraction (Munteanu and Marcu,2006), and parallel sentence extraction (Fung andCheung, 2004b; Munteanu and Marcu, 2005;Munteanu et al, 2004; Smith et al, 2010).Comparability between documents is often un-derstood as belonging to the same subject domain,genre or text type, so this definition relies on thesevague linguistic concepts.
The problem with thisdefinition then is that it cannot be exactly bench-marked, since it becomes hard to relate automatedmeasures of comparability to such inexact and un-measurable linguistic concepts.
Research on com-parable corpora needs not only good measures forcomparability, but also a clearer, technologically-grounded and quantifiable definition of compara-bility in the first place.In this paper we relate comparability to use-fulness of comparable texts for MT.
In particu-lar, we propose a performance-based definition ofcomparability, as the possibility to extract parallelor quasi-parallel translation equivalents ?
words,phrases and sentences which are translations ofeach other.
This definition directly relates compa-rability to texts?
potential to improve the qualityof MT by adding extracted phrases to phrase ta-bles, training corpus or dictionaries.
It also can bequantified as the rate of successful extraction oftranslation equivalents by automated tools, suchas proposed in Munteanu and Marcu (2006).Still, successful detection of translation equiv-alents from comparable corpora very much de-10pends on the quality of these corpora, specificallyon the degree of their textual equivalence and suc-cessful alignment on various text units.
There-fore, the goal of this work is to provide compa-rability metrics which can reliably identify cross-lingual comparable documents from raw corporacrawled from the Web, and characterize the de-gree of their similarity, which enriches compara-ble corpora with the document alignment infor-mation, filters out documents that are not usefuland eventually leads to extraction of good-qualitytranslation equivalents from the corpora.To achieve this goal, we need to define ascale to assess comparability qualitatively, met-rics to measure comparability quantitatively, andthe sources to get comparable corpora from.
Inthis work, we directly characterize comparabilityby how useful comparable corpora are for the taskof detecting translation equivalents in them, andultimately to machine translation.
We focus ondocument-level comparability, and use three cat-egories for qualitative definition of comparabilitylevels, defined in terms of granularity for possiblealignment:?
Parallel: Traditional parallel texts that aretranslations of each other or approximatetranslations with minor variations, which canbe aligned on the sentence level.?
Strongly-comparable: Texts that talk aboutthe same event or subject, but in differentlanguages.
For example, international newsabout oil spill in the Gulf of Mexico, orlinked articles in Wikipedia about the sametopic.
These documents can be aligned onthe document level on the basis of their ori-gin.?
Weakly-comparable: Texts in the same sub-ject domain which describe different events.For example, customer reviews about hoteland restaurant in London.
These documentsdo not have an independent alignment acrosslanguages, but sets of texts can be alignedon the basis of belonging to the same subjectdomain or sub-domain.In this paper, we present three different ap-proaches to measure the comparability of cross-lingual (especially under-resourced languages)comparable documents: a lexical mapping basedapproach, a keyword based approach, and a ma-chine translation based approach.
The experimen-tal results show that all of them can effectivelypredict the comparability levels of the compareddocument pairs.
We then further investigate theapplicability of the proposed metrics by measur-ing their impact on the task of parallel phrase ex-traction from comparable corpora.
It turns outthat, higher comparability level predicted by themetrics consistently lead to more number of paral-lel phrase extracted from comparable documents.Thus, the metrics can help select more compara-ble document pairs to improve the performance ofparallel phrase extraction.The remainder of this paper is organized as fol-lows.
Section 2 discusses previous work.
Section3 introduces our comparability metrics.
Section4 presents the experimental results and evaluation.Section 5 describes the application of the metrics.Section 6 discusses the pros and cons of the pro-posed metrics, followed by conclusions and futurework in Section 7.2 Related WorkThe term ?comparability?, which is the key con-cept in this work, applies to the level of corpora,documents and sub-document units.
However, sofar there is no widely accepted definition of com-parability.
For example, there is no agreement onthe degree of similarity that documents in com-parable corpora should have or on the criteria formeasuring comparability.
Also, most of the workthat performs translation equivalent extraction incomparable corpora usually assumes that the cor-pora they use are reliably comparable and focuseson the design of efficient extraction algorithms.Therefore, there has been very little literature dis-cussing the characteristics of comparable corpora(Maia, 2003).
In this section, we introduce somerepresentative work which tackles comparabilitymetrics.Some studies (Sharoff, 2007; Maia, 2003;McEnery and Xiao, 2007) analyse comparabilityby assessing corpus composition, such as struc-tural criteria (e.g., format and size), and linguisticcriteria (e.g., topic, domain, and genre).
Kilgarriffand Rose (1998) measure similarity and homo-geneity between monolingual corpora.
They gen-erate word frequency list from each corpus andthen apply ?2 statistic on the most frequent n (e.g.,500) words of the compared corpora.11The work which deals with comparabilitymeasures in cross-lingual comparable corpora iscloser to our work.
Saralegi et al (2008) measurethe degree of comparability of comparable cor-pora (English and Basque) according to the dis-tribution of topics and publication dates of docu-ments.
They compute content similarity for all thedocument pairs between two corpora.
These sim-ilarity scores are then input as parameters for theEMD (Earth Mover?s Distance) distance measure,which is employed to calculate the global com-patibility of the corpora.
Munteanu and Marcu(2005; 2006) select more comparable documentpairs in a cross-lingual information retrieval basedmanner by using a toolkit called Lemur1.
Theretrieved document pairs then serve as input forthe tasks of parallel sentence and sub-sentence ex-traction.
Smith et al (2010) treat Wikipedia asa comparable corpus and use ?interwiki?
links toidentify aligned comparable document pairs forthe task of parallel sentence extraction.
Li andGaussier (2010) propose a comparability met-ric which can be applied at both document leveland corpus level and use it as a measure to se-lect more comparable texts from other externalsources into the original corpora for bilingual lex-icon extraction.
The metric measures the propor-tion of words in the source language corpus trans-lated in the target language corpus by looking upa bilingual dictionary.
They evaluate the met-ric on the rich-resourced English-French languagepair, thus good dictionary resources are available.However, this is not the case for under-resourcedlanguages in which reliable language resourcessuch as machine-readable bilingual dictionarieswith broad word coverage or word lemmatizersmight be not publicly available.3 Comparability MetricsTo measure the comparability degree of documentpairs in different languages, we need to translatethe texts or map lexical items from the source lan-guage into the target languages so that we cancompare them within the same language.
Usuallythis can be done by using bilingual dictionaries(Rapp, 1999; Li and Gaussier, 2010; Prachassonand Fung, 2011) or existing machine translationtools.
Based on this process, in this section wepresent three different approaches to measure the1Available at http://www.lemurproject.org/comparability of comparable documents.3.1 Lexical mapping based metricIt is straightforward that we expect a bilingual dic-tionary can be used for lexical mapping between alanguage pair.
However, unlike the language pairsin which both languages are rich-resourced (e.g.,English-French, or English-Spanish) and dictio-nary resources are relatively easy to obtain, it islikely that bilingual dictionaries with good wordcoverage are not publicly available for under-resourced languages (e.g., English-Slovenian, orEnglish-Lithuanian).
In order to address thisproblem, we automatically construct dictionariesby using word alignment on large-scale parallelcorpora (e.g., Europarl and JRC-Acquis2).Specifically, GIZA++ toolkit (Och and Ney,2000) with default setting is used for word align-ment on the JRC-Acquis parallel corpora (Stein-berger et al, 2006).
The aligned word pairs to-gether with the alignment probabilities are thenconverted into dictionary entries.
For example,in Estonian-English language pair, the alignmentexample ?kompanii company 0.625?
in the wordalignment table means the Estonian word ?kom-panii?
can be translated as (or aligned with) theEnglish candidate word ?company?
with a prob-ability of 0.625.
In the dictionary, the transla-tion candidates are ranked by translation proba-bility in descending order.
Note that the dictio-nary collects inflectional form of words, but notonly base form of words.
This is because the dic-tionary is directly generated from the word align-ment results and no further word lemmatization isapplied.Using the resulting dictionary, we then per-form lexical mapping in a word-for-word map-ping strategy.
We scan each word in the sourcelanguage texts to check if it occurs in the dic-tionary entries.
If so, the first translation candi-date are recorded as the corresponding mappingword.
If there are more than one translation can-didate, the second candidate will also be kept asthe mapping result if its translation probability ishigher than 0.33.
For non-English and English2The JRC-Acquis covers 22 European languages andprovides large-scale parallel corpora for all the 231 languagepairs.3From the manual inspection on the word alignment re-sults, we find that if the alignment probability is higher than0.3, it is more reliable.12language pair, the non-English texts are mappedinto English.
If both languages are non-English(e.g., Greek-Romanian), we use English as a pivotlangauge and map both the source and targetlanguage texts into English4.
Due to the lackof reliable linguistic resources in non-Englishlanguages, mapping texts from non-English lan-guage into English can avoid language process-ing in non-English texts and allows us to makeuse of the rich resources in English for furthertext processing, such as stop-word filtering andword lemmatization5.
Finally, cosine similaritymeasure is applied to compute the comparabilitystrength of the compared document pairs.3.2 Keyword based metricThe lexical mapping based metric takes all thewords in the text into account for comparabilitymeasure, but if we only retain a small number ofrepresentative words (keywords) and discard allthe other less informative words in each docu-ment, can we judge the comparability of a doc-ument pair by comparing these words?
Our in-tuition is that, if two document share more key-words, they should be more comparable.
Tovalidate this, we then perform keyword extrac-tion by using a simple TFIDF based approach,which has been shown effective for keyword orkeyphrase extraction from the texts (Frank et al,1999; Hulth, 2003; Liu et al, 2009).More specifically, the keyword based metriccan be described as below.
First, similar to thelexical mapping based metric, bilingual dictionar-ies are used to map non-English texts into En-glish.
Thus, only the English resources are ap-plied for stop-word filtering and word lemmatiza-tion, which are useful text preprocessing steps forkeyword extraction.
We then use TFIDF to mea-sure the weight of words in the document and rankthe words by their TFIDF weights in descendingorder.
The top n (e.g., 30) words are extractedas keywords to represent the document.
Finally,the comparability of each document pair is deter-mined by applying cosine similarity to their key-4Generally in JRC-Acquis, the size of parallel corporafor most of non-English langauge pairs is much smaller thanthat of language pairs which contain English.
Therefore, theresulting bilingual dictionaries which contain English havebetter word coverage as they have many more dictionary en-tries.5We use WordNet (Fellbaum, 1998) for word lemmatiza-tion.word lists.3.3 Machine translation based metricsBilingual dictionary is used for word-for-wordtranslation in the lexical mapping based metricand words which do not occur in the dictionarywill be omitted.
Thus, the mapping result is likea list of isolated words and information such asword order, syntactic structure and named entitiescan not be preserved.
Therefore, in order to im-prove the text translation quality, we turn to thestate-of-the-art SMT systems.In practice, we use Microsoft translation API6to translate texts in under-resourced languages(e.g, Lithuanian and Slovenian) into English andthen explore several features for comparabilitymetric design, which are listed as below.?
Lexical feature: Lemmatized bag-of-wordrepresentation of each document after stop-word filtering.
Lexical similarity (denotedby WL) of each document pair is then ob-tained by applying cosine measure to the lex-ical feature.?
Structure feature: We approximate it bythe number of content words (adjectives, ad-verbs, nouns, verbs and proper nouns) andthe number of sentences in each document,denoted by CD and SD respectively.
The in-tuition is that, if two documents are highlycomparable, their number of content wordsand their document length should be similar.The structure similarity (denoted by WS) oftwo documentsD1 andD2 is defined as bel-low.WS = 0.5 ?
(CD1/CD2)+ 0.5 ?
(SD1/SD2)suppose that CD1<=CD2, and SD1<=SD2.?
Keyword feature: Top-20 words (ranked byTFIDF weight) of each document.
keywordsimilarity (denoted by WK) of two docu-ments is also measured by cosine.?
Named entity feature: Named entities ofeach document.
If more named entities co-occur in two documents, they are very likelyto talk about the same event or subject and6Available at http://code.google.com/p/microsoft-translator-java-api/13thus should be more comparable.
We useStanford named entity recognizer7 to extractnamed entities from the texts (Finkel et al,2005).
Again, cosine is then applied to mea-sure the similarity of named entities (denotedby WN ) between a document pair.We then combine these four different types ofscore in an ensemble manner.
Specifically, aweighted average strategy is applied: each indi-vidual score is associated with a constant weight,indicating the relative confidence (importance) ofthe corresponding type of score.
The overall com-parability score (denoted by SC) of a documentpair is thus computed as below:SC = ?
?WL + ?
?WS + ?
?WK + ?
?WNwhere ?, ?, ?, and ?
?
[0, 1], and ?+?+?+?
=1.
SC should be a value between 0 and 1, andlarger SC value indicates higher comparabilitylevel.4 Experiment and Evaluation4.1 Data sourceTo investigate the reliability of the proposedcomparability metrics, we perform experimentsfor 6 language pairs which contain under-resoured languages: German-English (DE-EN),Estonian-English (ET-EN), Lithuanian-English(LT-EN), Latvian-English (LV-EN), Slovenian-English (SL-EN) and Greek-Romanian (EL-RO).A comparable corpus is collected for each lan-guage pair.
Based on the definition of compa-rability levels (see Section 1), human annota-tors fluent in both languages then manually anno-tated the comparability degree (parallel, strongly-comparable, and weakly-comparable) at the doc-ument level.
Hence, these bilingual comparablecorpora are used as gold standard for experiments.The data distribution for each language pair, i.e.,number of document pairs in each comparabilitylevel, is given in Table 1.4.2 Experimental resultsWe adopt a simple method for evaluation.
Foreach language pair, we compute the averagescores for all the document pairs in the same com-parability level, and compare them to the gold7Available at http://nlp.stanford.edu/software/CRF-NER.shtmlLanguagepair#documentpairparallel strongly-comparableweakly-comparableDE-EN 1286 531 715 40ET-EN 1648 182 987 479LT-EN 1177 347 509 321LV-EN 1252 184 558 510SL-EN 1795 532 302 961EL-RO 485 38 365 82Table 1: Data distribution of gold standard corporastandard comparability labels.
In addition, in or-der to better reveal the relation between the scoresobtained from the proposed metrics and compara-bility levels, we also measure the Pearson correla-tion between them8.
For the keyword based met-ric, top 30 keywords are extracted from each textfor experiment.
For the machine translation basedmetric, we empirically set ?
= 0.5, ?
= ?
= 0.2,and ?
= 0.1.
This is based on the assumptionthat, lexical feature can best characterize the com-parability given the good translation quality pro-vided by the powerful MT system, while keywordand named entity features are also better indica-tors of comparability than the simple documentlength information.The results for the lexical mapping based met-ric, the keyword based metric and the machinetranslation based metric are listed in Table 2, 3,and 4, respectively.Languagepairparallel strongly-comparableweakly-comparablecorrelationDE-EN 0.545 0.476 0.182 0.941ET-EN 0.553 0.381 0.228 0.999LT-EN 0.545 0.461 0.225 0.964LV-EN 0.625 0.494 0.179 0.973SL-EN 0.535 0.456 0.314 0.987EL-RO 0.342 0.131 0.090 0.932Table 2: Average comparability scores for lexical map-ping based metricOverall, from the average scores for eachcomparability level presented in Table 2, 3,and 4, we can see that, the scores obtainedfrom the three comparability metrics can reli-8For correlation measure, we use numerical calibrationto different comparability degrees: ?Parallel?, ?strongly-comparable?
and ?weakly-comparable?
are converted as 3,2, and 1, respectively.
The correlation is then computedbetween the numerical comparability levels and the cor-responding average comparability scores automatically de-rived from the metrics.14Languagepairparallel strongly-comparableweakly-comparablecorrelationDE-EN 0.526 0.486 0.084 0.941ET-EN 0.502 0.345 0.184 0.990LT-EN 0.485 0.420 0.202 0.954LV-EN 0.590 0.448 0.124 0.975SL-EN 0.551 0.505 0.292 0.937EL-RO 0.210 0.110 0.031 0.997Table 3: Average comparability scores for keywordbased metricLanguagepairparallel strongly-comparableweakly-comparablecorrelationDE-EN 0.912 0.622 0.326 0.999ET-EN 0.765 0.547 0.310 0.999LT-EN 0.755 0.613 0.308 0.984LV-EN 0.770 0.627 0.236 0.966SL-EN 0.779 0.582 0.373 0.988EL-RO 0.863 0.446 0.214 0.988Table 4: Average comparability scores for machinetranslation based metricably reflect the comparability levels across dif-ferent language pairs, as the average scoresfor higher comparable levels are always sig-nificantly larger than those of lower compara-ble levels, namely SC(parallel)>SC(strongly-comparable)>SC(weakly-comparable).
In addi-tion, in all the three metrics, the Pearson correla-tion scores are very high (over 0.93) across dif-ferent language pairs, which indicate that thereis strong correlation between the comparabilityscores obtained from the metrics and the corre-sponding comparability level.Moreover, from the comparison of Table 2, 3,and 4, we also have several other findings.
Firstly,the performance of keyword based metric (seeTable 3) is comparable to the lexical mappingbased metric (see Table 2) as their comparabilityscores for the corresponding comparability levelsare similar.
This means it is reasonable to deter-mine the comparability level by only comparing asmall number of keywords of the texts.
Secondly,the scores obtained from the machine translationbased metric (see Table 4) are significantly higherthan those in both the lexical mapping based met-ric and the keyword based metric.
Clearly, thisis due to the advantages of using the state-of-the-art MT system.
In comparison to the approachof using dictionary for word-for-word mapping,it can provide much better text translation whichallows detecting more proportion of lexical over-lapping and mining more useful features in thetranslated texts.
Thirdly, in the lexical mappingbased metric and keyword based metric, we canalso see that, although the average scores for EL-RO (both under-resourced languages) conform tothe comparability levels, they are much lower thanthose of the other 5 language pairs.
The reasonis that, the size of the parallel corpora in JRC-Acquis for these 5 language pairs are significantlylarger (over 1 million parallel sentences) than thatof EL-EN, RO-EN9, and EL-RO, thus the result-ing dictionaries of these 5 language pairs also con-tain many more dictionary entries.5 ApplicationThe experiments in Section 4 confirm the reli-ability of the proposed metrics.
The compara-bility metrics are thus useful for collecting high-quality comparable corpora, as they can help filterout weakly comparable or non-comparable doc-ument pairs from the raw crawled corpora.
Butare they also useful for other NLP tasks, such astranslation equivalent detection from comparablecorpora?
In this section, we further measure theimpact of the metrics on parallel phrase extraction(PPE) from comparable corpora.
Our intuition isthat, if document pairs are assigned higher com-parability scores by the metrics, they should bemore comparable and thus more parallel phrasescan be extracted from them.The algorithm of parallel phrase extraction,which develops the approached presented inMunteanu and Marcu (2006), uses lexical over-lap and structural matching measures (Ion, 2012).Taking a list of bilingual comparable documentpairs as input, the extraction algorithm involvesthe following steps.1.
Split the source and target language docu-ments into phrases.2.
Compute the degree of parallelism for eachcandidate pair of phrases by using the bilin-gual dictionary generated from GIZA++(base dictionary), and retain all the phrasepairs with a score larger than a predefinedparallelism threshold.9Remember that in our experiment, English is used as thepivot language for non-English langauge pairs.153.
Apply GIZA++ to the retained phrase pairsto detect new dictionary entries and add themto the base dictionary.4.
Repeat Step 2 and 3 for several times (empir-ically set at 5) by using the augmented dic-tionary, and output the detected phrase pairs.Phrases which are extracted by this algorithmare frequently not exact translation equivalents.Below we give some English-German examplesof extracted equivalents with their correspondingalignment scores:1.
But a successful mission ?
seiner u?berauserfolgreichen Mission abgebremst ?0.8155019893333332.
Former President Jimmy Carter ?
Derehemalige US-Pra?sident Jimmy Carter ?0.697083249768253.
on the Korean Peninsula ?
auf der koreanis-chen Halbinsel ?
0.86774321454. across the Muslim world ?
mit der muslim-ischen Welt ermo?glichen ?
0.8933308645. to join the United Nations ?
der Wegin die Vereinten Nationen offensteht ?0.397418711927629Even though some of the extracted phrases arenot exact translation equivalents, they may stillbe useful resources both for SMT and RBMT ifthese phrases are passed through an extra pre-processing stage, of if the engines are modifiedspecifically to work with semi-parallel translationequivalents extracted from comparable texts.
Weaddress this issue in the discussion section (seeSection 6).For evaluation, we measure how the metrics af-fect the performance of parallel phrase extractionalgorithm on 5 language pairs (DE-EN, ET-EN,LT-EN, LV-EN, and SL-EN).
A large raw compa-rable corpus for each language pair was crawledfrom the Web, and the metrics were then appliedto assign comparability scores to all the docu-ment pairs in each corpus.
For each language pair,we set three different intervals based on the com-parability score (SC) and randomly select 500document pairs in each interval for evaluation.For the MT based metric, the three intervals are(1) 0.1<=SC<0.3, (2) 0.3<=SC<0.5, and (3)SC>=0.5.
For the lexical mapping based metricand keyword based metric, since their scores arelower than those of the MT based metric for eachcomparability level, we set three lower intervals at(1) 0.1<=SC<0.2, (2) 0.2<=SC<0.4, and (3)SC>=0.4.
The experiment focuses on countingthe number of extracted parallel phrases with par-allelism score>=0.410, and computes the averagenumber of extracted phrases per 100000 words(the sum of words in the source and target lan-guage documents) for each interval.
In addition,the Pearson correlation measure is also applied tomeasure the correlation between the interval11 ofcomparability scores and the number of extractedparallel phrases.
The results which summarize theimpact of the three metrics to the performance ofparallel phrase extraction are listed in Table 5, 6,and 7, respectively.Languagepair0.1<=SC<0.20.2<=SC<0.4SC>=0.4 correlationDE-EN 728 1434 2510 0.993ET-EN 313 631 1166 0.989LT-EN 258 419 894 0.962LV-EN 470 859 1900 0.967SL-EN 393 946 2220 0.975Table 5: Impact of the lexical mapping based metric toparallel phrase extractionLanguagepair0.1<=SC<0.20.2<=SC<0.4SC>=0.4 correlationDE-EN 1007 1340 2151 0.972ET-EN 438 650 1050 0.984LT-EN 306 442 765 0.973LV-EN 600 966 1722 0.980SL-EN 715 1026 1854 0.967Table 6: Impact of the keyword based metric to parallelphrase extractionFrom Table 5, 6, and 7, we can see thatfor all the 5 language pairs, based on the aver-age number of extracted aligned phrases, clearlywe have interval (3)>(2)>(1).
In other words, inany of the three metrics, a higher comparabilitylevel always leads to significantly more number10A manual evaluation of a small set of extracted datashows that parallel phrases with parallelism score>=0.4 aremore reliable.11For the purpose of correlation measure, the three inter-vals are numerically calibrated as ?1?, ?2?, and ?3?, respec-tively.16Languagepair0.1<=SC<0.30.3<=SC<0.5SC>=0.5 correlationDE-EN 861 1547 2552 0.996ET-EN 448 883 1251 0.999LT-EN 293 483 1070 0.959LV-EN 589 1072 2037 0.982SL-EN 560 1151 2421 0.979Table 7: Impact of the machine translation based met-ric to parallel phrase extractionof aligned phrases extracted from the comparabledocuments.
Moreover, although the lexical map-ping based metric and the keyword based metricproduce lower comparability scores than the MTbased metric (see Section 4), they have similarimpact to the task of parallel phrase extraction.This means, the comparability score itself doesnot matter much, as long as the metrics are re-liable and proper thresholds are set for differentmetrics.In all the three metrics, the Pearson correla-tion scores are very close to 1 for all the languagepairs, which indicate that the intervals of compa-rability scores obtained from the metrics are inline with the performance of equivalent extrac-tion algorithm.
Therefore, in order to extract moreparallel phrases (or other translation equivalents)from comparable corpora, we can try to improvethe corpus comparability by applying the compa-rability metrics beforehand to add highly compa-rable document pairs in the corpora.6 DiscussionWe have presented three different approaches tomeasure comparability at the document level.
Inthis section, we will analyze the advantages andlimitations of the proposed metrics, and the feasi-bility of using semi-parallel equivalents in MT.6.1 Pros and cons of the metricsUsing bilingual dictionary for lexical mapping issimple and fast.
However, as it adopts the word-for-word mapping strategy and out-of-vocabulary(OOV) words are omitted, the linguistic structureof the original texts is badly hurt after mapping.Thus, apart from lexical information, it is diffi-cult to explore more useful features for the com-parability metrics.
The TFIDF based keyword ex-traction approach allows us to select more repre-sentative words and prune a large amount of lessinformative words from the texts.
The keywordsare usually relevant to subject and domain terms,which is quite useful in judging the comparabil-ity of two documents.
Both the lexical mappingbased approach and the keyword based approachuse dictionary for lexical translation, thus rely onthe availability and completeness of the dictionaryresources or large scale parallel corpora.For the machine translation based metric, itprovides much better text translation than thedictionary-based approach so that the comparabil-ity of two document can be better revealed fromthe richer lexical information and other usefulfeatures, such as named entities.
However, thetext translation process is expensive, as it dependson the availability of the powerful MT systems12and takes much longer than the simple dictionarybased translation.In addition, we use a translation strategy oftranslating texts from under-resourced (or less-resourced) languages into rich-resourced lan-guage.
In case that both languages are under-resourced languages, English is used as the pivotlangauge for translation.
This can compensate theshortage of the linguistic resources in the under-resourced languages and take advantages of vari-ous resources in the rich-resourced languages.6.2 Using semi-parallel equivalents in MTsystemsWe note that modern SMT and RBMT sys-tems take maximal advantage of strictly parallelphrases, but they still do not use full potentialof the semi-parallel translation equivalents, of thetype that is illustrated in the application section(see Section 5).
Such resources, even though theyare not exact equivalents contain useful informa-tion which is not used by the systems.In particular, the modern decoders do not workwith under-specified phrases in phrase tables, anddo not work with factored semantic features.
Forexample, the phrase:But a successful mission ?
seiner u?beraus er-folgreichen Mission abgebremstThe English side contains the word but, whichpre-supposes contrast, and on the Greman sidewords u?beraus erfolgreichen (?generally success-ful?)
and abgebremst (?slowed down?)
?
whichtaken together exemplify a contrast, since they12Alternatively, we can also train MT systems for texttranslation by using the available SMT toolkits (e.g., Moses)on large scale parallel corpora.17have different semantic prosodies.
In this examplethe semantic feature of contrast can be extractedand reused in other contexts.
However, this wouldrequire the development of a new generation ofdecoders or rule-based systems which can suc-cessfully identify and reuse such subtle semanticfeatures.7 Conclusion and Future workThe success of extracting good-quality translationequivalents from comparable corpora to improvemachine translation performance highly dependson ?how comparable?
the used corpora are.
In thispaper, we propose three different comparabilitymeasures at the document level.
The experimentsshow that all the three approaches can effectivelydetermine the comparability levels of comparabledocument pairs.
We also further investigate theimpact of the metrics on the task of parallel phraseextraction from comparable corpora.
It turns outthat higher comparability scores always lead tosignificantly more parallel phrases extracted fromcomparable documents.
Since better quality ofcomparable corpora should have better applica-bility, our metrics can be applied to select highlycomparable document pairs for the tasks of trans-lation equivalent extraction.In the future work, we will conduct more com-prehensive evaluation of the metrics by capturingits impact to the performance of machine transla-tion systems with extended phrase tables derivedfrom comparable corpora.AcknowledgmentsWe thank Radu Ion at RACAI for providing usthe toolkit of parallel phrase extraction, and thethree anonymous reviewers for valuable com-ments.
This work is supported by the EU fundedACCURAT project (FP7-ICT-2009-4-248347) atthe Centre for Translation Studies, University ofLeeds.ReferencesBogdan Babych, Serge Sharoff and Anthony Hartley.2008.
Generalising Lexical Translation Strategiesfor MT Using Comparable Corpora.
Proceedingsof LREC 2008, Marrakech, Morocco.Yun-Chuang Chiao and Pierre Zweigenbaum.
2002.Looking for candidate translational equivalents inspecialized, comparable corpora.
Proceedings ofCOLING 2002, Taipei, Taiwan.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA,USA.Jenny Finkel, Trond Grenager, and Christopher Man-ning.
2005.
Incorporating Non-local Informationinto Information Extraction Systems by Gibbs Sam-pling.
Proceedings of ACL 2005, University ofMichigan, Ann Arbor, USA.Eibe Frank, Gordon Paynter and Ian Witten.
1999.Domain-specific keyphrase extraction.
Proceedingsof IJCAI 1999, Stockholm, Sweden.Pascale Fung and Percy Cheung.
2004a.
Mining verynon-parallel corpora: Parallel sentence and lexiconextraction via bootstrapping and EM.
Proceedingsof EMNLP 2004, Barcelona, Spain.Pascale Fung and Percy Cheung.
2004b.
Multi-levelbootstrapping for extracting parallel sentences froma quasicomparable corpus.
Proceedings of COL-ING 2004, Geneva, Switzerland.Anette Hulth.
2003.
Improved Automatic KeywordExtraction Given More Linguistic Knowledge.
Pro-ceedings of EMNLP 2003, Sapporo, Japan.Radu Ion.
2012.
PEXACC: A Parallel Data MiningAlgorithm from Comparable Corpora.
Proceedingsof LREC 2012, Istanbul, Turkey.Adam Kilgarriff and Tony Rose.
1998.
Measures forcorpus similarity and homogeneity.
Proceedings ofEMNLP 1998, Granada, Spain.Bo Li and Eric Gaussier.
2010.
Improving cor-pus comparability for bilingual lexicon extractionfrom comparable corpora.
Proceedings of COL-ING 2010, Beijing, China.Feifan Liu, Deana Pennell, Fei Liu and Yang Liu.2009.
Unsupervised Approaches for AutomaticKeyword Extraction Using Meeting Transcripts.Proceedings of NAACL 2009, Boulder, Colorado,USA.Belinda Maia.
2003.
What are comparable corpora?Proceedings of the Corpus Linguistics workshop onMultilingual Corpora: Linguistic requirements andtechnical perspectives, 2003, Lancaster, U.K.Anthony McEnery and Zhonghua Xiao.
2007.
Par-allel and comparable corpora?
In IncorporatingCorpora: Translation and the Linguist.
TranslatingEurope.
Multilingual Matters, Clevedon, UK.Emmanuel Morin, Beatrice Daille, Korchi Takeuchiand Kyo Kageura.
2007.
Bilingual terminologymining ?
using brain, not brawn comparable cor-pora.
Proceedings of ACL 2007, Prague, Czech Re-public.Dragos Munteanu and Daniel Marcu.
2006.
Ex-tracting parallel sub-sentential fragments from non-parallel corpora.
Proceedings of ACL 2006, Syn-dey, Australia.Dragos Munteanu and Daniel Marcu.
2005.
Improv-ing machine translation performance by exploitingnon-parallel corpora.
Computational Linguistics,31(4): 477-504.18Dragos Munteanu, Alexander Fraser and DanielMarcu.
2004.
Improved machine translationperformance via parallel sentence extraction fromcomparable corpora.
Proceedings of HLT-NAACL2004, Boston, USA.Franz Och and Hermann Ney.
2000.
Improved Statis-tical Alignment Models.
Proceedings of ACL 2000,Hongkong, China.Emmanuel Prochasson and Pascale Fung.
2011.
RareWord Translation Extraction from Aligned Compa-rable Documents.
Proceedings of ACL-HLT 2011,Portland, USA.Reinhard Rapp.
1995.
Identifying Word Translationin Non-Parallel Texts.
Proceedings of ACL 1995,Cambridge, Massachusetts, USA.Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated English and Ger-man corpora.
Proceedings of ACL 1999, CollegePark, Maryland, USA.Xabier Saralegi, Inaki Vicente and Antton Gurrutxaga.2008.
Automatic Extraction of Bilingual Termsfrom Comparable Corpora in a Popular ScienceDomain.
Proceedings of the Workshop on Compa-rable Corpora, LREC 2008, Marrakech, Morocco.Serge Sharoff.
2007.
Classifying Web corpora intodomain and genre using automatic feature identifi-cation.
Proceedings of 3rd Web as Corpus Work-shop, Louvain-la-Neuve, Belgium.Serge Sharoff, Bogdan Babych and Anthony Hartley.2006.
Using Comparable Corpora to Solve Prob-lems Difficult for Human Translators.
Proceedingsof ACL 2006, Syndey, Australia.Jason Smith, Chris Quirk and Kristina Toutanova.2010.
Extracting Parallel Sentences from Compa-rable Corpora using Document Level Alignment.Proceedings of NAACL 2010, Los Angeles, USA.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat and Dan Tufis.
2006.
The JRC-Acquis: A multilingual aligned parallel corpuswith 20+ languages.
Proceedings of LREC 2006,Genoa, Italy.Kun Yu and Junichi Tsujii.
2009.
Extracting bilingualdictionary from comparable corpora with depen-dency heterogeneity.
Proceedings of HLT-NAACL2009, Boulder, Colorado, USA.19
