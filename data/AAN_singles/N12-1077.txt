2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616?620,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsMeasuring Word Relatedness Using Heterogeneous Vector Space ModelsWen-tau YihMicrosoft ResearchOne Microsoft WayRedmond, WAscottyih@microsoft.comVahed Qazvinian?Department of EECSUniversity of MichiganAnn Arbor, MIvahed@umich.eduAbstractNoticing that different information sources of-ten provide complementary coverage of wordsense and meaning, we propose a simple andyet effective strategy for measuring lexical se-mantics.
Our model consists of a committeeof vector space models built on a text cor-pus, Web search results and thesauruses, andmeasures the semantic word relatedness us-ing the averaged cosine similarity scores.
De-spite its simplicity, our system correlates withhuman judgements better or similarly com-pared to existing methods on several bench-mark datasets, including WordSim353.1 IntroductionMeasuring the semantic relatedness of words is afundamental problem in natural language process-ing and has many useful applications, includingtextual entailment, word sense disambiguation, in-formation retrieval and automatic thesaurus discov-ery.
Existing approaches can be roughly catego-rized into two kinds: knowledge-based and corpus-based, where the former includes graph-based algo-rithms and similarity measures operating on a lexicaldatabase such as WordNet (Budanitsky and Hirst,2006; Agirre et al, 2009) and the latter consistsof various kinds of vector space models (VSMs)constructed with the help of a large collection oftext (Reisinger and Mooney, 2010; Radinsky et al,2011).
In this paper, we present a conceptuallysimple model for solving this problem.
Observingthat various kinds of information sources, such as?Work conducted while interning at Microsoft Research.general text corpora, Web search results and the-sauruses, have different word and sense coverage,we first build individual vector space models fromeach of them separately.
Given two words, eachVSM measures the semantic relatedness by the co-sine similarity of the corresponding vectors in itsspace.
The final prediction is simply the averagedcosine scores derived from these VSMs.
Despiteits simplicity, our system surprisingly yields verystrong empirical performance.
When comparing thepredictions with the human annotations on four dif-ferent datasets, our system achieves higher correla-tion than existing methods on two datasets and pro-vides very competitive results on the others.The rest of this paper is organized as follows.
Sec-tion 2 briefly reviews the related work.
Section 3 de-tails how we construct each individual vector spacemodel, followed by the experimental evaluation inSection 4.
Finally, Section 5 concludes the paper.2 BackgroundPrior work on measuring lexical semantics can becategorized as knowledge-based or corpus-based.Knowledge-based methods leverage word relationsencoded in lexical databases such as WordNet andprovide graph-based similarity measures.
Detailedcomparisons of these methods can be found in (Bu-danitsky and Hirst, 2006).
Corpus-based methodsassume related words tend to co-occur or to ap-pear in similar context.
For example, Gabrilovichand Markovitch (2007) measure word relatedness bywhether they tend to occur in the same Wikipediatopic.
In contrast, Reisinger and Mooney (2010)use the conventional ?context vector?
?
neighboring616terms of the occurrences of a target word ?
as theword representation.
In addition, they argue that itis difficult to capture different senses of a word witha single vector, and introduce a multi-prototype rep-resentation.
More recently, Radinsky et al (2011)analyze the temporal aspects of words and argue thatnon-identical terms in two term vectors should alsobe compared based on their temporal usage whencomputing the similarity score.
They construct thevectors using Wikipedia titles, Flickr image tags,and Del.icio.us bookmarks, and extract the temporalfrequency of each concept from 130 years of NewYork Times archive.
Methods that combine modelsfrom different sources do exist.
For instance, Agirreet al (2009) derive a WordNet-based measure us-ing PageRank and combined it with several corpus-based vector space models using SVMs.3 Vector Space Models fromHeterogeneous SourcesIn this section, we describe how we construct vari-ous vector space models (VSMs) to represent words,including corpus-based, Web-based and thesaurus-based methods.Corpus-based VSMs follow the standard ?distri-butional hypothesis,?
which states that words ap-pearing in the same contexts tend to have simi-lar meaning (Harris, 1954).
Each target word isthus represented by a high-dimensional sparse term-vector that consists of words occurring in its con-text.
Given a corpus, we first collect terms withina window of [?10,+10] centered at each occur-rence of a target word.
This bag-of-words repre-sentation is then mapped to the TF-IDF term vector:each term is weighted by log(freq) ?
log(N/df),where freq is the number of times the term appearsin the collection, df the document frequency of theterm in the whole corpus and N the number of totaldocuments.
We further employed two simple tech-niques to improve the quality of these term-vectors:vocabulary and term trimming.
Top 1,500 termswith high document frequency values are treatedas stopwords and removed from the vocabulary.Moreover, we adopted a document-specific featureselection method (Kolcz and Yih, 2007) designedoriginally for text classification and retain only thetop 200 high-weighted terms for each term-vector1.The corpus-based VSMs are created using EnglishWikipedia (Snapshot of Nov. 2010), consisting of917M words after preprocessing (markup tags re-moval and sentence splitting).Web-based VSMs leverage Web search results toform a vector of each query (Sahami and Heilman,2006).
For each word to compare, we issue it as aquery and retrieve the set of relevant snippets (top30 in our experiments) using a popular commercialsearch engine, Bing.
All these snippets together areviewed as a pseudo-document and mapped to a TF-IDF vector as in the corpus-based method.
We donot allow for automatic query expansion in our ex-periments to ensure that the retrieved snippets are di-rectly relevant to the target word and not expansionsbased on synonyms, hypernyms or hyponyms.
Weapply vocabulary trimming (top 1,000 terms withhigh DF values), but not term-trimming as the vec-tors have much fewer terms due to the small numberof snippets collected.Both the corpus-based and Web-based VSMs relyon the distributional hypothesis, which is often criti-cized for two weaknesses.
The first is that word pairsthat appear in the same context or co-occur are notnecessarily highly semantically related.
For exam-ple, ?bread?
and ?butter?
often have cosine scoreshigher than synonyms using corpus-based vectorsbecause of the phrase ?bread and butter?.
The sec-ond is that general corpora often have skewed cov-erage of words due to the Zipf?s law.
Regardless ofthe size of the corpus, the number of occurrencesof a rarely used word is typically very low, whichmakes the quality of the corresponding vector unre-liable.
To address these two issues, we include thethesaurus-based VSMs in this work as well.
Foreach group of similar words (synset) defined in thethesaurus, we treat it as a ?document?
and create adocument?word matrix, where each word is againweighted using its TF-IDF value.
Each column vec-tor in this matrix is thus the thesaurus-based vec-tor of the corresponding word.
Notice that giventwo words and their corresponding vectors, the co-sine score is more general than simply checking1In preliminary experiments, we found that active termswith low TF-IDF values tend to be noise.
By aggressivelyremoving them, the quality of the term-vectors can be signifi-cantly improved.617whether these two words belong to a group of sim-ilar words, as it judges how often they overlap invarious documents (i.e., sets of similar words).
Weexplored using two different thesauri in our exper-iments: WordNet and the Encarta thesaurus devel-oped by Bloomsbury Publishing, where the formerconsists of 227,446 synsets and 190,052 words andthe latter contains 46,945 synsets and 50,184 words.Compared to existing knowledge-based approaches,our VSM transformation is very simple and straight-forward.
It is also easy to extend our method to otherlanguages as only a thesaurus is required rather thana complete lexical database such as WordNet.4 Experimental EvaluationIn this section, we evaluate the quality of the VSMsconstructed using methods described in Section 3 ondifferent benchmark datasets, as well as the perfor-mance when combining them.4.1 Benchmark datasetsWe follow the standard evaluation method, which di-rectly tests the correlation of the word relatednessmeasures with human judgements on a set of wordpairs, using the Spearman?s rank correlation coeffi-cient.
Our study was conducted using four differ-ent datasets, including WS-353, RG-65, MC-30 andMTurk-287.The WordSim353 dataset (WS-353) is the largestamong them and has been used extensively in re-cent work.
Originally collected by Finkelstein etal.
(2001), the dataset consists of 353 word pairs.The degree of relatedness of each pair is assessedon a 0-10 scale by 13-16 human judges, where themean is used as the final score.
Examining therelations between the words in each pair, Agirreet al (2009) further split this dataset into similarpairs (WS-sim) and related pairs (WS-rel), wherethe former contains synonyms, antonyms, identicalwords and hyponyms/hypernyms and the latter cap-ture other word relations.
Collected by Rubensteinand Goodenough (1965), RG-65 contains 65 pairsof words that are either synonyms or unrelated, as-sessed on a 0-4 scale by 51 human subjects.
Taking30 pairs from them, Miller and Charles (1991) cre-ated the (MC-30) dataset by reassessing these wordpairs using 38 subjects.
These 30 pairs of wordsare also a subset of WS-353.
Although these threedatasets contain overlapping word pairs, their scoresare different because of the degree of relatednesswere given by different human subjects.
In additionto these datasets, we also evaluate our VSMs on theMturk-287 dataset that consists of 287 word pairscollected by (Radinsky et al, 2011) using AmazonMTurk.4.2 Results and AnalysisTable 1 summarizes the results of various methods,where the top part lists the performance of state-of-the-art systems and the bottom shows the results ofindividual vector space models, as well as combin-ing these models using the averaged cosine scores.We make several observations here.
First, whilenone of the four VSMs we tested outperforms thebest existing systems on the benchmark datasets,surprisingly, using the averaged cosine scores ofthese models, the performance is improved substan-tially.
It achieves higher Spearman?s rank coeffi-cient on WS-353 and MTurk-287 than any other sys-tems2 and are close to the state-of-the-art on MC-30 and RG-65.
Unlike some approach like (Hughesand Ramage, 2007), which performs well on somedatasets but poorly on others, combing the VSMsfrom heterogeneous sources is more robust.
Individ-ually, we notice that Wikipedia context VSM pro-vides consistently strong results, while thesaurus-based models work only reasonable on MC-30 andRG-65, potentially because other datasets containmore out-of-vocabulary words or proper nouns.
Dueto the inherent ambiguity of the task, there is a highvariance among judgements from different annota-tors.
Therefore, it is unrealistic to assume any of themethods can correlate perfectly to the mean humanjudgement scores.
In fact, the inter-agreement studydone on the WS-353 dataset indicates that the resultof our approach of combining heterogeneous VSMsis close to the averaged human performance.It is intriguing to see that by using the averagedcosine scores, the performance can be improvedover the best individual model (i.e., Wikipedia).
Ex-amining the scores of some word pairs carefully sug-2This may not be statistically significant.
Without havingthe exact output of existing systems, it is difficult to conduct arobust statistical significance test given the small sizes of thesedatasets.618Spearman?s ?Method WS-353 WS-sim WS-rel MC-30 RG-65 MTurk-287(Radinsky et al, 2011) 0.80 - - - - 0.63(Reisinger and Mooney, 2010) 0.77 - - - - -(Agirre et al, 2009) 0.78 0.83 0.72 0.92 0.96 -(Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59(Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 -Web Search 0.56 0.56 0.54 0.48 0.44 0.44Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29WordNet 0.37 0.49 0.49 0.79 0.78 0.25Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semanticword relatedness using the cosine similarity.gests the broader coverage of different words andsenses could be the reason.
For example, someof the words in the datasets have multiple senses,such as ?jaguar vs. car?
and ?jaguar vs. cat?.
Al-though in previous work, researchers try to captureword senses using different vectors (Reisinger andMooney, 2010) from the same text corpus, this is infact difficult in practice.
The usage of words in a bigtext corpus, which contains diversified topics, maystill be biased to one word sense.
For example, inthe Wikipeida term vector that represents ?jaguar?,we found that most of the terms there are related to?cat?.
Although some terms are associated with the?car?
meaning, the signals are rather weak.
Simi-larly, WordNet does not indicate ?jaguar?
could berelated to ?car?
at all.
In contrast, the ?car?
senseof ?jaguar?
dominates the vector created using thesearch engine.
As a result, incorporating modelsfrom different sources could be more effective thanrelying on word sense discovering algorithms op-erating solely on one corpus.
Another similar butdifferent example is the pair of ?bread?
and ?but-ter?, which are treated as synonyms by corpus-basedVSMs, but is demoted after adding the thesaurus-based models.5 ConclusionIn this paper we investigated the usefulness of het-erogeneous information sources in improving mea-sures of semantic word relatedness.
Particularly, wecreated vector space models using 4 data sourcesfrom 3 categories (corpus-based, Web-based andthesaurus-based) and found that simply averagingthe cosine similarity derived from these modelsyields a very robust measure.
Other than directly ap-plying it to measuring semantic relatedness, our ap-proach is complementary to more sophisticated sim-ilarity measures such as developing kernel functionsfor different structured data (Croce et al, 2011),where the similarity between words serves as a basiccomponent.While this result is interesting and encouraging, italso raises several research questions, such as howto enhance the quality of each vector space modeland whether the models can be combined more ef-fectively3.
We also would like to study whether sim-ilar techniques can be useful when comparing longertext segments like phrases or sentences, with poten-tial applications in paraphrase detection and recog-nizing textual entailment.AcknowledgmentsWe thank Joseph Reisinger for providing his pro-totype vectors for our initial study, Silviu-PetruCucerzan for helping process the Wikipedia files andGeoffrey Zweig for preparing the Bloomsbury the-saurus data.
We are also grateful to Chris Meekfor valuable discussions and to anonymous review-ers for their comments.3We conducted some preliminary experiments (not reportedhere) on tuning the weights of combining different modelsbased on cross-validation, but did not find consistent improve-ments, perhaps due to the limited size of the data.619ReferencesE.
Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pas?caand A. Soroa.
2009.
A study on similarity and re-latedness using distributional and wordnet-based ap-proaches.
In NAACL ?09, pages 19?27.A.
Budanitsky and G. Hirst.
2006.
Evaluating wordnet-based measures of lexical semantic relatedness.
Com-putational Linguistics, 32:13?47, March.D.
Croce, A. Moschitti, and R. Basili.
2011.
Structuredlexical similarity via convolution kernels on depen-dency trees.
In Proceedings of EMNLP 2011, pages1034?1046, July.L.
Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin,Z.
Solan, G. Wolfman, and E. Ruppin.
2001.
Placingsearch in context: The concept revisited.
In WWW,pages 406?414.
ACM.E.
Gabrilovich and S. Markovitch.
2007.
Computing se-mantic relatedness using wikipedia-based explicit se-mantic analysis.
In IJCAI ?07, pages 1606?1611.Z.
Harris.
1954.
Distributional structure.
Word,10(23):146?162.T.
Hughes and D. Ramage.
2007.
Lexical semantic re-latedness with random graph walks.
In Proceedings ofEMNLP-CoNLL-2007, pages 581?589.A.
Kolcz and W. Yih.
2007.
Raising the baseline forhigh-precision text classifiers.
In KDD ?07, pages400?409.G.
Miller and W. Charles.
1991.
Contextual correlatesof semantic similarity.
Language and cognitive pro-cesses, 6(1):1?28.K.
Radinsky, E. Agichtein, E. Gabrilovich, andS.
Markovitch.
2011.
A word at a time: computingword relatedness using temporal semantic analysis.
InWWW ?11, pages 337?346.J.
Reisinger and R. Mooney.
2010.
Multi-prototypevector-space models of word meaning.
In NAACL ?10.H.
Rubenstein and J. Goodenough.
1965.
Contextualcorrelates of synonymy.
Communications of the ACM,8:627?633, October.M.
Sahami and T. Heilman.
2006.
A web-based ker-nel function for measuring the similarity of short textsnippets.
In Proceedings of the 15th international con-ference on World Wide Web, pages 377?386.
ACM.620
