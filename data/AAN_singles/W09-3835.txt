Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 222?225,Paris, October 2009. c?2009 Association for Computational LinguisticsInteractive Predictive Parsing 1Ricardo Sa?nchez-Sa?ez, Joan-Andreu Sa?nchez and Jose?-Miguel Bened?
?Instituto Tecnolo?gico de Informa?ticaUniversidad Polite?cnica de ValenciaCam??
de Vera s/n, Valencia 46022 (Spain){rsanchez, jandreu, jbenedi}dsic.upv.esAbstractThis paper introduces a formal frameworkthat presents a novel Interactive Predic-tive Parsing schema which can be oper-ated by a user, tightly integrated into thesystem, to obtain error free trees.
Thiscompares to the classical two-step schemaof manually post-editing the erroneus con-stituents produced by the parsing system.We have simulated interaction and cal-culated evalaution metrics, which estab-lished that an IPP system results in a highamount of effort reduction for a manualannotator compared to a two-step system.1 IntroductionThe aim of parsing is to obtain the linguistic in-terpretation of sentences, that is, their underlyingsyntactic structure.
This task is one of the fun-damental pieces needed by a computer to uns-derstand language as used by humans, and hasmany applications in Natural Language Process-ing (Lease et al, 2006).A wide array of parsing methods exist, in-cluding those based on Probabilistic Context-FreeGrammars (PCFGs).
(Charniak, 2000; Collins,2003; Johnson, 1998; Klein and Manning, 2003;Matsuzaki et al, 2005; Petrov and Klein, 2007).The most impressive results are achieved by sub-tree reranking systems, as shown in the semi-supervised method of (McClosky et al, 2006),or the forest reranking approximation of (Huang,2008) in which packed parse forests (compactstructures that contain many possible tree deriva-tions) are used.These state-of-the-art parsers provide trees ofexcelent quality.
However, perfect results are vir-1Work supported by the MIPRCV ?Consolider Inge-nio 2010?
(CSD2007-00018), iTransDoc (TIN2006-15694-CO2-01) and Prometeo (PROMETEO/2009/014) reserachprojects, and the FPU fellowship AP2006-01363.tually never achieved.
If the need of one-hundred-percent error free trees arises, the supervision of auser that post-edits and corrects the errors is un-avoidable.Error free trees are needed in many tasks such ashandwritten mathematical expressions recognition(Yamamoto et al, 2006), or creation of new goldstandard treebanks (Delaclergerie et al, 2008)).For example, in the creation of the Penn Tree-bank grammar, a basic two-stage setup was em-ployed: a rudimentary parsing system providad askeletal syntactic representation, which then wasmanually corrected by human annotators (Marcuset al, 1993).In this paper, we introduce a new formal frame-work that tightly integrates the user within theparsing system itself, rather than keeping him iso-lated from the automatic tools used in a classi-cal two-step approach.
This approach introducesthe user into the parsing system, and we will callit ?interactive predictive parsing?, or simply IPP.An IPP system is interactive because the user is incontinuous contact with the parsing process, send-ing and receiving feedback.
An IPP system is alsopredictive because it reacts to the user corrections:it predicts and suggest new parse trees taking intoaccount the new gold knowledge received fromthe user.
Interactive predictive methods have beenstudied and successfully used in fields like Auto-matic Text Recognition (Toselli et al, 2008) andStatistical Machine Translation (Barrachina et al,2009; Vidal et al, 2006) to ease the work of tran-scriptor and translators.Assessment of the amount of effort saved by theIPP system will be measured by automatically cal-culated metrics.2 Interactive Predictive ParsingA tree t, associated to a string x1|x|, is composedby substructures that are usually referred as con-stituents or edges.
A constituent cAij is a span de-222fined by a nonterminal symbol (or syntactic tag) Athat covers the substring xij .Assume that using a given probabilistic context-free grammar G as the model, the parser analyzesthe input sentence x = x1 .
.
.
x|x| and producesthe parse tree t?t?
= argmaxt?TpG(t|x), (1)where pG(t|x) is the probability of parse tree tgiven the input string x using model G, and T isthe set of all possible parse trees for x.In an interactive predictive scenario, after ob-taining the (probably incorrect) best tree t?, the useris able to modify the edges cAij that are incorrect.The system reacts to each of the corrections intro-duced by the human by proposing a new t??
thattakes into account the corrected edge.
The orderin which incorrect constituents are reviewed deter-mines the amount of effort reduction given by thedegree of correctness of the subsequent proposedtrees.There exist several ways in which a human ana-lyzes a sentende.
A top-to-bottom may be consid-ered natural way of proceeding, and we follow thisapproach in this work.
This way, when a higherlevel constituent is corrected, possible erroneousconstituents at lower levels are expectedly auto-matically recalculated.The introduced IPP interaction process is sim-ilar to the ones already established in Computer-Assisted Text Recognition and Computer-AssistedTranslation 1.Within the IPP framework, the user reviews theconstituents contained in the tree to assess theircorrectness.
When the user find an incorrect edgehe modifies it, setting the correct label and span.This action implicitly validates a subtree that iscomposed by the corrected edge plus all its ances-tor edges, which we will call the validated prefixtree tp.
When the user replaces the constituent cAijwith the correct one c?Aij , the validated prefix treeis:tp(c?Aij ) = {cBmn : m ?
i, n ?
jd(cBmn) ?
d(c?Aij )}(2)with d(cDpq) being the depth of constituent cDpq.1In these fields, the user reads the sentence from left toright.
When the user finds and corrects an erroneus word, heis implicitly validating the prefix sentence up to that word.The remaining suffix sentence is recalculated by the systemtaking into account the validated prefix sentece.When a constituent correction is performed, theprefix tree tp(c?Aij ) is fixed and a new tree t??
thattakes into account the prefix is proposedt??
= argmaxt?TpG(t|x, tp(c?Aij )).
(3)Given that we are working with context-freegrammars, the only subtree that effectively needsto be recalcuted is the one starting from the par-ent of the corrected edge.
Let the corrected edgebe c?Aij and its parent cDst, then the following tree isproposedt??
= argmaxt?TpG(t|x, tp) = (t?
\ t?Dst) ?
t?
?Dst , (4)witht?
?Dst = argmaxtDst?TstpG(tDst|xmn, c?Aij ) .
(5)Expression (4) represents the newly proposedtree t?
?, which consists of original proposed treet?
minus the subpart of the original proposed treet?Dst (whose root is the parent of the corrected edgecDst) plus the newly calculated subtree t?
?Dst (whoseroot is also the parent of the corrected constituentcDst, but also takes into account the corrected oneas shown in Expression (5)).In Figure 1 we show an example that intends toclarify the interactive predictive process.
First, thesystem provides a proposed parse tree (Fig.
1.a).Then the user, which has in his mind the correctreference tree, notices that it has two wrong con-stituents (cX23 and cZ44) (Fig.
1.b), and choses to re-place cX23 by cB22 (Fig.
1.c).
Here, cB22 correspondsto c?Aij from expressions (3) and (5).As the user does this correction, the system au-tomatically validates the correct prefix: all the an-cestors of the modified constituent (dashed line inthe figure, tp(c?Aij ) from expression (2)).
The sys-tem also invalidates the subtrees related to the cor-rected constituent (dotted line line in the figure, t?Dstfrom expression (4)).Finally, the system automatically predicts a newsubtree (t?
?Dst from expression (4)) (Fig.
1.d).
No-tice how cZ34 changes its span and cD44 is introducedwhich provides the correct reference parse.Within the example shown in Figure 1, the userwould obtain the gold tree with just one correction,rather than the three operations needed on a two-step system (one deletion, one substitution and oneinsertion).223SB ZYba c dADC(a) Reference treeSba c dACBXYZ(b) Iteration 0:Proposed out-put tree 1Sba c dACBX Z 423 4Y(c) Iteration 0: Er-roneus constituentsSba c dAB 22 ??
?Y(d) Iteration 1:User correctedconstituentSB ZYba c dADC34(e) Iteration 1:Proposed outputtree 2Figure 1: Synthetic example of user interaction with the IPP system.3 IPP EvaluationThe objective of the experimentation presentedhere is to evaluate the amount of effort saved forthe user using the IPP system, compared to the ef-fort required to manually correct the trees withoutthe use of an interactive system.
In this section, wedefine a standard automatic evaluation protocol,akin to the ones used in Computer-Aided Trans-lation and Computer Aided Text Recognition.In the absence of testing of an interactive sys-tem with real users, the gold reference trees wereused to simulate system interaction by a humancorrector.
In order to do this, the constituents inthe proposed tree were automatically reviewed in apreorder manner 2.
In each step, the constituent inthe proposed tree was compared to the correspond-ing one in the reference tree: if the constituent wasequivalent no action was taken.
When one incor-rect constituent was found in the proposed tree, itwas replaced by the correct one from the referencetree.
This precise step simulated what a human su-pervisor would do, that is, to type the correct con-stituent in place of the erroneus one.The system then performed the predictive step(i.e.
recalculation of subtrees related to the cor-rected constituent).
We kept a correction count,which was incremented by one after each predic-tive step.3.1 Evaluation metricsFor evaluation, first we report a metric represent-ing the amount of human correcting work neededto obtain the gold tree in a classical two-step pro-cess (i.e.
the number of operations needed to post-edit the proposed tree in orther to obtain the gold2Interaction in this ordered manner guaranteed that theevaluation protocol only needed to modify the label A andthe end point j of a given edge cAij , while i remained validgiven the modifications of previous constituents.one).
We then compare this value to a metric thatmeasures the amount of effort needed to obtainthe gold tree with the human interacting within thepresented IPP system.Parsing quality is generally assessed by the clas-sical evaluation metrics, precission, recall and F-measure.
We defined the following metric thatmeasures the amount of effort needed in order topost-edit a proposed tree and obtain the gold ref-erence parse tree, akin to the Word Error Rateused in Statistical Machine Translation and relatedfields:?
Tree Constituent Error Rate (TCER): Min-imum number of constituent substitution,deletion and insertion operations needed toconvert the proposed parse tree into the corre-sponding gold reference tree, divided by thetotal number of constituents in the referencetree 3.The TCER is in fact strongly related to the F-measure: the higher the F-measure is, the lowerTCER will be.Finally, the relevant evaluation metric that as-sessed the IPP system performance represents theamount effort that the operator would have tospend using the system in order to obtain the goldtree, and is directly comparable to the TCER:?
Tree Constituent Action Rate (TCAC): Num-ber of constituent corrections performed us-ing the IPP system to obtain the referencetree, divided by the total number of con-stituents in the reference tree.4 Experimental resultsAn IPP system was implemented over the classicalCYK-Viterbi algorithm.
Experimentation was run3Edit distance is calcualted over the ordered set of treeconstituents.
This is an approximation of the edit distancebetween trees.224over the Penn Tree bank: sections 2 to 21 wereused to obtain a vanilla Penn Treebank Grammar;test set was the whole section 23.We obtained several binarized versions of thetrain grammar for use with the CYK.
The Chom-sky Normal Form (CNF) transformation methodfrom the NLTK4 was used to obtain several right-factored binary grammars of different sizes 5.A basic schema was introduced for parsing sen-tences with out-of-vocabulary words: when aninput word could not be derived by any of thepreterminals in the vanilla treebank grammar, avery small probability for that word was uniformlyadded to all of the preterminals.Results for the metrics discussed on section 3.1for different markovizations of the train grammarcan be seen in Table 1.
We observe that the perc-etage of corrections needed using the IPP systemis much lower than the rate of needed correctionsjust post-editing the proposed trees: from 42% to46% in effort reduction by the human supervisor.These results clearly show that an interactivepredictive system can relieve manual annotators ofa lot of burden in their task.Note that the presented experiments were doneusing parsing models that perform far from the lat-est F1 results; their intention was to assess the util-ity of the IPP schema.
Expected relative reduc-tions with IPP systems incorporating state-of-the-art parsers would not be so large.PCFG Baseline IPP RelRedF1 TCER TCACh=0, v=1 0.67 0.40 0.22 45%h=0, v=2 0.68 0.39 0.21 46%h=0, v=3 0.70 0.38 0.22 42%Table 1: Results for the test set: F1 and TCERfor the baseline system; TCAC for the IPP system;relative reduction beteween TCER and TCAC.5 ConclusionsWe have introduced a novel Interactive PredictiveParsing framewrok which can be operated by auser to obtain error free trees.
We have simulatedinteraction with this system and calculated evalau-tion metrics, which established that an IPP systemresults in a high amount of effort reduction for amanual annotator compared to a two-step system.4http://nltk.sourceforge.net/5This method implements the vertical (v value) and hori-zontal (h value) markovizations (Klein and Manning, 2003).Near term future work includes applying theIPP scenario to state-of-the-art reranking and pars-ing systems, as well as in the development of adap-tative parsing systemsReferencesBarrachina, Sergio, Oliver Bender, Francisco Casacu-berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,Antonio Lagarda, Hermann Ney, Jess Toms, En-rique Vidal, Juan-Miguel Vilar.
2009.
Statistical ap-proaches to computer-assisted translation.
In Com-putational Linguistics, 35(1) 3-28.Charniak, Eugene.
2000.
A maximum-entropy-inspired parser.
In NAACL ?00, 132-139.Collins, Michael.
2003.
Head-driven statistical mod-els for natural language parsing.
In ComputationalLinguistics, 29(4):589-637.De la Clergerie, ?Eric, Olivier Hamon, Djamel Mostefa,Christelle Ayache, Patrick Paroubek and Anne Vil-nat.
2008.
PASSAGE: from French Parser Evalua-tion to Large Sized Treebank.
In LREC?08.Huang, Liang.
2008.
Forest reranking: discriminativeparsing with non-local features.
In ACL ?08.Johnson, Mark.
1998.
PCFG models of linguistictree representation.
In Computational Linguistics,24:613-632.Klein, Dan and Chistopher D. Manning.
2003.
Accu-rate Unlexicalized Parsing.
In ACL ?03, 423-430.Lease, Matthew, Eugene Charniak, Mark Johnson andDavid McClosky.
2006.
A look at parsing and itsapplications.
In National Conference on ArtificialIntelligence, vol.
21-II, 1642-1645.Marcus, Mitchell P., Mary Ann Marcinkiewicz andBeatrice Santorini.
1995.
Building a Large Anno-tated Corpus of English: The Penn Treebank.
Com-putational Linguistics 19(2), 313-330.Matsuzaki, Takuya, Yasuke Miyao and Jun?ichi Tsujii.2005.
Probabilistic CFG with latent annotations.
InACL ?05, 75-82.McClosky, David, Eugene Charniak and Mark John-son.
2006.
Effective self-training for parsing.
InHLT-NAACL ?06Petrov, Slav and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In NAACL-HLT ?07.Toselli, Alejandro, Vero?nica Romero and Enrique Vi-dal.
2008.
Computer Assisted Transcription of TextImages and Multimodal Interaction.
In MLMI ?08.Vidal, Enrique, Francisco Casacuberta, Luis Ro-driguez, Jorge Civera and Carlos D. Martnez Hinare-jos.
2006.
Computer-assisted translation usingspeech recognition.
In IEEE Trans.
on Audio,Speech, and Language Processing, 14(3), 941-951.Yamamoto, Ryo, Shinji Sako, Takuya Nishimoto andShigeki Sagayama.
2006.
On-line recognitionof handwritten mathematical expressions based onstroke-based stochastic context-free grammar.
In10th International Workshop on Frontiers in Hand-writing Recognition.225
