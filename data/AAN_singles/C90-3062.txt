Repair Work in Human-Computer DialogueAlison Cawsey*Department of Artificial Intelligence, University of Edinburgh, Scotlandajc@uk.ae.ed.aipnaPirkko RaudaskoskiEnglish Department, University of Oulu, Finlandekl-pr@finfou.bitnetAbstracl;: If human-computer interaction is to beeffective, it is vi~al that there are opportunities to check onunderstanding, and repair that understanding when it fails.This paper discusses this idea of repair in human-computerinteraction, and provides a number of examples of differenttypes of repair work in an interactive xplanation system.1.
In t roduct ionThe importance of repair in human interaction isincreasingly recognised.
If a dialogue is to pro-ceed smoothly it is vital that there are opportanitiesfor checking understanding and providing clarificationwhen misunderstanding does occur.
Everyday interac-tion is full of such checks and repairs, though these maybe so au~;omatic as to be almost transparent, rarely dis-turbing ~he flow of the interaction.In human-computer interaction, providing opportu-nities for clarification may be even more important.
Ifthe communication is to be robust and effective, thenthere must be opportunities for both parties to 'repair'the interaction when it fails.
If the user is communicat?ing in natural anguage (or even in a complex commandlanguage) then there are many cases where the systemmay not 'understand'.
If the system is giving complexinstructions or explanations, then there are many caseswhere the user may not understand.These checks and repairs have been studied by peo-ple working in the field of conversation analysis (CA) formany years.
For example, people have analysed pref-erences for different ypes of repair \[7\], and typical se-quences of repair moves.Recently, there has been some interest in checks andrepafi" within Cognitive Science (though the approach*Supported by a post-doctoral fellowship from the Science andEngineering Research Councilto the subject is often very different from that of CA).This includes work by Ringle and Bruce \[5\], who anal-yse checking moves and conversation failure, and Clarkand Schaefer \[2\], who have recently proposed a model ofdialogae based on contributions rather than single com-municative acts.
These are the sections of discoursethrough which the participants arrive at the mutualknowledge that the conveyed message is understood,and may involve checking and repair work.Despite the prevalence of checks and repairs in hu-man interaction, there has been very little work withincomputational linguistics on these essential componentsof conversation.
The rest of this paper will discuss theproblem in more detail, and present some examples ofdifferent ypes of repair work in an implemented inter-active explanation system.2.
Repa i r  in  Human In teract ionIn human conversation there are continual implicitacknowledgements that communication is proceedingsmoothly.
The speaker is monitoring the hearer in dif-ferent ways to see if they understand (for example, usingchecking moves such as 'Do you know what I mean?
'),and the 'hearer' is often giving verbal acknowledgementto the speaker (e.g., 'yes', 'uhuh').
If the hearer takesover the conversation, she may acknowledge the last ut-terance implicitly by, for example, continuing the topic\[2\].
However, if the utterance is not understood, ~ re-pair may be initiated.
We can examine this repair fromseveral perspectives:Sequencing:  A typicalrepair sequence may consist ofa repair initiator by the hearer, a repair by the originalspeaker, and an acknowledgement by the hearer.
How-ever, repair sequences in general may be much morecomplex.
For example, the speaker may do a third turn327repair on realising, from the hearer's response that heroriginal utterance was not understood.
These differenttypes of repair have been discussed in \[7\].t tepa l r  In i t ia tors :  Repair initiators may take manyforms in human interaction, including: facial expres-sion; verbal signals ('huh?')
and clarification questions.In human dialogue, the speaker may frequently self-correct without hearer intervention.Source of  Trouble:  Communication may breakdown for many reasons, such as from lack of hearing,reference failure or from general misunderstanding ofcomplex material.
Although the form of the repair ini-tiator may indicate the source of the trouble, this isnot always the case.
It may therefore be necessary toguess at the likely source of trouble, possibly using dis-course context or assumptions about the hearer's knowl-edge to reason about likely problems \[3\].
Repair workboth relies on, and shapes the context of the interac-tion.
However, whatever the source of the problem, thebasic interactional mechanism is the same \[6\].3.
Example Repair WorkIn order to illustrate some of  these different aspects ofrepair, this section will give a number of examples oftypes of repair work in an interactive xplanation sys-tem (the EDGE system, described further in \[1\]).
Theseinclude repairs when the user fails to understand theexplanation, as well as repairs when the system fails tounderstand the user.
These latter are adapted from \[4\].The EDGE system plans explanations of the be-haviour of simple circuits, depending on assumptionsabout the user's knowledge.
These are interactive, withmany opportunities for repair work when the user failsto understand the explanation.
The user input to thesystem consists of one or two word commands or ques-tions, rather than arbitrary natural language utter-ances.
However, even with this restricted input therein an obvious need for repair work which addresses thesystems lack of 'understanding' as well as the users.3.1 User  M isunders tand ingsFirst, we will illustrate how the system may repair usermisunderstandings.
We must consider both how tostructure the dialogue, and how to plan the content ofa specific repair sequence.C lar i f i cat ion Quest ions :  Whenever the systempauses the user may ask a clarification question (us-ing a restricted command language).
The system willnormally reply to this question, then try and get backto what it was in the middle of explaining.
This isachieved using discourse 'plans' to structure the clar-ification sub-dialogue, and a simple notion of focus toattempt o resume the previous discussion in such a waythat it follows on from the topic introduced by the user.The following example illustrates this:S: The light detector circuit's components are: Alight-dependent-resistor and a fixed-resistor.U: What-is-a light-dependent-resistor?S: A light-dependent-resistor is a kind of resis-tor.
Its function is to provide an output resistancewhich depends on the input light intensity.S: Anyway, when its input light intensity is high,its output resistance is quite low ....In this example the system was planning to describethe detailed behaviour of the light detector circuit'scomponents.
Because of the interruption/clarification,the system chooses to first describe the behaviour of thelight dependent resistor.S ignal l ing M isunders tand ing :  The user may alsosignal that they are not following without mentioningthe exact problem - -  maybe they don't know why theydon't understand.
The system must then 'guess' at thelikely source of trouble.
This is done by maintaininga model of the discourse so far which includes any as-sumptions made about the user's knowledge.
In at-tempting a repair the system identifies an assumptionwhich may have been mistaken, then tries to fill in miss-ing knowledge or explain something another way.
Forexample:U: Huh?S: Don't you know what sort of circuit a light-detector-circuit is?U: No.S: OK, A light-detector-circuit is a kind ofpotential-divider circuit.
Anyway..Sys tem initiated remediation: Sometimes the sys-tem can deduce that the user has a misunderstandingfrom the user's utterances (e.g., replies to questions).Then a remediation sequence is initiated by the sys-tem using strategies based on work on tutorial dialogues(e.g., \[8\]).
For example:S: What's the output voltage of the light-detector-circuit?U: High.328S: No, a light-detector-circuit is like a heat-detector.circuit except its output voltage de-pends on the input \]ight-intentity nstead of hear-intensity.
So, what's the output voltage of thelight-detector-circuit?
'Fhese examples illustrate different ways repairs maybe iniated, how repair sequences may be structuredw:ithin an ongoing dialogue, and how the system maytress at problems or use standm'd remediation strate-gies.3.2 System ~Misunders tand lng  ~Within the dialogue there are also places where the usermay ask a question, but the system may not be able toin~;erpret i .
(\['he system must then choose an app,'opri.-at~ repair initiator.
In these examples the user's inputis in the form of a simple command hmguage --- for nat-urnl language input it is even more important o givehelpful repair initiators.Ob ject  mimmders tood:  If the object of the ques-tion is misunderstood, the repair initiator stmuld directattention to that ~missing' object:U: What-is-a light-circuit ?S: What.d,~-~ what?U: light-detector-circuit.S: OK, A light-detector-circuit is a kind of ..Ql:mstion type  misunders tood:  If the questiontype is misunderstood, attention should be directed tothat:U: Whatisa light-detector-circuit ?S: What about the light-detector-circuit?U: What-is-a light-detector-circuit.Both  misunders tood:  If the question is of the rightform but both parts are not understood, the systemsimply says 'what?
'.Wrong form:  If the utter~nce is not of a recognisableform (e.g., it cannot be.
'parsed')j the system informs theuser of acceptable forms (e.g., question-type question-obj).Repeated  errors :  Repair initiators for repeated er-rors give: further information, such ~ lists of relevantobject and question types.These simple examples illustrate tile importance ofnshtg an appropriate repair initiator when the systemfails to understand.
This is important for both com-mand and natural language based input.4.
ConclusionThis paper has illustrated ~tle importance, and some ofthe problems of repair work in human-computer dia-logues, hnportant issues include repair sequencing, se~lecting and responding to different repair iniators, andreasoning about the possible source of the problem andhelpful 'remediation' strategies.
The example system isfairly simple, though in an evaluation of an early ver-sion with menu-based user input, the interactive/repairbased approach to explanation generation proved use-ful.
Future work on any practical natural anguage di-Mogue system should consider these issues.References\[1\] A. Cawsey.
Generating explanatory discom'se.
I11R.
Dale, C. Mellish, and M. Zock, editors, Cur-rent Research in Natural Language Generation, Aca-demic Press, 1990.\[2\] tI.
Clark and E. Schaefer.
Contributing to discourse.Cognitive Science, 13:259-294, 1989.\[3\] J. D. Moore.
A Reactive Approach to Ezplanationin Expert and Advice-Giving Systems.
PhD thesis,Information Sciences Institute, University of South-ern California, 1989.
(published as ISI-SR-90-251).\[4\] P. Raudaskoski.
Repair work in human-computerinteraction.
In P. Luff, D. Frohlich, and N. Gilbert,editors, Computers and Conversation, AcademicPress, 1990.\[51 M. Ringle and B. Bruce.
Conversation failure.
InW.
Lehnert and M. Ringle, editors, Strategies forNatural Language Processing, Lawrence Earlbaum,Hillsdale, New Jersey, 1981.\[6\] E. Schegloff.
Some som'ces of misunderstanding intalk-in-interaction.
Lecture to the Cognitive Sci-ences program, University of California, Berkeley.
(71 E. Schegloff, G. Jefferson, and H. Sacks.
The prefer-ence for self-correction i the organisation of repairin conversation.
Language, 53:361-382, 1977.\[8\] B. Woolf and T. Murray.
A framework for repre-senting tutorial discourse.
In Proceedings of the lOthInternational Conference on Artificial fntelligence~pages 189-192, 1987.329
