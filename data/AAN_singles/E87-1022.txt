Subgrammars, Rule Classes and Control in theRosetta Translation System *Lisette Appelo Carel Fellinger Jan LandsbergenPhilips Research LaboratoriesP.O.
Box 80 000, 5600 JA Eindhoven, The NetherlandsAbst ractThe paper discusses a recent extension of the linguisticframework of the Rosetta system.
The original frame-work is elegant and has proved its value in practice,but it also has a number of deficiencies, of which themost salient is the impossibility to assign an explicitstructure to the grammars.
This may cause problems,especially in a situation where large grammars haveto be written by a group of people.
The newly devel-oped framework enables us to divide a grammar intosubgrammars in a linguistically motivated way and tocontrol explicitly the application of rules in a subgram-mar.
On the other hand it enables us to divide theset of grammar ules into rule classes in such a waythat we get hold of the more difficult translation rela-tions.
The use of both these divisions naturally leadsto a highly modular structure of the system, whichhelps in controlling its complexity.
We will show thatthese divisions also give insight into a class of difficulttranslation problems in which there is a mismatch ofcategories.1 The  Roset ta  F rameworkIn this section we will give an outline of the approachto machine translation pursued in the Rosetta project,which takes place at Philips Research Laboratories.The linguistic framework of Rosetta can be character-ized by a number of principles.
These are 'workingprinciples', intended to be helpful for systematic re-search on translation and for the actual constructionof translation systems.The principles are discussed here to the extent inwhich they are relevant o this paper.~rhis paper is the merger of two complementary paperson the Rosetta translation system that were submitted tothe European ACL Conference 1987, i.e.
'Subgrammars andRule Classes in the Rosetta Translation System' by Appeloand Fellinger and 'Controlled M-Grammars in the RosettaSystem' by Landsbergen.This research was partially sponsered by Nehem (Neder-landse Herst ruct ureringsmaatschappij).P r inc ip le  of  Expl ic i t  Grammars :  There isan explicit grammar for both the source and thetarget language.In most translation systems the target language isdefined indirectly by means of contrastive transferrules that specify the differences with the sourcelanguage.
We think it important o have an in-dependent criterion for correctness of the targettext.Compos i t iona l i t?
Principle."
The meaning ofan expression is a function of the meaning of itsparts and the way in which they are syntacticallycombined.This principle was adopted from Montague Gram-mar (cf.
Thomason, 1974).
Obviously, this prin-ciple will lead to an organlsation of the syntaxthat is strongly i~nfiuenced by semantic onsidera-tions.
But as it is an important criterion of a cor-rect translation that it is meaning-preserving, thisseems to be a useful guideline in machine transla-tion.The compositional grammars of Rosetta, calledM-grammars, consist of three components: a syn-tactic, a semantic and a morphological compo-nent.The syntact ic  component  defines surface treesof sentences.
The surface trees used in Rosetta,called S-trees, are ordered trees of which thenodes are labelled with syntactic categories andattribute-value pairs that bear other morpho-syntactic information.
The branches are labelledwith syntactic relations.
S-trees are used as inter-mediate representations a  well.The syntactic omponent defines the set of correctS-trees by specifying:1. a set of basic expressions.2.
a set of compositional syntact ic  rules.These rules make it possible to derive new S-treesand ultimately surface trees of sentences from thebasic expressions.
The rules have 'transforms.tional power', they may perform various opera-tions on S-trees.
The process of deriving a surface118tree starting from basic expressions by applyingsyntactic rules recursively, in a 'bottom-up' way,can be represented in a syntactic derivationtree with the basic expressions at the terminalsand the names of the applied rules at the non-terminals.
With each node of the derivation treean intermediate resulting S-tree can be associated,i.e.
the S-tree that is the result of the applicationof the rule of that node on the resulting S-trees ofits daughters (see figure I).the donkey is eating apples-the donkeythe donkey eat applesdonkey R,eat zl z2R4 RaR2zt eat applesapplesappleFigure I: syntactic derivation tree, the derived S-trees areparaphrased by stringsThe leaves of a complete surface tree correspondto the words of the sentence, but they have theform of categories and attribute-value pairs.
Themorphological component relates these leavesto actual symbol strings.
In this paper we willignore this morphological component and the S-trees will be 'paraphrased' by strings most of thetime to enhance the readability of these trees.The M-grammars  have a semantic  componentthat specifies1.
the meaning of the basic expressions (basicmeanings).2. the meaning of the rules (rule meanings) .In Montague Grammar these meanings are ex-pressed in intensional logic.
In the Rosetta systemthe meanings of rules and basic expressions arenot elaborated on in a logical language, but theyare represented by means of unique names.
Theconsequence is that a meaning of a sentence canbe represented as a so-called semant ic  deriva-tion tree: a tree with the same geometry as thesyntactic derivation tree but labelled with namesof rule meanings and basic meanings instead ofsyntactic rules and basic expressions.
In figure 2an example of a semantic derivation tree is given,corresponding to the syntactic derivation tree offigure 1.As basic expressions may have various meanings,there is in general a set of semantic derivationtrees corresponding to a syntactic derivation tree.There is in general a set of syntactic derivationtrees corresponding to each semantic derivationtree, because a basic meaning may correspond tovarious basic expressions and a meaning rule maycorrespond to various syntactic rules.M6IMsM+ MaB~ Mt M2/% iB2 X~ X2 BtFigure 2: semantic derivation tree corresponding to thesyntacticderivatlon tree of figure 1One Grammar Principle: The analysis andgeneration components for one language are basedon the same grammar.In other terms, we require the compositionalgrammar defined above to be 'reversible'.
Theanalysis component maps sentences onto deriva-tion trees, the generation component maps deriva-tion trees onto sentences.Because of this principle M-grammars have toobey certain conditions.
The most important con-dition is that for each generative syntactic rulethere must be a reverse analytical rule.
For amore extensive discussion of these conditions werefer to Landsbergen (1984).
Thanks to these con-ditions analysis algorithms can be defined whichyield for any input sentence the set of syntacticderivation trees of that sentence (see section 6 forthe formal definitions).In addition to theoretical motives, there are eco-nomic motives for adopting the One GrammarPrinciple.
If we plan to make translation systemsthat translate both from and into a particular lan-guage, it is efficient if these systems can be basedon one grammar.Because of this principle it suffices most of thetime to discuss the grammars from a composi-tional, generative point of view only.119?
I somorphy  Pr inc ip le :  Two sentences are trans-lations of each other if their meanings are derivedfrom the same basic meRnings in the same way, i.e.if they have the same semantic derivation tree.So this principle says that the information thathas to be conveyed uring translation is not onlythe meaning, but also the way in which the mean-ing is derived.This implies that we have to attune the grammarsof the system in the following way:1. each basic expression in one grammar corre-sponds to at least one basic expression i  theother grammar with the same meaning (i.e.corresponding to the same basic meaning).2. each syntactic rule of one grammar corre-sponds to at least one rule in the othergrammar with the same meaning (i.e.
cor-responding to the same rule meaning).So, two sentences are translations of each otherif they have corresponding, i somorph ic  syntac-tic derivation trees, i.e.
trees with the same ge-ometry and corresponding basic expressions andcorresponding rules at the leaves and at the nodesrespectively (see figure 3).Following this principle there are correspondingsets of rules, related to the same meaning rule,and corresponding sets of basic expressions, re-lated to the same basic meaning.
We call thegrammars isomorphic if these corresponding setsof rules obey certain applicability conditions.The Isomorphy Principle is the most characteris-tic principle of the Rosetta system, as it expressesour compositional theory of translation.In this approach complex structural transfer rulesare avoided, as rules and basic expressions of thesource language are related locally to rules andbasic expressions of the target language, although,of course, the individual grammars may be com-plicated because of the attuning.?
Principle of Interllnguality: There is anintermediate language into which analysis com-ponents of various languages translate and fromwhich the generation components of these lan-guages are able to translate.
If we combine thisprinciple with the Isomorphy Principle, the mainconsequence is that the semantic derivation treesconstitute the intermediate language and that theattuning of the grammars is done for possiblymore than two grammars.It should be stressed that the isomorphy and notthe interlinguality is the primary characteristic ofthe Rosetta framework.For a more extensive discussion of these principlesand more interesting examples we refer to Appelo andLandsbergen (1986).
Leermakers and Rous (1986) givean introduction to the Rosetta method along differentlines.The global design of the Rosetta system, which fol-lows from these principles is sketched in figure 4.
Foreach M-grammar the following system components aredefined:?
an analytical and a generative morphological com-ponent, A -MORPH and G-MORPH.
They ac-count for the relation between strings and lexicalS-trees (i.e.
S-trees corresponding to words).?
an analytical and a generative syntactic com-ponent, M-PARSER and M-GENERATOR.They account for the relation between surfacetrees and syntactic derivation trees.
These sys-tem components follow directly from the syntac-tic component of an M-grammar.
Their formaldefinition is given in subsection 6.1.?
an analytical and a generative semantic ompo-nent, A -TRANSFER and G-TRANSFER.They account for the relation between syntacticand semantic derivation trees.M-PARSER is preceded by a component called S-PARSER (for surface parser) which maps a sequenceof lexical S-trees (which is the output of A-MORPH)onto a set of surface trees of which the lexical S-treesare the leaves.
This set should contain the correct sur-face trees, but may contain also incorrect ones.
Thegenerative counterpart, LEAVES,  is trivial; it mapsthe surface tree onto the sequence of its leaves.2 Prob lems w i th  the  Roset taf rameworkThe framework outlined above has been worked out ina way that is simple and mathematically elegant, as theformal definitions in subsection 6.1 will illustrate.
Thisformalism has also proved its value in practice: theimplemented systems Rosettal and Rosetta2 have beenwritten in this framework.
In the sequel we will referto it as the Rosetta2 framework.
However, it also hasa number of deficiencies, which may cause problems,especially in a situation where large grammars haveto be written by a group of people.
Three kinds ofproblems can be distinguished.1.
Lack of  s t ruc ture  in M-grammaarsGrammars for natural languages are very largeand inherently complex.
In an M-grammar thesyntactic omponent specifies a set of rules with-out any internal structure.
Although the mathe-matical elegance of free production systems is ap-pealing, they are less suited for large grammars.As the number of rules grows, it becomes moreand more desirable that the syntax be subdividedinto parts with well-defined tasks and well-definedinterfaces with other parts.120ENGLISH <==> DUTCHthe donkeydonkeyR6 / "~- - - - - - ____~_I the donkey is eating applesRsthe donkey eat applesR4 R3 ~ ~ R~Ri R2 ~ ezelappleseat z, z2 appleR'~I de ezel eet appelsR I/~  de ezel appel8 eten~ zt appels etenR'~ R~/ /~ I  appaseet zt z~ appelFigure 3: isomorphic syntactic derivation trees for the sentence The donkey iseating apples and its translation i Dutch De ezelset appel8Source language Target languagesentence sentencesA-MORPHJ, ?sequences of sequences oflexical S-trees lexical S-trees $ 'tS-PARSER | L AVES ,,,\]surface trees4,M-PARSERsurface treessyntactic syntacticderivation derivationtrees J, treesA-TRANSFER I G-TRANSFER) semantic derivation trees J, IFigure 4: Global design of the Rosetta system2.This holds in particular if the grammars are devel-oped by a group of people.
It is necessary to havean explicit division of tasks and to coordinate thework of the individuals in a flexible way so thatthe system will be easy to modify, maintain andextend.In computer science it is common practice to di-vide a large task into subtasks with well-definedinterfaces.
This is known as the modu lar  ap-proach.
This approach as gained recognition ithe field of natural anguage processing too (cf.Isabelle and Macklovitch, 1986 and Vauquols andBoitet, 1985).
The question is how such a mod-ular approach can be applied in a compositionalgrammar, in an insightful and linguistically moti-vated way.Lack of control  on rule applicationsIn many cases the grammar writer has a certainordering of the rules in mind, e.g.
he may wantto express that the rules for inserting determinersduring NP-formation should be applied after therules for inserting adjectives.
In the M-grammarformalism explicit ordering is impossible, but therules can be ordered implicitly by characterizingthe S-trees in a specific way, e.g.
by splitting upa syntactic ategory into several categories, andby giving the rules applicability conditions whichguarantee that the aspired ordering is achieved.For example, if one wishes to order two rules thatboth operate on an NP, this can be achieved bycreating categories NP1, NP2 and NP3 and tolet the first rule transform an NP1 into an NP2and the second rule an NP2 into an NP3.
Thisapproach w~ followed in Rosetta2.
One of its121disadvantages is that it leads to a proliferation ofrather unnatural categories.It is hard to find an elegant and transparent wayof specifying rule order in a compositional gram-mar; the situation is more complicated than intransformational systems llke ROBRA (Vauquoisand Boitet, 1985), because rules may have morethan one argument.In addition to linear ordering one may want toadd other means of controlling the application ofrules, e.g.
one may want to make a distinctionbetween obligatory, optional and recursive rules.In M-grammars all rules are optional and poten-tially recursive.
It is not clear how to add obliga-tory rules to such a free production system; in factit is hard to understand what that would mean.There is also a problem with the reversibility ofobligatory rules: a rule that is obligatory dur-ing generation is not necessarily obligatory duringanalysis.3.
Lack of  s t ruc ture  In the t rans lat ion  re lat ionAs we have explained in section 1, the translationrelation between languages i  defined by attuningthe grammars to each other.
In this way complexstructural transfer (as discussed in Nagao andTsujii, 1986) can be avoided, but in some casesthe dependency between the grammars may com-plicate individual grammars.
Category  mis-match  is one of these translation problems, e.g.the graag//iilce case, where a Dutch adverb corre-sponds to an English verb.
In cases like this thereis a mismatch of syntactic ategories coupled withdifferent behaviour with respect o, e.g., tense: averb has tense, whereas an adverb has not.In Landsbergen (1984) a solution of the graag//likeproblem by means of isomorphic grammars w~discussed, for small example grammars.
Forlarger grammars a more systematic and struc-tured treatment of these translation problems isneeded, but this is not supported by the Rosetta2formalism.Another problem is caused by the fact that inthe isomorphic grammar framework each syntac-tic rule of one grammar must correspond to atleast one rule of another grammar.
For rules thatcontribute to the meaning this is exactly what wewant, because what h~ to be conveyed duringtranslation is not only the meaning, but also theway in which the meaning is derived.
However,there is a problem with rules that are only rele-vant to the form of the sentence and that carry notranslation-relevant information, especially if theyare language-specific.
A purely syntactic transfor-mation as Verb-Second in an SOV language likeDutch does not correspond in a natural way toa syntax rule of English.
In Rosetta2 this prob-lem could be solved in one of the following twoways: by adding a corresponding rule to the En-glish syntax that did nothing more than changethe syntactic category or by merging the Dutchtransformation rule with a meaningful rule.
Thesesolutions are not very elegant and complicate thegrammars unnecessarily.
It would be better ifthe correspondence between rules as required bythe Isomorphy Principle must hold for meaning-ful rules only.
The translation relation would thenbe defined in terms of a reduced derivation tree,which is labelled with meaningful rules.
The gen-eration component (M-GENERATOR)  will oper-ate on such a reduced tree and will have to decidewhat syntactic transformations are applicable atwhat point of the derivation.
This requires someway of controlling the applicability of the trans-formation rules.In the next sections we will describe the modular ap-proach chosen for the development of Rosetta3, whichmay help to solve the above-mentioned problems.
Wewill discuss a syntax oriented dlvlslon into subgram-mars in section 3 and a translation oriented divisioninto rule classes in section 4.
In section S we will arguethat a combination of the two divisions is needed.
Insection 6 the newly introduced notions will get a formaltreatment.
It will turn out that the way in which sub-grammars are defined enables us to define the controlof rule applications in a transparent way.The proposed modifications are completely in accor-dance with the basic principles mentioned in section 1.3 Subgrammars, a SyntaxOriented DivisionFrom the computer language Modula2 (cf.
Wlrth,1985) we learned the essentials of the modular ap-proach:I. divide the total into smaller parts (modules)with a well-defined task,2.
define explicitly what is used from other parts(Import) and what may be used by other parts(export) ,3. separate the definition from the implementation.The explicit definition of import and export andthe strict separation of implementation and definitionmakes it possible to prove the correctness of a modulein terms of its imports, without having to look at theimplementation of the imported modules.
This tack-les the above-mentioned complexity problem and thecoordination problem caused by the lack of structurein the M-grammars nicely.
In our view, applying themodular approach to grammars comes down to the fol-lowing requirements:1. dividing the grammar into subgrammars  with awell-defined linguistic task,/222.
defining explicitly what is visible to other sub-grammars (export) and what is used from othersubgrammars (Import),3. ensuring that the actual implementation (i.e.
therules) is of local significance only.Dividing grammars into subgrammars with a linguistictask has been done before, e.g.
in the GETA-systems(cf.
Vauquois and Boitet, 1985).
However, to ourknowledge, they do not meet requirement 2 and 3The actual subdivision chosen for the development ofRosetta3 was inspired by the notion projection fromthe X.-theory of Transformational Generative Gram-mar (cf.
e.g.
Chomsky, 1970): every major category Xis said to have a maximal projection X '~z, e.g.
NOUNhas the maximal projection NP.
Such projections pro-vide a syntactic division of the constituents of languageand appear to be a useful choice for modular units ina natural language system.Applying this idea to the compositional grammarsof Rosetta implies that basic expressions have a ma-jor category X and that there are syntactic rules thatwill ultimately compose S-trees of category X "~'=.
Foreach maximal projection a subgrammar can now be de-fined that expresses how X '~  can be derived from Xand other imported categories.
We will call a possiblederivation process of the projection from X to X maz aprojection path (see figure 5.
The most importantmajor categories (and their projections) in use in theRosetta systems are: NOUN (NP), VERB (VP), ADJ(ADJP), ADV (ADVP)  and PREP  (PP).R .. .
.
X "~z  /RSI41R /XFigure 5: A projection path from X to X 'nazX-theory also states that all projections have a sim-ilar syntactic structure (i.e.
phrase marker), which isrepresented in the schema of figure 6, but this aspectis less relevant for the Rosetta grammars.
For us, it isof more interest whether they are the result of similarderivations.
We will come back to this point in section5.A sentence is usually seen as a subject-predicate re-lation, i.e.
a combination of an NP  and a VP.
But other( speci/Z~.. "~( complement ) X ( complement )Figure 6: The projection of X to X 'nazXP  (i.e.
X maz) categories than VP, together with anNP, can express a subject-predlcate relationship as well(cf.
Stowell, 1981).
Such subject-predlcate relationsare called small clauses.
For example, the NP  him andthe ADJP funny in I think \[him funny\], or the two NP'shim and a fool in I consider \[him a foo 4 form a smallclause.
In Rosetta such tenseless clauses are called XP-PROP in which X stands for the X of the predicate.For example, in \[him funny\] we have ADJPPROF (withX = ADJ)  and in \[him a foo4 we have NPPROP (withX = NOUN) .
A tensed XPPROP is called a CLAUSEin Rosetta.
For example, in the sentences I think thathe is sleeping and I think that he is funny we have theCLAUSEs \[that he is sleeping\] and \[that he is funny\]respectively.This means that, starting from a basic expression ofcategory X, in principle three S-trees with a differenttop category X '?P can be derived: XP, XPPROP andCLAUSE.
Figure 7 shows some of the resulting deriva-tion trees and S-trees of the examples given above.Defining subgrammars in accordance with these'projection paths' provides a natural way of expressingthe application order of the rules within a subgrammar:the order is defined with respect to the projection pathonly.
A side effect of this explicit ordering of rule ap-plication is that it enables us to use a more efficientparse algorithm (M-PARSER).A subgrammar can now be characterized as follows:1. export S-tree of category X t"p (XP, XPPROP orCLAUSE)2. import:?
S-tree with a special category, the X-category, also called the head category.?
S-trees with categories that are exported byother subgrammars and that can be takenas an argument by rules with more than oneargument.3.
rules: a set of rules that take care of the pro-jection from X to X '?p.
Every rule has one argu-ment, which is called the head argument,  i.e.the S-tree with the head category or one of theintermediate results during its projection.123R2NPAheCLAUSEhe is sleepingRl CLAUSExl VP /,,,sleepxL VERBAsleepR4NPAhimADJPPROPhim funnyR3- -ADJPPROPx2 ADJP / ' , .funnyx2 ADJfunnyNPPROPhim a foolR6,ANP Rshimx3 NOUN~o lNPPROPx~ NP  /Na foolFigure 7: The derivation trees with the resulting S-trees ofthe projection of VERB to CLAUSE, ADJ to ADJPPROPand NOUN to NPPROP4.
control  expression:  a definition of the possibleapplication sequences of the rules, ordered withrespect o their head arguments.Neither the rules nor the intermediate results areknown to other subgrammars.
They can be consideredlocal to the subgrammar.
So 1 and 2 define the relationwith other subgrammars, whereas 3 and 4 are only oflocal significance, thus meeting our requirements forthe modular approach.An example of a subgrammar is the NP-subgrammarwith a NOUN as head and exporting an NP.
Othercategories that are imported by this subgrammar areDETP, ADJPPROP, etc.
the set of rules containsmodification rules and determiner rules, the controlexpression indicates that the modification rules can beapplied recursively and that they precede the deter-miner rules.Obviously, there will now be subgrammars that con-tain the same rules, e.g.
the subgrammars for NOUNto NP  and PRONOUN to NP.
For efficiency reasons,it is allowed to merge such subgrammars by defininga set of heads as import and a set of top categories asexport.For an elaboration of the notion control expressionand a formalisation of subgrammars we refer to section6.The advantages of this division into subgrammarsare 1) that the structure of the grammar has becomemore transparent, 2) that we now have units with well-defined interfaces which enables us to divide the workover several people, 3) that we can work at and testsmaller parts of a grammar.4 Ru le  C lasses ,  a T rans la t ionOr iented  D iv i s ionIn the Rosetta framework as sketched in section 1, thetranslation relation is defined at the level of rules andbasic expressions.
If there is a rule or basic expressionin one grammar, there must be at least one rule orbasic expression in the other grammar with the samemeaning (the Isomorphy Principle).
It is hard to gethold of the translation relation as a whole in terms ofthese primitives alone.
What we need is some structureof a higher order.1.
We distinguish purely syntactic rules calledt rans format ions  and mean ingfu l  rules.Some rules in the Rosetta grammars do not carry'meaning', but serve only a syntactic, transforma-tional purpose.
In the Rosetta2 framework thesemeaningless rules, which are often of a highlylanguage-specific character, sometimes requiredrules in other languages that were of no use there.124This point was already mentioned in section 2.Such rules are now no longer considered to bepart of the translation relation that is expressedby the isomorphy relation between the grammars.Therefore, they can be added freely to a gram-mar.
In this way a better distinction can be madebetween purely syntactic (and hence language-specific) knowledge and t rans lat ion  re levantknowledge.
The translation relation now can befreed from improper elements, which is highly de-sirable.In section 2 it was noticed that the introduction oftransformation rules requires ome way of control-ling their applicability.
The control expressionsintroduced in section 3 and formalised in section6 provide for this.2.
The set of rules of the grammars are divided intogroups called rule classes, each of which handlessome linguistic phenomenon.
These rule classesare subdivided into transformation classes andmeaningful rule classes.
A meaningful rule classhandles a linguistic phenomenon of which the se-mantics should be preserved uring translation.Such translation relevant linguistic phenomenaare, e.g., valency/semantic relations, scope, time,negation and voice.
The translation relation canbe further structured by these meaningful ruleclasses.
Only rules of different languages that be-long to the same meaningful rule class may corre-spond to each other or, to put it in other words,rules that do not belong to the same meaningfulrule class can never be translations of each other(see figure 8).
Within a meaningful rule cl~sthere can, of course, be some 'semantic differentia-tion', which should be retained under translation.For example, in the time rule class more than onetime reference can be distinguished, each with adistinct meaning, tThere can also be 'corresponding' transformationclasses in the grammars for different languages -e.g.
agreement rules -, but they do not play a rolein the translation relation.5 Combining Subgrammarsand Rule ClassesHaving introduced some order into the syntactic rulesof the grammar and into the translation relation, wesee that these divisions of rules are along 'vertical' and'horizontal' ines respectively (see figure 9).
The pro-jections of basic categories in one grammar, leadingto the division of the grammar into subgrammars, are1For each distinct ime reference meaning aseparate rulecan be defined, but it is also possible to introduce abstractbasic expressions ranging over the possible time referencesand have one rule that has such an abstract basic expressionas argument.mean ingfu l  rule classestime rule class \[~inegation rule classGrammars :  Gt G2Figure 8: meaningful rule classes bring order in the trans-lation relation between the grammars of the languages in-volvedalong vertical lines.
The relations between the gram-mars, leading to the division of all the rules of thegrammars into (meaningful) rule classes, are along hor-izontal lines.These two ways of dividing grammars have severalconsequences.On  the one hand, subgrammars help to structurethe grammar in a more modular way; they also givesome insight into the translation relation, but only inthe more 'trivial' cases, where the corresponding basicexpressions have the same syntactic ategory, subgram-mar G,l of grammar G corresponds solely to subgram-mar Gt of grammar G .
In category mismatch casesthe corresponding basic expressions fall into differentsubgrammars (e.g.
the graag/like case of section 2).On the other hand meaningful rule classes group to-gether semantically related rules, which gives insightin what has to be preserved uring translation, butthey are not the.right unit to make a modular struc-ture.
This makes it hard to define an adequate inter-face (import/export) between rule classes, because .g.the rule that negates a sentence is determined more bythe rules that form a sentence than by the other nega-tion rules (e.g.
in an adjective phrase) with which itforms the negation rule class.However, both subgrammars and rule classes allowfor a division of the labour over people.
That this is thecase with subgrammars is trivial, as subgrammars forma modular structure.
The reason that rule classes arealso useful units to divide the work is that knowledgeof a specific linguistic topic is needed for every ruleclass, knowledge that can typically be handled by oneperson.In order to have the benefits of both we combinedsubgrammars and rule classes in the following way:I. the rules of subgrammars are divided into rulesubclasses, which are subsets of rule classes2.
the application sequences of rules are defined interms of rule subclasses instead of rules.125meaningfu l  ru le classestime rule class \[rule class i" negation !INP~#/~/~CLAUSE?
mVP i NP  VP  CLAUSESubgrantmars  of  g rammar  G 1 Subgrammars of  grammar G:Figure O: horizontal and vertical division within grammars.
The shaded part denotes the subclass of the negation rules for theCLAUSE subgrammar of G t.The combination results in a modular structure of eachgrammar and helps to reduce the complexity of thetranslation relation.
It also helps to solve the class ofcategory mismatch problems elegantly.Isomorphic subgrammarsAs was already mentioned in section 3, X-theorystates that the projections of all major categories havea similar structure.
The division of the grammars intosubgrammars was based on the notion major categoryand the sorts of projections that we recognize (XP,XPPROP and CLAUSE) .
The fact that in X-theorythe phrase markers of the resulting constituents aresimilar, suggests that it is possible to assign similarderivations to them in a compositional grammar.
Thissimilarity is also suggested by the fact that most ruleclasses handle phenomena that play a role in everysubgrammar.
For example, in all subgrammars rulesfor valency/semantic relations and negation are found.They may differ, of course, in their transformations.The fact that we consider the Dutch NPs de ezel dieappels set and de appels etende ezel to be paraphraseswhich are both translations of the English NP the don-key that is eating apples 2 suggests that a tensed relativeclause should be composed similar to a tenseless 'ad-jectival' relative clause, or in other terms: that theirderivation trees should be i somorph ic  with respectto their meaningful rules.
The same can be said forthe adjectival phrase smart and the relative clause thatis smart in the \[smart\] girl and the girl \[that is smart/respectively.To make it possible that such phr~es and clauses aretranslations of each other, the subgrammars involvedare attuned as far as possible, resulting in 'isomorphic'subgrammars within one grammar.We will discuss two cases:2the eatin?
apples donkey is ungrammatical.1.
Same head category, but different op category2.
Different head categorySame head category, but different top cate-goryIn the example of the smart girl / the girl that is8mart the subgrammars for the projection of ADJ toADJPPROP and ADJ to CLAUSE are involved.
Theydiffer in that a transformation exists for the insertionof the auxiliary verb be in the clause case.
For isomor-phy reasons, in both cases a rule for time reference isneeded: in the clause case it spells out the tense forthe verb be; in the adjectival case it seems to be super-fluous, but with model-theoretical semantics in mindit can be argued to be needed, if we assume a modelwith a time component (see figure 10).ADJPPROP CLAUSERtimepre~ent Rtimepresent!R~tart R~tartxl*~smext xt//~smartFigure 10: Derivation trees resulting from the subgram-mars ADJ to ADJPROP and ADJ to CLAUSEThis kind of paraphrasing can be helpful if the literaltranslation is not allowed in the other language as is thec~e with de appels etende ezei, which cannot be trans-lated into *the eating apples donkell or I expect him toleave which cannot be translated into *ik ~erwacht hemte vertrekken, but has to be translated into ik verwaehtdat hij vertrekt (I-expect-that-he-leaves).126CLAUSEN P .~b.
, ,~ ,VERBPPROP VERBPPROPCLAUSE~ub.t,z lRNPi\[ R...~.~.,lllt,hij I| R ,\[ \[ R.,o..X2 toeqallig \[ k xl komenADVPPROP VERBPPROPHe happened to come Hi\] klnam toevalligFigure lh  Syntactic derivation trees with the relevant subgrammarsD i f fe rent  head  categoryIf the approach of attuning subgrammars as far aspossible is extended to subgrammars with differenthead categories, then it can help to solve the problemswith the above-mentioned class of category mismatchcases .For example, in he happened to come the raising verbhappen occurs and in hi\] kwam toevallig the sententialadverb toevallig.
As these two sentences are consideredtranslations of each other, the subgrammars for VERBand ADV should be attuned to each other.
This seemsto be impossible because it is quite natural that thecomplement of happen, i.e \[he come\] is inserted into theclause of happen, whereas toevallig (the basic expressionthat corresponds to happen) is inserted into the clausecorresponding to the complement clause of happen, i.e\[hi\] komen\].Semantically, in both cases, the clause is the ar-gument of happen and toevallig, but from a syntacticviewpoint adverbs are inserted into their arguments.We can solve this problem by allowing in these casesa 'switch of subgrammar'.
This is possible if the sub-grammars are split into two parts in such a way thatthe place of this subdivision coincides with the 'switchpoint'.
There is another argument for making this sub-division: the first part of the control expression of thesubgrammars for X to XPPROP and X to CLAUSE isthe same.
The succeeding part is in the CLAUSE casevery similar for all X.Figure 11 sketches how the examples He happenedto come and Hi\] kwam toevallig now can be derivedisomorphically.We noticed that this kind of mismatch of syntac-tic category appears most frequently with modal verbsand adverbs, auxiliaries and semi-auxiliaries, at least inthe languages Rosetta deals with (Dutch, English andSpanish).
In translation systems dealing with Japaneseand English these phenomena occur more frequently.(cf.
Nagao and Tsujii, 1986).Partial i somorphy  o f  subgrammarsIsomorphy between grammars of different languagesmust be defined in terms of isomorphy between thesubgrammars of these languages.
It should be notedthat it is not always possible to make a subgrammar ofone language completely isomorphic to one subgram-mar of the other language.
However, it is possible tomake subgrammars partially isomorphic and sets ofsubgrammars completely isomorphic, both within onelanguage and between different languages.
For exam-ple, within one language the subgrammars for ADJ  toCLAUSE and ADJ  to ADJPPROP need not be com-pletely isomorphic, neither do the ones for ADV toCLAUSE and VERB to CLAUSE.
But together thesubgrammars for ADJ  to CLAUSE and ADJ  to AD-JPPROP for Dutch can be completely isomorphic tothe corresponding subgrammars for English.6 Formal  aspectsIn this section we will discuss the main consequencesfor the Rosetta formalism of the ideas put forwardin sections 3, 4 and 5.
These consequences relatein particular to the definition of M-PARSER and M-GENERATOR.
We will first give - in section 6.1 - theoriginal definitions for the free, i.e.
'uncontrolled' M-grammars of Rosetta2.
In 6.2 we will give the reviseddefinitions for controlled M-grammars, currently usedfor the development of Rosetta3.6.1  F ree  M-grammarsThe syntactic component of an M-grammar defines aset of objects called S-trees (surface trees).127An S - t ree  is- a node N,- or an expression of the formN\[rl/tl,..., r .
/ t .
\ ]  (n>0)where N is a node, the ri's are syntactic relations andthe t;'s are S-trees.
(we will often use this kind of recursive definition:the second - recursive - part of the definition indi-cates that S-trees may have arbitrary, but finite, depth;the first part shows how the recursion terminates: theleaves of the trees are always (terminal) nodes)A node N is defined as a syntactic ategory followedby a tuple of attribute-value pairs (ai:vi).N = O{al :v,  .
.
.
.
.
ak:vk} (k>O)For each syntactic category the corresponding .-it-tributes are defined, for each attribute the set of pos-sible values is defined.
So, given a set of syntacticrelations and a set of syntactic categories with the cor-responding attributes and values, the set of possibleS-trees is defined.
This set is called T: the domain ofS-trees.So the general form of an S-tree t ist = C{at :v , , .
.
.
,  ak:vk} \ [ r t / t t , .
.
.
,  r , / t .
\ ]C is called the syntactic ategory of t.1.2.3.ad 1.ad 2.The syntactic component of an M-grammar  defines- the domain T by enumerating the syntactic re-lations, the categories and the corresponding at-tributes and values.- the set TM of well-formed S-trees, a subset of T.TM consists of the surface trees of sentences thatare well-formed according to the grammar.TM is defined by specifying:a set B of basic S-trees,a set of syntactic rules, called M-rules,a special category: SENTENCE.The set of basic S-trees is a subset of T (the basiclexicon).
A basic S-tree b has a unique name, tobe denoted as b_.An  M-rule R; defines a compositional function F:from tuples of S-trees to finite sets of S-trees.
Soapplication of R; to a tuple tt,...,t, yields a setF~(tt,...,t,).
The set is empty if the rule is notapplicable.Each M-rule is reversible, i.e.
it also defines ananalytical function Fi, the reverse of Fi.t ?
F , ( t t  .
.
.
.
.
t . )
?==~ (tt .
.
.
.
.
t , )  ?
F'i(t )S-trees are constructed by applying M-rules recur-sively, starting from basic expressions, The set TM isthe set of S-trees that can be derived in this way andthat have the category SENTENCE.The derivation process can be displayed in a syntac-tic derivation tree.A der ivat ion  t ree is- the name b of a basic expression,- or an expression of the formR~ <d t .
.
.
.
.
d ,  >, (n>0),where R; is a rule name and dr , .
.
.
,d ,  are derivationtrees.On the basis of the syntactic component of anM-grammar the functions M-GENERATOR and M-PARSER can be defined.
M-GENERATOR is applledto a derivation tree and yields a set of S-trees; M-PARSER is applied to an S-tree and yields a set ofderivation trees.M-GENERATOR(d)  = ~,.f{ t I 3b ?
B :d=b andt=b }U { t \] 3 t l , .
.
.
, t .
,  dl .
.
.
.
.
d .
,R i :d = R ,<d l , .
.
.
,d .> andt~ ?
M-GENERATOR(d l )  andt .
?
M-GENERATOR(d . )
andt ?
F,'(tl .
.
.
.
.
t , )  }(In this definition d, d~, d .
are derivation trees, t,tt ,  t .
are S-trees, B is the set of basic S-trees, b is abasic S-tree, b is the name of a basic expression, F: isthe compositional function defined by rule R~)M-PARSER( t ) =d..f{ d \[ 3 b ?
B : t=band d=b}U { d \[ 9 t l ,  .
.
.
.
t .
,  dl .
.
.
.
,dn, R; :s(ti .
.
.
.
, t . )
?
F i ( t ) ,dt ?
M-PARSER(t l )  and?
.
.d,  ?
M-PARSER(t,~) andd = R ;<dt  .
.
.
.
,d .> }(F'; is the analytical function defined by rule R;)Given the reversibility of the M-rules, it is easy toprove thatt E M-GENERATOR(d)  ~ d E M-PARSER(t)128Note that M-PARSER and M-GENERATOR canboth be used to define the set TM of well-formed S-trees.
T~ can be defined as the set of S-trees (of cat-egory SENTENCE)  that can be derived by applyingM-GENERATOR to all possible derivation trees.
Ta4can also be defined as the set of S-trees (of categorySENTENCE)  for which M-PARSER yields at least onederivation tree.
Because these definitions are equiva-lent, the One Grammar  Principle is obeyed.An  M-grammar  has to obey the measure  cond i -t ion :First, a measure on S-trees, i.e.
a function from S-trees to positive integers, must be defined.The condition says: if t is the result of applying acompositional rule to S-trees tl,...,tn then t is biggeraccording to this measure than each of the argumentstt,...,tn.
So application of an analytical rule yieldssmaller S-trees, which guarantees that the recursion inM-PARSER is finite.The algorithms for the components M-PARSER andM-GENERATOR follow directly from the set-theoreticdefinitions.6.2  Cont ro l led  M-grammarsThe syntactic component of a cont ro l led  M-g rammar  defines the domain T of S-trees in the sameway as for free M-grammars.The set TM of well-formed S-trees is defined by spec-ifying:1. a set B of basic S-trees,2.
a set of subgrammars,3.
a special category: SENTENCE.A subgrammar  Gi consists of:?
a set EXPORTCATS i  of syntactic ategories (thecategories of S-trees that can be exported).?
a set HEADCATS:  of syntactic categories (thecategories of S-trees that are allowed as the head),?
a set IMPORTCATS:  of syntactic categories (theCategories of other S-trees that may be imported),?
a set of M-rules, subdivided into a set MF-RULES:  of meaningful rules and a set TR-RULES: of transformation rules.
For each mean-ingful M-rule one of the arguments has to bedefined as the 'head' argument (transformationshave only one argument).
For notational conve-nience we will assume here that the head is alwaysthe first argument.?
a control expression ce:, which indicates what se-quences of rule applications are possible, from im-ported head to exported result.
(The ordering ofthe rules concerns the head arguments)The control expression indicates what the rulesubclasses are, how they are ordered, what rules theyconsist of, and whether they are recursive, optional orobligatory.
A control expression ce has the followingform:ce= Ao ?
At ..... An,where each A~ is a rule subclass, either a meaningfulrule class or a transformation class.A rule class A~ may be- obligatory: written as ( Rt \[ ... \] Rt  ), where theR,- are either meaningful rules or transformations.- recursive: written as { RI \[ ... \ [Rk },- optional: written as \[ Rt \[... \[ R~ \].An  example:(R,).
\[R2 IRs l .
(R41Rs }.
(R6\ ]R , )This control expression defines all sequences beginningwith Ri, then R2 or R3 or neither, then an arbitrarilylong sequence (possibly empty) of R4 or R~, then eitherRG or RT.Actually a control expression is a restricted kind ofregular expression over the alphabet of rule names.
(Itis not restricted in i tsconstruct ions but in the pos-sible combinations of these constructions.)
Each reg-ular expression denotes a set of instances: sequencesof rule names.
Each such rule sequence is a possiblep ro jec t ion  path  in the subgrammar (of.
section 3).Note that the rules in a sequence need not be applica-ble, this depends on the applicability conditions of therules themselves.It is required that each instance of the regular ex-pression contains at least one meaningful rule.The definition of a derivation tree has to be adjustedas follows.A der ivat ion  t ree  is:- the name b_ of a basic expression,- or an expression of the form(G.R;)<d~ .... ,d.> (n>0),where Gi is (the name of) a subgrammar, R i is(the name of) a meaningful M-rule, and dl,... ,d,~ arederivation trees.There are two differences with the old definition.The first is that the non-terminal nodes contain thesubgrammar name, next to the rule name.
The sec-ond is that the derivation tree is no longer a completetrace of rule applications, because the transformationsd.re not indicated explicitly.In the revised definition of M-GENERATOR and M-PARSER we will use a kind of incomplete derivationtree, defined as follows.An open  der ivat ion  t ree  is:- the 'empty derivation tree', De .129- or an expression of the form(G; ,R/)<DI , .
.
.
,D,  >,where G# is the name of a subgrammar, R i is thename of a meaningful M-rule, DI is an open derivationtree, D2,.. .
,D, are derivation trees.So an open derivation tree is like an ordinary deriva-tion tree, but with an empty derivation tree as leftmostleaf.Where this is useful we will refer to an ordinaryderivation tree as a closed derivation tree.Be given open derivation trees Dl and D~.We define DL\[D2\] as the open derivation tree thatresults if D2 is substituted for DE in Dr.If D2 is a closed derivation tree, the result of thesubstitution DI\[D2\] is a closed derivation tree.We will now present he revised definitions of M-PARSER and M-GENERATOR, for controlled M-grammars.
The definitions are not only valid for therestricted control expressions, but in fact for any regu-lar expression.
Here the set-theoretical definitions aregiven, the algorithms can be derived from them di-rectly.
The set TM of well-formed S-trees can be de-fined in terms of these functions, in the same way asin subsection 6.1.Rev ised  definition of M-PARSERFirst we will give an informal description of M-PARSER, in an 'operational' way.M-PARSER operates on an S-tree t. If t is a ba-sic expression b, M-PARSER(t) yields the derivationtree b_.
For a non-basic t M-PARSER(t) tries to applysubgrammar parsers, by calling SG-PARSER(Gi,t) forall subgrammars G; with the appropriate xport cat-egories (note that for the analytical functions the ex--port categories indicate what can be 'imported').
SG-PARSER(Gi, t) tries to apply the rules of control ex-pression cei to t (i.e.
the ~nalytical versions of therules, starting at the right of the control expression).A successful application of SG-PARSER yields apair (D, u), where D is an open derivation tree andu is the resulting 'head' S-tree.To u M-PARSER is applied again.
If successful, M-PARSER(u) yields a derivation tree d. Then D{d\] is aderivation tree of t.SG-PARSER is defined by means of a function CE-PARSER.
CE-PARSER has 4 arguments (G;, ce, D,t), where G, is a subgrammar name, ce is a controlexpression, D is the open derivation tree resulting fromprevious applications of CE-PARSER,  t is the S-treethat is yet to be parsed.When CF_,-PARSER is called for the first time, D isthe empty derivation tree and ce is the control expres-sion ce; of G;.CF_,-PARSER(G;, ce, D, t) tries to apply the (an-alytical versions of the) rules of control expression ceto t, in right-to-left order.
Successful application of arule yields a tnple of S-trees t l , .
.
.
, t , .
To tl the 'next'rule of the control expression is applied.
To t2,...,tnthe full M-PARSER is applied.
During the recurslveapplication of CF_,-PARSER D grows while ce shrinks.Application of a meaningful rule Rj leads to substi-tution of a new node (G#,Rj) in D. Application of asyntactic transformation does not change the deriva-tion tree.The result of applying CE-PARSER successfully to(Gi, ce~, D, t) is a triple (D2, u, A).
All rules of oneinstance of ce; have been applied then.
D2 has the formD{DI\], where Dl is the open derivation tree with themeaningful rules of this instance of cel at its projectionpath and u is the remaining S-tree to be parsed yet(the 'head').
A is a boolean, which tells whether a rule(or transformation) has been applied.
This is neededto avoid vacuous recursion of CF_,-PARSER in case ofcontrol expressions of the form { ce }, where ce hasempty instances, e.g.
if ce has itself the form cel?
Theboolean A would not be needed if the definitions wouldbe tuned to the restricted form of control expressionsas a sequence of rule classes.The definitions:M-PARSER(t)  =d..I{d 13 bEB:d=bandt  = b }u { d 13 G,, dr, D2, u:syncat(t) E EXPORTCATS;  and(D2, u) E SG-PARSER(G;,t) andd~ E M-PARSER(u)and d = D2\[d~\] }(In this definition d, dl are closed derivation trees,D2 is an open derivation tree, t, u are S-trees, syncat(t)is the syntactic ategory of t, b is a basic expression, bis the name of a basic expresslon, Gi is a subgrammar)SG-PARSER(G~,t) =d..!
{ (D, u) I(D, u, true) e CE-PARSER(G; ,  ce;, DE, t)}(ce; is the control expression of ce;)CF_,-PARSER(G;, ce, D, t) =~..1{ (D2, u, A) I q ceh ce2, DI, t l:ce = cel.ce2 and "ce2 is not a concatenation s and(DI, tl, A~) E CE-PARSER(GI, ce2, D, t) and(D2, u, A~) E CE,-PARSER(G,, ce,, D, ,t,) andA= Al orA2 }U { (D2, u, A) \[ 3 ce,, ce2:ce = cellce2 and "ce~ is not a disjunction s and(D2, u, A) e (OE-PARSER(G,, ce~, D, t)130U CF_.-PARSER(G,, cet, D, t)) }U { (D~, u, A) I 3 cet:ce = \[ce, l and((D~ = D and u = t and A = false) or(D2, u, true) ?
CF_,-PARSER(GI, ce,, D, t) andA = true) }U { (D~, u, A) I B ce, :ce = {ce,} and((D~ = D and u = t and A = false) or( 3 D,, it, At:(Dr, tt, true) ?
CE-PARSER(Gi ,  ce,, D, t) and(D2, u, A,) ?
CE-PARSER(GI ,  ce, D,, tt) andA = true ) ) }U { (D2, u, true) I 3 k, n, Rk, d2 .... ,d.:ce = Rk andRk ?
MF-RULES i  andD2 = D\[(G;, Rk)<D~, d2 .... ,d.>\] and(u, ta ..... t,) ?
F'k(t ) andd~ 6 M-PARSER(t2)  andd.
?M-PARSER( t . )
}U { (D2, u, true) I 3 k, at:Rk 6 TR-RULES;  andD2 =D and ce =Rk andu ?
F't,(t) }(ce, ce,, ce2 are control (sub)expressions, D, D,, D2are open derivation trees, d2,...,d, are closed deriva-tion trees, De  is the empty derivation tree, t, t,, t2,t., u are S-trees, Rk is an M-rule, F'k is the analyticalfunction defined by rule Rk, A, At, A2 are booleans)An additional advantage of controlled M-grammarsis that the measure condition (cf.
6.1) can be reformu-lated in a way that is much easier to obey that in theoriginal framework.The measure condition is reformulated as follows:1.
For the grammar as a whole a measure must bedefined in such a way that application of a subgrammarin generation yields exported S-trees which are biggerthan the imported S-trees.
Consequently applicationof a subgrammar during analysis yields smaller S-trees.This measure is similar to the measure for rules wehad in the free M-grammar formalism, but it is easierto define a measure for complete subgrammars thanfor rules.
Possible measures are: the total number ofnodes or the depth of an S-tree.2.
For each subexpression of the form { e } in a con-trol expression a measure on S-trees must be defined,such that application of e during analysis yields outputS-trees that are smaller than the argument S-trees ac-cording to this measure.
This measure can be definedseparately for each expression ( e }.Rev ised  de f in i t ion  o f  M-GENERATORAs the definitions relating to M-GENERATOR arecompletely symmetric to the definitions relating to M-PARSER, we will present hem without further com-ments.M-GENERATOR(d)  =d~/{ t lBb6B:d=bandt=b}U { t I 3 G;, d,, D~, u:d = D2\[dt\] andu ?
M-GENERATOR(dr )  andsyncat(u) ?
HEADCATS;  andt ?
SG-GEN(G;, D2, u) }( d, dt are closed derivation trees, D2 is an openderivation tree, t, u are S-trees, b is a basic expression,b is the name of a basic expression, G# is a subgram-mar, syncat(u) is the syntactic ategory of u)SG-GEN(G;, D, u) =a..!
{t I (t, De, true) ?
CE-GEN(G,,  ce,, D, u)}(cei is the control expression of Gi, D~ is the emptyderivation tree)CE-GEN(G;,  ce, D2, u) =d-.!
{ (t, D, A) \] q eel, ce2, D,, ti:ce = ce,.ce2 and "cel is not a concatenation" and(t,, D,, A,) ?
CF_,-GEN(GI, ce,, D2, u) and(t, D, A2) ?
CE-GEN(G;,  ce2, Dr, t l )  andA = Al or A2 }U { (t, D, A) I 3 ce,, ce2:ce = cel\]ce2 and "cet is not a dlsjunction" and( t, D, A) ?
(CE-GEN(G;,  ce,, D2, u)U CF_,-GEN(G,, ce,, D, ,  u)) }U { (t, D, A) I 3 ce,:ce = \[cell and((D~ = D and t = u andA=fa lse)  or((t, D, true) e CE-GEN(G;,  ce,, Ds, u) andA = true)) }U{( t ,D ,A)  Jqcet :ce = {cel} and((D2 = D and t = u and A = false) or( 3 D*, tl, At:(t, ,  Dr, true) E CF_,-GEN(G,, cel, Ds, u) and(t, D, A,) 6 CE-GEN(G;,  ce, Dl, tt) andA = true) ) }U { (t, D, true) I 3 k, n, Rk, d~,.
.
.
,d. :ce = Rk and131Rk ?
MF-RULES;  andD2 = D\[(G,, Rk)<D~, d2 .... ,d.>\] andt ?
Ft(u,t2,...,t,) andt2 ?
M-GENERATOR(d2)  andt, ?
M-GENERATOR(d , )  )U { (t, D, true) \[ q k, Rk:Rk ?
TR-RULES~D = D2 andce = Rt and t ?
Fk(u) }(ce, cet, ce2 are control expressions, D, Dr, D2 areopen derivation trees, d2,...,d, are closed derivationtrees, D~ is the empty derivation tree, t, it, t2, t,,u are S-trees, R~ an M-rule, Ft is the compositionalfunction defined by rule Rk, A, At, A2 are booleans)RemarksIn case of a recursive transformation class there isthe possibility of infinite recurslon during applicationof CE-GEN.
This must be prevented by defining a mea-sure on S-trees in such a way that each application ofa transformation of the class yields a smaller S-treeaccording to this measure.The definition of M-GENERATOR is symmetric tothe definition of M-PARSER ?
(There is one appar-ent exception: the condition on EXPORTCATS in?
M-PARSER and the condition on HEADCATS in M-GENERATOR.
However, these conditions are redun-dant from a formal point of view, because they mustfollow from the applicability conditions of the rulesin the control expression?)
Thanks to this symmetryit is simple to prove that M-GENERATOR and M-PARSER are each other's reverse.
One of the virtuesof this way of controlling rule applications is that theOne Grammar  Principle can still be obeyed.7 ConclusionIn section 2 we enumerated three types of problemswith the free M-grammar formalism used for the de-velopment of the Rosettal and Rosetta2 systems.The first problem was the lack of structure in free M-grammars.
This was solved in section 3 by introducinga modular approach, where M-grammars are dividedinto subgrammars in a way that was inspired by theprogramming language Modula-2 on the one hand andby the notion projection from X-theory on the otherhand.The second problem was that there is no way ofexplicitly controlling the application of rules in free M-grammars and that it is not obvious how this kind ofcontrol could be introduced in a compositional gram-mar, where rules may have more than one argument.The insight that was important to the solution of thisproblem was that application of a subgrammar comesdown to following a projection path, from the importedhead to the exported projection.
This implies thatdefining control in a subgrammar comes down to spec-ifying a set of possible sequences of rule applications,which can be done by means of a control expression,a regular expression over rule names.
An  importantadvantage of this way of controlling rule applicationsis that the One Grammar  Principle is still obeyed: thesame grammar (i.e.
the same subgrammars: the samerules, the same control expressions, etc.)
can be usedfor the compositional and the analytical definition ofa language.
This is proved by the formal definitions insubsection 6.2.The third problem concerned the consequences ofdefining the translation relation by means of isomor-phic grammars.
The introduction of an explicit dis-tinction between meaningful rules and syntactic trans-formations in section 4 avoids unnecessary complica-tions of the grammars without affecting the Principleof Isomorphy.
Because the applicability of syntactictransformations is restrained by the control expres-sions, they do not cause problems with effectivity orefficiency.
The introduction of rule classes gave moreinsight into complex translation relations.
In section5 it was shown that category mismatch problems canbe handled more systematically by a combination ofsubgrammars and rule classes.AcknowledgementsThe authors would like to thank all the members of theRosetta team for their constructive criticism.
In par-ticular we want to mention the invaluable contributionsof Jan Odijk with respect to linguistic matters.ReferencesAppelo, L. and J. Landsbergen (1986), The MachineTranslation Project Rosetta, Philips Research M.S.13.801, Proceedings First International Conference onState of the Art in Machine Translation, Saarbriicken,pp.
34-51.Chomsky, N. (1970), Remar~ on Nominalisation, inR.A.
Jacobs and P.S.
Rosenbaum (eds), Readings inEnglish Transformational Grammar, Georgetown Univer-sity Press, Washington DC, pp.
184-9.21.Isabelle, P. and E. Macklovitch (1086), Tran.sfer andMT Modularity, Proceedings Coling 1986, Bonn, pp.115-117.Landsbergen, J.
(1984), Isomorphic grammar~ and theiruse in the Rosetta translation 8ystent, Philips ResearchM.S.
12.950.
Paper presented at the Tutorial on Ma-chine Translation, Lugano.
To appear in M. King (ed),132Machine Translation the state of the art, Edinburg Uni-versity Press.Leermakers, R. and J. Rous (1986), The TranslationMethod of Rosetta, Computers and Translation, Voh 1,Number 3, pp.
169-183.Nagao, M. and J. Tsujii (1986), The Transfer Phase ofthe MU Machine Translation System Proceedings Coling1986, Bonn, pp.
97-103.Stowell, T. (1981), Origins of Phrase Structure, Ph.D.dissertation, MIT.Thomason, B.
(1974), Formal Philosophy.
Selected Pa-pers o| Richard Montague, Yale University Press, NewHRven.Vauquois, B. and C. Boitet (1985), Automated Transla-tion at Grenoble University, Computational Linguistics,Vol.
11, Number 1, pp.
28-36.Wirth, N. (1985), Programming in Modula-2, Springer-Verlag, third corrected edition.133
