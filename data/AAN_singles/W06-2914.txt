Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 101?108, New York City, June 2006. c?2006 Association for Computational LinguisticsWord Distributions for Thematic Segmentation in a Support VectorMachine ApproachMaria GeorgesculISSCO/TIM, ETIUniversity of Geneva1211 Geneva, Switzerlandmaria.georgescul@eti.unige.chAlexander ClarkDepartment of Computer ScienceRoyal Holloway University of LondonEgham, Surrey TW20 0EX, UKalexc@cs.rhul.ac.ukSusan ArmstrongISSCO/TIM, ETIUniversity of Geneva1211 Geneva, Switzerlandsusan.armstrong@issco.unige.chAbstractWe investigate the appropriateness of us-ing a technique based on support vectormachines for identifying thematic struc-ture of text streams.
The thematic seg-mentation task is modeled as a binary-classification problem, where the differentclasses correspond to the presence or theabsence of a thematic boundary.
Exper-iments are conducted with this approachby using features based on word distri-butions through text.
We provide em-pirical evidence that our approach is ro-bust, by showing good performance onthree different data sets.
In particu-lar, substantial improvement is obtainedover previously published results of word-distribution based systems when evalua-tion is done on a corpus of recorded andtranscribed multi-party dialogs.1 Introduction(Todd, 2005) distinguishes between ?local-level top-ics (of sentences, utterances and short discourse seg-ments)?
and ?discourse topics (of more extendedstretches of discourse)?.1 (Todd, 2005) points outthat ?discourse-level topics are one of the most elu-sive and intractable notions in semantics?.
Despitethis difficulty in giving a rigorous definition of dis-course topic, the task of discourse/dialogue segmen-tation into thematic episodes can be described by1In this paper, we make use of the term topic or theme asreferring to the discourse/dialogue topic.invoking an ?intuitive notion of topic?
(Brown andYule, 1998).
Thematic segmentation also relatesto several notions such as speaker?s intention, topicflow and cohesion.In order to find out if thematic segment identi-fication is a feasible task, previous state-of-the-artworks appeal to experiments, in which several hu-man subjects are asked to mark thematic segmentboundaries based on their intuition and a minimalset of instructions.
In this manner, previous studies,e.g.
(Passonneau and Litman, 1993; Galley et al,2003), obtained a level of inter-annotator agreementthat is statistically significant.Automatic thematic segmentation (TS), i.e.
thesegmentation of a text stream into topically coher-ent segments, is an important component in ap-plications dealing with large document collectionssuch as information retrieval and document brows-ing.
Other tasks that could benefit from the thematictextual structure include anaphora resolution, auto-matic summarisation and discourse understanding.The work presented here tackles the problemof TS by adopting a supervised learning approachfor capturing linear document structure of non-overlapping thematic episodes.
A prerequisite forthe input data to our system is that texts are dividedinto sentences or utterances.2 Each boundary be-tween two consecutive utterances is a potential the-matic segmentation point and therefore, we modelthe TS task as a binary-classification problem, whereeach utterance should be classified as marking the2Occasionally within this document we employ the term ut-terance to denote either a sentence or an utterance in its propersense.101presence or the absence of a topic shift in the dis-course/dialogue based only on observations of pat-terns in vocabulary use.The remainder of the paper is organised as fol-lows.
The next section summarizes previous tech-niques, describes how our method relates to themand presents the motivations for a support vector ap-proach.
Sections 3 and 4 present our approach inadopting support vector learning for thematic seg-mentation.
Section 5 outlines the empirical method-ology and describes the data used in this study.
Sec-tion 6 presents and discusses the evaluation results.The paper closes with Section 7, which briefly sum-marizes this work and offers some conclusions andfuture directions.2 Related WorkAs in many existing approaches to the thematic seg-mentation task, we make the assumption that thethematic coherence of a text segment is reflected atlexical level and therefore we attempt to detect thecorrelation between word distribution and thematicchanges throughout the text.
In this manner, (Hearst,1997; Reynar, 1998; Choi, 2000) start by using asimilarity measure between sentences or fixed-sizeblocks of text, based on their word frequencies inorder to find changes in vocabulary use and there-fore the points at which the topic changes.
Sen-tences are then grouped together by using a cluster-ing algorithm.
(Utiyama and Isahara, 2001) modelsthe problem of TS as a problem of finding the mini-mum cost path in a graph and therefore adopts a dy-namic programming algorithm.
The main advantageof such methods is that no training time and corporaare required.By modeling TS as binary-classification problem,we introduce a new technique based on support vec-tor machines (SVMs).
The main advantage offeredby SVMs with respect to methods such as those de-scribed above is related to the distance (or similarity)function used.
Thus, although (Choi, 2000; Hearst,1997) employ a distance function (i.e.
cosine dis-tance) to detect thematic shifts, SVMs are capableof using a larger variety of similarity functions.Moreover, SVMs can employ distance functionsthat operate in extremely high dimensional featurespaces.
This is an important property for our task,where handling high dimensionality data represen-tation is necessary (see section 4).An alternative to dealing with high dimensiondata may be to reduce the dimensionality of thedata representation.
Therefore, linear algebra di-mensionality reduction methods like singular valuedecomposition have been adopted by (Choi et al,2001; Popescu-Belis et al, 2004) in Latent Seman-tic Analysis (LSA) for the task of thematic segmen-tation.
A Probabilistic Latent Semantic Analysis(PLSA) approach has been adopted by (Brants etal., 2002; Farahat and Chen, 2006) for the TS task.
(Blei and Moreno, 2001) proposed a TS approach,by embedding a PLSA model in an extended Hid-den Markov Model (HMM) approach, while (Yam-ron et al, 1998) have previously proposed a HMMapproach for TS.A shortcoming of the methods described aboveis due to their typically generative manner of train-ing, i.e.
using the maximum likelihood estimationfor a joint sampling model of observation and la-bel sequences.
This poses the challenge of findingmore appropriate objective functions, i.e.
alterna-tives to the log-likelihood that are more closely re-lated to application-relevant performance measures.Secondly, efficient inference and learning for the TStask often requires making questionable conditionalindependence assumptions.
In such cases, improvedperformance may be obtained by using methodswith a more discriminative character, by allowingdirect dependencies between a label and past/futureobservations and by efficient handling higher-ordercombinations of input features.
Given the discrim-inative character of SVMs, we expect our model toattain similar benefits.3 Support Vector Learning Task andThematic SegmentationThe theory of Vapnik and Chervonenkis (Vapnik,1995) motivated the introduction of support vectorlearning.
SVMs have originally been used for clas-sification purposes and their principles have been ex-tended to the task of regression, clustering and fea-ture selection.
(Kauchak and Chen, 2005) employedSVMs using features (derived for instance from in-formation given by the presence of paragraphs, pro-nouns, numbers) that can be reliably used for topic102segmentation of narrative documents.
Aside fromthe fact that we consider the TS task on differentdatasets (not only on narrative documents), our ap-proach is different from the approach proposed by(Kauchak and Chen, 2005) mainly by the data repre-sentation we propose and by the fact that we put theemphasis on deriving the thematic structure merelyfrom word distribution, while (Kauchak and Chen,2005) observed that the ?block similarities providelittle information about the actual segment bound-aries?
on their data and therefore they concentratedon exploiting other features.An excellent general introduction to SVMs andother kernel methods is given for instance in (Cris-tianini and Shawe-Taylor, 2000).
In the section be-low, we give some highlights representing the mainelements in using SVMs for thematic segmentation.The support vector learner L is given a trainingset of n examples, usually denoted by Strain= ((~u1,y1),...,(~un, yn))?
(U ?
Y )n drawn independentlyand identically distributed according to a fixed dis-tribution Pr(u, y) = Pr(y|u)Pr(u).
Each train-ing example consists of a high-dimensional vector ~udescribing an utterance and the class label y. Theutterance representations we chose are further de-scribed in Section 4.
The class label y has onlytwo possible values: ?thematic boundary?
or ?non-thematic boundary?.
For notational convenience, wereplace these values by +1 and -1 respectively, andthus we have y ?
{-1, 1}.
Given a hypothesis spaceH, of functions h : U ?
{?1,+1} having the formh(~u) = sign(< ~w, ~u > +b), the inductive sup-port vector learner Lind seeks a decision functionhind from H, using Strain so that the expected num-ber of erroneous predictions is minimized.
Usingthe structural risk minimization principle (Vapnik,1995), the support vector learner gets the optimal de-cision function h by minimizing the following costfunction:W ind(~w, b, ?1, ?2, ..., ?n) = 12 < ~w, ~w > ++ C+n?i=0,yi=1?i + C?n?i=0,yi=?1?i,subject to:yi[< ~w ?
~ui > +b] ?
1?
?i for i = 1, 2, ..., n;?i ?
0 for i = 1, 2, ..., n.The parameters ~w and b follow from the optimi-sation problem, which is solved by applying La-grangian theory.
The so-called slack variables ?i,are introduced in order to be able to handle non-separable data.
The positive parameters C+ and C?are called regularization parameters and determinethe amount up to which errors are tolerated.
Moreexactly, training data may contain noisy or outlierdata that are not representative of the underlying dis-tribution.
On the one hand, fitting exactly to thetraining data may lead to overfitting.
On the otherhand, dismissing true properties of the data as sam-pling bias in the training data will result in low accu-racy.
Therefore, the regularization parameter is usedto balance the trade-off between these two compet-ing considerations.
Setting the regularization para-meter too low can result in poor accuracy, while set-ting it too high can lead to overfitting.
In the TS task,we used an automated procedure to select the regu-larization parameters, as further described in section5.3.In cases where non-linear hypothesis functionsshould be optimised, each ~ui can be mapped into?
(~ui) ?
F , where F is a higher dimensional spaceusually called feature space, in order to make linearthe relation between ~ui and yi.
Thus the original lin-ear learning machine can be adopted in finding theclassification solution in the feature space.When using a mapping function ?
: U ?
F ,if we have a way of computing the inner product??
(~ui), ?(~uj)?
directly as a function of the origi-nal input point, then the so-called kernel functionK(~ui, ~uj) = ??
(~ui), ?(~uj)?
is proved to simplifythe computational complexity implied by the directuse of the mapping function ?.
The choice of appro-priate kernels and its specific parameters is an empir-ical issue.
In our experiments, we used the Gaussianradial basis function (RBF) kernel:KRBF (~ui, ~uj) = exp(?
?2||~ui ?
~uj ||2).For the SVM calculations, we used the LIBSVM li-brary (Chang and Lin, 2001).4 Representation of the information usedto determine thematic boundariesAs presented in section 3, in the thematic segmen-tation task, an input ~ui to the support vector classi-fier is a vectorial representation of the utterance to103be classified and its context.
Each dimension of theinput vector indicates the value of a certain featurecharacterizing the utterance.
All input features hereare indicator functions for a word occurring withina fixed-size window centered on the utterance beinglabeled.
More exactly, the input features are com-puted in the following steps:1.
The text has been pre-processed by tokeniza-tion, elimination of stop-words and lemmatiza-tion, using TreeTagger (Schmid, 1996).2.
We make use of the so-called bag of words ap-proach, by mapping each utterance to a bag, i.e.a set that contains word frequencies.
Therefore,word frequencies have been computed to countthe number of times that each term (i.e.
wordlemma) is used in each utterance.
Then a trans-formation of the raw word frequency countsis applied in order to take into account boththe local (i.e.
for each utterance) word fre-quencies as well as the overall frequencies oftheir occurrences in the entire text collection.More exactly, we made experiments in paral-lel with three such transformations, which arevery commonly used in information retrievaldomain (Dumais, 1991): tf.idf, tf.normal andlog.entropy.3.
Each i-th utterance is represented by a vector~ui, where a j-th element of ~ui is computed as:ui,j =??i?t=i?winSizeft,j????i+winSize?k=i+1fk,j??
,where winSize ?
1 and fi,j is the weightedfrequency (determined in the previous step) ofthe j-th word from the vocabulary in the i-th ut-terance.
In this manner, we will have ui,j > 0 ifand only if at least two occurrences of the j-thterm occur within (2 ?
winSize) utterances onopposite sides of a boundary candidate.
Thatis, each ui,j is capturing how many word co-occurrences appear across the candidate utter-ance in an interval (of (2?winSize) utterances)centered in the boundary candidate utterance.4.
Each attribute value from the input data isscaled to the interval [0, 1].Note that the vector space representation adopted inthe previous steps will result in a sparse high dimen-sional input data for our system.
More exactly, table1 shows the average number of non-zero features perexample corresponding to each data set (further de-scribed in section 5.1).Data set Non zero featuresICSI 3.67%TDT 0.40%Brown 0.12%Table 1: The percentage of non-zero features per ex-ample.5 Experimental Setup5.1 Data sets usedIn order to evaluate how robust our SVM approachis, we performed experiments on three English datasets of approximately the same dimension (i.e.
con-taining about 260,000 words).The first dataset is a subset of the ICSI-MR cor-pus (Janin et al, 2004), where the gold standard forthematic segmentations has been provided by tak-ing into account the agreement of at least three hu-man annotators (Galley et al, 2003).
The corpusconsists of high-quality close talking microphonerecordings of multi-party dialogues.
Transcriptionsat word level with utterance-level segmentations arealso available.
A test sample from this dataset con-sists of the transcription of an approximately one-hour long meeting and contains an average of aboutseven thematic episodes.The second data set contains documents randomlyselected from the Topic Detection and Tracking(TDT) 2 collection, made available by (LDC, 2006).The TDT collection includes broadcast news andnewswire text, which are segmented into topicallycohesive stories.
We use the story segmentation pro-vided with the corpus as our gold standard labeling.A test sample from our subset contains an averageof about 24 segments.The third dataset we use in this study was origi-nally proposed in (Choi, 2000) and contains artifi-cial thematic episodes.
More precisely, the datasetis built by concatenating short pieces of texts that104Data set Weighting schema winSize ?
CICSI log.entropy 57 0.0625 0.01TDT tf.idf 17 0.0625 0.1Brown tf.idf 5 0.0625 0.001Table 2: The optimal settings found for the SVM model, using the RBF kernel.have been randomly extracted from the Brown cor-pus.
Any test sample from this dataset consists often segments.
Each segment contains at least threesentences and no more than eleven sentences.While the focus of our paper is not on the methodof evaluation, it is worth pointing out that the per-formance on the synthetic data set is a very poorguide to the performance on naturally occurring data(Georgescul et al, 2006).
We include the syntheticdata for comparison purposes.5.2 Handling unbalanced dataWe have a small percentage of positive examplesrelative to the total number of training examples.Therefore, in order to ensure that positive points arenot considered as being noisy labels, we change thepenalty of the minority (positive) class by setting theparameter C+ of this class to:C+ = ?
?
(nn+ ?
1?
1)?
C?,where n+ is the number of positive training exam-ples, n is the total number of training examples and?
is the scaling factor.
In the experiments reportedhere, we set the value for the scale factor ?
to ?
= 1and we have: C+ = 7 ?
C?
for the synthetic dataderived from Brown corpus; C+ = 18 ?
C?for theTDT data and C+ = 62 ?
C?
for the ICSI meetingdata.5.3 Model selectionWe used 80% of each dataset to determine the bestmodel settings, while the remaining 20% is usedfor testing purposes.
Each training set (for eachdataset employed) was divided into disjoint subsetsand five-fold cross-validation was applied for modelselection.In order to avoid too many combinations of pa-rameter settings, model selection is done in twophases, by distinguishing two kinds of parameters.First, the parameters involved in data representation(see section 4) are addressed.
We start with choosingan appropriate term weighting scheme and a goodvalue for the winSize parameter.
This choice isbased on a systematic grid search over 20 differ-ent values for winSize and the three variants tf.idf,tf.normal and log.entropy for term weighting.
Weran five-fold cross validation, by using the RBF ker-nel with its parameter ?
fixed to ?
= 1.
We also setthe regularization parameter C equal to C = 1.In the second phase of model selection, wetake the optimal parameter values selected in theprevious phase as a constant factor and searchthe most appropriate values for C and ?
para-meters.
The range of values we select from is:C ?
{10?3, 10?2, 10?1, 1, 10, 102, 103}and ?
?
{2?6, 2?5, 2?4, ..., 24, 26}and for each possiblevalue we perform five-fold cross validation.
There-fore, we ran the algorithm five times for the 91 =7 ?
13 parameter settings.
The most suitable modelsettings found are shown in Table 2.
For these set-tings, we show the algorithm?s results in section 6.6 Evaluation6.1 Evaluation MeasuresBeeferman et al (1999) underlined that the stan-dard evaluation metrics of precision and recall areinadequate for thematic segmentation, namely bythe fact that these metrics did not account for howfar away a hypothesized boundary (i.e.
a boundaryfound by the automatic procedure) is from the ref-erence boundary.
On the other hand, for instance,an algorithm that places a boundary just one utter-ance away from the reference boundary should bepenalized less than an algorithm that places a bound-ary ten (or more) utterances away from the referenceboundary.Hence the use of two other evaluation metricsis favored in thematic segmentation: the Pk met-ric (Beeferman et al, 1999) and the WindowDifferror metric (Pevzner and Hearst, 2002).
In con-105020406080100120 AlgorithmsError ratesP_k18.5411.0152.5120.4921.3660.0421.6831.912354.6268.48WD19.4713.5880.6323.9936.2891.9225.535.8825.4769.4195.48SVMC99   RandSVMC99RandSVMG03 G03* C99RandBrown dataTDT dataICSI dataFigure 1: Error rates of the segmentation systems.trast to precision and recall, these metrics allow for aslight vagueness in where the hypothesized thematicboundaries are placed and capture ?the notion ofnearness in a principled way, gently penalizing algo-rithms that hypothesize boundaries that aren?t quiteright, and scaling down with the algorithm?s degra-dation?
(Beeferman et al, 1999).
That is, comput-ing both Pk and WindowDiff metrics involves theuse of a fixed-size (i.e.
having a fixed number ofeither words or utterances) window that is movedstep by step over the data.
At each step, Pk andWindowDiff are basically increased (each metric ina slightly different way) if the hypothesized bound-aries and the reference boundaries are not within thesame window.During the model selection phase, we used pre-cision and recall in order to measure the system?serror rate.
This was motivated by the fact that pos-ing the TS task as a classification problem leads to aloss of the sequential nature of the data, which is aninconvenient in computing the Pk and WindowDiffmeasures.
However, during the final testing phaseof our system, as well as for the evaluation of theprevious systems, we use both the Pk and the Win-dowDiff error metric.The relatively small size of our datasets does notallow for dividing our test set into multiple sub-testsets for applying statistical significance tests.
Thiswould be desirable in order to indicate whether thedifferences in system error rates are statistically sig-nificant over different data sets.
Nevertheless, webelieve that measuring differences in error rates ob-tained on the test set is indicative of the relative per-formance.
Thus, the experimental results shown inthis paper should be considered as illustrative ratherthan exhaustive.6.2 ResultsIn order to determine the adequacy of our SVM ap-proach over different genres, we ran our system overthree datasets, namely the ICSI meeting data, theTDT broadcast data and the Brown written genredata.By measuring the system error rates using thePk and the WindowDiff metrics, Figure 1 summa-rizes the quantitative results obtained in our empir-ical evaluation.
In Figure 1, our SVM approach islabeled as SVM and we abbreviate WindowDiff asWD.
The results of our SVM system correspond tothe parameter values detected during model selec-tion (see Table 2).
We compare our system againstan existing thematic segmenter in the literature: C99(Choi, 2000).
We also give for comparison theerror rates of a naive algorithm, labeled as Randalgorithm, which randomly distributes boundariesthroughout the text.The LCseg system (Galley et al, 2003), labeledhere as G03, is to our knowledge the only word dis-tribution based system evaluated on ICSI meetingdata.
Therefore, we replicate the results reported by(Galley et al, 2003) when evaluation of LCseg wasdone on ICSI data.
The so-labeled G03* algorithm106indicates the error rates obtained by (Galley et al,2003) when extra (meeting specific) features havebeen adopted in a decision tree classifier.
However,note that the results reported by (Galley et al) arenot directly comparable with our results because ofa slight difference in the evaluation procedure: (Gal-ley et al) performed 25-fold cross validation and theaverage Pk and WD error rates have been computedon the held-out sets.Figure 1 illustrates the following interesting re-sults.
For the ICSI meeting data, our SVM approachprovides the best performance relative to the com-peting word distribution based state-of-the-art meth-ods.
This proves that our SVM-based system is ableto build a parametric model that leads to a segmenta-tion that highly correlates to a human thematic seg-mentation.
Furthermore, by taking into account therelatively small size of the data set we used for train-ing, it can be concluded that the SVM can buildqualitatively good models even with a small train-ing data.
The work of (Galley et al, 2003) showsthat the G03* algorithm is better than G03 by ap-proximately 10%, which indicates that on meetingdata the performance of our word-distribution basedapproach could possibly be increased by using othermeeting-specific features.By examining the error rates given by Pk metricfor the three systems on the TDT data set, we ob-serve that our system and C99 performed more orless equally.
With respect to the WindowDiff met-ric, our system has an error rate approximately 10%smaller than C99.On the synthetic data set, the SVM approachperformed slightly worse than C99, avoiding how-ever catastrophic failure, as observed with the C99method on ICSI data.7 ConclusionsWe have introduced a new approach based on worddistributions for performing thematic segmentation.The thematic segmentation task is modeled here asa binary classification problem and support vectormachine learning is adopted.
In our experiments, wemake a comparison of our approach versus existinglinear thematic segmentation systems reported in theliterature, by running them over three different datasets.
When evaluating on real data, our approach ei-ther outperformed the other existing methods or per-forms comparably to the best.
We view this as astrong evidence that our approach provides a unifiedand robust framework for the thematic segmentationtask.
The results also suggest that word distributionsthemselves might be a good candidate for capturingthe thematic shifts of text and that SVM learning canplay an important role in building an adaptable cor-relation.Our experiments also show the sensitivity of asegmentation method to the type of a corpus onwhich it is tested.
For instance, the C99 algorithmwhich achieves superior performance on a syntheticcollection performs quite poorly on the real-life datasets.While we have shown empirically that our tech-nique can provide considerable gains by using sin-gle word distribution features, future work will in-vestigate whether the system can be improved by ex-ploiting other features derived for instance from syn-tactic, lexical and, when available, prosodic infor-mation.
If further annotated meeting data becomesavailable, it would be also interesting to replicate ourexperiments on a bigger data set in order to verifywhether our system performance improves.Acknowledgments This work is partially sup-ported by the Interactive Multimodal InformationManagement project (http://www.im2.ch/).
Manythanks to the reviewers for their insightful sugges-tions.
We are grateful to the International ComputerScience Institute (ICSI), University of California forsharing the data with us.
The authors also thankMichael Galley who kindly provided us the thematicannotations of the ICSI data.ReferencesDoug Beeferman, Adam Berger, and John Lafferty.1999.
Statistical Models for Text Segmentation.
Ma-chine Learning, 34(1-3):177?210.David M. Blei and Pedro J. Moreno.
2001.
Topic Seg-mentation with an Aspect Hidden Markov Model.
InProceedings of the 24th annual international ACM SI-GIR conference on Research and development in in-formation retrieval, pages 343?348.
ACM Press.Thorsten Brants, Francine Chen, and Ioannis Tsochan-taridis.
2002.
Topic-Based Document Segmentationwith Probabilistic Latent Semantic Analysis.
In Pro-ceedings of the Eleventh International Conference on107Information and Knowledge Management, pages 211?218, McLean, Virginia, USA.
ACM Press.Gillian Brown and George Yule.
1998.
Discourse Analy-sis.
Cambridge Textbooks in Linguistics, Cambridge.Chih-Chung Chang and Chih-Jen Lin.
2001.
LIBSVM:a library for support vector machines.
Software avail-able at http://www.csie.ntu.edu.tw/ cjlin/libsvm.Freddy Choi, Peter Wiemer-Hastings, and JohannaMoore.
2001.
Latent Semantic Analysis for Text Seg-mentation.
In Proceedings of the 6th Conference onEmpirical Methods in Natural Language Processing,Seattle, WA.Freddy Choi.
2000.
Advances in Domain IndependentLinear Text Segmentation.
In Proceedings of the 1stConference of the North American Chapter of the As-sociation for Computational Linguistics, pages 26?33,Seattle, USA.Nello Cristianini and John Shawe-Taylor.
2000.
AnIntroduction to Support Vector Machines and otherkernel-based learning methods.
Cambridge Univer-sity Press, Cambridge, UK.Susan Dumais.
1991.
Improving the retrieval of informa-tion from external sources.
Behavior Research Meth-ods, Instruments and Computers, 23(2):229?236.Ayman Farahat and Francine Chen.
2006.
ImprovingProbabilistic Latent Semantic Analysis with PrincipalComponent Analysis.
In Proceedings of the 11th Con-ference of the European Chapter of the Asociation forComputational Linguistics, Trento, Italy.Michael Galley, Kathleen McKeown, Eric Fosler-Luissier, and Hongyan Jing.
2003.
Discourse Seg-mentation of Multy-Party Conversation.
In Proceed-ings of the 41st Annual Meeting of the Association forComputational Linguistics, pages 562?569.Maria Georgescul, Alexander Clark, and Susan Arm-strong.
2006.
An Analysis of Quantitative Aspects inthe Evaluation of Thematic Segmentation Algorithms.To appear.Marti Hearst.
1997.
TextTiling: Segmenting Text intoMulti-Paragraph Subtopic Passages.
ComputationalLinguistics, 23(1):33?64.Adam Janin, Jeremy Ang, Sonali Bhagat, Rajdip Dhillon,Jane Edwards, Javier Macias-Guarasa, Nelson Mor-gan, Barbara Peskin, Elizabeth Shriberg, AndreasStolcke, Chuck Wooters, and Britta Wrede.
2004.
TheICSI Meeting Project: Resources and Research.
InICASSP 2004 Meeting Recognition Workshop (NISTRT-04 Spring Recognition Evaluation), Montreal.David Kauchak and Francine Chen.
2005.
Feature-Based Segmentation of Narrative Documents.
In Pro-ceedings of the ACL Workshop on Feature Engineeringfor Machine Learning in Natural Language Process-ing, pages 32?39, Ann Arbor; MI; USA.LDC.
2006.
The Linguistic Data Consortium.
Availablefrom World Wide Web: http://www.ldc.upenn.edu.Rebecca J. Passonneau and Diane J. Litman.
1993.Intention-based Segmentation: Human Reliability andCorrelation with Linguistic Cues.
In Proceedings ofthe 31st conference on Association for ComputationalLinguistics, pages 148 ?
155, Columbus, Ohio.Lev Pevzner and Marti Hearst.
2002.
A Critique and Im-provement of an Evaluation Metric for Text Segmen-tation.
Computational Linguistics, 16(1):19?36.Andrei Popescu-Belis, Alexander Clark, Maria Georges-cul, Sandrine Zufferey, and Denis Lalanne.
2004.Shallow Dialogue Processing Using Machine Learn-ing Algorithms (or Not).
In Bourlard H. and Ben-gio S., editors, Multimodal Interaction and RelatedMachine Learning Algorithms, pages 277?290.
LNCS3361, Springer-Verlag, Berlin.Jeffrey Reynar.
1998.
Topic Segmentation: Algorithmsand Applications.
Ph.D. thesis, University of Pennsyl-vania.Helmut Schmid.
1996.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
Technical report, Insti-tute for Computational Linguistics of the Universityof Stuttgart.Richard Watson Todd.
2005.
A fuzzy approach to dis-course topics.
Journal of the International Associationfor Semiotic Studies, 155:93?123.Masao Utiyama and Hitoshi Isahara.
2001.
A Statis-tical Model for Domain-Independent Text Segmenta-tion.
In Proceedings of the 39th Annual Meeting ofthe ACL joint with the 10th Meeting of the EuropeanChapter of the ACL, pages 491?498, Toulouse, France.Vladimir Naumovich Vapnik.
1995.
The Nature of Sta-tistical Learning Theory.
Springer-Verlag, New York.Jonathan P. Yamron, Ira Carp, Lawrence Gillick, SteweLowe, and Paul van Mulbregt.
1998.
A HiddenMarkov Model Approach to Text Segmentation andEvent Tracking.
In Proceedings of the IEEE Confer-ence on Acoustics, Speech, and Signal Processing, vol-ume 17, pages 333?336, Seattle, WA.108
