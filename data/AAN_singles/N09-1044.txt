Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 389?396,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsGeo-Centric Language Models for Local Business Voice SearchAmanda Stent, Ilija Zeljkovic?, Diamantino Caseiro and Jay WilponAT&T Labs ?
Research180 Park Avenue Bldg.
103Florham Park, NJ 07932, USAstent, ilija, caseiro, jgw@research.att.comAbstractVoice search is increasingly popular, espe-cially for local business directory assistance.However, speech recognition accuracy onbusiness listing names is still low, leading touser frustration.
In this paper, we present anew algorithm for geo-centric language modelgeneration for local business voice search formobile users.
Our algorithm has several ad-vantages: it provides a language model forany user in any location; the geographic areacovered by the language model is adapted tothe local business density, giving high recog-nition accuracy; and the language models canbe pre-compiled, giving fast recognition time.In an experiment using spoken business list-ing name queries from a business directoryassistance service, we achieve a 16.8% abso-lute improvement in recognition accuracy anda 3-fold speedup in recognition time with geo-centric language models when compared witha nationwide language model.1 IntroductionVoice search is an increasingly popular applicationof speech recognition to telephony.
In particular,in the last two years several companies have comeout with systems for local business voice search(LBVS).
In this type of application, the user pro-vides a desired location (city/state) and a businessname, and the system returns one or more match-ing business listings.
The most traditional LBVSapplications are commercial 411 services, which areimplemented as a speech-only two-exchange dialogsuch as the one in Figure 1.
In this approach toLBVS, the speech recognizer (ASR) uses one gram-mar to recognize city/state, and then uses separategrammars for recognizing listings in each local area.This gives relatively high recognition accuracy.Advancements in ASR and search technologyhave made a more information retrieval-style LBVSfeasible.
In this approach, the ASR typically usesa large stochastic language model that permits theuser to specify location and listing name or cate-gory together in a single utterance, and then sub-mits recognition results to a search engine (Natara-jan et al, 2002).
This gives the user more flexibilityto ?say anything at any time?.
However, in recentevaluations of one-exchange LBVS we have foundthat locations are recognized with much higher ac-curacy than listing names1.
This may mean that theuser has to repeat both location and listing severaltimes (while in a traditional two-exchange interac-tion only one piece of information would have to berepeated).
In effect, system developers have tradedrecognition accuracy for interaction flexibility, po-tentially increasing user frustration.Advances in mobile phone technology make itpossible for us to combine the advantages of two-exchange and one-exchange LBVS.
The newestsmart phones come with global positioning system(GPS) receivers and/or with the ability to determinelocation through cell tower triangulation or wi-fi.
Ifwe know the location of a LBVS user, we can usea geo-centric language model to achieve improvedspeech recognition accuracy and speed.
This ap-proach unobtrusively exploits the benefits of two-1The vocabulary size for listing names is larger than that forcities and states in the USA.389S City and state?U Glendale CaliforniaS What listing?U pizzaFigure 1: Example 411-search dialogexchange voice search applications, while maintain-ing the flexibility of one-exchange systems.In this paper, we present an efficient algorithmfor constructing geo-centric language models froma business listing database and local business searchlogs.
Our algorithm has several advantages: it pro-vides a language model for any user in any location;the geographic area covered by the language modelis adapted to the local business density, giving highrecognition accuracy; and the language models canbe pre-compiled, giving fast recognition time.
Inan experiment using LBVS queries, we achieve: a16.8% absolute improvement in recognition accu-racy and a 3-fold speedup in recognition time withgeo-centric language models when compared with anationwide language model (such as those used inone-exchange LBVS); and a 4.4% absolute increasein recognition accuracy and a 16% speedup in recog-nition time with geo-centric language models whencompared with local area language models (such asthose used in two-exchange LBVS).The rest of this paper is structured as follows: InSection 2 we discuss related work on voice-drivenlocal search.
In Section 3 we present the motivationfor and architecture of a LBVS application.
In Sec-tion 4 we present our algorithm for generating geo-centric language models.
In Section 5 we describean evaluation of the performance of our geo-centriclanguage models on business listing name queriesfrom a deployed voice-driven search application.
InSection 6 we conclude and present future work.2 Related WorkLBVS is the most recent variation on automated di-rectory assistance (Buntschuh et al, 1998).
ASRfor directory assistance is difficult for several rea-sons: the vocabulary is large and includes foreignwords; there may be multiple possible pronuncia-tions for many words; and the frequency distribu-tion of words in the vocabulary is unusual, with afew words occurring very often and the rest, rarely.These difficulties are compounded by directory size.For example, Kamm et al (1995), in experimentson personal name directories, showed that ASR ac-curacy decreases from 82% for a 200 name directoryto 16.5% for a 1.5 million name directory.One way to reduce the directory size is to cover asmaller geographic area.
For example, early LBVScovered only one city (Seide and Kellner, 1997;Collingham et al, 1997).
Later, two-exchange, ap-plications required the user to specify their desiredlocation in the first exchange.
This information wasthen used to select a local area grammar or languagemodel for recognition of the listing name (Acero etal., 2008; Bacchiani et al, 2008; Yu et al, 2007;Georgila et al, 2003).
In our research, we have cre-ated a novel method for constructing language mod-els that cover a very small geographic area specificto the user?s geo-location.Another way to reduce the directory size is to droplistings that are unlikely to be requested.
For exam-ple, Kamm et al (1995), in their analysis of 13,000directory assistance calls, found that a mere 245 list-ings covered 10% of the call volume, and 870 list-ings covered 20%.
Chang et al (2008) found that intheir data sets, 19-25% of the call volume was cov-ered by the top 200 listings.
We take a different ap-proach: we add frequent nationwide listings to ourgeo-centric language models to increase coverage.Other work related to ASR in automated direc-tory assistance has looked at ways in which usersrefer to locations (Gupta et al, 1998) and listings(Li et al, 2008; Scharenborg et al, 2001; Yu et al,2007), confidence scoring for directory assistancesearch results (Wang et al, 2007), and ways of han-dling recognition errors through multimodal confir-mation and correction (Acero et al, 2008; Chang etal., 2008; Paek et al, 2008).
We do not address theseissues here.3 Local Business Voice SearchThe current generation of smart phones containsGPS and/or can run applications that can detect theuser?s geo-location using cell tower triangulation orwi-fi.
We hypothesize that this geo-location infor-mation can be used in mobile LBVS to improverecognition accuracy without sacrificing interactionflexibility.
Our analysis of a directory assistancedata set shows that in the majority of cases, users390Figure 2: Architecture of a voice-driven local search ap-plicationrequest local listings.
It is frustrating for the user ofa LBVS who cannot retrieve information for a busi-ness right around the corner.
So, a LBVS shouldmaximize accuracy for local listings2.Figure 2 shows the architecture of a mobileLBVS.
It includes ASR (in a speech-only or multi-modal interface), search, and presentation of results(through speech, text and/or graphics).
It also in-cludes location information from GPS, cell tower tri-angulation or wi-fi, or the user?s query history (fromprevious dialogs, or previous turns in this dialog).4 Using Location to Tailor LanguageModelsThere are two ways to use geo-location informa-tion in ASR for LBVS.
One way is to use the user?sgeo-location to automatically determine the nearestcity.
City and state can then be used to select a lo-cal area language model (LM) for recognizing list-ing names.
The advantages of this approach include:human knowledge about location can be included inthe design of the local areas; and local areas can be2Of course, a LBVS should also give the user the option ofspecifying a different location, and/or should be able to recog-nize listings users are most likely to ask for that may not existin their local area.designed to produce a minimal number of local areaLMs.
However, if the user is near the edge of thepre-defined local area, the selected LM may excludebusinesses close to the user and include businessesfar away from the user.
Also, some local area LMscontain many more directory listings than others.Another way is to construct a geo-centric LMcovering businesses in a given radius around theuser?s geo-location.
This approach has the advan-tage that listings included in the language modelwill certainly be close to the user.
However, on-the-fly computation of geo-centric language modelsfor large numbers of users is too computationallydemanding given current database and processingtechnology.
It is equally impractical to pre-compileall possible geo-centric language models, since com-mercial GPS provides coordinates accurate to about20 feet.
Here we present an algorithm for approxi-mating true geo-centric language modeling in a waythat is computationally feasible and user relevant.4.1 Local Area Language ModelsTelecommunications companies have long under-stood that customers may not know the exact townin which a desired listing is, or may be interested inlistings from several nearby towns.
Considerable ef-fort has been devoted to defining local service areas(LSAs) for telephone directories.
In the directoryservice that provided the database we use, businesslistings are organized into about 2000 LSAs, eachconsisting either of several adjacent small towns orof one big city.
For example, the Morristown, NJLSA includes Morristown itself as well as 53 ad-jacent localities and neighborhoods spanning fromPine Brook in the north-east to Mendham in thesouth-west.
By contrast, the New York, NY LSAcontains only New York City, which includes sev-eral hundred neighborhoods.
The Morristown, NJLSA contains 50000 business listings while the NewYork, NY LSA contains more than 200000 listings.We construct one LM for each LSA, givingroughly 2000 local area LMs for the whole of theUSA.4.2 Geo-Centric Language ModelsTo construct a a geo-centric LM for a user, we needgeo-coordinates (for the center of the LM) and asearch radius (to determine the extent of the LM).
It391Figure 3: Geo-centric areas in New York Cityis computationally infeasible to either pre-computegeo-centric LMs for each uniquely identifiable setof geo-coordinates in the USA, or to compute themon-the-fly for large numbers of users.
Fortunately,the number of business geo-coordinates in the USAis much sparser than the number of possible usergeo-coordinates.
There are about 17 million name-address unique businesses in the USA; assuming 8-digit geo-code accuracy they are located at about 8.5million unique geo-coordinates3.
So we build LMsfor business geo-coordinates rather than user geo-coordinates, and at run-time we map a user?s geo-coordinates to those of their closest business.To determine the search radius, we need a work-ing definition of ?local listing?.
However, ?local?varies depending on one?s location.
In New YorkCity, a local listing may be one up to ten blocksaway (covering a smaller geographic area than theLSA), while in Montana a local listing may be onethat one can drive to in 45 minutes (covering a largergeographic area than the LSA).
Compare Figures 3and 4.
?Local?
is clearly related to business den-sity at a particular location.
So we compute businessdensity and use this to determine the radius of ourgeo-centric LMs.We can do even better than this, however.
Busi-nesses are clustered geographically (in towns, shop-ping malls, etc.).
This means that the set of listingslocal to one business is likely to be very similar tothe set of listings local to a nearby business.
So wedo not need to build a separate LM for each businesslisting; instead, we can pre-determine the number ofbusinesses we want to be different from one LM toanother.
Then we can ?quantize?
the business geo-3The area of the USA with the highest business density isNew York, NY, where about 270000 businesses share about43000 geo-coordinates.Figure 4: Geo-centric area near Vaughn, Montanacoordinates so that those that have fewer than thatnumber of businesses different between their searchradii end up sharing a single LM.Our algorithm for constructing geo-centric LMsstarts with LSAs.
It proceeds in two stages: first, thebusiness centers for the LMs are found.
Second, asearch radius is computed for each LM center; andthird, the data for the LM is extracted.The LM center finding algorithm uses two param-eters: r1 (radius within an LSA; should be a littlesmaller than average LSA radius) and Nq (numberof businesses that should be different between twodifferent geo-centric LMs).
For each LSA:1.
Find mean latitude and longitude for the LSA:Compute mean and standard deviation for lati-tude (?lb, ?lb) and longitude (?gb, ?gb) over allbusinesses in the LSA.2.
Exclude national businesses which are listed inthe LSA with their out-of-LSA address and geo-coordinates: Compute mean and standard de-viation of latitude and longitude, (?l, ?l) and(?g, ?g) respectively, using all geo-coordinates(l, g) where: (l, g) is within a r1-mile radius of(?lb, ?gb); l is within ?lb of ?lb; and g is within?gb of ?gb.3.
Compute business density in the most business-dense region in the LSA: find a minimumand maximum longitude (gm, gM ) and lati-tude (lm, lM ) for all businesses that are within(?12?g) and (?12?l) of ?g and ?l respectively.Business density per square mile (d2) is equalto the number of businesses in the rectangle de-fined by the low-left (gm, lm) and upper-right(gM , lM ) corner.
Business density per mile isd1 =?d2.3924.
Compute geo-location quantization accuracy:Choose a desired number of business listingsNq that will fall to the same geo-coordinateswhen the quantization is applied.
This corre-sponds roughly to the minimum desired num-ber of different businesses in two adjacentgeo-centric LMs.
Quantization accuracy, inmiles, ?qm, then follows from the business den-sity d1: ?qm = Nq/d1.
Quantization ac-curacy for the longitude ?g satisfies equationdistance((?g, ?l), (?g+?g, ?l)) = ?qm.
?l sat-isfies a similar equation.5.
Quantize geo-coordinates for each business inthe LSA: Compute quantized geo-coordinates(lq, gq) for each business in the LSA.
gq =int(g/?g)?
?g; lq = int(l/?l)??l.
Each unique(lq, gq) is a LM center.The LM radius finding algorithm also uses twoparameters: r2 (maximum search radius for an LM);and Np (minimum number of businesses within ageo-centric language model, should be smaller thanaverage number of businesses per LSA).
For eachLM center:1.
Count the number of businesses at 1-mile ra-dius increments of the LM center2.
Choose the smallest radius containing at leastNp listings (or the r2 radius if there is nosmaller radius containing at least Np listings)3.
Extract data for all listings within the radius.Build LM from this data.The number of geo-centric LMs can be arbitrar-ily small, depending on the parameter values.
Webelieve that any number between 10K and 100Kachieves good accuracy while maintaining tractabil-ity for LM building and selection.
In the experi-ments reported here we used r1 = 3.5, Nq = 50,r2 = 3 and Np = 1000, giving about 15000 LMsfor the whole USA.To summarize: we have described an algorithmfor building geo-centric language models for voice-driven business search that: gives a local languagemodel for any user anywhere in the country; usesbusiness density determine ?local?
for any locationin the country; can be pre-compiled; and can betuned (by modifying the parameters) to maximizeperformance for a particular application5 ExperimentsIn this section we report an evaluation of geo-centriclanguage models on spoken business listing queriesfrom an existing directory assistance application.We compare the recognition accuracy and recogni-tion speed for geo-centric LMs to those of local areaLMs, of a national LM, and of combined LMs.5.1 DataOur test data comes from an existing two-exchangedirectory assistance application.
It comprises 60,000voice queries, each consisting of a city and statein the first exchange, followed by a business listingname in the second exchange.We wanted to test using queries for which weknow there is a matching listing in the city/state pro-vided by the caller.
So we used only the 15000queries for which there was a match in our nation-wide business listing database4.
We categorizedeach query as nationwide or local by looking upthe listing name in our database.
We considered anylisting name that occurred five or more times to benationwide; the remaining listings were consideredto be local.
This method fails to distinguish betweennational chains and different companies that happento have the same name.
(However, from a recog-nition point of view any listing name that occurs inmultiple locations across the country is in fact na-tionwide, regardless of whether the businesses towhich it refers are separate businesses.)
It is alsoquite strict because we used string equality ratherthan looser name matching heuristics.
Example na-tional queries include Wal-mart and Domino?s Pizza.Example local queries include Sauz Taco (Glendale,CA); Dempsey?s Restaurant (Adrian, MI); and Con-cord Farmers Club (Saint Louis, MO).
Some queriescontain street names, e.g.
Conoco on South Divi-sion; uh Wal-Mart on five thirty five; and Chuy?sMesquite Broiler off of Rosedale.For each query in our data, we say that its localarea LM is the local area LM that comes from its4A query matched an entry in our database if there was abusiness listing in our database starting with the listing nameportion of the query, in the city/state from the location portionof the query.393city and state, and that contains its listing name.
Itsgeo-centric LM is defined similarly.5.2 Language Model ConstructionWe constructed two baseline LMs.
The first is a Na-tional LM.
To take advantage of the non-uniformdistribution of queries to listings (see Section 2), wealso build a Top 2000 LM containing only informa-tion about the top 2000 most frequently requestedlisting names nationwide5 .
We expected this LM toperform poorly on its own but potentially quite wellin combination with local LMs.For national, top 2000, local area and geo-centric LMs, we build trigram Katz backoff lan-guage models using AT&T?s Watson language mod-eling toolkit (Riccardi et al, 1996).
The modelsare built using the listing names and categories inour nationwide listing database.
Listing names areconverted to sentences containing the listing name,street address, neighborhood and city/state.We predict that location-specific LMs willachieve high accuracy on local listings but will notbe very robust to national listings.
So we also exper-iment with combination LMs: local area combinedwith top 2000; geo-centric combined with top 2000;local area combined with national; and geo-centriccombined with national.
We use two combinationstategies: count merging and LM union.5.2.1 Count MergingThe count merging approach can be viewed as aninstance of maximum a posteriori (MAP) adapta-tion.
Let hw be a n-gram ending in word w and witha certain context h, and let cL(hw) and CT (hw)be its counts in the geo-centric/local area corpus Land top 2000 corpus T respectively.
Then p(w|h) iscomputed as:p(w|h) = ?LcL(hw) + (1?
?L)cT (hw)?LcL(h) + (1?
?L)cT (h) (1)where ?L is a constant that controls the contributionof each corpus to the combined model.
We appliedthis combination strategy to local area/geo-centricand top 2000 only, not to local area/geo-centric andnationwide.5We computed listing frequencies from query logs and usedlistings from the left-hand side of the frequency distributioncurve before it flattens out; there were about 2000 of these.5.2.2 LM UnionThe LM union approach uses a union of languagemodels at runtime.
Let W = w0w1 .
.
.
w|W | be asentence, pL(W ) be the probability ofW in the geo-centric/local area corpus L, and pT (W ) be the prob-ability ofW in the top 2000/national corpus T .
Thenp(W ) is computed as:p(W ) = max(?LpL(W ), (1?
?L)pT (W )) (2)?L is a constant that controls the contribution of eachcorpus to the combined model.
We applied this com-bination strategy to local area/geo-centric and top2000, and to local area/geo-centric and nationwide.Given the small size of our test set relative to thelarge number of local LMs it is unfeasible to train?L on held-out data.
Instead, we selected a valuefor ?L such that the adjusted frequency of the topbusiness in the top 2000 corpus becomes similar tothe frequency of the top business in the local LM.We anticipate that if we did have data for training ?Lmore weight would be given to the local area/geo-centric LM.5.3 Experimental MethodIn our experiments we use AT&T?s Watson speechrecognizer with a general-purpose acoustic modeltrained on telephone speech produced by AmericanEnglish speakers (Goffin et al, 2005).
We ran alltests on a research server using standard settings forour speech recognizer for large vocabulary speechrecognition.
For each LM we report recognition ac-curacy (string accuracy and word accuracy) overall,on nationwide listings only, on local listings only,and on queries that contain street names only.
Wealso report recognition time (as a fraction of realtime speed).5.4 ResultsResults are given in Table 1.
Comparing the base-line (National LM) to our geo-centric LMs, we seethat we achieve a 16.8% absolute increase in overallsentence accuracy with a 3-fold speedup.
Most ofthe improvement in sentence accuracy is due to bet-ter performance on local queries; however, we alsoachieve a 2.9% absolute increase in sentence accu-racy on nationwide queries.394LM Recognition accuracy: String/Word [%] Real time speedOverall Nationwide Local Queries withqueries queries street nameNationwide language modelsNational 51.3/58.0 59.9/60.8 40.3/54.1 17.9/47.3 1.05Top 2000 23.2/31.6 40.6/43.3 9.5/25.8 1.3/18.3 0.44Local language modelsLocal area 63.7/69.7 60.8/63.2 69.5/77.2 22.4/53.4 0.42Geo-centric 68.1/73.0 62.8/65.0 75.0/81.7 15.1/49.7 0.36Combined language models, LM unionLocal area, national 58.9/64.5 61.4/62.3 57.9/67.1 21.8/50.6 0.84Geo-centric, national 64.7/69.1 63.6/64.5 67.2/74.5 23.2/52.1 0.78Local area, top 2000 60.0/67.0 62.1/65.8 61.8/71.3 20.6/50.3 0.45Geo-centric, top 2000 64.7/70.7 63.4/66.7 68.8/76.5 14.7/48.2 0.42Combined language models, count mergingLocal area, top 2000 66.7/72.2 69.2/71.5 67.8/75.7 22.5/54.0 0.50Geo-centric, top 2000 67.7/72.6 68.3/70.5 70.4/77.7 13.2/46.9 0.44Table 1: Results on mobile 411 data (total listings 14235; national listings 4679; local listings 2495; listings with streetaddresses 1163)Now we look at the performance of different ap-proaches to nationwide and local language model-ing.
First we compare the two nationwide LMs.
Asexpected, we see that the overall sentence accuracyfor the National LM is more than twice as high asthat of the Top 2000 LM, but the recognition time ismore than twice as slow.
Next we compare the twolocal language modeling approaches.
We see thatgeo-centric LMs achieve a 4.4% absolute increasein overall sentence accuracy compared to local areaLMs and a 5.5% increase in sentence accuracy onlocal listings, while using less processing time.Next we look at combination language models.When we combine local and nationwide LMs us-ing LM union, we get small increases in sentenceaccuracy for nationwide queries compared to localLMs alone.
However, sentence accuracy for locallistings decreases.
Also, these models use more pro-cessing time than the local LMs.
When we com-bine local and national LMs using count merging,we get larger increases in sentence accuracy for na-tionwide queries over local LMs alone, and smallerdecreases for local queries, compared to using LMunion.
LMs trained using count merging use moreprocessing time than those trained using LM union,but still less than the National LM.We conclude that: geo-centric language model-ing leads to increased recognition accuracy and im-provements in recognition time, compared to us-ing a national language model; geo-centric languagemodeling leads to increased recognition accuracyand improvements in recognition time, compared tousing local area language models; and geo-centriclanguage models can be combined with a ?most fre-quently asked-for?
nationwide language model toget increased recognition accuracy on nationwidequeries, at the cost of a small increase in recognitiontime and a slight decrease in recognition accuracyfor local listings.Further analysis of our results showed anotherinteresting phenomenon.
While geo-centric LMsachieve higher recognition accuracy than the Na-tional LM and local area LMs on nationwide andlocal queries, recognition accuracy on queries thatcontain a street name decreases.
The likely reasonis that small local LMs do not have rich street namecoverage and people often do not refer to a street ad-dress precisely.
A person might use a route numberinstead of a street name; if a single road has dif-ferent names at different points they might use thewrong name; or they might use a variation on theactual name.
For example, the query ?Conoco onSouth Divison?
is correctly recognized by our na-tional LM but not with a geo-centric LM.
The clos-est matching listing in our database for that loca-tion is ?Conoco Convenience Store on South Boule-vard?.
We note that we did not make any attemptto generalize over the street names in our LMs, sim-395ply pulling one street name for each listing from thedatabase.
Slightly more robust handling of streetnames may cause this phenomenon to disappear.6 Conclusions and Future WorkSmart phones are able to give system developersincreasingly detailed information about their users.This information can and should be exploited to giveimproved robustness and performance in customerservices.
In this paper, we explored the use of lo-cation information (from GPS or cell tower triangu-lation) to improve ASR accuracy in LBVS.
We pre-sented an algorithm for geo-centric language modelgeneration that: adapts to the local business density;enables good local listing coverage; and requiresonly a limited number of language models.
We com-pared the performance of our geo-centric languagemodeling to an alternative ?local?
language model-ing approach and to a nationwide language model-ing approach, and showed that we achieve signifi-cant improvements in recognition accuracy (a 4.4%absolute increase in sentence accuracy compared tolocal area language modeling, and a 16.8% absoluteincrease compared to the use of a national languagemodel) with significant speedup.We are currently testing our geo-centric languagemodels in a LBVS prototype.
In future work, wewill optimize the parameters in our algorithm forgeo-centric LM computation and merging.
We alsoplan to explore the impact of integrating languagemodeling with search, and to examine the impactof these different language modeling approaches onperformance of a trainable dialog manager that takesn-best output from the speech recognizer.ReferencesA.
Acero, N. Bernstein, R. Chambers, Y. C. Ju, X. Li,J.
Odell, P. Nguyen, O. Scholz, and G. Zweig.
2008.Live search for mobile: web services by voice on thecellphone.
In Proceedings of ICASSP, pages 5256?5259.M.
Bacchiani, F. Beaufays, J. Schalkwyk, M. Schuster,and B. Strope.
2008.
Deploying GOOG-411: Earlylessons in data, measurement, and testing.
In Proceed-ings of ICASSP, pages 5260?5263.B.
Buntschuh, C. Kamm, G. Di Fabbrizio, A. Abella,M.
Mohri, S. Narayanan, I. Zeljkovic, R. Sharp,J.
Wright, S. Marcus, J. Shaffer, R. Duncan, andJ.
Wilpon.
1998.
VPQ: a spoken language interfaceto large scale directory information.
In Proceedings ofICSLP.S.
Chang, S. Boyce, K. Hayati, I. Alphonso, andB.
Buntschuh.
2008.
Modalities and demographicsin voice search: Learnings from three case studies.
InProceedings of ICASSP, pages 5252?5255.R.
Collingham, K. Johnson, D. Nettleton, G. Dempster,and R. Garigliano.
1997.
The Durham telephone en-quiry system.
International Journal of Speech Tech-nology, 2(2):113?119.K.
Georgila, K. Sgarbas, A. Tsopanoglou, N. Fakotakis,and G. Kokkinakis.
2003.
A speech-based human-computer interaction system for automating directoryassistance services.
International Journal of SpeechTechnology, 6:145?159.V.
Goffin, C. Allauzen, E. Bocchieri, D. Hakkani-Tur,A.
Ljolje, S. Parthasarathy, M. Rahim, G. Riccardi,and M. Saraclar.
2005.
The AT&T Watson speechrecognizer.
In Proceedings ICASSP.V.
Gupta, S. Robillard, and C. Pelletier.
1998.
Automa-tion of locality recognition in ADAS plus.
In Proceed-ings of IVITA, pages 1?4.C.
Kamm, C. Shamieh, and S. Singhal.
1995.
Speechrecognition issues for directory assistance applica-tions.
Speech Communication, 17(3?4):303?311.X.
Li, Y. C. Ju, G. Zweig, and A. Acero.
2008.
Languagemodeling for voice search: a machine translation ap-proach.
In Proceedings of ICASSP, pages 4913?4916.P.
Natarajan, R. Prasad, R. Schwartz, and J. Makhoul.2002.
A scalable architecture for directory assistanceautomation.
In Proceedings of ICASSP, pages 21?24.T.
Paek, B. Thiesson, Y. C. Ju, and B. Lee.
2008.
SearchVox: Leveraging multimodal refinement and partialknowledge for mobile voice search.
In Proceedingsof the 21st annual ACM symposium on User interfacesoftware and technology, pages 141?150.G.
Riccardi, R. Pieraccini, and E. Bocchieri.
1996.Stochastic automata for language modeling.
Com-puter Speech and Language, 10(4):265?293.O.
Scharenborg, J. Sturm, and L. Boves.
2001.
Businesslistings in automatic directory assistance.
In Proceed-ings of Eurospeech, pages 2381?2384.F.
Seide and A. Kellner.
1997.
Towards an automateddirectory information system.
In Proceedings of Eu-rospeech, pages 1327?1330.Y.
Y. Wang, D. Yu, Y. C. Ju, G. Zweig, and A. Acero.2007.
Confidence measures for voice search applica-tions.
In Proceedings of INTERSPEECH.D.
Yu, Y. C. Ju, Y. Y. Wang, G. Zweig, and A. Acero.2007.
Automated directory assistance system ?
fromtheory to practice.
In Proceedings of INTERSPEECH,pages 2709?2712.396
