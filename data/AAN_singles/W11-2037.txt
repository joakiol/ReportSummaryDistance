Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 319?324,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsError Return PlotsRon ArtsteinInstitute for Creative Technologies, University of Southern California12015 Waterfront Drive, Playa Vista, CA 90094-2536, USA<lastname>@ict.usc.eduAbstractError-return plots show the rate of error(misunderstanding) against the rate of non-return (non-understanding) for Natural Lan-guage Processing systems.
They are a use-ful visual tool for judging system performancewhen other measures such as recall/precisionand detection-error tradeoff are less informa-tive, specifically when a system is judged onthe correctness of its responses, but may electto not return a response.1 IntroductionMany Natural Language Processing systems makea distinction between misunderstanding, where thesystem interprets an input incorrectly, and non-understanding, where the system is aware that it isnot able to interpret an input (Bohus and Rudnicky,2005).
This distinction is common in dialogue sys-tems, where it pertains to Natural Language Under-standing components which pass their output to adialogue manager: a dialogue manager will act onthe contents of misunderstood input, but if it knowsthat the input is not understood then it can engage ina variety of recovery techniques, such as asking forclarification, moving on, or changing the topic.
Forthis reason non-understanding is usually preferred tomisunderstanding.
While common to dialogue sys-tems, the concept of non-understanding is useful forother tasks as well, whenever a system can bene-fit from the knowledge that its best interpretation islikely to be incorrect (see below for an example inquestion answering).Detecting non-understanding is a tradeoff: a sys-tem that is prone to non-understanding will in-evitably miss some inputs that it would have under-stood correctly under a forced interpretation.
Thisis similar but not identical to the familiar trade-offs between recall and precision (van Rijsbergen,1979) and between detection and error (Martin et al,1997).
Recall and precision are measures taken frominformation retrieval, where there are typically mul-tiple documents relevant to a query, and ideal per-formance is defined as retrieving all and only therelevant documents: recall measures the ?all?
partwhile precision measures the ?only?
part, and tun-ing a system to increase one measure typically im-plies decreasing its counterpart.
Detection and er-ror apply to forced choice tasks: each input must beclassified as either positive or negative, and decreas-ing false positives typically implies increasing falsenegatives and vice versa.
The tradeoff between mis-understanding and non-understanding is similar torecall-precision in that a response need not be givento each input, and is similar to detection-error in thatwhen a response is given, we only care about its cor-rectness and not about its exhaustiveness.There is presently no accepted measure forthe tradeoff between misunderstanding and non-understanding.
A recent example illustrating theconfusion, and need for a standard measure, comesfrom the QALD-1 Open Challenge (Question An-swering over Linked Data).1 The task is definedas giving a complete and correct answer to a nat-ural language question, but systems are allowed tonot return an answer.
The evaluation metric usesrecall and precision, but they are defined in a non-standard way.
Precision is defined as the number1http://www.sc.cit-ec.uni-bielefeld.de/sites/www.sc.cit-ec.uni-bielefeld.de/files/sharedtask.pdf (dated 2011-03-28)319of correctly answered questions divided by the to-tal number of answered questions; given that eachquestion receives at most one answer, this is equiv-alent to the standard definition of correct answersdivided by the total number of answers provided bythe system ?
it penalizes misunderstanding and givescredit to non-understanding.
Recall is also definedin a non-standard way.number of correctly answered questionsnumber of questionsThis would normally be considered the definitionof accuracy, and it penalizes misunderstanding andnon-understanding equally; the standard definitionof recall is the number of correct answers divided bythe number of available correct answers, and it doesnot normally penalize incorrect answers.
The reasonfor the confusion between recall and accuracy is thatin a task where each question has a unique correctanswer, failure to provide a correct answer to a ques-tion implies that an available answer has not beenretrieved.
What the QALD-1 evaluation does, ineffect, is penalize non-understanding through accu-racy, and penalize misunderstanding more, throughboth accuracy and precision.To properly evaluate the tradeoff between mis-understanding and non-understanding we need tolook at each type of error separately.
If each in-put receives a response, then accuracy is the com-plement of error; if some responses are not re-turned, then accuracy is the complement of the sumof errors (misunderstandings) and non-returns (non-understandings).
The relative severity of misunder-standing and non-understanding will vary based onthe application: a question-answering system thatis required to provide accurate information mighthave a low tolerance for misunderstanding, while astory-driven dialogue system might have a low tol-erance for asking clarification questions as a resultof non-understanding.
The relation between misun-derstanding and non-understanding is not fixed ?
asystem with lower error rates under a forced inter-pretation may turn out to have higher error rates thana competitor after allowing for non-understanding.It is therefore useful to look at the entire range ofreturn rates when evaluating systems.
The remain-der of this paper introduces the error-return plot asa graphical representation for comparing error ratesacross different return rates, and presents examplesfor its use from recent experiments.2 Characteristics of the tradeoffA Natural Language Processing component that iscapable of indicating non-understanding consists oftwo distinct processes: figuring out the best (or mostlikely) response to an input, and deciding whetherthe best response is likely to be appropriate.
Thesetwo processes may be implemented as distinct soft-ware components, as in the system used for theexperiments in section 4, NPCEditor (Leuski andTraum, 2010) ?
a classification-based system forNatural Language Understanding that chooses thebest interpretation from a fixed set.
NPCEditorfirst calculates the appropriateness of each avail-able interpretation, and then compares the score ofthe best interpretation to a predetermined threshold;if the best interpretation falls below the threshold,NPCEditor indicates non-understanding.
Other im-plementations are, of course, possible ?
for example,Patel et al (2006) describe an architecture where thesystem first decides if it can understand the input,and then tries to determine the interpretation onlyif the answer is positive.
The two processes mayalso be linked more intimately together, but in orderto determine the tradeoff between misunderstand-ing and non-understanding, there must be some wayto isolate the decision of whether or not the inputhas been understood.
By varying the sensitivity ofthis decision, we can compare the rates of misunder-standing across different rates of non-understanding.Decomposing Natural Language Understand-ing into two distinct processes helps illustratethe inapplicability of the popular measures ofROC curves (relative operating characteristic,Swets, 1973) and DET curves (detection error trade-off, Martin et al, 1997).
These measures only lookat the decision of whether an interpretation is goodenough, while abstracting away the decision aboutthe actual interpretation.
ROC and DET curves weredeveloped for detection and verification tasks, whereperformance is determined by the rate of errors ?misses and false alarms ?
irrespective of the com-position of the input.
They plot the false alarm rateagainst the hit rate (ROC) or miss rate (DET) ?
thatis, the returned errors as a proportion of all errors320against the returned (ROC) or missed (DET) correctresponses as a proportion of all correct responses.Consequently, ROC and DET curves say nothingabout the actual error rate.
A system with an er-ror rate of 10%, where errors are uniformly spreadamong correct responses when ranked by the sys-tem?s confidence, will have identical ROC and DETcurves to a system with an error rate of 40%, 50% or90% with the errors spread uniformly.For investigating the tradeoff between misunder-standing and non-understanding, we want to looknot only at the system?s decision about whether ornot to return an interpretation, but also at the correct-ness of the chosen interpretation.
We therefore needa plot that reflects the actual error rate as a functionof the return rate.3 DefinitionAn error-return plot is a graphical representation ofthe tradeoff between errors (misunderstandings) andfailures to return a response (non-understandings).It applies to systems that react to each input in oneof three possible ways ?
a correct response, an in-correct response, or a failure to respond to the input.The error rate and non-return rate are defined as fol-lows.Error rate =incorrect responsesnumber of inputsNon-return rate =failures to respondnumber of inputsIn order to plot the entire range of the tradeoff, thesystem is set to make a forced-choice response toeach input.
The responses are then ranked accordingto the system?s confidence (or whatever other mea-sure is used to decide when to issue a non-return),and at each possible cutoff, the non-return rate isplotted on the horizontal axis against the error rateon the vertical axis.
As the number of non-returnsgrows, the number of errors can only go down, sothe plot is monotonically decreasing; at the extremeright, where no responses are returned, error ratesare necessarily zero, while at the extreme left, theerror rate is equivalent to accuracy under a forcedchoice.
Lower curves indicate better performance.Figure 1: Comparing tokenizers, SGT Star data(Wang et al, 2011, black = baseline)4 ExamplesAn example error-return plot is shown in Figure 1.The plot is taken from Wang et al (2011), an experi-ment which tested the effect of using phonetic infor-mation in a Natural Language Understanding com-ponent in order to recover from speech recognitionerrors.
The base system is NPCEditor (Leuski andTraum, 2010), trained for SGT Star, a virtual charac-ter who provides information about the U.S. Army topotential recruits (Artstein et al, 2009).
For each in-put utterance, NPCEditor selects one output out of afixed set, based on a learned mapping between inputand output training examples; it also has the capabil-ity of not returning a response if the classifier?s con-fidence in the appropriateness of the best choice fallsbelow a certain threshold.
The specific experimentin Figure 1 tested alternative methods to tokenize theinput: the base tokenizer is represented by the thickblack curve, and uses words as tokens; alternativetokenizers are shown in thinner lines or in shades ofgray, and they use tokens with various mixtures ofphonetic and word information (phone unigrams, bi-grams etc.).
The test data consisted of utterances forwhich the correct interpretation is known, but whichNPCEditor would occasionally fail to classify due tospeech recognition errors.Figure 1 shows several properties at a glance.
Thebase tokenizer has a fairly high error rate (over 30%)321Figure 2: Comparing tokenizers, Twins data(Wang et al, 2011, black = baseline)under forced choice, but the error rate decreasesrapidly when non-understanding is allowed (on theleft-hand side of the plot the slope is close to ?1,which is the steepest possible decline).
When tol-erance for non-understanding is low, all the alter-native tokenizers produce lower error rates than thebaseline; however, increasing the non-understandingdoes not affect all tokenizers equally, and the er-ror rate of the baseline tokenizer improves morerapidly than others, so that at 30% non-return rate itis better than most of the alternative tokenizers.
Fi-nally, one alternative tokenizer ?
the thin black line ?shows best or almost-best performance at all returnrates, supporting the hypothesis of the original ex-periment, that adding phonetic information to a Nat-ural Language Understanding component can helpin recovery from speech recognition errors.Figure 2 is from the same experiment but usinga different data set ?
the one developed for the thetwins Ada and Grace, two virtual guides at the Mu-seum of Science in Boston who answer questionsabout their neighboring exhibits and about sciencein general (Swartout et al, 2010).
The overall errorrate is much lower than in Figure 1.
Otherwise, thepattern is similar, though we see that the thin gray to-kenizer has shifted from a close second-best to beingthe worst performer.
Once again, the thin black tok-enizer beats all the others across most return rates.Figure 3: Augmented classifiers (black = baseline)Figure 3 shows a different experiment, also usingNPCEditor.
This experiment tested the effect of tak-ing an existing virtual character ?
the twins Ada andGrace ?
and expanding the character?s understand-ing by adding training input-output pairs extractedautomatically from text (the method for extractingtraining data is described in Chen et al, 2011; thepresent experiment is currently under review forpublication).
The baseline classifier is the thickblack line, trained on the Twins?
original question-answer links; the alternative classifiers add automat-ically extracted questions-answer training links fromsuccessive orthogonal domains.
All classifiers wereevaluated using the same test set of questions fromthe original domain, in order to test how the additionof orthogonal training data affects performance oninputs from the original domain.
The plot shows thatthe effect is quite noticeable: the original classifierhas a 10% absolute error rate, which drops to virtu-ally zero at a non-return rate of 20% and above; theaugmented classifiers display a higher initial errorrate, and moreover this higher error rate is not easilymitigated by accepting higher non-return rates.
Theaugmented classifiers have the advantage of beingable to understand inputs from the added domains,but the cost is some confusion on the original do-main, both in terms of understanding the input, andin the ability to identify non-understanding.3225 DiscussionThe error-return plot is a graphical representationfor looking at the tradeoff between misunderstand-ing and non-understanding.
Evaluating systems ca-pable of indicating non-understanding is somewhattricky, and error-return plots can show informationthat is useful when comparing such systems.
Ifthe curve of one system completely dominates theother, then we can say with confidence that the firstsystem has better performance.
If the curves in-tersect, then we need to compare the parts of thecurve where we expect actual system performanceto fall, and this will vary by application.
The sys-tems described above all use the same strategy fordealing with non-understanding: they issue an ?off-topic?
response which asks for clarification, stalls,or changes the conversation topic.
The systems areintended for fairly short question-answer dialogues,for which an off-topic response rate of about 1 in 5is usually acceptable, so the critical region is around20% non-understanding.
In applications where it ispossible to judge the relative severity of misunder-standing and non-understanding, a weighted aver-age could identify the optimal setting for the non-understanding threshold.
Such an average shouldgive non-understanding a lower weight than misun-derstanding, since treating them as equal would ob-viate the need for identifying non-understanding.A counterpart to the error rate would be the?missed chance rate?
?
the proportion of responsesthat would have been correct under forced choicebut were not returned.
Curves for missed chancesstart at zero (when all responses are returned) and in-crease with the non-return rate to a maximum of oneminus the absolute error rate.
The relation betweenthe missed chance curve and the error return plotis straightforward: wherever the error return curvegoes down, the missed chance curve stays level,and wherever the error return plot stays level, themissed chance curve goes up.
The curves intersectat the point where the number of misunderstandingsis identical to the number of non-understandings thatwould have been correct under forced choice; it isnot clear, however, whether this point has any prac-tical significance.Error-return plots suffer from the usual problemof evaluating single components in a dialogue sys-tem: since subsequent input is to a certain extentcontingent on system actions, it is conceivable thata system prone to misunderstanding would triggerdifferent user utterances than a system prone to non-understanding.
Determining the full consequencesof non-understanding would require running a fulldialogue system with real users under varying set-tings; error-return plots show the performance ofNatural Language Understanding under the assump-tion of fixed input.Overall, error return plots provide useful in-formation about the tradeoff between misunder-standing and non-understanding in cases where re-call/precision, ROC and DET curves are less infor-mative.
They have been used in several recent ex-periments, and hopefully may gain acceptance as astandard tool for system evaluation.AcknowledgmentsThe project or effort described here has been spon-sored by the U.S. Army Research, Development,and Engineering Command (RDECOM).
State-ments and opinions expressed do not necessarily re-flect the position or the policy of the United StatesGovernment, and no official endorsement should beinferred.ReferencesRon Artstein, Sudeep Gandhe, Jillian Gerten, AntonLeuski, and David Traum.
2009.
Semi-formal evalu-ation of conversational characters.
In Orna Grumberg,Michael Kaminski, Shmuel Katz, and Shuly Wintner,editors, Languages: From Formal to Natural.
EssaysDedicated to Nissim Francez on the Occasion of His65th Birthday, volume 5533 of LNCS, pages 22?35.Springer, May.Dan Bohus and Alexander I. Rudnicky.
2005.
Sorry,I didn?t catch that!
?
An investigation of non-under-standing errors and recovery strategies.
In Proceed-ings of the 6th SIGdial Workshop on Discourse andDialogue, pages 128?143, Lisbon, Portugal, Septem-ber.Grace Chen, Emma Tosch, Ron Artstein, Anton Leuski,and David Traum.
2011.
Evaluating conversa-tional characters created through question generation.In Proceedings of the Twenty-Fourth InternationalFlorida Artificial Intelligence Research Society Con-ference, pages 343?344, Palm Beach, Florida, May.323Anton Leuski and David Traum.
2010.
Practical lan-guage processing for virtual humans.
In Proceedingsof the Twenty-Second Innovative Applications of Arti-ficial Intelligence Conference (IAAI-10), pages 1740?1747, Atlanta, Georgia, July.Alvin Martin, George Doddington, Terri Kamm, MarkOrdowski, and Mark Przybocki.
1997.
The DETcurve in assessment of detection task performance.
InEurospeech 1997, pages 1895?1898, Rhodes, Greece,September.Ronakkumar Patel, Anton Leuski, and David Traum.2006.
Dealing with out of domain questions in vir-tual characters.
In Jonathan Gratch, Michael Young,Ruth Aylett, Daniel Ballin, and Patrick Olivier, editors,Intelligent Virtual Agents: 6th International Confer-ence, IVA 2006, Marina Del Rey, CA, USA, August 21?23, 2006 Proceedings, volume 4133 of Lecture Notesin Artificial Intelligence, pages 121?131, Heidelberg,August.
Springer.William Swartout, David Traum, Ron Artstein, DanNoren, et al 2010.
Ada and Grace: Toward realis-tic and engaging virtual museum guides.
In Jan All-beck, Norman Badler, Timothy Bickmore, and AllaPelachaud, Catherine Safonova, editors, IntelligentVirtual Agents, volume 6356 of LNAI, pages 286?300.Springer, September.John A. Swets.
1973.
The relative operating characteris-tic in psychology.
Science, 182(4116):990?1000.C.
J. van Rijsbergen.
1979.
Information Retrieval.
But-terworths, London, 2nd edition.William Yang Wang, Ron Artstein, Anton Leuski, andDavid Traum.
2011.
Improving spoken dialogue un-derstanding using phonetic mixture models.
In Pro-ceedings of the Twenty-Fourth International FloridaArtificial Intelligence Research Society Conference,pages 329?334, Palm Beach, Florida, May.324
