Proceedings of the NAACL HLT 2010 First Workshop on Computational Neurolinguistics, pages 36?44,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsDetecting Semantic Category inSimultaneous EEG/MEG RecordingsBrian MurphyCentre for Mind/Brain SciencesUniversity of Trentocorso Bettini 31,38068 Rovereto, Italybrian.murphy@unitn.itMassimo PoesioCentre for Mind/Brain SciencesUniversity of Trentocorso Bettini 31,38068 Rovereto, Italymassimo.poesio@unitn.itAbstractElectroencephalography (EEG) and magne-toencephalography (MEG) are closely relatedneuroimaging technologies that both measuresummed electrical activity of synchronoussources of neural activity.
However they dif-fer in the portions of the brain to which theyare more sensitive, in the frequency bands theycan detect, and to the amount of noise to whichthey are subject.
Since semantic representa-tions are thought to be widely distributed inthe brain, this preliminary study consideredif the broader coverage offered by simulta-neous EEG/MEG recordings would increasesensitivity to these cognitive states.
The re-sults showed that MEG data allowed stim-uli in two semantic categories (mammals andtools) to be distinguished more accurately, de-spite some experimental settings that were op-timised for EEG.
The addition of EEG datadid not prove informative, indicating that itmay be redundant relative to MEG, even whenusing dimensionality reduction techniques tocombat overfitting.1 IntroductionElectroencephalography (EEG) and magnetoen-cephalography (MEG) are similar methods forrecording activity in the brain.
Both detect signalsthat are produced by the mixing of neural sources,where each source represents macro-scale synchro-nisation between the firing of individual neurons.The sum of these activities induce voltages at thescalp that are recorded with EEG, and magneticfields that are detected with MEG.
But the signalsyielded by each technique are not identical for sev-eral reasons.
EEG signals are heavily attenuatedand filtered (both in time in space) by the passagethrough skull and tissue.
As a result, MEG signalsare less noisy, have finer spatial resolution, capturea wider range of frequencies, and so have the po-tential to be more informative.
Further, the signalfootprint of MEG and EEG signals on the brain isnot the same: EEG sensors are more sensitive tocurrents that are radial to the scalp and so predomi-nantly detect activity in the at the top of gyri and thebottom of sulci (the top and bottom of folds in thesurface of the brain); while MEG is more sensitiveto currents that are tangential to the scalp, and sodetects more activity in the side walls of sulci.
Thehigh spatial resolution of MEG means that it cannotsee as deeply into the brain as EEG can.
Finally,MEG sensors of different types (in this case mag-netometers and planar gradiometers) are sensitive tomagnetic fields of different orientations (see Figure1): planar gradiometers are most sensitive to currentgenerators of a particular orientation directly underthe sensor position; magnetometers record genera-tors that are tangential and peripheral to the sensorarea.The distribution of sensor coverage may be im-portant for the decoding of semantic categories inparticular.
Neuroimaging evidence suggests that se-mantic representations may be widely distributed inthe brain.
For example there are well-establisheddifferences in neural activity in the fusiform gyrusthat correspond to higher level categories (naturalvs non-natural kinds; people vs places - see e.g.Chao et al, 2002); there is also evidence that the36Figure 1: Schematic from above of selective sensitivityof three co-located MEG sensorsLeft and centre panels show perpendicular planar gradiometers;right panel shows magnetometer.
A co-located EEG electrodewould be most sensitive to currents perpendicular to the scalp.Image courtesy of Elekta AB.meaning of bodily actions is encoded in the motor-cortex (Pulvermu?ller, 2005); and concepts associ-ated with eating (e.g.
foodstuffs) seem to be repre-sented at least in part by activations in gustatory cor-tex (Mitchell et al, 2008; Just et al, 2010).
Hencea wide coverage of sensors that are sensitive to dif-ferent but overlapping portions of brain tissue mayprovide a fuller description of semantic memories.Given the fact that it has been possible to decodeconceptual categories and language semantics fromEEG signals (Murphy et al, 2008, 2009), the ques-tion is if MEG signals can be shown to be more in-formative.
Similar studies on lower-level tasks typi-cally used in brain-computer interfaces suggests thatit may be: Hill et al (2006) find that there is amodest increase in the decoding accuracy on imag-ined motor activity with MEG, relative to EEG, andWaldert et al (2008) have similar findings detectingthe direction of hand movements.A related question is whether the information sup-plied by EEG and MEG is complementary, and ifso how best it should be combined.
This dependscritically on the number of signals used: raising thenumber of input signals increases the informationsupplied to the machine learning methods, but in-teracts with their tendency to overfit, if the numberof descriptive dimensions (recorded signals) is of asimilar order of magnitude to the number of trainingcases (experimental trials in which a stimulus is pre-sented).
This is often the case with data from neu-roimaging experiments, as there are practical limita-tions on the number of data points that can be col-lected: individual stimuli must usually be separatedby several seconds so that neural signals can returnto baseline between each, and participants can usu-ally only be expected to perform a task at full at-tention for 60 minutes or so, in such experimentalenvironments.To investigate this question, we replicated an ex-isting EEG experiment (Murphy et al, 2010).
In thatexperiment participants had been presented with im-ages of animals and tools, while EEG activity wasrecorded at 64 standard 10-10 locations, and sin-gle trials (stimulus presentations) could be classi-fied as representing the category of animal or toolwith an average accuracy of 72% over all sevenparticipants.
The classification methods used werean adaptive time/frequency window optimisation(Dalponte et al, 2007), a supervised spatial com-ponent signal decomposition (Common Spatial Pat-terns, Koles et al, 1990) that yielded measures ofneural activity based on signal power, and a support-vector machine (Boser et al, 1992).The replication experiment reported here was car-ried out with two participants, and used the sametask and materials, while simultaneously recordingwith a 306-channel MEG system (204 gradiometers,102 magnetometers) and a high-density 124-channelEEG system.
This data was then analysed using thesame machine learning methods as previously, butvarying the number and type of input signals, andusing dimensionality reduction to address increaseddimensionality.2 Methods2.1 Experiment and MaterialsTwo male native speakers of Italian took part inthe study, aged 30 and 47.
Both were right-handedwith corrected or normal vision.
Participants in thisstudy receive compensation of 7 euros per hour.
Theexperiment is conducted under the approval of theethics committee at the University of Trento, andparticipants gave informed consent.The participants were asked to perform a silentnaming task on grey-scale images of 30 land-mammals and 30 work tools.
Each stimulus waspresented between four and six times, in randomisedorder.1 The participants sat in a relaxed upright posi-1Participant 1 saw 264 stimulus trials (144 mammal and 120tool trials); participant 2 saw 360 (180 in each class).37tion 1.5m from a projector screen in moderate light-ing conditions.
Images were presented on a mediumgrey background and fell within a 6 degree viewingangle.
The task duration was split into five blocksand the participants were given the choice to pausebetween each.
The cumulative task time did not ex-ceed 45 minutes.Each trial began with the presentation of a fixa-tion cross for 0.25s, followed by the stimulus image,a further fixation cross for 0.75s and a blank screenfor 1s.
Participants were instructed to silently namethe object represented in their native tongue (Ital-ian), using the first appropriate label that came tomind, and to press the keyboard space-bar with theleft-hand to indicate they had found an appropriateword.
If the participant could not think of a suitablelabel, they were asked not to make a response.
Theimage remained on the screen until the participantresponded, or until a time-out of three seconds wasreached.
The participants were asked to keep stillduring the task, and to avoid eye-movements and fa-cial muscle activity in particular, except during theblank period.The materials were chosen to represent well-defined semantic categories and to minimise non-semantic, associative confounds.
The set of 30 landmammals were chosen to be both non-domesticatedand non-threatening, to avoid emotional valencewhether positive (e.g.
pets) or negative (e.g.
preda-tors).
Thirty hardware and garden implements werechosen as genuine work tools.
Appropriate pho-tographs were sourced from the internet, and nor-malised visually: each image file measured 300 pix-els square; the image proper was converted to grey-scale, superimposed on a homogeneous light-greybackground and had maximal horizontal and verticaldimensions of 250 pixels; image contrast was nor-malised.
The concepts represented are listed below.Land Mammals ant-eater, armadillo, badger,beaver, bison, boar, camel, chamois, chim-panzee, deer, elephant, fox, giraffe, gorilla,hare, hedgehog, hippopotamus, ibex, kan-garoo, koala, llama, mole, monkey, mouse,otter, panda, rhinoceros, skunk, squirrel, zebra(Italian formichiere, armadillo, tasso, castoro,bisonte, cinghiale, cammello, camoscio, scim-panz, cervo, elefante, volpe, giraffa, gorilla,coniglio, riccio, ippopotamo, stambecco,canguro, koala, lama, talpa, scimmia, topo,lontra, panda, rinoceronte, puzzola, scoiattolo,zebra)Work Tools Allen key, axe, chainsaw, craft-knife,crowbar, file, garden fork, garden trowel, hack-saw, hammer, mallet, nail, paint brush, paintroller, penknife, pick-axe, plaster trowel, pliers,plunger, pneumatic drill, power-drill, rake, saw,scissors, scraper, screw, screwdriver, sickle,spanner, tape-measure (Italian brugola, ascia,motosega, taglierino, piede di porco, lima,forcone, paletta, seghetto, martello, mazza,chiodo, pennello, rullo, coltellino svizzero, pic-cone, cazzuola, pinza, stura lavandini, martellopneumatico, trapano, rastrello, sega, forbici,spatola, vite, cacciavite, falce, chiave inglese,metro)2.2 Neural RecordingsThe experiment was conducted at the LNiF imag-ing laboratories at the University of Trento, using a306-sensor Elekta Neuromag system (2 planar gra-diometers and 1 magnetometer at each of 102 sensorlocations).
A dense-coverage 124-electrode EEGcap was used also, using a right mastoid referenceand forehead ground.
Both sets of signals wererecorded simultaneously at 1000Hz in a magneti-cally shielded room.
At the start of the session therelative positions of the MEG and EEG sensors weredetermined using a Polyhemus 3-D digitisation sys-tem.Data preprocessing was conducted using theMNE, FieldTrip and EEGLAB packages.2 The datawas band-pass filtered at 1-50Hz to remove slowdrifts in the signal and high-frequency noise, andthen down-sampled to 125Hz.
Eye and muscle arte-facts were not removed, but these lie outside therange of frequencies that were considered in theanalysis described below.2Martinos Centre for Biomedical Imaging(http://www.nmr.mgh.harvard.edu/martinos/); Don-ders Institute for Brain, Cognition and Behaviour(http://www.ru.nl/neuroimaging/fieldtrip); and Schwartz Centerfor Computational Neuroscience (http://sccn.ucsd.edu/eeglab/)respectively.382.3 AnalysisThe analysis method first applies a time/frequencyfilter to select an information-rich band and inter-val for the distinction of interest; a supervised de-composition to extract components of whole-scalpsynchronous activity that are sensitive to this classdistinction (Common Spatial Patterns, or CSP ?
seeParra et al, 2005; Model and Zibulevsky, 2006;Philiastides et al, 2006 for examples of other ap-plications to cognitive neuroscience); and a gen-eral purpose machine learning algorithm (Support-Vector Machine or SVM) that uses the resultingmeasures of signal power to predict the semanticclass of each trial.
Individual trial epochs are arbi-trarily allocated to one of k interlaced partitions ofequal size in a k-fold training/evaluation procedure.The time/frequency filter applied here wasadopted from the earlier experiment, as it had beenfound to provide optimal separation between trialsof the two classes over the participants of that study.Using this common window (4-18Hz, 95-360ms af-ter image onset) allows direct comparison betweenthe informativity of each type of sensor, or combina-tion of sensor types.
However this may disadvantageMEG, since it is more sensitive to higher frequencyactivity (> 50Hz), which at least one study hasfound to vary systematically with semantic classes(Tanji et al, 2005).The decomposition method used, CSP (Koleset al, 1990), extracts spatial components of elec-trophysiological activity (linear combinations of rawsignals) that correspond to synchronous neural sub-assemblies.
It is a supervised technique that yieldssignals whose level of activity (measured as signalpower) is modulated by the binary class distinctionof interest ?
that is signals that show high powerwhen processing mammal concepts, and low powerwhen processing tool concepts, or vice-versa.
CSPidentifies C components (where C is the number ofinput channels) that are ranked by their sensitivityto the class-separation of interest, in terms of op-timal variance for the two populations of signals(i.e., high variance between classes and low vari-ance within classes).
In this case we selected thefirst and the last rows of this matrix (Ramoser et al,2000) as the components that are most representa-tive for the classes mammals and tools, respectively.This procedure can be interpreted as extracting theevent-related spectral activity (i.e.
the relative event-related synchronisation) of two synchronous neuralstructures which have been found to have an op-timally differential response to the semantic cate-gories of interest.The final categorisation step is based on aSupport-Vector Machine (SVM) classifier (Boseret al, 1992; Vapnik, 1998).
The input for eachtrial consisted of two measures of neural activityextracted from the category-sensitive signal compo-nents: the variance of the waveform, which is pro-portional to signal power.
The features were furthernormalised by taking the log, and scaling to a rangeof -1 to +1 across all trials.
The SVM implementa-tion used was LIBSVM (Chang and Lin, 2001), anddefault parameters were used (radial basis functionkernel, cost parameter of 1, and a gamma value ofthe inverse of the number of data-points).3 Test andtraining data were kept strictly separate at all stagesof analysis.In the results that follow here, these techniqueswere first applied as before to replicate the previ-ous experiment, but then also with an additionalstep of dimensionality reduction to address the over-fitting we expected given the dramatically largernumber of input channels (up to 430 if all EEGand MEG channels were used, compared to 64channels in the previous experiment).
The signalrecorded in any individual channel will be com-prised of a mix of genuine neural activity (bothrelevant and irrelevant to our classification task),systematic noise sources (e.g.
50Hz electrical linenoise, eye-movement artefacts, heart-beat artefacts),and additional random noise.
And as EEG and MEGchannels record activity from partially overlappingportions of brain tissue, there is considerable re-dundancy between neighbouring channels.
Princi-ple Components Analysis (PCA) is a dimensionalityreduction technique that addresses both these issues,grouping redundant activity into the first (strongest)3No optimisation of SVM parameters was attempted, as ex-tensive parameter testing in the earlier experiment did not yieldany improvements in classification performance.
We believethat this is because CSP is in itself a powerful data-mining tech-nique, that here typically yields two simple clusters of data cor-responding to each semantic category.
We expect a simple lin-ear classifier would have similar performance on this task.39components, and relegating random noise to the lastcomponents.
Where PCA was used, it was ap-plied directly before the CSP-based extraction ofcategory-specific sources.3 ResultsIn the previous EEG experiment, the classificationaccuracy averaged 72%, but varied substantiallyfrom one participant to the next, ranging from 56%to 80%.
First we wanted to establish how repre-sentative these two new simultaneous MEG/EEGsessions had been, by replicating the EEG-basedanalysis.
To do this, an arbitrary subset of the 60EEG channels were selected (taking roughly everysecond channel among the total of 124), the stan-dard time/frequency filter window was applied, andthe resulting data was classified using a 5-fold test-training procedure.4 The first participant?s data wastypical of the previous cohort, classifying with accu-racy of 70% (in this session, accuracy over 61% issignificant at p < 0.05, using a one-sided binomialtest, n = 264, p = 0.54), while the second partici-pant?s data only achieved 52% accuracy (accuracyover 56% significant at p< 0.05, n= 360, p= 0.5).To get a first impression of the relative informa-tivity of each signal type, the same procedure wasperformed with subsets of 60 MEG channels: mag-netometers alone yielded markedly higher results(78% and 61% for participants 1 and 2 respectively),while planar gradiometers alone gave marginallylower results (67% and 48% respectively).Next, to examine the effect of increasing theamount of input data, we performed these analysesusing all available channels of each type.
In one case(participant 1, magnetometers) there was a drop in5% points, and another (participant 2, magnetome-ters) an increase of 3% points, but generally this hadlittle effect on results, indicating that in most casesany increase in available information was offset byoverfitting.These results are summarised in the first twocolumns of in Tables 1 and 2.
The tables also show4In each test/training partition, the labelled training dataalone was used to derive two category specific scalp-maps.These scalp-maps were used to extract signal components andresulting signal power measures for all trials.
The data was thenpartitioned again along the same folds for SVM training andprediction.Table 1: Classification accuracy, participant 1Type (available signals) 60 ch.
all ch.
60 cp.EEG (124) 70% 69% 76%Magnetometers (102) 78% 73% 78%Gradiometers (204) 67% 66% 71%Mag.+Grad.
(306) 72% 63% 77%EEG+Mag.
(224) 68% 67% 77%EEG+Grad.
(328) 69% 54% 73%EEG+Mag.+Grad.
(430) 72% 55% 77%ch: raw channel input; cp: PCA component inputsignificance: 61% at p < 0.05; 65% at p < 0.001Table 2: Classification accuracy, participant 2Type (available signals) 60 ch.
all ch.
60 cp.EEG (124) 52% 50% 52%Magnetometers (102) 61% 64% 68%Gradiometers (204) 48% 51% 60%Mag.+Grad.
(306) 63% 50% 56%EEG+Mag.
(224) 56% 53% 58%EEG+Grad.
(328) 52% 53% 62%EEG+Mag.+Grad.
(430) 58% 51% 55%ch: raw channel input; cp: PCA component inputsignificance: 56% at p < 0.05; 59% at p < 0.001the results for all possible combinations of the threesignal types, and it is apparent that the effect of over-fitting is more pronounced for these larger signalsets.
And though the base level of classification ac-curacy is very different for these two participants,both show a similar pattern with respect to signaltype and dimensionality: magnetometers are mostinformative for these semantic distinctions, and allsignal types are vulnerable to overfitting effects.To combat overfitting, we repeated these analy-ses with dimensionality reduction.
Since PCA isan unsupervised technique, the components werederived and extracted in one step over the wholedata set.
The first (strongest) 60 components werethen taken as input to the same analysis procedureas before (CSP-derived signal power estimates fedto the SVM), to give a global description of wholescalp neural activity, presumably with reduced re-dundancy and noise.
As can be seen in the finalcolumns of Tables 1 and 2, this resulted in optimalclassification accuracy in almost all cases, both rel-ative to the full collections of signals, and the 6040channel subsets.A serious limitation of these results however is thearbitrary selection of signal subsets.
While much ofthe information recorded between signals is likelyredundant, it could be that the random inclusion orexclusion of one channel or component could dra-matically affect accuracy, if that signal was particu-larly informative, or particularly subject to spuriousnoise.
So to have a more comprehensive view, weconducted an exhaustive parameter search throughpossible subsets of each combination of signal type,increasing set size in steps of five, and calculatingaverage classification accuracy with a moving win-dow of nine points.
The results are illustrated in Fig-ures 2 (using the raw signals as input) and 3 (usingPCA components of each signal set), and show theaverage prediction performance across both experi-mental participants.Several things stand out when considering the dif-ference between the classification performance us-ing raw signals directly, and dimensionality reducedsets.
In the PCA case, the classification accuracylevels start higher, rise faster, and peak earlier inalmost all cases.
In absolute terms optimum per-formance is little changed for magnetometer andEEG signals alone (peaking just above 70% and60% respectively), while gradiometers seem to ben-efit somewhat (by about 3% points).
But the PCAlines are also smoother, reflecting more stability inclassification, and so more independence from par-ticular parameter settings.Common to both plots is that magnetometers arethe most informative type, followed consecutivelyby gradiometers and EEG channels.
In terms of mu-tual redundancy, the information encoded in EEGchannels seems to largely be a subset of that en-coded by gradiometers (gradiometer performance isnot improved by the addition of EEG channels).
Theinteraction of magnetometer data and these signaltypes is more complex ?
magnetometer performanceis reduced by the addition of either or both EEG andgradiometer channels.4 ConclusionThis paper reports only two sessions of simultane-ous MEG/EEG recording, and there were some cleardifferences in the results for each participant, so theconclusions must be considered tentative.
Neverthe-less they suggest that EEG data are to a large ex-tent redundant with respect to MEG signals.
MEGmagnetometers in particular can lead to substantiallyhigher classification accuracy, with smaller numbersof channels, than EEG alone.
In the case of the sec-ond participant, prediction with EEG signals did notapproach significance, while MEG signals allowedhighly significant (p 0.001) performance.
We be-lieve that this advantage is due to the lack of attenu-ation and higher spatial resolution inherent in MEG,allowing it to pick out individual neural sources withmore precision.Regardless of the signal types chosen, the highdimensionality of the data posed challenges.
Anyarbitrary subset of channels may leave informativeaspects of brain-activity undetected and this led tofluctuating results; but including large numbers ofchannels invariably leads to overfitting, and conse-quent falls in classification accuracy.
In light ofthis, a reduction in dimensions that kept most of theglobal signal intact (in this case a principle com-ponents analysis) proved very effective in prevent-ing overfitting, giving reliably superior performancewith lower numbers of channels.While MEG signals proved more informative,there was not always a dramatic difference in perfor-mance (peak performance in participant 1 was sim-ilar for MEG or EEG; for participant 2 there wasa ca.
15% point difference).
However this studyused a time interval and frequency band in the sig-nal that had been optimised for EEG, so it may bethat considering a wider range of frequencies, higherin the spectrum, could allow MEG to achieve bet-ter results.
Also, though steps were taken to avoidit, slight movements by the participants relative tothe MEG apparatus will have compromised the reli-ability of its signals (EEG does not suffer from thesame problem as electrodes are placed directly onthe scalp).
This could be addressed in future studieswith continuous head tracking and correction.Finally, several variations could be tried to im-prove the overall classification performance of thesystem.
The spatial decomposition used (CSP) isparticularly prone to overfitting (Parra et al, 2005),and could be replaced with less aggressive tech-niques like Linear Discriminant Analysis.
Princi-ple component analysis is a rather brittle technique41Figure 2: Classification accuracy taking subsets of raw signals from sensors of different types, 9-point smoothedFigure 3: Classification accuracy taking subsets of PCA components derived from raw signals from sensors of differenttypes, 9-point smoothed42which is heavily biased towards the few strongestsources in a system, and so independent componentanalysis (ICA) may be a more effective choice fordimensionality reduction (Makeig et al, 1996).
Anddata from the various sensor types could be com-bined in other ways, using an ensemble of classi-fiers, each based on different subsets of signals, orby taking more than one class-sensitive componentper category.AcknowledgementsWe are very grateful to Elena Betta, Gianpaolo De-marchi and Gianpiero Monittola at the LNiF labsfor assistance in MEG data collection.
The workdescribed here was funded by CIMeC, the Au-tonomous Province of Trento, and the FondazioneCassa Risparmio Trento e Rovereto.ReferencesBoser, B. E.; I. M. Guyon; and V. N. Vapnik (1992):A training algorithm for optimal margin classi-fiers.
In: 5th Annual ACM Workshop on COLT,ed.
D. Haussler.
ACM Press, Pittsburgh, pp.
144?152.Chang, Chih-Chung and Chih-Jen Lin (2001): LIB-SVM: a library for support vector machines.Chao, Linda L.; Jill Weisberg; and Alex Martin(2002): Experience-dependent modulation of cat-egory related cortical activity.
Cerebral Cortex,12:545?551.Dalponte, Michele; Francesca Bovolo; and LorenzoBruzzone (2007): Automatic selection of fre-quency and time intervals for classification ofEEG signals.
Electronics Letters, 43:1406?1408.Hill, N.J.; T.N.
Lal; M. Schroder; T. Hinterberger;G. Widman; C.E.
Elger; B. Scholkopf; and N. Bir-baumer (2006): Classifying event-related desyn-chronization in EEG, ECoG and MEG signals.Lecture Notes in Computer Science, 4174:404.Just, M.A.
; V.L.
Cherkassky; S. Aryal; and T.M.Mitchell (2010): A neurosemantic theory of con-crete noun representation based on the underlyingbrain codes.
PLoS ONE, 5.Koles, Zoltan J.; Michael S. Lazar; and Steven Z.Zhou (1990): Spatial patterns underlying popula-tion differences in the background EEG.
BrainTopography, 2(4):275?284.Makeig, Scott; Anthony J.
Bell; Tzyy-ping Jung;and Terrence J. Sejnowski (1996): IndependentComponent Analysis of ElectroencephalographicData.
In: Advances in Neural Information Pro-cessing Systems.
MIT Press, vol.
8, pp.
145?151.Mitchell, Tom M.; Svetlana V. Shinkareva; AndrewCarlson; Kai-Min Chang; Vicente L. Malave;Robert A. Mason; and Marcel Adam Just (2008):Predicting Human Brain Activity Associated withthe Meanings of Nouns.
Science, 320:1191?1195.Model, Dmitri and Michael Zibulevsky (2006):Learning Subject-Specific Spatial and TemporalFilters for Single-Trial EEG Classification.
Neu-roImage, 32(4):1631?1641.Murphy, Brian; Marco Baroni; and Massimo Poesio(2009): EEG responds to conceptual stimuli andcorpus semantics.
In: Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing.
The Association for ComputationalLinguistics, pp.
619?627.Murphy, Brian; Michele Dalponte; Massimo Poe-sio; and Lorenzo Bruzzone (2008): Distinguish-ing Concept Categories from Single-Trial Elec-trophysiological Activity.
In: Proceedings of theAnnual Meeting of the Cognitive Science Society.Murphy, Brian; Massimo Poesio; Francesca Bovolo;Michele Dalponte; Lorenzo Bruzzone; and HebaLakany (2010): EEG decoding of semantic cate-gory reveals distributed representations for singleconcepts.
Brain and Language, under review.Parra, Lucas C.; Clay D. Spence; Adam D. Ger-son; and Paul Sajda (2005): Recipes for the linearanalysis of EEG.
NeuroImage, 28:326?341.Philiastides, M.G.
; R. Ratcliff; and P. Sajda (2006):Neural representation of task difficulty and de-cision making during perceptual categorization:a timing diagram.
Journal of Neuroscience,26(35):8965.Pulvermu?ller, Friedemann (2005): Brain mecha-nisms linking language and action.
Nature Re-views Neuroscience, 6:576?582.Ramoser, H.; J. M. Gerking; and Gert Pfurtscheller(2000): Optimal spatial filtering of single43trial EEG during imagined hand movement.IEEE Transactions on Rehabilitation Engineer-ing, 8(4):441?446.Tanji, Kazuyo; Kyoko Suzuki; Arnaud Delorme;and Nobukazu Shamoto, Hiroshiand Nakasato(2005): High-Frequency gamma-Band Activityin the Basal Temporal Cortex during Picture-Naming and Lexical-Decision Tasks.
Journal ofNeuroscience, 25(13):3287?3293.Vapnik, V. N. (1998): Statistical Learning Theory.Wiley.Waldert, S.; H. Preissl; E. Demandt; C. Braun;N. Birbaumer; A. Aertsen; and C. Mehring(2008): Hand movement direction decoded fromMEG and EEG.
Journal of Neuroscience,28(4):1000.44
