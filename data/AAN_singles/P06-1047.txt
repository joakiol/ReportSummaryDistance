Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 369?376,Sydney, July 2006. c?2006 Association for Computational LinguisticsExtractive Summarization using Inter- and Intra- Event RelevanceWenjie Li, Mingli Wu and Qin LuDepartment of ComputingThe Hong Kong Polytechnic University{cswjli,csmlwu,csluqin}@comp.polyu.edu.hkWei Xu and Chunfa YuanDepartment of Computer Science andTechnology, Tsinghua University{vivian00,cfyuan}@mail.tsinghua.edu.cnAbstractEvent-based summarization attempts toselect and organize the sentences in asummary with respect to the events orthe sub-events that the sentences de-scribe.
Each event has its own internalstructure, and meanwhile often relates toother events semantically, temporally,spatially, causally or conditionally.
Inthis paper, we define an event as one ormore event terms along with the namedentities associated, and present a novelapproach to derive intra- and inter- eventrelevance using the information of inter-nal association, semantic relatedness,distributional similarity and named en-tity clustering.
We then apply PageRankranking algorithm to estimate the sig-nificance of an event for inclusion in asummary from the event relevance de-rived.
Experiments on the DUC 2001test data shows that the relevance of thenamed entities involved in eventsachieves better result when their rele-vance is derived from the event termsthey associate.
It also reveals that thetopic-specific relevance from documentsthemselves outperforms the semanticrelevance from a general purposeknowledge base like Word-Net.1.
IntroductionExtractive summarization selects sentenceswhich contain the most salient concepts indocuments.
Two important issues with it arehow the concepts are defined and what criteriashould be used to judge the salience of the con-cepts.
Existing work has typically been based ontechniques that extract key textual elements,such as keywords (also known as significantterms) as weighed by their tf*idf score, or con-cepts (such as events or entities) with linguisticand/or statistical analysis.
Then, sentences areselected according to either the important textualunits they contain or certain types of inter-sentence relations they hold.Event-based summarization which has e-merged recently attempts to select and organizesentences in a summary with respect to events orsub-events that the sentences describe.
With re-gard to the concept of events, people do nothave the same definition when introducing it indifferent domains.
While traditional linguisticswork on semantic theory of events and the se-mantic structures of verbs, studies ininformation retrieval (IR) within topic detectionand tracking framework look at events asnarrowly defined topics which can becategorized or clustered as a set of relateddocuments (TDT).
IR events are broader (or tosay complex) events in the sense that they mayinclude happenings and their causes,consequences or even more extended effects.
Inthe information extraction (IE) community,events are defined as the pre-specified and struc-tured templates that relate an action to itsparticipants, times, locations and other entitiesinvolved (MUC-7).
IE defines what people callatomic events.
Regardless of their distinct perspectives, peo-ple all agree that events are collections of activi-ties together with associated entities.
To applythe concept of events in the context of text sum-marization, we believe it is more appropriate toconsider events at the sentence level, rather thanat the document level.
To avoid the complexityof deep semantic and syntactic processing, wecomplement the advantages of statisticaltechniques from the IR community and struc-tured information provided by the IE community.369We propose to extract semi-structured eventswith shallow natural language processing (NLP)techniques and estimate their importance forinclusion in a summary with IR techniques.Though it is most likely that documents nar-rate more than one similar or related event, mostevent-based summarization techniques reportedso far explore the importance of the events inde-pendently.
Motivated by this observation, thispaper addresses the task of event-relevancebased summarization and explores what sorts ofrelevance make a contribution.
To this end, weinvestigate intra-event relevance, that is action-entity relevance, and inter-event relevance, thatis event-event relevance.
While intra-event rele-vance is measured with frequencies of the asso-ciated events and entities directly, inter-eventrelevance is derived indirectly from a generalWordNet similarity utility, distributional simi-larity in the documents to be summarized,named entity clustering and so on.
Pagerankranking algorithm is then applied to estimate theevent importance for inclusion in a summaryusing the aforesaid relevance.The remainder of this paper is organized asfollows.
Section 2 introduces related work.
Sec-tions 3 introduces our proposed event-basedsummarization approaches which make use ofintra- and inter- event relevance.
Section 4 pre-sents experiments and evaluates different ap-proaches.
Finally, Section 5 concludes the paper.2.
Related WorkEvent-based summarization has been investi-gated in recent research.
It was first presented in(Daniel, Radev and Allison, 2003), who treateda news topic in multi-document summarizationas a series of sub-events according to humanunderstanding of the topic.
They determined thedegree of sentence relevance to each sub-eventthrough human judgment and evaluated six ex-tractive approaches.
Their paper concluded thatrecognizing the sub-events that comprise a sin-gle news event is essential for producing bettersummaries.
However, it is difficult to automati-cally break a news topic into sub-events.Later, atomic events were defined as the rela-tionships between the important named entities(Filatova and Hatzivassiloglou, 2004), such asparticipants, locations and times (which arecalled relations) through the verbs or actionnouns labeling the events themselves (which arecalled connectors).
They evaluated sentencesbased on co-occurrence statistics of the namedentity relations and the event connectors in-volved.
The proposed approach claimed to out-perform conventional tf*idf approach.
Appar-ently, named entities are key elements in theirmodel.
However, the constraints defining eventsseemed quite stringent.The application of dependency parsing,anaphora and co-reference resolution in recog-nizing events were presented involving NLP andIE techniques more or less (Yoshioka and Hara-guchi, 2004), (Vanderwende, Banko and Mene-zes, 2004) and (Leskovec, Grobelnik and Fral-ing, 2004).
Rather than pre-specifying events,these efforts extracted (verb)-(dependent rela-tion)-(noun) triples as events and took the triplesto form a graph merged by relations.As a matter of fact, events in documents arerelated in some ways.
Judging whether the sen-tences are salient or not and organizing them ina coherent summary can take advantage fromevent relevance.
Unfortunately, this was ne-glected in most previous work.
Barzilay and La-pata (2005) exploited the use of the distribu-tional and referential information of discourseentities to improve summary coherence.
Whilethey captured text relatedness with entity transi-tion sequences, i.e.
entity-based summarization,we are particularly interested in relevance be-tween events in event-based summarization.Extractive summarization requires rankingsentences with respect to their importance.Successfully used in Web-link analysis andmore recently in text summarization, Google?sPageRank (Brin and Page, 1998) is one of themost popular ranking algorithms.
It is a kind ofgraph-based ranking algorithm deciding on theimportance of a node within a graph by takinginto account the global information recursivelycomputed from the entire graph, rather than re-lying on only the local node-specific infor-mation.
A graph can be constructed by adding anode for each sentence, phrase or word.
Edgesbetween nodes are established using inter-sentence similarity relations as a function ofcontent overlap or grammatically relations be-tween words or phrases.The application of PageRank in sentence ex-traction was first reported in (Erkan and Radev,2004).
The similarity between two sentencenodes according to their term vectors was usedto generate links and define link strength.
Thesame idea was followed and investigated exten-370sively (Mihalcea, 2005).
Yoshioka and Haragu-chi (2004) went one step further toward event-based summarization.
Two sentences werelinked if they shared similar events.
When testedon TSC-3, the approach favoured longer sum-maries.
In contrast, the importance of the verbsand nouns constructing events was evaluatedwith PageRank as individual nodes aligned bytheir dependence relations (Vanderwende, 2004;Leskovec, 2004).Although we agree that the fabric of eventconstitutions constructed by their syntactic rela-tions can help dig out the important events, wehave two comments.
First, not all verbs denoteevent happenings.
Second, semantic similarityor relatedness between action words should betaken into account.3.
Event-based Summarization3.1.
Event Definition and Event MapEvents can be broadly defined as ?Who didWhat to Whom When and Where?.
Both lin-guistic and empirical studies acknowledge thatevent arguments help characterize the effects ofa verb?s event structure even though verbs orother words denoting event determine the se-mantics of an event.
In this paper, we chooseverbs (such as ?elect?)
and action nouns (such as?supervision?)
as event terms that can character-ize or partially characterize actions or incidentoccurrences.
They roughly relate to ?did What?.One or more associated named entities are con-sidered as what are denoted by linguists as eventarguments.
Four types of named entities are cur-rently under the consideration.
These are <Per-son>, <Organization>, <Location> and <Date>.They convey the information of ?Who?,?Whom?, ?When?
and ?Where?.
A verb or anaction noun is deemed as an event term onlywhen it presents itself at least once between twonamed entities.Events are commonly related with one an-other semantically, temporally, spatially, caus-ally or conditionally, especially when the docu-ments to be summarized are about the same orvery similar topics.
Therefore, all event termsand named entities involved can be explicitlyconnected or implicitly related and weave adocument or a set of documents into an eventfabric, i.e.
an event graphical representation (seeFigure 1).
The nodes in the graph are of twotypes.
Event terms (ET) are indicated by rectan-gles and named entities (NE) are indicated byellipses.
They represent concepts rather thaninstances.
Words in either their original form ormorphological variations are represented with asingle node in the graph regardless of how manytimes they appear in documents.
We call thisrepresentation an event map, from which themost important concepts can be pick out in thesummary.Figure 1 Sample sentences and their graphical representationThe advantage of representing with separatedaction and entity nodes over simply combiningthem into one event or sentence node is to pro-vide a convenient way for analyzing the rele-vance among event terms and named entitieseither by their semantic or distributional similar-ity.
More importantly, this favors extraction ofconcepts and brings the conceptual compressionavailable.We then integrate the strength of the connec-tions between nodes into this graphical model interms of the relevance defined from differentperspectives.
The relevance is indicated by),( ji nodenoder , where inode  and jnode  repre-sent two nodes, and are either event terms ( iet )or named entities ( jne ).
Then, the significanceof each node, indicated by )( inodew , is calcu-<Organization> America Online </Organization> was to buy <Organization>Netscape </Organization> and forge a partnership with <Organization> Sun</Organization>, benefiting all three and giving technological independencefrom <Organization> Microsoft </Organization>.371lated with PageRank ranking algorithm.
Sec-tions 3.2 and 3.3 address the issues of deriving),( ji nodenoder  according to intra- or/and inter-event relevance and calculating )( inodew  in de-tail.3.2 Intra- and Inter- Event RelevanceWe consider both intra-event and inter-eventrelevance for summarization.
Intra-event rele-vance measures how an action itself is associ-ated with its associated arguments.
It is indi-cated as ),( NEETR  and ),( ETNER  in Table 1below.
This is a kind of direct relevance as theconnections between actions and arguments areestablished from the text surface directly.
Noinference or background knowledge is required.We consider that when the connection betweenan event term iet  and a named entity jne  issymmetry, then TNEETRETNER ),(),( = .
Eventsare related as explained in Section 2.
By meansof inter-event relevance, we consider how anevent term (or a named entity involved in anevent) associate to another event term (or an-other named entity involved in the same or dif-ferent events) syntactically, semantically anddistributionally.
It is indicated by ),( ETETR or),( NENER in Table 1 and measures an indirectconnection which is not explicit in the eventmap needing to be derived from the externalresource or overall event distribution.Event Term(ET)Named En-tity (NE)Event Term (ET) ),( ETETR  ),( NEETRNamed Entity (NE) ),( ETNER  ),( NENERTable 1 Relevance MatrixThe complete relevance matrix is:?????
?=),(),(),(),(NENERETNERNEETRETETRRThe intra-event relevance ),( NEETR can besimply established by counting how many timesiet  and jne  are associated, i.e.
),(),( jijiDocument neetfreqneetr =  (E1)One way to measure the term relevance is tomake use of a general language knowledge base,such as WordNet (Fellbaum 1998).
Word-Net::Similarity is a freely available softwarepackage that makes it possible to measure thesemantic relatedness between a pair of concepts,or in our case event terms, based on WordNet(Pedersen, Patwardhan and Michelizzi, 2004).
Itsupports three measures.
The one we choose isthe function lesk.
),(),(),( jijijiWordNet etetlesketetsimilarityetetr ==(E2)Alternatively, term relevance can be meas-ured according to their distributions in the speci-fied documents.
We believe that if two eventsare concerned with the same participants, occurat same location, or at the same time, these twoevents are interrelated with each other in someways.
This observation motivates us to try deriv-ing event term relevance from the number ofname entities they share.|)()(|),( jijiDocument etNEetNEetetr ?=  (E3)Where )( ietNE is the set of named entities ietassociate.
| | indicates the number of the ele-ments in the set.
The relevance of named entitiescan be derived in a similar way.|)()(|),( jijiDocument neETneETnener ?=  (E4)The relevance derived with (E3) and (E4) areindirect relevance.
In previous work, a cluster-ing algorithm, shown in Figure 2, has been pro-posed (Xu et al 2006) to merge the named en-tity that refer to the same person (such asRanariddh, Prince Norodom Ranariddh and Presi-dent Prince Norodom Ranariddh).
It is used forco-reference resolution and aims at joining thesame concept into a single node in the eventmap.
The experimental result suggests thatmerging named entity improves performance insome extend but not evidently.
When applyingthe same algorithm for clustering all four typesof name entities in DUC data, we observe thatthe name entities in the same cluster do not al-ways refer to the same objects, even when theyare indeed related in some way.
For example,?Mississippi?
is a state in the southeast UnitedStates, while ?Mississippi River?
is the second-longest rever in the United States and flowsthrough ?Mississippi?.Step1: Each name entity is represented byikiii wwwne ...21= , where iw  is the ithword in it.
The cluster it belongs to, in-dicated by )( ineC , is initialled byikii www ...21 itself.Step2: For each name entityikiii wwwne ...21=For each name entity372jljjj wwwne ...21= , if )( ineC  is asub-string of )( jneC , then)()( ji neCneC = .Continue Step 2 until no change occurs.Figure 2 The algorithm proposed to merge thenamed entitiesLocation Person Date OrganizationMississippiProfessor SirRichardSouthwoodfirst sixmonths oflast yearLong BeachCity CouncilSir RichardSouthwoodSan Jose CityCouncilMississippiRiverRichardSouthwoodlast yearCity CouncilTable 2 Some results of the named entitymergedIt therefore provides a second way to measurenamed entity relevance based on the clustersfound.
It is actually a kind of measure of lexicalsimilarity.??
?=otherwise      ,0cluster same in the are ,      ,1),( jijiClusternenenener(E5)In addition, the relevance of the named enti-ties can be sometimes revealed by sentence con-text.
Take the following most frequently usedsentence patterns as examples:Figure 3 The example patternsConsidering that two neighbouring name enti-ties in a sentence are usually relevant, the fol-lowing window-based relevance is also experi-mented with.??
?=otherwise      ,0size  windowspecified-pre a within are ,      1,),(jijiPatternnenenener(E6)3.3 Significance of ConceptsThe significance score, i.e.
the weight)( inodew  of each inode , is then estimated recur-sively with PageRank ranking algorithm whichassigns the significance score to each node ac-cording to the number of nodes connecting to itas well as the strength of their connections.
Theequation calculating )( inodew using PageRankof a certain inode  is shown as follows.)),()(...),()(...
),()(()1()(11titjijiinodenodernodewnodenodernodewnodenodernodewddnodew+++++?=(E7)In (E7), jnode ( tj ,...2,1= , ij ? )
are thenodes linking to inode .
d is the factor used toavoid the limitation of loop in the map structure.It is set to 0.85 experimentally.
The significanceof each sentence to be included in the summaryis then obtained from the significance of theevents it contains.
The sentences with highersignificance are picked up into the summary aslong as they are not exactly the same sentences.We are aware of the important roles of informa-tion fusion and sentence compression in sum-mary generation.
However, the focus of this pa-per is to evaluate event-based approaches in ex-tracting the most important sentences.
Concep-tual extraction based on event relevance is ourfuture direction.4.
Experiments and DiscussionsTo evaluate the event based summarization ap-proaches proposed, we conduct a set of experi-ments on 30 English document sets provide bythe DUC 2001 multi-document summarizationtask.
The documents are pre-processed withGATE to recognize the previously mentionedfour types of name entities.
On average, each setcontains 10.3 documents, 602 sentences, 216event terms and 148.5 name entities.To evaluate the quality of the generatedsummaries, we choose an automatic summaryevaluation metric ROUGE, which has been usedin DUCs.
ROUGE is a recall-based metric forfixed length summaries.
It bases on N-gram co-occurrence and compares the system generatedsummaries to human judges (Lin and Hovy,2003).
For each DUC document set, the systemcreates a summary of 200 word length and pre-sent three of the ROUGE metrics: ROUGE-1(unigram-based), ROUGE-2 (bigram-based),and ROUGE-W (based on longest common sub-sequence weighed by the length) in the follow-ing experiments and evaluations.We first evaluate the summaries generatedbased on ),( NEETR  itself.
In the pre-evaluationexperiments, we have observed that some fre-<Person>, a-position-name of <Organization>,does something.<Person> and another <Person> do something.373quently occurring nouns, such as ?doctors?
and?hospitals?, by themselves are not marked bygeneral NE taggers.
But they indicate persons,organizations or locations.
We compare theROUGE scores of adding frequent nouns or notto the set of named entities in Table 3.
A noun isconsidered as a frequent noun when its fre-quency is larger than 10.
Roughly 5% improve-ment is achieved when high frequent nouns aretaken into the consideration.
Hereafter, when wemention NE in latter experiments, the high fre-quent nouns are included.
),( NEETR  NE Without HighFrequency NounsNE With HighFrequency NounsROUGE-1 0.33320 0.34859ROUGE-2 0.06260 0.07157ROUGE-W 0.12965 0.13471Table 3 ROUGE scores using ),( NEETR  itselfTable 4 below then presents the summariza-tion results by using ),( ETETR  itself.
It com-pares two relevance derivation approaches,WordNetR  and DocumentR .
The topic-specific rele-vance derived from the documents to be summa-rized outperforms the general purpose Word-Netrelevance by about 4%.
This result is reasonableas WordNet may introduce the word relatednesswhich is not necessary in the topic-specificdocuments.
When we examine the relevancematrix from the event term pairs with the high-est relevant, we find that the pairs, like ?abort?and ?confirm?, ?vote?
and confirm?, do reflectsemantics (antonymous) and associated (causal)relations to some degree.
),( ETETR  Semantic Rele-vance fromWord-NetTopic-SpecificRelevance fromDocumentsROUGE-1 0.32917 0.34178ROUGE-2 0.05737 0.06852ROUGE-W 0.11959 0.13262Table 4 ROUGE scores using ),( ETETR  itselfSurprisingly, the best individual result is fromdocument distributional similarity DocumentR),( NENE  in Table 5.
Looking more closely, weconclude that compared to event terms, namedentities are more representative of the docu-ments in which they are included.
In other words,event terms are more likely to be distributedaround all the document sets, whereas namedentities are more topic-specific and thereforecluster in a particular document set more.
Ex-amples of high related named entities in rele-vance matrix are ?Andrew?
and ?Florida?,?Louisiana?
and ?Florida?.
Although their rele-vance is not as explicit as the same of eventterms (their relevance is more contextual thansemantic), we can still deduce that some eventsmay happen in both Louisiana and Florida, orabout Andrew in Florida.
In addition, it alsoshows that the relevance we would have ex-pected to be derived from patterns and clusteringcan also be discovered by ),( NENERDocument .The window size is set to 5 experimentally inwindow-based practice.
),( NENER RelevancefromDocumentsRelevancefromClusteringRelevancefrom Window-based ContextROUGE-1 0.35212 0.33561 0.34466ROUGE-2 0.07107 0.07286 0.07508ROUGE-W 0.13603 0.13109 0.13523Table 5 ROUGE scores using ),( NENER  itselfNext, we evaluate the integration of),( NEETR , ),( ETETR  and ),( NENER .
AsDUC 2001 provides 4 different summary sizesfor evaluation, it satisfies our desire to test thesensibility of the proposed event-based summa-rization techniques to the length of summaries.While the previously presented results areevaluated on 200 word summaries, now wemove to check the results in four different sizes,i.e.
50, 100, 200 and 400 words.
The experi-ments results show that the event-based ap-proaches indeed prefer longer summaries.
Thisis coincident with what we have hypothesized.For this set of experiments, we choose to inte-grate the best method from each individualevaluation presented previously.
It appears thatusing the named entities relevance which is de-rived from the event terms gives the bestROUGE scores in almost all the summery sizes.Compared with the results provided in (Filatovaand Hatzivassiloglou, 2004) whose averageROUGE-1 score is below 0.3 on the same dataset, the significant improvement is revealed.
Ofcourse, we need to test on more data in the fu-ture.
),( NENER 50 100 200 400ROUGE-1 0.22383 0.28584 0.35212 0.41612ROUGE-2 0.03376 0.05489 0.07107 0.10275ROUGE-W 0.10203 0.11610 0.13603 0.13877),( NEETR 50 100 200 400ROUGE-1 0.22224 0.27947 0.34859 0.41644ROUGE-2 0.03310 0.05073 0.07157 0.10369ROUGE-W 0.10229 0.11497 0.13471 0.13850),( ETETR 50 100 200 400374ROUGE-1 0.20616 0.26923 0.34178 0.41201ROUGE-2 0.02347 0.04575 0.06852 0.10263ROUGE-W 0.09212 0.11081 0.13262 0.13742),( NEETR +),( ETETR +),( NENER50100200400ROUGE-1 0.21311 0.27939 0.34630 0.41639ROUGE-2 0.03068 0.05127 0.07057 0.10579ROUGE-W 0.09532 0.11371 0.13416 0.13913Table 6 ROUGE scores using complete R matrixand with different summary lengthsAs discussed in Section 3.2, the named enti-ties in the same cluster may often be relevant butnot always be co-referred.
In the following lastset of experiments, we evaluate the two ways touse the clustering results.
One is to considerthem as related as if they are in the same clusterand derive the NE-NE relevance with (E5).
Theother is to merge the entities in one cluster asone reprehensive named entity and then use it inET-NE with (E1).
The rationality of the formerapproach is validated.Clustering isused to deriveNE-NEClustering is used tomerge entities andthen to derive ET-NEROUGE-1 0.34072 0.33006ROUGE-2 0.06727 0.06154ROUGE-W 0.13229 0.12845Table 7 ROUGE scores with regard to how touse the clustering information5.
ConclusionIn this paper, we propose to integrate event-based approaches to extractive summarization.Both inter-event and intra-event relevance areinvestigated and PageRank algorithm is used toevaluate the significance of each concept (in-cluding both event terms and named entities).The sentences containing more concepts andhighest significance scores are chosen in thesummary as long as they are not the same sen-tences.To derive event relevance, we consider theassociations at the syntactic, semantic and con-textual levels.
An important finding on the DUC2001 data set is that making use of named entityrelevance derived from the event terms they as-sociate with achieves the best result.
The resultof 0.35212 significantly outperforms the onereported in the closely related work whose aver-age is below 0.3.
We are interested in the issueof how to improve an event representation inorder to build a more powerful event-basedsummarization system.
This would be one of ourfuture directions.
We also want to see how con-cepts rather than sentences are selected into thesummary in order to develop a more flexiblecompression technique and to know what char-acteristics of a document set is appropriate forapplying event-based summarization techniques.AcknowledgementsThe work presented in this paper is supportedpartially by Research Grants Council on HongKong (reference number CERG PolyU5181/03E)and partially by National Natural Science Foun-dation of China (reference number: NSFC60573186).ReferencesChin-Yew Lin and Eduard Hovy.
2003.
AutomaticEvaluation of Summaries using N-gram Co-occurrence Statistics.
In Proceedings of HLT-NAACL 2003, pp71-78.Christiane Fellbaum.
1998, WordNet: An ElectronicLexical Database.
MIT Press.Elena Filatova and Vasileios Hatzivassiloglou.
2004.Event-based Extractive summarization.
In Pro-ceedings of ACL 2004 Workshop on Summariza-tion, pp104-111.Gunes Erkan and Dragomir Radev.
2004.
LexRank:Graph-based Centrality as Salience in Text Sum-marization.
Journal of Artificial Intelligence Re-search.Jure Leskovec, Marko Grobelnik and Natasa Milic-Frayling.
2004.
Learning Sub-structures of Docu-ment Semantic Graphs for Document Summariza-tion.
In LinkKDD 2004.Lucy Vanderwende, Michele Banko and Arul Mene-zes.
2004.
Event-Centric Summary Generation.
InWorking Notes of DUC 2004.Masaharu Yoshioka and Makoto Haraguchi.
2004.Multiple News Articles Summarization based onEvent Reference Information.
In Working Notesof NTCIR-4, Tokyo.MUC-7.
http://www-nlpir.nist.gov/related_projects/muc/proceeings/ muc_7_toc.htmlNaomi Daniel, Dragomir Radev and Timothy Allison.2003.
Sub-event based Multi-document Summari-zation.
In Proceedings of the HLT-NAACL 2003Workshop on Text Summarization, pp9-16.375Page Lawrence, Brin Sergey, Motwani Rajeev andWinograd Terry.
1998.
The PageRank CitationRanking: Bring Order to the Web.
Technical Re-port, Stanford University.Rada Mihalcea.
2005.
Language Independent Extrac-tive Summarization.
ACL 2005 poster.Regina Barzilay and Michael Elhadad.
2005.
Model-ling Local Coherence: An Entity-based Approach.In Proceedings of ACL, pp141-148.TDT.
http://projects.ldc.upenn.edu/TDT.Ted Pedersen, Siddharth Patwardhan and JasonMichelizzi.
2004.
WordNet::Similarity ?
Measur-ing the Relatedness of Concepts.
In Proceedings ofAAAI, pp25-29.Wei Xu, Wenjie Li, Mingli Wu, Wei Li and ChunfaYuan.
2006.
Deriving Event Relevance from theOntology Constructed with Formal ConceptAnalysis, in Proceedings of CiCling?06, pp480-489.376
