Unsupervised Models for Named Entity ClassificationMichael Collins and Yoram SingerAT&T Labs-Research,180 Park Avenue, Florham Park, NJ 07932{mcollins, s inger}@research,  att.
comAbstractThis paper discusses the use of unlabeled examplesfor the problem of named entity classification.
Alarge number of rules is needed for coverage of thedomain, suggesting that a fairly large number of la-beled examples hould be required to train a classi-fier.
However, we show that the use of unlabeleddata can reduce the requirements for supervisionto just 7 simple "seed" rules.
The approach gainsleverage from natural redundancy in the data: formany named-entity instances both the spelling ofthe name and the context inwhich it appears aresufficient o determine its type.We present two algorithms.
The first method usesa similar algorithm to that of (Yarowsky 95), withmodifications motivated by (Blum and Mitchell 98).The second algorithm extends ideas from boostingalgorithms, designed for supervised learning tasks,to the framework suggested by (Blum and Mitchell98).1 IntroductionMany statistical or machine-learning approaches fornatural anguage problems require a relatively largeamount of supervision, in the form of labeled train-ing examples.
Recent results (e.g., (Yarowsky 95;Brill 95; Blum and Mitchell 98)) have suggestedthat unlabeled ata can be used quite profitably inreducing the need for supervision.
This paper dis-cusses the use of unlabeled examples for the prob-lem of named entity classification.The task is to learn a function from an in-put string (proper name) to its type, which wewill assume to be one of the categories Person ,Organization, or  Location.
For example, agood classifier would identify Mrs. Frank as a per-son, Steptoe & Johnson as a company, and Hon-duras as a location.
The approach uses both spellingand contextual rules.
A spelling rule might be a sim-ple look-up for the string (e.g., a rule that Hondurasis a location) or a rule that looks at words within astring (e.g., a rule that any string containing Mr. isa person).
A contextual rule considers words sur-rounding the string in the sentence in which it ap-pears (e.g., a rule that any proper name modified byan appositive whose head is president is a person).The task can be considered to be one componentof the MUC (MUC-6, 1995) named entity task (theother task is that of segmentation, i.e., pulling pos-sible people, places and locations from text beforesending them to the classifier).
Supervised meth-ods have been applied quite successfully to the fullMUC named-entity ask (Bikel et el.
97).At first glance, the problem seems quite com-plex: a large number of rules is needed to cover thedomain, suggesting that a large number of labeledexamples is required to train an accurate classifier.But we will show that the use of unlabeled ata candrastically reduce the need for supervision.
Givenaround 90,000 unlabeled examples, the methods de-scribed in this paper classify names with over 91%accuracy.
The only supervision is in the form of 7seed rules (namely, that New York, California andU.S.
are locations; that any name containing Mr. isa person; that any name containing Incorporated isan organization; and that LB.M.
and Microsoft areorganizations).The key to the methods we describe is redun-dancy in the unlabeled ata.
In many cases, inspec-tion of either the spelling or context alone is suffi-cient to classify an example.
For example, in.., says Mr. Cooper, a vice president of ..both a spelling feature (that the string contains Mr.)and a contextual feature (that president modifies thestring) are strong indications that Mr. Cooper isof type Person .
Even if an example like this isnot labeled, it can be interpreted as a "hint" that Mr.and president imply the same category.
The unla-beled data gives many such "hints" that two featuresshould predict the same label, and these hints turnout to be surprisingly useful when building a classi-fier.We present wo algorithms.
The first methodbuilds on results from (Yarowsky 95) and (Blum and100IMitchell 98).
(Yarowsky 95) describes an algorithmfor word-sense disambiguation that exploits redun-dancy in contextual features, and gives impressiveperformance.
Unfortunately, Yarowsky's method isnot well understood from a theoretical viewpoint:we would like to formalize the notion of redun-dancy in unlabeled ata, and set up the learningtask as optimization of some appropriate objectivefunction.
(Blum and Mitchell 98) offer a promis-ing formulation of redundancy, also prove some re-sults about how the use of unlabeled examples canhelp classification, and suggest an objective func-tion when training :with unlabeled examples.
Ourfirst algorithm is similar to Yarowsky's, but withsome important modifications motivated by (Blumand Mitchell 98).
The algorithm can be viewed asheuristically optimizing an objective function sug-gested by (Blum and Mitchell 98); empirically it isshown to be quite successful in optimizing this cri-teflon.The second algorithm builds on a boosting al-gorithm called AdaBoost (Freund and Schapire 97;Schapire and Singer 98).
The AdaBoost algorithmwas developed for supervised learning.
AdaBoostfinds a weighted combination of simple (weak) clas-sifiers, where the w'eights are chosen to minimize afunction that bounds the classification error on a setof training examples.
Roughly speaking, the newalgorithm presented in this paper performs a sim-ilar search, but instead minimizes a bound on thenumber of (unlabeled) examples on which two clas-sifiers disagree.
The algorithm builds two classifiersiteratively: each iteration involves minimization ofa continuously differential function which boundsthe number of examples on which the two classifiersdisagree.1.1 Additional Related WorkThere has been additional recent work on induc-ing lexicons or other knowledge sources from largecorpora.
(Brin 98)idescribes a system for extract-ing (author, book-tiile) pairs from the World WideWeb using an approach that bootstraps from an ini-tial seed set of examples.
(Berland and Charniak99) describe a method for extracting parts of ob-jects from wholes (e.g., "speedometer" f om "car")from a large corpus using hand-crafted patterns.
(Hearst 92) describes a method for extracting hy-ponyms from a corpus (pairs of words in "isa" re-lations).
(Riloff and Shepherd 97) describe a boot-strapping approach ifor acquiring nouns in particu-lar categories ( uch as "vehicle" or "weapon" cate-gofies).
The approach builds from an initial seed setfor a category, and is quite similar to the decisionlist approach described in (Yarowsky 95).
Morerecently, (Riloff and Jones 99) describe a methodthey term "mutual bootstrapping" for simultane-ously constructing a lexicon and contextual extrac-tion patterns.
The method shares ome characteris-tics of the decision list algorithm presented in thispaper.
(Riloff and Jones 99) was brought o our at-tention as we were preparing the final version of thispaper.2 The Problem2.1 The Data971,746 sentences of New York Times text wereparsed using the parser of (Collins 96).1 Word se-quences that met the following criteria were then ex-tracted as named entity examples:?
The word sequence was a sequence of consecu-tive proper nouns (words tagged as NNP or NNPS)within a noun phrase, and whose last word was headof the noun phrase.?
The NP containing the word sequence appearedin one of two contexts:1.
There was an appositive modifier to the NP,whose head is a singular noun (tagged NN).
For ex-ample, take.... says Maury Cooper, a vice president atS.&RIn this case, Maury Cooper is extracted.
It is a se-quence of proper nouns within an NP; its last wordCooper is the head of the NP; and the NP has an ap-positive modifier (a vice president at S.&P ) whosehead is a singular noun (president).2.
The NP is a complement to a preposition,which is the head of a PP.
This PP modifies anotherNP, whose head is a singular noun.
For example,... fraud related to work on a federallyfunded sewage plant in GeorgiaIn this case, Georgia is extracted: the NP contain-ing it is a complement tothe preposition i ; the PPheaded by in modifies the NP a federally fundedsewage plant, whose head is the singular noun plant.In addition to the named-entity string (MauryCooper or Georgia), a contextual predictor was alsoextracted.
In the appositive case, the contextualIThanks to Ciprian Chelba for running the parser and pro-viding the data.101predictor was the head of the modifying appositive(president in the Maury Cooper example); in thesecond case, the contextual predictor was the prepo-sition together with the noun it modifies (plant_in inthe Georgia example).
From here on we will referto the named-entity string itself as the spelling of theentity, and the contextual predicate as the context.2.2 Feature ExtractionHaving found (spelling, context) pairs in the parseddata, a number of features are extracted.
The fea-tures are used to represent each example for thelearning algorithm.
In principle a feature could bean arbitrary predicate of the (spelling, context) pair;for reasons that will become clear, features are lim-ited to querying either the spelling or context alone.The following features were used:fuil-string=x The full string (e.g., for MauryCooper, ful i- s t r ing=Maury_Cooper) .contains(x) If the spelling contains morethan one word, this feature appliesfor any words that the string contains(e.g., Maury Cooper contributes twosuch features, conta ins  (Maury) andconta ins  (Cooper).allcapl This feature appears if the spelling is a sin-gle word which is all capitals (e.g., IBM wouldcontribute this feature).ailcap2 This feature appears if the spelling is a si n-gle word which is all capitals or full periods,and contains at least one period.
(e.g., N .Y .would contribute this feature, IBM would not).nonalpha=x Appears if the spelling contains anycharacters other than upper or lower caseletters.
In this case nona lpha  is thestring formed by removing all upper/lowercase letters from the spelling (e.g., forThomas E. Petry nona lpha=.
,  for A.T.&T.nona lpha=.
.
&.
).context=x The context for the entity.
TheMaury Cooper and Georgia examples wouldcontribute context=president andc ont  ex t =p i ant_in respectively.context-type=x context - type=appos  in theappositive case, context - type=prep  inthe PP case.Table 1 gives some examples of entities and theirfeatures.3 Unsupervised Algorithms based onDecision Lists3.1 Supervised Decision List LearningThe first unsupervised algorithm we describe isbased on the decision list method from (Yarowsky95).
Before describing the unsupervised case wefirst describe the supervised version of the algo-rithm:Input to the learning algorithm: n labeled ex-amples of the form (xi, Yi).
Yi is the label of the ithexample (given that there are k possible labels, Yiis a member of y = {1 .
.
.k}) .
x i i saseto fmifeatures {xil, xi2... Ximi} associated with the ithexample.
Each xij is a member of A', where X is aset of possible features.Output of the learning algorithm: a functionh : &' ?
y ~ \[0, 1\] where h(x,y) is an estimateof the conditional probability p(ylx) of seeing labely given that feature x is present.
Alternatively, hcan be thought of as defining a decision list of rolesx ~ y ranked by their "strength" h(x, y).The label for a test example with features x isthen defined asy(x)  =arg  max h(x,y) (1)xEx,yrYIn this paper we define h(x, y) as the followingfunction of counts seen in training data:Count(x, y) + olh(x ,y )  = Count(x) +ks  (2)Count(x, y) is the number of times feature x isseen with label y in training data, Count(x) =~ueyC?unt(x'Y)" a is a smoothing parame-ter, and k is the number of possible labels.
Inthis paper k = 3 (the three labels are person ,organ izat ion ,  location), and we set ~ =0.1.
Equation 2 is an estimate of the conditionalprobability of the label given the feature, P(ylx).
z3.2 An Unsupervised AlgorithmWe now introduce a new algorithm for learningfrom unlabeled examples, which we will call DL-Co'IYain (DL stands for decision list, the term Co-train is taken from (Blum and Mitchell 98)).
The2(Yarowsky 95) describes the use of more sophisticatedsmoothing methods.
It's not clear how to apply these methodsin the unsupervised case, as they required cross-validation tech-niques: for this reason we use the simpler smoothing methodshown here.102Sentence \] Entities (Spelling/Context) FeaturesBut Robert Jordan, al partner at Robert Jordan/partner full-string=Robert Jordan contains(Robert)Steptoe & Johnson who took ... contains(Jordan) context=partner context-type=apposSteptoe & Johnson/partner_at full-string=Steptoe_&_Johnson contains(Steptoe)contains(&) contains(Johnson) onalpha=&context=partner_at context-type=prepBy hiring a company like A.T.&T./company_like full-string=A.T.&T, allcap2 nonalpha=..&.A.T.&T.... context=company_like context-type=prepHanson acquired Kidde Incor- Kidde Incorporated/parent full-string=Kidde_Incorporated contains(Kidde)porated, parent of Kidde Credit, contains(Incorporated) context=parent context-type=apposfor .
.
.
.Kidde-Credit/parenLof full-string=Kidde_Credit contains(Kidde)' contains(Credit) context=parent_of c ntext-type=prepTable 1: Some example named entities and their features.input to the unsupervised algorithm is an initial,"seed" set of rules.
In the named entity domainthese rules werefull-string=N~w-York -+ Locationful l -str ing=Cal i fornia -+ Locationfull-string=U~S.
-~ Locat ioncontains(Mr.),  -~ Personcontains(Incorporated) -~ Organizat ionful l -str ing=Microsoft --~ Organizat ionfull-string=I,B.M.
--+ Organizat ionEach of these rules was given a strength of0.9999.
The following algorithm was then used toinduce new rules:1.
Set n = 5.
(n is the maximum number of rulesof each type induced at each iteration.)2.
Initialization: Set the spelling decision listequal to the set of seed rules.3.
Label the training set using the current set ofspelling rules.
Examples where no rule appliesare left unlabeled.4.
Use the labeled examples to induce a decisionlist of contextual rules, using the method de-scribed in section 3.1.Let Count'(x) be the number of times fea-ture x is seen with some known label inthe training data.
For each label (Person ,Organization and Location), take then contextual rules with the highest value ofCountt(x) whose unsmoothed 3 strength isabove some threshold Pmin.
(If fewer thann rules have precision greater than Pmin, we3Note that taking tile top n most frequent rules alreadymakes the method robust o low count events, hence we do notuse smoothing, allowing low-count high-precision features tobe chosen on later iterations....keep only those rules which exceed the preci-sion threshold.)
Pmin was fixed at 0.95 in allexperiments in this paper.Thus at each iteration the method induces atmost n x k rules, where k is the number ofpossible labels (k = 3 in the experiments inthis paper).Label the training set using the current set ofcontextual rules.
Examples where no rule ap-plies are left unlabeled.On this new labeled set, select up to n x kspelling rules using the same method as in step4.
Set the spelling rules to be the seed set plusthe rules selected.I fn  < 2500 set n = n+ 5 and return tostep 3.
Otherwise, label the training data withthe combined spelling/contextual decision list,then induce a final decision list from the la-beled examples where all rules (regardless ofstrength) are added to the decision list.3.3 The Algorithm in (Yarowsky 95)We can now compare this algorithm to that of(Yarowsky 95).
The core of Yarowsky's algorithmis as follows:...Initialization: Set the decision list equal to theset of seed rules.Label the training set using the current set ofrules.Use the labels to learn a decision list h(z, y)where h is defined by the formula in equa-tion 2, with counts restricted to training dataexamples that have been labeled in step 2.103Set the decision list to include all rules whose(smoothed) strength is above some thresholdPrain .4.
Return to step 2.There are two differences between this methodand the DL-CoTrain algorithm:?
The DL-CoTrain algorithm is rather more cau-tious, imposing a gradually increasing limit on thenumber of rules that can be added at each iteration.?
The DL-CoTrain algorithm has separated thespelling and contextual features, alternating be-tween labeling and learning with the two types offeatures.
Thus an explicit assumption about he re-dundancy of the features - -  that either the spellingor context alone should be sufficient to build a clas-sifier - -  has been built into the algorithm.To measure the contribution of each modification,a third, intermediate algorithm, Yarowsky-cautiouswas also tested.
Yarowsky-cautious does not sep-arate the spelling and contextual features, but doeshave a limit on the number of rules added at eachstage.
(Specifically, the limit n starts at 5 and in-creases by 5 at each iteration.
)The first modification - cautiousness - is a rel-atively minor change.
It was motivated by the ob-servation that the (Yarowsky 95) algorithm addeda very large number of rules in the first few iter-ations.
Taking only the highest frequency rules ismuch "safer", as they tend to be very accurate.
Thisintuition is born out by the experimental results.The second modification is more important, andis discussed in the next section.3.4 Justification for the Separation ofContextual and Spelling FeaturesAn important reason for separating the two types offeatures is that this opens up the possibility of the-oretical analysis of the use of unlabeled examples.
(Blum and Mitchell 98) describe learning in the fol-lowing situation:?
Each example is represented by a feature vectorx drawn from a set of possible values (an instancespace) X.
The task is to learn a classification func-tion f : X ~ Y where Y is a set of possible labels.?
The features can be separated into two types:X = X1 x X2 where X 1 and X2 correspond totwo different "views" of an example.
In the namedentity task, X1 might be the instance space for thespelling features, X2 might be the instance spacefor the contextual features.
By this assumption,each element x E X can also be represented as(xl, x2) E X1 x X2.?
Each view of the example is sufficient for clas-sification.
That is, there exist functions f l  and f2such that for any example x = (xl,x2), f (x )  =f l (X l )  = f2(x2).
We never see an example x =(xl, x2) in training or test data such that f l (x l )  #f2(x2).Thus the method makes the fairly strong assump-tion that the features can be partitioned into twotypes such that each type alone is sufficient for clas-sification.?
Xl and x2 are not correlated too tightly.
(Forexample, there is not a deterministic function fromx I to x2.
)Now assume we have n pairs (xl,i, x2,i) drawnfrom X1 ?
X2, where the first m pairs have labels Yi,whereas for i = m+ 1...n the pairs are unlabeled.
Ina fully supervised setting, the task is to learn a func-tion f such that for all i = 1...m, f(Xl,i, x2,i) ---- Yi.In the cotraining case, (Blum and Mitchell 98) ar-gue that the task should be to induce functions f land f2 such that1.
f l(Xl, i)  = f2(x2,i) = Yi for/ = 1...m2.
f l (x l , i )  = f2(x2,i) for/ = m + 1...nSo f l  and f2 must (1) correctly classify the la-beled examples, and (2) must agree with each otheron the unlabeled examples.
The key point is thatthe second constraint can be remarkably powerfulin reducing the complexity of the learning problem.
(Blum and Mitchell 98) give an example that il-lustrates just how powerful the second constraintcan be.
Consider the case where IXll = \]Xa\] = Nand N is a "medium" sized number so that it is fea-sible to collect O(N)  unlabeled examples.
Assumethat the two classifiers are "rote learners": that is, f land f2 are defined through look-up tables that list alabel for each member of X1 or X2.
The problem isa binary classification problem.
The problem can berepresented asa graph with 2N vertices correspond-ing to the members of X1 and X2.
Each unlabeledpair (xl,i, x2,i) is represented as an edge betweennodes corresponding to Xl,i and x2,i in the graph.An edge indicates that the two features must havethe same label.
Given a sufficient number of ran-domly drawn unlabeled examples (i.e., edges), wewill induce two completely connected componentsthat together span the entire graph.
Each vertexwithin a connected component must have the samelabel - -  in the binary classification case, we need a104single labeled example to identify which componentshould get which label.
(Blum and Mitchell 98) go on to give PAC re-sults for learning in the cotraining case.
They alsodescribe an application of cotraining to classifyingweb pages (the tw~o feature sets are the words onthe page, and other pages pointing to the page).The method halves the error rate in comparison toa method using the' labeled examples alone.iLimitations of (B!um and Mitchell 98): Whilethe assumptions of (Blum and Mitchell 98) are use-ful in developing both theoretical results and an in-tuition for the problem, the assumptions are quitelimited.
In particul~, it may not be possible to learnfunctions f l (x l , i ) i  = f2(x2,i) for i = m + 1...n:either because there is some noise in the data, orbecause it is just not realistic to expect o learn per-fect classifiers given the features used for represen-tation.
It may be more realistic to replace the sec-ond criteria with a softer one, for example (Blumand Mitchell 98) suggest the alternative1.
f l (Xl , i )  = f2(x2,i) = Yi fori  = 1...m2.
The choice of fa and f2 must minimize thenumber of examples for which f l (Xl , i )  7 ~f2(z2,i).Alternatively, if f l  and f2 are probabilistic learn-ers, it might make sense to encode the second con-straint as one of minimizing some measure of thedistance between the distributions given by the twolearners.
The question of what soft function to pick,and how to design ' algorithms which optimize it, isan open question, but appears to be a promising wayof looking at the problem.The DL-CoTrain algorithm can be motivated asbeing a greedy method of satisfying the above 2constraints.
At each iteration the algorithm in-creases the number of rules, while maintaining ahigh level of agregment between the spelling andcontextual decision lists.
Inspection of the datashows that at n = 2500, the two classifiers both givelabels on 44,281 (4,9.2%) of the unlabeled examples,and give the same ~label on 99.25% of these cases.So the success of the algorithm may well be due toits success in max!mizing the number of unlabeledexamples on which the two decision lists agree.
Inthe next section we present an alternative approachthat builds two classifiers while attempting to sat-isfy the above constraints as much as possible.
Thealgorithm, called CoBoost, has the advantage of be-ing more general than the decision-list learning al- lInput: (x l ,Y l ) , .
.
.
,  (xm,Ym); xi E 2"V,yi = ?1Initialize D1 (i) = 1/m.Fort  = 1 , .
.
.
,T :?
Get weak hypothesis ht : 2 x -+ II~ by trainingweak learner using distribution Dt.?
Choose at E I1~.?
Update:Dt+l (i) = Dt(i)e-atyiht(xd /ztwhere Zt = E~--1 Dt(i) e-atyiht(xi).Output final hypothesis:f (x )  = sign ( T:  1 o~tht(x))Figure 1: The AdaBoost algorithm for binary prob-lems (Schapire and Singer 98).gorithm, and, in fact, can be combined with almostany supervised machine learning algorithm.4 A Boosting-based algorithmThis section describes an algorithm based on boost-ing algorithms, which were previously developedfor supervised machine learning problems.
We firstgive a brief overview of boosting algorithms.
Wethen discuss how we adapt and generalize a boost-ing algorithm, AdaBoost, to the problem of namedentity classification.
The new algorithm, which wecall CoBoost, uses labeled and unlabeled ata andbuilds two classifiers in parallel.
(We would liketo note though that unlike previous boosting algo-rithms, the CoBoost algorithm presented here is nota boosting algorithm under Valiant's (Valiant 84)Probably Approximately Correct (PAC) model.
)4.1 The AdaBoost algorithmThis section describes AdaBoost, which is the ba-sis for the CoBoost algorithm.
AdaBoost was firstintroduced in (Freund and Schapire 97); (Schapireand Singer 98) gave a generalization of AdaBoostwhich we will use in this paper.
For a description ofthe application of AdaBoost to various NLP prob-lems see the paper by Abney, Schapire, and Singerin this volume.The input to AdaBoost is a set of training exam-ples ((Xl, Y l ) , .
?
?
, (X rn ,  Ym)) -  Each xi E 2 x is theset of features constituting the ith example.
For themoment we will assume that there are only two pos-sible labels: each Yi is in {-1,  +1}.
AdaBoost isgiven access to a weak learning algorithm, which105accepts as input the training examples, along witha distribution over the instances.
The distributionspecifies the relative weight, or importance, of eachexample - -  typically, the weak learner will attemptto minimize the weighted error on the training set,where the distribution specifies the weights.The weak learner for two-class problems com-putes a weak hypothesis h from the input space intothe reals (h : 2 x --+ 11~), where the sign 4 of h(x)is interpreted as the predicted label and the mag-nitude Ih(x)l is the confidence in the prediction:large numbers for Ih(x) l indicate high confidence inthe prediction, and numbers close to zero indicatelow confidence.
The weak hypothesis can abstainfrom predicting the label of an instance x by set-ting h(x) = 0.
The final strong hypothesis, denotedf (x), is then the sign of a weighted sum of the weakhypotheses, f (x )  = sign (~tT=l atht(x)), wherethe weights at are determined uring the run of thealgorithm, as we describe below.Pseudo-code describing the generalized boostingalgorithm of Schapire and Singer is given in Fig-ure 1.
Note that Zt is a normalization constant thatensures the distribution Dt+l sums to 1; it is a func-tion of the weak hypothesis ht and the weight forthat hypothesis at chosen at the tth round.
The nor-malization factor plays an important role in the Ad-aBoost algorithm.
Schapire and Singer show thatthe training error is bounded above by1 exp --Yi o~tht(xi) HZt  .
(3)i=1 tThus, in order to greedily minimize an upper boundon training error, on each iteration we should searchfor the weak hypothesis ht and the weight at thatminimize Zt.In our implementation, we make perhaps the sim-plest choice of weak hypothesis.
Each ht is a func-tion that predicts a label (+1 or -1 )  on examplescontaining a particular feature xt, while abstainingon other examples:?1 xtCxht(x) = 0 Xt ~ xThe prediction of the strong hypothesis can then bewritten asawe define sign(O) = O.We now briefly describe how to choose ht and o~tat each iteration.
Our derivation is slightly differentfrom the one presented in (Schapire and Singer 98)as we restrict o~t o be positive.
Zt can be written asfollowsZt = ~ Dt(i)i:ggt~xi+ E nt(i) exp(-Yiatht(xi)).
(4)i:XtExiLetWo = E Dt(i),i:ht(xl)=OW+ = E Dt(i) ,i:ht(xi)=ylW_ = E Dr(i).i:ht(xl)=-yiFollowing the derivation of Schapire and Singer,providing that W+ > W_, Equ.
(4) is minimizedby settingat = ~ In .
(5)Since a feature may be present in only a few ex-amples, W_ can be in practice very small or even0, leading to extreme confidence values.
To pre-vent this we "smooth" the confidence by adding asmall value, e, to both W+ and W_, giving st =Plugging the value of at from Equ.
(5) and ht intoEqu.
(4) givesZt = Wo + 2v/W+W_ (6)In order to minimize Zt, at each iteration the finalalgorithm should choose the weak hypothesis (i.e.,a feature xt) which has values for W+ and W_ thatminimize Equ.
(6), with W+ > W_.4.2 The CoBoost algorithmWe now describe the CoBoost algorithm for thenamed entity problem.
Following the conventionpresented in earlier sections, we assume that eachexample is an instance pair of the from (Xl,i, X2,i)where Xj,i E 2"vJ,j E {1,2}.
In the named-entity problem each example is a (spelling,context)pair.
The first rn pairs have labels Yi, whereas fori = m + 1 , .
.
.
,n  the pairs are unlabeled.
Wemake the assumption that for each example, both106Iixl,i and x2,i alone are sufficient to determine the la-bel Yi.
The learning task is to find two classifiersfx : 2 & --+ {-1 ,  +1} f2 : 2 x'2 --+ {-1 ,  +1} suchthat f l (x l , i )  = f2(x2,i) = Yi for examples i =1 , .
.
.
,  m, and fl(Xl, i) = f2(x2,i) as often as possi-ble on examples i = m + 1 , .
.
.
,  n. To achieve thisgoal we extend the auxiliary function that boundsthe training error (see Equ.
(3)) to be defined overunlabeled as well as labeled instances.
Denote bygj(x) = ~t4h~: (x ) , j  E {1,2} the unthresholdedstrong-hypothesis ( .e., fj (x) = sign(gj (x))).
Wedefine the following function:mXco de_=y Zexp(_y ig l (X l , i ) )+i=1mexp(-y g (x ,d)i=1n-q- Z exp(--f2(x2,i)gl(xl,i))i=m+ln+ ~ exp(-f l(xl, i)g2(x2,i)).
(7)i=m+lIf Zco is small, then it follows that the two classi-fiers must have a'low error rate on the labeled ex-amples, and that they also must give the same la-bel on a large number of unlabeled instances.
Tosee this, note that the first two terms in the aboveequation correspond to the function that AdaBoostattempts to minimize in the standard supervised set-ting (Equ.
(3)), With one term for each classifier.The two new terms force the two classifiers to agree,as much as possible, on the unlabeled examples.Put another way, the minimum of Equ.
(7) is at0 when: 1)Vi : sign(gl(xi)) = sign(g2(xi));2) Igj(xi)l ~ ~;  and 3) sign(gj(xi)) = yi fori = 1 , .
.
.
,m.  In fact, Zco provides a bound onthe sum of the classification error of the labeled ex-amples and the number of disagreements betweenthe two classifiers on the unlabeled examples.
For-mally, let el (e2) be the number of classification er-rors of the first (second) learner on the training data,and let eco be the number of unlabeled examples onwhich the two classifiers disagree.
Then, it can beverified thatq + e2 + 2eco _< Zco ?We can now derive the CoBoost algorithm as ameans of minimizing Zco.
The algorithm buildstwo classifiers in parallel from labeled and unla-beled data.
As in boosting, the algorithm works inrounds.
Each round is composed of two stages; eachstage updates one of the classifiers while keepingthe other classifier fixed.
Denote the unthresholdedclassifiers after t - 1 rounds by 9} -x and assumethat it is the turn for the first classifier to be updatedwhile the second one is kept fixed.
We first define"pseudo-labels", yi, as follows:Yi l< i<mYi = sign(g~-l(x2,i)) m < i <_ nThus the first m labels are simply copied from thelabeled examples, while the remaining (n - m) ex-amples are taken as the current output of the secondclassifier.
We can now add a new weak hypothesisht 1 based on a feature in P(1 with a confidence valueoct 1. ht 1 and tit 1 are chosen to minimize the functionnZclo = Z exp(--,Yi(g~ - l(xi)  + c~tlh~(xl, i)))" (8)i=1We now define, for 1 < i < n, the following virtualdistribution,1 Dtl( i) = z--~ exp(-~ig~-l(xl,i) ),As before, Zt 1 is a normalization constant.
Equ.
(8)can now be rewritten 5 asnZ Dtl( i)exp(-,Yi~h~(xl, i))'i=lwhich is of the same form as the function Zt usedin AdaBoost.
Using the virtual distribution Dtl(i)and pseudo-labels ~)i, values for W0, W+ and W_can be calculated for each possible weak hypothesis(i.e., for each feature x E ,121); the weak hypothe-sis with minimal value for W0 + 2~+W_ can bechosen as before; and the weight for this weak hy-pothesis c~t = ?
In \ w_ +~ ) can be calculated.
Thisprocedure is repeated for T rounds while alternat-ing between the two classifiers.
The pseudo-codedescribing the algorithm is given in Fig.
2.The CoBoost algorithm described above dividesthe function Zco into two parts: Zco = Zclo + Zc2o ??
On each step CoBoost searches for a feature anda weight so as to minimize either Zclo or Zc2o .
In5up to a constant factor Zt ~ which does not affect he mini-mization of Equ.
(8) w.r.t, ht and at.107n m Input: {(xl,i, x2,i) }i=l , {Yi}i=lInitialize: Vi, j : g?
(x / )  = 0.Fort = 1, .
.
.
.
T and for j  = 1,2:?
Set pseudo-labels:Yi l< i<mYi = sign(9~-}(x3_j,{)) m < i _< n?
Set virtual distribution:D{(i) = 1 -~- exp ( -g ig \ ] - I  (xj,i))Ztwhere Zt 3 = E~=I exp(-Yi9\] -1 (xj,i)).?
Get a weak hypothesis ht 3 : 2A:J --+ IR.
by train-ing weak learner j using distribution D~.?
Choose at 6 ~.?
Update:t X -~- \]--l:x Vi : gj( j,i) g ~ j,i) + c~th~(xj,i) .Output final hypothesis:f (x)  = sign (E~=i gT(X j ) )Figure 2: The CoBoost algorithm.practice, this greedy approach almost always resultsin an overall decrease in the value of Zco.
Note,however, that there might be situations in whichZco in fact increases.One implementation issue deserves ome elab-oration.
Note that in our formalism a weak-hypothesis can abstain.
In fact, during the firstrounds many of the predictions of gl, 92 are zero.Thus corresponding pseudo-labels for instances onwhich 9j abstainare set to zero and these instancesdo not contribute to the objective function.
Eachlearner is free to pick the labels for these instances.This allow the learners to "bootstrap" each other byfilling the labels of the instances on which the otherside has abstained so far.The CoBoost algorithm just described is for thecase where there are two labels: for the named en-tity task there are three labels, and in general it willbe useful to generalize the CoBoost algorithm to themulticlass case.
Several extensions of AdaBoost formulticlass problems have been suggested (Freundand Schapire 97; Schapire and Singer 98).
In thiswork we extended the AdaBoost.MH (Schapire andSinger 98) algorithm to the cotraining case.
Ad-aBoost.MH maintains a distribution over instancesand labels; in addition, each weak-hypothesis out-puts a confidence vector with one confidence valuefor each possible label.
We again adopt an approachwhere we alternate between two classifiers: oneclassifier is modified while the other remains fixed.Pseudo-labels are formed by taking seed labels onthe labeled examples, and the output of the fixedclassifier on the unlabeled examples.
AdaBoost.MHcan be applied to the problem using these pseudo-labels in place of supervised examples.For the experiments in this paper we made a cou-ple of additional modifications to the CoBoost al-gorithm.
The algorithm in Fig.
(2) was extendedto have an additional, innermost loop over the (3)possible labels.
The weak hypothesis chosen wasthen restricted to be a predictor in favor of this la-bel.
Thus at each iteration the algorithm is forcedto pick features for the locat ion ,  person  andorgan izat ion  in turn for the classifier beingtrained.
This modification brings the method closerto the DL-CoTrain algorithm described earlier, andis motivated by the intuition that all three labelsshould be kept healthily populated in the unlabeledexamples, preventing one label from dominating - -this deserves more theoretical investigation.We also removed the context - type  featuretype when using the CoBoost approach.
This "de-fault" feature type has 100% coverage (it is seen onevery example) but a low, baseline precision.
Whenthis feature type was included, CoBoost chose thisdefault feature at an early iteration, thereby givingnon-abstaining pseudo-labels for all examples, witheventual convergence tothe two classifiers agreeingby assigning the same label to almost all examples.Again, this deserves further investigation.Finally, we would like to note that it is possible todevise similar algorithms based with other objectivefunctions than the one given in Equ.
(7), such as thelikelihood function used in maximum-entropy rob-lems and other generalized additive models (Laf-ferty 99).
We are currently exploring such algo-rithms.5 An EM-based approachThe Expectation Maximization (EM) algorithm(Dempster, Laird and Rubin 77) is a common ap-proach for unsupervised training; in this section wedescribe its application to the named entity prob-lem.
A generative model was applied (similar tonaive Bayes) with the three labels as hidden vari-108!ables on unlabeled examples, and observed vari-ables on (seed) labeled examples.
The model wasparameterized such that the joint probability of a(label, feature-sei) pair P(Yi, xi) is written asP(Yi, xi) = P(Yi, Xil ' ' .
Ximi)mi= P(yi)P(mi) N P(xij\]Yi)j= l(9)The model assumes that (y, x) pairs are generatedby an underlying process where the label is first cho-sen with some prior probability P(Yi); the numberof features mi is then chosen with some probabilityP(mi); finally th~ features are independently gen-erated with probabilities P(xij \[Yi).We again assume a training set of n examples{xl .
.
.
Xn} where the first m examples have labels{Yl .
.
.
ym}, and the last (n - m) examples are un-labeled.
For the purposes of EM, the "observed"data is {(xx,ya)i... (Xm, Ym),Xm+l...Xn}, andthe hidden data is {ym+l .
.
.
Yn}.
The likelihood ofthe observed ata under the model ism n kl~  P(yi, xl) ?
I I  ~ P(y, xi)i=1  i=m+l  y=l(10)where P(Yi, xi) is defined as in (9).
Training underthis model involves estimation of parameter valuesfor P(y), P(m) and P(xly).
The maximum likeli-hood estimates (i.e., parameter values which maxi-mize 10) can not be found analytically, but the EMalgorithm can be used to hill-climb to a local max-imum of the likelihood function from some initialparameter settings.
In our experiments we set theparameter values randomly, and then ran EM to con-vergence.Given parameter stimates, the label for a test ex-ample x is defined asf(x) = argum{~xk}P(x,y ) (11)We should note that the model in equation 9is deficient, in that it assigns greater than zeroprobability to some feature combinations thatare impossible.
For example, the indepen-dence assumptions mean that the model failsto capture the dependence between specific andmore general features (for example the fact thatthe feature fu l l ' - s t r ing=New_York  is alwaysseen with the features conta ins  (New) andLearning Algorithm Accuracy Accuracy(Clean) (Noise)BaselineEM(Yarowsky 95)Yarowsky-cautiousDL-CoTrainCoBoost45.8%83.1%81.3%91.2%91.3%91.1%41.8%75.8%74.1%83.2%83.3%83.1%Table 2: Accuracy for different learning methods.The baseline method tags all entities as the most fre-quent class type (organization).conta ins  (York) and is never seen with a fea-ture such as contains (Group)).
Unfortunately,modifying the model to account for these kind ofdependencies is not at all straightforward.6 Evaluation88,962 (spelling,context) pairs were extracted astraining data.
1,000 of these were picked atrandom, and labeled by hand to produce a testset.
We chose one of four labels for each exam-ple: location, person, organization,or no ise  where the no ise  category was used foritems that were outside the three categories.
Thenumbers falling into the locat ion ,  person ,o rgan i  z a t  i on categories were 186, 289 and 402respectively.123 examples fell into the no ise  category.
Ofthese cases, 38 were temporal expressions (either aday of the week or month of the year).
We excludedthese from the evaluation as they can be easily iden-tified with a list of days/months.
This left 962 ex-amples, of which 85 were noise.
Taking Arc to bethe number of examples an algorithm classified cor-rectly (where all gold standard items labeled no i s ewere counted as being incorrect), we calculated twomeasures of accuracy:NcAccuracy : Noise -- (12)962NcAccuracy :Clean - (13)962 - 85See Tab.
2 for the accuracy ofthe different meth-ods.
Note that on some examples (around 2% ofthe test set) CoBoost abstained altogether; in thesecases we labeled the test example with the baseline,o rgan izat ion ,  label.
Fig.
(3) shows learningcurves for CoBoost.10910.90.80.70.60.50.40.30.20.1".,.??".
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.  '
.
.
.
.
.
.
.
.
.
.
.
..,,.,,,~.-" Coverage: t ra in  ----* .....~  : Agreements : t ra in  ..... ?
....10 1 O0 1000 10000Number  of  roundsFigure 3: Learning curves for CoBoost.
The graphgives the accuracy on the test set, the coverage (pro-portion of examples on which both classifiers give alabel rather than abstaining), and the proportion ofthese examples on which the two classifiers agree.With each iteration more examples are assigned la-bels by both classifiers, while a high level of agree-ment (> 94%) is maintained between them.
Thetest accuracy more or less asymptotes.7 ConclusionsUnlabeled examples in the named-entity classifica-tion problem can reduce the need for supervision toa handful of seed rules.
In addition to a heuristicbased on decision list learning, we also presented aboosting-like framework that builds on ideas from(Blum and Mitchell 98).
The method uses a "soft"measure of the agreement between two classifiersas an objective function; we described an algorithmwhich directly optimizes this function.
We are cur-rently exploring other methods that employ simi-lar ideas and their formal properties.
Future workshould also extend the approach to build a completenamed entity extractor - -  a method that pulls propernames from text and then classifies them.
The con-textual rules are restricted and may not be applicableto every example, but the spelling rules are gener-ally applicable and should have good coverage.
Theproblem of "noise" items that do not fall into any ofthe three categories also needs to be addressed.ReferencesM.
Berland and E. Charniak.
1999.
Finding Parts in Very LargeCorpora.
In Proceedings of the the 37th Annual Meeting ofthe Association for Computational Linguistics (ACL-99).D.
M. Bikel, S. Miller, R. Schwartz, and R. Weischedel.
1997.Nymble: a High-Performance L arning Name-finder.
InProceedings of the Fifth Conference on Applied NaturalLanguage Processing, pages 194-201.A.
Blum and T. Mitchell.
1998.
Combining Labeled andUnlabeled Data with Co-Training.
In Proceedings of thel lth Annual Conference on Computational Learning The-ory (COLT-98).E.
Brill.
1995.
Unsupervised Learning of DisambiguationRules for Part of Speech Tagging.
In Proceedings of theThird Workshop on Very Large Corpora.S.
Brin.
1998.
Extracting Patterns and Relations from the WorldWide Web.
In WebDB Wokshop at EDBT '98.M.
Collins.
1996.
A New Statistical Parser Based on Bi-gram Lexical Dependencies.
Proceedings of the 34th AnnualMeeting of the Association for Computational Linguistics,pages 184-191.A.P.
Dempster, N.M. Laird, and D.B.
Rubin, (1977).
MaximumLikelihood from Incomplete Data Via the EM Algorithm,Journal of the Royal Statistical Society, Ser B, 39, 1-38.Y.
Freund.
Boosting a weak learning algorithm by majority.Information and Computation, 121 (2):256-285, 1995.Y.
Freund and R. E. Schapire.
A decision-theoretic general-ization of on-line learning and an application to boosting.Journal of Computer and System Sciences, 55( 1 ): I 19-139,1997.M.
Hearst.
1992.
Automatic Acquisition of Hyponyms fromLarge Text Corpora.
In Proceedings of the Fourteenth In-ternational Conference on Computational Linguistics.Michael Kearns.
Thoughts on hypothesis boosting.
Unpub-lished manuscript, December 1988.J.
Lafferty.
Additive Models, Boosting, and Inference for Gen-eralized Divergences.
In Proceedings of the Twelfth AnnualConference on Computational Learning Theory, 1999.Proceedings of the Sixth Message Understanding Conference(MUC-6).
Morgan Kaufmann, San Mateo, CA.E.
Riloff and J. Shepherd.
1997.
A Corpus-Based Approachfor Building Semantic Lexicons.
In Proceedings of the Sec-ond Conference on Empirical Methods in Natural LanguageProcessing (EMNLP-2).E.
Riloff and R. Jones.
1999.
Learning Dictionaries for Infor-mation Extraction by Multi-Level Bootstrapping.
In Pro-ceedings of the Sixteenth National Conference on ArtificialIntelligence (AAAI-99).R.
E. Schapire.
The strength of weak learnability.
MachineLearning, 5(2): 197-227, 1990.R.
E. Schapire and Y.
Singer.
Improved boosting algorithmsusing confidence-rated predictions.
In Proceedings of theEleventh Annual Conference on Computational LearningTheory, pages 80-91, 1998.
To appear, Machine Learning.G.
Valiant.
A theory of the learnable.
Communications ofthe ACM, 27(11): 1134-1142, November 1984.Yarowsky.
1995.
Unsupervised Word Sense DisambiguationRivaling Supervised Methods.In Proceedings of the 33rdAnnual Meeting of the Association for Computational Lin-guistics.
Cambridge, MA, pp.
189-196.L.D.110
