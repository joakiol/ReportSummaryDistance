Improved Source-Channel Models for Chinese Word Segmentation1Jianfeng Gao, Mu Li and Chang-Ning HuangMicrosoft Research, AsiaBeijing 100080, China{jfgao, t-muli, cnhuang}@microsoft.com1We would like to thank Ashley Chang, Jian-Yun Nie, Andi Wu and Ming Zhou for many useful discussions, and for comments onearlier versions of this paper.
We would also like to thank Xiaoshan Fang, Jianfeng Li, Wenfeng Yang and Xiaodan Zhu for theirhelp with evaluating our system.AbstractThis paper presents a Chinese word segmen-tation system that uses improved source-channel models of Chinese sentence genera-tion.
Chinese words are defined as one of thefollowing four types: lexicon words, mor-phologically derived words, factoids, andnamed entities.
Our system provides a unifiedapproach to the four fundamental features ofword-level Chinese language processing: (1)word segmentation, (2) morphological analy-sis, (3) factoid detection, and (4) named entityrecognition.
The performance of the system isevaluated on a manually annotated test set,and is also compared with several state-of-the-art systems, taking into account the factthat the definition of Chinese words oftenvaries from system to system.1 IntroductionChinese word segmentation is the initial step ofmany Chinese language processing tasks, and hasattracted a lot of attention in the research commu-nity.
It is a challenging problem due to the fact thatthere is no standard definition of Chinese words.In this paper, we define Chinese words as one ofthe following four types: entries in a lexicon, mor-phologically derived words, factoids, and namedentities.
We then present a Chinese word segmen-tation system which provides a solution to the fourfundamental problems of word-level Chinese lan-guage processing: word segmentation, morpho-logical analysis, factoid detection, and named entityrecognition (NER).There are no word boundaries in written Chinesetext.
Therefore, unlike English, it may not be de-sirable to separate the solution to word segmenta-tion from the solutions to the other three problems.Ideally, we would like to propose a unified ap-proach to all the four problems.
The unified ap-proach we used in our system is based on the im-proved source-channel models of Chinese sentencegeneration, with two components: a source modeland a set of channel models.
The source model isused to estimate the generative probability of aword sequence, in which each word belongs to oneword type.
For each word type, a channel model isused to estimate the generative probability of acharacter string given the word type.
So there aremultiple channel models.
We shall show in thispaper that our models provide a statistical frame-work to corporate a wide variety linguistic knowl-edge and statistical models in a unified way.We evaluate the performance of our system us-ing an annotated test set.
We also compare oursystem with several state-of-the-art systems, takinginto account the fact that the definition of Chinesewords often varies from system to system.In the rest of this paper: Section 2 discussesprevious work.
Section 3 gives the detailed defini-tion of Chinese words.
Sections 4 to 6 describe indetail the improved source-channel models.
Section8 describes the evaluation results.
Section 9 pre-sents our conclusion.2 Previous WorkMany methods of Chinese word segmentation havebeen proposed: reviews include (Wu and Tseng,1993; Sproat and Shih, 2001).
These methods canbe roughly classified into dictionary-based methodsand statistical-based methods, while many state-of-the-art systems use hybrid approaches.In dictionary-based methods (e.g.
Cheng et al,1999), given an input character string, only wordsthat are stored in the dictionary can be identified.The performance of these methods thus depends toa large degree upon the coverage of the dictionary,which unfortunately may never be complete be-cause new words appear constantly.
Therefore, inaddition to the dictionary, many systems also con-tain special components for unknown word identi-fication.
In particular, statistical methods have beenwidely applied because they utilize a probabilisticor cost-based scoring mechanism, instead of thedictionary, to segment the text.
These methodshowever, suffer from three drawbacks.
First, someof these methods (e.g.
Lin et al, 1993) identifyunknown words without identifying their types.
Forinstance, one would identify a string as a unit, butnot identify whether it is a person name.
This is notalways sufficient.
Second, the probabilistic modelsused in these methods (e.g.
Teahan et al, 2000) aretrained on a segmented corpus which is not alwaysavailable.
Third, the identified unknown words arelikely to be linguistically implausible (e.g.
Dai et al,1999), and additional manual checking is neededfor some subsequent tasks such as parsing.We believe that the identification of unknownwords should not be defined as a separate problemfrom word segmentation.
These two problems arebetter solved simultaneously in a unified approach.One example of such approaches is Sproat et al(1996), which is based on weighted finite-statetransducers (FSTs).
Our approach is motivated bythe same inspiration, but is based on a differentmechanism: the improved source-channel models.As we shall see, these models provide a moreflexible framework to incorporate various kinds oflexical and statistical information.
Some types ofunknown words that are not discussed in Sproat?ssystem are dealt with in our system.3 Chinese WordsThere is no standard definition of Chinese words ?linguists may define words from many aspects (e.g.Packard, 2000), but none of these definitions willcompletely line up with any other.
Fortunately, thismay not matter in practice because the definitionthat is most useful will depend to a large degreeupon how one uses and processes these words.We define Chinese words in this paper as one ofthe following four types: (1) entries in a lexicon(lexicon words below), (2) morphologically derivedwords, (3) factoids, and (4) named entities, becausethese four types of words have different function-alities in Chinese language processing, and areprocessed in different ways in our system.
Forexample, the plausible word segmentation for thesentence in Figure 1(a) is as shown.
Figure 1(b) isthe output of our system, where words of differenttypes are processed in different ways:(a) ???/??????/????/?/???/??/?/??
(Friends happily go to professor Li Junsheng?shome for lunch at twelve thirty.
)(b) [??+?
MA_S] [??????
12:30 TIME] [?
?MR_AABB] [?]
[???
PN] [??]
[?]
[??
]Figure 1: (a) A Chinese sentence.
Slashes indicate wordboundaries.
(b) An output of our word segmentation system.Square brackets indicate word boundaries.
+ indicates amorpheme boundary.?
For lexicon words, word boundaries are de-tected.?
For morphologically derived words, theirmorphological patterns are detected, e.g.
???
?friend+s?
is derived by affixation of theplural affix ?
to the noun ??
(MA_S in-dicates a suffixation pattern), and ?????happily?
is a reduplication of ??
?happy?
(MR_AABB indicates an AABB reduplica-tion pattern).?
For factoids, their types and normalizedforms are detected, e.g.
12:30 is the normal-ized form of the time expression ??????
(TIME indicates a time expression).?
For named entities, their types are detected,e.g.
???
?Li Junsheng?
is a person name(PN indicates a person name).In our system, we use a unified approach to de-tecting and processing the above four types ofwords.
This approach is based on the improvedsource-channel models described below.4 Improved Source-Channel ModelsLet S be a Chinese sentence, which is a characterstring.
For all possible word segmentations W, wewill choose the most likely one W* which achievesthe highest conditional probability P(W|S): W* =argmaxw P(W|S).
According to Bayes?
decision ruleand dropping the constant denominator, we canequivalently perform the following maximization:)|()(maxarg* WSPWPWW=.
(1)Following the Chinese word definition in Section 3,we define word class C as follows: (1) Each lexiconWord class Class model Linguistic ConstraintsLexicon word (LW) P(S|LW)=1 if S forms a word lexiconentry, 0 otherwise.Word lexiconMorphologically derived word(MW)P(S|MW)=1 if S forms a morph lexiconentry, 0 otherwise.Morph-lexiconPerson name (PN) Character bigram  family name list, Chinese PN patternsLocation name (LN) Character bigram  LN keyword list, LN lexicon, LN abbr.
listOrganization name (ON) Word class bigram ON keyword list, ON abbr.
listTransliteration names (FN) Character bigram transliterated name character listFactoid2 (FT) P(S|FT)=1 if S can be parsed using afactoid grammar G, 0 otherwiseFactoid rules (presented by FSTs).Figure 2.
Class models2In our system, we define ten types of factoid: date, time (TIME), percentage, money, number (NUM), measure, e-mail, phonenumber, and WWW.word is defined as a class; (2) each morphologicallyderived word is defined as a class; (3) each type offactoids is defined as a class, e.g.
all time expres-sions belong to a class TIME; and (4) each type ofnamed entities is defined as a class, e.g.
all personnames belong to a class PN.
We therefore convertthe word segmentation W into a word class se-quence C. Eq.
1 can then be rewritten as:)|()(maxarg* CSPCPCC=.(2)Eq.
2 is the basic form of the source-channel modelsfor Chinese word segmentation.
The models assumethat a Chinese sentence S is generated as follows:First, a person chooses a sequence of concepts (i.e.,word classes C) to output, according to the prob-ability distribution P(C); then the person attempts toexpress each concept by choosing a sequence ofcharacters, according to the probability distributionP(S|C).The source-channel models can be interpreted inanother way as follows: P(C) is a stochastic modelestimating the probability of word class sequence.
Itindicates, given a context, how likely a word classoccurs.
For example, person names are more likelyto occur before a title such as ??
?professor?.
SoP(C) is also referred to as context model afterwards.P(S|C) is a generative model estimating how likelya character string is generated given a word class.For example, the character string ???
is morelikely to be a person name than ???
?Li Jun-sheng?
because ?
is a common family name inChina while ?
is not.
So P(S|C) is also referred toas class model afterwards.
In our system, we use theimproved source-channel models, which containsone context model (i.e., a trigram language model inour case) and a set of class models of different types,each of which is for one class of words, as shown inFigure 2.Although Eq.
2 suggests that class model prob-ability and context model probability can be com-bined through simple multiplication, in practicesome weighting is desirable.
There are two reasons.First, some class models are poorly estimated,owing to the sub-optimal assumptions we make forsimplicity and the insufficiency of the trainingcorpus.
Combining the context model probabilitywith poorly estimated class model probabilitiesaccording to Eq.
2 would give the context model toolittle weight.
Second, as seen in Figure 2, the classmodels of different word classes are constructed indifferent ways (e.g.
name entity models are n-grammodels trained on corpora, and factoid models arecompiled using linguistic knowledge).
Therefore,the quantities of class model probabilities are likelyto have vastly different dynamic ranges amongdifferent word classes.
One way to balance theseprobability quantities is to add several class modelweight CW, each for one word class, to adjust theclass model probability P(S|C) to P(S|C)CW.
In ourexperiments, these class model weights are deter-mined empirically to optimize the word segmenta-tion performance on a development set.Given the source-channel models, the procedureof word segmentation in our system involves twosteps: First, given an input string S, all word can-didates are generated (and stored in a lattice).
Eachcandidate is tagged with its word class and the classmodel probability P(S?|C), where S?
is any substringof S. Second, Viterbi search is used to select (fromthe lattice) the most probable word segmentation(i.e.
word class sequence C*) according to Eq.
(2).5 Class Model ProbabilitiesGiven an input string S, all class models in Figure 2are applied simultaneously to generate word classcandidates whose class model probabilities areassigned using the corresponding class models:?
Lexicon words: For any substring S?
?
S, weassume P(S?|C) = 1 and tagged the class aslexicon word if S?
forms an entry in the wordlexicon, P(S?|C) = 0 otherwise.?
Morphologically derived words: Similar tolexicon words, but a morph-lexicon is usedinstead of the word lexicon (see Section 5.1).?
Factoids: For each type of factoid, we compilea set of finite-state grammars G, represented asFSTs.
For all S?
?
S, if it can be parsed using G,we assume P(S?|FT) = 1, and tagged S?
as afactoid candidate.
As the example in Figure 1shows, ??????
is a factoid (time) can-didate with the class model probability P(?????
?|TIME) =1, and ??
and ??
arealso factoid (number) candidates, with P(?
?|NUM) = P(?
?|NUM) =1?
Named entities: For each type of named enti-ties, we use a set of grammars and statisticalmodels to generate candidates as described inSection 5.2.5.1 Morphologically derived wordsIn our system, the morphologically derived wordsare generated using five morphological patterns: (1)affixation: ???
(friend - plural) ?friends?
; (2)reduplication: ??
?happy?
!
????
?happily?
;(3) merging: ??
?on duty?
+ ??
?off duty?
!???
?on-off duty?
; (4) head particle (i.e.
expres-sions that are verb + comp): ?
?walk?
+ ??
?out?!
???
?walk out?
; and (5) split (i.e.
a set ofexpressions that are separate words at the syntacticlevel but single words at the semantic level): ???
?already ate?, where the bi-character word ??
?eat?is split by the particle ?
?already?.It is difficult to simply extend the well-knowntechniques for English (i.e., finite-state morphology)to Chinese due to two reasons.
First, Chinese mor-morphological rules are not as ?general?
as theirEnglish counterparts.
For example, English pluralnouns can be in general generated using the rule?noun + s !
plural noun?.
But only a small subset ofChinese nouns can be pluralized (e.g.
???)
usingits Chinese counterpart ?noun + ?
!
plural noun?whereas others (e.g.
??
?pumpkins?)
cannot.Second, the operations required by Chinese mor-phological analysis such as copying in reduplication,merging and splitting, cannot be implemented usingthe current finite-state networks3.Our solution is the extended lexicalization.
Wesimply collect all morphologically derived wordforms of the above five types and incorporate theminto the lexicon, called morph lexicon.
The proce-dure involves three steps: (1) Candidate genera-tion.
It is done by applying a set of morphologicalrules to both the word lexicon and a large corpus.For example, the rule ?noun + ?
!
plural noun?would generate candidates like ???.
(2) Statis-tical filtering.
For each candidate, we obtain a setof statistical features such as frequency, mutualinformation, left/right context dependency from alarge corpus.
We then use an information gain-likemetric described in (Chien, 1997; Gao et al, 2002)to estimate how likely a candidate is to form amorphologically derived word, and remove ?bad?candidates.
The basic idea behind the metric is thata Chinese word should appear as a stable sequencein the corpus.
That is, the components within theword are strongly correlated, while the componentsat both ends should have low correlations withwords outside the sequence.
(3) Linguistic selec-tion.
We finally manually check the remainingcandidates, and construct the morph-lexicon, whereeach entry is tagged by its morphological pattern.5.2 Named entitiesWe consider four types of named entities: personnames (PN), location names (LN), organizationnames (ON), and transliterations of foreign names(FN).
Because any character strings can be in prin-ciple named entities of one or more types, to limitthe number of candidates for a more effectivesearch, we generate named entity candidates, givenan input string, in two steps: First, for each type, weuse a set of constraints (which are compiled by3Sproat et al (1996) also studied such problems (with the sameexample) and uses weighted FSTs to deal with the affixation.linguists and are represented as FSTs) to generateonly those ?most likely?
candidates.
Second, each ofthe generated candidates is assigned a class modelprobability.
These class models are defined asgenerative models which are respectively estimatedon their corresponding named entity lists usingmaximum likelihood estimation (MLE), togetherwith smoothing methods4.
We will describe brieflythe constraints and the class models below.5.2.1 Chinese person namesThere are two main constraints.
(1) PN patterns: Weassume that a Chinese PN consists of a family nameF and a given name G, and is of the pattern F+G.Both F and G are of one or two characters long.
(2)Family name list: We only consider PN candidatesthat begin with an F stored in the family name list(which contains 373 entries in our system).Given a PN candidate, which is a characterstring S?, the class model probability P(S?|PN) iscomputed by a character bigram model as follows:(1) Generate the family name sub-string SF, with theprobability P(SF|F); (2) Generate the given namesub-string SG, with the probability P(SG|G) (orP(SG1|G1)); and (3) Generate the second given name,with the probability P(SG2|SG1,G2).
For example, thegenerative probability of the string ???
giventhat it is a PN would be estimated as P(??
?|PN)= P(?|F)P(?|G1)P(?|?,G2).5.2.2 Location namesUnlike PNs, there are no patterns for LNs.
Weassume that a LN candidate is generated given S?
(which is less than 10 characters long), if one of thefollowing conditions is satisfied: (1) S?
is an entry inthe LN list (which contains 30,000 LNs); (2) S?
endsin a keyword in a 120-entry LN keyword list such as?
?city?5.
The probability P(S?|LN) is computed bya character bigram model.Consider a string ????
?Wusuli river?.
It is aLN candidate because it ends in a LN keyword ??river?.
The generative probability of the stringgiven it is a LN would be estimated as P(???
?|LN) = P(?
|<LN>) P(?|?)
P(?
|?)
P(?
|?
)4The detailed description of these models are in Sun et al(2002), which also describes the use of cache model and theway the abbreviations of LN and ON are handled.5For a better understanding, the constraint is a simplifiedversion of that used in our system.P(</LN>|?
), where <LN> and </LN> are symbolsdenoting the beginning and the end of a LN, re-spectively.5.2.3 Organization namesONs are more difficult to identify than PNs and LNsbecause ONs are usually nested named entities.Consider an ON ????????
?Air ChinaCorporation?
; it contains an LN ??
?China?.Like the identification of LNs, an ON candidateis only generated given a character string S?
(lessthan 15 characters long), if it ends in a keyword in a1,355-entry ON keyword list such as ??
?corpo-ration?.
To estimate the generative probability of anested ON, we introduce word class segmentationsof S?, C, as hidden variables.
In principle, the ONclass model recovers P(S?|ON) over all possible C:P(S?|ON) = ?CP(S?,C|ON) = ?CP(C|ON)P(S?|C,ON).
Since P(S?|C,ON) = P(S?|C), we have P(S?|ON)= ?CP(C|ON) P(S?|C).
We then assume that thesum is approximated by a single pair of termsP(C*|ON)P(S?|C*), where C* is the most probableword class segmentation discovered by Eq.
2.
Thatis, we also use our system to find C*, but the source-channel models are estimated on the ON list.Consider the earlier example.
Assuming that C*= LN/??/??/?
?, where ??
is tagged as a LN,the probability P(S?|ON) would be estimated using aword class bigram model as: P(???????
?|ON) ?
P(LN/??/??/?
?|ON) P(?
?|LN) =P(LN|<ON>)P(??|LN)P(??|??)P(??|??)P(</ON>|??)P(?
?|LN), where P(?
?|LN) isthe class model probability of ??
given that it is aLN, <ON> and </ON> are symbols denoting thebeginning and the end of a ON, respectively.5.2.4 Transliterations of foreign namesAs described in Sproat et al (1996): FNs are usuallytransliterated using Chinese character strings whosesequential pronunciation mimics the source lan-guage pronunciation of the name.
Since FNs can beof any length and their original pronunciation iseffectively unlimited, the recognition of such namesis tricky.
Fortunately, there are only a few hundredChinese characters that are particularly common intransliterations.Therefore, an FN candidate would be generatedgiven S?, if it contains only characters stored in atransliterated name character list (which contains618 Chinese characters).
The probability P(S?|FN)is estimated using a character bigram model.
Noticethat in our system a FN can be a PN, a LN, or an ON,depending on the context.
Then, given a FN can-didate, three named entity candidates, each for onecategory, are generated in the lattice, with the classprobabilities P(S?|PN)=P(S?|LN)=P(S?|ON)=P(S?|FN).
In other words, we delay the determina-tion of its type until decoding where the contextmodel is used.6 Context Model EstimationThis section describes the way the class modelprobability P(C) (i.e.
trigram probability) in Eq.
2 isestimated.
Ideally, given an annotated corpus,where each sentence is segmented into words whichare tagged by their classes, the trigram word classprobabilities can be calculated using MLE, togetherwith a backoff schema (Katz, 1987) to deal with thesparse data problem.
Unfortunately, building suchannotated training corpora is very expensive.Our basic solution is the bootstrapping approachdescribed in Gao et al (2002).
It consists of threesteps: (1) Initially, we use a greedy word segmen-tor6 to annotate the corpus, and obtain an initialcontext model based on the initial annotated corpus;(2) we re-annotate the corpus using the obtainedmodels; and (3) re-train the context model using there-annotated corpus.
Steps 2 and 3 are iterated untilthe performance of the system converges.In the above approach, the quality of the contextmodel depends to a large degree upon the quality ofthe initial annotated corpus, which is however notsatisfied due to two problems.
First, the greedysegmentor cannot deal with the segmentation am-biguities, and even after iterations, these ambigui-ties can only be partially resolved.
Second, manyfactoids and named entities cannot be identifiedusing the greedy word segmentor which is based onthe dictionary.To solve the first problem, we use two methodsto resolve segmentation ambiguities in the initialsegmented training data.
We classify word seg-mentation ambiguities into two classes: overlapambiguity (OA), and combination ambiguity (CA).Consider a character string ABC, if it can be seg-6The greedy word segmentor is based on a forward maximummatching (FMM) algorithm: It processes through the sentencefrom left to right, taking the longest match with the lexiconentry at each point.mented into two words either as AB/C or A/BCdepending on different context, ABC is called anoverlap ambiguity string (OAS).
If a characterstring AB can be segmented either into two words,A/B, or as one word depending on different context.AB is called a combination ambiguity string (CAS).To resolve OA, we identify all OASs in the trainingdata and replace them with a single token <OAS>.By doing so, we actually remove the portion oftraining data that are likely to contain OA errors.
Toresolve CA, we select 70 high-frequent two-char-acter CAS (e.g.
??
?talent?
and ?/?
?just able?
).For each CAS, we train a binary classifier (which isbased on vector space models) using sentences thatcontains the CAS segmented manually.
Then foreach occurrence of a CAS in the initial segmentedtraining data, the corresponding classifier is used todetermine whether or not the CAS should be seg-mented.For the second problem, though we can simplyuse the finite-state machines described in Section 5(extended by using the longest-matching constraintfor disambiguation) to detect factoids in the initialsegmented corpus, our method of NER in the initialstep (i.e.
step 1) is a little more complicated.
First,we manually annotate named entities on a smallsubset (call seed set) of the training data.
Then, weobtain a context model on the seed set (called seedmodel).
We thus improve the context model whichis trained on the initial annotated training corpus byinterpolating it with the seed model.
Finally, we usethe improved context model in steps 2 and 3 of thebootstrapping.
Our experiments show that a rela-tively small seed set (e.g., 10 million characters,which takes approximately three weeks for 4 per-sons to annotate the NE tags) is enough to get agood improved context model for initialization.7 EvaluationTo conduct a reliable evaluation, a manually anno-tated test set was developed.
The text corpus con-tains approximately half million Chinese charactersthat have been proofread and balanced in terms ofdomain, styles, and times.
Before we annotate thecorpus, several questions have to be answered: (1)Does the segmentation depend on a particularlexicon?
(2) Should we assume a single correctsegmentation for a sentence?
(3) What are theevaluation criteria?
(4) How to perform a faircomparison across different systems?Wordsegmentation Factoid PN LN ONSystemP% R% P% R% P% R% P% R% P% R%1 FMM 83.7 92.72 Baseline 84.4 93.83 2 + Factoid 89.9 95.5 84.4 80.04 3 + PN 94.1 96.7 84.5 80.0 81.0 90.05 4 + LN 94.7 97.0 84.5 80.0 86.4 90.0 79.4 86.06 5 + ON 96.3 97.4 85.2 80.0 87.5 90.0 89.2 85.4 81.4 65.6Table 1: system resultsAs described earlier, it is more useful to definewords depending on how the words are used in realapplications.
In our system, a lexicon (containing98,668 lexicon words and 59,285 morphologicallyderived words) has been constructed for severalapplications, such as Asian language input and websearch.
Therefore, we annotate the text corpus basedon the lexicon.
That is, we segment each sentence asmuch as possible into words that are stored in ourlexicon, and tag only the new words, which other-wise would be segmented into strings of one-character words.
When there are multiple seg-mentations for a sentence, we keep only one thatcontains the least number of words.
The annotatedtest set contains in total 247,039 tokens (including205,162 lexicon/morph-lexicon words, 4,347 PNs,5,311 LNs, 3,850 ONs, and 6,630 factoids, etc.
)Our system is measured through multiple preci-sion-recall (P/R) pairs, and F-measures (F?=1, whichis defined as 2PR/(P+R)) for each word class.
Sincethe annotated test set is based on a particular lexicon,some of the evaluation measures are meaninglesswhen we compare our system to other systems thatuse different lexicons.
So in comparison with dif-ferent systems, we consider only the preci-sion-recall of NER and the number of OAS errors(i.e.
crossing brackets) because these measures arelexicon independent and there is always a singleunambiguous answer.The training corpus for context model containsapproximately 80 million Chinese characters fromvarious domains of text such as newspapers, novels,magazines etc.
The training corpora for class mod-els are described in Section 5.7.1 System resultsOur system is designed in the way that componentssuch as factoid detector and NER can be ?switchedon or off?, so that we can investigate the relativecontribution of each component to the overall wordsegmentation performance.The main results are shown in Table 1.
Forcomparison, we also include in the table (Row 1)the results of using the greedy segmentor (FMM)described in Section 6.
Row 2 shows the baselineresults of our system, where only the lexicon is used.It is interesting to find, in Rows 1 and 2, that thedictionary-based methods already achieve quitegood recall, but the precisions are not very goodbecause they cannot identify correctly unknownwords that are not in the lexicon such factoids andnamed entities.
We also find that even using thesame lexicon, our approach that is based on theimproved source-channel models outperforms thegreedy approach (with a slight but statisticallysignificant different i.e., P < 0.01 according to the ttest) because the use of context model resolvesmore ambiguities in segmentation.
The mostpromising property of our approach is that thesource-channel models provide a flexible frame-work where a wide variety of linguistic knowledgeand statistical models can be combined in a unifiedway.
As shown in Rows 3 to 6, when componentsare switched on in turn by activating correspondingclass models, the overall word segmentation per-formance increases consistently.We also conduct an error analysis, showing that86.2% of errors come from NER and factoid detec-tion, although the tokens of these word types consistof only 8.7% of all that are in the test set.7.2 Comparison with other systemsWe compare our system ?
henceforth SCM, withother two Chinese word segmentation systems7:7Although the two systems are widely accessible in mainlandChina, to our knowledge no standard evaluations on Chineseword segmentation of the two systems have been published bypress time.
More comprehensive comparisons (with other well-known systems) and detailed error analysis form one area ofour future work.LN PN ON System # OASErrors P % R % F?=1 P % R % F?=1 P % R % F?=1MSWS 63 93.5 44.2 60.0 90.7 74.4 81.8 64.2 46.9 60.0LCWS 49 85.4 72.0 78.2 94.5 78.1 85.6 71.3 13.1 22.2SCM 7 87.6 86.4 87.0 83.0 89.7 86.2 79.9 61.7 69.6Table 2.
Comparison results1.
The MSWS system is one of the best availableproducts.
It is released by Microsoft?
(as a setof Windows APIs).
MSWS first conducts theword breaking using MM (augmented by heu-ristic rules for disambiguation), then conductsfactoid detection and NER using rules.2.
The LCWS system is one of the best researchsystems in mainland China.
It is released byBeijing Language University.
The systemworks similarly to MSWS, but has a largerdictionary containing more PNs and LNs.As mentioned above, to achieve a fair comparison,we compare the above three systems only in termsof NER precision-recall and the number of OASerrors.
However, we find that due to the differentannotation specifications used by these systems, itis still very difficult to compare their results auto-matically.
For example, ?????
?Beijing citygovernment?
has been segmented inconsistently as???/??
?Beijing city?
+ ?government?
or ??/???
?Beijing?
+ ?city government?
even in thesame system.
Even worse, some LNs tagged in onesystem are tagged as ONs in another system.Therefore, we have to manually check the results.We picked 933 sentences at random containing22,833 words (including 329 PNs, 617 LNs, and435 ONs) for testing.
We also did not differentiateLNs and ONs in evaluation.
That is, we onlychecked the word boundaries of LNs and ONs andtreated both tags exchangeable.
The results areshown in Table 2.
We can see that in this small testset SCM achieves the best overall performance ofNER and the best performance of resolving OAS.8 ConclusionThe contributions of this paper are three-fold.
First,we formulate the Chinese word segmentationproblem as a set of correlated problems, which arebetter solved simultaneously, including wordbreaking, morphological analysis, factoid detectionand NER.
Second, we present a unified approach tothese problems using the improved source-channelmodels.
The models provide a simple statisticalframework to incorporate a wide variety of linguis-tic knowledge and statistical models in a unifiedway.
Third, we evaluate the system?s performanceon an annotated test set, showing very promisingresults.
We also compare our system with severalstate-of-the-art systems, taking into account the factthat the definition of Chinese words varies fromsystem to system.
Given the comparison results, wecan say with confidence that our system achieves atleast the performance of state-of-the-art word seg-mentation systems.ReferencesCheng, Kowk-Shing, Gilbert H. Yong and Kam-Fai Wong.1999.
A study on word-based and integral-bit Chinese textcompression algorithms.
JASIS, 50(3): 218-228.Chien, Lee-Feng.
1997.
PAT-tree-based keyword extraction forChinese information retrieval.
In SIGIR97, 27-31.Dai, Yubin, Christopher S. G. Khoo and Tech Ee Loh.
1999.
Anew statistical formula for Chinese word segmentation in-corporating contextual information.
SIGIR99, 82-89.Gao, Jianfeng, Joshua Goodman, Mingjing Li and Kai-Fu Lee.2002.
Toward a unified approach to statistical languagemodeling for Chinese.
ACM TALIP, 1(1): 3-33.Lin, Ming-Yu, Tung-Hui Chiang and Keh-Yi Su.
1993.
Apreliminary study on unknown word problem in Chineseword segmentation.
ROCLING 6, 119-141.Katz, S. M. 1987.
Estimation of probabilities from sparse datafor the language model component of a speech recognizer.IEEE ASSP 35(3):400-401.Packard, Jerome.
2000.
The morphology of Chinese: A Lin-guistics and Cognitive Approach.
Cambridge UniversityPress, Cambridge.Sproat, Richard and Chilin Shih.
2002.
Corpus-based methodsin Chinese morphology and phonology.
In: COOLING 2002.Sproat, Richard, Chilin Shih, William Gale and Nancy Chang.1996.
A stochastic finite-state word-segmentation algorithmfor Chinese.
Computational Linguistics.
22(3): 377-404.Sun, Jian, Jianfeng Gao, Lei Zhang, Ming Zhou andChang-Ning Huang.
2002.
Chinese named entity identifica-tion using class-based language model.
In: COLING 2002.Teahan, W. J., Yingying Wen, Rodger McNad and Ian Witten.2000.
A compression-based algorithm for Chinese wordsegmentation.
Computational Linguistics, 26(3): 375-393.Wu, Zimin and Gwyneth Tseng.
1993.
Chinese text segmenta-tion for text retrieval achievements and problems.
JASIS,44(9): 532-542.
