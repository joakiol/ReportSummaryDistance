Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 37?40,Suntec, Singapore, 3 August 2009. c?2009 ACL and AFNLPA NLG-based Application for Walking DirectionsMichael Roth and Anette FrankDepartment of Computational LinguisticsHeidelberg University69120 Heidelberg, Germany{mroth,frank}@cl.uni-heidelberg.deAbstractThis work describes an online applicationthat uses Natural Language Generation(NLG) methods to generate walking di-rections in combination with dynamic 2Dvisualisation.
We make use of third partyresources, which provide for a givenquery (geographic) routes and landmarksalong the way.
We present a statisticalmodel that can be used for generatingnatural language directions.
This modelis trained on a corpus of walking direc-tions annotated with POS, grammaticalinformation, frame-semantics and mark-up for temporal structure.1 IntroductionThe purpose of route directions is to inform aperson, who is typically not familiar with his cur-rent environment, of how to get to a designatedgoal.
Generating such directions poses difficul-ties on various conceptual levels such as theplanning of the route, the selection of landmarksalong the way (i.e.
easily recognizable buildingsor structures) and generating the actual instruc-tions of how to navigate along the route using theselected landmarks as reference points.As pointed out by Tom & Denis (2003), theuse of landmarks in route directions allows formore effective way-finding than directions rely-ing solely on street names and distance measures.An experiment performed in Tom & Denis?
workalso showed that people tend to use landmarksrather than street names when producing routedirections themselves.The application presented here is an early re-search prototype that takes a data-driven genera-tion approach, making use of annotated corporacollected in a way-finding study.
In contrast topreviously developed NLG systems in this area(e.g.
Dale et.
al, 2002), one of our key features isthe integration of a number of online resources tocompute routes and to find salient landmarks.The information acquired from these resourcescan then be used to generate natural directionsthat are both easier to memorise and easier tofollow than directions given by a classic routeplanner or navigation system.The remainder of this paper is structured asfollows: In Section 2 we introduce our systemand describe the resources and their integrationin the architecture.
Section 3 describes our cor-pus-based generation approach, with Section 4outlining our integration of text generation andvisualisation.
Finally, Section 5 gives a shortconclusion and discusses future work.2 Combining ResourcesThe route planner used in our system is providedby the Google Maps API1.
Given a route com-puted in Google Maps, our system queries anumber of online resources to determine land-marks that are adjacent to this route.
At the timeof writing, these resources are: OpenStreetMaps2for public transportation, the Wikipedia WikiPro-ject Geographical coordinates3 for salient build-ings, statues and other objects, Google AJAXSearch API4 for ?yellow pages landmarks?
suchas hotels and restaurants, and Wikimapia 5  forsquares and other prominent places.All of the above mentioned resources can bequeried for landmarks either by a single GPS1 http://code.google.com/apis/maps/2 http://www.openstreetmap.org3 http://en.wikipedia.org/wiki/Wikipedia:WikiProjectGeographical_coordinates4 http://code.google.com/apis/ajaxsearch5 http://www.wikimapia.org37coordinate (using the LocalSearch method inGoogle AJAX Search and web tools in Wikipe-dia) or an area of GPS coordinates (using URLbased queries in Wikimapia and OpenStreet-Maps).
The following list describes the data for-mats returned by the respective services and howthey were integrated:?
Wikimapia and OpenStreetMaps ?
Bothresources return landmarks in the queriedarea as an XML file that specifies GPScoordinates and additional information.The XML files are parsed using a Java-Script implementation of a SAX parser.The coordinates and names of landmarksare then used to add objects within theGoogle Maps API.?
Wikipedia ?
In order to integrate land-marks from Wikipedia, we make use of acommunity created tool called search-a-place 6 , which returns landmarks fromWikipedia in a given radius of a GPScoordinate.
The results are returned in anHTML table that is converted to an XMLfile similar to the output of Wikimapia.Both the query and the conversion are im-plemented in a Yahoo!
Pipe7 that can beaccessed in JavaScript via its URL.?
Google AJAX Search ?
The results re-turned by the Google AJAX Search APIare JavaScript objects that can be directlyinserted in the visualisation using theGoogle Maps API.3 Using Corpora for GenerationA data-driven generation approach achieves anumber of advantages over traditional ap-proaches for our scenario.
First of all, corpusdata can be used to learn directly how certainevents are typically expressed in natural lan-guage, thus avoiding the need of manually speci-fying linguistic realisations.
Secondly, variationsof discourse structures found in naturally givendirections can be learned and reproduced toavoid monotonous descriptions in the generationpart.
Last but not least, a corpus with good cov-erage can help us determine the correct selectionrestrictions on verbs and nouns occurring in di-rections.
The price to pay for these advantages is6 http://toolserver.org/~kolossos/wp-world/umkreis.php7 http://pipes.yahoo.com/pipes/pipe.info?_id=BBI0x8G73RGbWzKnBR50VAthe cost of annotation; however we believe thatthis is a reasonable trade-off, in view of the factthat a small annotated corpus and reasonablegeneralizations in data modelling will likelyyield enough information for the intended navi-gation applications.3.1 Data CollectionWe currently use the data set from (Marciniak &Strube, 2005) to learn linguistic expressions forour generation approach.
The data is annotatedon the following levels:?
Token and POS level?
Grammatical level (including annotationsof main verbs, arguments and connectives)?
Frame-semantics level (including semanticroles and frame annotations in the sense of(Fillmore, 1977))?
Temporal level (including temporal rela-tions between discourse units)3.2 Our Generation ApproachAt the time of writing, our system only makesuse of the first three annotation levels.
The lexi-cal selection is inspired by the work of Ratna-parkhi (2000) with the overall process designedas follows: given a certain situation on a route,our generation component receives the respectiveframe name and a list of semantic role fillinglandmarks as input (cf.
Section 4).
The genera-tion component then determines a list of poten-tial lexical items to express this frame using therelative frequencies of verbs annotated as evok-ing the particular frame with the respective set ofsemantic roles (examples in Table 1).SELF_MOTIONPATH17% walk, 13% follow, 10%cross, 7% continue, 6% take, ?GOAL18% get, 18% enter, 9% con-tinue, 7% head, 5% reach, ?SOURCE 14% leave, 14% start, ?DIRECTION25% continue, 13% make,13% walk, 6% go, 3% take, ?DISTANCE 15% continue, 8% go, ?PATH + GOAL 29% continue, 14% take, ?DISTANCE +GOAL100% walkDIRECTION +PATH23% continue, 23% walk,8% take, 6% turn, 6% face, ?Table 1: Probabilities of lexical items for the frameSELF_MOTION and different frame elements38For frame-evoking elements and each associatedsemantic role-filler in the situation, the gram-matical knowledge learned from the annotationlevel determines how these parts can be put to-gether in order to generate a full sentence (cf.Table 2).SELF_MOTIONwalk +[building PATH]walk ?
walk + PPPP ?
along + NPNP ?
the + buildingget +[building GOAL]get ?
get + to + NPNP ?
the + buildingtake +[left DIRECTION]take ?
take + NPNP ?
a + leftTable 2: Examples of phrase structures for the frameSELF_MOTION and different semantic role fillers4 Combining Text and VisualisationAs mentioned in the previous section, our modelis able to compute single instructions at crucialpoints of a route.
At the time of writing the ac-tual integration of this component consists of aset of hardcoded rules that map route segments toframes, and landmarks within the segment to rolefillers of the considered frame.
The rules arespecified as follows:?
A turning point given by the Google MapsAPI is mapped to the SELF_MOTION framewith the actual direction as the semanticrole direction.
If there is a landmark adja-cent to the turning point, it is added to theframe as the role filler of the role source.?
If a landmark is adjacent or within thestarting point of the route, it will bemapped to the SELF_MOTION frame withthe landmark filling the semantic rolesource.?
If a landmark is adjacent or within thegoal of a route, it will be mapped to theSELF_MOTION frame with the landmarkfilling the semantic role goal.?
If a landmark is adjacent to a route or aroute segment is within a landmark, therespective segment will be mapped to theSELF_MOTION frame with the landmarkfilling the semantic role path.5 Conclusions and OutlookWe have presented the technical details of anearly research prototype that uses NLG methodsto generate walking directions for routes com-puted by an online route planner.
We outlinedthe advantages of a data-driven generation ap-proach over traditional rule-based approachesand implemented a first-version application,which can be used as an initial prototype exten-sible for further research and development.Our next goal in developing this system is toenhance the generation component with an inte-grated model based on machine learning tech-niques that will also account for discourse levelphenomena typically found in natural languagedirections.
We further intend to replace the cur-rent hard-coded set of mapping rules with anautomatically induced mapping that alignsphysical routes and landmarks with the semanticrepresentations.
The application is planned to beused in web experiments to acquire further datafor alignment and to study specific effects in thegeneration of walking instructions in a multimo-dal setting.The prototype system described above will bemade publicly available at the time of publica-tion.AcknowledgementsThis work is supported by the DFG-financed in-novation fund FRONTIER as part of the Excel-lence Initiative at Heidelberg University (ZUK49/1).ReferencesDale, R., Geldof, S., & Prost, J.-P. (2002).
Generatingmore natural route descriptions.
Proceedings of the2002 Australasian Natural Language ProcessingWorkshop.
Canberra, Australia.Fillmore, C. (1977).
The need for a frame semanticsin linguistics.
Methods in Linguistics , 12, 2-29.Marciniak, T., & Strube, M. (2005).
Using anannotated corpus as a knowledge source forlanguage generation.
Proceedings of the Workshopon Using Corpora for Natural LanguageGeneration, (pp.
19-24).
Birmingham, UK.Ratnaparkhi, A.
(2000).
Trainable Methods forSurface Natural Language Generation.
Proceedingsof the 6th Applied Natural Language ProcessingConference.
Seattle, WA, USA.Tom, A., & Denis, M. (2003).
Referring to landmarkor street information in route directions: Whatdifference does it make?
In W. Kuhn, M. Worboys,& S. Timpf (Eds.
), Spatial Information Theory (pp.384-397).
Berlin: Springer.39Figure 1: Visualised route from Rohrbacher Stra?e 6 to Hauptstrasse 22, Heidelberg.
Left: GoogleMapsdirections; Right: GoogleMaps visualisation enriched with landmarks and directions generated by our system(The directions were manually inserted here as they are actually presented step-by-step following the route)Script OutlineOur demonstration is outlined as follows: At firstwe will have a look at the textual outputs ofstandard route planners and discuss at whichpoints the respective instructions could be im-proved in order to be better understandable oreasier to follow.
We will then give an overviewof different types of landmarks and argue howtheir integration into route directions is a valu-able step towards better and more natural instruc-tions.Following the motivation of our work, we willpresent different online resources that providelandmarks of various sorts.
We will look at theinformation provided by these resources, exam-ine the respective input and output formats, andstate how the formats are integrated into a com-mon data representation in order to access theinformation within the presented application.Next, we will give a brief overview of the cor-pus in use and point out which kinds of annota-tions were available to train the statistical gen-eration component.
We will discuss which otherannotation levels would be useful in this scenarioand which disadvantages we see in the currentcorpus.
Subsequently we outline our plans toacquire further data by collecting directions forroutes computed via Google Maps, which wouldallow an easier alignment between the instruc-tions and routes.Finally, we conclude the demonstration with apresentation of our system in action.
During thepresentation, the audience will be given the pos-sibility to ask questions and propose routes forwhich we show our system?s computation andoutput (cf.
Figure 1).System RequirementsThe system is currently developed as a web-based application that can be viewed with anyJavaScript supporting browser.
A mid-end CPUis required to view the dynamic route presenta-tion given by the application.
Depending on thepresentation mode, we can bring our own laptopso that the only requirements to the local organ-isers would be a stable internet connection (ac-cess to the resources mentioned in the systemdescription is required) and presentation hard-ware (projector or sufficiently large display).40
