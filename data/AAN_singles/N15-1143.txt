Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1305?1310,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsEstimating Numerical Attributesby Bringing Together Fragmentary CluesHiroya Takamura and Jun?ichi TsujiiTokyo Institute of Technology Microsoft Research Asiatakamura@pi.titech.ac.jp jtsujii@microsoft.comAbstractThis work is an attempt to automatically ob-tain numerical attributes of physical objects.We propose representing each physical objectas a feature vector and representing sizes aslinear functions of feature vectors.
We trainthe function in the framework of the com-bined regression and ranking with many typesof fragmentary clues including absolute clues(e.g., A is 30cm long) and relative clues (e.g.,A is larger than B).1 IntroductionWe know how large surfboards usually are and alsothat an inner pocket of any jacket is much smallerthan a surfboard.
Since we know about these nu-merical attributes, nobody of sound mind has prob-ably ever tried to vainly put a surfboard into an in-ner pocket of a jacket.
However, computers do nothave comprehensive knowledge of this sort.
Thislack of comprehensive knowledge of the numericalattributes is one obstacle to flexible and natural man-machine communication.
This work is an attemptto automatically obtain knowledge on numerical at-tributes so that computers can use it.The knowledge on numerical attributes is alsovery useful on many other occasions.
For exam-ple, it enables computers to alert their users whenthe users input incorrect numbers that are outside ofthe normal range of the attribute.
In image recogni-tion, a large red object will unlikely be recognized asa strawberry if the computer knows its normal size.In natural language processing, QA systems can usenumerical knowledge to eliminate the out-of-rangeanswer candidates to numerical questions.A number of attempts similar to the current workhave been made in some other fields such as psy-chology or fuzzy theory.
However, such attemptsheavily rely on costly experiments such as givingquestionnaires to human subjects and have a prob-lem in their scalability.
In contrast, the currentwork attempts to use NLP techniques on large textdata both online and offline in order to obtain suchknowledge without relying on costly experimentssuch as questionnaires.
A possible criticism of thisproject is that simply examining an existing knowl-edge source such as Wikipedia might accomplishthis purpose without much effort.
Indeed Wikipediaprovides numerical information of some physicalobjects, but not all.
For example, theWikipedia pagefor watches provides descriptions on their functionand their history, but no information on their size.Clues to the numerical attributes are rather scat-tered over corpora and other linguistic resources.
Ina corpus, we can find informative descriptions suchas ?X is 35cm tall?.
We can also find text fragmentssuggesting an order relation between two physicalobjects with regard to the size as in ?X is largerthan Y?, as well as implicit clues such as ?I put Xinto Y?, which usually means X is smaller than Y .Holonymy relations (X is a part of Y ) in a thesaurussuggest an order relation in size (X is smaller thanY ).
Glosses in a dictionary also provide subtle cluesto the sizes of entry words.
Each of these clues aloneis not sufficient for precisely determining the size,so we have to bring them together.
We have there-fore developed a mathematical model that uses these1305clues and determines the sizes of many physical ob-jects simultaneously.
The approach consists of twosteps: (i) many different types of clues to the numer-ical attribute are collected from various linguisticsresources, and (ii) those collected clues are broughttogether by a combined regression and ranking.2 Related WorkHovy et al (2002) pointed out the importance of theknowledge on the numerical attributes in questionanswering.
They hand-coded the possible range ofa numerical attribute.
Akiba et al (2004), Fujihataet al (2001), Aramaki et al (2007), and Bakalovet al (2011) made similar attempts.
Their target,however, is the fixed numerical attributes of thenamed entities, while our target is the numerical at-tributes of general physical objects, not restricted tothe named entities.Davidov and Rappoport (2010) collected varioustypes of text fragments indicating values of numer-ical attributes of physical objects.
Our work differsfrom theirs in that we explore more subtle linguisticclues in addition to those used in the previous work,by using a global mathematical model that brings to-gether all the clues.Narisawa et al (2013) tried to determine whethera given amount is large, small, or normal as a sizeof an object, making good use of clue words such asonly; The sentence ?This laptop weighs only 0.7kg?means that laptops are usually heavier than 0.7kg.3 Fragmentary clues to sizes3.1 Physical objectsWe first collect physical objects, i.e., objects forwhich the size can be defined.
However, the numeri-cal attribute of a word depends on the sense in whichthe word is being used.
We will therefore determinethe size of each sense instead of each word.
Specif-ically, we determine the size of each noun synset inthe Japanese WordNet (Bond et al, 2009).
We basi-cally regard as physical objects the synsets that aredescendants of the synset corresponding to ?physi-cal objects?
(00002684-n).
We filter out the physi-cal objects that are descendants of any of the follow-ing synsets ( 09334396-n, 00027167-n, 09239740-n,09287968-n, 09277686-n, 09335240-n, 04564698-n, and 03670849-n), since their sizes would be hardto define (e.g., earth, location, soil).We further filter out approximately 400 synsetsfor various reasons such as ambiguity.13.2 Collecting absolute cluesWe collect absolute clues, which indicate a value ofa physical object without reference to other physicalobjects.We used a search engine2with a query such as?
?the size ofA?
ANDmeter?
(AND represents a log-ical conjunction) and decompose the retrieved snip-pets into text fragments with ?...?
as a delimiter.We used only the first 1,000 pages (the maximumamount allowed by the terms of use for API users)for the query comprising a pattern (?the size of A?,?the length of A?, or ?the height of A?)
and a lengthunit (millimeter, centimeter, meter, or kilometer).Note that absolute clues are corpus-based.3.3 Collecting relative cluesWe also collect relative clues, which suggest a nu-merical order relation between two physical objects,i.e., A should be larger than B.
Note that holonymyand comparative sentences below are explicit rela-tive clues as opposed to implicit relative clues thatfollow.
Note also that holonymy is WordNet-basedwhile comparative sentences and implicit relativeclues are corpus-based.3.3.1 HolonymyIf A is a part of B, it usually means that Ais smaller than B.
We can obtain such part-of(holonymy) relations from the WordNet.
Specif-ically, for each physical object obtained in Sec-tion 3.1, we retrieve its holonymy synsets.
If asynset is a holonym of another synset, it suggeststhat the former is larger than the latter.3.3.2 Comparative sentencesThe sentence ?the middle finger is longer than thering finger?
suggests that the relation ?middle finger> ring finger?
holds for the size attribute.
We collectsuch comparative sentences.
Specifically, we search1The list of those synsets and textual patterns and Japanesesearch keywords used in this work are available fromhttp://www.lr.pi.titech.ac.jp/?takamura/core9.html .2Yahoo!JAPAN API.1306an n-gram corpus (Kudo and Kazawa, 2007) for thetextual patterns including ?A is longer than B?.33.3.3 Implicit relative cluesPeople tend not to write out clues explicitlywhen most readers are expected to have the relevantknowledge.
Since absolute clues and comparativesentences are explicit, we cannot expect a sufficientamount of such clues.We argue that people unintentionally put manypieces of common knowledge into some specific tex-tual patterns.
The sentence ?I put my wallet into thepocket?
suggests that ?pocket > wallet?
holds for thenumerical attribute.
We collect from the n-gram cor-pus such textual patterns (A in B, put A in B, takeA out of B, store A in B, put A on B, drop A fromB, A go into B, and A go out of B).4 Bringing together the clues4.1 Feature representation and linear modelTo bring together the clues introduced in Section 3,we first represent physical objects with feature vec-tors and employ a linear model in which the sizef(w,x) is represented as the inner product w ?
xof feature vector x and weight vector w.We use the following features: the synsets that areancestors of the target synset (i.e., synsets that can befound by traversing up through hypernym-hyponymrelations or instance-of relations), the synsets thatthe target synset is a member of (hmem inWordNet),the hypernym synsets of the target synset (hype inWordNet), the synsets that the target synset is an in-stance of (inst in WordNet), the synsets that the tar-get synset has as a component (mprt in WordNet),the synsets that the target synset is a component of(hprt in WordNet), the head word in the gloss in adictionary, and the synonyms in the target synset.4.2 FormalizationWe discuss how to estimate weight vectorw.Some physical objects are given absolute clues.
Ifmultiple absolute clues are found for an object, weregard their average (actually, its logarithm) as theapproximate size used for training.
Since the sizeis a real number, the machine learning frameworkto be employed should be regression.
Additionally,3We also used ?shorter?, ?larger?, and ?smaller?.relative clues are incorporated into the training bymeans of ranking framework.
We henceforth use thecombined regression and ranking.Our formalization is similar to the combined re-gression and ranking model developed by Scul-ley (2010).
Let Daand Drdenote respectively thetraining datasets consisting of absolute clues and rel-ative clues.
Each element in Dais represented as apair of a feature vectorx and its average size y. Eachelement in Dris represented as a tuple of featurevectors x1and x2, and the order relation z; z indi-cates whether x1is larger (z = +1), or x2is larger(z = ?1).
We minimize the following function:(1 ?
?
)La(w, Da) + ?Lr(w, Dr) +?2||w||2, (1)where ?
is a trade-off parameter between regres-sion loss La(w, Da) and pairwise loss Lr(w, Dr).
(?/2)||w||2is the regularization term.The regression loss La(w, Da) is decomposed as1|Da|?
(x,y)?Dala(y, f(w,x)), (2)where la(y, f(w,x)) is the loss of the pair (x, y)under the model w, and is represented by squaredloss (y ?
f(w,x))2, indicating the difference be-tween the target value and the model output.The pairwise loss Lr(w, Dr), is decomposed as1|Dr|?
(x1,x2,z)?Drlr(z,x1,x2,w), (3)where lr(z,x1,x2,w) is the loss of the tuple(x1,x2, z) under the model w, and is representedby hinge loss, max(0, 1 ?
z ?
f(w,x1?
x2)).While a single type of loss function was used forthe regression loss and the pairwise loss in the pre-vious work (Sculley, 2010), the current frameworkrelies on two different types of loss functions, i.e.,squared loss and hinge loss, so that both absoluteand relative clues can be used in the model.5 Experiments5.1 Experimental settingWe followed the process in Section 3.1 and elimi-nated infrequent ones from the obtained synsets.
For1307the remaining synsets, we performed a search for ab-solute and relative clues and obtained 1,329 abso-lute clues and 7,335 relative clues.
This set of rela-tive clues stems from 848 WordNet-based clues and6,496 corpus-based clues with a small overlap.
Wenote that fewer than 1% of these 6,496 corpus-basedclues are explicit.
The synsets for which no cluesare found are removed from the following process,leaving 3,598 synsets.
Thoroughly using the webdata might provide a larger overall amount, but thecurrent result suggests that there are fewer absoluteclues than relative ones and fewer explicit clues thanimplicit ones.We evaluate the methods in two different ways.One is the difference: the sizes of the 262 randomlysampled synsets without absolute clues are manu-ally determined, and we calculated the differencebetween the estimated size and the manually deter-mined size for each of those synsets.
The other isthe order relation classification: the size relations of1,152 randomly sampled pairs of synsets are manu-ally annotated, and we employ as an evaluation met-ric the accuracy indicating how many of those rela-tions are correctly predicted.We implemented our combined regression andranking method by modifying a package.4We usedthe logarithms of sizes as the target value.
We tuned?
in Equation (1) to the value that optimizes the ac-curacy out of 11 values5: 10?7, 10?6, ?
?
?
, 103.We tested different numbers of absolute clues intraining (namely, 300, 500, 800, 1,000) in order toexamine its effect.5.2 ResultsFigure 1 shows how the average difference for eachnumber of absolute clues changes as ?
in Equa-tion (1) is varied.
All types of clues and featuresare used for Figure 1 (a), while the clues and fea-tures extracted from WordNet except for glosses areexcluded for Figure 1 (b).
The latter emulates thesituation where the dictionary is available, but thelarge-scale thesaurus such as WordNet is not.
Theleft-most point (?
= 0) for each figure correspondsto simple regression.
The curves show that the dif-ference can be reduced by using the combined re-4http://code.google.com/p/sofia-ml/5In the actual application, we would be able to use develop-ment data for tuning.Size (cm) Synset Example word1.35?10?111678768-n ovum2.68?10002312744-n silkworm3.26?10002206856-n bee7.16?10004453037-n tooth of gear9.09?10003209910-n floppy disk1.14?10103378442-n foot3.01?10104586225-n wind chime3.35?10103485794-n hand towel4.57?10104590553-n windshield1.56?10209189157-n nest of hawk or eagle1.65?10204152829-n screen4.31?10402687992-n airportTable 1: Sample of the estimated sizesgression and ranking.
The improvement is more re-markable when fewer absolute clues are used.Similarly, Figure 2 shows how the accuracy of theorder relation classification for each number of ab-solute clues changes as ?
is varied.
The accuracyof the order relation classification was around 70to 80 %.
The benefit of using combined regressionand ranking is more remarkable in Figure 2 (b), i.e.,when the thesaurus is not available.Table 1 shows a sample of physical objects andtheir estimated sizes.
We can see that the overalltrend of the size has been successfully captured.We also examine some features with small orlarge weights in Table 2.
Very small weights aregiven to, for example, elementary particles in thefield of particle physics, hydrons, and bacteria.6Feature WeightSynset for baryon, as ancestor -7.75Hydron as synonym -7.75Synset for fermion, as ancestor -7.13Electron, as synonym -6.06Bacteria, as synonym -6.06Bell tower, hprt feature +7.15Railroad as synonym, +8.16Means of transportation as ancestor +8.38Table 2: Features with large absolute weights.
Note thatbaryon is a heavy particle in the field of particle physics.6More comprehensive results are available fromhttp://www.lr.pi.titech.ac.jp/?takamura/core9.html .13083.33.43.53.63.73.83.94.04.14.24.30  0.02  0.04  0.06  0.08  0.10AveragedifferenceAlpha30050080010004.04.24.44.64.85.05.25.40  0.02  0.04  0.06  0.08  0.10AveragedifferenceAlpha3005008001000(a) All types of clues and features are used (b) WordNet-based clues and features areexcluded except for the glossesFigure 1: Average difference between the estimated size and the manually determined size (log of centimeter).74757677787980810  0.02  0.04  0.06  0.08  0.10Accuracy(%)Alpha3005008001000666768697071727374750  0.02  0.04  0.06  0.08  0.10Accuracy(%)Alpha3005008001000(a) All types of clues and features are used (b) WordNet-based clues and features areexcluded except for the glossesFigure 2: Accuracy of order relation classification6 ConclusionWe addressed the task of automatically extractingnumerical attributes of physical objects.
We proposerepresenting the sizes of objects using a linear func-tion.
We used the combined regression and rankingmodel with both absolute and relative clues.Currently, many features are extracted from a the-saurus WordNet.
If we can extract effective featuresfrom other resources, we would be able to apply ourmethod to the objects that are not in the thesaurus.Future work also includes the following:?
more accurately collecting physical objects,?
sense disambiguation of words in clues,?
use of superlative sentences,?
filtering out descriptions of rare events,?
a more effective way of using glosses,?
application to other attributes, e.g., weight,?
handling idioms.AcknowledgmentThis work was partially supported by Microsoft Re-search (CORE Project 9).1309ReferencesTomoyosi Akiba, Katunobu Itou, and Atsushi Fujii.2004.
Question answering using common sense andutility maximization principle.
In Proceedings of theFourth NTCIR Workshop on Research in InformationAccess Technologies Information Retrieval, QuestionAnswering and Summarization, pages 297?303.Eiji Aramaki, Takeshi Imai, Kengo Miyo, and KazuhikoOhe.
2007.
UTH: SVM-based semantic relation clas-sification using physical sizes.
In Proceedings of the4th International Workshop on Semantic Evaluations,SemEval ?07, pages 464?467, Stroudsburg, PA, USA.Association for Computational Linguistics.Anton Bakalov, Ariel Fuxman, Partha Pratim Talukdar,and Soumen Chakrabarti.
2011.
SCAD: Collectivediscovery of attribute values.
In Proceedings of the20th International Conference on World Wide Web(WWW?11), pages 447?456.Francis Bond, Hitoshi Isahara, Sanae Fujita, KiyotakaUchimoto, Takayuki Kuribayashi, and Kyoko Kan-zaki.
2009.
Enhancing the japanese wordnet.
In Pro-ceedings of the 7th Workshop on Asian Language Re-sources (in conjunction with ACL-IJCNLP 2009).Dmitry Davidov and Ari Rappoport.
2010.
Extractionand approximation of numerical attributes from theweb.
In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics, pages1308?1317.Katsuyuki Fujihata, Masahiro Shiga, and Tatsuro Mori.2001.
Extraction of numerical expressions by con-straints and default rules of dependency structure.
InSpecial Interest Group of Information Processing So-ciety of Japan, 2001-NL-145 (in Japanese).Eduard Hovy, Ulf Hermjakob, Chin-Yew Lin, andDeepak Ravichandran.
2002.
Using knowledge to fa-cilitate factoid answer pinpointing.
In Proceedings ofthe 19th International Conference on ComputationalLinguistics, pages 369?375.Taku Kudo and Hideto Kazawa.
2007.
Japanese webn-gram corpus, version 1.Katsuma Narisawa, Yotaro Watanabe, Junta Mizuno,Naoaki Okazaki, and Kentaro Inui.
2013.
Is a 204cm man tall or small?
acquisition of numerical com-mon sense from the web.
In Proceedings of the 51stAnnual Meeting of the Association for ComputationalLinguistics (ACL 2013), pages 382?391.David Sculley.
2010.
Combined regression and rank-ing.
In Proceedings of the 16th ACM SIGKDD inter-national conference on Knowledge discovery and datamining, KDD ?10, pages 979?988, New York, NY,USA.
ACM.1310
