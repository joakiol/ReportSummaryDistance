TOWARD A COMPUTATIONAL THEORY OF SPEECH PERCEPTIONJonathan AllenResearch Laboratory of Electronics & Dept.
of Electrical Engineering and Computer ScienceMassachusetts Institute of Technology, Cambridge, MA 02139ABSTRACTIn recent years,a great deal of evidence has been collec-ted which gives substantially increased insight into thenature of human speech perception.
It is the author'sbelief that such data can be effectively used to infermuch of the structure of a practical speech recognitionsystem.
This paper details a new view of the role ofstructural constraints within the several structural do-mains (e.g.
articulation, phonetics, phonology, syntax,semantics) that must be utilized to infer the desiredpercept.Each of the structural domains mentioned above has a sub-stantial "internal theory" describing the constraintswithin that domain, but there are also many interactionsbetween structural domains which must be considered.Thus words llke "incline" and "survey" shift stress withsyntactic role, and there is a pragmatic bias for theambiguous sentence "John called the boy who has smashedhis car up."
to be interpreted under a strategy thatreflects a tendency for local completion of syntacticstructures.
It is clear, then, that while analysiswithin a structural domain (e.g.
syntactic parsing) canbe performed up to a point,lnteraction with other domainsand integration of constraint strengths across thesedomains is needed for correct perception.
The variousconstraints have differing and changing strengths atdifferent points in an utterance, so that no fixed metriccan be used to determine their contribution to the well-formedness of the utterance.At the segmental level, many diverse cues for segmentalfeatures have been found.
As many as 16 cues mark thevoicing distinction, for example.
We may think of eachof these cues as also representing a constraint, and thestrength of the constraint varies with the context.
Forexample, stop closure duration must be interpreted in thecontext of the local rate of speech, and a given valueof closure duration can signify either a voiced or anunvoiced stop depending on the surrounding vowel dura-tions.
Thus several cues must be integrated to obtainthe perceived segmental feature, and the weights assignedto each cue vary with the local context.From the preced ing  examples,  i t  i s  seen that  in order  tomodel human speech percept ion ,  i t  i s  necessary  to dyna-mica l ly  in tegrate  a wide var ie ty  of const ra in ts .
Theev idence argues  s t rong ly  for  an ac t ive  focussed search ,whereby the perceptua l  mechanism knows, as the u t te ranceunfolds, where the strongest constraint strengths are,and uses this reliable information, while ignoring"cues" that are unreliable or non-determining in theimmediate context.
For example, shadowing experimentshave shown that listeners (performing the shadowingtask) can restore disrupted words to their original formby using semantic and syntactic context, thus demonstra-ting the integration process.
Furthermore, techniquesare now available for analytically finding that infor-matlon in an input stimulus which can maximally discri-mlnate between two candidate prototypes, so that theperceptua l  control structure can focus only on suchinformation co make a choice between the candidates.In this paper, we develop a theory for speech recogni-tion which contains the required dynamic integrationcapability coupled with the ability to  focus on a res-tricted set  o f  cues wh ich  has been contextua l lyse lec ted .The model of speech recogn i t ion  which we have developedrequires, of course, an initial low-level analysis ofthe speech waveform to get  s ta r ted .
We argue from therecent  psycho l lngu is t i c  l i te ra ture  that  s t ressedsy l lab les  prov ide  the requ i red  ent ry  po in ts .
S t ressedsy l lab le  peaks can be read i ly  located ,  and use of thephonotactics of segmental distribution within syllables,together with the relatively clear articulation ofsyllable-initial consonants, allows us to formulate arobust procedure for determining initial segmental"islands", around which further analysis can proceed.In fact, there is evidence to indicate that the humanlexicon is organized and accessed via these  stressedsyllables.
The restriction of the original analysis tothese stressed syllables can be regarded as another formof focussed search, which in turn leads to additionalsearches dictated by the relative constraint strengthsof the various domains contributing to the percept.
Weargue that these views are not only consonant with thecurrent knowledge of human speech perceptlon, but formthe proper basis for the design of hlgh-performanceSpeech recognition systems.17
