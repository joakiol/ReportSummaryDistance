Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 577?584Manchester, August 2008Applying Discourse Analysis and Data Mining Methods toSpoken OSCE AssessmentsMeladel Mistica, Timothy BaldwinThe University of MelbourneCSSE{mmistica,tim}@csse.unimelb.edu.auMarisa Cordella, Simon MusgraveMonash UniversitySchool of Languages, Cultures and Linguistics{marisa.cordella,simon.musgrave}@arts.monash.edu.auAbstractThis paper looks at the transcribed data ofpatient-doctor consultations in an exami-nation setting.
The doctors are interna-tionally qualified and enrolled in a bridg-ing course as preparation for their Aus-tralian Medical Council examination.
Inthis study, we attempt to ascertain if thereare measurable linguistic features of theconsultations, and to investigate whetherthere is any relevant information aboutthe communicative styles of the qualify-ing doctors that may predict satisfactoryor non-satisfactory examination outcomes.We have taken a discourse analysis ap-proach in this study, where the core unit ofanalysis is a ?turn?.
We approach this prob-lem as a binary classification task and em-ploy data mining methods to see whetherthe application of which to richly anno-tated dialogues can produce a system withan adequate predictive capacity.1 IntroductionThis paper describes our experimentation with ap-plying data mining methods to transcribed doctor?patient consultations.
It is in essence a discoveryproject: we apply methods to a field and task thatis not ordinarily associated with such approachesin order to ascertain whether this could make for atractable learning task.The task involves the extraction of dis-course features from doctor?patient consultationsperformed by international medical graduatesc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.
(IMGs), and what is known as ?simulated pa-tients?
(Vu et al, 1994), respectively.
The IMGsare enrolled in a bridging course in Melbourne aspreparation for their Australian Medical Council(AMC) examination, the successful completion ofwhich is one of the pre-requisites to becoming afully accredited practitioner in Australia.
This par-tially replicates the AMC examination by studyingin detail how IMGs perform two objective struc-tured clinical examinations (OSCEs).
See Sec-tion 2 for full details of the examination environ-ment and participants involved.The main questions raised when initiating thisstudy were:?
How objective is the testing??
What is the importance placed on languageskills in OSCE environments??
What makes for a successful OSCE?In this research, we aim to build classifiersthat make reasonable predictions of the data beingtested, and possibly point us in the right directionwith respect to the questions above.
From the clas-sifiers we build, we also hope to ascertain which ofour features best predict a successful examination.We organise the paper as follows.
In Section 2,we briefly describe the examination environmentand process, the marking scheme, and the partic-ipants involved in the testing of the IMGs.
Wealso outline some of the issues that have arisenwith regard to the current methods of IMG testing.In Section 3, we present details of the data used.Section 4 describes the features we develop for thetask and discusses the reasoning behind the selec-tion of features from a discourse analysis perspec-tive.
Section 5 discusses the results of the exper-iments, with further examination of the data.
The577last two sections, Sections 6 and 7, comprise a dis-cussion of the results and concluding remarks.2 BackgroundWith Western nations becoming increasingly re-liant on medical professionals trained overseas,there is, in turn, a growing need to develop a re-liable means of objectively assessing IMGs.
Theshortage of medical doctors is a worldwide phe-nomenon currently affecting many Western so-cieties such as the UK, Canada, US and NewZealand, which compete for the best medical prac-titioners available around the world.
Australia isnot immune to this global phenomenon, and inthe last two decades the shortage of local medi-cal practitioners in Australia has worsened (Bir-rell et al, 2004).
Challenges to the healthcaresystem in the country are particularly evident inthe areas of providing medical care for a grow-ing elderly population and of servicing rural ar-eas, where locally trained doctors do not feel par-ticularly attracted to practise medicine (Han et al,2006).
Currently 35% of the rural medical work-force and 20% of the total national medical work-force consist of IMGs (Flynn, 2006).
These figuresmay increase even further in some regions (Spike,2006), as preparation of fully educated and trainedlocal medical graduates takes up to thirteen yearsto complete.There is considerable disparity among IMGs intheir background training, clinical skills, under-standing of the health system and communicationskills (McGrath, 2004).
In order to be registeredto practice in Australia, IMGs must successfullycomplete the Australian Medical Council exami-nations and a period of supervised training.
Themedical knowledge of IMGs is assessed in twoways: by multiple choice examinations and byclinical examinations.
This second form of ex-amination consists of a series of simulated medi-cal consultations in which a role-player takes thepart of the patient, and the IMG?s professionalknowledge, lay-cultural knowledge, socio-culturalassumptions, institutional norms, and values andpersonal experiences are all in full display duringthe unfolding of the medical event (Roberts et al,2003).
Whenever cultural factors are not sharedwith their patients, the interpretative schema andtherefore the comprehension of speech are affectedby this lack of commonality in the participants?inferences and contextual cues (Gumperz, 1999).Such effects are likely to cause miscommunica-tion in medical visits and have a potential nega-tive effect on patients?
satisfaction in the consul-tation.
Identification of the communication diffi-culties faced by IMGs can therefore inform mod-ifications to the training provided to IMGs whenthey prepare for the Australian Medical Councilexaminations, as well as suggesting more nuancedand targeted procedures for assessing communica-tive skills within those examinations, all with thegoal of working toward a better equipped medicalworkforce for the future.
The use of automated an-alytic procedures to try to establish objective crite-ria for communicative success is an important stepin this process.Assessing language knowledge and competencequantitatively is not a novel concept in second lan-guage learning assessment.
However, the applica-tion of data mining methods to automatically as-sess language proficiency in a discourse setting isnovel.
Levow et al (1999) propose an architec-ture to automatically assess language proficiency.In their paper, they propose an architecture thatemploys data mining methods, but do not buildclassifiers over their spoken data to test this pro-posal.
A closely related line of research is on theautomatic classification of discourse elements toassess the quality of a written genre (Burstein etal., 2001).
Like this work, it focuses on extractingfeatures from the discourse as a whole.
But unlikethis study, the authors extract high level features,such as rhetorical structure, of written discourse.The study we present in this paper is rather uniquein its approach to language assessment.3 DataThe data is taken from transcribed recordings ofexaminations from students enrolled in a bridg-ing course at Box Hill Hospital in Melbourne,Australia.
Each candidate was video-recorded en-acting medical consultation scenarios with whatis known as a standardised or simulated patient(SP).
This method of testing is known as an ob-jective structured clinical examination (OSCE),which is an emulation of a doctor?patient consul-tation, much like a role-play setting.In this study, the role of the patient (SP) is en-acted by a qualified doctor who follows a script,and has well-defined ailment(s) and accompanyingconcerns.
Even though the SP assumes the sameailment and disposition with all the candidates, the578interaction between the candidate and the SP is un-cued and free-form.
They simply present the infor-mation in a standardised manner across all candi-dates and perform the role of the patient as felici-tously as possible.For this set of examinations there are 2 types ofOSCE stations referred to as STD (sexually trans-mitted disease ?
genital herpes) and BC (bowelcancer).
The SP for the STD station is played bya female doctor.
The patient she plays has genitalherpes and is concerned about how this will affecther chances of falling pregnant, and how this con-dition may also affect her baby.
The SP for the BCstation is played by an older male.
A tumour isdiscovered in his bowel lining and he is reluctantto undergo any treatment because one of his goodfriends suffered a similar condition and his qualityof life was severely diminished.Even though the consultation is free to be nego-tiated between doctor (candidate) and patient (sim-ulated patient), each of the OSCEs cannot exceed8 minutes, and is terminated by the examiner if itdoes so.3.1 TranscriptionThe recordings are transcribed in ELAN, a multi-media annotation tool developed at theMax PlanckInstitute, to help encode low-level linguistic fea-tures such as overlapping and timing information.The information and features extracted from thediscourse are largely based on a ?turn?.Here we consider a turn as being normally domi-nated by one speaker.
It can be made up of multipleintonation units.
When there is backchannelling,overlapping, or any interruption by the other par-ticipant, then the turn is encoded as ending at theend of the interrupted intonation unit.
Otherwise,transition pauses commonly signal turn changes,unless latching occurs.Given that the OSCE setting aims to emulateas close as possible a real medical consultation,this interaction, like all uncued spoken dialogues,also has evidence of complicated turn-taking ne-gotiations, disfluent and unintelligible speech, in-terrupted speech, challenges for the floor, and thelike, all of which must be encoded and noted inELAN.
Transcribing such data is not a trivial mat-ter.
In addition, transcribing the data in order toextract these features is also a demanding task initself, which makes creating data for such tasks aninvolved process.Disfluencies and repairs are encoded in a limitedway, only by way of marking up truncated or un-finished words.
We also do not take a fine-grainedapproach in encoding delaying strategies (Clark etal., 2002), that is we do not differentiate whetherthe uh or ah encoded represents lexical search, awish to hold the floor, a wish to give up the flooror buying time to construct what to say next.3.2 OSCE scoringIn an OSCE setting, candidates are given an over-all pass or fail rating for each station by an OSCEexaminer observing the interaction.
This overallevaluation can be based on a number of perfor-mance criteria which tests the candidates medical,clinical and communication skills (Grand?Maisonet al, 1992).
The OSCE marking scheme used forthis study consists of 5 assessable categories, asfollows:APPROACH: the ability of the candidate to com-municate with the patient;HISTORY: the ability of the candidate to collectmedical history;INTERPRETATION: how well does the candidateinterpret his or her investigation in order toformulate an appropriate diagnosis;MANAGEMENT: how well does the candidateformulate a management plan for the diagno-sis;COUNSELLING: is the candidate able to give ap-propriate counselling to the patient.The first category tests language knowledge andcompetency both at the lexical and discourse level,while the remaining four categories test medicalknowledge and clinical competency.4 Feature EngineeringWe extracted a total of 38 features from the tran-scribed data.
Some of these features are based onwhat is marked up according to the transcriptionscheme, while others are based on timing informa-tion or lexical information as encoded in ELAN.These include features such as signals for delayingspeaking or hesitation (Clark et al, 2002), featuresof conversational dominance (Itakura, 2000), themanner in which turn-taking is negotiated (Sackset al, 1974), temporal features such as pausing (tenBosch et al, 2005), as well as our own features,579which include ?lexical introduction?, and ?lexicalrepeat?.In encoding features of conversationaldominance, we focus on participatory domi-nance (Itakura, 2000), which looks at whichspeaker contributes most to the dialogue in termsof content.Lexical introduction refers to a non-stop wordthat is introduced by the doctor (IMG) or the pa-tient (SP), while lexical repeat encodes how manytimes a word introduced by the other interlocutoris repeated by the speaker.Almost all of the features developed are contin-uous, based on timing information or word counts.The only binary feature used encodes whether thedoctor initiates the consultation or not.As mentioned in the previous section, the fea-tures developed were largely based on turns.
Thisis to capture, along with other features such asoverlapping and pauses, the interactional aspect ofthe communication.
For example, conversationalcooperation and speaker reassurance can be cap-tured with these features.
Another aspect to thedevelopment of these features, particularly for thelexical-based features, is whether the IMG has asuitable vocabularly and if they employ it appro-priately in the interaction.We arrive at 11 feature sets from which we buildour classifiers, as described in Table 1.Not all features are exclusive to any one featureset, that is, it is possible for a single feature to be-long to a number of feature sets.The sets were designed to isolate possible char-acteristics of not only the discourse as a whole, buthow the participants negotiated their interaction.These features sets were developed from observ-ing each of the consultations with the expectationthat these were salient and determining features ofa successful examination.5 ExperimentsThere was a total of 11 OSCE candidates, all ofwhom performed an STD and a BC station, giv-ing us in total 22 instances for this binary classi-fication task to predict a pass or fail examinationresult.
Of the 22 instances, we had 5 failures and17 passes.
Given the small number of instances,we maximised our dataset by employing 10-foldstratified cross-validation, as well as leave-one-outcross-validation which uses all but one instance intraining and the held-out instance for testing.Feature set Example featuresall - all 38 featurescooperation - overall word count- length of interaction- number of turnshesitation - number of uh and ah- number of unfinished wordsoverlap - number of overlapping words- length of overlap (time)pause - transition pauses- within turn pausestimeBased - all time-based featuresturns - all turn-based features- number of turns- longest turn- single word responsesuniqNrepeat - number of introduced contentwords by each speaker- number of times speakeruses word introduced by otherwordBased - number of words in dialogue- longest number of wordsin a turnpatient - all SP-based featuresdoctor - all IMG-based featuresTable 1: The 11 feature sets developedThe baseline system we use for comparison iszero-R, or majority vote.
For our supervised clas-sifier, we employ a lazy learner in the form of theIB1 algorithm implemented in WEKA.5.1 Results for Feature SetsOur initial classifiers held some promise.
The clas-sifier built from all of the features was equivalentto the baseline system, and the combination of theword-based features surpassed the baseline?s re-sults, as shown in Table 2.To evaluate our system, we employ simple clas-sification accuracy, in addition to precision, recalland F-score.
Classification accuracy is the propor-tion of correct predictions by the classifier, irre-spective of class.
Precision gauges how successfulthe pass predictions of a given classifier are, whilerecall gives us an indication of how successful agiven classifier is at identifying the candidates whoactually passed.
Finally, F-score is a composite ofprecision and recall, and gives us an overall perfor-mance rating relative to passed candidates.The least successful classifier was built on the58010-fold cross validation Leave-one-out cross validationFeature set Accuracy Precision Recall F-score Accuracy Precision Recall F-scorebaseline .773 .773 1.00 .872 .773 .773 1.00 .872all .773 .773 1.00 .872 .773 .773 1.00 .872cooperation .682 .789 .824 .806 .682 .778 .824 .800hesitation .636 .737 .824 .778 .636 .737 .824 .778overlap .773 .833 .882 .857 .773 .833 .882 .857pause .682 .778 .824 .800 .727 .789 .882 .833timeBased .500 .647 .688 .667 .545 .706 .706 .706turns .727 .789 .882 .833 .727 .789 .882 .833uniqNrepeat .636 .765 .765 .765 .682 .778 .824 .800wordBased .864 .850 1.00 .919 .864 .850 1.00 .919patient .727 .867 .765 .813 .727 .867 .765 .813doctor .733 .800 .941 .865 .727 .789 .882 .833Table 2: Classification results for STD and BCfeature set based on timing, which contains in-formation such as the overall length of the dia-logue, the overall length of transition pauses, in-turn pauses and other time-based features.
Thiswas most surprising because as a general observa-tion, candidates who allowed extended pauses anduncomfortable silences were those who seemed toperform poorly, and those who did not leave toomany silences, and could maintain the flow of thedialogue, seemed to perform well.Given the small number of training instanceseach classifier is based on, these first results weresomewhat encouraging.
With respect to the base-line, the overall performance of two of the sys-tems equalled or surpassed the baseline in termsof F-score.
Most of the classifiers performed wellin terms of precision but less well in terms of re-call, i.e.
when the classifiers predicted a pass theywere generally correct, but there were significantnumbers of candidates who were predicted to havefailed but passed in practice.5.2 Data Introspection RetrospectivelyAlthough the results show promise, it was ex-pected that more of the feature sets would returnmore favourable results.
The possible reasons whythe time-based features, and many of the other fea-ture sets developed, did not perform as well as ex-pected may have been because the features used inbuilding the classifiers could have been combinedin a better way, or because the data itself had toomany anomalies or was too disparate.
We wouldexpect that extra data could iron out such anoma-lies, but developing additional data is expensiveand more recordings are not always available.
Theadvantage of having a small dataset is that we areable to do fine-grained annotation of the data, butthe obvious disadvantage is that we cannot easilygenerate extra amounts of training data.One very noticeable feature of the OSCE sta-tions was that the STD SP had a very differentcommunicative style to that of the the BC SP.Based on this observation we conducted tests giventhe hypothesis that the possible bias in the datacould have stemmed from having two very differ-ent testing approaches from the two SPs.
In gen-eral, the BC SP was more leading and in a sensemore forgiving with the candidates.
In contrast tothis, the STD SP tended to be more felicitous inher role as a patient, allowing awkward silencesand not prompting the candidates for further ex-ploration.We conduct the Mann-Whitney test, a rank sumtest, over the data in order to diagnose whether thepoor results were due to the distribution of the dataor whether the classifiers built with the selectedfeatures were simply poor predictors.
The Mann-Whitney test ascertains whether there is a differ-ence in the population mean of the two samplesgiven, without making any assumptions about thedistribution of the data.We sub-sample the data in two ways in exam-ining its homogeneity: (a) FAIL juxtaposed withPASS candidates; and (b) BC juxtaposed with STDstations.
Test (a) essentially tests which exam-inable category contributes the most to a pass orfail outcome, whilst test (b) examines whetherthere is an inherent difference in the way the test-581Category OVERALL APPROACH HISTORY INTERPRETATION MANAGEMENT COUNSELLINGz-score 1.84 1.21 -0.03 2.53 0.85 1.64Table 3: Mann-Whitney z-score for BC and STD samples (OVERALL is the cumulative total of all 5categories)Category OVERALL APPROACH HISTORY INTERPRETATION MANAGEMENT COUNSELLINGz-score -3.29 -3.13 -2.43 -2.31 -2.31 -1.57Table 4: Mann-Whitney z-score for failed and passed samplesing was conducted between the BC and STD sta-tions.BC vs. STDWe use the ranking from the 5 assessable cate-gories outlined in Section 3 and obtain the Mann-Whitney z-score for each category.
The z-scoregives us an indication of how disparate the twoseparated datasets, BC and STD, are.
The furtheraway from 0 the z-score is, the greater the evidencethat BC and STD data are not from the same pop-ulation, and should be treated as such.
The resultsof this test, as seen in Table 3, show that these twogroups differ quite markedly: the candidates wereconsistently marked differently for all assessablecategories except HISTORY.
This is a striking pe-culiarity because each candidate was tested in boththe STD and BC stations.Based on the above, we can posit that the dis-tinct testing styles of the STD and BC SPs werethe reason for our original lacklustre results, andthat the two data samples need to be treated sepa-rately for the classifiers to perform consistently.FAIL vs. PASSIn addition to the BC vs. STD test, we also testhow the failing candidates differ from the passingcandidates across the evaluation criteria.The main idea behind this test is to see whichof the assessable categories contributed the mostin the overall outcome of the examination.
For thistest, we would not expect the absolute z-score ofany of the assessment components to exceed theabsolute z-score of the OVERALL category giventhat it is the cumulative scores of all categories.The results in Table 4 suggest that APPROACHcorrelates most highly with the pass/fail dividein the OSCE assessments, followed by HISTORY,then INTERPRETATION and MANAGEMENT, andfinally COUNSELLING.
Recall that APPROACH isthe component that assesses language and commu-nication skills.
In particular, it assesses the styleand appropriateness of the way candidates con-vey information, from lexical choice to display-ing empathy through communication style.
Giventhat APPROACH correlates most strongly with theassessment result, the decision to focus our fea-ture engineering efforts on linguistic aspects of thedoctor?patient interaction would appear justified.5.3 Results for STD & BC DataGiven the results from the Mann-Whitney tests re-ported in the previous section, we separate the datainto two lots: those from the STD station, andthose from the BC station.Even though there were very few instances inthe original dataset, we aim to see in these experi-ments whether this separation improves the perfor-mance of the classifiers.
We build classifiers overeach dataset using the same features as before.The results of the tests performed over the sep-arated datasets, as shown in Table 5, show a bigimprovement over the baseline for STD, while theBC dataset is more problematic.In the STD group, we see that four feature sets,all, turns, wordBased and patient equal or surpassthe baseline F-score.In contrast to this, upon examination of theperformance of the classifiers built over the BCdataset, we do not observe any improvements overthe baseline and the results are markedly worsethan those for the combined dataset.
Having saidthis, when we combine the outputs of the two com-ponent classifiers, the F-score for all features is0.882, an improvement over the original combinedsystem.6 DiscussionThe OSCE assessment does not merely examinethe language skills of the candidates, but it also as-582BC STDFeature Set Accuracy Precision Recall F-score Accuracy Precision Recall F-scorebaseline .818 .818 1.00 .900 .727 .727 1.00 .842all .727 .875 .778 .824 .909 .889 1.00 .941cooperation .727 .800 .889 .842 .364 .571 .500 .533hesitation .636 .778 .778 .778 .636 .700 .875 .778overlap .727 .800 .889 .842 .636 .700 .875 .778pause .818 .889 .889 .889 .545 .667 .750 .706timeBased .636 .857 .667 .750 .545 .667 .750 .706turns .636 .778 .778 .778 .818 .800 1.00 .889uniqNrepeat .727 .800 .889 .842 .727 .778 .875 .824wordBased .636 .778 .778 .778 .909 .889 1.00 .941patient .727 .875 .778 .824 .818 .875 .875 .875doctor .818 .818 1.00 .900 .455 .625 .625 .625Table 5: Results for separated BC and STD datasets (leave-one-out)sesses the efficacy of their communication skills inconveying correct and accurate medical informa-tion within a clinical setting.
It can be seen fromTable 4 that there is a high correlation between theoverall pass or fail and the assessable category AP-PROACH.The examiners?
subjectivity of overall perfor-mance is minimised by the highly structured exam-ination setup and well-defined assessment criteria.However, as shown in Table 3, the communicativestyle of the SP is a contributing factor to the per-ception of successful clinical and communicationskills.
The Mann-Whitney tests suggest that anSP?s approach and their apparent satisfaction dur-ing the clinical encounter can affect the judgementof the examiner.Additional inspection of the data revealed thatthe assessment criteria which focused on languageand communication skills correlated highly withan overall pass grade, moreso than the other cri-teria.
This seems to suggest that more emphasisshould be placed on language skills and communi-cation style in the assessment of the candidates.Assessing language competency is no trivialmatter, and capturing the linguistic features of di-alogues in an attempt to define competence, as wehave done here, is a demanding task in itself.
Al-though many of our features were focused on turn-taking, speaker response and interaction, we didnot develop features that encompass the informa-tion structure of the communicative event.It is assumed that miscommunication betweennon-native and native speakers of a language is dueto a lack of language knowledge pertaining to syn-tax, morphology or lexical semantics.
Howevermany of these communication difficulties arise notbecause of this lack of grammatical knowledge,but through a difference in discourse styles or in-formation structure as governed by different cul-tures (Wiberg, 2003; Li, 1999).Given that the word-based feature sets werethe most successful predictors of an OSCE out-come, future work of this kind could make use ofmedical-based lexicons to gauge whether technicalor non-technical word usage in such environmentsis judged favourably.
In addition, further workshould be done to test the hypothesis that informa-tion structure or rhetorical structure does impact onoverall perception of a successful communication,such as a variation on the methods employed byBurstein et al (2001).One obvious improvement to this study wouldbe to reduce the expense in producing the anno-tated data.
Future work could also be done in auto-matically extracting features from non-transcribeddata, such as timing information based on pauselength and the turn length of each speaker.7 ConclusionsIn this research, we have built classifiers overtranscribed doctor?patient consultations in an at-tempt to predict OSCE outcomes.
We achievedencouraging results based on a range of lexical anddiscourse-oriented features.In our first experiments, we combined the datafrom two discrete stations in an attempt to max-imise training data, and achieved modest results.Subsequent analysis with the Mann-Whitney test583indicated both that success in the APPROACH cat-egory correlates strongly with an overall success-ful OSCE, and that the data for the two stations ismarkedly different in nature.
Based on this find-ing, we conduct tests over the data for the individ-ual stations with noticeable improvements to theresults.The results of this exploratory study have beenquite encouraging, given the novel domain andlimited data.
We have shown that a data miningapproach to OSCE assessment is feasible, whichwe hope will open the way to increased interest inautomated medical assessment based on linguisticanalysis.ReferencesBirrell, Bob, Lesleyanne Hawthorne.
2004.
MedicarePlus and overseas trained doctors.
People and Place,12(2):83?99.ten Bosch, Louis, Nelleke Oostdijk, Lou Boves.
2005.On temporal aspects of turn taking in conversationaldialogues.
Speech Communication, 47(2005):80?86.Burstein, Jill, Daniel Marcu, Slava Andreyev, MartinChodorow.
2001.
Towards Automatic Classificationof Discourse Elements in Essays.
ACL, 90-97.Clark, Herber H., Jean E. Fox Tree.
2002.
Usinguh and um in spontaneous speaking.
Cognition,84(2002):73?111.Flynn, Joanna.
2006.
Medical Release.
AustralianMedical Council, 17(August 2006).Grand?Maison, Paul, Jo?elle Lescop, Paul Rainsberry,Carlos A. Brailovsky.
1992.
Large-scale use of anobjective, structured clinical examination for licens-ing family physicians.
Canadian Medical Associa-tion, 146(10):1735?1740.Gumperz, John.
1999.
On Interactional Sociolinguis-tic Method.
In Talk, Work and Institutional Order.Discourse in Medical, Mediation and ManagementSettings S. Sarangi and C. Robers (eds), 453?471.Han, Gil-Soo, John .S Humphreys.
2006.
Integratoinand retention of international medical graduates inrural communities.
A typological analysis.
The Aus-tralian Sociological Association, 42(2):189?207.Itakura, Hiroko.
2000.
Describing conversationaldominance.
Journal of Pragmatics, 33(2001):1859?1880.Levow, Gina-Anne, Mari Broman Olsen.
1999.
Mod-eling the language assessment process and result:Proposed architecture for an automatic oral profi-ciency assessment.
Workshop On Computer Medi-ated Language Assessment And Evaluation In Natu-ral Language Processing.Li, Han Zao.
1999.
Comunication Information in Con-versations: A Cross-cultural Comparison.
Interna-tional Journal of Intercultural Relations, 23(3):387?409.McGrath, Barry.
2004.
Overseas-trained doctors.
Inte-gration of overseas-trained doctors in the Australianmedical workforce.
The Medical Journal of Aus-tralia, 181(11/12):640?642.Roberts, Celia, Val Wass, Roger Jones, Srikant Sarangi,Annie Gillett.
2003.
A discourse analysis studyof ?good?
and ?poor?
communication in an OSCE:a proposed new framework for teaching students.Medical Education, 50:192?201.Sacks, Harvey, Emanuel A. Schegloff, Gail Jefferson.1974.
A Simplest Systematics for the Organiza-tion of Turn-Taking for Conversation.
Language,50(4):696?735.Spike, Neil.
2006. International Medical Graduates:The Australian perspective.
Acad Med, 81):842?846.Vu, Nu Viet, Howard S. Barrows.
1994.
Use of Stan-dardized Patients in Clinical Assessments: RecentsDevelopments and Measurement Findings.
Educa-tional Researcher, 23(3):23?30.Wiberg, Eva.
2003.
Interactional context in L2 dia-logues.
Journal of Pragmatics, 35(2003):389?407.584
