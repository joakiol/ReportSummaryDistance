SESSION 13: NEW DIRECTIONSRalph WeischedelBBN Systems and Technologies70 Fawcett StreetCambridge, MA 02138The three papers of Session 13 address issuesdiffering from those in the remainder of theworkshop.
Two employ a methodology todiscover preferences for speech input in a multi-modal interface.
The third raises issues ofprocessing human language without anyassumption that the speech or text has beenconverted to an online sequence of ASCII characters(or other character codes).As an introduction to the first two papers, considerWizard of Oz experiments uch as used incollecting ATIS data.
In such an experiment, thesubject is asked to use a system to solve one ormore problems.
The "system" could be a personwho simulates a proposed capability, for instanceto determine language and interface properties for aproposed computer capability.
Alternatively, thesystem might be an existing capability.Perhaps the first such experiment was performed byAshok Malhotra (1975) to collect data that wouldsuggest how varied (and challenging) textualqueries would be in an interactive queryapplication.
Malhotra simulated the whole system,a very labor-intensive task.The first paper ("Mode Preference in a SimpleData-Retrieval Task") employs fully implementedcomponents omeasure user preference for spokeninput, versus filling a form, versus employing ascroll bar to look up telephone numbers in anonline telephone book.
The paper immediately gotmy attention with the following statement in theintroduction, "For activities in a workstationenvironment, formal comparisons of speech withother input modes have failed to demonstrate a clearadvantage for speech on conventional ggregatemeasures of performance, such as time-to-completion .
.
.
".
The author's experimentsdemonstrate a flaw in the analysis of previousresults and go on to measure a marked preferencefor speech input, even when speech may not givethe best time-to-completion results.The second paper, "A Simulation-Based ResearchStrategy for Designing Complex NL Systems,"involves a person behind the scenes (the wizard)simulating the system, though much is automated.The resulting environment being simulated for theuser is quite rich, allowing both speech andhandwriting input.
Careful preparation of theexperimental environment enabled automatedsupport so that response to the user is streamlined,thereby allowing the user to move at his/her ownpace.
To illustrate the kind of studies themethodology supports, the authors show someresults suggesting that syntactic ambiguity is lesswhen filling out a form (rather than whenproducing unconstrained input) and is also less inhandwriting than in speech.The third paper, "Speech and Text-ImageProcessing in Documents," assumes minimalsignal processing.
For instance, they describeediting and indexing of audio forms rather than thetext file resulting from continuous speechrecognition.
Similarly "text-image" processing, isthe editing of the bitmap representation resultingfrom scanning a document in, rather than editing asequence of bytes in some character code such asASCII.
One of the tools described is thereforeaptly named "Image Emacs".
A third effortdescribed in this paper is document image decoding,a framework for processing scanned-in documents.REFERENCESMalhotra, A.
"Design Criteria for a Knowledge-Based English Language System for Management:An Experimental Analysis", MassachusettsInstitute of Technology, Cambridge, Ma., MACTR, No.
146, February, 1975.363
