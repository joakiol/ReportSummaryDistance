Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006, pages 38?53,Sydney, July 2006. c?2006 Association for Computational LinguisticsAnnotation Compatibility Working Group Report*Contributors: A. Meyers, A. C. Fang, L. Ferro, S. K?bler, T. Jia-Lin, M. Palmer, M. Poesio,A.
Dolbey, K. K. Schuler, E. Loper, H. Zinsmeister, G. Penn, N. Xue, E. Hinrichs, J. Wiebe,J.
Pustejovsky, D. Farwell, E. Hajicova, B. Dorr, E. Hovy, B.
A. Onyshkevych, L. LevinEditor: A Meyers meyers@cs.nyu.edu*As this report is a compilation, some sections may not reflect the views of individual contributors.AbstractThis report explores the question of compatibilitybetween annotation projects including translatingannotation formalisms  to each other or tocommon forms.
Compatibility issues are crucialfor systems that use the results of multipleannotation projects.
We hope that this report willbegin a concerted effort in the field to track thecompatibility of annotation schemes for part ofspeech tagging, time annotation, treebanking,role labeling and other phenomena.1.
IntroductionDifferent corpus annotation projects are drivenby different goals, are applied to different typesof data (different genres, different languages,etc.)
and are created by people with differentintellectual backgrounds.
As a result of these andother factors, different annotation efforts makedifferent underlying theoretical assumptions.Thus, no annotation project is really theory-neutral, and in fact, none should be.
It is thetheoretical concerns which make it possible towrite the specifications for an annotation projectand which cause the resulting annotation to beconsistent and thus usable for various naturallanguage processing (NLP) applications.
Ofcourse the theories chosen for annotation projectstend to be theories that are useful for NLP.
Theyplace a high value on descriptive adequacy (theycover the data), they are formalized sufficientlyfor consistent annotation to be possible, and theytend to share major theoretical assumptions withother annotation efforts, e.g., the noun is the headof the noun phrase, the verb is the head of thesentence, etc.
Thus the term theory-neutral isoften used to mean something like NLP-friendly.Obviously, the annotation compatibility problemthat we address here is much simpler than itwould be if we had to consider theories whichplace a low emphasis on NLP-friendly properties(Minimalism.
Optimality Theory, etc.
).As annotation projects are usually researchefforts, the inherent theoretical differences maybe viewed as part of a search for the truth and theenforcement of adherence to a given (potentiallywrong) theory could hamper this search.
Inaddition, annotation of particular phenomenamay be simplified by making theoreticalassumptions conducive to describing thosephenomena.
For example, relative pronouns(e.g., that in the NP the book that she read) maybe viewed as pronouns in an anaphora annotationproject, but as intermediate links to argumentsfor a study of predicate argument structure.On the other hand, many applications wouldbenefit by merging the results of differentannotation projects.
Thus, differences betweenannotation projects may be viewed as obstacles.For example, combining two or more corporaannotated with the same information mayimprove a system (i.e., "there's no data like moredata.")
To accomplish this, it may be necessaryto convert corpora annotated according to one setof specifications into a different system or toconvert two annotation systems into a thirdsystem.
For example, to obtain lots of part ofspeech data for English, it is advantageous toconvert POS tags from several tagsets (seeSection 2) into a common form.
For moretemporal data than is available in Timex3 format,one might have to convert Timex2 and Timex3tags into a common form (See Section 5).Compromises that do not involve conversion canbe flawed.
For example, a machine learner maydetermine that feature A in framework 1 predictsfeature A' in framework 2.
However, the systemmay miss that features A and B in framework 1actually both correspond to feature A', i.e., theyare subtypes.
In our view, directly modeling theparameters of compatibility would be preferable.38Some researchers have attempted to combine anumber of different resource annotations into asingle merged form.
One motivation is that themerged representation may be more than the sumof its parts.
It is likely that inconsistencies anderrors (often induced by task-specific biases) canbe identified and adjusted in the mergingprocess; inferences may be drawn from how thecomponent annotation systems interact; acomplex annotation in a single framework maybe easier for a system to process than severalannotations in different frameworks; and amerged framework will help guide furtherannotation research (Pustojevsky, et.
al.
2005).Another reason to merge is that a mergedresource in language A may be similar to anexisting resource in language B.
Thus mergingresources may present opportunities forconstructing nearly parallel resources, which inturn could prove useful for a multilingualapplication.
Merging PropBank (Kingsbury, andPalmer 2002) and NomBank (Meyers, et.
al.2004) would yield a predicate argument structurefor nouns and verbs, carrying more similarinformation to the Praque DependencyTreeBank's TectoGrammatical structure(Hajicova and Ceplova, 2000) than eithercomponent.This report and an expanded online versionhttp://nlp.cs.nyu.edu/wiki/corpuswg/AnnotationCompatibility  both describe how to findcorrespondences between annotationframeworks.
This information can be used tocombine various annotation resources indifferent ways, according to one?s research goals,and, perhaps, could lead to some standards forcombining annotation.
This report will outlinesome of our initial findings in this effort with aneye towards maintaining and updating the onlineversion in the future.
We hope this is a steptowards making it easier for systems to usemultiple annotation resources.2.
Part of Speech and Phrasal CategoriesOn our website, we provide correspondencesamong a number of different part of speechtagsets in a version of the table from pp.
141--142 of Manning and Sch?tze (1999),  modifiedto include the POS classes from CLAWS1 andICE.
Table 1 is a sample taken from this tablefor expository purposes (the full table is notprovided due to space limitations).
Traditionally,part of speech represents a fairly coarse-graineddivision among types of words, usuallydistinguishing among: nouns, verbs, adjectives,adverbs, determiners and possibly a few otherclasses.
While part of speech classifications mayvary for particular words, especially closed classitems, we have observed a larger problem.
Mostpart of speech annotation projects incorporateother distinctions into part of speechclassification.
Furthermore, they incorporatedifferent types of distinctions.
As a result,conversion between one tagset and another israrely one to one.
It can, in fact, be many tomany, e.g., BROWN does not distinguish theTable 1: Part of Speech CompatibilityExtending Manning and Sch?tze 1999, pp.
141-142,to cover Claws1 and ICE -- Longer Version OnlineClass WrdsClawsc5,Claws1BrownPTB  ICEAdjHap-py,badAJ0  JJ  JJ  ADJ.
geAdj,comphap-pier,worseAJC  JJR  JJR  ADJ.compAdj,supernic-est-worstAJS  JJT  JJS  ADJ.supAdj,pastparteaten JJ  ??
VBN, JJADJ.edpAdj,prespartcalm-ing  JJ  ?
?VBG, JJADJ.ingpAdvslow-ly,sweet-lyAV0  RB  RB  ADV.
geAdvcompfaster  AV0  RBR  RBR  ADV.compAdvsuperfast-est  AV0  RBT  RBSADV.supAdvPartup,off,outAVP,RP, RI  RP  RPADV.
{phras,ge}Conjcoordand,orCJC,CC  CC  CCCON-JUNC.39coordDetthis,each,ano-therDT0,DT  DT  DTPRON.dem.sing,PRON(recip)Det.pronany,someDT0,DTI  DT1  DTPRON.nonass,PRON.assDetpronPlurthesethoseDT0,DTS  DTS  DTPRON.dem.pluDetpreq  quiteDT0,aBL  ABL  PDTADV.intensDetpreqall,halfDT0,ABN  ABN  PDTPRON.univ,PRON.quantNounair-craft,dataNN0  NN  NN  N.com.singNounsingcat,pen  NN1  NN  NNN.com.singNounplurcats,pens  NN2  NNS  NNSN.com.pluNounpropsingParis,MikeNP0  NP  NNP  N.prop.singVerb.baseprestake,live  VVB  VB  VBPV.X.
{pres,imp}Verb,infintake,live  VVI  VB  VBV.X.infinVerb,pasttook,lived  VVD  VBD  VBDV.X.pastVerb,presparttak-ing,liv-ingVVG  VBG  VBG  V.X.
ingpVerb,past-parttaken,livedVVN  VBN  VBN  V.X.edpVerb,prestakes,VVZ  VBZ  VBZ  V.X.
presinfinitive form of a verb (VB in the PennTreebank, V.X.infin in ICE) from the present-tense form (VBP in the Penn Treebank, V.X.presin ICE) that has the same spelling (e.g., see inThey see no reason to leave).
In contrast, ICEdistinguishes among several differentsubcategories of verb (cop, intr, cxtr, dimontr,ditr, montr and TRANS) and the Penn Treebankdoes not.1 In a hypothetical system which mergesall the different POS tagsets, it would beadvantageous to factor out different types offeatures (similar to ICE), but include all thedistinctions made by all the tag sets.
Forexample, if a token give is tagged as VBP in thePenn Treebank, VBP would be converted intoVERB.anysubc.pres.
If another token give wastagged VB in Brown, VB would be converted toVERB.anysubc{infin,n3pres} (n3pres = not-3rd-person and present tense).
This allows systems toacquire the maximum information from corpora,tagged by different research groups.CKIP Chinese-Treebank (CCTB) and PennChinese Treebank (PCTB) are two importantresources for Treebank-derived Chinese NLPtasks (CKIP, 1995; Xia et al, 2000; Xu et al,2002; Li et al, 2004).
CCTB is developed intraditional Chinese (BIG5-encoded) at theAcademia Sinica, Taiwan (Chen et al, 1999;Chen et al, 2003).
CCTB uses the Information-based Case Grammar (ICG) framework toexpress both syntactic and semantic descriptions.The present version CCTB3 (Version 3) provides61,087 Chinese sentences, 361,834 words and 6files that are bracketed and post-edited byhumans based on a 5-million-word tagged SinicaCorpus (CKIP, 1995).
CKIP POS tagging is ahierarchical system.
The first POS layers includeeight main syntactic categories, i.e.
N (noun), V(verb), D (adverb), A (adjective), C(conjunction), I (interjection), T (particles) and P(preposition).
In CCTB, there are 6 non-terminalphrasal categories: S (a complete tree headed bya predicate), VP (a phrase headed by apredicate), NP (a phrase beaded by an N), GP (aphrase headed by locational noun or adjunct), PP1In the ICE column of Table 1 X represents a thedisjunction of verb subcategorization types {cop,intr, cxtr, dimontr, ditr, montr, trans}.40(a phrase headed by a preposition) and XP (aconjunctive phrase that is headed by aconjunction).Top Layer (TL) Bottom Layer (BL) Exam-ples PCTB CCTB PCTB CCTB inotherwordsADVP Head AD Dkthere-foreADVP result AD Cbcabe-causeP reason P CbaapastNP-TMP time:NP NT NddalastyearNP-TMP NP NT NdabaamongNP-ADV NP NN NepalsoDVP ADV AD:DEV Dkin thelastfewyearsLCP-TMP GPNT:LCGPNddc:NgPCTB annotates simplified Chinese texts (GB-encoded) from newswire sources (Xinhuanewswire, Hong Kong news and Sinorama newsmagazine, Taiwan).
It is developed at theUniversity of Pennsylvania (UPenn).
The PCTBannotates Chinese texts with syntacticbracketing, part of speech information, emptycategories and function tags (Xia et al 2000,2002, 2005).
The predicate-argument structure ofChinese verbs for the PCTB is encoded in thePenn Chinese Proposition Bank (Xue, et.
Al.2005).
The present version PCTB5.1 (PCTBVersion 5.1), contains 18,782 sentences, 507,222words, 824,983 Hanzi and 890 data files.PCTB?s bracketing annotation is in the sameframework as other Penn Treebanks, bearing aloose connection to the Government and BindingTheory paradigm.
The PCTB annotation schemeinvolves 33 POS-tags, 17 phrasal tags, 6 verbcompound tags, 7 empty category tags and 26functional tags.Table 2 includes Top-Layer/Bottom-Layer POSand phrasal categories correspondences betweenPCTB4 and CCTB3 for words/phrases expressedas the same Chinese characters in the same order.3.
Differences Between FrameworksWe assume that certain high level differencesbetween annotation schemata should be ignoredif at all possible, namely those that representdifferences of analyses that are notationallyequivalent.
In this section, we will discuss thosesorts of differences with an eye towardsevaluating whether real differences do in factexist, so that way users of annotation can becareful should these differences be ofsignificance to their particular application.To clarify, we are talking about the sort of highlevel differences which reflect differences in thelinguistic framework used for representingannotation, e.g., many frameworks representlong distance dependencies in equivalent, butdifferent ways.
In this sense, the linguisticframework of the Penn Treebank is a phrasestructure based framework that includes aparticular set of node labels (POS tags, phrasalcategories, etc.
), function tags, indices, etc.
2.3.1 Dependency vs. ConstituencyFigure 1 is a candidate rule for converting aphrase structure tree to a dependency tree or viceversa.
Given a phrase consisting of constituentsC(n-i) to C(n+j), the rule assumes that: there isone unique constituent C(n) that is the head ofthe phrase; and it is possible to identify this headin the phrase structure grammar, either using areliable heuristic or due to annotation that marksthe head of the phrase.
When converting the2Linguistic frameworks are independent of encodingsystems, e.g., Penn Treebank?s inline LISP-ish notation, canbe converted to inline XML, offset annotation, etc., Suchencoding differences are outside the scope of this report41Fig.
1: Candidate Consituency/Dependency Mappingphrase structure tree to the dependency tree, therule promotes the head to the root of the tree.When converting a dependency tree to a phrasestructure tree, the rule demotes the root to aconstituent, possibly marking it as the head, andnames the phrase based on the head?s part ofspeech, e.g., nouns are heads of NPs.
This rule isinsufficient because: (1) Identifying the head of aphrase by heuristics is not 100% reliable andmost phrase structure annotation does not includea marking for the head; (2)  Some phrasestructure distinctions do not translate well tosome Dependency Grammars, e.g., the VPanalysis and nestings of prenominal modifiers3;and (3) The rule only works for phrases that fitthe head plus modifiers pattern and many phrasesdo not fit this pattern (uncontroversially).While most assume that verbs act like the headof the sentence, a Subject + VP analysis of asentence complicates this slightly.
Regarding S-bars (relative clauses, that-S, subordinate-conjunction + S, etc.
), there is some variation3The Prague Depedency Treebank orders dependencybranches from the same head to represent the scope of thedependencies.
Applicative Universal Grammar (Shauyman1977) incorporates phrases into dependency structure.among theories whether the verb or the pre-Selement (that, subordinate conjunction, etc.)
isassigned the head label.
Names, Dates, andother "patterned" phrases don't seem to have aunique head.
Rather there are sets of constituentswhich together act like the head.
For example, inDr.
Mary Smith, the string Mary Smith acts likethe head.
Idioms are big can of worms.
Theirheadedness properties vary quite a bit.Sometimes they act like normal headed phrasesand sometimes they don't.
For example, thephrase pull strings for John obeys all the rules ofEnglish that would be expected of a verb phrasethat consists of a verb, an NP and a complementPP.
In contrast, the phrase let alne (Fillmore, et.al.
1988) has a syntax unique to that phrase.Semi-idiomatic constructions (including phrasalverbs, complex prepositions, etc.)
raise some ofthe same questions as idioms.
While makingheadedness assumptions similar to other phrasesis relatively harmless, there is some variation.For example, in the phrase Mary called Fred upon the phone, there are two common views: (a)called is the head of the VP (or S) and up is aparticle that depends on called; and (b) the VPhas a complex head called up.
For mostpurposes, the choice between these two analysesis arbitrary.
Coordinate structures also requiredifferent treatment from head + modifier phrases-- there are multiple head-like constituents.A crucial factor is that the notion head is used torepresent different things.
(cf.
Corbett, et.
al.1993, Meyers 1995).
However, there are twodominant notions.
The first we will call thefunctor (following Categorial Grammar).
Thefunctor is the glue that holds the phrase together-- the word that selects for the other words,determines word order, licenses the construction,etc.
For example, coordinate conjunctions arefunctors because they link the constituents intheir phrase together.
The second head likenotion we will call the thematic head, the wordor words that determine the external selectionalproperties of the phrase and usually the phrasalcategory as well.
For example, in the nounphrase the book and the rock, the conjunctionand is the functor, but the nouns and book androck are thematic heads.
The phrase is a concretenoun phrase due to book and rock.
Thus thefollowing sentence is well-formed: I held thebook and the rock, but the following sentence isill-formed *I held the noise and the redness.Furthermore, the phrase the book and the rock isa noun phrase, not a conjunction phrase.42In summary, there are some differences betweenphrase structure and dependency analyses whichmay be lost in translation, e.g., dependencyanalyses include head-marking by default andphrase structure analyses do not.
On the otherhand, phrase structure analyses include relationsbetween groupings of words which may notalways be preserved when translating todependencies.
Moreover, both identifying headsand combining words into phrases have theirown sets of problems which can come to theforefront when translation between the twomodalities is attempted.
To be descriptivelyadequate, frameworks that mark heads do dealwith these issues.
The problem is that they aredealt with in different ways across dependencyframeworks and across those phrase structureframeworks where heads are marked.
Forexample, conjunction may be handled as being adistinct phenomenon (another dimension) thatcan be filtered through to the real heads.Alternatively, a head is selected on theoretical orheuristic grounds (the head of the first theconjunct, the conjunction, etc.)
When workingwith multiple frameworks, a user must adjust forthe assumptions of each framework.3.2 Gap Filling MechanismsIt is well-known that there are several equivalentways to represent long distance and lexicallybased dependencies, e.g., (Sag and Fodor, 1994).Re-entrant graphs (graphs with shared structure),empty category/antecedent pairs, representationsof discontinuous constituents, among othermechanisms can all be used to represent thatthere is some relation R between two (or more)elements in a linguistic structure that is, in somesense, noncanonical.
The link by any of thesemechanisms can be used to show that the relationR holds in spite of violations of a proximityconstraint (long distance dependencies), a specialconstruction such as control, or many otherconditions.
Some examples follow:1.
Whati did you read ei?
(WH extraction)2.
The terroristi was captured ei (Passive)3.
Ii wanted ei to accept  it.
(Control)It seems to us that the same types of cases aredifficult for all such approaches.
In theunproblematic cases, there is a gap (orequivalent) with a unique filler found in the samesentence.
In the "difficult" cases, this does nothold.
In some examples, the filler is hypotheticaland should be interpreted something like thepronoun anyone (4 below) or the person beingaddressed (5).
In other examples, the identitybetween filler and gap is not so straight-forward.In examples like (6), filler and gap are typeidentical, not token identical (they representdifferent reading events).
In examples like (7), agap can take split antecedents.
Conventionalfiller/gap mechanims of all types have to bemodified to handle these types of examples.4.
They explained how e to drive the car5.
e don't talk to me!6.
Sally [read a linguistics article]i, butJohn didn't ei.7.
Sallyi spoke with Johnj about e,,i,j,,leaving together.3.3  Coreference and AnaphoraThere is little agreement concerning coreferenceannotation in the research community.
Fundingfor the creation of the existing anaphoricallyannotated corpora (MUC6/7, ACE) has comeprimarily from initiatives focused on specificapplication tasks, resulting in task-orientedannotation schemes.
On the other hand, a few(typically smaller) corpora have also beencreated to be consistent with existing, highlydeveloped theoretical accounts of anaphora froma linguistic perspective.
Accordingly, manyschemes for annotating coreference or anaphorahave been proposed, differing significantly withrespect to: (1) the task definition, i.e., what typeof semantic relations are annotated; (2) theflexibility that annotators have.By far the best known and most used scheme isthat originally proposed for MUC 6 and lateradapted for ACE.
This scheme was developed tosupport information extraction and its primaryaim is to identify all mentions of the sameobjects in the text (?coreference?)
so as to collectall predications about them.
A <coref> elementis used to identify mentions of objects (theMARKABLES); each markable is given anindex; subsequent mentions of alreadyintroduced objects are indicated by means of theREF attribute, which specifies the index of theprevious mention of the same object.
Forexample, in (1), markable 10 is a mention of thesame object as markable 9.
(This example isadapted from a presentation by Jutta Jaeger.)431.
<coref id="9">The New Orleans Oil andGas [...] company</coref> added that<coref id="10" type="ident" ref="9">it</coref> doesn?t expect [...].The purpose of the annotation is to supportinformation extraction.
To increase codingreliability, the MUC scheme conflates differentsemantic relations into a single IDENT relation.For example, coders marked pairs of NPs asstanding in IDENT relations, even when theseNPs would more normally be assumed to be in apredication relations, e.g., appositions as in 2 andNPs across a copula as in 3.
This conflation ofsemantic relations is a convenient simplificationin many cases but it is untenable in general, asdiscussed by van Deemter & Kibble (2001).2.
Michael H. Jordan, the former head ofPepsico?s international operations3.
Michael H. Jordan is the former head ofPepsico?s international operationsFrom the point of view of markup technology,the way used to represent coreference relations inMUC is very restrictive.
Only one type of linkcan be annotated at a time: i.e., it is not possiblyto identify a markable as being both a mention ofa previously introduced referent and as abridging reference on a second referent.
Inaddition, the annotators do not have the option tomark anaphoric expressions as ambiguous.The MATE m`eta-scheme?
(Poesio, 1999) wasproposed as a very general repertoire of markupelements that could be used to implement avariety of existing coreference schemes, such asMUC or the MapTask scheme, but also morelinguistically motivated schemes.
From the pointof view of markup technology, the two crucialdifferences from the MUC markup method arethat the MATE meta-scheme is (i) based onstandoff technology, and, most relevant for whatfollows, (ii) follows the recommendations of theText Encoding Initiative (TEI) which suggestseparating relations (?LINKs?)
from markables.LINKs can be used to annotate any form ofsemantic relations (indeed, the same notion wasused in the TimeML annotation of temporalrelations).
A structured link, an innovation ofMATE, can represent ambiguity (Poesio &Artstein, 2005).
In (4), for example, theantecedent of the pronoun realized by markablene03 in utterance 3.3 could be either engine E2or the boxcar at Elmira; with the MATE scheme,coders can mark their uncertainty.4.
[in file markable.xml]3.3: hook <COREF:DE ID=?ne01?>engineE2</COREF:DE> to  <COREF:DE ID=?ne02?>the boxcar at ?
Elmira </COREF:DE>5.1: and send <COREF:DE ID=?ne03?>it</COREF:DE> to <COREF:DE ID=?ne04?>Corning</COREF:DE>[in a separate file ?
e.g., link.xml]<COREF:LINK HREF="markable.xml#id(ne03)" type=?ident?><COREF:ANCHOR HREF=?markable.xml#id(ne01)?
/><COREF:ANCHOR HREF=?markable.xml#id(ne02)?
/></COREF:LINK>The MATE meta-scheme also allowed a richerset of semantic relations in addition to IDENT,including PART-OF, PRED for predicates, etc.,as well as methods for marking antecedents notexplicitly introduced via an NP, such as plansand propositions.
Of course, using this addedpower is only sensible when accompanied byexperimentally tested coding schemes.The MATE meta-scheme was the starting pointfor the coding scheme used in the GNOMEproject (Poesio 2004).
In this project, a schemewas developed to model anaphoric relations intext in the linguistic sense?e.g., the informationabout discourse entities and their semanticrelations expressed by the text.
A relation calledIDENT was included, but it was only used tomark the relation between mentions of the samediscourse entity; so, for example, neither of therelations in (2) would be marked in this way.From the point of view of coding schemes usedfor resource creation, the MATE meta-schemegave rise to two developments: the standoffrepresentation used in the MMAX annotationtool, and the Reference Annotation Framework(Salmon-Alt & Romary, 2004).
MMAX was thefirst usable annotation tool for standoffannotation of coreference (there are now at leastthree alternatives: Penn?s WordFreak, MITRE?sCALISTO, and the NITE XML tools).
Themarkup scheme was a simplification of theMATE scheme, in several respects.
First of all,cross-level reference is not done using href links,44but by specifying once and for all which filescontain the base level and which files containeach level of representation; each level points tothe same base level.
Secondly, markables andcoref links are contained in the same file.5.
[ markable file]<?xml version="1.0"?> <markables> ?
?<markable id="markable_36" span="word_5,word_6, word_7?member="set_22" ></markable> ?.
<markable id="markable_37"span="word_14, word_15, word_16"member="set_22" > </markable> ?.</markables>The original version of MMAX, 0.94, onlyallowed to specify one identity link and onebridging reference per markable, but beginningversion 2.0,  multiple pointers are possible.
Aninteresting aspect of the proposal is that identitylinks are represented by specifying membershipto coreference chains instead of linking toprevious mentions.
Multiple pointers were usedin the ARRAU project to represent ambiguouslinks, with some restrictions.
The RAFframework was proposed not to directly supportannotation, but as a rich enough markupframework to be used for annotation exchange.3.3.2 ConversionSeveral types of conversion between formats forrepresenting coreference information areroutinely performed.
Perhaps the most commonproblem is to convert between inline formatsused for different corpora: e.g., to convert theMUC6 corpus into GNOME.
However, it isbecoming more and more necessary to to convertstandoff into inline formats for processing (e.g.,MMAX into MAS-XML), and viceversa.The increasing adoption of XML as a standardhas made the technical aspect of conversionrelatively straightforward, provided that the sameinformation can be encoded.
For example,because the GNOME format is richer than boththe MUC and MMAX format, it should bestraightforward to convert a MUC link into aGNOME link.
However, the correctness of theconversion can only be ensured if the samecoding instructions were followed; the MUCIDENT links used in (2) and (3) would not beexpressed in the GNOME format as IDENTlinks.
There is no standard method we know offor identifying these problematic links, althoughsyntactic information can sometimes help.
Theopposite of course is not true; there is no directway of representing the information in (4) in theMUC format.
Conversion between the MAS-XML and the MMAX format is also possible,provided that pointers are used to represent bothbridging references and identity links.4 Predicate-Argument RelationsPredicate argument relations are labeled relationsbetween two words/phrases of a linguisticdescription such that one is a semantic predicateor functor and the other is an argument of thispredicate.
In the sentence The eminent linguistread the book, there is a SUBJECT (or AGENT,READER, ARG0, DEPENDENT etc.)
relationbetween the functor read and the phrase Theeminent linguist or possibly the word linguist ifassuming a dependency framework.
Typically,the functor imposes selectional restrictions on theargument.
The functor may impose word orderrestrictions as well, although this would onlyeffect "local" arguments (e.g., not argumentsrelated by WH extraction).
Another popular wayof expressing this relation is to say that readassigns the SUBJECT role to The eminentlinguist in that sentence.
Unfortunately, this wayof stating the relation sometimes gives the falseimpression that a particular phrase can only be amember of one such relation.
However, this isclearly not the case, e.g., in The eminent linguistwho John admires read the book, The eminentlinguist is the argument of: (1) a SUBJECTrelation with read and an OBJECT relation withadmires.
Predicate-argument roles label relationsbetween items and are not simply tags on phrases(like Named Entity Tags, for example).There are several reasons why predicateargument relations are of interest for naturallanguage processing, but perhaps the most basicreason is that they provide a way to factor out thecommon meanings from equivalent or nearlyequivalent utterances.
For example, mostsystems would represent the relation betweenMary and eat in much the same way in thesentences: Mary ate the sandwich, The sandwichwas eaten by Mary, and Mary wanted to eat thesandwich.
Crucially, the shared aspect ofmeaning can be modeled as a relation with eat(or ate) as the functor and Mary as the argument(e.g., SUBJECT).
Thus providing predicate45argument relations can provide a way togeneralize over data and, perhaps, allow systemsto mitigate against the sparse data problem.Systems for representing predicate argumentrelations vary drastically in granularity,  Inparticular, there is a long history of disagreementabout the appropriate level of granularity of rolelabeling, the tags used to distinguish betweenpredicate argument relations.
At one extreme, nodistinction is made between predicate relations,one simply marks that the functor and argumentare in a predicate-argument relation (e.g.,unlabeled dependency trees).
In anotherapproach, one might distinguish among thearguments of each predicate with a small set oflabels, sometimes numbered -- examples of thisapproach include Relational Grammar(Perlmutter 1984), PropBank and NomBank.These labels have different meanings for eachfunctor, e.g., the subject of eat, write and devourare distinct.
This assumes a very high level ofgranularity, i.e., there are several times thenumber of possible relations as there are distinctfunctors.
So 1000 verbs may license as many as5000 distinct relations.
Under other approaches,a small set of relation types are generalizedacross functors.
For example, under RelationalGrammar's Universal Alignment Hypothesis(Perlmutter and Postal 1984, Rosen 1984),subject, object and indirect object relations areassumed to be of the same types regardless ofverb.
These terms thus are fairly coarse-graineddistinctions between types of predicate/argumentrelations between verbs and their arguments.Some predicate-neutral relations are more finegrained, including Panini's Karaka of 2000 yearsago, and many of the more recent systems whichmake distinctions such as agent, patient, theme,recipient, etc.
(Gruber 1965, Fillmore 1968,Jackendoff 1972).
The (current) InternationalAnnotation of Multilingual Text Corpora project(http://aitc.aitc.net.org/nsf/iamtc/) takes thisapproach.
Critics claim that it can be difficult tomaintain consistency across predicates with thesesystems without constantly increasing theinventory of role labels to describe idiosyncraticrelations, e.g., the relation between the verbsmultiply, conjugate, and their objects.
Forexample, only a very idiosyncratic classificationcould capture the fact that only a large roundobject (like the Earth) can be the object ofcircumnavigate.
It can also be unclear which oftwo role labels apply.
For example, there can bea thin line between a recipient and a goal, e.g.,the prepositional object of John sent a letter tothe Hospital could take one role or the otherdepending on a fairly subtle ambiguity.To avoid these problems, some annotationresearch (and some linguistic theories) hasabandoned predicate-neutral approaches, in favorof the approaches that define predicate relationson a predicate by predicate basis.
Furthermore,various balances have been attempted to solvesome of the problems of the predicate-neutralrelations.
FrameNet defines roles on a scenarioby scenario basis, which limits the growth of theinventory of relation labels and insuresconsistency within semantic domains or frames.On the other hand, the predicate-by-predicateapproach is arguably less informative then thepredicate-neutral approach, allowing for nogeneralization of roles across predicates.
Thusalthough PropBank/NomBank use a strictlypredicate by predicate approach, there have beensome attempts to regularize the numbering forsemantically related predicates.
Furthermore, thedescriptors used by the annotators to define rolescan sometimes be used to help make finerdistinctions (descriptors often include familiarrole labels like agent, patient, etc.
)The diversity of predicate argument labelingsystems and the large inventory of possible rolelabels make it difficult to provide a simplemapping (like Table 1 for part of speechconversion) between these types of systems.
TheSemLink project provides some insight into howthis mapping problem can be solved.4.2 SemLinkSemLink is a project to link the lexical resourcesof FrameNet, PropBank, and VerbNet.
The goalis to develop computationally explicitconnections between these resources combiningindividual advantages and overcoming theirlimitations.4.2.1 BackgroundVerbNet consists of hierarchies of verb classes,extended from those of Levin 1993.
Each classand subclass is characterized extensionally by itsset of verbs, and intensionally by argument listsand syntactic/semantic features of verbs.
The fullargument list consists of 23 thematic roles, and46possible selectional restrictions on the argumentsare expressed using binary predicates.
VerbNethas been extended from the Levin classes, andnow covers 4526 senses for 3175 lexemes.
Aprimary emphasis for VerbNet is grouping verbsinto classes with coherent syntactic and semanticcharacterizations in order to facilitate acquisitionof new class members based on observablesyntactic/semantic behavior.
The hierarchicalstructure and small number of thematic roles isintended to support generalizations.FrameNet consists of collections of semanticframes, lexical units that evoke these frames, andannotation reports that demonstrate uses oflexical units.
Each semantic frame specifies a setof frame elements.
These are elements thatdescribe the situational props, participants andcomponents that conceptually make up part ofthe frame.
Lexical units appear in a variety ofparts of speech, though we focus on verbs here.A lexical unit is a lexeme in a particular sensedefined in its containing semantic frame.
Theyare described in reports that list the syntacticrealizations of the frame elements, and valencepatterns that describe possible syntactic linkingpatterns.
3486 verb lexical units have beendescribed in FrameNet which places a primaryemphasis on providing rich, idiosyncraticdescriptions of semantic properties of lexicalunits in context, and making explicit subtledifferences in meaning.
As such it could providean important foundation for reasoning aboutcontext dependent semantic representations.However, the large number of frame elementsand the current sparseness of annotations foreach one has hindered machine learning.PropBank is an annotation of 1M words of theWall Street Journal portion of the Penn TreebankII with semantic role labels for each verbargument.
Although the semantic roles labels arepurposely chosen to be quite generic, i.e., ArgO,Arg1, etc., they are still intended to consistentlyannotate the same semantic role across syntacticvariations, e.g., Arg1 in "John broke thewindow" is the same window (syntactic object)that is annotated as the Arg1 in "The windowbroke" (syntactic subject).
The primary goal ofPropBank is to provide consistent generallabeling of semantic roles for a large quantity oftext that can provide training data for supervisedmachine learning algorithms.
PropBank can alsoprovide frequency counts for (statistical) analysisor generation.
PropBank includes a lexiconwhich lists, for each broad meaning of eachannotated verb, its "frameset", the possiblearguments, their labels and all possible syntacticrealizations.
This lexical resource is used as a setof verb-specific guidelines by the annotators, andcan be seen as quite similar in nature toFrameNet, although much more coarse-grainedand general purpose in the specifics.To summarize, PropBank and FrameNet bothannotate the same verb arguments, but assigndifferent labels.
PropBank has a small number ofvague, general purpose labels with sufficientamounts of training data geared specifically tosupport successful machine learning.
FrameNetprovides a much richer and more explicitsemantics, but without sufficient amounts oftraining data for the hundreds of individual frameelements.
An ideal environment would allow usto train generic semantic role labelers onPropBank, run them on new data, and then beable to map the resulting PropBank argumentlabels on rich FrameNet frame elements.The goal of SemLink is to create just such anenvironment.
VerbNet provides a level ofrepresentation that is still tied to syntax, in theway that PropBank is, but provides a somewhatmore fine-grained set of role labels and a set offairly high level, general purpose semanticpredicates, such as contact(x,y), change-of-location(x, path), cause(A, X), etc.
As such it canbe seen as a mediator between PropBank andFrameNet.
In fact, our approach has been to usethe explicit syntactic frames of VerbNet to semi-automatically map the PropBank instances ontospecific VerbNet classes and role labels.
Themapping can then be hand-corrected.
In parallel,SemLink has been creating a mapping table fromVerbNet class(es) to FrameNet frame(s), andfrom role label to frame element.
This will allowthe SemLink project to automatically generateFrameNet representations for every VerbNetversion of a PropBank instance with an entry inthe VerbNet-FrameNet mapping table.4.2.2 VerbNet <==> FrameNet linkingOne of the tasks for the SemLink project is toprovide explicit mappings between VerbNet andFrameNet.
The mappings between these tworesources which have complementaryinformation about verbs and disjoint coverageopen several possibilities to increase their47robustness.
The fact that these two resources arenow mapped gives researchers different levels ofrepresentation for events these verbs represent tobe used in natural language applications.
Themapping between VerbNet and FrameNet wasdone in two steps: (1) mapping VerbNet verbsenses to FrameNet lexical units; (2) mappingVerbNet thematic roles to the equivalent (if pre-sent) FrameNet frame elements for the corre-sponding class/frame mappings uncovered dur-ing step 1.In the first task, VerbNet verb senses weremapped to corresponding FrameNet senses, ifavailable.
Each verb member of a VerbNet classwas assigned to a (set of) lexical units of Frame-Net frames according to semantic meaning andto the roles this verb instance takes.
Thesemappings are not one-to-one since VerbNet andFrameNet were built with distinctly differentdesign philosophies.
VerbNet verb classes areconstructed by grouping verbs based mostly ontheir participation in diathesis alternations.
Incontrast, FrameNet is designed to group lexicalitems based on frame semantics, and a singleFrameNet frame may contain sets of verbs withrelated senses but different subcategorizationproperties and sets of verbs with similar syntacticbehavior may appear in multiple frames.The second task consisted of mapping VerbNetthematic roles to FrameNet frame elements forthe pairs of classes/frames found in the first task.As in the first task, the mapping is not alwaysone-to-one as FrameNet tends to record muchmore fine-grained distinctions than VerbNet.So far, 1892 VerbNet senses representing 209classes were successfully mapped to FrameNetframes.
This resulted in 582 VerbNet class ?FrameNet frame mappings, across 263 uniqueFrameNet frames, for a total of 2170 mappingsof VerbNet verbs to FrameNet lexical units.4.2.3 PropBank <==> VerbNet linkingSemLink is also creating a mapping betweenVerbNet and PropBank, which will allow the useof the machine learning techniques that havebeen developed for PropBank annotations togenerate more semantically abstract VerbNetrepresentations.
The mapping between VerbNetand PropBank can be divided into two parts: a"lexical mapping" and an "instance classifier.
"The lexical mapping defines the set of possiblemappings between the two lexicons, independentof context.
In particular, for each item in thesource lexicon, it specifies the possiblecorresponding items in the target lexicon; and foreach of these mappings, specifies how thedetailed fields of the source lexicon item (such asverb arguments) map to the detailed fields of thetarget lexicon item.
The lexical mappingprovides a set of possible mappings, but does notspecify which of those mappings should be usedfor each instance; that is the job of the instanceclassifier, which looks at a source lexicon item incontext, and chooses the most appropriate targetlexicon items allowed by the lexical mapping.The lexical mapping was created semi-automatically, based on an initial mapping whichput VerbNet thematic roles in correspondencewith individual PropBank framesets.
This lexicalmapping consists of a mapping between thePropBank framesets and VerbNet's verb classes;and a mapping between the roleset argumentlabels and the VerbNet thematic roles.
Duringthis initial mapping, the process of assigning averb class to a frameset was performed manuallywhile creating new PropBank frames.
Thethematic role assignment, on the other hand, wasa semi-automatic process which finds the bestmatch for the argument labels, based on theirdescriptors, to the set of thematic role labels ofVerbNet.
This process required humanintervention due to the variety of descriptors forPropBank labels, the fact that the argument labelnumbers are not consistent across verbs, andgaps in frameset to verb class mappings.To build the instance classifier, SemLink startedwith two heuristic classifiers.
The first classifierworks by running the SenseLearner WSD engineto find the WordNet class of each verb; and thenusing the existing WordNet/VerbNet mapping tochoose the corresponding VerbNet class.
Thisheuristic is limited by the performance of theWSD engine, and by the fact that theWordNet/VerbNet mapping is not available forall VerbNet verbs.
The second heuristic classifierexamines the syntactic context for each verbinstance, and compares it to the syntactic framesof each VerbNet class.
The VerbNet class with asyntactic frame that most closely matches theinstance's context is assigned to the instance.The SemLink group ran these two heuristicmethods on the Treebank corpus and are hand-48correcting the results in order to obtain aVerbNet-annotated version of the Treebankcorpus.
Since the Treebank corpus is alsoannotated with PropBank information, this willprovide a parallel VerbNet/PropBank corpus,which can be used to train a supervised classifierto map from PropBank frames to VerbNetclasses (and vice versa).
The feature space forthis machine learning classifier includesinformation about the lexical and syntacticcontext of the verb and its arguments, as well asthe output of the two heuristic methods.5.
Version ControlAnnotation compatibility is also an issue forrelated  formalisms.
Two columns in Table 1 aredevoted to different CLAWS POS tagsets, but thereare several more CLAWS tagsets(www.comp.lancs.ac.uk/ucrel/annotation.html),differing both in degree of detail and choice ofdistinctions made.
Thus a detailed conversiontable among even just the CLAWS tagsets mayprove handy.
Similar issues arise with the year toyear changes of the ACE annotation guidelines(projects.ldc.upenn.edu/ace/ ) which includenamed entity, semantic classes for nouns,anaphora, relation and event annotation.
Asannotation formalisms mature,  specificationscan change to improve annotation consistency,speed or the usefulness for some specific task.
Inthe interest of using old and new annotationtogether (more training data), it is helpful to haveexplicit mappings for related formalisms.
Table 2is a (preliminary) conversion table for Timex2and Timex3, the latter of which can be viewedessentially as an elaboration of the former.Table 3: Temporal Markup Translation Table4Description  TIMEX2  TIMEX3  CommentContains a normal-ized form of thedate/timeVAL="1964-10-16"  val="1964-10-16"  Some TIMEX2 points are TIMEX3 durationsCaptures temporalmodifiers  MOD="APPROX"  mod="approx"  ---Contains a normal-ized form of ananchoringdata/timeANCHOR_VAL="1964-W22"  ---See TIMEX3 beginPoint andendPointCaptures relativedirection betweenVAL and AN-CHOR_VALANCHOR_DIR="BEFORE"  ---See TIMEX3 beginPoint andendPointIdentifies set ex-pressions  SET="YES"  type="SET"  ---Provides unique IDnumber  ID="12"  tid="12"Used to relate time expres-sions to other objectsIdentifies type ofexpression  ---  type="DATE"Hold over from TIMEX.
De-rivable from format ofVAL/valIdentifies indexicalexpressions  ---  temporalFunction="true"In TIMEX3, indexical expres-sions are normalized via atemporal function, applied aspost-processIdentifies referencetime used to com-pute val---  anchorTimeID="t12"  Desired in TIMEX2Identifies dis- ---  functionInDocu- Used for date stamps on4This preliminary table shows the attributes side by side with only one sample value, although other values are possible49course function  ment="CREATION_TIME"  documentsCaptures anchorsfor durations  ---beginPoint="t11", end-Point="t12"Captured by TIMEX2 AN-CHOR attributesCaptures quantifi-cation of a set ex-pression---  quant="EVERY"  Desired in TIMEX2Captures numberof reoccurences inset expressions---  freq="2X"  Desired in TIMEX26.
The Effect of Language DifferencesMost researchers involved in linguisticannotation (particularly for NLP) take it forgranted that coverage of a particular grammar fora particular language is of the utmost important.The (explanatory) adequacy of the particularlinguistic theory assumed for multiple languagesis considered a much less important.
Given thediversity of annotation paradigms, we may go astep further and claim that it may be necessary tochange theories when going from one languageto another.
In particular, language-specificphenomena can complicate theories in ways thatprove unnecessary for languages lacking thesephenomena.
For example, English requires amuch simpler morphological framework thenlanguages like German, Russian, Turkish orPashto.
It has also been claimed on severaloccasions that a VP analysis is needed in somelanguages (English), but not others (Japanese).For the purposes of annotation, it would seemsimplest  to choose the simplest language-specific framework that is capable of capturingthe distinctions that one is attempting toannotate.
If the annotation is robust, it should bepossible to convert it automatically into somelanguage-neutral formalism should one arise thatmaximizes descriptive and explanatoryadequacy.
In the meanwhile, it would seemunnecessary to complicate grammars of specificlanguages to account for phenomena which donot occur in those languages.6.1 The German T?Ba-D/Z TreebankGerman has a freer word order than English.This concerns the distribution of the finite verband the distribution of arguments and adjuncts.German is a general Verb-Second languagewhich means that in the default structure indeclarative main clauses as well as in wh-questions the finite verb surfaces in secondposition preceded by only one constituent whichis not necessarily the subject.
In embeddedclauses the finite verb normally occurs in a verb-phrase-final position following its arguments andadjuncts, and other non-finite verbal elements.German is traditionally assumed to have a head-final verb phrase.
The ordering of arguments andadjuncts is relatively free.
Firstly almost anyconstituent can be topicalised preceding the finiteverb in Verb-Second position.
Secondly theorder of the remaining arguments and adjuncts isstill relatively free.
Ross (1967) coined the termScrambling to describe the variety of linearorderings.
Various factors are discussed to play arole here such as pronominal vs. phrasalconstituency, information structure, definitenessand animacy (e.g.
Uszkoreit 1986).The annotation scheme of the German T?Ba-D/Ztreebank was developed with special regard tothese properties of German clause structure.
Themain ordering principle is adopted fromtraditional descriptive analysis of German (e.g.Herling 1821, H?hle 1986).
It partitions theclause into 'topological fields' which are definedby the distribution of the verbal elements.
Thetop level of the syntactic tree is a flat structure offield categories including: Linke Klammer - leftbracket (LK) and Rechte Klammer - verbalcomplex (VC) for verbal elements and Vorfeld -initial field (VF), C-Feld - complementiser field(C), Mittelfeld - middle field (MF), Nachfeld -final field (NF) for other elements.Below the level of field nodes the annotationscheme provides hierarchical phrase structuresexcept for verb phrases.
There are no verbphrases annotated in T?Ba-D/Z.
It was one of themajor design decisions to capture the distributionof verbal elements and their arguments andadjuncts in terms of topological fields instead ofhierarchical verb phrase structures.
The freeword order would have required to makeextensive use of traces or other mechanisms torelate dislocated constituents to their base50positions,  which in itself was problematic sincethere is no consensus among German linguists onwhat the base ordering is.
An alternative whichavoids commitment to specific base positions isto use crossing branches to deal withdiscontinuous constituents.
This approach isadopted for example by the German TIGERtreebank (Brants et al 2004).
A drawback ofcrossing branches is that the treebank cannot bemodeled by a context free grammar.
Since T?Ba-D/Z was intended to be used for parser training,it was not a desirable option.
Arguments andadjuncts are thus related to their predicates bymeans of functional labels.
In contrast to thePenn Treebank, T?Ba-D/Z assigns grammaticalfunctions to all arguments and adjuncts.
Due tothe freer word order functions cannot be derivedfrom relative positions only.The choice of labels of grammatical functions islargely based on the insight that grammaticalfunctions in German are directly related to thecase assignment (Reis 1982).
The labelstherefore do not refer to grammatical functionssuch as subject, direct object or indirect objectbut make a distinction between complement andadjunct functions and classify the nominalcomplements according to their case marking:accusative object (OA), dative object (OD),genitive object (OG), and also nominative'object' (ON) versus verbal modifier (V-MOD) orunderspecified modifier (MOD).Within phrases a head daughter is marked at eachprojection level.
Exceptions are ellipticalphrases, coordinate structures, strings of foreignlanguage, proper names and appositions withinnoun phrases.
Modifiers of arguments andadjuncts are assigned a default non-headfunction.
In case of discontinuous constituentsthe function of the modifier is either explicitlymarked by means of a complex label such asOA-MOD (the modifier of an accusative object)or by means of a secondary edge REFINT incase the modified phrase has a default head ornon-head function itself (which holds in the caseof e.g.
NP complements of prepositions).Figures 2 to 4 illustrate the German T?Ba-D/Ztreebank annotation scheme (Telljohann et al(2005).
?
it combines a flat topological analysiswith structural and functional information.Fig.
2: verb-secondDort w?rde er sicher angenommen werden.there would he surely accepted be'He would be surely accepted there.'Fig.
3: verb-finalZu hoffen ist, da?
der R?ckzug vollst?ndig seinwird.
to hope is that the fallback complete be will'We hope that they will retreat completely.'Fig.
4: discont.
constituent marked OA-MODWie w?rdet ihr das Land nennen, in dem ihrgeboren wurdet?how would you the country call in which youborn were'How would you call the country in which youwere born?'517.
Concluding RemarksThis report has laid out several major annotationcompatibility issues, focusing primarily onconversion among different annotationframeworks that represent the same type ofinformation.
We have provided procedures forconversion, along with their limitations.
As morework needs to be done in this area, we intend tokeep the online version available for cooperativeelaboration and extension.
Our hope is that theconversion tables will be extended and moreannotation projects will incorporate details oftheir projects in order to facilitate compatibility.The compatibility between annotationframeworks becomes a concern when (forexample) a user attempts to use annotationcreated under two or more distinct frameworksfor a single application.
This is true regardless ofwhether the annotation is of the same type (theuser wants more data for a particularphenomenon); or of different types (the userwants to combine different types of information).AcknowledgementThis research was supported, in part, by the Na-tional Science Foundation under Grant CNI-0551615.ReferencesBrants, S., S. Dipper, P. Eisenberg, S. Hansen, E.Knig, W. Lezius, C. Rohrer, G. Smith & H.Uszkoreit, 2004.
TIGER: LinguisticInterpretation of a German Corpus.
In E.Hinrichs and K. Simov, eds, Research onLanguage and Computation, Special Issue.Volume 2: 597-620.Chen, K.-J., Luo, C.-C., Gao, Z.-M., Chang, M.-C., Chen, F.-Y., and Chen, C.-J., 1999.
TheCKIP Chinese Treebank.
In Journ ees ATALAsur les Corpus annot es pour la syntaxe, Talana,Paris VII: pp.85-96.Chen, K.-J.
et al Building and Using ParsedCorpora, 2003.
(A. Abeill?
eds) KLUWER,Dordrecht.
.CKIP, 1995.
Technical Report no.
95-02, thecontent and illustration of Sinica corpus ofAcademia Sinica.
Inst.
of Information Science.G.
Corbett, N. M. Fraser, and S. McGlashan,1993.
Heads in Grammatical Theory.
CambridgeUniversity Press, Cambridge.K.
Van Deemter and R. Kibble, 2001.
OnCoreferring: Coreference in MUC and relatedAnnotation schemes.
Journal of ComputationalLinguistics 26, 4, S. 629-637C.
Fillmore, 1968.
The Case for Case.
In E. Bachand R. T. Harms, eds, Universals in LinguisticTheory.
Holt, Rinehart and Winston, NYC.
Fillmore, P. Kay & M. O?Connor.
1988.Regularity and Idiomaticity in GrammaticalConstructions: The Case of Let Alone.,Language,  64:  501-538.J.
S. Gruber, 1965.
Studies in Lexical Relations.Ph.D.
thesis, MITE.
Hajicov and M. Ceplov, 2000.
Deletions andTheir Reconstruction in TectogrammaticalSyntactic Tagging of Very Large Corpora.
InProceedings of Coling 2000:  pp.
278-284.S.
H. A. Herling, 1821.
?ber die Topik derdeutschen Sprache.
In Abhandlungen desfrankfurterischen Gelehrtenvereins f?r deutscheSprache.
Frankfurt/M.
Drittes St?ck.T.
N. H?hle, 1986.
Der Begriff M`ittelfeld'.Anmerkungen ?ber die Theorie dertopologischen Felder.
In A. Sch?ne (Ed.
),Kontroversen alte und neue.
Akten des 7.Internationalen GermanistenkongressesG?ttingen.
329-340.R.
Jackendoff, 1972.
Semantic Interpretation inGenerative Grammar.
MIT Press, Cambridge.P.
Kingsbury and M. Palmer 2002.
Fromtreebank to propbank.
In Proc.
LREC-2002H.
Lee, C.-N. Huang,  J. Gao and X.
Fan, 2004.Chinese chunking with another type of spec.
InSIGHAN-2004.
Barcelona: pp.
41-48.B.
Levin 1993.
English Verb Classes andAlternations: A Preliminary Investigation.
Univ.of Chicago Press.C.
Manning and H. Sch?tze.
1999.
Foundationsof Statistical Natural Language Processing, MIT.52A.
Meyers, R. Reeves, C. Macleod, R. Szekely,V.
Zielinska, B.
Young, and R. Grishman, 2004.The NomBank Project: An Interim Report.
InNAACL/HLT 2004 Workshop Frontiers inCorpus Annotation.A.
Meyers, 1995.
The NP Analysis of NP.
InPapers from the 31st Regional Meeting of theChicago Linguistic Society, pp.
329-342.D.
M. Perlmutter and P. M. Postal, 1984.
The 1-Advancement Exclusiveness Law.
In D. M.Perlmutter & C. G. Rosen, eds 1984.
Studies inRelational Grammar 2.
Univ.
of Chicago Press.D.. M. Perlmutter, 1984.
Studies in RelationalGrammar 1.
Univ.
of Chicago Press.M.
Poesio, 1999.
Coreference, in MATEDeliverable 2.1, http://www.ims.uni-stuttgart.de/projekte/mate/mdag/cr/cr_1.htmlM.
Poesio, 2004.
"The MATE/GNOME Schemefor Anaphoric Annotation, Revisited", Proc.
ofSIGDIAL.M.
Poesio and R. Artstein, 2005.
The Reliabilityof Anaphoric Annotation, Reconsidered: TakingAmbiguity into Account.
Proc.
of ACLWorkshop on Frontiers in Corpus Annotation.J.
Pustejovsky, A. Meyers, M. Palmer, and M.Poesio, 2005.
Merging PropBank, NomBank,TimeBank, Penn Discourse Treebank andCoreference.
In ACL 2005 Workshop: Frontiersin Corpus Annotation II: Pie in the Sky.M.
Reis, 1982.
"Zum Subjektbegriff imDeutschen".
In: Abraham, W.
(Hrsg.
):Satzglieder im Deutschen.
Vorschl?ge zursyntaktischen, semantischen und pragmatischenFundierung.
T?bingen: Narr.
171-212.C.
G. Rosen, 1984.
The Interface betweenSemantic Roles and Initial GrammaticalRelations.
In D.. M. Perlmutter and C. G. Rosen,eds, Studies in Relational Grammar 2.
Univ.
ofChicago Press.J.
R. Ross,  1967.
Constraints on Variables inSyntax.
Doctoral dissertation, MIT.I.
A.
Sag and J. D. Fodor, 1994.
Extractionwithout traces.
In R. Aranovich, W. Byrne, S.Preuss, and M. Senturia, eds, Proc.
of theThirteenth West Coast Conference on FormalLinguistics, volume 13,  CSLI Publications/SLA.S.
Salmon-Alt and L. Romary, RAF: towards aReference Annotation Framework, LREC 2004S.
Shaumyan, 1977.
Applicative Grammar as aSemantic Theory of Natural Language.
ChicagoUniv.
Press.H.
Telljohann, E. Hinrichs, S. K?bler and H.Zinsmeister.
2005.
Stylebook of the T?bingerTreebank of Written German (T?Ba-D/Z).Technical report.
University of T?bingen.C.
Thielen and A. Schiller, 1996.
Ein kleines underweitertes Tagset f?rs Deutsche.
In: Feldweg,H.
; Hinrichs, E.W.
(eds.
): WiederverwendbareMethoden und Ressourcen zur linguistischenErschliessung des Deutschen.
Vol.
73 ofLexicographica.
T?bingen: Niemeyer.
193-203.J.-L.Tsai, 2005.
A Study of Applying BTMModel on the Chinese Chunk Bracketing.
InLINC-2005, IJCNLP-2005, pp.21-30.H.
Uszkoreit, 1986.
"Constraints on Order" inLinguistics 24.F.
Xia, M. Palmer, N. Xue, N., M. E. Okurowski,J.
Kovarik, F.-D. Chiou, S. Huang, T. Kroch, andMarcus, M., 2000.
Developing Guidelines andEnsuring Consistency for Chinese TextAnnotation.
In: Proc.
of LREC-2000.
Greece.N.
Xue, F. Chiou and M. Palmer.
Building aLarge-Scale Annotated Chinese Corpus, 2002.In: Proc.
of COLING-2002.
Taipei, Taiwan.N.
Xue, F. Xia,  F.-D. Chiou and M. Palmer,2005.
The Penn Chinese TreeBank: PhraseStructure Annotation of a Large Corpus.Natural Language Engineering, 11(2)-207.53
