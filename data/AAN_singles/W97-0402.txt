A Dialogue Analysis Model with Statistical Speech ActProcessing for Dialogue Machine Translation*J ae -won Lee  and  G i l  Chang K imDept .
of  Computer  Sc ience and  CA IRKorea  Advanced Ins t i tu te  of Sc ience andTechno logy ,  Tae jon ,  305-701, Korea{ j wonl ee, gckim}Ocsone, kaist, ac.
krJungyun SeoDept.
of Computer ScienceSogang UniversitySeoul, 121-742, Koreaseo?nlpeng, sogaag, ac.
krAbst ractIn some cases, to make a proper trans-lation of an utterance in a dialogue, thesystem needs various information aboutcontext.
In this paper, we propose a sta-tistical dialogue analysis model based onspeech acts for Korean-English dialoguemachine translation.
The model uses syn-tactic patterns and N-grams reflecting thehierarchical discourse structures of dia-logues.
The syntactic pattern includes thesyntactic features that are related with thelanguage dependent expressions of speechacts.
The N-gram of speech acts basedon hierarchical recency approximates thecontext.
Our experimental results withtrigram showed that the proposed modelachieved 78.59 % accuracy for the top can-didate and 99.06 % for the top four candi-dates even though the size of the trainingcorpus is relatively small.
The proposedmodel can be integrated with other ap-proaches for an efficient and robust anal-ysis of dialogues.1 IntroductionRecently, special concerns are paid to research on di-alogue machine translation.
Many different aspectsof dialogue, however, make it difficult to translatespoken language with conventional machine transla-tion techniques.
One of the reasons is that a surfaceutterance may represent several ambiguous mean-ings depending on context.
That means such utter-ance can be translated into many different ways de-pending on context.
Interpreting this kind of utter-ances often requires the analysis of contexts.
There-fore, the discourse structure of a dialogue plays avery important role in translating the utterances inthe dialogue.
Discourse structures of dialogues areusually represented as hierarchical structures which*This research is supported in part by the ministry ofinformation and communication of Korea.reflect embedding subdialogues (Grosz and Sidner1986).Many researchers have studied the way how toanalyze dialogues.
One of the representative ap-proaches is the plan-based method (Litman et al1987; Caberry 1989).
Considering that our dia-logue translation system is to be combined withthe speech system to develop an automatic translat-ing telephone, however, the plan-based approach assome limitations.
In an automatic translating tele-phone environment, he system must make one cor-rect translated target sentence for each source sen-tence and must be able to respond in real time.
How-ever, the plan inference is computationally expensiveand is hard to be scaled up.
In order to overcomesuch limitations, we have focused on defining mini-mal approach which uses knowledgebase assmall aspossible while it can handle ambiguous utterances.This paper presents an efficient discourse anal-ysis model using statistical speech act processingfor Korean-English dialogue machine translation.
Inthis model, we suggest a probabilistic model whichuses surface syntactic patterns and the N-gram ofspeech act reflecting the hierarchical structures ofdialogues to decide the speech act of an input sen-tence and to maintain a discourse structure.
Theproposed model consists of two steps : (1) identify-ing the syntactic pattern of an utterance (2) calcu-lating the plausibility for possible speech acts anddiscourse relations.After presenting some motivational examples insection 2, we discuss the statistical speech act .pro-cessing model to analyze discourse structure in sec-tion 3.
In section 4, we describe a method to ana-lyze dialogue structure using the proposed statisticalspeech act processing.
We discuss experimental re-sults for the proposed model in section 5.
Finally,we draw some conclusions.2 Mot ivat ionTranslation of dialogues often requires the analysisof contexts.
That is, a surface utterance may betranslated ifferently depending on context.
In this10section, we present some motivational examples.The word 'yey q in Korean has a number of En-glish expression such as 'yes', 'no', 'O.K:', 'Hello','thanks', and so on (Jae-woong Choe 1996).
Whenthe speech act of the utterance 'yey' is response, itmust be translated as 'yes' or 'no'.
On the otherhand, when the speech act of the utterance is ac-cept, it must be translated as 'O.K.'
.
It is even usedas greeting or opening in Korean.
In this case, 'Hello'is an appropriate xpression in English.The verb 'kulehsupnita' in Korean, also, maybe translated differently depending on context.Kulehsupnila is used to accept the previous utter-ance in Korean.
In this case, it must be translateddifferently depending on context.
The following di-alogue examples how such cases.Dialogue 1A : Hankwuk hotelipnikka?
(Is it Hankwuk Hotel?
)B : Yey, kulehsupnita.
(Yes, It is.
)Dialogue 2A : Kayksil yeyyak hasyesssupnikka?
(Did you reserve a room?
)B : Yey, kulehsupnita.
(Yes, I did.
)To differentiate such cases, a translation systemmust analyze the context of a dialogue.
Since a dia-logue has a hierarchical structure than a linear struc-ture, the discourse structure of a dialogue must beanalyzed to reflect the context in translation.
Thereare the previous plan-based approaches for analyz-ing context in dialogues.
Since it is very difficultto have a complete knowledge, it is not easy to finda correct analysis using such knowledge bases.
Inthis paper, we propose a statistical dialogue analy-sis model based on speech acts for dialogue machinetranslation.
Such model is weaker than the dialogueanalysis model which uses many difference source ,ofknowledge.
However, it is more efficient and robust,and easy to be scaled up.
We believe that this kindof minimal approach is more appropriate for a trans-lation system.3 Statistical Speech Act ProcessingWe construct a statistical dialogue model based onspeech acts as follows.Let D denote a dialogue which consists of a se-quence of n utterances, U1, U2 .
.
.
.
, Un, and let Sidenote the speech act of Ui.
With this notation,1All notations for Korean follow Yale RomanizationSystem notation.Sentence Type \[ - Assert YN-QuestWH-Quest- ImperativeMain-Verbt PV AFRAGLEXEMEAux-Verb I Clue-Word IMust t yey Want aniyoIntent kulemyenPossible ...ServeServe_toMayIntendFigure 1: A Syntactic PatternP(UilUt,U2,...,U i-l) means the probability thatUi will be uttered given a sequence of utterancesU1,U2,...,Ui-1.
As shown in the equation (1),we can approximate P(UilU1, U2,..., Ui-1) by theproduct of the sentential probability P(UilSi) andthe contextual probability P(SilS1,S2,...,Si-1)(Nagata and Morimoto 1994).
In subsequent sec-tions, we describe the details for each probability.P(UitU~, U2,..., U,_,) (1)P(U, IS~)P( S,\[S1, $2 ..... S,_a ).3.1 Sentent ia l  P robab i l i tyThere is a strong relation between the speaker'sspeech act and the surface utterances expressingthat speech act (Allen 1989 ; Andernach 1996).
Thatis, the speaker utters a sentence which most wellexpresses his/her intention (speech act).
This sen-tence allows the hearer to infer what the speaker'sspeech act is.
However, a sentence can be used asseveral speech acts depending on the context of thesentence.The sentential probability P(Ui ISi) represents therelationship between the speech acts and the featuresof surface sentences.
In this paper, we approximateutterances with a syntactic pattern, which consistsof the selected syntactic features.We decided the syntactic pattern which consistsof the fixed number of syntactic features.
SentenceType, Main- Verb, Aux- Verb, Clue- Word are selectedas the syntactic features since they provide strongcues to infer speech acts.
The features of a syntacticpattern with possible entries are shown in figure 1.?
Sentence Type represents the mood of an ut-terance.
Assert, YN-Quest, WH-Quest, Imper-ative are possible sentence types.?
Main- Verb is the type of the main verb in theutterance.
PA is used when the main verb rep-resents a slate and PV for the verbs of type11Table 1: A part of the syntactic patterns extracted from corpusSpeech Act Sentence Type Main- Verb Aux- Verb Clue WordRequest-Act Imperative PV Request NoneRequest-Act YN-Quest PV Possible NoneRequest-Act Assert PV Want NoneAsk-Ref WH-Quest PV None NoneAsk-Ref YN-Quest PJ None NoneAsk-Ref Imperative malhata Request NoneInform Assert PJ None NoneInform Assert PV None NoneRequest-Conf YN-Quest PJ None NoneRequest-Conf YN-Quest FRAG None NoneResponse Assert PJ None yeySuggest Wh-Quest PV Serve Noneevent or action.
Utterances without verbs be-long to FRAG (fragment).
In the case of per-formative verbs (ex.
promise, request, etc.
),lexical items are used as a Main-Verb becausethese are closely tied with specific speech acts.?
Aux-Verb represents the modality such asWant, Possible, Must, and so on.?
Clue-Word is the special word used in the ut-terance having particular speech acts, such asYes, No, O.K., and so on.We extracted 167 pairs of speech acts and syntac-tic patterns from a dialogue corpus automaticallyusing a conventional parser.
As the result of ap-plying these syntactic patterns to all utterances incorpus, we found that the average number of speechact ambiguity for each utterance is 3.07.
Table 1gives a part of the syntactic patterns extracted fromcorpus.Since a syntactic pattern can be matched withseveral speech acts, we use sentential probability,P(UilSi) using the probabilistic score calculatedfrom the corpus.
Equation (2) represents the ap-proximated sentential probability.
F denotes thesyntactic pattern and freq denotes the frequencycount of its argument.P(U~IS,) ~ P(LIS,) = freq(Fi, Si)fTeq(Si) (2)3.2 Contextua l  Probab i l i tyThe contextual probability P(SilS1, $2, .
.
.
,  Si-1) isthe probability that n utterances with speech actSi is uttered given that utterances with speech act$1, $2, ?
?., Si-1 were previously uttered.
Since pre-vious speech acts constrain possible speech acts inthe next utterance, contextual information have animportant role in determining the speech act of anutterance.
For example, if an utterance with ask-refspeech act uttered, then the next speech act wouldbe one of response, request-conf, and reject.
In thiscase, response would be the most likely candidate.The following table shows an example of the speechact bigrams.Si--1 Si Ratioask-ref response 58.46ask-ref request-confirm 18.46ask-ref ask-if 7.69ask-ref ask-ref 3.08ask-ref suggest 3.08ask-ref inform 1.54This table shows that response is the most likelycandidate speech act of the following utterance ofthe utterances with ask-refspeech act.
Also, request-confirm and ask-if are probable candidates.Since it is impossible to consider all preceding ut-terances $1, $2, .
.
.
,  Si-1 as contextual information,we use the n-gram model.
However, simply usingn utterances linearly adjacent to an utterance ascontextual information has a problem due to sub-dialogues which frequently occurred in a dialogue.Let's consider an example dialogue.In dialogue 3, utterances 3-4 are part of an em-bedded segment.
In utterance 3, the speaker asks forthe type of rooms without responding to B's ques-12Dialogue 31.
A : I would like to reserve a room.2.
B : What kind of room do you want?3.
A : What kind of room do you have?4.
B : We have single and double rooms.5.
A : A single room, please.request-actask-refask-refresponseresponsetion (utterance 2).
This subdialogue continues upto the utterance 4.
As shown in the above exam-ple, dialogues cannot be viewed as a linear sequenceof utterances.
Rather, dialogues have a hierarchicalstructure.
Therefore, if we use n utterances linearlyadjacent to an utterance as a context, we cannot re-fleet the hierarchical structure of a dialogue in themodel.Therefore, we approximate the context for an ut-terance as speech acts of n utterances which is hi-erarchically recent to the utterance.
An utteranceA is hierarchically recent to an utterance B if A isadjacent o B in the tree structure of the discourse(Walker 1996).
Equation (3) represents the approxi-mated contextual probability in terms of hierarchicalrecency in the case of using trigram.
In this equa-tion, Ui is adjacent o Uj and Uj is adjacent o Ukin the discourse structure, where 1 _< j < k _< i -  1 .P(SilS1,S2 .
.
.
.
,& - l )  '~' P(SilSj,S~).
(3)RA =RI  =?
request- ~acce  action pt/eJRC/RI/ask-if/ Q~respoO ask-ref _ nse _ Orequest- R~con fiO confirm rm/e O RC : ~4 D iscourse  S t ructure  Ana lys i sNow we can define a discourse structure analysismodel with the statistical speech act processing.Formally, choose Si which maximizes the followingprobabilitymax P( F~IS~ )P( S~ISj, Sk ).
(4)S,where Si is a possible speech act for the utteranceUi.
Uj and Uk are the utterances which Uj is hi-erarchically adjacent o Ui, and Uk to Uj, where 1<_j<k<_ i -1 .In equation (4), one problem is to search all pos-sible Uj that Ui can be connected to.
We use thedialogue transition etworks (DTN) and a stack formaintaining the dialogue state efficiently.
The di-alogue transition etworks describe possible flow ofspeech acts in dialogues as shown in figure 2 (Seoet al 1994, Jin Ah Kim et al 1995).
Since DTNis defined using recursive transition etworks, it canhandle recursively embedded subdialogues.
It worksjust like the RTN parser (Woods 1970).
If a subdi-alogue is initiated, a dialogue transition etwork isinitiated and a current state is pushed on the stack.On the other hand, if a subdialogue is ended, then aGI  : (3inform/responseRI/ -~"-k...JFigure 2: A part of the dialogue transition etworkA:requestacti?n~t'--)RA- I  : v ; ik-ref ~O B : response~RI - I I  u3 u4Figure 3: The transitions of dialogue 313dialogue transition network is ended and a currentstate is popped from the stack.
This process contin-ues until a dialogue is finished.With DTN and the stack, the system makes ex-pectations for all possible speech acts of the nextutterance.
For example, let us consider dialogue 3.Figure 3 shows the transitions with the dialogue 3.In utterance 2, according to the RA diagramin figure 2, B may request-confirm or request-il~formation.
Since B asks for the type of rooms,push operation occurs and a RI diagram is initi-ated.
In utterance 3, A doesn't know the possibleroom sizes, hence asks B to provide such informa-tion.
Therefore, push operation occurs again and anew RI diagram is initiated.
This diagram is con-tinued by response in utterance 4.
In utterance 5,this diagram is popped from the stack by responsefor ask-refin utterance 2.In this state, some cases can be expected for thenext utterance.
The first case is to clarify the ut-terance 5.
The second case is to return to the ut-terance 1.
The last case is to introduce a new sub-dialogue.
Therefore, if we assume that ask-if andrequest-confirm are possible from the syntactic pat-tern of the next utterance, then the following tablecan be expected for the next utterance from the di-alogue transition networks.Uk Uj U~(0:-:init) (0:-:init) (6:B:ask-if)(2:B:ask-ref) (5:A:response) (6:B:ask-if)(2:B:ask-ref) (5:A:response) (6:B:request-conf)(0:-:init) (l:A:request-act) (6:B:ask-if)Since DTN has the same expressive power asATN(Augmented Transition Network) grammar, webelieve that it is not enough to cover the whole phe-nomenon of dialogues.
However, considering the factthat the utterances requiring context for translationis relatively small, it is practically acceptable for di-alogue machine translation.5 Exper iments  and  Resu l tsIn order to experiment the proposed model, we used70 dialogues recorded in real fields such as hotelreservation and airline reservation.
These 70 dia-logues consist of about 1,700 utterances, 8,319 wordstotal.
Each utterance in dialogues was annotatedwith speech acts (SA) and with discourse structureinformation (DS).
DS is an index that represents thehierarchical structure of discourse.
Table 2 showsthe distribution of speech acts in this dialogue cor-pus.
The following shows a part of an annotateddialogue corpus.Table 2: The distribution of speech acts in corpusSpeech Act Type Ratw Speech Act Type Ratioask-ref ask-ifinform responserequest-confirm request-actionsuggest confirmaccept rejectcorrect promiseexpressive greetinggood-bye TotalTable 3: Experimental results1 2 3 4Model I 68.48 % 74.57 % 76.09 % 76.30 %Model II 78.59 % 92.82 % 97.88 % 99.06 %/SP /hote lIKSlEtten pangul wenhasipnikka?/ES/What k ind of room do you want?/SA/ask-ref/DS/\[1\]/SP/customerIKSIEtten pangiisssupnikka?/ES/What k ind of room do you have?/SA/ask - re f/DS/ \ [1 ,1 \ ]We test two models in order to verify the efficiencyof the proposed model.
Model-I is the proposedmodel based on linear recency, where an utterance U/is always connected to the previous utterance Ui-1.Model-II is the model based on hierarchical recency.Table 3 shows the average accuracy of two models.Accuracy figures shown in table 3 are computedby counting utterances that have a correct speechact and a correct discourse relation.
In the closedexperiments, Modelq achieved 68.48 % accuracy forthe top candidate and 76.30 % for the top four can-didates.
In contrast, the proposed model, Model-II, achieved 78.59 % accuracy for the top candidateand 99.06 % for the top four candidates.
Errors inModel-I occurred, because the hierarchical structureof dialogues was not considered.
Although dialoguecorpus are relatively small, the experimental resultsshowed that the proposed model is efficient for ana-lyzing dialogues.146 Conclus ionsIn this paper, we described an efficient dialogue anal-ysis model with statistical speech act processing.
Weproposed a statistical method to decide a speechact of a sentence and to maintain a discourse struc-ture.
This model uses the surface syntactic patternsof the sentence and N-gram of speech acts of thesentences which are discourse structurally recent totile sentence.
Our experimental results with trigramshowed that the proposed model achieved 78.59 %accuracy for the top candidate and 99.06 % for thetop four candidates although the size of the train-ing corpus is relatively small.
This model is weakerthan the dialogue analysis model which uses manydifference source of knowledge.
However, it is moreefficient and robust, and easy to be scaled up.
Webelieve that this kind of statistical approach can beintegrated with other approaches for an efficient androbust analysis of dialogues.ReferencesHwan Jin Choi, Young Hwan Oh, 1996, "Analysis ofIntention in Spoken Dialogue Based on Learningof Intention Dependent Sentence Patterns", Jour-nal of Korea Science Information Society, Vol.23,No.8, pp.862-870, In Korea.Jae-woong Choe, 1996, "Some Issues in Conversa-tional Analysis : Telephone Conversations for Ho-tel Reservation," In Proc.
of Hangul and KoreanLanguage Information Processing, pp.7-16, In Ko-rea.James F. Allen, C. Raymond Perrault, 1980, "Ana-lyzing Intention in Utterances", Artificial Intelli-gence, Vol.15, pp.143-178Elizabeth A. Hinkelman, James F. Allen, 1989,"Two Constraints on Speech Act Ambiguity," InProc.
of th 27th Annual Meeting of the ACL, As-sociation of Computational Linguistics, pp.212-219.Barbara J. Grosz, Candace L. Sidner, 1986, "Atten-tion, Intentions, and the Structure of Discourse",Computational Linguistics, Vol.12, No.3, pp.175-204.Philip R. Cohen, C. Raymond Perrault, 1979, "El-ements of a Plan-Based Theory of Speech Acts",Cognitive Science, Vol.3, pp.177-212.Diane J. Litman, James F. Allen, 1987, "A PlanRecognition Model for Subdialogues in Conversa-tions", Cognitive Science, Vol.11, pp.163-200.Hiroaki Kitano, 1994, "Speech-to-Speech Transla-tion : A Massively Parallel Memory- Based Ap-proach",Kluwer Academic Publishers.Jan Alexandersson, Elisabeth Maier, Nobert Rei-thinger, 1994, "A Robust and Efficient Three-Layered Dialogue Component for a Speech-to-Speech Translation System", Proc.
of the 7th Eu-ropean Association for Computational Linguis-tics, pp.
188-193.Jin Ah Kim, Young Hwan Cho, Jae-won Lee, GilChang Kim, 1995, "A Response Generation inDialogue System based on Dialogue Flow Dia-grams," Natural Language Processing Pacific RimSymposium, pp.634-639.Jungyun Seo, Jae-won Lee, Jae-Hoon Kim, Jeong-Mi Cho, Chang-Hyun Kim, and Gil Chang Kim,1994, "Dialogue Machine Translation Using a Di-alogue Model", Proc.
of China-Korea Joint Sym-posium on Machine Translation, pp.55-63.Masaaki Nagata and Tsuyoshi Morimoto, 1994,"First Steps towards Statistical Modeling of Di-alogue to Predict the Speech Act Type of theNext Utterance", Speech Communication, Vol.15,pp.193-203.Massko Kume, Gayle K. Sato, Kei Yoshimoto,1990, "A Descriptive Framework for Translat-ing Speaker's Meaning", Proc.
of the 4th Euro-pean Association for Computational Linguistics,pp.264-271.Marilyn Walker and Steve Whittaker, 1990, "Mixedinitiative in Dialogue : An Investigation i to Dis-course Segmentation", In Proc.
of the 28th An-nual Meeting of the ACL, Association of Compu-tational Linguistics, pp.70-78.Sandra Caberry, 1989, "A Pragmatics-Based Ap-proach to Ellipsis Resolution", ComputationalLinguistics, Vol.15, No.2, pp.75-96.Toine Andernach, 1996, "A Machine Learning Ap-proach to the Classification of Dialogue Utter-ances", Proceedings of NeMLaP-2, Bilkent Uni-versity, Turkey.Marilyn A. Walker, 1996, "Limited Attention andDiscourse Structure,", Computational Linguistics,Vol.22, No.2, pp.255-264.Woods, W. A., 1970, "Transition Network Gram-mars for Natural Language Analysis," Commun.of the ACM, Vol.13, pp.591-606.15
