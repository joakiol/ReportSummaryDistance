Recognizing Unregistered Names for Mandarin Word IdentificationLiang-Jyh Wang, Wei-Chuan Li, and Chao-Huang ChangComputer and Communication Research Laboratories (CCL)Industrial Technology Research Institute (ITRI)Hsinchu, Taiwail, I~.O.C.E-mail: changch%e0sun3.ccl.itri.org.tw@cunyvm.bitnetAbst rac tWord Identification has been an important and ac-tive issue in Chinese Natural Language Processing.In this paper, a new mechanism, based on the conceptof sublanguage, is proposed for identifying unknownwords, especially personal names, in Chinese newspa-pers.
The proposed mechanism includes title.drivenname recognition, adaptive dynamic word formation,identification of Z-character and 3-character Chinesenames without title.
We will show the e~:perimentalresults for two corpora and compare them with the re-sults by the NTIIU's statistic-based system, the onlysystem that we know has attacked the same problem.The ezperimental results have shown significant im-provements over the WI systems without the nameidentification capability.1 In t roduct ionWord Identification (WI, also known as Segmenta-tion) has been an important and active issue illChinese Natural Language Processing.
Various ap-proaches are proposed for this problem \[1\], such asMM (Maximum Matclfing) method \[8\], RMM (Re-verse Directional Maximum Matching) metlmd, OM(Optimum Matching) method, statistical approaches\[5\], and unification approaches \[12\].
lIowever, thereare still a number of problems to conquer towards asatisfactory WI system.
Among them are a clear defi-nition of Chinese words, an objective valuation suitewith appropriate corpora, and the processing of un-known words (such as personal names, place names,and organization ames).In this paper, we will deal with the problem of un-known words, especially personal names, althougii theproposed approach can be easily extended to coverplace nantes and organization antes.
According toChang, et al \[2\], proper nouns (which compose a ma-jor part of unknown words) account for more thanfifty percent of errors made by a typical system.
Thus,successful processing of proper nouns is essential fora satisfactory WI system.Almost all WI systems use a lexicon to guide thesegmentation process.
In fixed domains such as aclassical novel or technical texts, we can put all pos-sible words in the lexicon and avoid the unknown-word problem.
However, in a dynamic domain suchas newspapers, it is impossible to enumerate all pos-sible words in advance.
For example, some personalnames, such as suspects or victims , often appear inonly one day's news.
Thus, recognition of these per-sonal names and other unknown words is very impor-tant.Chang, et al \[2\] (at National Tsing-Hua Univer-sity, ttsinchu, Taiwan) proposed a Multiple-Corpusapproach to solve the problem.
They consider the WIproblem as a constraint satisfaction problem (CSP)and use a number of corpora to train their statistic-based system.
The probabilities of each Chinese char-acter as a surnanm, the first character and the secondcharacter in a first name are computed based on thetraining.
Using these statistics, two-character andthree.character personal names are proposed to com-pete with the words in the lexicon.
Then, a dynamicprogramming technique is used to decide the mostprobable solution to the CSP.
They reported a 90percent average correct rate of surname-name identi-fication.
To the best of our knowledge, this is the onlygroup that has proposed a solution to the problem.Chang's approach is completely statistic-based andeasy-to-implenmnt.
However, we argue that syntacticand semantic information must be considered in asuccessfid WI system.2 A Sub language ApproachThe concept of sublanguages (i.e., languages in re-stricted domains) has been considered very importantin natural anguage processing \[6, 7\].
A sublanguageusually has its own special syntax, semantics, andstyle, which are more restricted comparing with thelanguage as a whole.
In this paper, we will show howthe study of a sublanguage can help identifying namesand forming them in a dynamic, adaptive way.2.1 ObservationFrom the United News, one of the most popular dailynewspapers in Taiwan, we have acquired a news-paper corpus of more than one million characters.This corpus has been used for building our lexicon,computing statistics, and testing our WI systemsfor spell-checking, preprocessing for speech synthesis,Ac'lXS DE COLING-92.
NAN'r~, 23-28 AOtrr 1992 1 2 3 9 FROC.
OF COLING-92.
NANTES.
AtrG.
23-28, 1992and phoneme-to-word conversion.After studying the segmentation output of thenewspaper corpus, we observed that (1) unknownwords are mostly personal names (translation amesor otherwise), place names, and organization amesin addition to those words that should have been builtin the lexicon (a similar conclusion was obtained byChang's papers); aud (2) when a personal name ap-pears the first time, it is usually accompanied witha title (such as taibel shizhang ~:~b~:~ Taipeimayor} or a role noun (such as jizhe \]~ ~ reporter,houxianren It~j~,~.
candidate).From these observations, we propose the followingmechanisms to help identifying unknown words in theWI process: (1) title-driven ame recognition and (2)adaptive dynamic word tbrmation.2.2 Title-driven Name RecognitionAs we mentioned above, it is not plausible to put allproper names in the lexicon for a dynamic domainsuch as news articles.
Since a new personal nameusually appears with a title or a role noun, we canuse the clue to design a set of word formation rulesin our parsing-based WI system \[11\] (s~ the nextsection).
Part  of the set of rules in augmented CFGformat are :<name> ~-- <tit le> <last> <first>{ Build <last> <first> as a name )<nurse> ~- <last> <first> <tit le>{ Build <last> <first> as a name )<tit le> +- <word>{ Test if <word> is'a title }<last> ~ <word>{ Test if <word> is a surnanae )<first> *-- <word>{ "lest if <word> is 1- or 2-char }<first> ~- <word> <word>{ Test if both <word> are 1-char }A Chinese name usually consists of two to fourcharacters: one- or two-character surname and one-or two-character fi st name.
Furthermore, surnamesare among a limited set.
Thus, in rule 4, the aug-mented part is just a membership test.
We can storethe surname information as a feature in the \[exicalentries.
Similarly, we have title and r~ole featuresin the lexicon for rule 3.
Note that in the currentdesign, translation ames of foreigners and husbandsurname prefixing of married women can not be cor-rectly identified.
However, this approach works foreomanon persoual names that occupy a major part ofunknown words.2.3 Adaptive Dynamic Word Forma-tionAfter a new personal name is recognized through theset of rules described above, the system will dynam-ically build a lexical entry for it.
Thus, if the nameappears in later sentences in the news article, it canbe correctly identified.In Figure 1 is an example for adaptive dy-namic word formation.
In the article, there arefour Chinese names: ni2 shu2 yah2 ~ (4 in-stances), ye4 yingl hao2 ~ ' I~  (1 instance), eai4jial tlng2 ~ (4 instances), and wu2 xun2 long2~:~ (1 iustance).
In first instances, all fournames come with a title: lao3shil ~ (teacher),ji4zhe3 \ ]~ (reporter), er2tong2 ~ (child), andjian3cha2guanl ~i~'E" (prosecutor).
Since thenames are built in the lexicon dynamically, the otherinstances of the names can be identified with higherscores than names without title.
In other words, thenames with title are built with much more confidence.2 .4  Names  w i thout  T i t leIn addition to the names with title or role, the otherpersonal names are proposed through a surname-driven rule.
In other words, when the WI systemmeets a surname word, a personal name proposingrule is invoked although its preference score would bemuch lower than regular words and names with title.2.5 Place Names and OrganizationNamesThe proposed mechanism can be extended to coverplace names and organization ames.
Just llke per-sonal names appear with title, place names can beidentified through the unit such as xian ~ (county),shi i~i (city), jie ff~ (street), lu t~ (road), etc.
Simi-larly, organization names can be identified by the typesuch as gongsi /C~ (company), bu n\[~ (departmentor ministry), ke ~ (section), and so on.
This parthas not yet implemented in our system.3 The SystemSince July 1986, we have been involved in developinga series of Chinese-related NLP systems,'including anEnglish-Chinese MT system, a Japanese-Chinese MT,a Chinese Word Knowledge Base, a Chinese Parser,and a Chinese Spell-Checker.
tIere, we will onlybriefly describe the Chinese WI system as a frontendfor the Chinese Parser.
For more details, the readeris referred to Wang, et al \[11\].We consider the WI process as a parsing processwith word composition grammar, instead of a CSPproblem \[2\], a unification problem \[12\] .
.
.
.
scanningprocess.
A set of Chinese word composition gram-mar rules are designed to capture the characteris-tics of Chinese words.
The grammar epresentationis Augmented CFG which is also used to write theEnglish grammar in our English-Chinese MT system.The parser we used is based on Tomita's GeneralizedLR Parser \[10\].
Itowever, the augmented parts (testsand actions) and preference scoring module have beenadded.AUIES DE COLING-92, NAr~r\].:s.
23-28 no~r 1992 1 2 4 0 PROC.
OF COLING-92.
NANTES, AUG. 23-28, 1992~ ~ ' ~ ~ ~ ~ ~ A ~ ~ ?
~Figure 1: An Example for Adaptive Dynamic Word FormationIll the WI process, the basic unit is a character.A Chinese word is composed of one to five (may belonger) characters.The WI system consists of a lexicon, the word com-position grammar, the preference scoring module, thetest functions, and the parser.The lexicon contains a list of Chinese words (sortedby the internal code order) with the following infor-mation: the characters from wblch the word is com-posed, its frequency count, its part of speech, andsome semantic features (such as title, surname, androle).
The lexicon is a general purpose one; that is,it is built independent of the testing corpora.
Cur-rently, there are more than 90,000 lexical entries inthe lexicon.A rule in the word grammar consists of a context-free part and an augmented part.
Iq addition to theunknown word identification described in the previ-ous section, augmented parts are used for recognizing(1) replication of words; (2) nmnbers; (3) prefixe~;(4) suffixes; and (5) the determiner measure construc-tions.Since the word parser would produce two or moreparses for an ambiguous sentence, a preference scor-ing module has been designed to choose the correctparse.
Currently, the preference score is assignedbased on (1) the length of the word (longer wordsare preferred), (2) the frequency count, and (3) se-mantic consideration ( e.g., three-character personalnames are preferred to two-character ones).
The WIsystem is written in Common Lisp, running on a TIMicro-Explorer machine.4 Experimental ResultsBefore we present he experimental results, two per-formance indices, recall rate and precision rate, of aWI system are defined below following Sproat andShih \[9\] and Chang, et al \[3\].
Let C be the segmen-tation results hy the computer, H the results by thehuman (the correct results), and I the intersection ofC and II.
Then, recall rate is I divided by tI, and pre-cision rate I divided by C. Fo~" example, if there are 20words in a sentence (i.e., H equals 20), the WI systemproduces 22 words for the sentence (i.e., C equals 22),and there are 18 words m common (i.e., I equals 18),tile recall rate would be 0.90 and the precision rate0.82.To demonstrate tile proposed mechanism, we havetested the W\[ system with two corpora: (1) ten arti-cles from a newspaper corpus, the United Daily cor-pus, (2) 61 sentences from Chang et al \[4\].
The firstcorpus is selected from the United Daily on March 8,1991.
The selection criterion is that the article doesnot contain any table or figure and, preferably, con-tains Chinese names.
The second corpus is composedof difficult cases for which the NTHU WI system ei-ther can not identify the names or overgenerates someChinese names.In the experiment, we use four versions of the WIsystem to segment he ten articles.
Version 1 is theWI system without name recognition capability, Ver-sion 2 the system recognizing only names with title,Version 3 the system recognizing both names withtitle and 3-character names, and Version 4 also rec-ognizing 2-character names.Recall rates (RR) and precision rates (PK) are com-puted automatically by comparing the segmentationoutput with the correct answers egmented by human.The experinmntal results are summarized in Table 1.From the table, we can observe the following facts:1.
Version 2 (It~:96.17, PR:93.46) has a signif-icant improvement over Version 1 (RI~:94.77,PR:89.28).
In other words, the capability forname recognition is very important in a WI sys-tem.
Although Version '2 only has a limited capa-bility (for names with title), the improvement israther apparent.
Note that in Version 2, the dy-namic word formation mechanism is much moreuseful than in Version 3 or 4.2.
Version 3 has the best results (RR.:97.51,PR.
:98.19) among the four versions.
It is bettertitan Version 2 for tile obvious reason: the capa-bility for identifying 3-character names withouttitle.3.
Although Version 4 has one more function, iden-tification of 2-character names without title,than Version 3, the result (ITK:96.32, PR:97.51)is slightly worse than Version 3.
This is mainlyACTF.S DE COLING-92, Nhma~s, 23-28 ho~r 1992 1 2 4 1 Pane.
or COLING-92, Nx~rrEs, Auo.
23-28, 1992setxlx5x6x7x8x17 279 93.17 84.92 93.88 87.88x25 343 92.13 84.72 92.13 84.72x26 260 98.85 " 96.62 99.62 98.85x27 311 91.64 80.97 92.60 83.24x38 216 97.70 94.80 100.00 100.00\[ Total I 2,728 \] 94.77 89.28 96.17 93.46 97.51Table I: Experimentalresultsfor the firstVersion 1 Version 2 Version 3 Version 4RRI PR1 RR2 PR2 RR3 PR3 RR4 PR497.79 95.38 98.42 96.59 97.48 96.26 95.58 94.39'89.13 82.00 91.30 95.45 '91.30 95.45 91.30 95.4593.45 85.33 99.40 98.82 99.40 98.82 98.21 98.2195.19 91.45 95.19 91.45 96.14 ?97.32 93.98 95.6398.66 96.59 99.20 97.63 98A2 98.92 97.32 98.6498.57 98.57 94.62 97.4697.95 98.82 97.37 98.52100.00 100.00 99.23 99'16196.14 97.71 94.53 96.71100100 \]0O.00 99.23 99.6298.19 96,32 97.51#words31746168415373corpusbecause the gain (recognition of 2-characternames) is less than the loss (misintepreting 2single-character words as a 2-character name).4.
We will analyze the imperfections by the WI sys-tem in a subsection after the comparison withNTIIU's system.Compar i son  w i th  NTHU's  SystemIn Chang, et al \[4\], which we will call NTHU's sys-tem, they reported a 95 percent precision rate and arecall rate greater than 95 percent, and listed 5 sam-plea (A-samples) the name in which their system canidentify correctly, 34 examples (B-samples) for whichthe names are missed, and 22 examples (C-samples)for which Chinese names are over-generated.
Amongthem, we found 3 A-samples, 6 B-samples, and 3C-samples contain personal names with title.
SinceNTHU's system is completely statistic-based, it cannot make use of the title information.
On the otherhand, our sublanguage-based system would processthese samples correctly.These 61 examples are fed to our WI system forcomparison of the name recognition algorithms.
Thefollowing results are for reference only, since the com-parison is rather unfair (the examples are mostly theeases their system can not recognize correctly).1.
For the 5 A-samples, our system can recognizefour of them.
The only A-sample it failed toidentify is: huang2 rong2 you2 you2 de0 dao4jli ~ ~ ~ ~ il~ .
Our segmentation result ishuang2-rong2-you2 you2 deO dao4, while the cor-rect result is huang2-rong2 you2-you2 de0 dao4.The reason is (l) our lexicon does not have theadverb you2-you2, and (2) we prefer 3-characternames over 2-character ones.
Note that NTHU'ssystem can process all 5 cases successfully.2.
For the 34 B-samples, our system can identify25 of them correctly.
That  is, there are 9 B-samples the names in which both our system andNTHU's system can not identify.
We will discussthe reasons why these cases can not be recognizedin the next subsection.3.
For the 22 C-samples for which NTHU's systemovergenerates personal names, our system hasprocessed 16 of them correctly.
We will discussthe reasons in the next section why our systemalso overgenerates personal names for the other6 C-samples.4.
For these 61 samples, our system can process 45of them correctly.Some Imper fect ionsThere are still some problems remained unsolved inour WI system.
Some are problems for WI systems ingeneral.
'rite others are specific to name recognitionsystems only.1.
Two-character names are difficult to recognize,especially when followed by a single-characterword.
For example, in yil jing4 gangl ha3 fa3bao3 qu3 chul ~1~1\ ]~,~\ ]~ , yil-jing4 is a 2-chaxacter name.
However, our WIsystem produces a 3-character name yil-jing4-gangl, since gangl (just) is a single characterword.
Although human usually can identify thenames correctly by context, our Wl  system pro-posed the 3-character names understandably.2.
The name of a maffied woman is usually pre-fixed with her husband's urname.
Thus, a 3-character name would become 4-character, i.e.,husband's urname, father's surname, and a 2-character given name, e.g., xu3 lin2 yah2 mei2~ 1 ~  .
Currently, this kind of namescannot be identified correctly, although a word-grammar ule can be easily added.3.
Some single-character surnames, such as lisa2(year), tangl ~ (soup), ceng2 ~ (once), andhusng2 ~ (yellow), are common single-characterwords.
Thus, the name recognition algorithmsometimes overgenerates a personal name byACRES DE COLING-92, NANTES.
23-28 AOt)r 1992 1 2 4 2 Paoc.
OF COLING-92.
NANTES, AUG. 23-28.
1992combining one such word with two followingcharacters.4.
Some surnames are rather unusual, such aslian ~ (lotus), ping2 ~ (duckweed), and que4(but).
This would make the names not recog-nizable.
There is a tradeoff between a completesurname list and a minimal common surnamelist.
On the one end, a complete surname listwould help name recognition but it helps over-generation as well.
On the other end, a minimallist would limit the overgeneratiou while missingsome would-be names.5.
Some single-character words are very difficultto identify when they can be grouped as two-character words with the characters in the neigh-bout.
A famous example is ba3 shou3 ~ (ahandle).
The problem is very difficult to solvefor any WI systems.6.
Even when the title information is used, overgen-eration of personal names is still hard to avoid.In the following is one of such examples:?
yao l  qlng3 tai2 hal3 di4 fang1 fa3 yuan4zhangl lu3 xue2 jian3 eha3 guanl tan2 yao4wu4 lan4 yong4 wen4 ti2.Both the correct name zhangl-lu3-xue2~\[~Jl~ and an overgenerated name tan2-yao4-wu4 1 ~  are produced by our system.
Afine adjustment of the scoring fnnctiou should beable to overcome this problem.
However, thereare so many similar problems uch that it wouldbe a real problem when we develop a full-scalesystem.7.
In Version 4 of our system, 2-character nameswithout title are recognized in addition to thoseof Version 3, i.e., names with title and 3-character names without title.
However, boththe recall rate and precision rate of Version 4 arelower than those of Version 3.
The major reasonis that too many 2-character names are gener-ated.5 ConclusionIn this paper, we have proposed a new mechanismfor identifying unknown words, especially personalnames, in Chinese newspapers.
The proposed mecha-nism includes title-driven ame recognition, adaptivedynamic word formation, identification of 2-characterand 3-character Chinese names without title.
Wehave also shown the experinmntal results for two cor-pora and have compared them with the results by theNTHU's WI system.Although there are still some problems remainedunsolved (as discussed above), the experimental re-sults have shown significant improvements over theWI systems without the name identification capabil-ity.AcknowledgementThis paper is a partial result of the projectNo.
33H3100 conducted by the Industrial TechnologyResearch Institute, Taiwan, under the sponsorship ofthe Ministry of Economic Affairs, R.O.C.References\[1\] ACCC.
The Status and Profess of Chinese LanguageProcessing Technology.
Association for Common Chi-nese Code, International, Beijing, China, 1991.\[2\] J.-S. Chang, S.-D. Chen, Y. Chen, J. S. Liu, and S.-J.Ker.
A Multiple-corpus Approach to Identification ofChinese Surname-names.
In Proceedings o\] NaturalLanguage Processing Pacific Rim Symposium, pages87-91, 1991.\[3\] J.-S. Chang, C.-D. Chen and S.-D. Chang.
Chineseword segmentation through constraint satisfactionand statistical optimization.
In Proc.
of ROCLINGIV, pages 147-165, 1991.\[4\] ~f~t~,  g /~ ?
~ ,  ~1~/?
?
~ l i~ i$ .
~;N/i~J~r~#~:t$iQ'~ , q t  ' 1 9 9 I .\[8\] C. K. Fan and W. H. TsM.
Automatic word identi-fication in Chinese sentences by the rela.x,~tion tech-nique.
In Prec.
of National Computer Symposium,pages 423-431, Taipei, Taiwan, 1987.\[6\] R. Grishman and R. Kittredge, editors.
AnalyzingLanguage in Restricted Domains: Sublanguage De-~crlption and Processing.
Lawrence Erlbaum Asso-dates, HillsdaJe, N J, 1986.\[7\] R. Kittredge and J. Lehrberger, editors.
Sublau-guage: Studies of language in restricted domains.Waiter de Gruyter, Berlin, 1982.\[8\] N. Liana.
On the automatic segmentation f Chinesewords and related theory.
In Proc.
of the 1987 In-ternational Conference on Chinese information pro-cessing, pages 454-459, Beijing, 1987.\[9\] R. Sprout and C. Shih.
A statistic method for findingword boundaries in Chinese text.
Computer Process-ing of Chinese ~ Oriental Languages, 4(4):336-351,March, 199D.\[1O\] M. Tomita.
Eff~clent Parsing/or Natural Language.Kluwer Academic Publishers, 1986.\[11\] L.-J.
Wang, T. Pei, W.-C. Li, and L.-C. Huang.
Aparsing method for identifying words in MandarinChinese.
Ia Proc.
of HCA1.91, pages 1018-1023,1991.\[12\] C.-L. Yeh and 14.-J.
Lee.
Unification-based wordidentification for Mandarin Chinese sentences.
Proc.o.\[ 1988 ICCPCOL, pages 27-32, Toronto, Canada,1988.ACRES DE COL1NG-92, NANTES, 23-28 aOt3T 1992 1 2 4 3 PROC.
OF COLING-92, NAturEs.
AUG. 23-28, 1992
