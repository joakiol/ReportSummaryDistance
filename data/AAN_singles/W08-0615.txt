BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 94?95,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics 1Conditional Random Fields and Support Vector Machines for DisorderNamed Entity Recognition in Clinical TextsDingcheng Li Karin Kipper-Schuler Guergana SavovaUniversity of Minnesota Mayo Clinic College of Medicine Mayo Clinic College of MedicineMinneapolis, Minnesota, USA Rochester, Minnesota, USA Rochester, Minnesota, USAlixxx345@umn.edu schuler.karin@mayo.edu savova.guergana@mayo.eduAbstractWe present a comparative study betweentwo machine learning methods, ConditionalRandom Fields and Support Vector Ma-chines for clinical named entity recognition.We explore their applicability to clinicaldomain.
Evaluation against a set of goldstandard named entities shows that CRFsoutperform SVMs.
The best F-score withCRFs is 0.86 and for the SVMs is 0.64 ascompared to a baseline of 0.60.1 Introduction and backgroundNamed entity recognition (NER) is the discoveryof named entities (NEs), or textual mentions thatbelong to the same semantic class.
In the biomedi-cal domain NEs are diseases, signs/symptoms, ana-tomical signs, and drugs.
NER performance is highas applied to scholarly text and newswire narra-tives (Leaman et al, 2008).
Clinical free-text, onthe other hand, exhibits characteristics of both in-formal and formal linguistic styles which, in turn,poses challenges for clinical NER.
ConditionalRandom Fields (CRFs) (Lafferty et al, 2001) andand Support Vector Machines (SVMs) (Cortes andVapnik, 1995) are machine learning techniqueswhich can handle multiple features during learn-ing.
CRFs?
main strength lies in their ability to in-clude various unrelated features, while SVMs?
inthe inclusion of overlapping features.
Our goal isto compare CRFs and SVMs performance forclinical NER with focus on disease/disorder NEs.2 Dataset and featuresOur dataset is a gold standard corpus of 1557 sin-gle- and multi-word disorder annotations (Ogren etal., 2008).
For training and testing the CRF andSVM models the IOB (inside-outside-begin) nota-tion (Leaman, 2008) was applied.
In our project,we used 1265 gold standard annotations for train-ing and 292 for testing.
The features used for thelearning process are described as follows.
Diction-ary look-up is a binary value feature that representsif the NE is in the dictionary (SNOMED-CT).
Bagof Words (BOW) is a representation of the contextby the unique words in it.
Part-of-speech tags(POS) of BOW is the pos tags of the contextwords.
Window size is the number of tokens repre-senting context surrounding the target word.
Ori-entation(left or right) is the location of the featurein regard to the target word.
Distance is the prox-imity of the feature in regard to the target wordCapitalization has one of the four token-based val-ues: all upper case, all lower case, mixed_case andinitial upper case.
Number features refer to thepresence or absence of related numbers.
Featuresets are in Table 1.3 Results and discussionFigure 1 shows the CRF results.
The F-scores, re-call and precision for the baseline dictionary look-up are 0.604, 0.468 and 0.852 respectively.
WhenBOW is applied in feature combination 2 resultsimprove sharply adding 0.15, 0.17 and 0.08 pointsrespectively.
The F-score, recall and precision im-prove even further with the capitalization feature to0.858, 0.774 and 0.963 respectively.
Figure 2shows SVM results.
The addition of more featuresto the model did not show an upward trend.
Thebest results are with feature combination 1 and 3.The F-score reaches 0.643, which although an im-provement over the baseline greatly underperformsCRF results.
BOW features seem not discrimina-tive with SVMs.
When the window size increasesto 5, performance decreases as demonstrated infeature combinations 2, 4 and 8.
Results with fea-ture combination 4, in particular, has a pronounceddownward trend.
Its F-score is 0.612, a decrease by0.031 compared with Test 1 or Test 3.
Its recalland precision are 0.487 and 0.822 respectively, adecrease by 0.036 and 0.01 respectively.
This sup-ports the results achieved with CRFs where asmaller window size yields better performance.942No Features1 dictionary look-up (baseline)2 dictionary look-up+BOW+Orientation+distance (Win-dow 5)3 dictionary look-up + BOW + Orientation + distance(Window 3)4 dictionary look-up + BOW  + POS + Orientation +distance (Window 5)5 dictionary look-up + BOW +POS + Orientation + dis-tance (Window 3)6 dictionary look-up + BOW +POS + Orientation + dis-tance (Window 3) + bullet number7 dictionary look-up + BOW + POS + Orientation +distance(Window 3) + measurement8 dictionary look-up + BOW + POS + Orientation +distance  (Window 5) + neighboring number9 dictionary look-up + BOW +POS + Orientation + dis-tance (Window 3) + neighboring number10 dictionary look-up + BOW +POS + Orientation + dis-tance (Window 3)+neighboring number+measurement11 dictionary look-up+BOW+POS+Orientation (Window3)+neighboring number+bullet number + measurement12 dictionary look-up + BOW +POS + Orientation+distance (Window 3) + neighboring number + bulletnumber + measurement + capitalizationTable 1: Feature combinationsFigure 1: CRF evaluation resultsFigure 2: SVM evaluation resultsAs the results show, context represented by theBOW feature plays an important role indicating theimportance of the words surrounding NEs.
On theother hand, POS tag features did not bring muchimprovement, which perhaps hints at a hypothesisthat grammatical roles are not as important as con-text in clinical text.
Thirdly, a small window size ismore discriminative.
Clinical notes are unstruc-tured free text with short sentences.
If a larger win-dow size is used, many words will share similarfeatures.
Fourthly, capitalization is highly dis-criminative.
Fifthly, as a finite state machine de-rived from HMMs, CRFs can naturally considerstate-to-state dependences and feature-to-state de-pendences.
On the other hand, SVMs do not con-sider such dependencies.
SVMs separate the datainto categories via a kernel function.
They imple-ment this by mapping the data points onto an opti-mal linear separating hyperplane.
Finally, SVMsdo not behave well for large number of featurevalues.
For large number of feature values, itwould be more difficult to find discriminative linesto categorize the labels.4 Conclusion and future workWe investigated the use of CRFs and SVMs fordisorder NER in clinical free-text.
Our resultsshow that, in general, CRFs outperformed SVMs.We demonstrated that well-chosen features alongwith dictionary-based features tend to improve theCRF model?s performance but not the SVM?s.AcknowledgementsThe work was partially supported by a BiomedicalInformatics and Computational Biology scholar-ship from the University of Minnesota.ReferencesCorinna Cortes and Vladimir Vapnik.
Support-vectornetwork.
Machine Learning, 20:273-297, 1995.John Lafferty, Andrew McCallum and FernandoPereira.
Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data.In Proceedings of the Eighteenth International Con-ference on Machine Learning (ICML-2001), 2001.Robert Leaman and Graciela Gonzalez.
BANNER: anExecutable Survey of Advances in BiomedicalNamed Entity Recognition.
Pacific Symposium onBiocomputing 13:652-663.
2008.Philip Ogren, Guergana Savova and Christopher GChute.
Constructing evaluation corpora for auto-mated clinical named entity recognition.
Proc LREC2008.95
