Proceedings of the 8th Workshop on Asian Language Resources, pages 14?21,Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language ProcessingConsiderations on Automatic Mapping Large-Scale Heterogene-ous Language Resources: Sejong Semantic Classes and KorLexHeum ParkCenter for U-Port ITResearch and EducationPusan National Universityparheum2@empal.comAesun YoonLI Lab.
Dept.
of FrenchPusan National Universityasyoon@pusan.ac.krWoo Chul Park andHyuk-Chul Kwon*AI Lab Dept.
of ComputerSciencePusan National Universityhckwon@pusan.ac.krAbstractThis paper presents an automatic map-ping method among large-scale hetero-geneous language resources: SejongSemantic Classes (SJSC) and KorLex.KorLex is a large-scale Korean Word-Net, but  it lacks specific syntactic &semantic information.
Sejong Electron-ic Dictionary (SJD), of which semanticsegmentation depends on SJSC, hasmuch lower lexical coverage thanKorLex, but shows refined syntactic &semantic information.
The goal of thisstudy is to build a rich language re-source for improving Korean semanti-co-syntactic parsing technology.
There-fore, we consider integration of themand propose automatic mapping me-thod with three approaches: 1) Infor-mation of Monosemy/Polysemy ofWord senses (IMPW), 2) Instances be-tween Nouns of SJD and Word sensesof KorLex (INW), and 3) SemanticallyRelated words between Nouns of SJDand Synsets of KorLex (SRNS).
Weobtain good performance using com-bined three approaches: recall 0.837,precision 0.717, and F1 0.773.1 IntroductionWhile remarkable progress has been made inKorean language engineering on morphologi-cal level during last two decades, syntactic andsemantic processing has progressed moreslowly.
The syntactic and semantic processingrequires 1) linguistically and formally welldefined argument structures with the selection-al restrictions of each argument, 2) large andsemantically well segmented lexica, 3) mostimportantly, interrelationship between the ar-gument structures and lexica.
A couple of lan-guage resources have been developed or can beused for this end.
Sejong Electronic Dictiona-ries (SJD) for nouns and predicates (verbs andadjectives) along with semantic classes (Hong2007) were developed for syntactic and seman-tic analysis, but the current versions do notcontain enough entries for concrete applica-tions, and they show inconsistency problem.
AKorean WordNet, named KorLex (Yoon & al,2009), which was built on Princeton WordNet2.0 (PWN) as its reference model, can providemeans for shallow semantic processing butdoes not contain refined syntactic and semanticinformation specific to Korean language.
Ko-rean Standard Dictionary (STD) provides alarge number of entries but it lacks systematicdescription and formal representation of wordsenses, like other traditional dictionaries forhumans.
Given these resources which weredeveloped through long-term projects (5 ?
10years), integrating them should result in signif-icant benefits to Korean syntactic and semanticprocessing.The primary goal of our recent work includ-ing the work reported in this paper is to build alanguage resource, which will improve Koreansemantico-syntactic parsing technology.
Weproceed by integrating the argument structuresas provided by SJD, and the lexical-semantichierarchy as provided by KorLex.
SJD is alanguage resource, of which all word sensesare labeled according to Sejong semanticclasses (SJSC), and in which selectional re-* Corresponding Author14strictions are represented in SJSC as for theargument structures of predicates.
KorLex is alarge scale language resource, of which thelexical-semantic hierarchies and other lan-guage?independent semantic relations betweensynsets (synonym sets) share with those ofPWN, and of which Korean language specificinformation comes from STD.
The secondarygoal is the improvement of three resources as aresult of comparing and integrating them.In this paper, we report on one of the operat-ing steps toward to our goals.
We linked eachword sense of KorLex to that of STD by hand,when the former was built in our previouswork (Yoon & al.
2009).
All predicates in SJDwere mapped to those of STD on word senselevel by semi-automatic mapping (Yoon,2010).
Thus KorLexVerb and KorLexAdj havesyntactico-semantic information on argumentstructures via this SJD - STD mapping.
How-ever, the selectional restrictions provided bySJD are not useful, if SJSC which representsthe selectional restrictions in SJD is not linkedto KorLex.
We thus conduct two mapping me-thods between SJSC and upper nodes of Kor-LexNoun: 1) manual mapping by a PH.D incomputational semantics (Bae & al.
2010), and2) automatic mapping.
This paper reports thelatter.
Reliable automatic mapping methodsamong heterogeneous language resourcesshould be considered, since the manual map-ping among large-scale resources is a verytime and labor consuming job, and might lackconsistency.
Less clean resources are, muchharder and more confusing manual mapping is.In this paper, we propose an automatic map-ping method of those two resources with threeapproaches to determine mapping candidatesynsets of KorLex to a terminal node of SJSC:1) using information of monosemy/polysemyof word senses, 2) using instances betweennouns of SJD and word senses of KorLex, and3) using semantically related words betweennouns of SJD and word senses of KorLex.
Wecompared the results of automatic mappingmethod with three approaches with those ofmanual mapping aforementioned.In the following Section 2, we discuss re-lated studies concerning language resourcesand automatic mapping methods of heteroge-neous language resources.
In Section 3, weintroduce KorLex and SJD.
In Section 4, wepropose an automatic mapping method withthree approaches from semantic classes of SJDto synsets of KorLex.
In Section 5, we com-pare the results of automatic mapping withthose of manual mapping.
In Section 6, wedraw conclusions and future works.2 Related WorksMost existing mappings of heterogeneous lan-guage resources were conducted manually bylanguage experts.
The Suggested UpperMerged Ontology (SUMO) had been fullylinked to PWN.
For manual mapping of be-tween PWN and SUMO, it was consideredsynonymy, hypernymy and instantiation be-tween synsets of PWN and concepts of SUMO,and found the nearest instances of SUMO forsynsets of PWN.
Because the concept items ofSUMO are much larger than those of PWN, itcould be mapped between high level conceptsof PWN and synonymy concepts of SUMOeasily.
(Ian Niles et al2003).
Dennis Spohr(2008) presented a general methodology tomapping EuroWordNet to the SUMO for ex-traction of selectional preferences for French.Jan Scheffczyk et al (2006) introduced theconnection of FrameNet to SUMO.
They pre-sented general-domain links between Frame-Net Semantic Types and SUMO classes inSUOKIF and developed a semi-automatic,domain-specific approach for linking Frame-Net Frame Elements to SUMO classes(Scheffczyk & al.
2006).
Sara Tonelli et al(2009) presented a supervised learning frame-work for the mapping of FrameNet lexicalunits onto PWN synsets to solve limited cover-age of semantic phenomena for NLP applica-tions.
Their best results were recall 0.613, pre-cision 0.761 and F1 measure 0.679.Considerations on automatic mapping me-thods among language resources were alwaysattempted for the sake of efficiency, using si-milarity measuring and evaluating methods.Typical traditional evaluating methods be-tween concepts of heterogeneous language re-sources were the dictionary-based approaches(Kozima & al 1993), the semantic distancealgorithm using PWN (Hirst & al 1998), thescaling method by semantic distance betweenconcepts (Sussna 1997), conceptual similaritybetween concepts (Wu & al 1994), the scaled15semantic similarity between concepts (Leacock1998), the semantic similarity between con-cepts using IS-A relation (Resnik 1995), themeasure of similarity between concepts (Lin1998), Jiang and Conrath?s (1997) similaritycomputations to synthesize edge and nodebased techniques, etc.Satanjeev et al (2003) presented a newmeasure of semantic relatedness between con-cepts that was based on the number of sharedwords (overlaps) in their definitions (glosses)for word sense disambiguation.
The perfor-mances of their extended gloss overlap meas-ure with 3-word window were recall 0.342,precision 0.351 and F1 0.346.
Siddharth et al(2003) presented the Adapted Lesk Algorithmto a method of word sense disambiguationbased on semantic relatedness.
In addition,Alexander et al(2006) introduced the 5 exist-ing evaluating methods for PWN-based meas-ures of lexical semantic relatedness and com-pared the performance of typical five measuresof semantic relatedness for NLP applicationsand information retrieval.
Among them, Jiang-Conrath?s method showed the best perfor-mances: precision 0.247, recall 0.231 and F10.211 for Detection.In many studies, it was presented a varietyof the adapted evaluating algorithms.
Amongthem, Jiang-Conrath?s method, Lin?s themeasure of similarity and Resnik?s the seman-tic similarity show good performances (Alex-ander & al 2006, Daniele 2009).3 Language resources to be mapped3.1 KorLex 1.5KorLex 1.5 was constructed from 2004 to2007.
Different from its previous version(KorLex 1.0) which preserves all semanticrelations among synsets of PWN, KorLex 1.5modifies them by deletion/correction ofexisting synsets, addition of new synsets andconversion of hierarchical structure.
Currently,KorLex includes nouns, verbs, adjectives,adverbs and classifiers: KorLexNoun,KorLexVerb, KorLexAdj, KorLexAdv andKorLexClas, respectively.
Table 1 shows thesize of KorLex 1.5, in which ?Trans?
means thenumber of synsets translated from PWN 2.0and ?Total?
is the number of manually addedsynsets including translated ones.Word FormsSynsets WordSensesTrans TotalKorLexNoun 89,125 79,689 90,134 102,358KorLexVerb 17,956 13,508 16,923 20,133KorLexAdj 19,698 18,563 18,563 20,905KorLexAdv 3,032 3,664 3,664 3,123KorLexClas 1,181 - 1,377 1,377Total 130,992 115,424 130,661 147,896Table  1.
Product of KorLex 1.5KorLexNoun includes 25 semantic domainswith 11 unique beginners with maximum 17levels in depth and KorLexVerb includes 15semantic domains with 11 unique beginnerswith maximum 12 levels in depth.
Basically,KorLex synsets inherit the semantic informa-tion of PWN synsets mapped to them.
Thesynset information of PWN consists of synsetID, semantic domain, POS, word senses, se-mantic relations, frame information, and so on.We linked each word sense of KorLex 1.5 tothat of STD by hand, when the former wasbuilt in our previous work (Yoon & al.
2009).STD includes 509,076 word entries with about590,000 word senses.
It contains a wide cover-age for general words and a variety of examplesentences for each meaning.
More than 60% ofword senses in KorLex 1.5 are linked to thoseof STD.
KorLex 1.5, thus, inherits lexical rela-tions described in STD, but both resources lackrefined semantic-syntactic information.3.2 Sejong Electronic DictionarySJD was developed during 1998-2007 manual-ly by linguists for a variety of Korean NLPapplication as a general-purpose machine read-able dictionary.
Based on Sejong semanticclasses (SJSC), approximately 25,000 nounsand 20,000 predicates (verbs and adjectives,SJPD) contain refined syntactic and semanticinformation.SJSC is a set of hierarchical meta-languagesclassifying word senses and it includes 474terminal nodes and 139 non-terminal nodes,and 6 unique beginners.
Each unique beginnerhas levels from minimum 2 to maximum 7 le-vels in depth.
Sejong Noun Dictionary (SJND)contains 25,458 entries and 35,854 wordsenses having lexical information for each en-try: semantic classes of SJSC, argument struc-tures, selectional restrictions, semantically re-lated words, derivatioinal relations/words et al16Figure 1.
Correlation of lexical informationamong SJND, SJPD and SJSCFigure 1 shows the correlation of lexical in-formation among SJND, SJPD and SJSC.
Cer-tainly, that information of SJD should be ap-plied to a variety of NLP applications: infor-mation retrieval, text analysis/generation, ma-chine translations, and various studies andeducations.
However, SJD has much lowerlexical coverage than KorLex.
More seriousproblem is that SJND and SJPD are still noisy:internal consistency inside each dictionary andexternal interrelationship between SJND, SJPD,and SJSC need to be ameliorated, as indicatedby dot line in Fig.
1.4 Automatic Mapping from SemanticClass of SJSC to Synsets of KorLexKorLex and SJSC have different hierarchicalstructures, grain sizes, and lexical informationas aforementioned.
For example, the semanticclasses of SJSC are much bigger concepts ingrain size than the synsets of KorLex: 623concepts in SJSC vs.130,000 synsets in Kor-Lex.
Determining their semantic equivalencethus needs to be firmly based on linguisticclues.Using following 3 linguistic clues that wefound, we propose an automatic mapping me-thod from semantic classes of SJSC to synsetsof KorLex with three approaches to determinemapping candidate synsets: 1) Information ofMonosemy/Polysemy of Word senses (IMPW),2) Instances between Nouns of SJD and Wordsenses of KorLex (INW), and 3) SemanticallyRelated words between Nouns of SJD andSynsets of KorLex (SRNS).For automatic mapping method, followingprocesses were conducted.
First, to find wordsenses of synsets that matched to nouns ofSJND for each semantic class.
Second, to se-lect mapping candidate synsets among themwith three approaches aforementioned.
Third,to determine the least upper bound (LUB) syn-sets and mapping synsets among candidates.Finally, to link each semantic class of SJSC toall lower-level synsets of LUB synsets.4.1 Finding matched word senses betweensynsets and nouns of SJNDFor a semantic class of SJSC, we first findword senses and synsets from KorLex thatmatched with nouns of SJND classified to thatsemantic class.
Figure 2 shows the matchedword senses and synsets between nouns ofSJND, then synsets of KorLex for a semanticclass.
The left side of Figure 2 shows nodes ofsemantic classes with hierarchical structureand the center box shows the matched words(bold ones) among nouns of SJND with wordsenses of synsets in KorLex, and the right sideshows matched word senses and synsets inKorLex?
hierarchical structure.Figure  2.
Matched word senses and synsetswith nouns of SJND for a semantic classFor example, a semantic class?Atmospheric Phenomena?
(rectangle in theleft) has nouns of SJND (words in the center),the bold words are the matched words withword senses of synsets from KorLex, and theunderlined synsets of the right side are thematched ones and synset IDs in KorLex.
Thenotations for automatic mapping process be-tween semantic classes of SJSC and synsets ofKorLex are as follows: noun of SJND is ns,matched noun nsm, un-matched nsu , semanticclass of SJSC is sc, synset is ss and word senseof a synset is ws in KorLex, and monosemyword is wmono and polysemy word is wpoly.A semantic class sc has nouns ns of SJNDhaving matched noun nsm and un-matched nsuby comparing with word senses ws of a synsetss in KorLex.
Thus a synset has word senses asss1={ws1, ws2, ?, wsn}={ nsm1, nsm2, ?, nsmk,nsu k+1, nsu k+2, ?}.
And nouns of SJND for asemantic class sc1 is presented ns(sc1)={nsm1,17nsm2, ?, nsmk, nsu k, nsu k+1, ?}.
Therefore, wecan find the matched word senses nsm1 ~ nsmkfor a semantic class sc from nouns of SJNDand word senses of a synset ss in KorLex.4.2 Selecting Mapping Candidate SynsetsUsing those matched synsets and word senses,we select mapping candidate synsets with threedifferent approaches.4.2.1 Using Information of Monosemyand Polysemy of KorLexUsing information of monosemy/polysemy ofword senses of a synset, the first approach eva-luates mapping candidate synsets.
The candi-date synsets are evaluated into three catego-ries: mc(A) is a most relevant candidate synset,mc(B) is a relevant candidate synset and mc(C)is a reserved synset.
Evaluation begins fromlowest level synsets to top-level beginner.
Theprocess of first approach is as follows.1) For a synset which contains a single wordsense, ss={ws1}, if the word sense is a mo-nosemy, it is categorized as a a candidatesynset mc(A).
If it is a polysemy, categori-zation is postponed for evaluating related-ness among siblings: candidate mc(C).2) In the case of a synset having more thanone word sense, ss={ws1, ws2, ?
}, if thematched words nsm among word senses of asynset are over 60%: Pss(ws)=(count(nsm)/count(ws)) ?
0.6, we evaluate whether thatsynset is mapping candidate in the next step.3) If all matched words nsm of a synset aremonosemic, we categorize it as a candidatesynset mc(A).
If monosemic words amongmatched words are over 50%: Pss(wmono|nsm) ?
0.5, it is evaluated as a mc(B).
Asynset containing polysemies over 50%:Pss(wpoly|nsm) ?
0.5, categorization is post-poned for evaluating relatedness amongsiblings: candidate synset mc(C).4) To repeat from step 1) to 3) for all of syn-sets, in order to evaluate mapping candidatesynsets.
And then, to construct hierarchicalstructure for all those synsets.4.2.2 Using Instances between Nouns ofSJND and Word senses of KorLexThe second approach is to evaluate mappingcandidate synsets using comparison of in-stances between nouns of SJND and wordsenses of a synset.
As for KorLex, we used theexamples of STD linked to word senses ofKorLex.
Figure 3 shows instances of STD andSJND for a word sense ?Apple?.Figure  3.
Instances of STD and SJND forword sense ?Apple?We reformulated the Lesk algorithm (Lesk1987, Banerjee and Pedersen 2002) for com-paring instances and evaluating mapping can-didate synsets.
The process of evaluating map-ping candidate synsets is as follows.1) To compare instances of a noun ns ofSJND with examples of a word of STDlinked to word sense ws of a synset ss, andto compute the Relatedness-A(ns, ws) =score(instance(ns), example(ws)).2) To compare all nouns ns of SJND for asemantic class with all nouns in instancesof STD linked to word senses ws, and  tocompute the Relatedness-B(ns, ws) =score(?ns, nouns(example(ws))).3) If Relatedness-A(ns, ws) ?
?1 and Related-ness-B(ns, ws) ?
?2, a synset is evaluated asa candidate synset mc(A).
If either Related-ness-A(ns, ws) ?
?1 or Relatedness-B(ns,ws) ?
?2, evaluated as a candidate synsetmc(B).
When threshold ?1 and ?2 were 1~4,we had good performances.4) To repeat from step 1) to 3) for all of syn-sets, in order to determine mapping candi-date synsets.
And then, to construct hierar-chical structure for all those synsets.4.2.3 Using Semantically Relatedness be-tween Nouns of SJND and Synsets ofKorLexThe third approach is to evaluate mappingcandidate synsets using comparison of seman-tic relations and their semantically relatedwords between a noun of SJND and wordsenses of a synset.
To compute the relatednessbetween them, we reformulated the computa-18tional formula of relatedness based on the Leskalgorithm (Lesk 1987, Banerjee & al 2002).The process of evaluating mapping candidatesynsets is as follows.1) To compare semantically related words:between synonyms, hypernyms, hyponymsand antonyms of a noun of SJND and thoseof a synset of KorLex.
To compute the Re-latedness-C(ns, ss) = score (relations(ns),relations(ss)).2) To compare all nouns ns of SJND for asemantic class with synonyms, hypernymsand hyponyms of a synset of KorLex, andcompute the Relatedness-D(ns, ss) = score(?ns, relations(ss)).3) If Relatedness-C(ns, ss) ?
?3 and Related-ness-D(ns, ss) ?
?4, a synset is evaluated asa candidate synset mc(A).
If either Related-ness-C(ns, ss) ?
?3 or Relatedness-D(ns, ss)?
?4, evaluated as a candidate synset mc(B).When threshold ?3 and ?4 were 1~4, wehave good performances.4) To repeat from step 1) to 3) for all of syn-sets, in order to determine mapping synsets.And then, to construct hierarchical struc-ture for all those synsets.4.3 Determining Least Upper Bound(LUB) Synsets and Mapping SynsetsNext, we determine the LUB synsets usingmapping candidate synsets and hierarchicalstructure having semantic relations: parent,child and sibling.
In order to determine LUBand mapping synsets, we begin evaluation withbottom-up direction.
Using relatedness amongchild-sibling candidate synsets, we evaluatedwhether their parent synset is a LUB synset ornot.
If the parent is a LUB synset, we evaluateits parent (grand-parent of the candidate) syn-set using relatedness among its sibling synsets.If the parent is not a LUB, the candidate syn-sets mc(A) or mc(B) are determined as map-ping synsets (or LUB) and stop finding LUB.For all semantic classes, we determine LUBand mapping synsets.
Finally, we link the LUBand mapping synsets to each semantic class ofSJSC.
The process of determining of LUB andmapping synsets is as follows.1) Using candidate synsets and their sibling,for all candidate synsets mc(A), mc(B) ormc(C) selected from the processes of ?4.2Select Mapping Candidate Synsets?, to de-termine whether it is a LUB or not and fi-nal mapping synsets.2) Among sibling synsets, if the ratio ofcount(mc(A)) to count(mc(A)+mc(B)+mc(C)) is over 60%, the parent synset ofsiblings is evaluated as a candidate synsetmc(A) and as a LUB.3) If the ratio of count(mc(A)+mc(B))  tocount(mc(A)+mc(B)+mc(C)) is over 70%,the parent of siblings is evaluated as a can-didate synset mc(A) and as a LUB.
If theratio of count(mc(A)+mc(B)) to count(mc(A) +mc(B)+mc(C)) is between 50%and 69%, the parent of siblings is evaluatedas a candidate synset mc(B) and as a LUB.4) And if the others, to stop finding LUB forthat synset and to determine final mappingsynsets with its own level of candidate.5) To repeat from step 1) to 4) until findingLUB synsets and final mapping synsets.Figure  4.
Hierarchical structure of mappingcandidate synsets for a semantic classFigure 4 shows hierarchical structure ofmapping candidate synsets for a semantic class?Furniture?
and when candidate synsets?
ID are?04004316?
(Chair & Seat): mc(B), ?04209815?
(Table & Desk): mc(B), ?14441331?
(Table):mc(C), and ?14436072?
(Shoe shelf & Shoerack): mc(A), we determine whether their par-ent synset ?03281101?
(Furniture) is a LUB ornot, and evaluate it as a candidate synset mc(A)or mc(B).
In this case, synset ?03281101?
(Fur-niture) is a candidate mc(A) and a LUB synset.For all semantic classes, we find their map-ping LUB and mapping synsets using informa-tion of hierarchical structure and candidatesynsets.
Finally, we link each semantic class ofSJSC to all lower level synsets of matchedLUB synsets.195 Experiments and ResultsWe experimented automatic mapping between623 semantic classes of SJSC and 90,134 nounsynsets of KorLex using the proposed automat-ic mapping method with three approaches.
Toevaluate the performances, we used the resultsof manual mapping as correct answers, thatwas mapped 474 semantic classes (terminalnodes) of SJSC to 65,820 synsets (73%) (in-clude 6,487 LUB) among total 90,134 nounsynsets of KorLex.
We compared the results ofautomatic mapping with those of manual map-ping.
For evaluation of performances, we em-ployed Recall, Precision and the F1 measure:F1 = (2*Recall*Precision)/(Recall+ Precision).Approaches Recall Precision F11) 0.904 0.502 0.6452) 0.774 0.732 0.7523) 0.670 0.802 0.7301)+2) 0.805 0.731 0.7661)+3) 0.761 0.758 0.7592)+3) 0.636 0.823 0.7181)+2)+3) 0.838 0.718 0.774Table  2.
Performances of automatic mappingwith three approachesTable 2 shows the performances of automat-ic mapping with three approaches: 1) IMPW,2) INW, and 3) SRNS.
The ?1)?, ?2)?
or ?3) inthe Table present the results using for eachapproach method and ?1)+2)?, ?1)+3)?
or?2)+3)?
present those of combining two ap-proaches.
The ?1)+2)+3)?
presents those of thecombining three approaches and we can seethe best performances using the last approachamong results: recall 0.837, precision 0.717and F1 0.773.
The first approach ?1)?
methodshows high recall, but low precision and thethird approach ?3)?
method present low recalland high precision.
?1)+3)?
and ?2)+3)?
showsgood performances overall.
Thus, we could seegood performances using the combined ap-proach methods.Second, we compared the numbers of se-mantic classes, nouns entries of SJND, nounsynsets and word senses of KorLex for eachapproach, after mapping processes.As shown in Table 3, we can see the mostnumbers of mapping synsets using the ?1)?
ap-proach.
The ?1)+2)+3)?
shows the results simi-lar to ?1)?, but has the best performances (seeTable 2).
The percentages in the round bracketpresent the ratio of the results of automaticmapping to original lexical data of Sejong andKorLex: 474 semantic classes of SJSC, 25,245nouns of SJND and 90,134 noun synsets and147,896 word senses in KorLex.SJD KorLexApproaches SC (SJSC)Nouns(SJND) SynsetsWordSenses1) 473 18,575 54,943 69,9702) 445 18,402 52,109 66,9363) 413 18,047 49,768 64,0031)+2) 463 18,521 52,563 67,1091)+3) 457 18,460 51,786 66,1572)+3) 383 17,651 48,398 62,0631)+2)+3) 466 (98.3%)18,542(72.8%)54,083(60%)69,259(46.8%)Table  3.
Numbers of semantic class, noun ofSJD, synset and word sense of KorLexIn manual mapping, we mapped 73%(65,820) synsets of KorLex for 474 semanticclasses of SJSC.
The 24,314 synsets was ex-cluded in manual mapping among 90,134 totalnouns synsets.
The reasons of excluded synsetsin manual mapping were 1) inconsistency ofinheritance for lexical relations of parent-childin SJSC or KorLex, 2) inconsistency betweencriteria for SJSC and candidate synsets, 3)candidate synsets belonging to more than twosemantic classes, 4) specific proper nouns(chemical compound names), and 5) polysemicabstract synsets (Bae & al.
2010).In automatic mapping, we could map 60%(54,083) synsets among total nouns synsets(90,134) of KorLex, and it is 82.2% of the re-sults of manual mapping.
The 11,737 synsetswas excluded in automatic mapping by com-paring with manual mapping.
Most of themwere 1) tiny-grained synsets found in the low-est levels, 2) synsets having no matched wordsenses with those of SJND, 3) synsets withpolysemic word senses, 4) word senses havingpoor instances in KorLex and in SJND, 5)word senses in SJND having poor semanticrelations.Level LUB Ratio Level LUB Ratio1 18 0.6% 9 230 7.3%2 18 0.6% 10 98 3.1%3 174 5.5% 11 32 1.0%4 452 14.3% 12 20 0.6%5 616 19.5% 13 4 0.1%6 570 18.0% 14 4 0.1%7 486 15.4% 15 2 0.1%8 442 14.0% 16-17 0 0%Table  4.
Numbers and Ratio of LUB synsetsexcluded in automatic mapping20Table 4 shows the numbers and ratio of theLUB synsets excluded in automatic mappingfor each level in depth.
Most synsets are 4-8levels synsets among 17 levels in depth.6 ConclusionsWe proposed a novel automatic mapping me-thod with three approaches to link Sejong Se-mantic Classes and KorLex using 1) informa-tion of monosemy/polysemy of word senses, 2)instances of nouns of SJD and word senses ofKorLex, 3) semantically related words ofnouns of SJD and synsets of KorLex.
To findcommon clues from lexical information amongthose language resources is important processin automatic mapping method.
Our proposedautomatic mapping method with three ap-proaches shows notable performances by com-paring with other studies on automatic map-ping among language resources: recall 0.837,precision 0.717 and F1 0.773.
Therefore, fromthose studies, we can improve Korean seman-tico-syntactic parsing technology by integrat-ing the argument structures as provided by SJD,and the lexical-semantic hierarchy as providedby KorLex.
In addition, we can enrich threeresources: KorLex, SJD and STD as results ofcomparing and integrating them.
We expect toimprove automatic mapping technology amongother Korean language resources through thisstudy.AcknowledgementThis work was supported by the National Re-search Foundation of Korea (NRF) grantfunded by the Korea government(MEST) (No.2007-0054887).ReferencesJan Scheffczyk, Adam Pease, Michael Ellsworth.2006.
Linking FrameNet to the Suggested UpperMerged Ontology.
Proc of the 2006 conferenceon Formal Ontology in Information Systems(FOIS 2006): 289-300.Ian Niles and Adam Pease.
2003.
Linking lexiconsand ontologies: Mapping wordnet to the sug-gested upper merged ontology.
In Proceedings ofthe 2003 International Conference on Informa-tion and Knowledge Engineering (IKE 03).KorLex, 2007.
Korean WordNet, Korean Languageprocessing Lab, Pusan National University.Available at http://korlex.cs.pusan.ac.krC.
Hong.
2007.
The Research Report of Develop-ment 21th century Sejong Dictionary, Ministryof Culture, Sports and Tourism, The National In-stitute of the Korean Language.Dennis Spohr.
2008.
A General Methodology forMapping EuroWordNets to the Suggested Up-per Merged Ontology, Proceedings of the 6thLREC 2008:1-5.Alexander Budanitsky and Graeme Hirst.
2006.Evaluating WordNet-based Measures of Lexi-cal Semantic Relatedness, Computational Lin-guistics,Vol 32: Issue 1:13- 47.Siddharth Patwardhan, Satanjeev Banerjee and TedPedersen.
2003.
Using Measures of SemanticRelatedness for Word Sense Disambiguation,CICLing 2003, LNCS(vol 2588):241-257.Satanjeev Banerjee and Ted Pedersen.
2002.
AnAdapted Lesk Algorithm for Word Sense Dis-ambiguation Using WordNet, Proceedings ofCICLing 2002, LNCS 2276:136-145Sara Tonelli and Daniele Pighin.
2009.
New Fea-tures for FrameNet -WordNet Mapping, Pro-ceedings of the 13th Conference on Computa-tional Natural Language Learning: 219-227.Aesun Yoon, Soonhee Hwang, E. Lee, Hyuk-ChulKwon.
2009.
Consruction of Korean WordNet?KorLex 1.5?, JourNal of KIISE: Sortware andApplications, Vol 36: Issue 1:92-108.Soonhee Hwang, A. Yoon, H. Kwon.
2010.
KorLex1.5: A Lexical Sematic Network for KoreanNumeral Classifiers, JourNal of KIISE: Sort-ware and Applications, Vol 37: Issue 1:60-73.Sun-Mee Bae, Kyoungup Im, Aesun Yoon.
2010.Mapping Heterogeneous Ontologies for theHLT Applications: Sejong Semantic Classesand KorLexNoun 1.5, Korean Journal of Cog-nitive Science.
Vol.
21: Issue 1: 95-126.Aesun Yoon.
2010.
Mapping Word Senses of Ko-rean Predicates Between STD(STandard Dic-tionary) and SJD(SeJong Electronic Dictio-nary) for the HLT Applications,  Journal of theLinguistic Society of Korea.
No 56: 197-235.Hyopil Shin.
2010.
KOLON: Mapping KoreanWords onto the Microkosmos Ontology andCombining Lexical Resources.
Journal of theLinguistic Society of Korea.
No 56: 159-196.21
