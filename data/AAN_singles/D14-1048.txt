Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 425?429,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsAligning English Strings with Abstract Meaning Representation GraphsNima Pourdamghani, Yang Gao, Ulf Hermjakob, Kevin KnightInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern California{damghani,yanggao,ulf,knight}@isi.eduAbstractWe align pairs of English sentences andcorresponding Abstract Meaning Repre-sentations (AMR), at the token level.
Suchalignments will be useful for downstreamextraction of semantic interpretation andgeneration rules.
Our method involveslinearizing AMR structures and perform-ing symmetrized EM training.
We obtain86.5% and 83.1% alignment F score on de-velopment and test sets.1 IntroductionBanarescu et al.
(2013) describe a semantics bankof English sentences paired with their logicalmeanings, written in Abstract Meaning Represen-tation (AMR).
The designers of AMR leave openthe question of how meanings are derived fromEnglish sentences (and vice-versa), so there areno manually-annotated alignment links betweenEnglish words and AMR concepts.
This paperstudies how to build such links automatically, us-ing co-occurrence and other information.
Auto-matic alignments may be useful for downstreamextraction of semantic interpretation and genera-tion rules.AMRs are directed, acyclic graphs with labelededges, e.g., the sentence The boy wants to go isrepresented as:(w / want-01:arg0 (b / boy):arg1 (g / go-01:arg0 b))We have hand-aligned a subset of the 13,050available AMR/English pairs.
We evaluate ourautomatic alignments against this gold standard.A sample hand-aligned AMR is here (??n?
speci-fies a link to the nth English word):the boy wants to go(w / want-01?3:arg0 (b / boy?2):arg1 (g / go-01?5:arg0 b))This alignment problem resembles that of statisti-cal machine translation (SMT).
It is easier in someways, because AMR and English are highly cog-nate.
It is harder in other ways, as AMR is graph-structured, and children of an AMR node are un-ordered.
There are also fewer available trainingpairs than in SMT.One approach is to define a generative modelfrom AMR graphs to strings.
We can then useEM to uncover hidden derivations, which align-ments weakly reflect.
This approach is used instring/string SMT (Brown et al., 1993).
How-ever, we do not yet have such a generative graph-to-string model, and even if we did, there mightnot be an efficient EM solution.
For exam-ple, in syntax-based SMT systems (Galley et al.,2004), the generative tree/string transduction storyis clear, but in the absence of alignment con-straints, there are too many derivations and rulesfor EM to efficiently consider.We therefore follow syntax-based SMT customand use string/string alignment models in align-ing our graph/string pairs.
However, while it isstraightforward to convert syntax trees into stringsdata (by taking yields), it is not obvious how to dothis for unordered AMR graph elements.
The ex-ample above also shows that gold alignment linksreach into the internal nodes of AMR.Prior SMT work (Jones et al., 2012) describesalignment of semantic graphs and strings, thoughtheir experiments are limited to the GeoQuery do-main, and their methods are not described in de-tail.
Flanigan et al (2014) describe a heuristicAMR/English aligner.
While heuristic alignerscan achieve good accuracy, they will not automat-ically improve as more AMR/English data comes425online.The contributions of this paper are:?
A set of gold, manually-alignedAMR/English pairs.?
An algorithm for automatically aligningAMR/English pairs.?
An empirical study establishing alignmentaccuracy of 86.5% and 83.1% F score for de-velopment and test sets respectively.2 MethodWe divide the description of our method into threeparts: preprocessing, training, and postprocessing.In the preprocessing phase, we linearize the AMRgraphs to change them into strings, clean both theAMR and English sides by removing stop wordsand simple stemming, and add a set of correspond-ing AMR/English token pairs to the corpus to helpthe training phase.
The training phase is basedon IBM models, but we modify the learning algo-rithm to learn the parameters symmetrically.
Fi-nally, in the postprocessing stage we rebuild thealigned AMR graph.
These components are de-scribed in more detail below.2.1 PreprocessingThe first step of the preprocessing component is tolinearize the AMR structure into a string.
In thisstep we record the original structure of nodes inthe graph for later reconstruction of AMR.
AMRhas a rooted graph structure.
To linearize thisgraph we run a depth first search from the root andprint each node as soon as it it visited.
We printbut not expand the nodes that are seen previously.For example the AMR:(w / want-01:arg0 (b / boy):arg1 (g / go-01:arg0 b))is linearized into this order: w / want-01 :arg0 b /boy :arg1 g / go-01 :arg0 b.Note that semantically related nodes often stayclose together after linearization.After linearizing the AMR graph into a string,we perform a series of preprocessing steps includ-ing lowercasing the letters, removing stop words,and stemming.The AMR and English stop word lists are gen-erated based on our knowledge of AMR design.We know that tokens like an, the or to be verbswill very rarely align to any AMR token; similarly,AMR role tokens like :arg0, :quant, :opt1 etc.
aswell as the instance-of token /, and tokens liketemporal-quantity or date-entity rarely align to anyEnglish token.
We remove these tokens from theparallel corpus, but remember their position to beable to convert the resulting string/string align-ment back into a full AMR graph/English stringalignment.
Although some stopwords participatein gold alignments, by removing them we will buya large precision gain for some recall cost.We remove the word sense indicator and quo-tation marks for AMR concepts.
For instance wewill change want-01 to want and ?ohio?
to ohio.Then we stem AMR and English tokens into theirfirst four letters, except for role tokens in AMR.The purpose of stemming is to normalize Englishmorphological variants so that they are easier tomatch to AMR tokens.
For example English to-kens wants, wanting, wanted, and want as well asthe AMR token want-01 will all convert to wantafter removing the AMR word sense indicator andstemming.In the last step of preprocessing, we benefitfrom the fact that AMR concepts and their cor-responding English ones are frequently cognates.Hence, after stemming, an AMR token often canbe translated to a token spelled similarly in En-glish.
This is the case for English token want andAMR token want in the previous paragraph.
Tohelp the training model learn from this fact, weextend our sentence pair corpus with the set ofAMR/English token pairs that are spelled identi-cally after preprocessing.
Also, for English tokensthat can be translated into multiple AMR tokens,like higher and high :degree more we add the cor-responding string/string pairs to the corpus.
Thisset is extracted from existing lexical resources, in-cluding lists of comparative/superlative adjectives,negative words, etc.After preprocessing, the AMR at the start ofthis section will change into: want boy go andthe sentence The boy wants to go changes into boywant to go, and we will also add the identity pairswant/want, boy/boy, and go/go to the corpus.2.2 TrainingOur training method is based on IBM word align-ment models (Brown et al., 1993).
We modifythe objective functions of the IBM models to en-426courage agreement between learning parametersin English-to-AMR and AMR-to-English direc-tions of EM.
The solution of this objective func-tion can be approximated in an extremely simpleway that requires almost no extra coding effort.Assume that we have a set of sentence pairs{(E,A)}, where each E is an English sentenceand each A is a linearized AMR.
According toIBM models, A is generated from E through agenerative story based on some parameters.For example, in IBM Model 2, given E wefirst decide the length of A based on some prob-ability l = p(len(A)|len(E)), then we decidethe distortions based on a distortion table: d =p(i|j, len(A), len(E)).
Finally, we translate En-glish tokens into AMR ones based on a translationtable t = p(a|e) where a and e are AMR and En-glish tokens respectively.IBM models estimate these parameters to max-imize the conditional likelihood of the data:?A|E= argmaxL?A|E(A|E) or ?E|A=argmaxL?E|A(E|A) where ?
denotes the set ofparameters.
The conditional likelihood is intrinsicto the generative story of IBM models.
However,word alignment is a symmetric problem.
Hence itis more reasonable to estimate the parameters in amore symmetric manner.Our objective function in the training phase is:?A|E, ?E|A= argmaxL?A|E(A|E)+L?E|A(E|A)subject to ?A|E?E= ?E|A?A= ?A,EWe approximate the solution of this objectivefunction with almost no change to the existingimplementation of the IBM models.
We relaxthe constraint to ?A|E= ?E|A, then apply thefollowing iterative process:1.
Optimize the first part of the objective func-tion: ?A|E= argmaxL?A|E(A|E) using EM2.
Satisfy the constraint: set ?E|A?
?A|E3.
Optimize the second part of the objectivefunction: ?E|A= argmaxL?E|A(E|A)using EM4.
Satisfy the constraint: set ?A|E?
?E|A5.
IterateNote that steps 1 and 3 are nothing more thanrunning the IBM models, and steps 2 and 4 arejust initialization of the EM parameters, using ta-bles from the previous iteration.
The initializationsteps only make sense for the parameters that in-volve both sides of the alignment (i.e., the transla-tion table and the distortion table).
For the trans-lation table we set tE|A(e|a) = tA|E(a|e) for En-glish and AMR tokens e and a and then normalizethe t table.
The distortion table can also be initial-ized in a similar manner.
We initialize the fertilitytable with its value in the previous iteration.Previously Liang et al.
(2006) also presented asymmetric method for training alignment parame-ters.
Similar to our work, their objective functioninvolves summation of conditional likelihoods inboth directions; however, their constraint is onagreement between predicted alignments while wedirectly focus on agreement between the parame-ters themselves.
Moreover their method involves amodification of the E step of EM algorithm whichis very hard to implement for IBM Model 3 andabove.After learning the parameters, alignments arecomputed using the Viterbi algorithm in both di-rections of the IBM models.
We tried mergingthe alignments of the two directions using meth-ods like grow-diag-final heuristic or taking inter-section of the alignments and adding some highprobability links in their union.
But these methodsdid not help the alignment accuracy.2.3 PostprocessingThe main goal of the postprocessing component isto rebuild the aligned AMR graph.
We first insertwords removed as stop words into their positions,then rebuild the graph using the recorded originalstructure of the nodes in the AMR graph.We also apply a last modification to the align-ments in the postprocessing.
Observing that pairslike worker and person :arg0-of work-01 appearfrequently, and in all such cases, all the AMR to-kens align to the English one, whenever we seeany of AMR tokens person, product, thing or com-pany is followed by arg0-of, arg1-of or arg2-offollowed by an AMR concept, we align the twoformer tokens to what the concept is aligned to.3 Experiments3.1 Data DescriptionOur data consists of 13,050 publicly availableAMR/English sentence pairs1.
We have hand1LDC AMR release 1.0, Release date: June 16, 2014https://catalog.ldc.upenn.edu/LDC2014T12427aligned 200 of these pairs to be used as develop-ment and test sets2.
We train the parameters onthe whole data.
Table 1 presents a description ofthe data.
We do not count parenthesis, slash andAMR variables as AMR tokens.
Role tokens arethose AMR tokens that start with a colon.
Theydo not represent any concept, but provide a linkbetween concepts.
For example in:(w / want-01:arg0 (b / boy):arg1 (g / go-01:arg0 b))the first :arg0 states that the first argument of theconcept wanting is the boy and the second argu-ment is going.train dev testSent.
pairs 13050 100 100AMR tokens 465 K 3.8 K (52%) 2.3 K (%55)AMR role tokens 226 K 1.9 K (23%) 1.1 K (%22)ENG tokens 248 K 2.3 K (76%) 1.7 K (%74)Table 1: AMR/English corpus.
The number inparentheses is the percent of the tokens aligned ingold annotation.
Almost half of AMR tokens arerole tokens, and less than a quarter of role tokensare aligned.3.2 Experiment ResultsWe use MGIZA++ (Gao and Vogel, 2008) asthe implementation of the IBM models.
We runModel 1 and HMM for 5 iterations each, then runour training algorithm on Model 4 for 4 iterations,at which point the alignments become stable.
Asalignments are usually many to one from AMR toEnglish, we compute the alignments from AMR toEnglish in the final step.Table 2 shows the alignment accuracy forModel 1, HMM, Model 4, and Model 4 plus themodification described in section 2.2 (Model 4+).The alignment accuracy on the test set is lowerthan the development set mainly because it is in-trinsically a harder set, as we only made smallmodifications to the system based on the develop-ment set.
Recall error due to stop words is onedifference.2The development and test AMR/English pairs can befound in /data/split/dev/amr-release-1.0-dev-consensus.txtand /data/split/test/amr-release-1.0-test-consensus.txt, re-spectively.
The gold alignments are not included in thesefiles but are available separately.model precision recall F scoreDevModel 1 70.9 71.1 71.0HMM 87.6 80.1 83.7Model 4 89.7 80.4 84.8Model 4+ 94.1 80.0 86.5TestModel 1 74.8 71.8 73.2HMM 83.8 73.8 78.5Model 4 85.8 74.9 80.0Model 4+ 92.4 75.6 83.1Table 2: Results on different models.
Our trainingmethod (Model 4+) increases the F score by 1.7and 3.1 points on dev and test sets respectively.Table 3 breaks down precision, recall, andF score for role and non-role AMR tokens, andalso shows in parentheses the amount of recall er-ror that was caused by removing either side of thealignment as a stop word.token type precision recall F scoreDevrole 77.1 48.7 59.7non-role 97.2 88.2 92.5all 94.1 80.0 (34%) 86.5Testrole 71.0 37.8 49.3non-role 95.5 84.7 89.8all 92.4 75.6 (36%) 83.1Table 3: Results breakdown into role and non-role AMR tokens.
The numbers in the parenthesesshow the percent of recall errors caused by remov-ing aligned tokens as stop words.While the alignment method works very well onnon-role tokens, it works poorly on the role tokens.Role tokens are sometimes matched with a wordor part of a word in the English sentence.
For ex-ample :polarity is matched with the un part of theword unpopular, :manner is matched with mostadverbs, or even in the pair:thanks(t / thank-01:arg0 (i / i):arg1 (y / you))all AMR tokens including :arg0 and :arg1 arematched to the only English word thanks.
Incon-sistency in aligning role tokens has made this ahard problem even for human experts.4284 Conclusions and Future WorkIn this paper we present the first set of manuallyaligned English/AMR pairs, as well as the firstpublished system for learning the alignments be-tween English sentences and AMR graphs thatprovides a strong baseline for future research inthis area.
As the proposed system learns thealignments automatically using very little domainknowledge, it can be applied in any domain andfor any language with minor adaptations.Computing the alignments between Englishsentences and AMR graphs is a first step for ex-traction of semantic interpretation and generationrules.
Hence, a natural extension to this workwill be automatically parsing English sentencesinto AMR and generating English sentences fromAMR.AcknowledgmentsThis work was supported by DARPA con-tracts HR0011-12-C-0014 and FA-8750-13-2-0045.
The authors would like to thank David Chi-ang, Tomer Levinboim, and Ashish Vaswani (inno particular order) for their comments and sug-gestions.ReferencesLaura Banarescu, Claire Bonial, Shu Cai, MadalinaGeorgescu, Kira Griffitt, Ulf Hermjakob, KevinKnight, Philipp Koehn, Martha Palmer, and NathanSchneider.
2013.
Abstract meaning representationfor sembanking.
In Linguistic Annotation Workshop(LAW VII-ID), ACL.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational linguistics,19(2):263?311.Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,Chris Dyer, and Noah A. Smith.
2014.
A discrim-inative graph-based parser for the abstract meaningrepresentation.
In ACL.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In HLT-NAACL.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing Workshop, ACL.Bevan Jones, Jacob Andreas, Daniel Bauer,Karl Moritz Hermann, and Kevin Knight.
2012.Semantics-based machine translation with hyper-edge replacement grammars.
In COLING.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In HLT-NAACL.429
