Mul t imoda l  References in GEORAL TACTILEJ acques  S i rouxUniversit6 de Rennes I, IR ISA/ IUT  Lannion, ENSSAT, 6, rue de KerampontBP 447 F-22305 Lannion Cedex Francesiroux@enssat.frMarc  GuyomardUniversit6 de Rennes I, IR ISA/ENSSAT 6, rue de KerampontBP 447 F-22305 Lannion Cedex Franceguyomard@enssat.
frF ranck  Mu l ton  and  Chr i s tophe  R6mondeauENSSAT Lannion FranceAbst rac tThe paper specifically presents how linguistic (oral) andtactile references are dealt with in the GEORAL sys-tem which has already been described in other papers.In this system, users can formulate their queries andprovide their responses using the oral (linguistic) mo-dality and the tactile modality separately or together.We describe the referential phenomena which occur insuch a context and we point out why the oral modalityhas to be the basis of the processing of the referencesand why robustness problems have to be dealt with.We then provide details about the three steps of thereference processing (linguistic analysis, processing ofthe tactile events and merging process) as well as themodeling of the communicative acts used in the system(as planning operators).IntroductionAdding a new modality in an existing oral dialogue sys-tem poses many interesting problems.
Among these,those which concern the referential phenomena deserveto be quoted.
How do the users designate the referents?If several modalities are used, how can we model thevarious activities on each modality?
How to exploitthem?
how to deal with the performance problem (ro-bustness)?...
All these questions arise, but not all havecomplete answers despite numerous work done in thedomain \[2, 12\].In order to eliminate some drawbacks of speech reco-gnition, we have added a touch screen to an oral system\[7\].
Thus users can formulate their queries and providetheir responses using the oral (linguistic) modality andthe tactile modality separately or together.
This paperpresents responses to some of the questions above.
Firstwe describe the system the goal of which is the queryingof a geographic and tourist database.
Then we ana-lyse the referential phenomena both from the linguisticand the tactile point of view.
This analysis is origi-nated from an experimental (WOZ) work \[11\] and theresults have been confirmed by way of a first evaluationof the system with naive users.
The different ypes ofproblems are underlined.
The paper continues by pre-senting the general principles which guide us and thedescription of the principal processing methods.
Theprinciples are concerned with the choice of the moda-lity on which the resolution of references i  based, thearchitecture of the steps and the type of modeling.
Inthe course of the description of the processing methods,we provide details about the format and the contentof the data used.
In the conclusion, we outline futureplanned studies using the system.
More details aboutthe preliminary experiments, the architecture and thesystem evaluation can be found in \[11, 18, 19\].Sys tem descr ip t ionGEORAL Tactile is a multimodal system which is ableto provide information of a touristic nature to naiveusers.
Users can ask for information about he locationof places of interest (city, beach, chateau, church,...) wi-thin a region or a subregion, or distance and itinerarybetween two localities.
Users interact with the systemusing three different modalities: in a visual mode bylooking to the map displayed on the screen, in an oraland natural anguage mode (thanks to a speech reco-gnition board 1) and in a gesture mode pointing to ordrawing on a touch screen.
The system itself uses boththe oral channel (text-to-speech synthesis) and graphics1The speech input is processed by the recognition boardMEDIAS0 (licenced by France Telecom CNET).40 J. Siroux, M. Guyomard, F. Multon and C. Rdmondeausuch as the flashing of sites, routes and zooming in onsubsections of the map, so as to best inform the user.The dialogue model is an adaptation of the LOKImodel \[22\].
It allows to build up a structured ialoguehistory based on the theme of the queries.
Some dia-logue functionalities (spelling, repeating, writing) areadded in order to take into account specific features ofthe oral mode.
The model also contains co-operative al-gorithms \[9, 10\] which avoid producing empty responsesand allow to manage the interaction in a directed butfriendly manner.Re ferent ia l  phenomenaIn such a context, we implemented a WOZ experiment\[11\] in order to study how users designate the referents.The main outcomes of this study have been confirmedduring a first evaluation of the system \[19\].
We examinehere primarily the deictic problems concerning both thetactile and linguistic users' activities.
Most standardanaphora re dealt with in the system (using lexical,syntactic and semantic information).
This, however, isnot discussed here.What  are the referents?In this application, the possible referents are sites ~ andlocalities which are recorded in the database and whichmay appear on the displayed map.
From a user pointof view, and depending on the state of the dialogue, apossible referent may be displayed on the screen (forexample at the beginning of the dialogue, the main lo-calities are presented on the map; after a suggestive res-ponse of the system, a few interesting localities are pre-sented on the map with a flashing effect possibly afterzooming in) or may only be evoked when, for examplea user would like to know if a certain site not displayedon the screen exists in a zone of the map.How do  users  designate?Var ious  types  o f  tactile activities Two main typesof tactile activities are observed:?
the pointing mode: the user points out a point onthe screen which may correspond to a referent (site,locality) or to a place for which there is no referent.?
the zoning mode: the user drawns up a zone in whichthe user want to do a search for referents.
The dra-wing of the zone may be quite complex: it can usesome elements of the map (coast, river,...), the surfacecan be open or closed...
In the current implementa-tion, only the closed zones are dealt with.2In our system, site is a place of interest (eg.
a church),locality is a place name and zone is a region delimited bythe system or the user.Tactile and Linguistic joint activities The pre-sence of the tactile screen modifies the linguistic beha-viour of the user: some particular deictic terms (around10 words and expressions are dealt with) and particularsyntactic structures appear.
Three possible relation-ships between oral utterances and tactile gestures havebeen identified (the two main ones follow):?
bound relationship in which one deictic item appea-ring in the oral utterance and a touch activity areused together to designate a referent (or a set of re-ferents) on the map3:(1) U: Are there any beaches in this locality?
+ atouch on a locality.
(2) U: Are there any chateaux here?
+ a touch on alocality.
(3) U: Are there any churches in this zone?
+ dra-wing a zone on the map.
(4) U: Here + a touch on a locality.
(5) U: This one + a touch on a site.confirmative relationship for which the oral syntagmis sufficient enough to comprehend but is however ac-companied by a tactile designation, which is redun-dant with the linguistic reference:(6) U: Are there any beaches in Lannion?
+ a touchon Lannion.
(7) U: in Lannion + a touch on Lannion.Some diff icult iesThese designation modes seem to be very straightfor-ward and easy to deal with but some problems whichdepend on the user behaviour arise and make proces-sing more complicated.The relationship between the deictic term and the tac-tile designation is not systematic.
For example, one canfind an utterance (2) occuring together with a drawingof a zone (in French pointing would better correspondto the item here), or second example, utterance (3) canalso merely come with a pointing which is not sugges-ted by the syntagm in this zone.
From another pointof view, the user tactile activities may be imprecise, forexample the pointing together with utterance (1) coulddesignate a place where there is no locality.
These pro-blems suggest o design mechanisms which will have todeal with these imprecisions in a static and dynamicway.Experiments have also displayed differences betweenusers concerning the use of the tactile screen.
The de-gree of use of the tactile is highly dependant of the sub-jects: on average 36% of the initial requests are com-posed of a tactile activity but the highest rate for any3These examples are litteral translation of the examplesactually used in the system.Multimodal References in GEORAL TACTILE 41given user is around 95% and the lowest 2%.
These factsmean that oral modality has to keep a dominating roleas far the reference processing is concerned.are there any beaches here ?will be transformed as :Processing the referencesMain principlesSome main principles can characterize our approach ofthe problem; they reflect two major concerns: the firstone is the robustness in order to deal with the impreci-sion and the second one is the flexibility in order to tuneout the behaviour of the system and to make easier itsevolution.
These principles are as follows:?
The global processing is divided up in three sequen-tial steps: a linguistic analysis, a tactile analysis anda merging process.?
The processing is mainly based on the oral moda-lity, i.e.
on the analysis (syntactic and thematic)of the oral utterance.
This fact not only allows usto take into account he different uses of the system(with or without he tactile screen), but also compelsus to do so because the tactile mode does not pro-vide sufficient information in most of the cases.
Thischoice presents ome consequences and drawbacks:the speech recognition becomes very important andthe discrepancies between oral and tactile activitieswill be dealt with by the tactile analysis.?
The algorithms are based on contextual information.The dialogue history (context) provides the necessaryelements (referents) to progressively solve the refe-rences, and the oral utterance (co-text) provides pre-dictions about foreseen referents and type of tactileactivity.
Nevertheless, we chose an approach wherethe results of the linguistic and tactile activities aremerged instead of an approach where the activitiesare interpreted using the tactile context \[20\].?
Finally, the modelling of the different activities is ba-sed on planning operators which allow us to easilybuild up communicative acts that represent the jointactivities of the user.Main ProcessesLinguistic Analysis This analysis is made up of twomodules: the syntactical and the  thematic analysiswhich are triggered after the speech recognition.
Thesyntactic analysis produces a complete syntactic treeusing the difference list method \[6\].
The deictic andanaphoric syntagms are only spotted in the utteranceand coded inside the tree.
The thematic analysis hastwo principal roles as regards the tactile function.
Itdetermines the possible types (style) of tactile touch(point, zone) as well as the theme of the question (typeof object in question).
It also produces an intermediarystructure, a so-called dialogue act, of which the mo-deling of propositional content is inspired by \[1\].
Forexample, the user's utterance:ASK(U, S, informref(S, U, beach, Q(beach,locality(deicphore(pointing)))))where deicphore(pointing) is generated by the presenceof the keyword here and indicates a user tactile activityto point out the place where the system will have toexplore.
The transmission of the theme to the tactileprocessor is accompanied by the relevant objects of thedatabase.Processing the tactile activities The aim of thisprocessing is, starting from the elementary events whichcorrespond to tactile activity of the user, to provide thepossible objects of the database which correspond to thedesignated or desired referents.
The process is based ona prediction about the style transmitted by the thema-tic analyser as well as on objects (potential referents)pre-selected from the database.
It produces a possibleempty list (tactile acts) of designated objects.At this level the robustness problems are two-fold:(1) the gestural activity may consist of several gestures(drawing multiple zones, touching multiple locations),(2) the gestural activity may not be consistent with thelinguistic activity.
As far as the first type is concerned,we only take into account he two final points or the lastdrawn zone.
As for the second type, we have designeda small set of rules (easily modifiable), which allows usto modify the gestural activity observed according tothe expected style.
Up to now, this modification doesnot take into account neither the geographical contextnor the dialogic one.Producing Communicative Acts A communica-tive act (CA) expresses the user's intention, which inturn is simultaneously conveyed by the speech activity(the dialogue act) and the tactile activity.
In orderto determine a CA one must merge the two types ofactivity, whilst using to a maximum advantage the re-dundant information conveyed by the two media \[4, 20\].This merging must also take into account possible inco-herence problems between media, as a result either ofthe system (speech recognition and understanding) orof the user.
According to the dialogue context, (reco-gnized type of dialogue act) the merging is carried outin two ways.
A set of rules, taking into account he dif-ferent situations on the media, is used for dealing withphatic dialogue acts, as it is for a closed question.
Theyenable a decision to be taken.
The following rule (sim-plified):identification(L2) :-speech (L1),tactile(L2).specifies that the location designated by the user willbe L2 because it was designated in a tactile fashion des-pite the fact that speech recognition provided L1.
Theexpertise currently coded in the rules is the outcomeof the WOZ corpus; it has a tendency to favor tactile42 J. Siroux, M. Guyomard, F. Multon and C. RdmondeauNAME:HEADER:BODY:CONSTRAINT:PRECONDIT ION:Request_completive modeREQUEST(U, S, INFORMEREF(S,U, ?x, q(?x, ?P'(?o'))))ASK(U,S, informerf(S,V, ?x, Q(?x, ?P(?D))))D~signer(U, S, %)D~ictique(?P(?D)), ?o, ?P'(?o'))Figure 1: A model for the Request Communicative Actmedia.
The specification by means of rules will makefuture modifications easier.The second mode of merging concerns the dialogueacts labelled as requests.
It is based on a representationof CA as plan operators \[5, 15, 16, 21\].
Dialogue actsas well as the tactile acts are considered as low levelplan operators.
Whilst merging, we solve tactile andlinguistic o-references \[3, 8\].For example, Figure 1 shows a model of the CA RE-QUEST for the completive mode where a tactile eventand a dialogue act have to be merged.
This case is spe-cified by the presence of the tactile act "D~signer" inthe Body part of the model.The predicate D~ictique in the precondition partchecks the consistency beetween the deictic term(?P(?D)) within the dialogue act ASK and the referent(%) provided by the tactile act.
It produces the referent(?P'(?o')) to be placed in the communicative act.
Forexample, the deictic term locality (deicphore(pointing))in the dialogue act:ASK(U, S, informref(S, U, beach, Q(beach, loca-lity(deicphore(pointing)))))and the referent (Lannion.
pointing, 1, X, Y) in the tac-tile actD~signer(U, S, (Lannion, pointing, 1, X, Y))will be recognized as compatible and allow to producethe referent locality(Lannion) for the CA REQUEST:Request(U, S, informref(S, U, beach, Q(beach, loca-lity(Lannion))))Further details are provided in \[17\].
We can also ob-serve the considerable flexibility brought about by theuse of rules in the verification of preconditions.D iscuss ion  and  Future  PlansWe described the methods and models we designed inorder to take into account deictic references within aspecific framework.
These solutions are mainly basedon contextual information.
They allow to deal withsome robustness problems and to provide a certain flexi-bility for specifying the operations in order to take intoaccount future new semantic or pragmatic information.Clearly, the solutions we have presented in this frame-work are strongly dependent on the kind of applicationtargeted.
For example, an application in which usershandle objects using the system presents other charac-teristics and so will need other solutions.We plan to extend this work in several directions:?
to take into account other styles of designations andtactile activities.
For example, to allow activitiessuch as:U: Are there any beaches along this coast?
+ U fol-lows with his finger a coastorU: Are there any chateaux above this river?
+ Utouches on a river.These possibilities need to add a lot of new item tothe speech recognition vocabulary but in addition re-quire new knowledge about he cartographic context.It will be also necessary to pay closer attention touser behaviour and perhaps even contemplate usermodelling.?
to allow the user to ask about typical features of cer-tain referents (for example: opening hours of a site).In this case, clearly the nature of the referential phe-nomena will change and will need some more sophis-ticated processing \[14\].Acknowledgements.
This project was partially fun-ded by CNET (France Telecom), contract 92 7B.References\[1\] Allen J.
Natural Language Understanding.
TheBenjamin/Cummings Publishing Company, Inc.,1987.\[2\] Proceedings of CMC95 International Conferenceon Cooperative Multimodal Communication, H.Bunt, R.-J.
Beun and T. Borghuis (eds), Eindho-yen, The Netherlands, 24-26 May 1995.\[3\] Cohen, P. R. The Pragmatics of Referring and theModality of Communication.
Computational Lin-guistics, Vol.
10, Num.
2, April-June 1984, p. 97-146.\[4\] Cohen, P. R. The role of Natural Languagein a Multimodal Interface.
Proceedings of 2ndFRIENDP1, International symposium on next ge-neration human interface technology, Tokyo, Ja-pan, Nov. 1991.Multimodal References in GEORAL TACT ILE  43mmmmmmmnmmmnmmmmmmm\[\]mmmmmmmn\[5\] Feiner S.K.
and McKeown K.R.
Coordinating Textand Graphics in Explanation Generation.
Procee-dings of the AAAI-90, July 30-August 3, 1990.\[6\] Gal A, Lapalme G. and Saint-Dizier P. Prolog pourl'analyse automatique du langage naturel, l~ditionsEyrolles, Paris, 1988.\[7\] Gavignet F., Guyomard M., Siroux J. Implemen-ting an oral and geographic multimodal applica-tion: the G6oral project.
Pre-proceedings ofthe Se-cond Venaco Workshop on the Structure of Multi-modal Dialogue, NATO, Acquafredda di Maratea,Italy, September, 16-20, 1991.\[8\] Green G. M. Pragmatics and Natural Lan-guage Understanding.
Lawrence Erlbaum asso-ciates, 1987.\[9\] M. Guyomard and J. Siroux.
Suggestive and Cor-rective Answers : a Single Mechanism, in Thestructure of multimodal dialogue, Taylor M. M.,N6el F. and Bouwhuis D.G.
Editeurs, North Hol-land, 1989, p. 361-374.
(Workshop NATO The struc-ture of multimodal dialogue, V6naco, 1986.
)\[10\] Guyomard M., Siroux J. and Cozannet A. TheRole of Dialogue in Speech Recognition.
The Caseof The Yellow Pages System.
Proceedings EUROS-PEECH 91, Genova, Italy, 1991, p. 1051-1054.\[11\] Guyomard M., Le Meur D., Poignonnec S. and Si-roux J.
Experimental work for the dual usage ofvoice and touch screen for a cartographic applica-tion.
Proceedings of ESCA Tutorial and ResearchWorkshop on Spoken Dialogue Systems, may 30-June 2, Vigs?, Denmark, 1995.\[12\] Proceedings of First International Workshop OnIntelligence and Multimodality in Multimedia In-terfaces: Research and Applications.
J. Lee (ed.
),Edinburg, Scotland, UK, 13-14 July 1995.\[13\] Litman D. J., Allen J.
A Plan Recognition Mo-del for Subdialogue in Conversations.
CognitiveScience 11, p. 163-200, 1987.\[14\] Mathieu F.-A.
Prise en compte de contraintespragmatiques pour guider un syst6me de recon-naissance de la parole: le syst6me COMPTA.
PHDthesis, universit6 Henry Poincar6, Nancy, Mars1997.\[15\] Maybury M.T.
Planning Multimedia ExplanationsUsing Communicative Acts.
Proceedings of theNinth National Conference on Artificial Intelli-gence, AAAI  91, Anaheim, CA, July, 14-19, 1991.\[16\] Maybury M.T.
Communicative Acts for Explana-tion Generation.
International Journal of Man-Machine Studies, 37(2), 135-172.\[17\] Multon F. GEORAL tactile un syst~me multimo-dal.
Rapport de DEA, IFSIC, universit~ de Rennes1, 1994.\[18\] Siroux J., Guyomard M., Multon F. and R6mon-deau C. Modeling and Processing of the Oral andTactile Activities in the GI~ORAL Tactile System.Proceedings of CMC95 International Conferenceon Cooperative Multimodal Communication, Eind-hoven, The Netherlands, 24-26 May 1995.\[19\] Siroux J., Guyomard M., Multon F. and R6mon-deau C. Speech and Tactile Based GEORAL Sys-tem.
Proceedings of EUROSPEECH95, 18-21 Sep-tember, Madrid, 1995.\[20\] Tyler S.W., Schlossberg J.L.
and Cook L.K.
CHO-RIS : An Intelligent Interface Architecture for Mul-timodal Interaction.
Proceedings of the AAAI91Workshop on Intelligent Multimedia Interfaces,Anaheim, CA, July, 14-19, 1991.\[21\] Wahlster W., Andr6 E., Graf W. and Rist T. De-signing Illustrated Texts : How Language Produc-tion is influenced by Graphics Generation.
Procee-dings of EACL 91, Berlin, April 1991.\[22\] Wachtel T. Discourse structure -LOKI.NLi-i.1,Research Unit for Information Science and Arti-ficial Intelligence, University of Hamburg, 1985.
