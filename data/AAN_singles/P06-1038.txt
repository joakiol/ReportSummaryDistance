Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 297?304,Sydney, July 2006. c?2006 Association for Computational LinguisticsEfficient Unsupervised Discovery of Word CategoriesUsing Symmetric Patterns and High Frequency WordsDmitry DavidovICNCThe Hebrew UniversityJerusalem 91904, Israeldmitry@alice.nc.huji.ac.ilAri RappoportInstitute of Computer ScienceThe Hebrew UniversityJerusalem 91904, Israelwww.cs.huji.ac.il/?arirAbstractWe present a novel approach for discov-ering word categories, sets of words shar-ing a significant aspect of their mean-ing.
We utilize meta-patterns of high-frequency words and content words in or-der to discover pattern candidates.
Sym-metric patterns are then identified usinggraph-based measures, and word cate-gories are created based on graph cliquesets.
Our method is the first pattern-basedmethod that requires no corpus annota-tion or manually provided seed patternsor words.
We evaluate our algorithm onvery large corpora in two languages, us-ing both human judgments and WordNet-based evaluation.
Our fully unsupervisedresults are superior to previous work thatused a POS tagged corpus, and computa-tion time for huge corpora are orders ofmagnitude faster than previously reported.1 IntroductionLexical resources are crucial in most NLP tasksand are extensively used by people.
Manual com-pilation of lexical resources is labor intensive, er-ror prone, and susceptible to arbitrary human deci-sions.
Hence there is a need for automatic author-ing that would be as unsupervised and language-independent as possible.An important type of lexical resource is thatgiven by grouping words into categories.
In gen-eral, the notion of a category is a fundamental onein cognitive psychology (Matlin, 2005).
A lexi-cal category is a set of words that share a signif-icant aspect of their meaning, e.g., sets of wordsdenoting vehicles, types of food, tool names, etc.A word can obviously belong to more than a singlecategory.
We will use ?category?
instead of ?lexi-cal category?
for brevity1.Grouping of words into categories is useful in it-self (e.g., for the construction of thesauri), and canserve as the starting point in many applications,such as ontology construction and enhancement,discovery of verb subcategorization frames, etc.Our goal in this paper is a fully unsuperviseddiscovery of categories from large unannotatedtext corpora.
We aim for categories containing sin-gle words (multi-word lexical items will be dealtwith in future papers.)
Our approach is based onpatterns, and utilizes the following stages:1.
Discovery of a set of pattern candidates thatmight be useful for induction of lexical re-lationships.
We do this in a fully unsuper-vised manner, using meta-patterns comprisedof high frequency words and content words.2.
Identification of pattern candidates that giverise to symmetric lexical relationships.
Thisis done using simple measures in a word re-lationship graph.3.
Usage of a novel graph clique-set alorithmin order to generate categories from informa-tion on the co-occurrence of content words inthe symmetric patterns.We performed a thorough evaluation on two En-glish corpora (the BNC and a 68GB web corpus)and on a 33GB Russian corpus, and a sanity-checktest on smaller Danish, Irish and Portuguese cor-pora.
Evaluations were done using both human1Some people use the term ?concept?.
We adhere to thecognitive psychology terminology, in which ?concept?
refersto the mental representation of a category (Matlin, 2005).297judgments and WordNet in a setting quite simi-lar to that done (for the BNC) in previous work.Our unsupervised results are superior to previouswork that used a POS tagged corpus, are less lan-guage dependent, and are very efficient computa-tionally2 .Patterns are a common approach in lexical ac-quisition.
Our approach is novel in several as-pects: (1) we discover patterns in a fully unsu-pervised manner, as opposed to using a manuallyprepared pattern set, pattern seed or words seeds;(2) our pattern discovery requires no annotation ofthe input corpus, as opposed to requiring POS tag-ging or partial or full parsing; (3) we discover gen-eral symmetric patterns, as opposed to using a fewhard-coded ones such as ?x and y?
; (4) the clique-set graph algorithm in stage 3 is novel.
In addition,we demonstrated the relatively language indepen-dent nature of our approach by evaluating on verylarge corpora in two languages3 .Section 2 surveys previous work.
Section 3 de-scribes pattern discovery, and Section 4 describesthe formation of categories.
Evaluation is pre-sented in Section 5, and a discussion in Section 6.2 Previous WorkMuch work has been done on lexical acquisitionof all sorts.
The three main distinguishing axes are(1) the type of corpus annotation and other humaninput used; (2) the type of lexical relationship tar-geted; and (3) the basic algorithmic approach.
Thetwo main approaches are pattern-based discoveryand clustering of context feature vectors.Many of the papers cited below aim at the con-struction of hyponym (is-a) hierarchies.
Note thatthey can also be viewed as algorithms for categorydiscovery, because a subtree in such a hierarchydefines a lexical category.A first major algorithmic approach is to repre-sent word contexts as vectors in some space anduse similarity measures and automatic clusteringin that space (Curran and Moens, 2002).
Pereira(1993) and Lin (1998) use syntactic features in thevector definition.
(Pantel and Lin, 2002) improveson the latter by clustering by committee.
Cara-ballo (1999) uses conjunction and appositive an-notations in the vector representation.2We did not compare against methods that use richer syn-tactic information, both because they are supervised and be-cause they are much more computationally demanding.3We are not aware of any multilingual evaluation previ-ously reported on the task.The only previous works addressing our prob-lem and not requiring any syntactic annotation arethose that decompose a lexically-defined matrix(by SVD, PCA etc), e.g.
(Schu?tze, 1998; Deer-wester et al 1990).
Such matrix decompositionis computationally heavy and has not been provento scale well when the number of words assignedto categories grows.Agglomerative clustering (e.g., (Brown et al1992; Li, 1996)) can produce hierarchical wordcategories from an unannotated corpus.
However,we are not aware of work in this direction that hasbeen evaluated with good results on lexical cate-gory acquisition.
The technique is also quite de-manding computationally.The second main algorithmic approach is touse lexico-syntactic patterns.
Patterns have beenshown to produce more accurate results than fea-ture vectors, at a lower computational cost on largecorpora (Pantel et al 2004).
Hearst (1992) uses amanually prepared set of initial lexical patterns inorder to discover hierarchical categories, and uti-lizes those categories in order to automatically dis-cover additional patterns.
(Berland and Charniak, 1999) use hand craftedpatterns to discover part-of (meronymy) relation-ships, and (Chklovski and Pantel, 2004) discovervarious interesting relations between verbs.
Bothuse information obtained by parsing.
(Pantel et al2004) reduce the depth of the linguistic data usedbut still requires POS tagging.Many papers directly target specific applica-tions, and build lexical resources as a side effect.Named Entity Recognition can be viewed as an in-stance of our problem where the desired categoriescontain words that are names of entities of a par-ticular kind, as done in (Freitag, 2004) using co-clustering.
Many Information Extraction papersdiscover relationships between words using syn-tactic patterns (Riloff and Jones, 1999).
(Widdows and Dorow, 2002; Dorow et al 2005)discover categories using two hard-coded symmet-ric patterns, and are thus the closest to us.
Theyalso introduce an elegant graph representation thatwe adopted.
They report good results.
However,they require POS tagging of the corpus, use onlytwo hard-coded patterns (?x and y?, ?x or y?
), dealonly with nouns, and require non-trivial computa-tions on the graph.A third, less common, approach uses set-theoretic inference, for example (Cimiano et al2982005).
Again, that paper uses syntactic informa-tion.In summary, no previous work has combinedthe accuracy, scalability and performance advan-tages of patterns with the fully unsupervised,unannotated nature possible with clustering ap-proaches.
This severely limits the applicabilityof previous work on the huge corpora available atpresent.3 Discovery of PatternsOur first step is the discovery of patterns that areuseful for lexical category acquisition.
We use twomain stages: discovery of pattern candidates, andidentification of the symmetric patterns among thecandidates.3.1 Pattern CandidatesAn examination of the patterns found useful inprevious work shows that they contain one or morevery frequent word, such as ?and?, ?is?, etc.
Ourapproach towards unsupervised pattern inductionis to find such words and utilize them.We define a high frequency word (HFW) as aword appearing more than TH times per millionwords, and a content word (CW) as a word appear-ing less than TC times per a million words4.Now define a meta-pattern as any sequence ofHFWs and CWs.
In this paper we require thatmeta-patterns obey the following constraints: (1)at most 4 words; (2) exactly two content words; (3)no two consecutive CWs.
The rationale is to seewhat can be achieved using relatively short pat-terns and where the discovered categories containsingle words only.
We will relax these constraintsin future papers.
Our meta-patterns here are thusof four types: CHC, CHCH, CHHC, and HCHC.In order to focus on patterns that are more likelyto provide high quality categories, we removedpatterns that appear in the corpus less than TPtimes per million words.
Since we can ensure thatthe number of HFWs is bounded, the total numberof pattern candidates is bounded as well.
Hence,this stage can be computed in time linear in thesize of the corpus (assuming the corpus has beenalready pre-processed to allow direct access to aword by its index.
)4Considerations for the selection of thresholds are dis-cussed in Section 5.3.2 Symmetric PatternsMany of the pattern candidates discovered in theprevious stage are not usable.
In order to find a us-able subset, we focus on the symmetric patterns.Our rationale is that two content-bearing wordsthat appear in a symmetric pattern are likely tobe semantically similar in some sense.
This sim-ple observation turns out to be very powerful, asshown by our results.
We will eventually combinedata from several patterns and from different cor-pus windows (Section 4.
)For identifying symmetric patterns, we use aversion of the graph representation of (Widdowsand Dorow, 2002).
We first define the single-pattern graph G(P ) as follows.
Nodes corre-spond to content words, and there is a directed arcA(x, y) from node x to node y iff (1) the words xand y both appear in an instance of the pattern Pas its two CWs; and (2) x precedes y in P .
Denoteby Nodes(G), Arcs(G) the nodes and arcs in agraph G, respectively.We now compute three measures on G(P ) andcombine them for all pattern candidates to filterasymmetric ones.
The first measure (M1) countsthe proportion of words that can appear in bothslots of the pattern, out of the total number ofwords.
The reasoning here is that if a pattern al-lows a large percentage of words to participate inboth slots, its chances of being a symmetric pat-tern are greater:M1 :=|{x|?yA(x, y) ?
?zA(z, x)}||Nodes(G(P ))|M1 filters well patterns that connect words hav-ing different parts of speech.
However, it mayfail to filter patterns that contain multiple levelsof asymmetric relationships.
For example, in thepattern ?x belongs to y?, we may find a word Bon both sides (?A belongs to B?, ?B belongs to C?
)while the pattern is still asymmetric.In order to detect symmetric relationships in afiner manner, for the second and third measureswe define SymG(P ), the symmetric subgraph ofG(P ), containing only the bidirectional arcs andnodes of G(P ):SymG(P ) = {{x}, {(x, y)}|A(x, y) ?
A(y, x)}The second and third measures count the pro-portion of the number of symmetric nodes andedges in G(P ), respectively:M2 :=|Nodes(SymG(P ))||Nodes(G(P ))|299M3 :=|Arcs(SymG(P ))||Arcs(G(P ))|All three measures yield values in [0, 1], andin all three a higher value indicates more symme-try.
M2 and M3 are obviously correlated, but theycapture different aspects of a pattern?s nature: M3is informative for highly interconnected but smallword categories (e.g., month names), while M2 isuseful for larger categories that are more looselyconnected in the corpus.We use the three measures as follows.
For eachmeasure, we prepare a sorted list of all candidatepatterns.
We remove patterns that are not in thetop ZT (we use 100, see Section 5) in any of thethree lists, and patterns that are in the bottom ZBin at least one of the lists.
The remaining patternsconstitute our final list of symmetric patterns.We do not rank the final list, since the categorydiscovery algorithm of the next section does notneed such a ranking.
Defining and utilizing such aranking is a subject for future work.A sparse matrix representation of each graphcan be computed in time linear in the size of the in-put corpus, since (1) the number of patterns |P | isbounded, (2) vocabulary size |V | (the total numberof graph nodes) is much smaller than corpus size,and (3) the average node degree is much smallerthan |V | (in practice, with the thresholds used, itis a small constant.
)4 Discovery of CategoriesAfter the end of the previous stage we have a setof symmetric patterns.
We now use them in orderto discover categories.
In this section we describethe graph clique-set method for generating initialcategories, and category pruning techniques for in-creased quality.4.1 The Clique-Set MethodOur approach to category discovery is based onconnectivity structures in the all-pattern word rela-tionship graph G, resulting from merging all of thesingle-pattern graphs into a single unified graph.The graph G can be built in time O(|V | ?
|P | ?AverageDegree(G(P ))) = O(|V |) (we use Vrather than Nodes(G) for brevity.
)When building G, no special treatment is donewhen one pattern is contained within another.
Forexample, any pattern of the form CHC is containedin a pattern of the form HCHC (?x and y?, ?both xand y?.)
The shared part yields exactly the samesubgraph.
This policy could be changed for a dis-covery of finer relationships.The main observation on G is that words thatare highly interconnected are good candidates toform a category.
This is the same general obser-vation exploited by (Widdows and Dorow, 2002),who try to find graph regions that are more con-nected internally than externally.We use a different algorithm.
We find all strongn-cliques (subgraphs containing n nodes that areall bidirectionally interconnected.)
A clique Q de-fines a category that contains the nodes in Q plusall of the nodes that are (1) at least unidirectionallyconnected to all nodes in Q, and (2) bidirectionallyconnected to at least one node in Q.In practice we use 2-cliques.
The strongly con-nected cliques are the bidirectional arcs in G andtheir nodes.
For each such arc A, a category is gen-erated that contains the nodes of all triangles thatcontain A and at least one additional bidirectionalarc.
For example, suppose the corpus contains thetext fragments ?book and newspaper?, ?newspaperand book?, ?book and note?, ?note and book?
and?note and newspaper?.
In this case the three wordsare assigned to a category.Note that a pair of nodes connected by a sym-metric arc can appear in more than a single cate-gory.
For example, suppose a graph G containingfive nodes and seven arcs that define exactly threestrongly connected triangles, ABC,ABD,ACE.The arc (A,B) yields a category {A,B,C,D},and the arc (A,C) yields a category {A,C,B,E}.Nodes A and C appear in both categories.
Cate-gory merging is described below.This stage requires an O(1) computation foreach bidirectional arc of each node, so its com-plexity is O(|V | ?
AverageDegree(G)) =O(|V |).4.2 Enhancing Category Quality: CategoryMerging and Corpus WindowingIn order to cover as many words as possible, weuse the smallest clique, a single symmetric arc.This creates redundant categories.
We enhance thequality of the categories by merging them and bywindowing on the corpus.We use two simple merge heuristics.
First,if two categories are identical we treat them asone.
Second, given two categories Q,R, we mergethem iff there?s more than a 50% overlap betweenthem: (|Q ?
R| > |Q|/2) ?
(|Q ?
R| > |R|/2).300This could be added to the clique-set stage, but thephrasing above is simpler to explain and imple-ment.In order to increase category quality and re-move categories that are too context-specific, weuse a simple corpus windowing technique.
In-stead of running the algorithm of this section onthe whole corpus, we divide the corpus into win-dows of equal size (see Section 5 for size deter-mination) and perform the category discovery al-gorithm of this section on each window indepen-dently.
Merging is also performed in each win-dow separately.
We now have a set of categoriesfor each window.
For the final set, we select onlythose categories that appear in at least two of thewindows.
This technique reduces noise at the po-tential cost of lowering coverage.
However, thenumbers of categories discovered and words theycontain is still very large (see Section 5), so win-dowing achieves higher precision without hurtingcoverage in practice.The complexity of the merge stage is O(|V |)times the average number of categories per wordtimes the average number of words per category.The latter two are small in practice, so complexityamounts to O(|V |).5 EvaluationLexical acquisition algorithms are notoriouslyhard to evaluate.
We have attempted to be asthorough as possible, using several languages andboth automatic and human evaluation.
In the auto-matic part, we followed as closely as possible themethodology and data used in previous work, sothat meaningful comparisons could be made.5.1 Languages and CorporaWe performed in-depth evaluation on two lan-guages, English and Russian, using three cor-pora, two for English and one for Russian.
Thefirst English corpus is the BNC, containing about100M words.
The second English corpus, Dmoz(Gabrilovich and Markovitch, 2005), is a web cor-pus obtained by crawling and cleaning the URLsin the Open Directory Project (dmoz.org), result-ing in 68GB containing about 8.2G words from50M web pages.The Russian corpus was assembled from manyweb sites and carefully filtered for duplicates, toyield 33GB and 4G words.
It is a varied corpuscomprising literature, technical texts, news, news-groups, etc.As a preliminary sanity-check test we also ap-plied our method to smaller corpora in Danish,Irish and Portuguese, and noted some substantialsimilarities in the discovered patterns.
For exam-ple, in all 5 languages the pattern corresponding to?x and y?
was among the 50 selected.5.2 Thresholds, Statistics and ExamplesThe thresholds TH , TC , TP , ZT , ZB , were deter-mined by memory size considerations: we com-puted thresholds that would give us the maximalnumber of words, while enabling the pattern ac-cess table to reside in main memory.
The resultingnumbers are 100, 50, 20, 100, 100.Corpus window size was determined by startingfrom a very small window size, defining at ran-dom a single window of that size, running the al-gorithm, and iterating this process with increasedwindow sizes until reaching a desired vocabularycategory participation percentage (i.e., x% of thedifferent words in the corpus assigned into cate-gories.
We used 5%.)
This process has only anegligible effect on running times, because eachiteration is run only on a single window, not onthe whole corpus.The table below gives some statistics.
V is thetotal number of different words in the corpus.
Wis the number of words belonging to at least oneof our categories.
C is the number of categories(after merging and windowing.)
AS is the aver-age category size.
Running times are in minuteson a 2.53Ghz Pentium 4 XP machine with 1GBmemory.
Note how small they are, when com-pared to (Pantel et al 2004), which took 4 daysfor a smaller corpus using the same CPU.V W C AS TimeDmoz 16M 330K 142K 12.8 93mBNC 337K 25K 9.6K 10.2 6.8mRussian 10M 235K 115K 11.6 60mAmong the patterns discovered are the ubiqui-tous ?x and y?, ?x or y?
and many patterns con-taining them.
Additional patterns include ?from xto y?, ?x and/or y?
(punctuation is treated here aswhite space), ?x and a y?, and ?neither x nor y?.We discover categories of different parts ofspeech.
Among the noun ones, there are manywhose precision is 100%: 37 countries, 18 lan-guages, 51 chemical elements, 62 animals, 28types of meat, 19 fruits, 32 university names, etc.A nice verb category example is {dive, snorkel,swim, float, surf, sail, canoe, kayak, paddle, tube,drift}.
A nice adjective example is {amazing,301awesome, fascinating, inspiring, inspirational, ex-citing, fantastic, breathtaking, gorgeous.
}5.3 Human Judgment EvaluationThe purpose of the human evaluation was dual: toassess the quality of the discovered categories interms of precision, and to compare with those ob-tained by a baseline clustering algorithm.For the baseline, we implemented k-means asfollows.
We have removed stopwords from thecorpus, and then used as features the words whichappear before or after the target word.
In the calcu-lation of feature values and inter-vector distances,and in the removal of less informative features, wehave strictly followed (Pantel and Lin, 2002).
Weran the algorithm 10 times using k = 500 withrandomly selected centroids, producing 5000 clus-ters.
We then merged the resulting clusters us-ing the same 50% overlap criterion as in our algo-rithm.
The result included 3090, 2116, and 3206clusters for Dmoz, BNC and Russian respectively.We used 8 subjects for evaluation of the Englishcategories and 15 subjects for evaluation of theRussian ones.
In order to assess the subjects?
re-liability, we also included random categories (seebelow.
)The experiment contained two parts.
In PartI, subjects were given 40 triplets of words andwere asked to rank them using the following scale:(1) the words definitely share a significant partof their meaning; (2) the words have a sharedmeaning but only in some context; (3) the wordshave a shared meaning only under a very un-usual context/situation; (4) the words do not shareany meaning; (5) I am not familiar enough withsome/all of the words.The 40 triplets were obtained as follows.
20 ofour categories were selected at random from thenon-overlapping categories we have discovered,and three words were selected from each of theseat random.
10 triplets were selected in the samemanner from the categories produced by k-means,and 10 triplets were generated by random selec-tion of content words from the same window inthe corpus.In Part II, subjects were given the full categoriesof the triplets that were graded as 1 or 2 in Part I(that is, the full ?good?
categories in terms of shar-ing of meaning.)
They were asked to grade thecategories from 1 (worst) to 10 (best) according tohow much the full category had met the expecta-tions they had when seeing only the triplet.Results are given in Table 1.
The first line givesthe average percentage of triplets that were givenscores of 1 or 2 (that is, ?significant shared mean-ing?.)
The 2nd line gives the average score ofa triplet (1 is best.)
In these lines scores of 5were not counted.
The 3rd line gives the averagescore given to a full category (10 is best.)
Inter-evaluator Kappa between scores 1,2 and 3,4 was0.56, 0.67 and 0.72 for Dmoz, BNC and Russianrespectively.Our algorithm clearly outperforms k-means,which outperforms random.
We believe that theRussian results are better because the percentageof native speakers among our subjects for Russianwas larger than that for English.5.4 WordNet-Based EvaluationThe major guideline in this part of the evalua-tion was to compare our results with previouswork having a similar goal (Widdows and Dorow,2002).
We have followed their methodology asbest as we could, using the same WordNet (WN)categories and the same corpus (BNC) in additionto the Dmoz and Russian corpora5 .The evaluation method is as follows.
We tookthe exact 10 WN subsets referred to as ?subjects?in (Widdows and Dorow, 2002), and removed allmulti-word items.
We now selected at random 10pairs of words from each subject.
For each pair,we found the largest of our discovered categoriescontaining it (if there isn?t one, we pick anotherpair.
This is valid because our Recall is obviouslynot even close to 100%, so if we did not pick an-other pair we would seriously harm the validity ofthe evaluation.)
The various morphological formsof the same word were treated as one during theevaluation.The only difference from the (Widdows andDorow, 2002) experiment is the usage of pairsrather than single words.
We did this in order todisambiguate our categories.
This was not neededin (Widdows and Dorow, 2002) because they haddirectly accessed the word graph, which may bean advantage in some applications.The Russian evaluation posed a bit of a prob-lem because the Russian WordNet is not readilyavailable and its coverage is rather small.
Fortu-nately, the subject list is such that WordNet words5(Widdows and Dorow, 2002) also reports results for anLSA-based clustering algorithm that are vastly inferior to thepattern-based ones.302Dmoz BNC Russianus k-means random us k-means random us k-means randomavg ?shared meaning?
(%) 80.53 18.25 1.43 86.87 8.52 0.00 95.00 18.96 7.33avg triplet score (1-4) 1.74 3.34 3.88 1.56 3.61 3.94 1.34 3.32 3.76avg category score (1-10) 9.27 4.00 1.8 9.31 4.50 0.00 8.50 4.66 3.32Table 1: Results of evaluation by human judgment of three data sets (ours, that obtained by k-means, andrandom categories) on the three corpora.
See text for detailed explanations.could be translated unambiguously to Russian andwords in our discovered categories could be trans-lated unambiguously into English.
This was themethodology taken.For each found category C containing N words,we computed the following (see Table 2): (1) Pre-cision: the number of words present in both C andWN divided by N ; (2) Precision*: the number ofcorrect words divided by N .
Correct words are ei-ther words that appear in the WN subtree, or wordswhose entry in the American Heritage Dictionaryor the Britannica directly defines them as belong-ing to the given class (e.g., ?keyboard?
is definedas ?a piano?
; ?mitt?
is defined by ?a type of glove?.
)This was done in order to overcome the relativepoorness of WordNet; (3) Recall: the number ofwords present in both C and WN divided by thenumber of (single) words in WN; (4) The num-ber of correctly discovered words (New) that arenot in WN.
The Table also shows the number ofWN words (:WN), in order to get a feeling by howmuch WN could be improved here.
For each sub-ject, we show the average over the 10 randomlyselected pairs.Table 2 also shows the average of each measureover the subjects, and the two precision measureswhen computed on the total set of WN words.
The(uncorrected) precision is the only metric given in(Widdows and Dorow, 2002), who reported 82%(for the BNC.)
Our method gives 90.47% for thismetric on the same corpus.5.5 SummaryOur human-evaluated and WordNet-based resultsare better than the baseline and previous work re-spectively.
Both are also of good standalone qual-ity.
Clearly, evaluation methodology for lexicalacquisition tasks should be improved, which is aninteresting research direction in itself.Examining our categories at random, we founda nice example that shows how difficult it is toevaluate the task and how useful automatic cate-gory discovery can be, as opposed to manual def-inition.
Consider the following category, discov-ered in the Dmoz corpus: {nightcrawlers, chicken,shrimp, liver, leeches}.
We did not know whythese words were grouped together; if asked in anevaluation, we would give the category a very lowscore.
However, after some web search, we foundthat this is a ?fish bait?
category, especially suitablefor catfish.6 DiscussionWe have presented a novel method for pattern-based discovery of lexical semantic categories.It is the first pattern-based lexical acquisitionmethod that is fully unsupervised, requiring nocorpus annotation or manually provided patternsor words.
Pattern candidates are discovered us-ing meta-patterns of high frequency and contentwords, and symmetric patterns are discovered us-ing simple graph-theoretic measures.
Categoriesare generated using a novel graph clique-set alo-rithm.
The only other fully unsupervised lexicalcategory acquisition approach is based on decom-position of a matrix defined by context feature vec-tors, and it has not been shown to scale well yet.Our algorithm was evaluated using both humanjudgment and automatic comparisons with Word-Net, and results were superior to previous work(although it used a POS tagged corpus) and moreefficient computationally.
Our algorithm is alsoeasy to implement.Computational efficiency and specifically lackof annotation are important criteria, because theyallow usage of huge corpora, which are presentlybecoming available and growing in size.There are many directions to pursue in the fu-ture: (1) support multi-word lexical items; (2) in-crease category quality by improved merge algo-rithms; (3) discover various relationships (e.g., hy-ponymy) between the discovered categories; (4)discover finer inter-word relationships, such asverb selection preferences; (5) study various prop-erties of discovered patterns in a detailed manner;and (6) adapt the algorithm to morphologicallyrich languages.303Subject Prec.
Prec.
* Rec.
New:WNDmozinstruments 79.25 89.34 34.54 7.2:163vehicles 80.17 86.84 18.35 6.3:407academic 78.78 89.32 30.83 15.5:396body parts 73.85 79.29 5.95 9.1:1491foodstuff 83.94 90.51 28.41 26.3:1209clothes 83.41 89.43 10.65 4.5:539tools 83.99 89.91 21.69 4.3:219places 76.96 84.45 25.82 6.3:232crimes 76.32 86.99 31.86 4.7:102diseases 81.33 88.99 19.58 6.8:332set avg 79.80 87.51 22.77 9.1:509all words 79.32 86.94BNCinstruments 92.68 95.43 9.51 0.6:163vehicles 94.16 95.23 3.81 0.2:407academic 93.45 96.10 12.02 0.6:396body parts 96.38 97.60 0.97 0.3:1491foodstuff 93.76 94.36 3.60 0.6:1209cloths 93.49 94.90 4.04 0.3:539tools 96.84 97.24 6.67 0.1:219places 87.88 97.25 6.42 1.5:232crimes 83.79 91.99 19.61 2.6:102diseases 95.16 97.14 5.54 0.5:332set avg 92.76 95.72 7.22 0.73:509all words 90.47 93.80Russianinstruments 82.46 89.09 25.28 3.4:163vehicles 83.16 89.58 16.31 5.1:407academic 87.27 92.92 15.71 4.9:396body parts 81.42 89.68 3.94 8.3:1491foodstuff 80.34 89.23 13.41 24.3:1209clothes 82.47 87.75 15.94 5.1:539tools 79.69 86.98 21.14 3.7:219places 82.25 90.20 33.66 8.5:232crimes 84.77 93.26 34.22 3.3:102diseases 80.11 87.70 20.69 7.7:332set avg 82.39 89.64 20.03 7.43:509all words 80.67 89.17Table 2: WordNet evaluation.
Note the BNC ?allwords?
precision of 90.47%.
This metric was re-ported to be 82% in (Widdows and Dorow, 2002).It should be noted that our algorithm can beviewed as one for automatic discovery of wordsenses, because it allows a word to participate inmore than a single category.
When merged prop-erly, the different categories containing a word canbe viewed as the set of its senses.
We are planningan evaluation according to this measure after im-proving the merge stage.ReferencesMatthew Berland and Eugene Charniak, 1999.
Findingparts in very large corpora.
ACL ?99.Peter Brown, Vincent Della Pietra, Peter deSouza,Jenifer Lai, Robert Mercer, 1992.
Class-based n-gram models for natural language.
Comp.
Linguis-tics, 18(4):468?479.Sharon Caraballo, 1999.
Automatic construction of ahypernym-labeled noun hierarchy from text.
ACL?99.Timothy Chklovski, Patrick Pantel, 2004.
VerbOcean:mining the web for fine-grained semantic verb rela-tions.
EMNLP ?04.Philipp Cimiano, Andreas Hotho, Steffen Staab, 2005.Learning concept hierarchies from text corpora us-ing formal concept analysis.
J. of Artificial Intelli-gence Research, 24:305?339.James Curran, Marc Moens, 2002.
Improvements inautomatic thesaurus extraction.
ACL Workshop onUnsupervised Lexical Acquisition, 2002.Scott Deerwester, Susan Dumais, George Furnas,Thomas Landauer, Richard Harshman, 1990.
Index-ing by latent semantic analysis.
J. of the AmericanSociety for Info.
Science, 41(6):391?407.Beate Dorow, Dominic Widdows, Katarina Ling, Jean-Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.Using curvature and Markov clustering in graphs forlexical acquisition and word sense discrimination.MEANING ?05.Dayne Freitag, 2004.
Trained named entity recognitionusing distributional clusters.
EMNLP ?04.Evgeniy Gabrilovich, Shaul Markovitch, 2005.
Fea-ture generation for text categorization using worldknowledge.
IJCAI ?05.Marti Hearst, 1992.
Automatic acquisition of hy-ponyms from large text corpora.
COLING ?92.Hang Li, Naoki Abe, 1996.
Clustering words with theMDL principle.
COLING ?96.Dekang Lin, 1998.
Automatic retrieval and clusteringof similar words.
COLING ?98.Margaret Matlin, 2005.
Cognition, 6th edition.
JohnWiley & Sons.Patrick Pantel, Dekang Lin, 2002.
Discovering wordsenses from text.
SIGKDD ?02.Patrick Pantel, Deepak Ravichandran, Eduard Hovy,2004.
Towards terascale knowledge acquisition.COLING ?04.Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.Distributional clustering of English words.
ACL ?93.Ellen Riloff, Rosie Jones, 1999.
Learning dictionariesfor information extraction by multi-level bootstrap-ping.
AAAI ?99.Hinrich Schu?tze, 1998.
Automatic word sense discrim-ination.
Comp.
Linguistics, 24(1):97?123.Dominic Widdows, Beate Dorow, 2002.
A graph modelfor unsupervised Lexical acquisition.
COLING ?02.304
