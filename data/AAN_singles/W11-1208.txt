Paraphrase Fragment Extraction from Monolingual Comparable CorporaRui WangLanguage Technology LabDFKI GmbHStuhlsatzenhausweg 3 / Building D3 2Saarbruecken, 66123 Germanyrwang@coli.uni-sb.deChris Callison-BurchComputer Science DepartmentJohns Hopkins University3400 N. Charles Street (CSEB 226-B)Baltimore, MD 21218, USAccb@cs.jhu.eduAbstractWe present a novel paraphrase fragment pairextraction method that uses a monolingualcomparable corpus containing different arti-cles about the same topics or events.
The pro-cedure consists of document pair extraction,sentence pair extraction, and fragment pair ex-traction.
At each stage, we evaluate the in-termediate results manually, and tune the laterstages accordingly.
With this minimally su-pervised approach, we achieve 62% of accu-racy on the paraphrase fragment pairs we col-lected and 67% extracted from the MSR cor-pus.
The results look promising, given theminimal supervision of the approach, whichcan be further scaled up.1 IntroductionParaphrase is an important linguistic phenomenonwhich occurs widely in human languages.
Sinceparaphrases capture the variations of linguistic ex-pressions while preserving the meaning, they arevery useful in many applications, such as machinetranslation (Marton et al, 2009), document summa-rization (Barzilay et al, 1999), and recognizing tex-tual entailment (RTE) (Dagan et al, 2005).However, such resources are not trivial to ob-tain.
If we make a comparison between para-phrase and MT, the latter has large parallel bilin-gual/multilingual corpora to acquire translation pairsin different granularity; while it is difficult to find a?naturally?
occurred paraphrase ?parallel?
corpora.Furthermore, in MT, certain words can be translatedinto a (rather) small set of candidate words in thetarget language; while in principle, each paraphrasecan have infinite number of ?target?
expressions,which reflects the variety of each human language.A variety of paraphrase extraction approacheshave been proposed recently, and they require dif-ferent types of training data.
Some require bilingualparallel corpora (Callison-Burch, 2008; Zhao et al,2008), others require monolingual parallel corpora(Barzilay and McKeown, 2001; Ibrahim et al, 2003)or monolingual comparable corpora (Dolan et al,2004).In this paper, we focus on extracting paraphrasefragments from monolingual corpora, because this isthe most abundant source of data.
Additionally, thiswould potentially allow us to extract paraphrases fora variety of languages that have monolingual cor-pora, but which do not have easily accessible paral-lel corpora.This paper makes the following contributions:1.
We adapt a translation fragment pair extrac-tion method to paraphrase extraction, i.e., frombilingual corpora to monolingual corpora.2.
We construct a large collection of para-phrase fragments from monolingual compara-ble corpora and achieve similar quality from amanually-checked paraphrase corpus.3.
We evaluate both intermediate and final resultsof the paraphrase collection, using the crowd-sourcing technique, which is effective, fast, andcheap.52Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 52?60,49th Annual Meeting of the Association for Computational Linguistics,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsCorpora Sentence level Sub-sentential levelParaphrase acquisitionMonolingual Parallel e.g., Barzilay and McKeown (2001) This paperComparable e.g., Quirk et al (2004) e.g., Shinyama et al (2002) & This paperBilingual Parallel N/A e.g., Bannard and Callison-Burch (2005)Statistical machine translationBilingual Parallel Most SMT systems SMT phrase tablesComparable e.g., Fung and Lo (1998) e.g., Munteanu and Marcu (2006)Table 1: Previous work in paraphrase acquisition and machine translation.2 Related WorkRoughly speaking, there are three dimensions tocharacterize the previous work in paraphrase ac-quisition and machine translation, whether thedata comes from monolingual or bilingual corpora,whether the corpora are parallel or comparable, andwhether the output is at the sentence level or at thesub-sentential level.
Table 1 gives one example ineach category.Paraphrase acquisition is mostly done at thesentence-level, e.g., (Barzilay and McKeown, 2001;Barzilay and Lee, 2003; Dolan et al, 2004), which isnot straightforward to be used as a resource for otherNLP applications.
Quirk et al (2004) adopted theMT approach to ?translate?
one sentence into a para-phrased one.
As for the corpora, Barzilay and McK-eown (2001) took different English translations ofthe same novels (i.e., monolingual parallel corpora),while the others experimented on multiple sourcesof the same news/events, i.e., monolingual compa-rable corpora.At the sub-sentential level, interchangeable pat-terns (Shinyama et al, 2002; Shinyama and Sekine,2003) or inference rules (Lin and Pantel, 2001)are extracted, which are quite successful in named-entity-centered tasks, like information extraction,while they are not generalized enough to be appliedto other tasks or they have a rather small coverage,e.g.
RTE (Dinu and Wang, 2009).
To our bestknowledge, there is few focused study on generalparaphrase fragments extraction at the sub-sententiallevel, from comparable corpora.
A recent studyby Belz and Kow (2010) mainly aimed at naturallanguage generation, which they performed a smallscale experiment on a specific topic, i.e., Britishhills.Given the available parallel corpora from the MTcommunity, there are studies focusing on extractingparaphrases from bilingual corpora (Bannard andCallison-Burch, 2005; Callison-Burch, 2008; Zhaoet al, 2008).
The way they do is to treat one lan-guage as an pivot and equate two phrases in the otherlanguages as paraphrases if they share a commonpivot phrase.
Paraphrase extraction draws on phrasepair extraction from the translation literature.
Sinceparallel corpora have many alternative ways of ex-pressing the same foreign language concept, largequantities of paraphrase pairs can be extracted.As for the MT research, the standard statisticalMT systems require large size of parallel corpora fortraining and then extract sub-sentential translationphrases.
Apart from the limited parallel corpora,comparable corpora are non-parallel bilingual cor-pora whose documents convey the similar informa-tion are also widely considered by many researchers,e.g., (Fung and Lo, 1998; Koehn and Knight, 2000;Vogel, 2003; Fung and Cheung, 2004a; Fung andCheung, 2004b; Munteanu and Marcu, 2005; Wuand Fung, 2005).
A recent study by Smith et al(2010) extracted parallel sentences from comparablecorpora to extend the existing resources.At the sub-sentential level, Munteanu andMarcu (2006) extracted sub-sentential translationpairs from comparable corpora based on the log-likelihood-ratio of word translation probability.They exploit the possibility of making use of reportswithin a limited time window, which are about thesame event or having overlapping contents, but indifferent languages.
Quirk et al (2007) extractedfragments using a generative model of noisy transla-tions.
They show that even in non-parallel corpora,useful parallel words or phrases can still be foundand the size of such data is much larger than that of53Document PairExtractionSentence PairExtractionFragment PairExtractionCorpora(Gigaword)<doc> ... in1995 ...</doc><doc> ... Jan.,1995 ...</doc>Comparability<sent>NATO ...in 1995 ...</sent><sent> In1995,NATO ...</sent>N-GramOverlapping<frag> thefinance chief</frag><frag> thechief financialofficer </frag>InterchangeabilityParaphrasedFragmentsParaphraseCollection(MSR)ParaphraseCollecton(CCB)Figure 1: A three stage pipeline is used to extract paraphrases from monolingual textsparallel corpora.
In this paper, we adapt ideas fromthe MT research on extracting sub-sentential trans-lation fragments from bilingual comparable corpora(Munteanu and Marcu, 2006), and use the tech-niques to extract paraphrases from monolingual par-allel and comparable corpora.Evaluation is another challenge for resource col-lection, which usually requires tremendous labor re-sources.
Both Munteanu and Marcu (2006) andQuirk et al (2007) evaluated their resources indi-rectly in MT systems, while in this paper, we makeuse of the crowd-sourcing technique to manuallyevaluate the quality of the paraphrase collection.In parcitular, Amazon?s Mechanical Turk1 (MTurk)provides a way to pay people small amounts ofmoney to perform tasks that are simple for humansbut difficult for computers.
Examples of these Hu-man Intelligence Tasks (or HITs) range from label-ing images to moderating blog comments to pro-viding feedback on relevance of results for a searchquery.
Using MTurk for NLP task evaluation hasbeen shown to be significantly cheaper and faster,and there is a high agreement between aggregatenon-expert annotations and gold-standard annota-tions provided by the experts (Snow et al, 2008).1http://www.mturk.com/3 Fragment Pair AcquisitionFigure 1 shows the pipeline of our paraphrase ac-quisition method.
We evaluate quality at each stageusing Amazon?s Mechanical Turk.
In order to en-sure that the non-expert annotators complete the taskaccurately, we used both positive and negative con-trols.
If annotators answered either control incor-rectly, we excluded their answers.
For all the ex-periments we describe in this paper, we obtain theanswers within a couple of hours or an overnight.Our focus in this paper is on fragment extraction,but we briefly describe document and sentence pairextraction first.3.1 Document Pair ExtractionMonolingual comparable corpora contain textsabout the same events or subjects, written in one lan-guage by different authors (Barzilay and Elhadad,2003).
We extract pairs of newswire articles writtenby different news agencies from the GIGAWORD cor-pus, which contains articles from six different agen-cies.
Although the comparable documents are not inparallel, at the sentential or sub-sentential level, theparaphrased fragments may still exist.To quantify the comparability between two doc-uments, we calculate the number of overlappingwords and give them different weights based onTF-IDF (Salton and McGill, 1983) using the More-54LikeThis2 function provided by Lucene.After collecting the document pairs, we asked an-notators, ?Are these two documents about the sametopic?
?, and allowing them to answer ?Yes?, ?No?,and ?Not sure?.
Each set of six document pairs con-tained, four to be evaluated, one positive control (apair of identical documents) and one negative con-trol (a pair of random documents).
We sampled400 document pairs with the comparability score be-tween 0.8 and 0.9, and another 400 pairs greater than0.9.
We presented them in a random order and eachwas labeled by three annotations.
After excludingthe annotations containing incorrect answers for ei-ther control, we took a majority vote for every docu-ment pair, and if three annotations are different fromeach other.We found document pairs with >0.9 were classi-fied by annotators to be related more than half thetime, and a higher threshold would greatly decreasethe number of document pairs extracted.
We per-formed subsequent steps on the 3896 document pairsthat belonged to this category.3.2 Sentence Pair ExtractionAfter extracting pairs of related documents, wenext selected pairs of related sentences from withinpaired documents.
The motivation behind is thatthe standard word alignment algorithms can be eas-ily applied to the paired sentences instead of docu-ments.
To do so we selected sentences with overlap-ping n-grams up to length n=4.
Obviously for para-phrasing, we want some of the n-grams to differ, sowe varied the amount of overlap and evaluated sen-tence pairs with a variety of threshold bands3.We evaluated 10 pairs of sentences at a time, in-cluding one positive control and two negative con-trols.
A random pair of sentential paraphrases fromthe RTE task acted as the positive control.
Thenegative controls included one random pair of non-paraphrased, but highly relevant sentences, and arandom pair of sentences.
Annotators classified thesentence pairs as: paraphrases, related sentences,2http://lucene.apache.org/java/2_9_1/api/contrib-queries/org/apache/lucene/search/similar/MoreLikeThis.html3In the experiment setting, the thresholds (maximum com-parability and minimum comparability) for the 4 groups are,{0.78,0.206}, {0.206,0.138}, {0.138,0.115}, {0.115,0.1}.0%?10%?20%?30%?40%?50%?60%?70%?80%?90%?100%?0.1-??0.108?0.108-??0.115?0.115-??0.125?0.125-??0.138?0.138-??0.16?0.16-??0.206?0.206-?
?0.78?invalid?not_related?related?paraphrases?Figure 2: Results of the sentence pair extraction.
The x-axis is the threshold for the comparability scores; and they-axis is the distribution of the annotations.and non-related sentences.We uniformly sampled 200 sentence pairs fromeach band.
They are randomly shuffled into morethan 100 HITs and each HIT got three annotations.Figure 2 shows the distribution of annotations acrossdifferent groups, after excluding answers that failedthe controls.Our best scoring threshold band was 0.2-0.8.
Sen-tence pairs with this overlap were judged to be para-phrases 45% of the time, to be related 30% of thetime, and to be unrelated 25% of the time.
Althoughthe F2 heuristic proposed by Dolan et al (2004),which takes the first two sentences of each documentpair, obtains higher relatedness score (we evalu-ated F2 sentences as 50% paraphrases, 37% related,and 13% unrelated), our n-gram overlap method ex-tracted much more sentence pairs per document pair.One interesting observation other than the generalincreasing tendency is that the portion of the relatedsentence pairs is not monotonic, which exactly re-flects our intuition about a good comparability value(neither too high nor too low).
However, some er-rors are difficult to exclude.
For instance, one sen-tence says ?The airstrikes were halted for 72 hourslast Thursday...?
and the other says ?NATO and UNofficials extended the suspension of airstrikes for afurther 72 hours from late Sunday...?.
Without fine-grained analysis of the temporal expressions, it isdifficult to know whether they are talking about thesame event.
The F2 method does provide us a fairlygood way to exclude some unrelated sentence pairs,but note that the pairs collected by this method are55Figure 3: An example of fragment pair extraction.
Stop words are all set to 1 initially.
Zero is the threshold, and theunderscored phrases are the outputs.only about 0.5% of using the comparability scores.We show in Figure 1 that we also use an addi-tional sentence-level paraphrase corpus as the inputof this module.
We take all the positive instances(i.e.
the two sentences in a pair are paraphrase toeach other) and pass them to the later stage as well,as for comparison with our paraphrase collection ex-tracted from the comparable sentence pairs.
In all,we used 276,120 sentence pairs to feed our fragmentextraction method.3.3 Fragment Pair ExtractionThe basic procedure is to 1) establish alignments be-tween words or n-grams and 2) extract target para-phrase fragments.
For the first step, we use two ap-proaches.
One is to change the common substringalignment problem from string to word sequenceand we extend the longest common substring (LCS)extraction algorithm to multiple common n-grams.An alternative way is to use a normal word aligner(widely used as the first step in MT systems) to ac-complish the job.
For our experiments, we use theBerkeleyAligner4 (Liang et al, 2006) by feeding it adictionary of pairs of identical words along with thepaired sentences.
We can also combine these twomethods by performing the LCS alignment first andadding additional word alignments from the aligner.These form the three configurations of our system(Table 2).Following Munteanu and Marcu (2006), we useboth positive and negative lexical associations forthe alignment.
The positive association measures4http://code.google.com/p/berkeleyaligner/how likely one word will be aligned to another(value from 0 to 1); and the negative associationsindicates how unlikely an alignment exists betweena word pair (from -1 to 0).
The basic idea to haveboth is that when a word cannot be aligned with anyother words, it will choose the least unlikely one.
Ifthe positive association of w1 being aligned with w2is defined as the conditional probability p(w1|w2),the negative associations will simply be p(w1|?w2).Since we obtain a distribution of all the possiblewords aligned with w1 from the word aligner, bothp(w1|w2) and p(w1|?w2) can be calculated; for theLCS alignment, we simply set p(w1|w2) as 1 andp(w1|?w2) as -1, if w1 and w2 are aligned; and viceversa, if not.After the initialization of all the word alignmentsusing the two associations, each word takes the av-erage of the neighboring four words and itself.
Theintuition of this smoothing is to tolerate a few un-aligned parts (if they are surrounded by alignedparts).
Finally, all the word alignments having a pos-itive score will be selected as the candidate fragmentelements.
Figure 3 shows an example of this pro-cess.The second step, fragment extraction, is a bittricky, since a fragment is not clearly defined likea document or a sentence.
One option is to fol-low the MT definition of a phrase, which means asub-sentential n-gram string (usually n is less than10).
Munteanu and Marcu (2006) adopted this, andconsidered all the possible sub-sentential translationfragments as their targets, i.e.
the adjacent n-grams.For instance, in Figure 3, all the adjacent wordsabove the threshold (i.e.
zero) will form the target56ConfigurationsAligner+ LCS+ Word+ LCS+Word+Phrase Extraction Chunk N-Gram ChunkOur CorpusPARAPHRASE 15% 36% 32%RELATED 21% 26% 21%SUM 36% 62% 53%The MSR CorpusPARAPHRASE 38% 44% 49%RELATED 20% 19% 18%SUM 58% 63% 67%Table 2: Distribution of the Extracted Fragment Pairs ofour Corpus and MSR Corpus.
We manually evaluated1051 sentence pairs in all.
We use LCS or word aligner asthe initialization and apply n-gram-based or chunk-basedphrase extraction.
The first column serves as the baseline.paraphrase, ?the Bosnian Serbs to pull their heavyweapons back from?
and those aligned words in theother sentence ?the Bosnian Serbs withdraw theirheavy weapons from?
will be the source paraphrase.The disadvantage of this definition is that the ex-tracted fragment pairs might not be easy for humanbeings to interpret or they are even ungrammatical(cf.
the fourth example in Table 5).
An alternativeway is to follow the linguistic definition of a phrase,e.g.
noun phrase (NP), verb phrase (VP), etc.
In thiscase, we need to use (at least) a chunker to prepro-cess the text and obtain the proper boundary of eachfragment and we used the OpenNLP chunker.We finalize our paraphrase collection by filter-ing out identical fragment pairs, subsumed fragmentpairs (one fragment is fully contained in the other),and fragment having only one word.
Apart from sen-tence pairs collected from the comparable corpora,we also did experiments on the existing MSR para-phrase corpus (Dolan and Brockett, 2005), which isa collection of manually annotated sentential para-phrases.The evaluation on both collections is done by theMTurk.
Each task contains 8 pairs of fragments tobe evaluated, plus one positive control using iden-tical fragment pairs, and one negative control usinga pair of random fragments.
All the fragments areshown with the corresponding sentences from wherethey are extracted5.
The question being asked is5We thought about evaluating pairs of isolated fragments,?How are the two highlighted phrases related?
?, andthe possible answers are, ?These phrases refer to thesame thing as each other?
(PARAPHRASE), ?Thesephrases are overlap but contain different informa-tion?
(RELATED), and ?The phrases are unrelated orinvalid?
(INVALID).
Table 2 shows the results (ex-cluding invalid sentence pairs) and Table 5 showssome examples.In general, the results on MSR is better than thoseon our corpus6.
Comparing the different settings,for our corpus, word alignment with n-gram frag-ment extraction works better; and for corpora withhigher comparability (e.g.
the MSR corpus), theconfiguration of using both LCS and word align-ments and the chunk-based fragment extraction out-performs the others.
In fact, PARAPHRASE and RE-LATED are not quite comparable7, since the bound-ary mismatch of the fragments may not be obviousto the Turkers.
Nevertheless, we would assume acleaner output from the chunk-based method, andboth approaches achieve similar levels of quality.Zhao et al (2008) extracted paraphrase frag-ment pairs from bilingual parallel corpora, andtheir log-liner model outperforms Bannard andCallison-Burch (2005)?s maximum likelihood esti-mation method with 67% to 60%.
Notice that, ourstarting corpora are (noisy) comparable corpora in-stead of parallel ones (for our corpus), and the ap-proach is almost unsupervised8, so that it can beeasily scaled up to other larger corpora, e.g.
thenews websites.
Furthermore, we compared our frag-ment pair collection with Callison-Burch (2008)?sapproach on the same MSR corpus, only about 21%of the extracted paraphrases appear on both sides,which shows the potential to combine different re-sources.4 Analysis of the CollectionsIn this section, we present some analysis on the frag-ment pair collection.
We show the basic statistics ofthe corpora and then some examples of the output.but later found out it was difficult to make the judgement.6A sample of the corpus can be downloaded here:http://www.coli.uni-saarland.de/?rwang/resources/paraphrases.7Thanks to the anonymous reviewer who pointed this out.8The MTurk annotations can be roughly viewed as a guidefor parameter tuning instead of training the system57As for comparison, we choose two other paraphrasecollections, one is acquired from parallel bilingualcorpora (Callison-Burch, 2008) and the other is us-ing the same fragment extraction algorithm on theMSR corpus.4.1 Statistics of the CorporaStage Collection Size %GIGAWORD (1995) 600,000 10%Documents Retrieved 150,000 2.5%Document Pairs Selected 10,000 0.25%Sentence Pairs Extracted 270,000 0.1%Fragment Pairs Extracted 90,000 0.01%Table 3: The size of our corpus.
We only used ca.
10%of the GIGAWORD corpus in the experiments and the sizeof the collection at each stage are shown in the table.Table 3 roughly shows the percentage of the ex-tracted data compared with the original GIGAWORDcorpus at each stage9.
In the experiments reportedhere, we only use a subset of the news articles in1995.
If we scale to the full GIGAWORD corpus (19Gigabytes, news from 1994 to 2006), we expect anorder of magnitude more fragment pairs to be col-lected.Apart from the size of the corpus, we are also in-terested in the composition of the corpus.
Table 4shows the proportions of some n-grams contained inthe corpus.
Here CCB denotes the paraphrase col-lection acquired from parallel bilingual corpora re-ported in (Callison-Burch, 2008), and MSR?
denotesthe collection using the same algorithm on the MSRcorpus.In Table 4, the four columns from the left areabout the fragments (one part of each fragment pair),and the six columns from the right are about para-phrases.
For example, 1 & 2 indicates the paraphrasecontains one single word on one side and a 2-gramon the other side.
Since we deliberately exclude sin-gle words, the n-gram distributions of OUR and MSRare ?flatter?
than the other two corpora, but still, 2-grams fragments occupy more than 40% in all cases.The n-gram distributions of the paraphrases are evenmore diverse for the OUR and MSR corpora.
The sum9All the numbers in the table are roughly estimated, due tothe variations of different settings.
This just gives us an impres-sion of the space for improvement.of the listed proportions are only around 45%, whilefor CCB and MSR?, the sums are about 95%.4.2 ExamplesTable 5 shows some examples from the best two set-tings.
From our corpus, both simple paraphrases(?Governor ... said?
and ?Gov.
...
announced?
)and more varied ones (?rose to fame as?
and ?thehighlight of his career?)
can be extracted.
It?s clearthat the smoothing and extraction algorithms do helpwith finding non-trivial paraphrases (shown in Fig-ure 3).
The extracted phrase ?campaign was?
showsthe disadvantage of n-gram-based phrase extractionmethod, since the boundary of the fragment could beimproper.
Using a chunker can effectively excludesuch problems, as shown in the lower part of the ta-ble, where all the extracted paraphrases are gram-matical phrases.
Even from a parallel paraphrasecorpus at the sentence level, the acquired fragmentpairs (w/o context) could be non-paraphrases.
Forinstance, the second pair from the MSR corpus showsthat one news agency gives more detailed informa-tion about the launching site than the other, and thelast example is also debatable, whether it?s ?under$200?
or ?around $200?
depending on the reliabilityof the information source.5 Summary and Future WorkIn this paper, we present our work on paraphrasefragment pair extraction from monolingual compa-rable corpora, inspired by Munteanu and Marcu(2006)?s bilingual method.
We evaluate our inter-mediate results at each of the stages using MTurk.Both the quality and the quantity of the collectedparaphrase fragment pairs are promising given theminimal supervision.
As for the ongoing work, weare currently expanding our extraction process to thewhole GIGAWORD corpus, and we plan to apply itto other comparable corpora as well.
For the fu-ture work, we consider incorporating more linguisticconstraints, e.g.
using a syntactic parser (Callison-Burch, 2008), to further improve the quality of thecollection.
More importantly, applying the collectedparaphrase fragment pairs to other NLP applications(e.g.
MT, RTE, etc.)
will give us a better view of theutility of this resource.58N-grams Phrases Para-phrases1 2 3 4 1 & 1 1 & 2 2 & 2 1 & 3 2 & 3 3 & 3OUR N/A 43.4% 30.5% 16.4% N/A N/A 20.0% N/A 16.7% 8.8%MSR N/A 41.7% 30.5% 16.0% N/A N/A 20.1% N/A 16.6% 9.4%CCB 10.7% 42.7% 32.0% 10.9% 34.7% 16.3% 24.0% 2.5% 9.4% 6.9%MSR?
8.1% 41.4% 37.2% 10.0% 29.0% 16.6% 26.8% 2.8% 10.7% 9.6%Table 4: The (partial) distribution of N-grams (N=1-4) in different paraphrase collections.From Our Corpus: using word aligner and n-gram-based phrase extraction... unveiled a detailed peace plan calling for the Bosnian Serbs to pull their heavy weapons back from Sarajevo.
ParaphraseIf the Bosnian Serbs withdraw their heavy weapons from Sarajevo?s outskirts, ...In San Juan, Puerto Rico, Governor Pedro Rosello said the the storm could hit the US territory by Friday, ... ParaphraseIn Puerto Rico, Gov.
Pedro Rossello announced that banks will be open only until 11 a.m. Friday and ...Kunstler rose to fame as the lead attorney for the ?Chicago Seven,?
... ParaphraseThe highlight of his career came when he defended the Chicago Seven ...... initiated the air attacks in response to Serb shelling of Sarajevo that killed 38 people Monday.
InvalidThe campaign was to respond to a shelling of Sarajevo Monday that killed 38 people.From MSR Corpus: using both LCS and word aligner and chunk-based phrase extractionO?Brien?s attorney, Jordan Green, declined to comment.
ParaphraseJordan Green, the prelate?s private lawyer, said he had no comment.Iraq?s nuclear program had been dismantled, and there ?was no convincing evidence of its reconstitution.?
ParaphraseIraq?s nuclear program had been dismantled and there was no convincing evidence it was being revived, ...... to blast off between next Wednesday and Friday from a launching site in the Gobi Desert.
Related... to blast off as early as tomorrow or as late as Friday from the Jiuquan launching site in the Gobi Desert.... Super Wireless Media Router, which will be available in the first quarter of 2004, at under $200.
RelatedThe router will be available in the first quarter of 2004 and will cost around $200, the company said.Table 5: Some examples of the extracted paraphrase fragment pairs.AcknowledgmentsThe first author would like to thank the EuroMatrix-Plus project (IST-231720) which is funded by theEuropean Commission under the Seventh Frame-work Programme.
The second author is supportedby the EuroMatrixPlusProject, by the DARPAGALE program under Contract No.
HR0011-06-2-0001, and by the NSF under grant IIS-0713448.The authors would like to thank Mirella Lapata andDelip Rao for the useful discussions as well as theanonymous Turkers who helped us to accomplishthe tasks.ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of ACL.R.
Barzilay and N. Elhadad.
2003.
Sentence alignmentfor monolingual comparable corpora.
In Proceedingsof EMNLP.Regina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: An unsupervised approach using multiple-sequence alignment.
In Proceedings of HLT-NAACL.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedingsof ACL.Regina Barzilay, Kathleen McKeown, and Michael El-hadad.
1999.
Information fusion in the context ofmulti-document summarization.
In Proceedings ofACL, College Park, MD.Anja Belz and Eric Kow.
2010.
Extracting parallel frag-ments from comparable corpora for data-to-text gen-eration.
In Proceedings of the 6th International Nat-ural Language Generation Conference, Stroudsburg,PA, USA.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of EMNLP.I.
Dagan, O. Glickman, and B. Magnini.
2005.
The pas-cal recognising textual entailment challenge.
In Pro-ceedings of the RTE Workshop.Georgiana Dinu and Rui Wang.
2009.
Inference rulesand their application to recognizing textual entailment.59In Proceedings of EACL, Athens, Greece.
Associationof Computational Linguistics.William B. Dolan and Chris Brockett.
2005.
Automat-ically constructing a corpus of sentential paraphrases.In Proceedings of the IWP2005.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.
Un-supervised construction of large paraphrase corpora:Exploiting massively parallel news sources.
In Pro-ceedings of COLING.Pascale Fung and Percy Cheung.
2004a.
Mining verynon-parallel corpora: Parallel sentence and lexicon ex-traction via bootstrapping and EM.
In Proceedings ofEMNLP.Pascale Fung and Percy Cheung.
2004b.
Multi-levelbootstrapping for extracting parallel sentences from aquasi-comparable corpus.
In Proceedings of COLING.P.
Fung and Y. Y.
Lo.
1998.
An IR approach for translat-ing new words from nonparallel, comparable texts.
InProceedings of ACL.Ali Ibrahim, Boris Katz, and Jimmy Lin.
2003.
Extract-ing structural paraphrases from aligned monolingualcorpora.
In Proceedings of ACL.Philipp Koehn and Kevin Knight.
2000.
Estimating wordtranslation probabilities from unrelated monolingualcorpora using the EM algorithm.
In Proceedings ofthe National Conference on Artificial Intelligence.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of NAACL.Dekang Lin and Patrick Pantel.
2001.
Dirt - discovery ofinference rules from text.
In Proceedings of the ACMSIGKDD.Yuval Marton, Chris Callison-Burch, and Philip Resnik.2009.
Improved statistical machine translation usingmonolingually-derived paraphrases.
In Proceedings ofEMNLP, Singapore.Dragos Munteanu and Daniel Marcu.
2005.
Improvingmachine translation performance by exploiting compa-rable corpora.
Computational Linguistics, 31(4), De-cember.Dragos Stefan Munteanu and Daniel Marcu.
2006.
Ex-tracting parallel sub-sentential fragments from non-parallel corpora.
In Proceedings of ACL.Chris Quirk, Chris Brockett, and William B. Dolan.2004.
Monolingual machine translation for paraphrasegeneration.
In Proceedings of the 2004 Conference onProceedings of the Conference on Empirical Methodsin Natural Language Processing, Barcelona, Spain.Chris Quirk, Raghavendra Udupa, and Arul Menezes.2007.
Generative models of noisy translations withapplications to parallel fragment extraction.
In Pro-ceedings of MT Summit XI, Copenhagen, Denmark.G.
Salton and M. J. McGill.
1983.
Introduction tomodern information retrieval.
ISBN 0-07-054484-0.McGraw-Hill.Y.
Shinyama and S. Sekine.
2003.
Paraphrase acquisitionfor information extraction.
In Proceedings of Interna-tional Workshop on Paraphrasing.Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.2002.
Automatic paraphrase acquisition from news ar-ticles yusuke shinyama satoshi sekine automatic para-phrase acquisition from news articles.
In Proceed-ings of Human Language Technology Conference, SanDiego, USA.Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from compara-ble corpora using document level alignment.
In Hu-man Language Technologies: The 2010 Annual Con-ference of the North American Chapter of the Associ-ation for Computational Linguistics, Stroudsburg, PA,USA.
Association of Computational Linguistics.Rion Snow, Brendan O?Connor, Daniel Jurafsky, and An-drew Y. Ng.
2008.
Cheap and fast - but is it good?Evaluating non- expert annotations for natural lan-guage tasks.
In Proceedings of EMNLP.Stephan Vogel.
2003.
Using noisy bilingual data for sta-tistical machine translation.
In Proceedings of EACL.Dekai Wu and Pascale Fung.
2005.
Inversion transduc-tion grammar constraints for mining parallel sentencesfrom quasi-comparable corpora.
In Proceedings ofIJCNLP, Jeju Island, Korea.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008.
Pivot approach for extracting paraphrase pat-terns from bilingual corpora.
In Proceedings of ACL.60
