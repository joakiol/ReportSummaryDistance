Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55?63,Beijing, August 2010Application of the Tightness Continuum Measureto Chinese Information RetrievalYing Xu?, Randy Goebel?, Christoph Ringlstetter?
and Grzegorz Kondrak?
?Department of Computing Science ?Center for Language andUniversity of Alberta Information Processing (CIS)Ludwig Maximilians University{yx2,goebel,kondrak}@cs.ualberta.ca kristof@cis.uni-muenchen.deAbstractMost word segmentation methods em-ployed in Chinese Information Retrievalsystems are based on a static dictionaryor a model trained against a manuallysegmented corpus.
These general seg-mentation approaches may not be opti-mal because they disregard informationwithin semantic units.
We propose a novelmethod for improving word-based Chi-nese IR, which performs segmentation ac-cording to the tightness of phrases.
Inorder to evaluate the effectiveness of ourmethod, we employ a new test collectionof 203 queries, which include a broad dis-tribution of phrases with different tight-ness values.
The results of our experi-ments indicate that our method improvesIR performance as compared with a gen-eral word segmentation approach.
The ex-periments also demonstrate the need forthe development of better evaluation cor-pora.1 IntroductionWhat distinguishes Chinese Information Retrievalfrom information retrieval (IR) in other languagesis the challenge of segmenting the queries and thedocuments, created by the lack of word delimiters.In general, there are two categories of segmenters:character-based methods and word-based meth-ods.
Despite the superior performance of bigramsegmenters (Nie et al, 2000; Huang et al, 2000;Foo and Li, 2004), word-based approaches con-tinue to be investigated because of their applica-tion in sophisticated IR tasks such as cross lan-guage IR, and within techniques such as query ex-pansion (Nie et al, 2000; Peng et al, 2002a).Most word-based segmenters in Chinese IR areeither rule-based models, which rely on a lexi-con, or statistical-based models, which are trainedon manually segmented corpora (Zhang et al,2003).
However, the relationship between the ac-curacy of Chinese word segmentation and the per-formance of Chinese IR is non-monotonic.
Penget al (2002b) reported that segmentation meth-ods achieving segmentation accuracy higher than90% according to a manual segmentation standardyield no improvement in IR performance.
Theyfurther argued that IR often benefits from splittingcompound words that are annotated as single unitsby manual segmentation.The essence of the problem is that there is noclear definition of word in Chinese.
Experimentshave shown only about 75% agreement among na-tive speakers regarding the correct word segmen-tation (Sproat et al, 1996).
While units such as??
?
(peanut) and ???|?
(match maker)should clearly be considered as a single term inChinese IR, compounds such as ??????
(ma-chine learning) are more controversial.1Xu et al (2009) proposed a ?continuum hy-pothesis?
that rejects a clean binary classifica-tion of Chinese semantic units as either compo-sitional or non-compositional.
Instead, they intro-duced the notion of a tightness measure, whichquantifies the degree of compositionality.
Onthis tightness continuum, at one extreme are non-1This issue is also present to a certain degree in languagesthat do use explicit delimiters, including English (Halpern,2000; McCarthy et al, 2003; Guenthner and Blanco, 2004).55compositional semantic units, such as ???|?
(match maker), and at the other end are se-quences of consecutive words with no depen-dency relationship, such as ??0???
(Shang-hai where).
In the middle of the spectrum arecompositional compounds such as ??????
(machine learning) and phrases such as ?thB??
(legitimate income).In this paper, we propose a method to ap-ply the concept of semantic tightness to ChineseIR, which refines the output of a general Chi-nese word segmenter using tightness information.In the first phase, we re-combine multiple unitsthat are considered semantically tight into singleterms.
In the second phase, we break single unitsthat are not sufficiently tight.
The experiments in-volving two different IR systems demonstrate thatthe newmethod improves IR performance as com-pared to the general segmenter.Most Chinese IR systems are evaluated on thedata from the TREC 5 and TREC 6 competi-tions (Huang et al, 2000; Huang et al, 2003;Nie et al, 2000; Peng et al, 2002a; Peng et al,2002b; Shi and Nie, 2009).
That data containsonly 54 queries, which are linked to relevancy-judged documents.
During our experiments, wefound the TREC query data is ill-suited for ana-lyzing the effects of compound segmentation onChinese IR.
For this reason, we created an addi-tional set of queries based on the TREC corpus,which includes a wide variety of semantic com-pounds.This paper is organized as follows.
After sum-marizing related work on Chinese IR and wordsegmentation studies, we introduce the measureof semantic tightness.
Section 4 describes the in-tegration of the semantic tightness measure intoan IR system.
Section 5 discusses the availabledata for Chinese IR evaluation, as well as an ap-proach to acquire new data.
Section 6 presents theresults of our method on word segmentation andIR.
A short conclusion wraps up and gives direc-tions for future work.2 Related WorkThe impact of different Chinese word segmen-tation methods on IR has received extensive at-tention in the literature (Nie et al, 2000; Penget al, 2002a; Peng et al, 2002b; Huang et al,2000; Huang et al, 2003; Liu et al, 2008; Shiand Nie, 2009).
For example, Foo and Li (2004)tested the effects of manual segmentation and var-ious character-based segmentations.
In contrastwith most related work that only reports the over-all performance, they provide an in-depth analysisof query results.
They note that a small test col-lection diminishes the significance of the results.In a series of papers on Chinese IR, Pengand Huang compared various segmentation meth-ods in IR, and proposed a new segmentationmethod (Peng et al, 2002a; Peng et al, 2002b;Huang et al, 2000; Huang et al, 2003).
Theirexperiments suggest that the relationship betweensegmentation accuracy and retrieval performanceis non-monotonic, ranging from 44%-95%.
Theyhypothesize that weak word segmenters are ableto improve the accuracy of Chinese IR by break-ing compound words into smaller constituents.Shi and Nie (2009) proposed a probability-based IR score function that combines a unigramscore with a word score according to ?phrase in-separability.?
Candidates for words in the queryare selected by a standard segmentation program.Their results show a small improvement in com-parison with a static combination of unigram andword methods.Liu et al (2008) is the research most similarto our proposed method.
They point out that cur-rent segmentation methods which treat segmenta-tion as a classification problem are not suitablefor Chinese IR.
They propose a ranking supportvector machine (SVM) model to predict the inter-nal association strength (IAS) between characters,which is similar to our concept of tightness.
How-ever, they do not analyze their segmentation ac-curacy with respect to a standard corpus, such asChinese Treebank.
Their method does not reliablysegment function words, mistakenly identifying?{|?
(?s people) as tight, for example.
Unliketheir approach, our segmentation method tacklesthe problem by combining the tightness measurewith a general segmentation method.Chinese word segmentation is closely relatedto multiword expression extraction.
McCarthy etal.
(2003) investigate various statistical measuresof compositionality of candidate multiword verbs.56Silva et al (1999) propose a new compositional-ity measure based on statistical information.
Themain difference with Xu et al?s measure is thatthe latter is focused on word sense disambigua-tion.
In terms of multiword expressions in IR,Vechtomova (2001) propose several approaches,such as query expansion, to incorporating Englishmultiword expressions in IR.
Braschler and Rip-plinger (2004) analyze the effect of stemming anddecompounding on German text retrieval.
How-ever, Chinese compound segmentation in IR is athorny issue and needs more investigation for thereasons mentioned earlier.3 Semantic Tightness ContinuumWe adopt the method developed by (Xu et al,2009) for Chinese semantic unit tightness mea-sure, which was shown to outperform the point-wise mutual information method.
For the sakeof completeness we briefly describe the basic ap-proach here.
The input of the measure is the prob-ability distribution of a unit?s segmentation pat-terns, i.e., potential segmentation candidates.
Theoutput is a tightness value; the greater the value,the tighter the unit.
In this paper, we focus on 4-gram sequences because 4-character compoundsare the most prominent in Chinese.
There areeight possible segmentations of any 4-charactersequence: ?ABCD,?
?A|BCD,?
?A|B|CD,?
etc.For a sequence of n characters, there are 2n?1 po-tential segmentations.
Equation 1 below definesthe tightness measure.ratio =?????
?P t(s)max(?P t(s1|s2))+ 1Nif ?P t(s) > ?undef otherwise(1)In Equation 1, ?P t(s) stands for frequencies ofsegmentation patterns of a potential semantic units; Pt(s1|s2) is a pattern which segments the units into two parts: s1 and s2; ?
is a threshold toexclude rare patterns; and N is a smoothing factorwhich is set as the number of documents.
Notethat when the first part of the denominator is zero,the ratio of the unit will be very high.
Intuitively,the lack of certain separating patterns in the datais evidence for the tightness of the units.4 Application to Chinese IRWe propose a novel approach to segmentationfor Chinese IR which is based on the tight-ness measure.
Our segmenter revises the out-put of a general segmenter according to the tight-ness of units.
The intuition behind our methodis that segmentation based on tightness of unitswill lead to better IR performance.
For exam-ple, keeping ??CF?
(Pinatubo) as a unitshould lead to better results than segmenting itinto ??
(skin)|(include)|C(picture)|F(large)?.On the other hand, segmenting the compositionalphrase ?)?)?
(Kuwait country) into ?)?(Kuwait)|)(country)?
can improve recall.
Werevise an initial segmentation in two steps: first,we combine components that should not havebeen separated, such as ??CF?
(Pinatubo);second, we split units which are compositional,such as ?)?)?
(Kuwait country).In order to combine components, we firstextract 4-gram non-compositional compoundswhose tightness values are greater than a thresh-old ?1 in a reference corpus, and then revise ageneral segmenter by combining two separatedwords if their combination is in the list.
This ap-proach is similar to the popular longest match firstmethod (LMF), but with segmentation chunks in-stead of characters, and with the compound listserving as the lexicon.
For example, considera sequence ?ABCDEFGHIGK,?
which a generalsegmenter annotates as ?ABC|D|E|F|G|HI|GK.
?If our compound list constructed according to thetightness measure contains {?DEFG?
}, the re-vised segmentation will be ?ABC|DEFG|HI|GK.
?Units of length less than 4 are segmented by usingthe LMF rule against a dictionary.In order to split a compositional unit, we set theadditional thresholds ?2, ?3, and ?4, and employthe segmentation rules in Equation 2.
The intu-ition comes from the pattern lattice of a unit (Fig-ure 1).
For the patterns on the same level, the mostfrequent pattern suggests the most reasonable seg-mentation.
For the patterns on different levels, thefrequency of each level indicates the tightness ofthe unit.57Figure 1.
The Lattice of the 8 Patterns.ifv1 = ?Pt(ABCD)max(?Pt(A|BCD),?Pt(AB|CD),?Pt(ABC|D))+ 1N> ?2then ?ABCD?
is one unit;else ifv2 =max(?Pt(A|BCD),?Pt(AB|CD),?Pt(ABC|D))+ 1Nmax(?Pt(A|B|CD),?Pt(A|BC|D),?Pt(AB|C|D))+ 1N> ?3then ?ABCD?
is segmented into two parts;else ifv3 =max(?Pt(A|B|CD),?Pt(A|BC|D),?Pt(AB|C|D))+ 1N?Pt(A|B|C|D)+ 1N> ?4then ?ABCD?
is segmented into three parts;else?ABCD?
is segmented into four parts;(2)We apply the rules in Equation 2 to the se-quence of 4-grams, with simple voting for select-ing the segmentation pattern.
For example, withinthe sequence ?ABCDEF,?
three 4-gram patternsare considered: ?ABCD,?
?BCDE,?
and ?CDEF.
?If only one of the 4-grams contains a segmentationdelimiter, the insertion of the delimiter dependsonly upon that 4-gram.
If two 4-grams contain thesame delimiter, the insertion of the delimiter de-pends upon the two 4-grams.
If the two 4-gramsdisagree on the segmentation, a confidence valueis calculated as in Equation 3,confidence = vi ?
?i+1, (3)where i ?
[1, 2, 3].
If three 4-grams contain thesame delimiter, voting is employed to decide thesegmentation.
Returning to our example, supposethat the first 4-gram is segmented as ?A|B|C|D,?the second as ?BC|DE,?
and the third as ?C|DE|F.
?Then the segmentation delimiter between ?A?
and?B?
is inserted, but the delimiter between ?B?
and?C?
depends on the confidence values of the firsttwo segmentation patterns.
Finally, the delimiterbetween ?C?
and ?D?
depends on the result of vot-ing among the three 4-gram segmentations.The two steps of combining and splitting caneither be applied in succession or separately.
Inthe former case, ?1 must be greater or equal to ?2.In the remainder of this paper, we refer to the firststep as ?Tight Combine,?
and to the second stepapplied after the first step as ?Tight Split.?
Notethat the second method can be used to segmentsentences directly instead of revising the output ofa general segmenter.
This method, which we referto as ?Online Tight,?
has the same shortcomingas the method of Liu et al (2008), namely it fre-quently fails to segment function words.
For ex-ample, it erroneously identifies ?{|?
(?s people)as tight.
Therefore, we do not attempt to embed itinto the IR systems discussed in Section 6.5 Test CollectionWe analyzed the currently available Chinese testcollection of TREC, and found it unsuitable forevaluating different strategies of compound seg-mentation.
One problem with the TREC data isthat the Chinese queries (topic titles) have toomany keywords.
According to the output of ICT-CLAS, a general segmenter, the average length ofChinese queries is 12.2 words; in contrast, the av-erage length of English ad-hoc queries in TREC-5 and 6 (English topics 251-350) is 4.7.
Even ifwe use English translation of the Chinese queriesinstead, the average length is still more than 7words.
The problem with long queries is thatthey introduce complicating effects that interactin ways difficult to understand.
An example isthe co-occurrence between different keywords inthe base corpus.
Sometimes a completely correctsegmentation causes a decrease in IR performancebecause the score function assigns a higher scoreto less important terms in a topic.
For example,for query 47 (Trec-6 dataset), ?9F5??CF????????S???
(Philippines,Mount Pinatubo, volcanic ash, magma, eruption),preserving the unit Pinatubo makes the averageprecision drop from 0.76 to 0.62 as compared tothe segmentation ??||C|F?.
The score of the58unit is lower than that the sum of its components,which results in a relatively low ranking for somerelevant documents.
Another problem with theTREC Chinese test collection is the small numberof queries (54).
The number of of queries contain-ing non-compositional words is smaller still.
Sim-ilarly, the other available corpus, NTCIR, com-prises only 50 queries.
In order to be confident ofour results, we would like to have a more substan-tial number of queries containing units of varyingtightness.Because of the shortcomings of available datasets, we created our own test collection.
There arethree components that define an IR test collection:a query set, a corpus from which relevant docu-ments are retrieved, and relevance judgements foreach query.
Our criteria for gathering these com-ponents are as follows.First, the set of queries should contain bothtight queries and loose queries.
For example,there should be tight queries such as ???|?
(match maker), loose queries such as ??00?
(Shanghai customs), and queries with tightnessvalues in between, such as ??????
(machinelearning).
Furthermore, the queries should be re-alistic, rather than constructed by introspection.In order to meet these requirements we randomlychose 4-gram noun phrases (tagged by ICTCLAS)from the TREC corpus.
51 queries are from a realdata set, the Sogou query logs2.
The remaining152 queries, which are selected manually basedon the initial 51 queries, represent queries that IRsystem users are likely to enter.
For example,queries of locations and organizations are morelikely than queries such as ?how are you.?
Fi-nally, the queries should not be too general (i.e.,resulting in too many relevant documents found),nor too specific (no relevant documents).
There-fore, we selected the 4-grams which had the cor-responding document frequency in the TREC cor-pus between 30 and 300.The second set of criteria concerns the rele-vance judgements of documents.
As our retrievalcorpus, we adopted the TREC Mandarin corpus,which contains 24,959 documents.
Because of re-source limitation, we used the Minimum Test Col-2Sogou query logs 2007 can be downloaded athttp://www.sogou.com/labs/dl/q.html.lection (MTC) method (Carterette et al, 2006).The method pools documents in such a way thatthe documents which are best for discriminatingbetween different IR systems are judged first.
Weapplied this method on a document set that con-tains all of the top 100 results of 8 IR systems(two score functions, tf*idf and BM25, 4 index-ing methods, unigram, bigram, ICTCLAS seg-mentation, and our Tight Combine segmentation).The systems were implemented with the Luceneframework (http://lucene.apache.org/).The last criterion determines which documentis relevant to a query.
Annotators?
opinions varyabout whether a document is relevant to a topic.Is having the query in a document enough to bethe criterion of relevance?
For the query ?Bei-jing airport,?
should the document that containsthe sentence ?Chairman Mao arrived at the Bei-jing airport yesterday,?
be classified as relevant?Since our goal is to analyze the relationship be-tween Chinese word segmentation, and IR, weuse weak relevant judgements.
It is more relatedto score functions to distinguish weak relevancefrom strong relevance, that is, whether the queryis the topic of the document.
This means the abovedocument is judged as relevant for the query ?Bei-jing airport.
?In summary, our own test collection has about200 queries, and at least 100 judged documentsper query with the TREC corpus as our base cor-pus3.6 ExperimentsWe conducted a series of experiments in word-based Chinese information retrieval, with the aimof establishing which segmenter is best for CIR,while pursuing the best segmentation performancein terms of segmented corpus is not the main crux.In this section, we first present the accuracy of dif-ferent segmentation methods, and then discuss theresults of IR systems.6.1 Chinese Word SegmentationICTCLAS is a Chinese segmentation tool built bythe Institute of Computing Technology, ChineseAcademy of Sciences.
Its segmentation model is a3The query set and relevance judgements are available athttp://www.cs.ualberta.ca/?yx2/research.html59class-based hidden Markov model (HMM) model(Zhang et al, 2003).
The segmenter is trainedfrom manually segmented corpus, which makesit ignore both the tightness of units and unknownwords such as ??CF?
(Pinatubo), which aredifficult to identify.In this experiment, we segmented the ChineseTreebank using ICTCLAS and our three methodsthat employ the tightness measure.
The evalua-tion is based on the manual segmentation of thecorpus.
We evaluated the methods on the entireTreebank corpus, employing 10-cross validationfor result significance verification.In order to measure the tightness of Chinesesemantic units, pattern distributions of every 4-gram were extracted from the Chinese Gigawordcorpus.
Tight Combine is the ICTCLAS refinedsegmentation that employs the non-compositionalcompound list from the Chinese Gigaword cor-pus.
The threshold for non-compositional com-pound ?1 is set to 11.
Tight Split is the refinedsegmentation of Tight Combine using Equation 2.Online Tight is the segmentation using Equation2 directly.
For Tight Split and Online Tight, weemployed a lexicon which contains 41,245 words,and set the thresholds ?2, ?3, and ?4 to 11, 0.01,and 0.01, respectively.
The parameters ?1 and ?2are set according to the observation that the per-centage of non-compositional units is high whenthe tightness is greater than 11 for all the 4-gramsin the Chinese Gigaword corpus.
The other twoparameters were established after experimentingwith several parameter pairs, such as (1,1), (0.1,0.1), and (0.1, 0.01).
We chose the one with thebest segmentation accuracy according to the stan-dard corpus.Table 1 shows the mean accuracy result over the10 folders.
The accuracy is the ratio of the numberof correctly segmented intervals to the number ofall intervals.
The result shows that our methodimproves over the ICTCLAS segmentation result,but the improvement is not statistically significant(measured by t-test).
The only significant result isthat Online tight is worse than other methods.Surprisingly, there is a large gap betweenTight Split and Online Tight, although they em-ploy the same parameters.
It turns out the ma-jor difference lies in the segmentation of functionICTCLAS 88.8%Tight Combine 89.0%Tight Split 89.1%Online Tight 80.5%Table 1.
Segmentation accuracy of different seg-menters.words.
Since it is based on ICTCLAS, Tight Splitdoes a good job in segmenting function wordssuch as verbal particles which represent past tense???
and the nominalizer ?{.?
Online Tighttends to combine these words with the consecu-tive one.
For example, considering ?????
(cu-mulated), the Treebank and Tight Split segment itinto ???|??
(cumulate + particle); while On-line Tight leaves it unsegmented.6.2 IR Experiment SetupWe conducted our information retrieval experi-ments using the Lucene package (Hatcher andGospodnetic, 2004).
The documents and querieswere segmented by our three approaches beforeindexing and searching process.
In order to ana-lyze the performance of our segmentation meth-ods with different retrieval systems, we employedtwo score functions: the BM25 function (Peng etal., 2002b) 4; and BM25Beta (Function 4), whichprefers documents with more query terms.Score(Q,D) ={T(1+?
)?N?Ti=0 score(ti, D) if T < N?Ni=0 score(ti, D) if T = N(4)In the above equation, score(ti, D) is the scoreof the term ti in the document D. Althoughwe used BM25 as our base score function forscore(ti, D), it can be replaced by other scorefunctions, such as tf*idf, or a probability languagemodel.
?
is a parameter to control a penalty com-ponent for those documents that do not containall the query terms; T is the number of distinc-tive query terms in the document; and N is thenumber of query terms.
The function penalizesdocuments that do not contain all the query terms,4An implementation of BM25 into Lucene can be down-loaded at http://arxiv.org/abs/0911.504660BM25 BM25BetaICTCLAS 62.78% 70.79%Tight Combine 65.92% 71.19%Tight Split 63.40% 70.95%Table 2.
MAP of different IR systems with differ-ent segmenters.which is an indirect way of incorporating proxim-ity distance 5.6.3 IR Experiment ResultsTable 2 shows the comparison of our two seg-menters to ICTCLAS on the IR task.
The per-formance of IR systems was measured by meanaverage precision (MAP) of the query set.
The re-sults show that Tight Combine is better than theICTCLAS segmentation, especially when usingBM25.
The relationship between Tight Split andICTCLAS is not clear.In order to give a more in-depth analysis ofthe word segmentation methods with respect tothe targeted phenomenon of semantic units, weclassified the 200 queries into three categories ac-cording to their tightness as measured by func-tion 1.
The three classes are queries with tight-ness in ranges [+?, 10), [10, 1), and [1, 0),which contain 54, 41, and 108 queries respec-tively.
Queries in the range [+?, 10) are tightqueries, such as ?v???
(Virginia).
Queriesin the range [1, 0) are loose queries, such as ?????
(advertising company).
Other queries arethose compounds which have ambiguous segmen-tations, such as ???'a?
(chain reaction).
Be-cause the classification was based on the tightnessmeasure, there are some errors.
For example, ?|?L??
(Renmin University) was classified as aloose query although it should at least be in themiddle range.
The three classes cover the wholetightness continuum, i.e.
the whole possible queryset.
Table 3 shows the MAP with respect to theseclasses for the word segmentation methods.
Forqueries with tightness less than 10, the results ofICTCLAS and Tight Combine are approximatelyequal, which is not surprising since with few ex-5We also experimented with replacing ?
with the tight-ness value, but the results were not substantially different.
[+?, 10) [10, 1) [1, 0)BM25ICTCLAS 74.48% 60.28% 57.87%Tight Combine 86.44% 60.55% 57.70%Tight Split 88.86% 56.78% 53.17%BM25 BetaICTCLAS 84.60% 72.56% 63.28%Tight Combine 86.44% 72.70% 63.07%Tight Split 88.86% 74.80% 60.39%Table 3.
Results on three query categories.ceptions they have the same segmentation for bothqueries and documents.For the interesting case of segmentation oftight units, i.e.
queries in the range [+?, 10),the results show clear superiority for IR systemsbased on our segmentation methods.
When us-ing BM25, MAP is 86.44% for Tight Combine,as compared to 74.48% for standard word seg-mentation .
The advantage of Tight Combine overICTCLAS is that it combines units such as ???@??
(plate glass) as the term is tight, whileICTCLAS segments that unit into ????
(plate)and ?@??
(glass).
This is evidence that wordsegmentation models based on the tight measureare better than models trained on a human anno-tated corpus which ignored tightness information.Interestingly, Tight Split is superior in the range[+?, 10), although the segmentation for thesequeries is the same as with Tight Combine.
Whenwe analyzed the instances, we found it improvedIR results of proper nouns.
One possible expla-nation is that splitting of proper nouns such as?v????
(Virginia state) in documents im-proved the recall even when the segmentation ofthe queries remained the same.
For example, forquery ?v???
(Virginia), documents whichcontain ?v????
(Virginia state) should beretrieved.
However, since ICTCLAS treats ?v????
as a word, those documents are missed.Instead, Tight Split segments the sequence into?v??|?,?
which results in the retrieval ofthose documents.In the range of [10, 1), the result is mixed.For some instances, Tight Split is worse thanTight Combine and ICTCLAS, as it segmentsqueries such as ???'a?
(chain reaction).However, in other instances, it is better than61Tight Combine and ICTCLAS since it segmentsqueries such as ?)6??
(international chess).The result suggests that the setting of the thresh-old for non-compositional terms should be below10.In the range of [1, 0), the result is also mixed.One reason for the low performance of Tight Splitis that the tightness measure is not precise forthose queries, which affects the segmentation.
Forexample, splitting the queries ??|???
(labormovement) and ???L??
(Zhongshan Univer-sity) decreases the IR performance dramatically.In future work, we would like to investigate thisproblem by segmenting queries manually accord-ing to their tightness.
If the manual segmentationis superior, it would provided evidence for the hy-pothesis that segmentation based on tightness issuperior.The difference between BM25 and BM25 Betain the range [10, 1) suggests that for ChineseIR, it is better to segment text in a more fine-grained way, and combine terms through a scorefunction.
For example, for queries such as ???'a?
(chain reaction), for which splitting theunit is worse, BM25 Beta decreases the negativeeffect of splitting dramatically.
For the query?|F??
(life insurance), when using BM25,Tight Split is worse than ICTCLAS (average pre-cision 0.59 vs. 0.66); but when using BM25 Beta,it is better than ICTCLAS (average precision 0.72vs.
0.66).7 ConclusionFor Chinese IR, we have developed a new methodto segment documents based on the tightness ofChinese semantic units.
The segmentation per-formance of our method is close to ICTCLAS,but the mean average precision of IR systemsusing our method is higher than for ICTCLASwhen using BM25.
In addition, we proposed afine-grained segmenter plus a score function thatprefers short proximity distance for CIR.In the future, we plan to employ ranking SVMmodels with the tightness measure as one of thefeatures for segmentation (Liu et al, 2008).
Wehope that it can predict the tightness more pre-cisely, by combining with other features.
In termsof our test collection, the 203 query set clearlyhelps the in-depth analysis for the performance ofdifferent IR systems on different queries.
We alsoplan to gather more queries and more judged doc-uments in order to further analyze the influenceof the proper treatment of semantic units in Chi-nese information retrieval.
A large query set couldalso make it possible to employ machine learningmodels for IR (Song et al, 2009).ReferencesBraschler, Martin, and Ba?rbel Ripplinger.
2004.
Howeffective is stemming and compounding for Germantext retrieval?
Information Retrieval, 7(3/4), 291-316.Carterette, Ben, James Allan, and Ramesh Sitaraman.2006.
Minimal Test Collections for Retrieval Evalu-ation.
Proceedings of the 29th Annual InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, 268-275.Chang, Pi-Chuan, Michel Galley, and Christopher D.Manning.
2008.
Optimizing Chinese Word Seg-mentation for Machine Translation Performance.Proceedings of the Third Workshop on MachineTranslation, 224-232.Foo, Schubert and Hui Li.
2004.
Chinese word seg-mentation and its effect on information retrieval.
In-formation Processing and Management: an Inter-national Journal, 40(1), 161-190.Guenthner, Frantz and Xavier Blanco.
2004.
Multi-lexemic expressions: an overview.
Linguisticae In-vestigationes Supplementa, 239-252.Halpern, Jack.
2000.
Is English Segmentation Trivial?Technical report, CJK Dictionary Institute.Hatcher, Erik and Otis Gospodnetic?
2004.
Lucene inAction.
Manning Publications Co.Huang, Xiangji, Stephen Robertson, Nick Cercone,and Aijun An.
2003.
Probability-Based ChineseText Processing and Retrieval.
Computational In-telligence, 16(4), 552-569.Huang, Xiangji, Fuchun Peng, Dale Schuurmans, NickCercone, and Stephen E. Robertson.
2003.
Apply-ing Machine Learning for Text Segmentation in In-formation Retrieval.
Information Retrieval, 6 (3-4),pp.
333-362, 2003.Jiang, Wenbin, Liang Huang, Qun Liu, and YajuanLv.
2008.
A Cascaded Linear Model for Joint Chi-nese Word Segmentation and Part-of-Speech Tag-ging.
Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics.62Liu, Yixuan, Bin Wang, Fan Ding, and Sheng Xu.2008.
Information Retrieval Oriented Word Seg-mentation based on Character Associative StrengthRanking.
Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Process-ing, 1061-1069.McCarthy, Diana, Bill Keller, and John Carroll.
2003.Detecting a Continuum of Compositionality inPhrasal Verbs.
Proceedings Of the ACL-SIGLEDX(a Special Interest Group on the Lexicon Workshop)on Multiword Expressions, 73-80.Nie, Jian-Yun, Jiangfeng Gao, Jian Zhang, and MingZhou.
2000.
On the use of words and N-gramsfor Chinese information retrieval.
Proceedings ofthe Fifth International Workshop on Information Re-trieval with Asian Languages, 141-148.Packard, Jerome L. 2000.
Morphology of Chinese:A Linguistic and Cognitive Approach.
CambridgeUniversity Press.Peng, Fuchun, Xiangji Huang, Dale Schuurmans, NickCercone, and Stephen E. Robertson.
2002.
UsingSelf-supervised Word Segmentation in Chinese In-formation Retrieval.
Proceedings of the 25th An-nual International ACM SIGIR Conference on Re-search and Development in Information Retrieval,349-350.Peng, Fuchun, Xiangji Huang, Dale Schuurmans, andNick Cercone.
2002.
Investigating the Relationshipbetween Word Segmentation Performance and Re-trieval Performance in Chinese IR.
Retrieval Per-formance in Chinese IR, Coling2002, 1-7.Shi, Lixin and Jian-Yun Nie.
2009.
Integrating phraseinseparability in phrase-based model.
Proceedingsof the 32th Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, 708-709.Silva, Joaquim, Gae?l Dias, Sylvie Guillore?, and Jose?Gabriel Pereira Lopes.
1999.
Using LocalMaxs Al-gorithm for the Extraction of Contiguous and Non-contiguous Multiword Lexical Units.
In Proceed-ings of 9th Portuguese Conference in Artificial In-telligence (EPIA 1999), 849.Sproat, Richard, Chilin Shih, William Gale and NancyChang.
1996.
A Stochastic Finite-State Word-Segmentation Algorithm for Chinese.
Computa-tional Linguistics, 22(3), 377-404, 1996.Song, Young-In, Jung-Tae Lee, and Hae-Chang Rim.2009.
Word or Phrase?
Learning Which Unit toStress for Information Retrieval.
Proceedings of the47th Annual Meeting of the Association for Compu-tational Linguistics and the 4th International JointConference on Natural Language Processing of theAsian Federation of Natural Language Processing,1048-1056.Tao, Tao and ChengXiang Zhai.
2007.
An explorationof proximity measures in information retrieval.
Pro-ceedings of the 30th annual international ACM SI-GIR conference on Research and development in in-formation retrieval, 295-302.Vechtomova, Olga.
2001.
Approaches to using wordcollocation in information retrieval.
Ph.D. Thesis(City University, 2001).Xu, Ying, Christoph Ringlstetter, and Randy Goebel.2009.
A Continuum-based Approach for TightnessAnalysis of Chinese Semantic Units.
Proc.
of the23rd Pacific Asia Conference on Language, Infor-mation and Computation, 569-578.Zhang, Hua-Ping, Hong-Kui Yu, De-Yi Xiong, andQun Liu.
2003.
HHMM-based Chinese lexical an-alyzer ICTCLAS.
Proceedings of the 2nd SIGHANWorkshop on Chinese Language Processing, 184-187.63
