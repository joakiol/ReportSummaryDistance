Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17?26,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsWhat Is Word Meaning, Really?
(And How Can Distributional Models Help Us Describe It?
)Katrin ErkDepartment of LinguisticsUniversity of Texas at Austinkatrin.erk@mail.utexas.eduAbstractIn this paper, we argue in favor of re-considering models for word meaning, us-ing as a basis results from cognitive sci-ence on human concept representation.More specifically, we argue for a moreflexible representation of word meaningthan the assignment of a single best-fittingdictionary sense to each occurrence: Ei-ther use dictionary senses, but view themas having fuzzy boundaries, and assumethat an occurrence can activate multiplesenses to different degrees.
Or move awayfrom dictionary senses completely, andonly model similarities between individ-ual word usages.
We argue that distri-butional models provide a flexible frame-work for experimenting with alternativemodels of word meanings, and discuss ex-ample models.1 IntroductionWord sense disambiguation (WSD) is one ofthe oldest problems in computational linguis-tics (Weaver, 1949) and still remains challeng-ing today.
State-of-the-art performance on WSDfor WordNet senses is at only around 70-80%accuracy (Edmonds and Cotton, 2001; Mihalceaet al, 2004).
The use of coarse-grained sensegroups (Palmer et al, 2007) has led to consider-able advances in WSD performance, with accura-cies of around 90% (Pradhan et al, 2007).
Butthis figure averages over lemmas, and the problemremains that while WSDworks well for some lem-mas, others continue to be tough.In WSD, polysemy is typically modeledthrough a list of dictionary senses thought to bemutually disjoint, such that each occurrence ofa word is characterized through one best-fittingdictionary sense.
Accordingly, WSD is typicallyframed as a classification task.
Interestingly, thetask of assigning a single best word sense is veryhard for human annotators, not just machines (Kil-garriff and Rosenzweig, 2000).In this paper we advocate the exploration ofalternative computational models of word mean-ing.
After all, one possible reason for the con-tinuing difficulty of (manual as well as automatic)word sense assignment is that the prevailing modelmight be suboptimal.
We explore three main hy-potheses.
The first builds on research on the hu-man concept representation that has shown thatconcepts in the human mind do not work likesets with clear-cut boundaries; they show gradedmembership, and there are typical members aswell as borderline cases (Rosch, 1975; Hamp-ton, 2007).
Accordingly, (A) we will suggestthat word meaning may be better modeled us-ing a graded notion of sense membership thanthrough concepts with hard boundaries.
Second,even if senses have soft boundaries, the questionremains of whether they are disjoint.
(B) Wewill argue in favor of a framework where multi-ple senses may apply to a single occurrence, todifferent degrees.
This can be viewed as a dy-namical grouping of senses for each occurrence,in contrast to static sense groups as in Palmer etal.
(2007).
The first two hypotheses still rely onan existing sense list.
However, there is no univer-sal agreement across dictionaries and across taskson the number of senses that words have (Hanks,2000).
Kilgarriff (1997) even argues that general,task-independent word senses do not exist.
(C) Byfocusing on individual occurrences (usages) ofa lemma and their degree of similarity, we canmodel word meaning without recourse to dic-tionary senses.In this paper, we are going to argue in favor ofthe use of vector space as a basis for alternativemodels of word meaning.
Vector space modelshave been used widely to model word sense (Lund17and Burgess, 1996; Deerwester et al, 1990; Lan-dauer and Dumais, 1997; Sahlgren and Karlgren,2005; Pado?
and Lapata, 2007), their central prop-erty being that proximity in space can be used topredict semantic similarity.
By viewing word oc-currences as points in vector space, we can modelword meaning without recourse to senses.
An ad-ditional advantage of vector space models is thatthey are also widely used in human concept rep-resentation models, yielding many modeling ideasthat can be exploited for computational models.In Section 2 we review the evidence that wordsense is a tough phenomenon to model, and we layout findings that support hypotheses (A)-(C).
Sec-tion 4 considers distributional models that repre-sent word meaning without recourse to dictionarysenses, following (C).
In Section 5 we discuss pos-sibilities for embedding dictionary senses in vec-tor space in a way that respects points (A) and (B).2 Computational and cognitive models ofword meaningIn this section, we review the problems of (manualand automatic) sense assignment, and we discussdiscusses cognitive models of concept representa-tion and polysemy, following the three hypotheseslaid out in the introduction.Word sense assignment.
In computational lin-guistics, the problem of polysemy is typicallyphrased as one of choosing one best-fitting sensefor the given occurrence out of a dictionary-defined sense list.
However, this is a hard taskboth for humans and for machines.
With Word-Net (Fellbaum, 1998), the electronic lexicon re-source that is currently most widely used in com-putational linguistics, inter-annotator agreement(ITA) lies in the range of 67% to 78% (Landeset al, 1998; Snyder and Palmer, 2004; Mihal-cea et al, 2004), and state-of-the-art WSD sys-tems achieve accuracy scores of 73% to 77% (Ed-monds and Cotton, 2001; Mihalcea et al, 2004).This problem is not specific to WordNet: Anal-yses with the HECTOR dictionary led to simi-lar numbers (Kilgarriff and Rosenzweig, 2000).Sense granularity has been suggested as a reasonfor the difficulty of the task (Palmer et al, 2007).And in fact, the use of more coarse-grained sensesleads to greatly ITA as well as WSD accuracy,with about a 10% improvement for either mea-sure (Palmer et al, 2007; Pradhan et al, 2007).
InOntoNotes (Hovy et al, 2006), an ITA of 90% isused as the criterion for the construction of coarse-grained sense distinctions.
However, intriguingly,for some high-frequency lemmas such as leavethis ITA threshold is not reached even after mul-tiple re-partitionings of the semantic space (Chenand Palmer, 2009) ?
indicating that the meaning ofthese words may not be separable into senses dis-tinct enough for consistent annotation.
A recentanalysis of factors influencing ITA differences be-tween lemmas (Passonneau et al, 2010) foundthree main factors: sense concreteness, specificityof the context in which a target word occurs, andsimilarity between senses.
It is interesting to notethat only one of those factors, the third, can be ad-dressed through a change of dictionary.More radical solutions than sense grouping thathave been proposed are to restrict the task to deter-mining predominant sense in a given domain (Mc-Carthy et al, 2004), or to work directly with para-phrases (McCarthy and Navigli, 2009).
(A) Graded sense membership.
Research onthe human concept representation (Murphy, 2002;Hampton, 2007) shows that categories in thehuman mind are not simply sets with clear-cutboundaries.
Some items are perceived as moretypical than others (Rosch, 1975; Rosch andMervis, 1975).
Also, some items are clear mem-bers, others are rated as borderline (Hampton,1979).
On borderline items, people are more likelyto change their mind about category member-ship (McCloskey and Glucksberg, 1978).
How-ever, these results concern mental concepts, whichraises the question of the relation between mentalconcepts and word senses.
This relation is dis-cussed in most depth by Murphy (1991; 2002),who argues that while not every human conceptis associated with a word, word meanings showmany of the same phenomena as concepts in gen-eral; word meaning is ?made up of pieces of con-ceptual structure?.
In cognitive linguistics therehas been much work on word meaning based onmodels with graded membership and typically ef-fects (Coleman and Kay, 1981; Lakoff, 1987;Cruse, 1986; Taylor, 1989).
(B) Multiple senses per occurrence.
Whilemost manual word sense annotation efforts al-low annotators to assign more than one dictionarysense to an occurrence, this is typically phrasedas an exception rather than the default.
In the re-cent WSsim annotation study (Erk et al, 2009),18SensesSentence 1 2 3 4 5 6 7 AnnotatorThis question provoked arguments in America about theNorton Anthology of Literature by Women, some of thecontents of which were said to have had little value asliterature.1 4 4 2 1 1 3 Ann.
14 5 4 2 1 1 4 Ann.
21 4 5 1 1 1 1 Ann.
3Table 1: From (Erk et al, 2009): A sample annotation from the WSsim dataset.
The senses are: 1:state-ment, 2:controversy, 3:debate, 4:literary argument, 5:parameter, 6:variable, 7:line of reasoningwe asked three human annotators to judge the ap-plicability of WordNet senses on a graded scale of1 (completely different) to 5 (identical) and giv-ing a rating for each sense rather than picking one.Table 1 shows an example sentence with annota-tor ratings for the senses of the target argument.For this sentence, the annotators agree that senses2 and 3 are highly applicable, but there also indi-vidual differences in the perceived meaning: Onlyannotator 2 views sense 1 as applying to a highdegree.
In an annotation setting with graded judg-ments, it does not make sense to measure exactagreement on judgments.
We instead evaluatedITA using Spearman?s rho, a nonparametric corre-lation test, finding highly significant correlations(p  0.001) between each pair of annotators, aswell as highly significant correlations with the re-sults of a previous, traditional word sense annota-tion of the same dataset.
The annotators made useof the complete scale (1-5), often opting for inter-mediate values of sense applicability.
In addition,we tested whether there were groups of sensesthat always got the same ratings on any given sen-tence (which would mean that the annotators im-plicitly used more coarse-grained senses).
Whatwe found instead is that the annotators seemed tohave mixed and matched senses for the individualoccurrences in a dynamic fashion.
(C) Describing word meaning without dictio-nary senses.
In lexicography, Kilgarriff (1997)and Hanks (2000) cast doubt on the existenceof task-independent, distinct senses.
In cogni-tive science, Kintsch (2007) calls word meaning?fluid and flexible?.
And some researchers in lex-ical semantics have suggested that word mean-ings lie on a continuum between clear cut casesof ambiguity on the one hand, and on the otherhand vagueness where clear cut boundaries do nothold (Tuggy, 1993).
There are some psycholog-ical studies on whether different senses of a pol-ysemous word are represented separately in themind or whether there is some joint representa-tion.
However, so far the evidence is inconclusive1) We study the methods and concepts that each writer uses todefend the cogency of legal, deliberative, or more generallypolitical prudence against explicit or implicit charges thatpractical thinking is merely a knack or form of cleverness.2) Eleven CIRA members have been convicted of criminalcharges and others are awaiting trial.Figure 1: From (Erk et al, 2009): A sense pairfrom the USim dataset, for the target charge.n.Annotator judgments: 2,3,4and varies strongly with the experimental setting.Some studies found evidence for a separate rep-resentation (Klein and Murphy, 2001; Pylkkanenet al, 2006).
Brown (2008) finds a linear changein semantic similarity effects with sense distance,which could possibly point to a continuous rep-resentation of word meaning without clear senseboundaries.
But while there is no definitive answeryet on the question of the mental representationof polysemy, a computational model that does notrely on distinct senses has the advantage of makingfewer assumptions.
It also avoids the tough lexi-cographic problem mentioned above, of decidingon a best set of senses for a given domain.In the recent USim annotation study (Erk et al,2009), we tested whether human annotators couldreliably and consistently provide word meaningjudgments without the use of dictionary senses.Three annotators rated the similarity of pairs of oc-currences (usages) of a common target word, againon a scale of 1-5.
Figure 1 shows an example,with the corresponding annotator judgments.
Theresults on this task were encouraging: Again us-ing correlation to measure ITA, we found a highlysignificant correlation (p  0.001) between thejudgments of each pair of annotators.
Further-more, there was a strong correlation on judgmentsgiven with and without the use of dictionary senses(USim versus WSsim) for the same data.193 Vector space models of word meaningin isolationThis section gives a brief overview of the use ofvector spaces to model concepts and word mean-ing in cognition and computational linguistics.In two of the current main theories of conceptrepresentation, feature vectors play a prominentrole.
Prototype theory (Hampton, 1979; Smith andMedin, 1981) models degree of category member-ship through similarity to a single prototype.
Ex-emplar models (Medin and Schaffer, 1978; Nosof-sky, 1992; Nosofsky and Palmeri, 1997) representa concept as a collection of all previously seen ex-emplars and compute degree of category member-ship as similarity to stored exemplars.
Both pro-totypes and exemplars are typically represented asfeature vectors.
Many models represent a conceptas a region rather than a point in space, often char-acterized by a feature vector plus a separate di-mension weight vector (Smith et al, 1988; Hamp-ton, 1991; Ga?rdenfors, 2004).
The features areindividually meaningful and interpretable and in-clude sensory and motor features as well as func-tion and taxonomic features.
There are severaldatasets with features elicited from human sub-jects (McRae et al, 2005; Vigliocco et al, 2004).In computational linguistics, distributionalmodels represent the meaning of a word as a vec-tor in a high-dimensional space whose dimensionscharacterize the contexts in which the word typi-cally occurs (Lund and Burgess, 1996; Landauerand Dumais, 1997; Sahlgren and Karlgren, 2005;Pado?
and Lapata, 2007).
In the simplest case,the dimensions are context words, and the valuesare co-occurrence counts.
In contrast to spacesused in cognitive science, the dimensions in dis-tributional models are typically not interpretable(though see Almuhareb and Poesio (2005), Baroniet al (2010)).
A central property of distributionalmodels is that proximity in vector space is a pre-dictor of semantic similarity.
These models havebeen used successfully in NLP (Deerwester et al,1990; Manning et al, 2008), as well as in psy-chology (Landauer and Dumais, 1997; Lowe andMcDonald, 2000; McDonald and Ramscar, 2001).4 Vector space models of word meaningin contextIf we want to represent word meaning throughindividual usages and their similarity only, with-out the use of dictionary senses (along hypothesis(C)), distributional models are an obvious choice,if we can just represent each individual usage asa point in space.
However, vector space modelshave mostly been used to represent the meaning ofa word in isolation: The vector for a word is com-puted by summing over all its corpus occurrences,thereby summing over all its meanings.
There area few vector space models of meaning in context,though they differ in what it is that they model.One group of models computes a single vector fora whole sentence, encoding both the words and thesyntactic structure (Smolensky, 1990; B. Coeckeand Clark, 2010).
In this case, the dimensionalityof the vectors varies with the syntactic complexityof the sentence in question.
A second group alsocomputes a single vector for a whole expression,but the vector for a larger expression is a combi-nation of the word vectors for the words occurringin the expression (Landauer and Dumais, 1997;Mitchell and Lapata, 2008).
Syntactic structureis not encoded.
The resulting vector, of the samedimensionality as the word vectors, is then a com-bination of the contexts in which the words of thesentence occur.
A third group of approaches de-rives a separate vector for each word in a givensentence (Erk and Pado?, 2008; Thater et al, 2009;Erk and Pado?, 2010).
While an approach of thesecond type would derive a single, joint vector for,say, the expression catch a ball, an approach fromthe third group would derive two vectors, one forthe word catch in the context of ball, and one forthe word ball in the context of catch.
In this thirdgroup, the dimensionality of a vector for a word incontext is the same as for a word in isolation.In this paper, we focus on the third type of ap-proaches.
Our aim is to study alternatives to dic-tionary senses for characterizing word meaning.So we need a meaning characterization for eachindividual word in a given sentence context, ratherthan a single vector for a larger expression.We can also classify distributional approachesto word meaning in context into prototype- andexemplar-based approaches.
Prototype-based ap-proaches first compute a (prototype) vector foreach word in isolation, then modify this vec-tor according to the context in a given occur-rence (Landauer and Dumais, 1997; Mitchelland Lapata, 2008; Erk and Pado?, 2008; Thateret al, 2009).
Typical methods for combiningprototype vectors are addition, component-wisemultiplication (introduced by Mitchell and Lap-20catchhefielderdogcoldbaseballdriftobjsubjaccusesayclaimcomp-1ballwhirlflyprovidethrowcatchorganiseobj-1subj-1modredgolfelegantcatch...coldbaseballdriftobjsubj...comp-1ball...throwcatchorganiseobj-1subj-1mod...!
!Figure 2: From (Erk and Pado?, 2008): Left: Vector representations for verb catch and noun ball.
Lexicalinformation plus selectional preferences.
Right: Computing context-specific meaning by combiningpredicate and argument via selectional preference vectorsata (2008)), and component-wise minimum.
Thenthere are multiple prototype approaches that stat-ically cluster synonyms or occurrences to induceword senses(Schu?tze, 1998; Pantel and Lin, 2002;Reisinger and Mooney, 2010).
Exemplar-basedapproaches represent a word in isolation as a col-lection of its occurrences or paraphrases, then se-lect only the contextually appropriate exemplarsfor a given occurrence context (Kintsch, 2001; Erkand Pado?, 2010).
In this paper we focus on the firstand third group of approaches, as they do not relyon knowledge of how many word senses (clusters)there should be.A structured vector space model for wordmeaning in context.
In Erk and Pado?
(2008), weproposed the structured vector space model (SVS),which relies solely on syntactic context for com-puting a context-specific vector.
It is a prototype-based model, , and called structured because it ex-plicitly represents argument structure, using multi-ple vectors to represent each word.
Figure 2 (left)illustrates the representation.
A word, for exam-ple catch, has one vector describing the meaningof the word itself, the lexical vector ~catch.
It isa vector for the word in isolation, as is usual forprototype-based models.
In addition, the represen-tation for catch contains further vectors describingthe selectional preferences for each argument po-sition.
The obj preference vector of catch is com-puted from the lexical vectors of all words thathave been observed as direct objects of catch insome syntactically parsed corpus.
In the examplein Figure 2, we have observed the direct objectscold, baseball, and drift.
In the simplest case,the obj preference vector of catch is then com-puted as the (weighted) sum of the three vectors~cold, ~baseball and ~drift.
Likewise, ball is repre-sented by one vector for ball itself, one for ball ?spreferences for its modifiers (mod), one vector forthe verbs of which it is a subject (subj?1), and onefor the verbs of which is an object (obj?1).The vector for catch in a given context, say inthe context catch ball, is then computed as illus-trated on the right side of Figure 2: The lexicalvector ~catch is combined with the obj?1 vector ofball, modifying the vector ~catch in the direction ofverbs that typically take ball as an object.
For thevector combination, any of the usual operationscan be used: addition, component-wise multipli-cation, or minimum.
Likewise, the lexical vector~ball is combined with the obj preference vector ofcatch to compute the meaning of ball in the con-text catch ball.The standard evaluation for vector models ofmeaning in context is to predict paraphrase appro-priateness.
Paraphrases always apply to a wordmeaning, not a word.
For example, contract isan appropriate paraphrase for catch in the contextJohn caught the flu, but it is not an appropriateparaphrase in the context John caught a butterfly.A vector space model can predict paraphrase ap-propriateness as the similarity (measured, for ex-ample, using Cosine) of the context-specific vec-tor of catch with the lexical vector of contract:The more similar the vectors, the higher the pre-dicted appropriateness of the paraphrase.
We eval-uated SVS on two datasets.
The first is a tightlycontrolled psycholinguistic dataset of subject/verbpairs with paraphrases for the verbs only (Mitchelland Lapata, 2008).
The other is the Lexical Sub-stitution dataset, which has annotator-generatedparaphrases for target words in a larger senten-tial context and which is thus closer to typicalNLP application scenarios (McCarthy and Nav-igli, 2009).
SVS showed comparable performanceto the model by Mitchell and Lapata (2008) on the21former dataset, and outperformed the Mitchell andLapata model on the latter.One obvious extension is to use all availablesyntactic context, instead of focusing on a sin-gle syntactic neighbor.
We found no improve-ment on SVS in a straightforward extension toadditional syntactic context items (Erk and Pado?,2009).
However, Thater et al (2009) did achievebetter performance with a different model thatused all syntactic context.Taking larger context into account in anexemplar-based model.
But even if we take thecomplete local syntactic context into account, weare missing some evidence, in particular non-localinformation.
The word ball is interpreted differ-ently in sentences (1a) and (1b) 1 even though itspredicate ran has more or less the samemeaning inboth sentences.
What is different is the subject ofran, player versus debutante, which is not a directsyntactic neighbor of the ambiguous word ball.
(1)(a) the player ran to the ball(b) the debutante ran to the ballEven though we are not using dictionary senses,the types of evidence that should be useful forcomputing occurrence-specific vectors should bethe same as for traditional WSD; and one of themain type of features used there is bag-of-wordscontext.
In (Erk and Pado?, 2010), we proposed anexemplar-based model of word meaning in con-text that relied on bag-of-words context informa-tion from the whole sentence, but did not use syn-tactic information.
The model assumes that eachtarget lemma is represented by a set of exemplars,where an exemplar is a sentence in which the tar-get lemma occurs.
Polysemy is then modeled byactivating (selecting) relevant exemplars of a tar-get lemma in a given occurrence s.2 Both the ex-emplars and the occurrence s are modeled as vec-tors.
We simply use first-order vectors that re-flect the number of times each word occurs in agiven sentence.
The activated exemplars are thensimply the ones whose vectors are most similarto the vector of s. The results that we achievedwith the exemplar-based model on the LexicalSubstitution dataset were considerably better than1These two examples are due to Ray Mooney.2Instead of the binary selection of each exemplar that thismodel uses, it would also be possible to assign each exemplara weight, making it partially selected.those achieved with any of the syntax-based ap-proaches (Erk and Pado?, 2008; Erk and Pado?,2009; Thater et al, 2009).While prototype models compute a vector byfirst summing over all observed occurrences andthen having to suppress dimensions that are notcontextually appropriate, exemplar models onlytake contextually appropriate exemplars into ac-count in the first place, which is conceptuallysimpler and thus more attractive.
But there arestill many open questions, in particular the bestcombination of bag-of-words context and syntac-tic context as evidence for computing occurrence-specific vector representations.5 The role of dictionary sensesWord meaning models that rely only on individualword usages and their similarities are more flex-ible than dictionary-based models and make lessassumptions.
On the other hand, dictionaries offernot just sense lists but also a wealth of informationthat can be used for inferences.
WordNet (Fell-baum, 1998) has relations between words and be-tween synsets, most importantly synonymy andhyponymy.
VerbNet (Kipper et al, 2000) specifiessemantic properties of a predicate?s arguments, aswell as relations between the arguments.In this section we discuss approaches for em-bedding dictionary senses in a distributional modelin a way that supports hypotheses (A) and (B)(graded sense membership, and description of anoccurrence through multiple senses) and that sup-ports testing the applicability of dictionary-basedinference rules.Mapping dictionary senses to points in vec-tor space.
Dictionary senses can be mapped topoints in vector space very straightforwardly if wehave sense-annotated corpus data.
In that case,we can compute a (prototype) vector for a sensefrom all corpus occurrences annotated with thatsense.
We used this simple model (Erk and Mc-Carthy, 2009) to predict the graded sense appli-cability judgments from the WSsim dataset.
(SeeSection 2 for more information on this dataset.
)The predictions of the vector space model sig-nificantly correlate with annotator judgments.
Incomparison with an approach that uses the con-fidence levels of a standard WSD model as pre-dictions, the vector space model shows higher re-call but lower precision ?
for definitions of preci-sion and recall that are adapted to the graded case.22Another way of putting the findings is to say thatthe WSD confidence levels tend to under-estimatesense applicability, while the vector space modeltends to over-estimate it.Attachment sites for inference rules.
As dis-cussed above, vector space models for word mean-ing in context are typically evaluated on para-phrase applicability tasks (Mitchell and Lapata,2008; Erk and Pado?, 2008; Erk and Pado?, 2009;Thater et al, 2009).
They predict the applicabil-ity of a paraphrase like (2) based on the similaritybetween a context-specific vector for the lemma(here, catch) and a context-independent vector forthe paraphrase.
(in this case, contract).X catch Y ?
X contract Y (2)Another way of looking at this is to consider theinference rule (2) to be attached to a point inspace, namely the vector for contract, and to trig-ger the inference rule for an occurrence of catch ifit is close enough to the attachment site.
If weknow the WordNet sense of contract for whichrule (2) holds ?
it happens to be sense 4 ?, we canattach the rule to a vector for sense 4 of contract,rather than a vector computed from all occurrencesof the lemma.
Note that when we use dictionar-ies as a source for inference rules, for exampleby creating an inference rule like (2) for each twowords that share a synset and for each direct hy-ponym/hypernym pair, we do know the WordNetsense to which each inference rule attaches.Mapping dictionary senses to regions in vectorspace.
In Erk (2009) we expand on the idea oftying inference rules to attachment sites by repre-senting a word sense not as a point but as a regionin vector space.
The extent of the regions is esti-mated through the use of both positive exemplars(occurrences of the word sense in question), andnegative exemplars (occurrences of other words).The computational models we use are inspired bycognitive models of concept representation thatrepresent concepts as regions (Smith et al, 1988;Hampton, 1991), in particular adopting Shepard?slaw (Shepard, 1987), which states that perceivedsimilarity to an exemplar decreases exponentiallywith distance from its vector.In the longer term, the goal for the associationof inference rules with attachment sites is to obtaina principled framework for reasoning with par-tially applicable inference rules in vector space.6 Conclusion and outlookIn this paper, we have argued that it may be timeto consider alternative computational models ofword meaning, given that word sense disambigua-tion, after all this time, is still a tough problem forhumans as well as machines.
We have followedthree hypotheses.
The first two involve dictionarysenses, suggesting that (A) senses may best beviewed as applying to a certain degree, rather thanin a binary fashion, and (B) that it may make senseto describe an occurrence through multiple sensesas a default rather than an exception.
The thirdhypothesis then departs from dictionary senses,suggesting (C) focusing on individual word us-ages and their similarities instead.
We have arguedthat distributional models are a good match forword meaning models following hypotheses (A)-(C): They can represent individual word usages aspoints in vector space, and they can also representdictionary senses in a way that allows for gradedmembership and overlapping senses, and we havediscussed some existing models, both prototype-based and exemplar-based.One big question is, of course, about the us-ability of these alternative models of word mean-ing in NLP applications.
Will they do better thandictionary-based models?
The current evaluations,testing paraphrase applicability in context, are astep in the right direction, but more task-orientedevaluation schemes have to follow.We have argued that it makes sense to look tocognitive models of mental concept representa-tion.
They are often based on feature vectors, andthere are many interesting ideas in these modelsthat have not yet been used (much) in computa-tional models of word meaning.
One of the mostexciting ones, perhaps, is that cognitive models of-ten have interpretable dimensions.
While dimen-sions of distributional models are usually not in-dividually interpretable, there are some first mod-els (Almuhareb and Poesio, 2005; Baroni et al,2010) that use patterns to extract meaningful di-mensions from corpus data.
This offers many newperspectives: For which tasks can we improve per-formance by selecting dimensions that are mean-ingful specifically for that task (as in Mitchell etal.
(2008))?
Can interpretable dimensions be usedfor inferences?
And, when we are computing vec-tor space representations for word meaning in con-text, is it possible to select meaningful dimensionsthat are appropriate for a given context?23Acknowledgements.
This work was supportedin part by National Science Foundation grant IIS-0845925, and by a Morris Memorial Grant fromthe New York Community Trust.ReferencesA.
Almuhareb and M. Poesio.
2005.
Finding conceptattributes in the web.
In Proceedings of the CorpusLinguistics Conference, Birmingham.M.
Sadrzadeh B. Coecke and S. Clark.
2010.
Mathe-matical foundations for a compositional distributedmodel of meaning.
Lambek Festschrift, LinguisticAnalysis, 36.M.
Baroni, B. Murphy, E. Barbu, and M. Poesio.
2010.Strudel: A corpus-based semantic model based onproperties and types.
Cognitive Science, 34(2):222?254.S.
W. Brown.
2008.
Choosing sense distinctions forWSD: Psycholinguistic evidence.
In Proceedings ofACL/HLT, Columbus, OH.J.
Chen and M. Palmer.
2009.
Improving Englishverb sense disambiguation performance with lin-guistically motivated features and clear sense dis-tinction boundaries.
Journal of Language Resourcesand Evaluation, Special Issue on SemEval-2007,43:181?208.L.
Coleman and P. Kay.
1981.
The English word ?lie?.Linguistics, 57.D.
A. Cruse.
1986.
Lexical Semantics.
CambridgeUniversity Press.S.
Deerwester, S. T. Dumais, T. K. Landauer, G. W.Furnaas, and R. A. Harshman.
1990.
Indexing bylatent semantic analysis.
Journal of the Society forInformation Science, 41(6):391?407.P.
Edmonds and S. Cotton, editors.
2001.
Proceed-ings of the SensEval-2 Workshop, Toulouse, France.ACL.
See http://www.sle.sharp.co.uk/senseval.K.
Erk and D. McCarthy.
2009.
Graded word senseassignment.
In Proceedings of EMNLP, Singapore.K.
Erk and S. Pado?.
2008.
A structured vector spacemodel for word meaning in context.
In Proceedingsof EMNLP, Honolulu, HI.K.
Erk and S. Pado?.
2009.
Paraphrase assessment instructured vector space: Exploring parameters anddatasets.
In Proceedings of the EACL Workshop onGeometrical Methods for Natural Language Seman-tics (GEMS).K.
Erk and S. Pado?.
2010.
Exemplar-based modelsfor word meaning in context.
In Proceedings of theACL, Uppsala.K.
Erk, D. McCarthy, and N. Gaylord.
2009.
Inves-tigations on word senses and word usages.
In Pro-ceedings of ACL, Singapore.Katrin Erk.
2009.
Representing words as regions invector space.
In Proceedings of CoNLL.C.
Fellbaum, editor.
1998.
WordNet: An electroniclexical database.
MIT Press, Cambridge, MA.P.
Ga?rdenfors.
2004.
Conceptual spaces.
MIT press,Cambridge, MA.J.
A. Hampton.
1979.
Polymorphous concepts in se-mantic memory.
Journal of Verbal Learning andVerbal Behavior, 18:441?461.J.
A. Hampton.
1991.
The combination of prototypeconcepts.
In P. Schwanenflugel, editor, The psy-chology of word meanings.
Lawrence Erlbaum As-sociates.J.
A. Hampton.
2007.
Typicality, graded membership,and vagueness.
Cognitive Science, 31:355?384.P.
Hanks.
2000.
Do word meanings exist?
Computersand the Humanities, 34(1-2):205?215(11).E.
H. Hovy, M. Marcus, M. Palmer, S. Pradhan,L.
Ramshaw, and R. Weischedel.
2006.
OntoNotes:The 90% solution.
In Proceedings of HLT-NAACL,pages 57?60, New York.A.
Kilgarriff and J. Rosenzweig.
2000.
Frameworkand results for English Senseval.
Computers and theHumanities, 34(1-2):15?48.A.
Kilgarriff.
1997.
I don?t believe in word senses.Computers and the Humanities, 31(2):91?113.W.
Kintsch.
2001.
Predication.
Cognitive Science,25:173?202.W.
Kintsch.
2007.
Meaning in context.
In T.K.
Lan-dauer, D. McNamara, S. Dennis, andW.
Kintsch, ed-itors, Handbook of Latent Semantic Analysis, pages89?105.
Erlbaum, Mahwah, NJ.K.
Kipper, H.T.
Dang, and M. Palmer.
2000.
Class-based construction of a verb lexicon.
In Proceedingsof AAAI/IAAI.D.E.
Klein and G.L.
Murphy.
2001.
The representa-tion of polysemous words.
Journal of Memory andLanguage, 45:259?282.G.
Lakoff.
1987.
Women, fire, and dangerous things.The University of Chicago Press.T.
Landauer and S. Dumais.
1997.
A solution to Platosproblem: the latent semantic analysis theory of ac-quisition, induction, and representation of knowl-edge.
Psychological Review, 104(2):211?240.S.
Landes, C. Leacock, and R. Tengi.
1998.
Build-ing semantic concordances.
In C. Fellbaum, editor,WordNet: An Electronic Lexical Database.
The MITPress, Cambridge, MA.24W.
Lowe and S. McDonald.
2000.
The direct route:Mediated priming in semantic space.
In Proceed-ings of the Cognitive Science Society, pages 675?680.K.
Lund and C. Burgess.
1996.
Producinghigh-dimensional semantic spaces from lexical co-occurrence.
Behavior Research Methods, Instru-ments, and Computers, 28:203?208.C.
D. Manning, P. Raghavan, and H. Schu?tze.
2008.Introduction to Information Retrieval.
CambridgeUniversity Press.D.
McCarthy and R. Navigli.
2009.
The English lexi-cal substitution task.
Language Resources and Eval-uation, 43(2):139?159.
Special Issue on Compu-tational Semantic Analysis of Language: SemEval-2007 and Beyond.D.
McCarthy, R. Koeling, J. Weeds, and J. Carroll.2004.
Finding predominant senses in untagged text.In Proceedings of ACL, Barcelona.M.
McCloskey and S. Glucksberg.
1978.
Natural cat-egories: Well defined or fuzzy sets?
Memory &Cognition, 6:462?472.S.
McDonald and M. Ramscar.
2001.
Testing the dis-tributional hypothesis: The influence of context onjudgements of semantic similarity.
In Proceedingsof the Cognitive Science Society, pages 611?616.K.
McRae, G. S. Cree, M. S. Seidenberg, and C. Mc-Norgan.
2005.
Semantic feature production normsfor a large set of living and nonliving things.
Behav-ior Research Methods, 37(4):547?559.D.
L. Medin and M. M. Schaffer.
1978.
Context the-ory of classification learning.
Psychological Review,85:207?238.R.
Mihalcea, T. Chklovski, and A. Kilgariff.
2004.
TheSenseval-3 English lexical sample task.
In Proceed-ings of SensEval-3, Barcelona.J.
Mitchell and M. Lapata.
2008.
Vector-based modelsof semantic composition.
In Proceedings of ACL,Columbus, OH.T.
Mitchell, S. Shinkareva, A. Carlson, K. Chang,V.Malave, R. Mason, and M. Just.
2008.
Predictinghuman brain activity associated with the meaningsof nouns.
Science, 320(5880):1191?1195.G.
L. Murphy.
1991.
Meaning and concepts.
InP.
Schwanenflugel, editor, The psychology of wordmeanings.
Lawrence Erlbaum Associates.G.
L. Murphy.
2002.
The Big Book of Concepts.
MITPress.R.
M. Nosofsky and T. J. Palmeri.
1997.
An exemplar-based random walk model of speeded classification.Psychological Review, 104(2):266?300.R.
M. Nosofsky.
1992.
Exemplars, prototypes, andsimilarity rules.
In A. Healy, S. Kosslyn, andR.
Shiffrin, editors, From learning theory to connec-tionist theory: essays in honor of W.K.
Estes, vol-ume 1, pages 149?168.
Erlbaum, Hillsdale, NJ.S.
Pado?
and M. Lapata.
2007.
Dependency-based con-struction of semantic space models.
ComputationalLinguistics, 33(2):161?199.M.
Palmer, H. Trang Dang, and C. Fellbaum.
2007.Making fine-grained and coarse-grained sense dis-tinctions, both manually and automatically.
NaturalLanguage Engineering, 13:137?163.P.
Pantel and D. Lin.
2002.
Discovering word sensesfrom text.
In Proceedings of KDD, Edmonton,Canada.R.
Passonneau, A. Salleb-Aouissi, V. Bhardwaj, andN.
Ide.
2010.
Word sense annotation of polyse-mous words by multiple annotators.
In Proceedingsof LREC-7, Valleta, Malta.S.
Pradhan, E. Loper, D. Dligach, and M. Palmer.2007.
Semeval-2007 task 17: English lexical sam-ple, SRL and all words.
In Proceedings of Se-mEval?, Prague, Czech Republic.L.
Pylkkanen, R. Llinas, and G.L.
Murphy.
2006.
Therepresentation of polysemy: MEG evidence.
Jour-nal of Cognitive Neuroscience, 18:97?109.J.
Reisinger and R.J. Mooney.
2010.
Multi-prototypevector-space models of word meaning.
In Proceed-ing of NAACL.E.
Rosch and C. B. Mervis.
1975.
Family resem-blance: Studies in the internal structure of cate-gories.
Cognitive Psychology, 7:573?605.E.
Rosch.
1975.
Cognitive representations of seman-tic categories.
Journal of Experimental Psychology:General, 104:192?233.M.
Sahlgren and J. Karlgren.
2005.
Automatic bilin-gual lexicon acquisition using random indexing ofparallel corpora.
Journal of Natural Language En-gineering, Special Issue on Parallel Texts, 11(3).H.
Schu?tze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24(1).R.
Shepard.
1987.
Towards a universal law ofgeneralization for psychological science.
Science,237(4820):1317?1323.E.
E. Smith and D. L. Medin.
1981.
Categories andConcepts.
Harvard University Press, Cambridge,MA.E.
E. Smith, D. Osherson, L. J. Rips, and M. Keane.1988.
Combining prototypes: A selective modifica-tion model.
Cognitive Science, 12(4):485?527.25P.
Smolensky.
1990.
Tensor product variable bindingand the representation of symbolic structures in con-nectionist systems.
Artificial Intelligence, 46:159?216.B.
Snyder andM.
Palmer.
2004.
The English all-wordstask.
In 3rd International Workshop on SemanticEvaluations (SensEval-3) at ACL-2004, Barcelona,Spain.J.
Taylor.
1989.
Linguistic Categorization: Prototypesin Linguistic Theory.
Oxford Textbooks in Linguis-tics.S.
Thater, G. Dinu, and M. Pinkal.
2009.
Rankingparaphrases in context.
In Proceedings of the ACLWorkshop on Applied Textual Inference, Singapore.D.
H. Tuggy.
1993.
Ambiguity, polysemy and vague-ness.
Cognitive linguistics, 4(2):273?290.G.
Vigliocco, D. P. Vinson, W. Lewis, and M. F. Gar-rett.
2004.
Representing the meanings of objectand action words: The featural and unitary semanticspace hypothesis.
Cognitive Psychology, 48:422?488.W.
Weaver.
1949.
Translation.
In W.N.
Locke andA.D.
Booth, editors, Machine Translation of Lan-guages: Fourteen Essays.
MIT Press, Cambridge,MA.26
