Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 320?328,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsPositive Diversity Tuningfor Machine Translation System CombinationDaniel Cer, Christopher D. Manning and Daniel JurafskyStanford UniversityStanford, CA 94305, USA{danielcer,manning,jurafsky}@stanford.eduAbstractWe present Positive Diversity Tuning, anewmethod for tuningmachine translationmodels specifically for improved perfor-mance during system combination.
Sys-tem combination gains are often limitedby the fact that the translations producedby the different component systems aretoo similar to each other.
We propose amethod for reducing excess cross-systemsimilarity by optimizing a joint objectivethat simultaneously rewards models forproducing translations that are similar toreference translations, while also punish-ing them for translations that are too sim-ilar to those produced by other systems.The formulation of the Positive Diversityobjective is easy to implement and allowsfor its quick integration with most machinetranslation tuning pipelines.
We find thatindividual systems tuned on the same datato Positive Diversity can be even morediverse than systems built using differentdata sets, while still obtaining good BLEUscores.
When these individual systems areused together for system combination, ourapproach allows for significant gains of 0.8BLEU even when the combination is per-formed using a small number of otherwiseidentical individual systems.1 IntroductionThe best performing machine translation sys-tems are typically not individual decoders butrather are ensembles of two ormore systemswhoseoutput is then merged using system combinationalgorithms.
Since combining multiple distinctequally good translation systems reliably producesgains over any one of the systems in isolation, it iswidely used in situations where high quality is es-sential.Exploiting system combination brings signifi-cant cost: Macherey and Och (2007) showed thatsuccessful system combination requires the con-struction of multiple systems that are simultane-ously diverse and well-performing.
If the systemsare not distinct enough, they will bring very lit-tle value during system combination.
However,if some of the systems produce diverse transla-tions but achieve lower overall translation quality,their contributions risk being ignored during sys-tem combination.Prior work has approached the need for diversesystems by using different system architectures,model components, system build parameters, de-coder hyperparameters, as well as data selectionand weighting (Macherey and Och, 2007; DeNeroet al 2010; Xiao et al 2013).
However, duringtuning, each individual system is still just trained tomaximize its own isolated performance on a tuneset, or at best an error-driven reweighting of thetune set, without explicitly taking into account thediversity of the resulting translations.
Such tuningdoes not encourage systems to rigorously exploremodel variations that achieve both good translationquality and diversity with respect to the other sys-tems.
It is reasonable to suspect that this results inindividual systems that under exploit the amountof diversity possible, given the characteristics ofthe individual systems.For better system combination, we proposebuilding individual systems to attempt to simulta-neously maximize the overall quality of the indi-vidual systems and the amount of diversity acrosssystems.
We operationalize this problem formu-lation by devising a new heuristic measure calledPositive Diversity that estimates the potential use-fulness of individual systems during system com-bination.
We find that optimizing systems towardPositive Diversity leads to significant performancegains during system combination even when thecombination is performed using a small number of320otherwise identical individual translation systems.The remainder of this paper is organized as fol-lows.
Section 2 and 3 briefly review the tuningof individual machine translation systems and howsystem combination merges the output of multiplesystems into an improved combined translation.Section 4 introduces our Positive Diversity mea-sure.
Section 5 introduces an algorithm for traininga collection of translation systems toward PositiveDiversity.
Experiments are presented in sections 6and 7.
Sections 8 and 9 conclude with discussionsof prior work and directions for future research.2 Tuning Individual Translation SystemsMachine translation systems are tuned towardsomemeasure of the correctness of the translationsproduced by the system according to one or moremanually translated references.
As shown in equa-tion (1), this can be written as finding parametervalues?
that produce translations sys?
that in turnachieve a high score on some correctness measure:argmax?Correctness(ref[],sys?)
(1)The correctness measure that systems are typi-cally tuned toward is BLEU (Papineni et al 2002),which measures the fraction of the n-grams thatare both present in the reference translations andthe translations produced by a system.
The BLEUscore is computed as the geometric mean of theresulting n-gram precisions scaled by a brevitypenalty.The most widely used machine translationtuning algorithm, minimum error rate training(MERT) (Och, 2003), attempts to maximize thecorrectness objective directly.
Popular alternativessuch as pairwise ranking objective (PRO) (Hop-kins and May, 2011), MIRA (Chiang et al 2008),and RAMPION (Gimpel and Smith, 2012) use sur-rogate optimization objectives that indirectly at-tempt to maximize the correctness function by us-ing it to select targets for training discriminativeclassification models.
In practice, either optimiz-ing correctness directly or optimizing a surrogateobjective that uses correctness to choose optimiza-tion targets results in roughly equivalent transla-tion performance (Cherry and Foster, 2012).Even when individual systems are being builtto be used in a larger combined system, they arestill usually tuned to maximize their isolated in-dividual system performance rather than to maxi-mize the potential usefulness of their contributionduring system combination.1 To our knowledge,no effort has been made to explicitly tune towardcriteria that attempts to simultaneously maximizethe translation quality of individual systems andtheir mutual diversity.
This is unfortunate since themost valuable component systems for system com-bination should not only obtain good translationperformance, but also produce translations that aredifferent from those produced by other systems.3 System CombinationSimilar to speech recognition?s Recognizer Out-put Voting Error Reduction (ROVER) algorithm(Fiscus, 1997), machine translation system com-bination typically operates by aligning the transla-tions produced by two or more individual transla-tion systems and then using the alignments to con-struct a search space that allows new translations tobe pieced together by picking and choosing partsof the material from the original translations (Ban-galore et al 2001; Matusov et al 2006; Rosti etal., 2007a; Rosti et al 2007b; Karakos et al 2008;Heafield and Lavie, 2010a).2 The alignment of theindividual system translations can be performedusing alignment driven evaluation metrics such asinvWER, TERp, METEOR (Leusch et al 2003;Snover et al 2009; Denkowski and Lavie, 2011).The piecewise selection of material from the orig-inal translations is performed using the combina-tion model?s scoring features such as n-gram lan-guage models, confidence models over the indi-vidual systems, and consensus features that score acombined translation using n-gramsmatches to theindividual system translations (Rosti et al 2007b;Zhao and He, 2009; Heafield and Lavie, 2010b).Both system confidence model features and n-gram consensus features score contributions basedin part on how confident the system combinationmodel is in each individual machine translationsystem.
This means that little or no gains will typ-ically be seen when combining a good system withpoor performing systems even if the systems col-1The exception being Xiao et al(2013)?s work usingboosting for error-driven reweighting of the tuning set2Other system combination techniques exist such as can-didate selection systems, whereby the combination model at-tempts to find the best single candidate produced by one of thetranslation engines (Paul et al 2005; Nomoto, 2004; Zwartsand Dras, 2008), decoder chaining (Aikawa and Ruopp,2009), re-decoding informed by the decoding paths takenby other systems (Huang and Papineni, 2007), and decodingmodel combination (DeNero et al 2010).321Input : systems [], tune(), source, refs [], ?, EvalMetric (), SimMetric ()Output: models []// start with an empty set of translations from prior iterationsother_sys []?
[]for i?
1 to len(systems []) do// new Positive Diversity measure using prior translationsPD?,i()?
new PD(?, EvalMetric(), SimMetric(), refs [], other_sys [])// tune a new model to fit PD?,i// e.g., using MERT, PRO, MIRA, RAMPION, etc.models [i]?
tune(systems [i], source, PD?,i())// Save translations from tuned modeli for use during// the diversity computation for subsequent systemspush(other_sys [], translate(systems [i],models [i], source))endreturnmodels []Algorithm 1: Positive Diversity Tuning (PDT)lectively produce very diverse translations.3The requirement that the systems used for sys-tem combination be both of high quality and di-verse can be and often is met by building severaldifferent systems using different system architec-tures, model components or tuning data.
However,as will be shown in the next few sections, by ex-plicitly optimizing an objective that targets bothtranslation quality and diversity, it is possible toobtain meaningful system combination gains evenusing a single system architecture with identicalmodel components and the same tuning set.4 Positive DiversityWe propose Positive Diversity as a heuristicmeasurement of the value of potential contribu-tions from an individual system to system combi-nation.
As given in equation (2), PositiveDiversityis defined as the correctness of the translations pro-duced by a systemminus a penalty term that scoreshow similar the systems translations are with thoseproduced by other systems:PD?
= ?
Correctness(ref[],sys?)?(1?
?)
Similarity(other_sys[],sys?
)(2)The hyperparameter ?
explicitly trades-off thepreference for a well performing individual sys-3The machine learning theory behind boosting suggeststhat it should be possible to combine a very large number ofpoor performing systems into a single good system.
However,for machine translation, using a very large number of individ-ual systems brings with it difficult computational challenges.tem with system combination diversity.
Higher?
values result in a Positive Diversity metric thatmostly favors good quality translations.
However,even for large ?
values, if two translations are ofapproximately the same quality, the Positive Di-versity metric will prefer the one that is the mostdiverse given the translations being produced byother systems.The Correctness() and Similarity()measures are any function that can score transla-tions from a single system against other transla-tions.
This includes traditionalmachine translationevaluation metrics (e.g, BLEU, TER, METEOR)as well as any other measure of textual similarity.For the remainder of this paper, we use BLEU tomeasure both correctness and the similarity of thetranslations produced by the individual systems.When tuning individual translation systems towardPositive Diversity, our task is then to maximizeequation (3) rather than equation (1):argmax?
?
BLEU(ref[],sys)?(1?
?)
BLEU(other_sys[],sys) (3)Since this learning objective is simply the differ-ence between two BLEU scores, it should be easyto integrate into most existing machine translationtuning pipelines that are already designed to op-timize performance on translation evaluation met-rics.322PDT Individual System DiversitySystem \ Iteration 1 2 3 4 5 6 7 8 9 10?
= 0.95 36.6 32.0 19.0 13.6 11.9 8.2 15.9 8.7 7.3 2.3?
= 0.97 32.9 21.7 17.7 10.4 2.7 7.4 2.3 7.3 2.1 2.9?
= 0.99 23.9 13.1 7.9 2.3 3.2 2.6 2.2 1.5 3.4 0.7Table 1: Diversity scores for PDT individual systems onBOLT dev12 dev.
Individual systems are tuned toPositive Diversity on GALE dev10 web tune.
A system?s diversity score is measured as its 1.0?BLEUscore on the translations produced by PDT systems from earlier iterations.
Higher scores mean morediversity.Diversity of Baseline System vs.
Individual PDT Systems Available at Iteration iPDT Systems \ Iteration 0 1 2 3 4 5 6 7 8 9 10?
= 0.95 27.3 20.4 16.8 14.9 12.8 11.4 9.4 8.6 8.3 8.1 7.9?
= 0.97 28.4 21.3 15.8 14.7 13.3 13.0 12.5 12.2 10.3 10.0 9.7?
= 0.99 27.5 22.6 18.5 17.1 16.8 15.9 15.4 14.6 14.3 13.5 13.4Table 2: Diversity scores of a baseline system tuned to BOLT dev12 tune, a different tuning set than whatwas used for the PDT individual systems.
The baseline system diversity is scored against all of the PDTindividual systems available at iteration i for a given ?
value and over translations of BOLT dev12 dev.5 Tuning to Positive DiversityTo tune a collection of machine transla-tion systems using Positive Diversity, we pro-pose a staged process, whereby systems aretuned one-by-one to maximize equation (2)using the translations produced by previouslytrained systems to compute the diversity term,Similarity(other_sys[], sys?
).As shown in Algorithm 1, Positive DiversityTuning (PDT) takes as input: a list of machinetranslation systems, systems[]; a tuning proce-dure for training individual systems, tune(); atuning data set with source and reference trans-lations, source and refs; a hyperparameter ?to adjust the trade-off between fitting the refer-ence translations and diversity between the sys-tems; and metrics to measure correctness andcross-system similarity, Correctness() andSimilarity().The list of systems can contain any translationsystem that can be parameterized using tune().This can be a heterogeneous collection of substan-tially different systems (e.g., phrase-based, hier-archical, syntactic, or tunable hybrid systems) oreven multiple copies of a single machine transla-tion system.
In all cases, systems later in the listwill be trained to produce translations that both fitthe references and are encouraged to be distinctfrom the systems earlier in the list.During each iteration, the system constructs anew Positive Diversity measure PD?,i using thetranslations produced during prior iterations oftraining.
This PD?,i measure is then given totune() as the the training criteria for modeliof systemi.
The function tune() is any al-gorithm that allows a translation system?s perfor-mance to be fit to an evaluation metric.
Thisincludes both minimum error rate training algo-rithms (MERT) that attempt to directly optimize asystem?s performance on a metric, as well as othertechniques such as Pairwaise Ranking Objective(PRO),MIRA, and RAMPION that optimize a sur-rogate loss based on the preferences of an evalua-tion metric.After training a model for each system, the re-sulting model-system pairs can be combined usingany arbitrary system combination strategy.6 ExperimentsExperiments are performed using a singlephrase-based Chinese-to-English translation sys-tem, built with the Stanford Phrasal machine trans-lation toolkit (Cer et al 2010).
The system wasbuilt using all of the parallel data available forPhase 2 of the DARPA BOLT program.
The Chi-nese data was segmented to the Chinese Tree-Bank (CTB) standard using a maximum matchword segmenter, trained on the output of a CRFsegmenter (Xiang et al 2013).
The bitext wasword aligned using the Berkeley aligner (Liang etal., 2006).
Standard phrase-pair extraction heuris-323BLEU scores from individual systemstuned during iteration i of PDTPDT System 0 1 2 3 4 5 6 7 8 9 10?
= 0.95 16.2 16.0 15.7 15.9 16.1 16.1 15.9 15.4 16.1 15.9 16.2?
= 0.97 16.4 15.8 15.8 15.9 16.0 16.2 16.1 16.2 16.2 16.4 16.1?
= 0.99 16.3 16.1 16.2 15.9 16.3 16.4 16.4 16.3 16.4 16.5 16.3Table 3: BLEU scores on BOLT dev12 dev achieved by the individual PDT systems tuned on GALEdev10 web tune.
Scores report individual system performance before system combination.tics were used to extract a phrase-table over wordalignments symmetrized using grow-diag (Koehnet al 2003).
We made use of a hierarchical re-ordering model (Galley and Manning, 2008) aswell as a 5-gram languagemodel trained on the tar-get side of the bi-text and smoothed usingmodifiedKneeser-Ney (Chen and Goodman, 1996).Individual PDT systems were tuned on theGALE dev10 web tune set using online-PRO(Green et al 2013; Hopkins and May, 2011)to the Positive Diversity Tuning criterion.4 TheMulti-EngineMachine Translation (MEMT) pack-age was used for system combination (Heafieldand Lavie, 2010a).
We used BOLT dev12 dev asa development test set to explore different ?
pa-rameterizations of the Positive Diversity criteria.7 ResultsTable 1 illustrates the amount of diversityachieved by individual PDT systems on the BOLTdev12 dev evaluation set for ?
values 0.95, 0.97,and 0.99.5 Using different tuning sets is one of thecommon strategies for producing diverse compo-nent systems for system combination.
Thus, as abaseline, Table 2 gives the diversity of a systemtuned to BLEU using a different tuning set, BOLTdev12 tune, with respect to the PDT systems avail-able at each iteration.
As in Table 1, the diver-sity computation is performed using translations ofBOLT dev12 dev.Like the cross-system diversity term in the for-mulation of Positive Diversity using BLEU in4Preliminary experiments performed using MERT to trainthe individual systems produced similar results to those seenhere.
However, we switched to online-PRO since it dramat-ically reduced the amount time required to train each indi-vidual system.
We expect similar results when using othertuning algorithms for the individual systems, such as MIRAor RAMPION.5Due to time constraints, wewere not able to try additional?
values.
Given that our results suggest the lowest ?
valuefrom the ones we tried works best (i.e., ?
= 0.95), it wouldbe worth trying additional smaller ?
values such as 0.90equation (3), we measure the diversity of trans-lations produced by an individual system as thenegative BLEU score of the translations with re-spect to the translations from systems built duringprior iterations.
For clarity of presentation, thesediversity scores are reported as 1.0?BLEU.
Using1.0?BLEU to score cross-system diversity, meansthat the reported numbers can be roughly inter-preted as the fraction of n-grams from the individ-ual systems built during iteration i that have notbeen previously produced by other systems builtduring any iteration < i.6In our experiments, we find that for ?
?
0.97,during the first three iterations of PDT, there ismore diversity among the PDT systems tuned on asingle data set (GALE dev10 web tune) than thereis between systems tuned on different datasets(BOLT dev12 tune vs. GALE dev10 wb tune).
Thisis significant since using different tuning sets is acommon strategy for increasing diversity duringsystem combination.
These results suggest PDTis better at producing additional diversity than us-ing different tuning sets.
The PDT systems alsoachieve good coverage of the n-grams present inthe baseline system that was tuned using differentdata.
At iteration 10 and using ?
= 0.95, the base-line systems receive a diversity score of only 7.9%when measured against the PDT systems.7As PDT progresses, it becomes more difficult totune systems to produce high quality translationsthat are substantially different from those alreadybeing produced by other systems.
This is seen inthe per iteration diversity scores, whereby duringiteration 5, the individual PDT translation systemshave a 1.0?BLEU diversity score with prior sys-tems ranging from 11.9%, when using an ?
value6This intuitive interpretation assumes a brevity penaltythat is approximately 1.0.7For this diversity score, the brevity penalty is 1.0, mean-ing the diversity score is based purely on the n-grams presentin the baseline system that are not present in translations pro-duced by one or more of the PDT systems324Figure 1: System combination BLEU score achieved using Positive Diversity Tuning with the ?
values0.95, 0.97, and 0.99.
Four iterations of PDT with ?
= 0.95 results in a 0.8 BLEU gain over the initialBLEU tuned system.
We only examine combinations of up to 6 systems (i.e., iterations 0-5), as the timerequired to tune MEMT increases dramatically as additional systems are added.of 0.95, to 3.2% when using an ?
value of 0.99.A diversity score of 3.2% when using ?
= 0.99suggests that by iteration 5, very high ?
valuesput insufficient pressure on learning to find mod-els that produce diverse translations.
When usingan ?
of 0.95, a sizable amount of diversity still ex-ists across the systems translations all the way toiteration 7.
By iteration 10, only a small amountof additional diversity is contributed by each addi-tional system for all of the alpha values (< 3%).8Table 3 shows the BLEU scores obtained on theBOLT dev12 dev evaluation set by the individualsystems tuned during each iteration of PDT.
The0th iteration for each ?
value has an empty set oftranslations for the diversity term.
This means theresulting systems are effectively tuned to just max-imize BLEU.
Differences in system performanceduring this iteration are only due to differences inthe random seeds used during training.
Starting atiteration 1, the individual systems are optimized toproduce translations that both score well on BLEU8We speculate that if heterogeneous translation systemswere used with PDT, it could be possible to run with higher ?values and still obtain diverse translations after a large numberof PDT iterationsand are diverse from the systems produced dur-ing prior iterations.
It is interesting to note thatthe systems trained during these subsequent itera-tions obtain BLEU scores that are usually competi-tive with those obtained by the iteration 0 systems.Taken together with the diversity scores in Table1, this strongly suggests that PDT is succeedingat increasing diversity while still producing highquality individual translation systems.Figure 1 graphs the system combination BLEUscore achieved by using varying numbers of Pos-itive Diversity Tuned translation systems and dif-ferent ?
values to trade-off translation quality withtranslation diversity.
After running 4 iterations ofPDT, the best configuration, ?
= 0.95, achieves aBLEU score that is 0.8 BLEU higher than the cor-responding BLEU trained iteration 0 system.9From the graph, it appears that PDT perfor-mance initially increases as additional systems areadded to the system combination and then laterplateaus or even drops after too many systems areincluded.
The combinations using PDT systems9Recall that the iteration 0 system is effectively just tunedto maximize BLEU since we have an empty set of translationsfrom other systems that are used to compute diversity325built with higher ?
values reach the point of di-minishing returns faster than combinations usingsystems built with lower alpha values.
For in-stance, ?
= 0.99 plateaus on iteration 2, while?
= 0.95 peaks on iteration 4.
It might be pos-sible to identify the point at which additional sys-tems will likely not be useful by using the diversityscores in Table 1.
Scoring about 10% or less onthe 1?BLEUdiversitymeasure, with respect to theother systems being used within the system combi-nation, seems to suggest the individual system willnot be very helpful to add into the combination.8 Related WorkWhile the idea of encouraging diversity in indi-vidual systems that will be used for system combi-nation has been proven effective in speech recogni-tion and document summarization (Hinton, 2002;Breslin and Gales, 2007; Carbonell and Goldstein,1998; Goldstein et al 2000), there has only beena modest amount of prior work exploring suchapproaches for machine translation.
Prior workwithin machine translation has investigated adapt-ing machine learning techniques for building en-sembles of classifiers to translation system tuning,encouraging diversity by varying both the hyper-parameters and the data used to build the individualsystems, and chaining together individual transla-tion systems.Xiao et al(2013) explores using boosting totrain an ensemble of machine translation systems.Following the standard Adaboost algorithm, eachsystem was trained in sequence on an error-drivenreweighting of the tuning set that focuses learningon the material that is the most problematic for thecurrent ensemble.
They found that using a singlesystem to tune a large number of decoding mod-els to different Adaboost guided weightings of thetuning data results in significant gains during sys-tem combination.Macherey and Och (2007) investigated systemcombination using automatic generation of diverseindividual systems.
They programmatically gener-ated variations of systems using different build anddecoder hyperparameters such as choice of word-alignment algorithm, distortion limit, variations ofmodel feature function weights, and the set of lan-guage models used.
Then, in a process similar toforward feature selection, they constructed a com-bined system by iteratively adding the individualautomatically generated system that produced thelargest increase in quality when used in conjunc-tion with the systems already selected for the com-bined system.
They also explored producing varia-tion by using different samplings of the the trainingdata.
The individual and combined systems pro-duced by sampling the training data were inferiorto systems that used all of the available data.
How-ever, the experiments facilitated insightful analysison what properties an individual system must havein order to be useful during system combination.They found that in order to be useful within a com-bination, individual systems need to produce trans-lations of similar quality to other individual sys-tems within the system combination while also be-ing as uncorrelated as possible from the other sys-tems.
The Positive Diversity Tuning method in-troduced in our work is an explicit attempt to buildindividual translation systems that meet this crite-ria, while being less computationally demandingthan the diversity generating techniques exploredby Macherey and Och (2007).Aikawa and Ruopp (2009) investigated build-ing machine translations systems specifically foruse in sequential combination with other systems.They constructed chains of systems whereby theoutput of one decoder is feed as input to the nextdecoder in the pipeline.
The downstream systemsare built and tuned to correct errors produced bythe preceding system.
In this approach, the down-stream decoder acts as a machine learning basedpost editing system.9 ConclusionWe have presented Positive Diversity as a newway of jointly measuring the quality and diversityof the contribution of individual machine transla-tion systems to system combination.
This methodheuristically assesses the value of individual trans-lation systems by measuring their similarity to thereference translations as well as their dissimilarityfrom the other systems being combined.
We op-erationalize this metric by reusing existing tech-niques from machine translation evaluation to as-sess translation quality and the degree of similar-ity between systems.
We also give a straightfor-ward algorithm for training a collection of individ-ual systems to optimize Positive Diversity.
Ourexperimental results suggest that tuning to PositiveDiversity leads to improved cross-system diversityand system combination performance even whencombining otherwise identical machine translation326systems.The Positive Diversity Tuning method exploredin this work can be used to tune individual systemsfor any ensemble in which individual models canbe fit to multiple extrinsic loss functions.
SinceHall et al(2011) demonstrated the general purposeapplication of multiple extrinsic loss functions totraining structured prediction models, Positive Di-versity Tuning could be broadly useful within nat-ural language processing and for other machinelearning tasks.In future work within machine translation, itmay prove fruitful to examine more sophisticatedmeasures of dissimilarity.
For example, one couldimagine a metric that punishes instances of simi-lar material in proportion to some measure of theexpected diversity of the material.
It might also beuseful to explore joint rather than sequential train-ing of the individual translation systems.AcknowledgmentsWe thank the reviewers and the members of the Stan-ford NLP group for their helpful comments and sugges-tions.
This work was supported by the Defense AdvancedResearch Projects Agency (DARPA) Broad Operational Lan-guage Translation (BOLT) program through IBM and a fel-lowship to one of the authors from the Center for AdvancedStudy in the Behavioral Sciences.
Any opinions, findings,and conclusions or recommendations expressed in this mate-rial are those of the author(s) and do not necessarily reflectthe view of DARPA or the US government.ReferencesTakakoAikawa andAchimRuopp.
2009.
Chained sys-tem: A linear combination of different types of sta-tistical machine translation systems.
In Proceedingsof MT Summit XII.S.
Bangalore, G. Bordel, and Giuseppe Riccardi.
2001.Computing consensus translation from multiple ma-chine translation systems.
In ASRU.C.
Breslin and M. J F Gales.
2007.
Complementarysystem generation using directed decision trees.
InICASSP.Jaime Carbonell and Jade Goldstein.
1998.
The use ofMMR, diversity-based reranking for reordering doc-uments and producing summaries.
In SIGIR.Daniel Cer, Michel Galley, Daniel Jurafsky, andChristopher D. Manning.
2010.
Phrasal: A statis-tical machine translation toolkit for Exploring newmodel features.
In NAACL/HLT.Stanley F. Chen and Joshua Goodman.
1996.
An em-pirical study of smoothing techniques for languagemodeling.
In ACL.Colin Cherry and George Foster.
2012.
Batch tun-ing strategies for statistical machine translation.
InNAACL/HLT.David Chiang, Yuval Marton, and Philip Resnik.
2008.Online large-margin training of syntactic and struc-tural translation features.
In EMNLP.John DeNero, Shankar Kumar, Ciprian Chelba, andFranz Och.
2010.
Model combination for machinetranslation.
In NAACL/HLT.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: AutomaticMetric for Reliable Optimization andEvaluation of Machine Translation Systems.
In Pro-ceedings of the EMNLP 2011 Workshop on Statisti-cal Machine Translation.J.G.
Fiscus.
1997.
A post-processing system to yieldreduced word error rates: Recognizer output votingerror reduction (ROVER).
In ASRU.Michel Galley and Christopher D. Manning.
2008.
Asimple and effective hierarchical phrase reorderingmodel.
In Proceedings of the Conference on Empir-ical Methods in Natural Language Processing.Kevin Gimpel and Noah A. Smith.
2012.
Structuredramp loss minimization for machine translation.
InNAACL/HLT.J.
Goldstein, V. Mittal, J. Carbonell, andM.
Kantrowitz.
2000.
Multi-document summa-rization by sentence extraction.
In ANLP/NAACLWorkshop on Automatic Summarization.Spence Green, Sida Wang, Daniel Cer, and Christo-pher D. Manning.
2013.
Fast and adaptive onlinetraining of feature-rich translation models.
In (to ap-pear) ACL.Keith Hall, Ryan McDonald, and Slav Petrov.
2011.Training structured prediction models with extrinsicloss functions.
In Domain Adaptation Workshop atNIPS.Kenneth Heafield and Alon Lavie.
2010a.
CMUmulti-enginemachine translation forWMT2010.
InWMT.Kenneth Heafield and Alon Lavie.
2010b.
Voting on n-grams for machine translation system combination.In AMTA.Geoffrey E. Hinton.
2002.
Training products of ex-perts by minimizing contrastive divergence.
NeuralComput., 14(8):1771?1800, August.Mark Hopkins and Jonathan May.
2011.
Tuning asranking.
In EMNLP.Fei Huang and Kishore Papineni.
2007.
Hierarchi-cal system combination for machine translation.
InEMNLP-CoNLL.327Damianos Karakos, Jason Eisner, Sanjeev Khudanpur,and Markus Dreyer.
2008.
Machine translation sys-tem combination using ITG-based alignments.
InACL/HLT.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL.Gregor Leusch, Nicola Ueffing, and Hermann Ney.2003.
A novel string-to-string distancemeasure withapplications to machine translation evaluation.
InMT Summit.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In NAACL/HLT.Wolfgang Macherey and Franz J. Och.
2007.
Anempirical study on computing consensus transla-tions from multiple machine translation systems.
InEMNLP/CoNLL.Evgeny Matusov, Nicola Ueffing, and Hermann Ney.2006.
Computing consensus translation from multi-ple machine translation systems using enhanced hy-potheses alignment.
In EMNLP.Tadashi Nomoto.
2004.
Multi-engine machine transla-tion with voted language model.
In ACL.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In ACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In ACL.Michael Paul, Takao Doi, Youngsook Hwang, KenjiImamura, Hideo Okuma, and Eiichiro Sumita.
2005.Nobody is perfect: ATR?s hybrid approach to spokenlanguage translation.
In IWSLT.Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang,Spyros Matsoukas, Richard Schwartz, and BonnieDorr.
2007a.
Combining outputs from multiple ma-chine translation systems.
In NAACL/HLT.Antti-Veikko Rosti, Spyros Matsoukas, and RichardSchwartz.
2007b.
Improved word-level systemcombination for machine translation.
In ACL.Matthew Snover, Nitin Madnani, Bonnie J. Dorr, andRichard Schwartz.
2009.
Fluency, adequacy, orHTER?
: exploring different human judgments witha tunable MT metric.
InWMT.Bing Xiang, Xiaoqiang Luo, and Bowen Zhou.
2013.Enlisting the ghost: Modeling empty categories formachine translation.
In ACL.Tong Xiao, Jingbo Zhu, and Tongran Liu.
2013.
Bag-ging and boosting statistical machine translation sys-tems.
Artif.
Intell., 195:496?527, February.Yong Zhao and Xiaodong He.
2009.
Using n-grambased features for machine translation system com-bination.
In NAACL/HLT.Simon Zwarts and Mark Dras.
2008.
Choosing theright translation: A syntactically informed classifi-cation approach.
In CoLING.328
