PRIS at Chinese Language Processing--Chinese Personal Name DisambiguationJiayue Zhang, Yichao Cai, Si Li, Weiran Xu, Jun GuoSchool of Information and Communication EngineeringBeijing Universit of Posts and Telecommunicationsjyz0706@gmail.comAbstractThe more Chinese language materials comeout, the more we have to focus on the ?samepersonal name?
problem.
In our personalname disambiguation system, the hierarchicalagglomerative clustering is applied, andnamed entity is used as feature for documentsimilarity calculation.
We propose a two-stagestrategy in which the first stage involves wordsegmentation and named entity recognition(NER) for feature extraction, and the secondstage focuses on clustering.1 IntroductionWorld Wide Web (WWW) search engines havebecome widely used in recent years to retrieveinformation about real-world entities such aspeople.
Web person search is one of the mostfrequent search types on the web search engine.As the sheer amount of web information ex-pands at an ever more rapid pace, the named-entity ambiguity problem becomes more andmore serious in many fields, such as informationintegration, cross-document co-reference, andquestion answering.
It is crucial to develop me-thodologies that can efficiently disambiguate theambiguous names form any given set of data.There have been two recent Web People Search(WePS) evaluation campaigns [1] on personalname disambiguation using data from Englishlanguage web pages.
Previous researches onname disambiguation mainly employ clusteringalgorithms which disambiguates ambiguousnames in a given document collection throughclustering them into different reference entities.However, Chinese personal name disambigua-tion is potentially more challenging due to theneed for word segmentation, which could intro-duce errors that can in large part be avoided inthe English task.There are four tasks in Chinese LanguageProcessing of the CIPS-SIGHAN Joint Confe-rence, and we participate in the Chinese PersonalName Disambiguation task.
To accomplish thistask, we focused on solving two main problemswhich are word segmentation and duplicatenames distinguishment.
To distinguish duplicatenames, the system adopts named entity recogni-tion and clustering strategy.
For word segmenta-tion and NER, we applied a sharing platformnamed LTP designed by Harbin Institute ofTechnology [2].This tagger identifies and labelsnames of locations, organizations, people, time,date, numbers and proper nouns in the input text.The paper is organized as follows.
Section 2 in-troduces our feature extractions along with theircorresponding similarity matrix learning.
In Sec-tion 3, we analyze the performance of our sys-tem.
Finally, we draw some conclusions.2 MethodologyOur approach follows a common architecture fornamed-entity disambiguation: the detection ofambiguous objects, feature extractions and theircorresponding similarity matrix learning, andclustering.
The framework of overall processingis shown in Figure 1.Word SegmentationNamed Entity RecognitionBuilding VSMHACSubmitted ResultsCorpusLTPTF-IDFK-LdivergenceweightsimilarityFigure 1.
System Framework2.1 The detection of ambiguous objectsSince it is common for a single document tocontain one or more mentions of the ambiguouspersonal name, that is to say, the personal namemay appear several times in one document, thereis a need to define the object to be disambi-guated.
Here, we adopt the policy of ?one personper document?
(all mentions of the ambiguouspersonal name in one document are assumed torefer to the same personal entity in reality) as in[3] [4] [5].
Therefore, an object is defined as asingle entity with the ambiguous personal namein a given document.
This definition of the ob-ject (document-level object) might be not com-prehensive, because the mentions of the ambi-guous personal name in a document may refer tomultiple entities, but we found that this is a rarecase (most of those cases occur in genealogyweb pages).
On the other hand, the document-level object can include much information de-rived from that document, so that it can berepresented by features [6].For a given ambiguous personal name, wordsegmentation is applied first.
Then we try to ex-tract all mentions of the ambiguous personalname.
Take the given personal name ????
forexample, first, the exact match of the name isextracted.
Secondly, mentions that are super-strings of the given name like ????
?is alsoextracted .
Finally , mentions that contain cha-racter sequences but not a personal name like????????
is ignored.Given this definition of an object, we define atarget entity as an entity that includes a mentionof the ambiguous personal name.2.2 Feature extraction and similarity ma-trix learningMost of the previous work ([3] [4] [5]) used to-ken information in the given documents.
In thispaper, we follow and extend their work especial-ly for a web corpus.
Furthermore, compared to atoken, a phrase contains more information fornamed-entity disambiguation.
Therefore, we ex-plore both token and phrase-based informationin this paper.
Finally, there are two kinds of fea-ture vectors developed in our system, token-based and phrase-based.
The token-based featurevector is composed of tokens, and the phrase-based feature is composed of phrases.
The twofeature vectors are combined into a unified fea-ture vector in which tf-idf strategy is used forsimilarity calculation.2.2.1 Named Entity FeaturesFrom the results and papers of various teamsparticipating WePS, NEs have been shown to beeffective features in person name disambigua-tion, so we used NEs as features in this study.Through observation, we found that two differ-ent individuals can be identified by their corres-ponding NEs, especially by location, organiza-tion name and some proper nouns.
Hence, in ourstudy, we only extracted person, location, organ-ization name and proper noun as feature fromthe output of LTP, while time, date and numbersare discarded.
However, location and organiza-tion name have many proper nouns relatedweakly to a certain person.
Therefore, termshaving high-document-frequency in training datasets are removed from test data.2.2.2 Similarity matrix learningAfter NE extraction, we applied the vector spacemodel to the calculation of similarities betweenfeatures.
In the model, tf-idf is used as theweight of the feature, which is defined in Eq.
(1).iijijij nNMaxFreqfreqwIDFTF log)(: ???
(1)Here, wij is the weight of term (or phrase) ti indocument dj, freqij is the frequency of ti in dj,MaxFreqij is the frequency of the term (or phrase)whose frequency is the most in dj, N is the num-ber of documents under one given name, and niis the number of documents which has term (orphrase) ti.In this study, the similarities basedon features described above were calculated us-ing K-L divergence defined as Eq.
(2).?
?iKL iQiPiPQPD )()(log)()||((2)P and Q denote the vector of a document respec-tively.
K-L divergence between two vectorsshows the distance of two related documents.The smaller the value of K-L divergence of twovectors becomes, the closer the two documentsare.
In order to prevent the zero denominator, weapplied Dirichlet smoothing, i.e.
, the zero ele-ment in the vector will be replaced by 0.00001.2.3 ClusteringClustering is the key part for our personal namedisambiguation system.
This task is viewed as anunsupervised hard clustering problem.
First, weview the problem as unsupervised, using the dis-tributed training data for parameter validation, tooptimally tune the parameters in the clusteringalgorithm.
Secondly, we observed that the ma-jority of the input documents reference a singleindividual.
Hence, we view the problem as hardclustering, assigning input document to exactlyone individual, so that the produced clusters donot overlap.In our system, hierarchical agglomerative clus-tering (HAC) is used as a clustering method.
Itbuilds up a hierarchy of groups by continuouslymerging the two most similar groups.
Each ofthese groups starts as a single item, in this casean individual document.
In each iteration thismethod calculates the distances between everypair of groups, and the closest ones are mergedtogether to form a new group.
The vector of thenew group is the average of the original pair.This is repeated until there is only one group.This process is shown in Fig.
2.We used a threshold for selecting cluster.
So it isnot necessary to determine the number of clus-ters beforehand.
W  view the whole group as abinary tree, every node which is not a leaf hastwo children, left child and right child, and has arecord of the distance between the two children.We traverse the tree from the root, if the distancebetween the pair of children which form thecluster is larger than the threshold, then movedown to check the distance of its left child, thenright child.
The process will continue until thedistance between two children is less than thethreshold.
When the process comes to an end, allthe leaves under the node will be considered tobe in the same cluster.
The selecting process willcontinue until all the leaves are assigned to acluster.
The threshold is tuned using the distr i-buted training data.The whole process mainly consists of twophases, the first phase is clustering all the singleitems into one group, and the second is selectingcluster down along the tree from the root.
Thisstrategy has a major disadvantage which is thenew node is the average of its children.
Hence,with the merger of nodes going on, the distancebetween different groups becomes smaller andsmaller, which makes the boundaries betweendifferent clusters blur.
This is probably the mainreason that leads to the unsatisfactory results.Figure 2 visualization of hierarchical clustering3 PerformanceSince there is no correct answer of test datareceived, we present the performance of our sys-tem of training data.
There are two results gottenfrom the distributed evaluation in Table 1: one isevaluated with B-Cubed, and the other with P_IP.Both scores indicate that personal name disam-biguation needs more effort.Table 1 The performance of training dataprici-sionrecall F_scoreB-Cubed71.83 62.88 56.98purity In-versepurityF_scoreP_IP 76.43 67.71 62.764 ConclusionIn this report, we describe a system for the Chi-nese Personal Name Disambiguation task, apply-ing a two-stage clustering model.
Because this isour first time attending this kind of task, thereare many aspects not having been taken into ac-count.
Therefore, improving system performancebecomes motivation for us to work on it conti-nuously.
In future work, we?ll focus on improv-ing the clustering algorithm and proper featureextraction.ReferencesJ.
Artiles, J. Gonzalo and S. Sekine.
WePS 2 Evalua-tion Campaign: overview of the Web PeopleSearch Clustering Task.
In 2nd Web People SearchEvaluation Workshop (WePS 2009).
In18thWWW Conference, 2009.http://ir.hit.edu.cn/A.
Bagga and B. Baldwin.
1998.
Ent ity?based Cross?document Co?referencing Using the Vector SpaceModel.
In 17th COLING.C.
H. Gooi and J. Allan.
2004.
Cross -Document Co-reference on a Large Scale Corpus.NAACLT.
Pedersen, A. Purandare and A. Kulkarn i.
2005.Name Discrimination by Clustering Similar Con-texts.
In  Proc.
of the Sixth International Confe-rence on Intelligent Text  Processing and Computa-tional Linguistics, page 226-237.
Mexico City,Mexico.Y.
Chen and J. H. Martin.
CU-COMSEM: ExploringRich Features for Unsupervised Web PersonalName Disambiguation.
In WWW Conference,2007.M.
Ikeda, S. Ono, I. Sato, M. Yoshida and H. Naka-gawa.
Person Name Disambiguation on the Webby TwoStage Clustering.
In 18th WWW Confe-rence, 2009.E.
Elmacioglu, Y. F. Tan, S.Yan, M. Y. Kan and D.W. Lee.
Web People Name Disambiguation bySimple Clustering with Rich Features.
In WWWConference, 2007.
