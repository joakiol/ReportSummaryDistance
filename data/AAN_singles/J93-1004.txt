A Program for Aligning Sentences inBilingual CorporaWil l iam A. Gale*AT&T Bell LaboratoriesKenneth  W. Church*AT&T Bell LaboratoriesResearchers in both machine translation (e.g., Brown et al 1990) and bilingual lexicography (e.g.,Klavans and Tzoukermann 1990) have recently become interested instudying bilingual corpora,bodies of text such as the Canadian Hansards (parliamentary proceedings), which are availablein multiple languages (such as French and English).
One useful step is to align the sentences,that is, to identify correspondences b tween sentences inone language and sentences in the otherlanguage.This paper will describe a method and a program (align) for aligning sentences based on asimple statistical model of character lengths.
The program uses the fact that longer sentences inone language tend to be translated into longer sentences in the other language, and that shortersentences tend to be translated into shorter sentences.
A probabilistic score is assigned to eachproposed correspondence of sen tences, based on the scaled ifference oflengths of the two sentences(in characters) and the variance of this difference.
This probabilistic score is used in a dynamicprogramming framework to find the maximum likelihood alignment of sentences.It is remarkable that such a simple approach works as well as it does.
An evaluation wasperformed based on a trilingual corpus of economic reports issued by the Union Bank of Switzer-land (UBS) in English, French, and German.
The method correctly aligned all but 4% of thesentences.
Moreover, it is possible to extract a large subcorpus that has a much smaller errorrate.
By selecting the best-scoring 80% of the alignments, the error rate is reduced from 4% to0.7%.
There were more errors on the English-French subcorpus than on the English-Germansubcorpus, howing that error rates will depend on the corpus considered; however, both weresmall enough to hope that the method will be useful for many language pairs.To further esearch on bilingual corpora, a much larger sample of Canadian Hansards (ap-proximately 90 million words, half in English and and half in French) has been aligned with thealign program and will be available through the Data Collection Initiative of the Associationfor Computational Linguistics (ACL/DCI).
In addition, in order to facilitate replication of thealign program, an appendix is provided with detailed c-code of the more difficult core of the alignprogram.1.
IntroductionResearchers in both machine translation (e.g., Brown et al 1990) and bilingual lexi-cography (e.g., Klavans and Tzoukermann 1990) have recently become interested instudying bilingual corpora, bodies of text such as the Canadian Hansards (parliamen-tary debates), which are available in multiple languages (such as French and English).The sentence alignment task is to identify correspondences between sentences in one* AT&T Bell Laboratories 600 Mountain Avenue Murray Hill, NJ, 07974(~) 1993 Association for Computational LinguisticsComputational Linguistics Volume 19, Number 1Table 1Input to alignment program.English FrenchAccording to our survey, 1988 sales ofmineral water and soft drinks were muchhigher than in 1987, reflecting the grow-ing popularity of these products.
Cola drinkmanufacturers in particular achieved above-average growth rates.
The higher turnoverwas largely due to an increase in the salesvolume.
Employment and investment levelsalso climbed.
Following a two-year transi-tional period, the new Foodstuffs Ordinancefor Mineral Water came into effect on April1, 1988.
Specifically, it contains more strin-gent requirements regarding quality consis-tency and purity guarantees.Quant aux eaux min6rales et aux limonades,elles rencontrent toujours plus d'adeptes.
Eneffet, notre sondage fait ressortir des ventesnettement sup6rieures a celles de 1987, pourles boissons ~ base de cola notamment.
Laprogression des chiffres d'affaires r6sulte engrande partie de l'accroissement du volumedes ventes.
Uemploi et les investissementsont 6galement augment6.
La nouvelle ordon-nance f6d6rale sur les denr6es alimentairesconcernant entre autres les eaux min6rales,entr6e n vigueur le ler avril 1988 apr6s unep6riode transitoire de deux ans, exige surtoutune plus grande constance dans la qualit6 etune garantie de la puret6.language and sentences in the other language.
This task is a first step toward the moreambitious task finding correspondences among words.
1The input is a pair of texts such as Table 1.
The output identifies the alignmentbetween sentences.
Most English sentences match exactly one French sentence, but itis possible for an English sentence to match two or more French sentences.
The firsttwo English sentences in Table 2 illustrate a particularly hard case where two Englishsentences align to two French sentences.
No smaller alignments are possible becausethe clause ".
.
.
sales .
.
.were  h igher .
.
. "
in the first English sentence corresponds to(part of) the second French sentence.
The next two alignments below illustrate themore typical case where one English sentence aligns with exactly one French sentence.The final alignment matches two English sentences to a single French sentence.
Thesealignments agreed with the results produced by a human judge.Aligning sentences i just a first step toward constructing a probabilistic dictionary(Table 3) for use in aligning words in machine translation (Brown et al 1990), or forconstructing a bilingual concordance (Table 4) for use in lexicography (Klavans andTzoukermann 1990).Although there has been some previous work on the sentence alignment (e.g.,Brown, Lai, and Mercer 1991 \[at IBM\], Kay and R6scheisen \[this issue; at Xerox\],and Catizone, Russell, and Warwick, in press \[at ISSCO\], the alignment task remains asignificant obstacle preventing many potential users from reaping many of the benefitsof bilingual corpora, because the proposed solutions are often unavailable, unreliable,and/or  computationally prohibitive.Most of the previous work on sentence alignment has yet to be published.
Kay'sdraft (Kay and R6scheisen; this issue), for example, was written more than two yearsago and is still unpublished.
Similarly the IBM work is also several years old, but not1 In statistics, tring-matching problems are divided into two classes: alignment problems andcorrespondence problems.
Crossing dependencies are possible in the latter, but not in the former.76William A. Gale and Kenneth W. Church Program for Aligning SentencesTable 2Output from alignment program.English FrenchAccording to our survey, 1988 sales of min-eral water and soft drinks were much higherthan in 1987, reflecting the growing popular-ity of these products.
Cola drink manufac-turers in particular achieved above-averagegrowth rates.Quant aux eaux min6rales et aux limonades,elles rencontrent toujours plus d'adeptes.
Eneffet, notre sondage fait ressortir des ventesnettement sup6rieures a celles de 1987, pourles boissons a base de cola notamment.The higher turnover was largely due to an La progression des chiffres d'affaires r6sulteincrease in the sales volume, en grande partie de l'accroissement du vol-ume des ventes.Employment and investment levels also L'emploi et les investissements ont 6gale-climbed, ment augment6.Following a two-year transitional period, thenew Foodstuffs Ordinance for Mineral Wa-ter came into effect on April 1, 1988.
Specif-ically, it contains more stringent require-ments regarding quality consistency and pu-rity guarantees.La nouvelle ordonnance f6d6rale sur lesdenr6es alimentaires concernant entre autresles eaux min6rales, entr6e en vigueur le leravril 1988 apr6s une p6riode transitoire dedeux ans, exige surtout une plus grande con-stance dans la qualit6 et une garantie de lapuret6.Table 3An entry in a probabilistic dictionary.
(from Brown et al 1990)English French Prob (FrenchlEnglish)the le 0.610the la 0.178the 1' 0.083the les 0.023the ce 0.013the il 0.012the de 0.009the ~ 0.007the que 0.007very well documented  in the publ ished literature; consequently, there has been a lotof unnecessary subsequent work  at ISSCO and elsewhere.
2The method we describe has the same sentenceqength basis as does that of Brown,Lai, and Mercer, while the two differ considerably f rom the lexical approaches triedby Kay and R6scheisen and by Catizone, Russell, and Warwick.The feasibility of other methods has varied greatly.
Kay's approach is apparent lyquite slow.
At least, with the currently inefficient implementat ion,  it might  take hours2 After we finished most of this work, it came to our attention that the IBM MT group has at least fourpapers that mention sentence alignment.
(Brown et al 1988a,b) start from a set of aligned sentences,suggesting that they had a solution to the sentence alignment problem back in 1988.
Brown et al (1990)mention that sentence l ngths formed the basis of their method.
The draft by Brown, Lai, and Mercer(1991) describes their process without giving equations.77Computational Linguistics Volume 19, Number 1Table 4A b i l ingual  concordance.bank/banque ("money" sense)it could also be a place where we would have a bank of experts.
SENT i know several people who aftre le lieu oti se retrouverait une esp6ce de banque d' experts.
SENT je connais plusieurs persf finance (mr. wilson) and the governor of thees finances ( m.  wilson ) et le gouverneur de lareduced by over 800 per cent in one week throughus de 800 p. 100 en une semaine a cause d'unebank of canada have frequently on behalf of the cabanque du canada ont fr6quemment u ilis6 au cobank action.
SENT there was a haberdasher who woubanque.
SENT voila un chemisier qui aurait apprbank/banc ("place" sense)h a forum.
SENT such was the case in the georgesentre les 6tats-unis et le canada a propos duhan i did.
SENT he said the nose and tail of thegouvernement avait c6d6 les extr6mit6s duhe fishing privileges on the nose and tail of theles privil6ges de p~che aux extr6mit6s dubank issue which was settled between canada and thbanc de george.
SENT c'est dans le but de r6bank were surrendered by this government.
SENT thbanc.
SENT en fait, lors des n6gociations de 1bank went down the tube before we even negotiatedbanc ont 6t6 liquid6s avant rhyme qu' on aito align a single Scientific American article (Kay, personal communication).
It ought obe possible to achieve fairly reasonable r sults with much less computation.
The IBMalgorithm is much more efficient since they were able to extract nearly 3 million pairsof sentences from Hansard materials in 10 days of running time on an IBM Model3090 mainframe computer with access to 16 megabytes of virtual memory (Brown,Lai, and Mercer 1991).The evaluation of results has been absent or rudimentary.
Kay gives positive ex-amples of the alignment process, but no counts of error rates.
Brown, Lai, and Mercer(1991) report hat they achieve a 0.6% error rate when the algorithm suggests aligningone sentence with one sentence.
However, they do not characterize its performanceoverall or on the more difficult cases.Since the research community has not had access to a practical sentence alignmentprogram, we thought that it would be helpful to describe such a program (align) and toevaluate its results.
In addition, a large sample of Canadian Hansards (approximately90 million words, half in French and half in English) has been aligned with the alignprogram and has been made available to the general research community through theData Collection Initiative of the Association for Computational Linguistics (ACL/DCI).In order to facilitate replication of the align program, an appendix is provided withdetailed c-code of the more difficult core of the align program.The align program is based on a very simple statistical model of character lengths.The model makes use of the fact that longer sentences in one language tend to betranslated into longer sentences in the other language, and that shorter sentencestend to be translated into shorter sentences.
A probabilistic score is assigned to eachpair of proposed sentence pairs, based on the ratio of lengths of the two sentences(in characters) and the variance of this ratio.
This probabilistic score is used in adynamic programming framework in order to find the maximum likelihood alignmentof sentences.It is remarkable that such a simple approach can work as well as it does.
Anevaluation was performed based on a trilingual corpus of 15 economic reports issuedby the Union Bank of Switzerland (UBS) in English, French, and German (14,680words, 725 sentences, and 188 paragraphs in English and corresponding numbers in78William A. Gale and Kenneth W. Church Program for Aligning Sentencesthe other two languages).
The method correctly aligned all but 4% of the sentences.Moreover, it is possible to extract a large subcorpus that has a much smaller errorrate.
By selecting the best-scoring 80% of the alignments, the error rate is reducedfrom 4% to 0.7%.
There were more errors on the English-French subcorpus than onthe English-German subcorpus, showing that error rates will depend on the corpusconsidered; however, both were small enough for us to hope that the method will beuseful for many language pairs.
We believe that the error rate is considerably owerin the Canadian Hansards because the translations are more literal.2.
Paragraph AlignmentThe sentence alignment program is a two-step rocess.
First paragraphs are aligned,and then sentences within a paragraph are aligned.
It is fairly easy to align paragraphsin our trilingual corpus of Swiss banking reports since the boundaries are usuallyclearly marked.
However, there are some short headings and signatures that can beconfused with paragraphs.
Moreover, these short "pseudo-paragraphs" are not alwaystranslated into all languages.
On a corpus this small the paragraphs could have beenaligned by hand.
It turns out that "pseudo-paragraphs" u ually have fewer than 50characters and that real paragraphs usually have more than 100 characters.
We usedthis fact to align the paragraphs automatically, checking the result by hand.The procedure correctly aligned all of the English and German paragraphs.
How-ever, one of the French documents was badly translated and could not be alignedbecause of the omission of one long paragraph and the duplication of a short one.This document was excluded for the purposes of the remainder of this experiment.We will show below that paragraph alignment is an important step, so it is fortu-nate that it is not particularly difficult.
In aligning the Hansards, we found that para-graphs were often already aligned.
For robustness, we decided to align paragraphswithin certain fairly reliable regions (denoted by certain Hansard-specific formattingconventions) using the same method as that described below for aligning sentenceswithin each paragraph.3.
A Dynamic Programming FrameworkNow, let us consider how sentences can be aligned within a paragraph.
The programmakes use of the fact that longer sentences in one language tend to be translated intolonger sentences in the other language, and that shorter sentences tend to be trans-lated into shorter sentences.
3 A probabilistic score is assigned to each proposed pairof sentences, based on the ratio of lengths of the two sentences (in characters) andthe variance of this ratio.
This probabilistic score is used in a dynamic programmingframework in order to find the maximum likelihood alignment of sentences.
The fol-3 We will have little to say about how sentence boundaries are identified.
Identifying sentenceboundaries is not always as easy as it might appear for reasons described in Liberman and Church (inpress).
It would be much easier if periods were always used to mark sentence boundaries; butunfortunately, many periods have other purposes.
In the Brown Corpus, for example, only 90% of theperiods are used to mark sentence boundaries; the remaining 10% appear in numerical expressions,abbreviations, and so forth.
In the Wall Street Journal, there is even more discussion of dollar amountsand percentages, as well as more use of abbreviated titles such as Mr.; consequently, only 53% of theperiods in the Wall Street Journal are used to identify sentence boundaries.
For the UBS data, a simpleset of heuristics were used to identify sentences boundaries.
The dataset was sufficiently small that itwas possible to correct he remaining mistakes by hand.
For a larger dataset, such as the CanadianHansards, it was not possible to check the results by hand.
We used the same procedure that is used inChurch (1988).
This procedure was developed by Kathryn Baker (unpublished).79Computational Linguistics Volume 19, Number 1f .
-e-f -Q .t~e~?
-E0000P,o OlI0*?
**., *f * **.
.,***** t- **I I I500 1000 1500English paragraph lengthFigure 1Paragraph lengths are highly correlated.
The horizontal axis shows the length of Englishparagraphs, while the vertical scale shows the lengths of the corresponding Germanparagraphs.
Note that the correlation is quite large (.991).lowing striking figure could easily lead one to this approach.
Figure 1 shows that thelengths (in characters) ofEnglish and German paragraphs are highly correlated (.991).Dynamic programming is often used to align two sequences of symbols in a vari-ety of settings, such as genetic ode sequences from different species, speech sequencesfrom different speakers, gas chromatograph sequences from different compounds, andgeologic sequences from different locations (Sankoff and Kruskal 1983).
We could ex-pect these matching techniques to be useful, as long as the order of the sentences doesnot differ too radically between the two languages.
Details of the alignment techniquesdiffer considerably from one application to another, but all use a distance measure tocompare two individual elements within the sequences and a dynamic programmingalgorithm to minimize the total distances between aligned elements within two se-quences.
We have found that the sentence alignment problem fits fairly well into thisframework, though it is necessary to introduce a fairly interesting innovation into thestructure of the distance measure.Kruskal and Liberman (1983) describe distance measures as belonging to one oftwo classes: trace and time-warp.
The difference becomes important when a singleelement of one sequence is being matched with multiple elements from the other.
Intrace applications, uch as genetic ode matching, the single element is matched withjust one of the multiple elements, and all of the others will be ignored.
In contrast,in time-warp applications such as speech template matching, the single element ismatched with each of the multiple elements, and the single element will be usedin multiple matches.
Interestingly enough, our application does not fit into either of80William A. Gale and Kenneth W. Church Program for Aligning Sentences"00tO00d00d\] I I I I \[ \]-3 -2 -1 0 1 2 3deltaFigure 2Delta is approximately normal.
The horizontal axis shows ~, while the vertical scale shows theempirical density of delta for the hand-aligned regions as points, and a normal (0,1) densityplot (lines) for comparison?
The empirical density is slightly more peaked than normal (and itsmean is not quite zero), but the differences are small enough for the purposes of the algorithm.Kruskal and Liberman's classes because our distance measure needs to compare thesingle element with an aggregate of the multiple elements.4.
The Distance MeasureIt is convenient for the distance measure to be based on a probabilistic model so thatinformation can be combined in a consistent way.
Our distance measure is an estimateof - logProb(match I 6), where ~ depends on 11 and/2, the lengths of the two portionsof text under consideration.
The log is introduced here so that adding distances willproduce desirable results.This distance measure is based on the assumption that each character in one lan-guage, L~, gives rise to a random number of characters in the other language, L2.
Weassume these random variables are independent and identically distributed with anormal distribution.
The model is then specified by the mean, c, and variance, s2, ofthis distribution, c is the expected number  of characters in L2 per character in Lb ands 2 is the variance of the number  of characters in L2 per character in L1.
We define ~ tobe (12 - llC)/V~l s2 so that it has a normal distribution with mean zero and varianceone (at least when the two portions of text under consideration actually do happen tobe translations of one another).Figure 2 is a check on the assumption that 6 is normal ly distributed.
The figure isconstructed using the parameters c and s 2 estimated for the program.81Computational Linguistics Volume 19, Number 10~ eJ"0t ' -Q.0I I b I0 500 1000 1500English paragraph lengthFigure 3Variance is modeled proportional to length.
The horizontal axis plots the length of Englishparagraphs, while the vertical axis shows the square of the difference of English and Germanlengths, an estimate of variance.
The plot indicates that variance increases with length, aspredicted by the model.
The line shows the result of a robust regression analysis.
Five extremepoints lying above the top of this figure have been suppressed since they did not contribute tothe robust regression.The parameters c and S 2 are  determined empirically from the UBS data.
We couldestimate c by counting the number of characters in German paragraphs then divid-ing by the number of characters in corresponding English paragraphs.
We obtain81105/73481 ~ 1.1.
The same calculation on French and English paragraphs yieldsc ~ 72302/68450 ~ 1.06 as the expected number of French characters per Englishcharacter.
As will be explained later, performance does not seem to be very sensitiveto these precise language-dependent quantities, and therefore we simply assume thelanguage-independent value c ~ 1, which simplifies the program considerably.
Thisvalue would clearly be inappropriate for English-Chinese alignment, but it seemslikely to be useful for most pairs of European languages.s 2 is estimated from Figure 3.
The model assumes that s 2 is proportional to length.The constant of proportionality is determined by the slope of the robust regressionline shown in the figure.
The result for English--German is s 2 = 7.3, and for English-French is s 2 = 5.6.
Again, we will see that the difference in the two slopes is nottoo important.
Therefore, we can combine the data across languages, and adopt thesimpler language-independent stimate s 2 ~ 6.8, which is what is actually used in theprogram.We now appeal to Bayes Theorem to estimate Prob(match \] 6) as a constant imesProb(6 I match) Prob(match).
The constant can be ignored since it will be the same for82William A. Gale and Kenneth W. Church Program for Aligning SentencesTable 5Prob(match)Category Frequency Prob(match)1-1 1167 0.891-0 or 0-1 13 0.00992-1 or 1-2 117 0.0892-2 15 0.0111312 1.00all proposed matches.
The conditional probability Prob(~ I match) can be estimated byProb(~ \] match) = 2(1 - Prob(\]~l) )where Prob(\]61) is the probability that a random variable, z, with a standardized (meanzero, variance one) normal distribution, has magnitude at least as large as 16\].
That is,Prob(~)- 1 f~ v~ oo e -z2/2 dz.The program computes 6 directly from the lengths of the two portions of text, 11 and12, and the two parameters, c and s 2.
That is, 6 = (/2 - llC)/IX/~lS 2.
Then, Prob(\]6\]) iscomputed by integrating a standard normal distribution (with mean zero and varianceone).
Many statistics textbooks include a table for computing this.
The code in theappendix uses the pnorm function, which is based on an approximation described byAbramowitz and Stegun (1964; p. 932, equation 26.2.17).The prior probability of a match, Prob(match), is fit with the values in Table 5, whichwere determined from the hand-marked UBS data.
We have found that a sentence inone language normally matches exactly one sentence in the other language (1-1).
Threeadditional possibilities are also considered: 1-0 (including 0-1), 2-1 (including 1-2), and2-2.
Table 5 shows all four possibilities.This completes the discussion of the distance measure.
Prob(match I 6) is computedas an (irrelevant) constant imes Prob(~ \] match)Prob(match).
Prob(match) is computedusing the values in Table 5.
Prob(6 \] match) is computed by assuming that Prob(6 \]match) = 2(1 -Prob(\]~\]) ), where Prob(16\]) has a standard normal distribution.
We firstcalculate 6 as (12 - llc)/Ix/~lS 2 and then Prob(\]6\[) is computed by integrating a standardnormal distribution.
See the c-function two_side_distance in the appendix for an exampleof a c-code implementation of these calculations.The distance function d, represented in the program as two,side_distance, is definedin a general way to allow for insertions, deletion, substitution, etc.
The function takesfour arguments: Xl~ Yl, x2, y2.1.
Let d(xl,yl, 0~ 0) be the cost of substituting Xl with yl,2.
d(xl, 0; 0, 0) be the cost of deleting Xl,3.
d(O, yl; 0, 0) be the cost of insertion of Yl,4.
d(Xl,yl; x2, 0) be the cost of contracting Xl and x2 to yl,83Computational Linguistics Volume 19, Number 15. d(Xl,yl;O, y2) be the cost of expanding X1 to yl and y2, and6.
d(Xl,yl;x2,y2) be the cost of merging xl and x2 and matching with Yland yR.5.
The Dynamic Programming AlgorithmThe algorithm is summarized in the following recursion equation.
Let si, i = 1 ...
I, bethe sentences ofone language, and tj, j -- 1-.. J, be the translations ofthose sentences inthe other language.
Let d be the distance function described in the previous ection, andlet D(i,j) be the minimum distance between sentences sl , .
.
.s i  and their translationst l , .
.
.t j ,  under the maximum likelihood alignment.
D(i,j) is computed by minimizingover six cases (substitution, deletion, insertion, contraction, expansion, and merger)which, in effect, impose a set of slope constraints.
That is, D(i,j) is defined by thefollowing recurrence with the initial condition D(i,j) = O.D(i,j - 1) + d(O, tj;O,O)D( i -  1,j) + d(si, O;O,O)D( i -  1 , j -  1) + d(si, tj;O,O)D(i,j) = min D( i -  l , j -  2) q- d(si, tj;O, tj_l)D( i -  2 , j -1 )  + d(si, ty;Si-l,0)D( i -  2 , j -  2) + d(si, tfisi-l,tj-1)6.
EvaluationTo evaluate align, its results were compared with a human alignment.
All of the UBSsentences were aligned by a primary judge, a native speaker of English with a readingknowledge of French and German.
Two additional judges, a native speaker of Frenchand a native speaker of German, respectively, were used to check the primary judge on43 of the more difficult paragraphs having 230 sentences (out of 118 total paragraphswith 725 sentences).
Both of the additional judges were also fluent in English, havingspent the last few years living and working in the United States, though they wereboth more comfortable with their native language than with English.The materials were prepared in order to make the task somewhat less tedious forthe judges.
Each paragraph was printed in three columns, one for each of the threelanguages: English, French, and German.
Blank lines were inserted between sentences.The judges were asked to draw lines between matching sentences.
The judges werealso permitted to draw a line between a sentence and "null" if they thought hat thesentence was not translated.
For the purposes of this evaluation, two sentences weredefined to "match" if they shared a common clause.
(In a few cases, a pair of sentencesshared only a phrase or a word, rather than a clause; these sentences did not count asa "match" for the purposes of this experiment.
)After checking the primary judge with the other two judges, it was decided thatthe primary judge's results were sufficiently reliable that they could be used as astandard for evaluating the program.
The primary judge made only two mistakes onthe 43 hard paragraphs (one French mistake and one German mistake), whereas theprogram made 44 errors on the same materials.
Since the primary judge's error rate isso much lower than that of the program, it was decided that we needn't be concernedwith the primary judge's error rate.
If the program and the judge disagree, we canassume that the program is probably wrong.The 43 "hard" paragraphs were selected by looking for sentences that mappedto something other than themselves after going through both German and French.84William A. Gale and Kenneth W. Church Program for Aligning SentencesTable 6Complex matches are more difficult.category English-French English-German totalN err % N err % N err %1-01-12-12-23-13-28 8 100542 14 2.659 8 149 3 331 1 1001 1 1005 5 100625 9 1.458 2 3.46 2 331 1 1000 0 - -13 13 1001167 23 2.0117 10 915 5 332 2 1001 1 100Specifically, for each English sentence, we attempted to find the corresponding Germansentences, and then for each of them, we attempted to find the corresponding Frenchsentences, and then we attempted to find the corresponding English sentences, whichshould hopefully get us back to where we started.
The 43 paragraphs included allsentences in which this process could not be completed around the loop.
This relativelysmall group of paragraphs (23% of all paragraphs) contained a relatively large fractionof the program's errors (82%).
Thus, there seems to be some verification that thistrilingual criterion does in fact succeed in distinguishing more difficult paragraphsfrom less difficult ones.There are three pairs of languages: English-German, English-French, and French-German.
We will report on just the first two.
(The third pair is probably dependenton the first two.)
Errors are reported with respect o the judge's responses.
That is,for each of the "matches" that the primary judge found, we report the program ascorrect if it found the "match" and incorrect if it didn't.
This procedure is better thancomparing on the basis of alignments proposed by the algorithm for two reasons.First, it makes the trial "blind," that is, the judge does not know the algorithm's resultwhen judging.
Second, it allows comparison of results for different algorithms on acommon basis.The program made 36 errors out of 621 total alignments (5.8%) for English-Frenchand 19 errors out of 695 (2.7%) alignments for English-German.
Overall, there were55 errors out of a total of 1316 alignments (4.2%).
The higher error rate for English-French alignments may result from the German being the original, so that the Englishand German differ by one translation, while the English and French differ by twotranslations.Table 6 breaks down the errors by category, illustrating that complex matchesare more difficult.
1-1 alignments are by far the easiest.
The 2-1 alignments, whichcome next, have four times the error rate for 1-1.
The 2-2 alignments are harder still,but a majority of the alignments are found.
The 3-1 and 3-2 alignments are not evenconsidered by the algorithm, so naturally all three instances of these are counted aserrors.
The most embarrassing category is 1-0, which was never handled correctly.
Inaddition, when the algorithm assigns a sentence to the 1-0 category, it is also alwayswrong.
Clearly, more work is needed to deal with the 1-0 category.
It may be necessaryto consider language-specific methods in order to deal adequately with this case.Since the algorithm achieves ubstantially better performance on the 1-1 regions,one interpretation of these results is that the overall low error rate is due to thehigh frequency of 1-1 alignments in English-French and English-German translations.85Computational Linguistics Volume 19, Number 1Table 7The distance measure is the best predictor of errors.Variable Coef.
Std.
Dev.Distance Measure .071 .011Category Type .52 .47Paragraph Length .0003 .0005Sentence Length .0013 .0029Coef./Std.
Dev.6.51.10.60.5Translations to linguistically more different languages, such as Hebrew or Japanese,might encounter a higher proportion of hard matches.We investigated the possible dependence of the error rate on four variables:1.
Sentence Length2.
Paragraph Length3.
Category Type4.
Distance Measure.We used logistic regression (Hosmer and Lemeshow 1989) to see how well each ofthe four variables predicted the errors.
The coefficients and their standard deviationsare shown in Table 7.
Apparently, the distance measure is the most useful predictor,as indicated by the last column.
In fact, none of the other three factors was found tocontribute significantly beyond the effect of the distance measure, indicating that thedistance measure is already doing an excellent job, and we should not expect muchimprovement if we were to try to augment the measure to take these additional factorsinto account.The fact that the score is such a good predictor of performance can be used to ex-tract a large subcorpus that has a much smaller error rate.
By selecting the best scoring80% of the alignments, the error rate can be reduced from 4% to 0.7%.
In general, wecan trade off the size of the subcorpus and the accuracy by setting a threshold, andrejecting alignments with a score above this threshold.
Figure 4 examines this trade-offin more detail.Less formal tests of the error rate in the Hansards suggest hat the overall errorrate is about 2%, while the error rate for the easy 80% of the sentences i about 0.4%.Apparently the Hansard translations are more literal than the UBS reports.
It took20 hours of real time on a sun 4 to align 367 days of Hansards, or 3.3 minutes perHansard-day.
The 367 days of Hansards contained about 890,000 sentences or about 37million "words" (tokens).
About half of the computer time is spent identifying tokens,sentences, and paragraphs, and about half of the time is spent in the align programitself.The overall error, 4.2%, that we get on the UBS corpus is considerably higherthan the 0.6% error reported by Brown, Lai, and Mercer (1991).
However, a directcomparison is misleading because of the differences in corpora and the differences insampling.
We have observed that the Hansards are much easier than the UBS.
Ourerror rate drops by about 50% in that case.
Aligning the UBS French and English texts ismore difficult than aligning the English and German, because the French and English86William A. Gale and Kenneth W. Church Program for Aligning Sentences03o.~, 04c -O0..0. .
.
.
.
.
.
.
.
.
.
.
.
~_ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.I I I I I20 40 60 80 1 O0percent of retained alignmentsFigure 4Extracting a subcorpus with lower error rate.
The fact that the score is such a good predictorof performance can be used to extract a large subcorpus that has a much smaller error rate.
Ingeneral, we can trade off the size of the subcorpus and the accuracy by setting a threshold andrejecting alignments with a score above this threshold.
The horizontal axis shows the size ofthe subcorpus, and the vertical axis shows the corresponding error rate.
An error rate of about2/3% can be obtained by selecting a threshold that would retain approximately 80% of thecorpus.versions are separated by two translations, both being translations of the Germanoriginal.
In addition, IBM samples only the 1-1 alignments, which are much easierthan any other category, as one can see from Table 6.Given these differences in testing methodology as well as the differences in thealgorithms, we find the methods giving broadly similar results.
Both methods giveresults with sufficient accuracy to use the resulting alignments, or selected portionsthereof, for acquisition of lexical information.
And neither method achieves humanaccuracy on the task.
(Note that one difference between their method and ours is thatthey never find 2-2 alignments.
This would give their method a min imum overall errorrate of 1.4% on the UBS corpus, three times the human error rate on hard paragraphs.
)We conclude that a sentence al ignment method that achieves human accuracy willneed to have lexical information available to it.7.
Variations and Extensions7.1 Measuring Length in Terms Of Words Rather than CharactersIt is interesting to consider what happens if we change our definition of length to countwords rather than characters.
It might seem that a word is a more natural linguisticunit than a character.
However, we have found that words do not perform as well as87Computational Linguistics Volume 19, Number 1characters.
In fact, the "words" variation increases the number of errors dramatically(from 36 to 50 for English-French and from 19 to 35 for English-German).
The totalerrors were thereby increased from 55 to 85, or from 4.2% to 6.5%.We believe that characters are better because there are more of them, and there-fore there is less uncertainty.
On the average, there are 117 characters per sentence(including white space) and only 17 words per sentence.
Recall that we have modeledvariance as proportional to sentence length, V(I) = s21.
Using the character data, wefound previously that s 2 ~ 6.5.
The same argument applied to words yields s 2 ~ 1.9.For comparison's sake, it is useful to consider the ratio of x/-V~/m (or equivalently,s/x/-m), where m is the mean sentence l ngth.
We obtain x/V(m)/m ratios of 0.22 forcharacters and 0.33 for words, indicating that characters are less noisy than words,and are therefore more suitable for use in align.Although Brown, Lai, and Mercer (1991) used lengths measured in words, com-parisons of error rates between our work and theirs will not test whether charactersor words are more useful.
As set out in the previous section, there are numerousdifferences in testing methodology and materials.
Furthermore, there are apparentlymany differences between the IBM algorithm and ours other than the units of mea-surement, which could also account for any difference on performance.
Appropriatemethodology is to compare methods with only one factor varying, as we do here.7.2 Ignoring Paragraph BoundariesRecall that align is a two-step rocess.
First, paragraph boundaries are identified andthen sentences are aligned within paragraphs.
We considered eliminating the first stepand found a threefold egradation i performance.
The English-French errors wereincreased from 36 to 84, and the English-German errors from 19 to 86.
The overallerrors were increased from 55 to 170.
Thus the two-step approach reduces errors bya factor of three.
It is possible that performance might be improved further still byintroducing additional alignment steps at the clause and/or phrase levels, but testingthis hypothesis would require access to robust parsing technology.7.3 Adding a 2-2 CategoryThe original version of the program did not consider the category of 2-2 alignments.Table 6 shows that the program was right on 10 of 15 actual 2-2 alignments.
This wasachieved at the cost of introducing 2 spurious 2-2 alignments.
Thus in 12 tries, theprogram was right 10 times, wrong 2 times.
This is significantly better than chance,since there is less than 1% chance of getting 10 or more heads out of 12 flips of a faircoin.
Thus it is worthwhile to include the 2-2 alignment possibility.7.4 Using More Accurate Parameter EstimatesWhen we discussed the estimation of the model parameters, c and s 2, we mentionedthat it is possible to fit the parameters more accurately if we estimate different valuesfor each language pair, but that doing so did not seem to increase performance by verymuch.
In fact, we found exactly the same total number of errors, although the errors areslightly different.
Changing the parameters esulted in four changes to the output forEnglish-French (two right and two wrong), and two changes to the output for English-German (one right and one wrong).
Since it is more convenient to use language-independent parameter values, and doing so doesn't seem to hurt performance verymuch (if at all), we have decided to adopt the language-independent values.88William A. Gale and Kenneth W. Church Program for Aligning Sentences7.5 Extensions7.5.1 Hard and Soft Boundaries.
Recall that we rejected one of the French documentsbecause one paragraph was omitted and two paragraphs were duplicated.
We couldhave handled this case if we had employed a more powerful paragraph alignmentalgorithm.
In fact, in aligning the Canadian Hansards, we found that it was necessaryto do something more elaborate than we did for the UBS data.
We decided to usemore or less the same procedure for aligning paragraphs within a document as theprocedure that we used for aligning sentences within a paragraph.
Let us introducethe distinction between hard and soft delimiters.
The alignment program is definedto move soft delimiters as necessary within the constraints of the hard delimiters.Hard delimiters cannot be modified, and there must be equal numbers of them.
Whenaligning sentences within a paragraph, the program considers paragraph boundariesto be "hard" and sentence boundaries to be "soft."
When aligning paragraphs withina document, he program considers document boundaries to be "hard" and paragraphboundaries to be "soft."
This entension has been incorporated into the implementationpresented in the appendix.7.5.2 Augmenting the Dictionary Function to Consider Words.
Many alternativealignment procedures such as Kay and R6scheisen (unpublished) make use of words.
Itought to help to know that the English string "house" and the French string "maison"are likely to correspond.
Dates and numbers are perhaps an even more extreme xam-ple.
It really ought o help to know that the English string "1988" and the French string"1988" are likely to correspond.
We are currently exploring ways to integrate thesekinds of clues into the framework described above.
However, at present, he algorithmdoes not have access to lexical constraints, which are clearly very important.
We expectthat once these clues are properly integrated, the program will achieve performancecomparable to that of the primary judge.
However, we are still not convinced that itis necessary to process these lexical clues, since the current performance is sufficientfor many applications, uch as building a probabilistic dictionary.
It is remarkable justhow well we can do without lexical constraints.
Adding lexical constraints might slowdown the program and make it less useful as a first pass.8.
ConclusionsThis paper has proposed a method for aligning sentences in a bilingual corpus, basedon a simple probabilistic model, described in Section 3.
The model was motivatedby the observation that longer regions of text tend to have longer translations, andthat shorter egions of text tend to have shorter translations.
In particular, we foundthat the correlation between the length of a paragraph in characters and the length ofits translation was extremely high (0.991).
This high correlation suggests that lengthmight be a strong clue for sentence alignment.Although this method is extremely simple, it is also quite accurate.
Overall, therewas a 4.2% error rate on 1316 alignments, averaged over both English-French andEnglish-German data.
In addition, we find that the probability score is a good predictorof accuracy, and consequently, it is possible to select a subset of 80% of the alignmentswith a much smaller error rate of only 0.7%.The method is also fairly language-independent.
BothEnglish-French and English-German data were processed using the same parameters.
If necessary, it is possible tofit the six parameters in the model with language-specific values, though, thus far, wehave not found it necessary to do so.89Computational Linguistics Volume 19, Number 1We have examined a number of variations.
In particular, we found that it is betterto use characters rather than words in counting sentence length.
Apparently, the per-formance is better with characters because there is less variability in the differences ofsentence lengths so measured.
Using words as units increases the error rate by hal lfrom 4.2% to 6.5%.In the future, we would hope to extend the method to make use of lexical con-straints.
However, it is remarkable just how well we can do without such constraints.We might advocate our simple character alignment procedure as a first pass, even tothose who advocate the use of lexical constraints.
Our procedure would complementa lexical approach quite well.
Our method is quick but makes a few percent errors;a lexical approach is probably slower, though possibly more accurate.
One might gowith our approach when the scores are small, and back off to a lexical-based approachas necessary.AcknowledgmentsWe thank Susanne Wolff and EvelyneTzoukermann for their pains in aligningsentences.
Susan Warwick provided us withthe UBS trilingual corpus and convinced usto work on the sentence alignment problem.ReferencesAbramowitz, M., and Stegun, I.
(1964).Handbook of Mathematical Functions.
USGovernment Printing Office.Brown, P.; Cocke, J.; Della Pietra, S.; DellaPietra, V.; Jelinek, F.; Mercer, R.; andRoossin, P. (1988a).
"A statisticalapproach to French/English translation.
"In Proceedings, RIA088 Conference.Cambridge, MA.Brown, P.; Cocke, J.; Della Pietra, S.; DellaPietra, V.; Jelinek, F.; Mercer, R.; andRoossin, P. (1988b).
"A statisticalapproach to language translation."
InProceedings, 13th International Conference onComputational Linguistics (COLING-88).Budapest, Hungary.Brown, P.; Cocke, J.; Della Pietra, S.; DellaPietra, V.; Jelinek, F.; Lafferty, J.; Mercer,R.
; and Roossin, P. (1990).
"A statisticalapproach to machine translation.
"Computational Linguistics, 16, 79-85.Brown, P.; Lai, J.; and Mercer, R.
(1991).
"Aligning sentences in parallel corpora.
"In Proceedings, 47th Annual Meeting of theAssociation for Computational Linguistics.Catizone, R.; Russell, G.; and Warwick, S.(in press).
"Deriving translation data frombilingual texts."
In Lexical Acquisition:Using on-line Resources to Build a Lexicon,edited by Zernik.
Lawrence Erlbaum.Church, K. (1988).
"A stochastic partsprogram and noun phrase parser forunrestricted text."
In Proceedings, SecondConference on Applied Natural LanguageProcessing.
Austin, TX.Hosmer, D., and Lemeshow, S. (1989).Applied Logistic Regression.
Wiley.Klavans, J., and Tzoukermann, E.
(1990).
"The BICORD system."
In Proceedings,15th International Conference onComputational Linguistics (COLING-90),174-179.Kay, M., and R6scheisen, M.
(1988).
"Text-translation alignment."
Xerox PaloAlto Research Center.Kruskal, J., and Liberman, M. (1983).
"Thesymmetric time-warping problem: Fromcontinuous to discrete."
In Time Warps,String Edits, and Macro Molecules: TheTheory and Practice of Sequence Comparison,edited by D. Sankoff and J. Kruskal.Addison-Wesley.Liberman, M., and Church, K. (in press).
"Text analysis and word pronunciation itext-to-speech synthesis."
In Advances inSpeech Signal Processing, edited by S. Furuiand M. Sondhi.Sankoff, D., and Kruskal, J.
(1983).
TimeWarps, String Edits, and Macromolecules: TheTheory and Practice of Sequence Comparison.Addison-Wesley.90William A. Gale and Kenneth W. Church Program for Aligning SentencesAppendix: Programwith Michael D. RileyThe following code is the core of align.
It is a C language program that inputs twotext files, with one token (word) per line.
The text files contain a number of delimitertokens.
There are two types of delimiter tokens: "hard" and "soft."
The hard regions(e.g., paragraphs) may not be changed, and there must be equal numbers of them inthe two input files.
The soft regions (e.g., sentences) may be deleted (1-0), inserted (0-1), substituted (1-1), contracted (2-1), expanded (1-2), or merged (2-2) as necessary sothat the output ends up with the same number of soft regions.
The program generatestwo output files.
The two output files contain an equal number of soft regions, eachon a line.
If the -v command line option is included, each soft region is preceded byits probability score.#include <fcntl.
h>#include <malloc.h>#include <math.h>#include <stdio.h>#include <string.h>#include <sys/mman.h>#include <sys/types.h>#include <values.h>#include <sys/stat.h>/*usage:align regions -D '.PARA' -d '.End of Sentence' file1 file2outputs two files: filel.al ~ file2.alhard regions are delimited by the -D argsoft regions are delimited by the -d arg*/#define dist(x,y) distances\[(x) * ((ny) + 1) + (y)\]#define pathx(x,y) path x\[(x) * ((ny) + i) + (y)\]#define pathy(x,y) path_y\[(x) * ((ny) + 1) + (y)\]#define MAX_FILENAME 286#define BIG DISTANCE 2800/* Dynamic Programming Optimization */struct alignment {int xl;int yl;int x2;int y2;int d;};char *hard_delimiter = NULL;char *soft_delimiter = NULL;int verbose = O;/* utility functions */I~ -D arg *II* -d arg *II* -v arg *I91Computational Linguistics Volume 19, Number 1char *readchars(), **readlines(), **substrings();void err();/*seq_align by Mike Rileyx and y are sequences of objects, represented as non-zero ints,to be aligned.dist_funct(xl, yl, x2, y2) is a distance function of 4 args:dist_funct(xl, yl, O, O) gives cost of substitution of xl by yl.dist_funct(xl, O, O, 01 gives cost of deletion of xl.dist_funct(O, yl, O, 01 gives cost of insertion of yl.dist_funct(xl, yl, x2, 01 gives cost of contraction of (xl,x2) to yl.dist_funct(xl, yl, O, y2) gives cost of expansion of xi to (yl,y2).dist_funct(xl, yl, x2, y2) gives cost to match (xl,x2) to (yl,y2).align is the alignment, with (align\[i\].xl, align\[i\].x2) alignedwith (align\[i\].yl, align\[i\].y2).
Zero in align\[\].xl and align\[\].ylcorrespond to insertion and deletion, respectively.
Non-zero inalign\[\].x2 and align\[\].y2 correspond to contraction and expansion,respectively, align\[\].d gives the distance for that pairing.The function returns the length of the alignment.
*/intseq_align(x, y, nx, ny, dist_funct, align)int *x, *y, nx, ny;int (*dist_funct)();struct alignment **align;int *distances, *path_x, *path_y, n;int i, j, oi, oj, di, dj, dl, d2, d3, d4, d5, d6, dmin;struct alignment *ralign;distances = (int *) malloc((nx + I) * (ny + i) * sizeof(int));path_x = (int *) malloc((nx + i) * (ny + I) * sizeof(int));path_y = (int *) malloc((nx + I) * (ny + i) * sizeof(int));ralign = (struct alignment *) malloc((nx + ny)?
sizeof(struct alignment));for(j = O; j <= ny; j++) {for(i = O; i <= nx; i++) {dl = i>O &~ j>O ?
/* substitution */dist(i-l, j-l) + (*dist_funct)(x\[i-l\], y\[j-1\], O, O): MAXINT;d2 = i>O ?
/* deletion */dist(i-l, j) + (*dist_funct)(x\[i-l\], O, O, O): MAXINT;d3 = j>O ?
/* insertion */dist(i, j-l) + (*dist_funct)(O, y\[j-1\], O, O)92William A. Gale and Kenneth W. Church Program for Aligning Sentences: MAXINT;d4 = i>l && j>O ?
/* contract ion */dist(i-2, j-l) + (~dist_funct)(x\[ i -2\] ,  y\[j- l\], x\[i- l\], O): MAXINT;d5 = i>O && j>l ?
/~ expansion */dist(i- l ,  j-2) + (~dist_funct)(x\[ i - l \ ] ,  y\[j-2\], O, y\[j- l\]): MAXINT;d6 = i>l && j>l ?
/~ melding ~/dist(i-2, j-2) + (*dist_funct)(x\[ i -2\] ,  y\[j-2\], x\[i-l\], y\[j- l\]): MAXINT;dmin = di;i f(d2<dmin) dmin=d2;if(d3<dmin) dmin=d3;if(d4<dmin) dmin=d4;if(d5<dmin) dmin=dS;if(d6<dmin) dmin=d6;i f(dmin == MAXINT) {dist(i , j)  = O;}else i f(dmin == dl) {dist(i , j)  = dl;pathx(i , j )  = i-l;pathy(i , j )  = j-l;}else i f(dmin == d2) {dist(i , j)  = d2;pathx(i, j)  = i-l;pathy(i , j )  = j;}else i f(dmin == d3) {dist(i , j)  = d3;pathx(i, j)  = i;pathy(i , j )  = j-l;}else i f(dmin == d4) {dist(i , j)  = d4;pathx(i , j )  = i-2;pathy(i , j )  = j-l;}else if(drain == d5){dist(i , j)  = d5;pathx(i , j )  = i-l;pathy(i , j )  = j-2;}else /* dmin == d6 */ {dist(i , j)  = d6;pathx( i , j )  = i -2 ;pathy(i , j )  = j-2;}93Computational Linguistics Volume 19, Number 1}n=O;for ( i=nx,  3=ny ; i>O II j>O ; i = oi, j = oj) {oi = pathx( i ,  j) ;oj = pathy( i ,  j) ;di  = i - oi;dj = j - o j;i f (d i  == i a~ dj == I) { /* subst i tu t ion  */ra l ign\ [n\ ]  .xl = x\[ i - i \ ]  ;ra l ign \ [n \ ] .y l  = y\[ j - i \ ] ;ra l ign  \[n\] .x2 = O;ra l ign  In\] .y2 = 0 ;ra l ign \ [n++\] .d  = dist( i ,  j) - d is t ( i - i ,  j - i ) ;e lse i f (d i  == 1 ~a dj == O) { /* de le t ion  */ra l ign\ [n\ ]  .xl = x\[ i - l \ ]  ;ra l ign\ [n\ ]  .yl = O;ra l ign\ [n\ ]  .x2 = O;ra l ign  \[n\] .
y2 = 0 ;ra l ign \ [n++\] .d  = d ist ( i ,  j) - d is t ( i - l ,  j);e lse i f (d i  == 0 ~ dj == I) { /* inser t ion  */ra l ign\ [n\ ]  .xl = O;ra l ign \ [n \ ] .y l  = y\[ j - l \ ] ;ra l ig~ InS .x2 = O;ra l ign  \[n\] .
y2 = 0 ;ra l ign\ [n++\]  .d = d ist ( i ,  j) - d ist( i ,  j - l ) ;e lse i f(dj  == i) { /* cont rac t ion  */ra l ign\ [n\ ]  .xl = x\[ i -2\]  ;ra l ign \ [n \ ] .y l  = y\ [ j - l \ ] ;ra l ig~\ [n \ ] .x2  = x\[ i - l \ ]  ;ra l ign  \[n\] .
y2 = 0 ;ra l ign \ [n++\] .d  = d ist ( i ,  j) - d is t ( i -2 ,  j - l ) ;e lse i f (d i  == i) { /* expans ion  */ra l ign \ [n \ ] .x l  = x\[ i - l \ ] ;ra l ign  In\] .
yl = y \[j -2\] ;ra l ign\ [n\ ]  .x2 = O;ra l ign \ [n \ ] .y2  = y\ [ j - l \ ] ;ra l ign \ [n++\] .d  = d ist ( i ,  j) - d is t ( i - l ,  j -2);}else /* di == 2 aa dj == 2 */ { /* me ld ing  */ra l ign \ [n \ ] .x l  = x\[ i -2\]  ;ra l ign  In\] .
yl = y \[j -2\] ;ra l ign \ [n \ ] .x2  = x\[ i - l \ ]  ;ra l ign \ [n \ ] .y2  = y\ [ j - l \ ] ;94William A. Gale and Kenneth W. Church Program for Aligning Sentencesra l ign\[n++\] .d  = dist(i, j) - dist(i-2, j-2);}}*al ign = (struct al ignment *) mal loc(n * s izeof(struct al ignment));for(i=O; i<n; i++)bcopy(ra l ign + i, (*align) + (n-i-l), s izeof(struct al ignment));free(distances);free(path_x);free(path_y);free(ral ign);return(n);}/* Local Distance Funct ion *//* Returns the area under a normal d istr ibut ionfrom -inf to z standard deviat ions */doublepnorm(z)double z;{double t, pd;t = 1/ (1  + 0.2316419 * z);?
pd  = 1 - 0,3989423 *exp( -z  * z /2 )  *( ( ( (1 .330274429 * t - 1.821255978) * t+ 1.781477937) * t - 0.356563782) * t + 0.319381530) * t ;/ *  see Abramowitz ,  M., and I .
Stegun (1964) ,  26 .2 .17  p. 932 * /re turn(pd) ;}/ *  Return  -100 * log  probab i l i ty  that  an Eng l i sh  sentence  of  lengthlen l  i s  a t rans la t ion  of  a fo re ign  sentence  of  length  len2 .
Theprobab i l i ty  i s  based on two parameters ,  the  mean and var iance  ofnumber of  fo re ign  characters  per  Eng l i sh  character .
*/i n tmatch( len l ,  l en2)in t  len l ,  l en2 ;{double  z ,  pd, mean;doub le  c = 1;doub le  s2 = 6.8  ;i f ( lenl==O && len2==O) return(O);mean = (lenl + len2/c)/2;z = (c * lenl - len2)/sqrt(s2 * mean);/* Need to deal with both sides of the normal d istr ibut ion */if(z < O) z = -z;95Computational Linguistics Volume 19, Number 1pd = 2 * (1 - pnorm(z));if(pd > O) return((int)(-lO0 * log(pd)));else return(BIG_DISTANCE);}inttwo_side_distance(xl, yl, x2, y2)int xl, yl, x2, y2;int penalty21 = 230;log(\[prob of 2-1 match\]int penalty22 = 440;Iog(\[prob of 2-2 match\]int penaltyOl = 450;log(\[prob of 0-i match\] / \[prob of I-i match\])/* -i00 */ \[prob of 1-1 match\]) *// *  -100 */ \[prob of 1-1 match\]) * // *  -100 ** /if(x2 == 0 ~& y2 == O)if(x1 == O) /* insertion */return(match(x1, yl) + penalty01);else if(y1 == O) /* deletion */return(match(x1, yl) + penalty01);else return (match(xl, yl)); /* substitution */else if(x2 == O) /* expansion */return (match(x1, yl + y2) + penalty21);else if(y2 == O) /* contraction */return(match(xl + x2, yl) + penalty21);else /* merger */return(match(x1 + x2, yl + y2) + penalty22);}/* Functions for Manipulating Regions */struct region {char **lines;int length;};voidprint_region(fd, region, score)int score;FILE *fd;struct region *region;{char **lines, **end;lines = region->lines;96William A. Gale and Kenneth W. Church Program for Aligning Sentencesend = lines + region->length;for( ; lines < end ; lines++)fprintf(fd, "Zs\n", *lines);}intlength_of_a_region(region)struct region *region;{int result;char **lines, **end;lines = region->lines;end = lines + region->length;result = end - lines;for( ; lines < end; lines++)result += strlen(*lines);return(result);}int *region_lengths(regions, n)struct region *regions;int n;{int i;int *result;result = (int *)malloc(n * sizeof(int));if(result == NULL) err("malloc failed");for(i = O; i < n; i++)result\[i\] = length of_a_region(regions\[i\]);return(result);}struct region *find_sub_regions(region, delimiter, len_ptr)struct region *region;char *delimiter;int *len_ptr;struct region *result;char **i, **lines, **end;int n = O;lines = region->lines;end = lines + region->length;for(l = l ines; i < end; I++)if(delimiter && strcmp(*l, delimiter) == O) n++;97Computational Linguistics Volume 19, Number 1result = (struct region ~)calloc(n+l, sizeof(struct region));if(result == NULL) err("malloc failed");*len_ptr = n;n = O;result\[O\].lines = lines;for(1 = lines; 1 < end; l++)if(delimiter &~ strcmp(*l, delimiter) == O) {result\[n\].length = 1 - result\[n\].lines;result\[n+l\].l ines = I+i;n++;}result\[n\].length = 1 - result\[n\].lines;if(n != *len_ptr) {fprintf(stderr, "find_sub_regions: n = ~d, *len_ptr = ~d\n", n,*len_ptr);exit(2);}return(result);}/* Top Level Main Function */intmain(argc, argv)int argc;char **argv;char **linesl, ~*lines2;int number_of l inesl ,  number_of_lines2;struct region ~hard_regionsl, ~hard_regions2, ~soft regionsl,~soft_regions2;struct region ~hard_endl, ~hard_end2, tmp;int number_ofhard_regionsl ;int number_of hard_regions2;int number_ofsoft_regionsl ;int number_of soft_regions2;int ~lenl, ~len2;int c, n, i, ix, iy, prevx, prevy;struct alignment ~align, ~a;FILE *outl, ~out2;char f i lename\[MAXFILENAME\];extern char ~optarg;extern int optind;/* parse arguments */while((c = getopt(argc, argv, "vd:D:"))switch(c) {case 'v''verbose = 1;break;case 'd':soft delimiter = strdup(optarg);!= EOF)98William A. Gale and Kenneth W. Church Program for Aligning Sentencesbreak;case 'D':hard_delimiter = strdup(optarg);break;default:fprintf(stderr, "usage: align_regions \[d (soft delimiter)\](hard delimiter)\]\n");exit(2);}if(argc != optind + 2) err("wrong number of arguments");/* open output files */sprintf(filename, "~s.al", argv\[optind\]);out1 = fopen(filename, "w");if(outl == NULL) {fprintf(stderr, "can't open ~s\n", filename);exit(2);}sprintf(filename, "~s.al", argv\[optind+l\]);out2 = fopen(filename, "w");if(out2 == NULL) {fprintf(stderr, "can't open ~s\n", filename);exit(2);}\[Dlinesl = readlines(argv\[optind\], &number_of_linesl);lines2 = readlines(argv\[optind+l\], &number_of_lines2);tmp.lines = linesl;tmp.length = number_of_linesl;hard_regionsl = f ind_subregions(&tmp, hard_delimiter,~number_of_hard_regionsl);tmp.lines = lines2;tmp.length = number_of_lines2;hard_regions2 = find_sub_regions(&tmp, hard_delimiter,&number_of_hard_regions2);i f(number_ofhard_regionsl != number_of_hard_regions2)err("align_regions: input files do not contain thesame number of hard regions");hard_endl = hard_regionsl + number_of_hard_regionsl;hard_end2 = hard regions2 + number of_hard regions2;for( ; hard_regionsl < hard_endl ; hard regionsl++, hard_regions2++) {soft_regionsl = find_sub_regions(hard_regionsl\[O\], soft_delimiter,&number_of_soft_regionsl);soft_regions2 = find_sub_regions(hard_regions2\[O\], soft_delimiter,&number_of_soft_regions2);lenl = region_lengths(soft_regionsl, number_of_soft_regionsl);99Computational Linguistics Volume 19, Number 1len2 = region_lengths(soft_regions2, number_of_soft_regions2);n = seq_align(lenl, len2, number_of_soft_regionsl,number_of_soft_regions2,two_side_distance, ~align);prevx = prevy = ix = iy = O;for(i = O; i < n; i++) {a = aalign\[i\];if(a->x2 > O) ix++; else if(a->xl == O) ix--;if(a->y2 > O) iy++; else if(a->yl == O) iy--;if(a->xl == 0 a~ a->yl == 0 ~& a->x2 == 0 ~ a->y2 == O){ix++; iy++;}ix++;iy++;if(verbose) {fprintf(outl, ".Score ~dkn", a->d);fprintf(out2, ".Score ~dkn", a->d);}for( ; prevx < ix; prevx++)print_region(outl, soft_regionsl\[prevx\], a->d);fprintf(outl, "~sin", soft_delimiter);for( ; prevy < iy; prevy++)print_region(out2, soft_regions2\[prevy\], a->d);fprintf(out2, "Zskn", soft_delimiter);}fprintf(outl, "~skn", hard_delimiter);fprintf(out2, "~skn", hard_delimiter);free(align);free(soft_regionsl);free(soft_regions2);free(lenl);free (len2) ;}}/~ Util ity Functions ~/voiderr(msg)char ~msg;{fprintf(stderr, "~ERROR~:  %s\n", msg);exit(2);}/~ return the contents of the file as a stringand stuff the length of this string into len_ptr ~/charreadchars(filen~ne, len_ptr)char ~filename;100William A. Gale and Kenneth W. Church Program for Aligning Sentencesint ~len ptr;FILE *fd;char *result;struct stat stat_buf;fd = fopen(filename, "r");if(fd == NULL) err("open failed");if(fstat(fileno(fd), &stat_buf) == -I)err("stat failed");*len_ptr = stat buf.st_size;result = malloc(*len_ptr);if(result == NULL) err("malloc failed\n");if(fread(result, sizeof(char), *len_ptr, fd) != ~len_ptr)err("fread failed");if(fclose(fd) == -i)err("fclose failed");return(result);}/* split string into a number of substrings delimited by a delimitercharacterreturn an array of substringsstuff the length of this array into len_ptr */char **substrings(string, end, delimiter, len_ptr)char *string, *end, delimiter;int *len_ptr;char *s, **result;int i = O;while(string < end && *string == delimiter) string++;for(s = string; s < end; s++)if(*s == delimiter) i++;*len_ptr = i;result = (char **)malloc(sizeof(char *) * (i+l));if(result == NULL) err("malloc failed");i = O;result\[i++\] = string;for(s = string; s < end; s++)if(~s == delimiter) {result\[i++\] = s+l;*s = O;101Computational Linguistics Volume 19, Number 1}i--; /*the last entry is beyond the end*/if(i != *len_ptr) {fprintf(stderr, "align_regions: confusion; i = ~d; *len_ptr = ~d\n", i,*len_ptr);exit(2);}return(result);}/* return an array of strings, one string for each line of the fileset len_ptr to the number of lines in the file */char **readlines(filename, len_ptr)char *filename;int *len_ptr;char *chars;int number_of_chars;chars = readchars(filename, ~number_of_chars);return(substrings(chars, chars + number_of_chars, '\n' , len_ptr)) ;102
