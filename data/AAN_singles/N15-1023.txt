Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 218?224,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsInducing Lexical Style Properties for Paraphrase and Genre DifferentiationEllie PavlickUniversity of Pennsylvaniaepavlick@seas.upenn.eduAni NenkovaUniversity of Pennsylvanianenkova@seas.upenn.eduAbstractWe present an intuitive and effective methodfor inducing style scores on words andphrases.
We exploit signal in a phrase?s rate ofoccurrence across stylistically contrasting cor-pora, making our method simple to implementand efficient to scale.
We show strong resultsboth intrinsically, by correlation with humanjudgements, and extrinsically, in applicationsto genre analysis and paraphrasing.1 IntroductionTrue language understanding requires comprehend-ing not just what is said, but how it is said, yetonly recently have computational approaches beenapplied to the subtleties of tone and style.
As theexpectations on language technologies grow to in-clude tailored search, context-aware inference, andanalysis of author belief, an understanding of stylebecomes crucial.Lexical features have proven indispensable for thegood performance of most applications dealing withlanguage.
Particularly, more generalized characteri-zations of the lexicon (Brown et al, 1992; Wilson etal., 2005; Feng et al, 2013; Ji and Lin, 2009; Resnik,1995) have become key in overcoming issues withlexical sparseness and in providing practical seman-tic information for natural language processing sys-tems (Miller et al, 2004; Rutherford and Xue, 2014;Velikovich et al, 2010; Dodge et al, 2012).
Mostwork on stylistic variation, however, has focusedon larger units of text (Louis and Nenkova, 2013;Danescu-Niculescu-Mizil et al, 2012; Greene andResnik, 2009; Xu et al, 2012) and studies of style atthe lexical level have been scant.
The few recent ef-forts (Brooke et al, 2010; Brooke and Hirst, 2013b;Formal/Casual Complex/Simplejesus/my gosh great/a lot18 years/eighteen cinema/a movierespiratory/breathing a large/a bigyes/yeah music/the banddecade/ten years much/many things1970s/the seventies exposure/the showforemost/first of all relative/his familymegan/you there matters/the thingssomewhere/some place april/aprthis film/that movie journal/diaryfull/a whole bunch the world/everybodyotherwise/another thing burial/funeralfather/my dad rail/the trainrecreation/hobby physicians/a doctorTable 1: Paraphrases with large style differences.
Ourmethod learns these distinctions automatically.Brooke and Hirst, 2013a) have been motivated bythe need to categorize genre in multiple continuousdimensions and focused on applying standard meth-ods for lexical characterization via graph propaga-tion or crowdsourcing.We propose a simple and flexible method for plac-ing phrases along a style spectrum.
We focus ontwo dimensions: formality and complexity.
We eval-uate the resulting scores in terms of their correla-tion with human judgements as well as their util-ity in two tasks.
First, we use the induced dimen-sions to identify stylistic shifts in paraphrase, allow-ing us to differentiate stylistic properties in the Para-phrase Database (PPDB) with high accuracy.
Sec-ond, we test how well the induced scores capturedifferences between genres, and explore the extentto which these differences are due to topic versuslexical choice between stylistically different expres-sions for the same content.
We show that style alone218does differentiate between genres, and that the com-bined indicators of style and topic are highly effec-tive in describing genre in a way consistent with hu-man judgements.2 MethodWe focus on two style dimensions: formality andcomplexity.
We define formal language as the wayone talks to a superior, whereas casual language isused with friends.
We define simple language to bethat used to talk to children or non-native Englishspeakers, whereas more complex language is usedby academics or domain experts.We use the Europarl corpus of parliamentary pro-ceedings as an example of formal text and theSwitchboard corpus of informal telephone conversa-tions as casual text.
We use articles from Wikipediaand simplified Wikipedia (Coster and Kauchak,2011) as examples of complex and simple languagerespectively.
For each style dimension, we subsam-ple sentences from the larger corpus so that the twoends of the spectrum are roughly balanced.
Weend up with roughly 300K sentences each for for-mal/casual text and about 500K sentences each forsimple/complex text.1Given examples of language at each end of a styledimension, we score a phrase by the log ratio ofthe probability of observing the word in the refer-ence corpus (REF) to observing it in the combinedcorpora (ALL).
For formality the reference corpusis Europarl and the combined data is Europarl andSwitchboard together.
For complexity, the referencecorpus is normal Wikipedia and the combined data isnormal and simplified Wikipedia together.
Specifi-cally, we map a phrase w onto a style dimension via:FORMALITY(w) = log(P (w | REF )P (w | ALL)).We assign formality scores to phrases up to threewords in length that occur at least three times total inALL, regardless of whether they occur in both cor-pora.
Phrases which do not occur at all in REF aretreated as though they occurred once.1Number of words: casual (2MM), formal (7MM), simple(9MM), complex (12MM).3 EvaluationWe first assess the intrinsic quality of the scores re-turned by our method by comparing against subjec-tive human judgements of stylistic properties.Phrase-level human judgements For each of ourstyle dimensions, we take a random sample of 1,000phrases from our corpora.
We show each phrase to 7workers on Amazon Mechanical Turk (MTurk) andask the worker to indicate using a sliding bar (cor-responding to a 0 to 100 scale) where they feel eachword falls on the given style spectrum (e.g.
casualto formal).
Workers were given a high-level descrip-tion of each style (like those given at the beginningof Section 2) and examples to guide their annotation.Formal Casual Complex SimpleLow ?exchange , uh per capita is notproceedings all that stuff referendum the nightscrutiny pretty much proportional upHigh ?his speech radio mid possiblein return for are really japan center ofof the series to move into os setsTable 2: Phrases with high and low levels of annotatoragreement, measured by the variance of the human raters?scores (Low ?
= high agreement).We estimate inter-annotator agreement by com-puting each rater?s correlation with the average ofthe others.
The inter-annotator correlation was rea-sonably strong on average (?
= 0.65).
However,not all phrases had equally strong levels of humanagreement.
Table 2 shows some examples of phraseswhich fell ?obviously?
on one end of a style spec-trum (i.e.
the variance between humans?
ratings waslow) and some other examples which were less clear.Quality of automatic scores We compute the cor-relation of our method?s score with the average hu-man rating for each phrase.
The results are sum-marized in Table 4.
The log-ratio score correlateswith the human score significantly above chance,even matching inter-human levels of correlation onthe formality dimension.4 ApplicationsWe evaluate the acquired style mappings in twotasks: finding paraphrase pairs with differences instyle and characterizing genre variation.219agreed ?
great ?
sure ?
yeahassumes ?
implies ?
imagine ?
guesscurrently ?
today ?
now ?
nowadaysmost beautiful ?
very nice ?
really nice ?
really prettyfollowing a ?
in the aftermath ?
in the wake ?
right afterthe man who ?
one who ?
the one that ?
the guy thatTable 3: Groups of paraphrases ordered from most formal (left) to least formal (right), as described in Section 4.1.Spearman ?Formality ComplexityInter-annotator 0.654 0.657Log-ratio score 0.655 0.443Table 4: First row: mean correlation of each rater?s scoreswith the average of the others.
Second row: correlation ofour automatic style score with the average human score.4.1 Differentiating style in paraphrasesParaphrases are usually defined as ?meaning equiva-lent?
words or phrases.
However, many paraphrases,even while capturing the same meaning overall, dis-play subtle differences which effect their substi-tutability (Gardiner and Dras, 2007).For example, paraphrasing ?I believe that wehave...?
as ?I think we got...?
preserves the mean-ing but causes a clear change in style, from a moreformal register to a casual one.
It has been proposedthat paraphrases are rarely if ever perfectly equiva-lent, but instead represent near synonyms (Edmondsand Hirst, 2002), which contain subtle differences inmeaning and connotation.We test whether our method can tease apart stylis-tic variation given a set of ?equivalent?
phrases.We use phrase pairs from the Paraphrase Database(PPDB) (Ganitkevitch et al, 2013).
Using thescoring method described in Section 2, we iden-tify paraphrase pairs which display stylistic varia-tion along a particular dimension.
We can find pairs?w1, w2?
in PPDB for which FORMALITY(w1) ?FORMALITY(w2) is large; Table 1 gives some ex-amples of pairs identified using this method.
We canalso view paraphrases along a continuum; Table 3shows groups of paraphrases ordered from most for-mal to most casual and Figure 1 shows how para-phrases of the phrase money rank along the formalityand complexity dimensions.
For example, we cap-ture the fact that money is more formal but simplerthan the idiomatic expression a fortune.Figure 1: Several paraphrases for money ranked accord-ing to automatically learned style dimensions.Pairwise human judgements To evaluate thegoodness of our style-adapted paraphrases, we takea random sample of 3,000 paraphrase pairs fromPPDB and solicit MTurk judgements.
We showworkers each paraphrase pair and ask them to choosewhich of the words is more casual, or to indicate ?nodifference.?
We also carry out the analogous task forthe complexity distinction.
We take the majority of7 judgements as the true label for each pair.In only 9% of the 3,000 paraphrase pairs, turkersdecided there was no stylistic difference in the pair,indicating that indeed formality and complexity dif-ferences are truly characteristic of paraphrases.
Infurther analysis we ignore the pairs for which theconsensus was no difference but note that in fur-ther work we need to automate the identification ofstylistically equivalent paraphrases.Automatically differentiating paraphrases Us-ing the human judgements, we compute the accu-racy of our method for choosing which word in apair is more formal (complex).
We use the mag-nitude of the difference in formality (complexity)score as a measure of our method?s confidence in itsprediction.
E.g.
the smaller the gap in FORMALITY,220the less confident our method is that there is a truestyle difference.
Table 5 shows pairwise accuracyas a function of confidence: it is well above the50% random baseline, reaching 90% for the high-confidence predictions in the complexity dimension.Pairwise accuracyTop 10% Top 25% OverallComplexity 0.90 0.88 0.74Formality 0.72 0.73 0.68Table 5: Pairwise accuracy for paraphrase pairs at varyinglevels confidence.
Top 10% refers to the 10% of pairswith largest difference in log-ratio style score.
Randomguessing achieves an accuracy of 0.5.4.2 Genre characterizationNow we explore if the dimensions we learned at thesub-sentential level can be used to capture stylisticvariation at the sentence and genre level.Sentence-level human judgements We gatherhuman ratings of formality and complexity for 900sentences from the MASC corpus (Ide et al, 2010):20 sentences from each of 18 genres.2Recently datafrom this corpus has been used to study genre differ-ence in terms of pronoun, named entity, punctuationand part of speech usage (Passonneau et al, 2014).We use the data to test a specific hypothesis that au-tomatically induced scores for lexical style are pre-dictive of perceptions of sentence- and genre-levelstyle.We average 7 independent human scores to getsentence-level style scores.
To get genre-level stylescores, we use the the average of the 20 sentence-level scores for the sentences belonging to thatgenre.In human perception, the formality and com-plexity dimensions are highly correlated (Spearman?
= 0.7).
However, we see many interesting ex-amples of sentences which break this trend (Table6).
Overall, inter-annotator correlations are reason-ably strong (?
?
0.5), but as in the phrase-level2Court transcripts, debate transcripts, face-to-face conver-sations, blogs, essays, fiction, jokes, letters, technical writing,newspaper, twitter, email, ficlets (short fan fiction), govern-ment documents, journal entries, movie scripts, non-fiction, andtravel guides.
We omit the ?telephone?
genre, since it is toosimilar to the Switchboard corpus and may inflate results.annotations, we see some sentences for which thejudgement seems unanimous among annotators andsome sentences for which there is very little consen-sus (Table 7).
We discuss this variation further inSection 5.Formal/Simple has dr. miller left the courtroom?Formal/Simple i want to thank you for listening tonight.Casual/Complex right.
cuz if we have a fixed number ofneurons-?Casual/Complex i was actually thinking we could use thewarping factors that we compute for themfcc?sTable 6: Some examples of sentences for which the gen-erally high correlation between formality and complexitydoes not hold.Automatically characterizing genre The extentto which genre is defined by topic versus style is anopen question.
We therefore look at two methods forgenre-level style characterization, which we apply atthe sentence-level as well as at the genre-level.First, we take the average formality (complexity)score of all words in the text, which we refer to asthe ?all words?
method.
Using the style score alonein this way will likely to conflate aspects of topicwith aspects of style.
For example, the word birth-day receives a very low formality score whereas thephrase united nations receives a very high formalityscore, reflecting the tendency of certain topics to bediscussed more formally than others.!!!!!
!bigmy annual gigantic birthday post .remarkableimmensecolossalquitetotallyveryintends to enjoy her birthday thoroughlywhollyFigure 2: Authors reveal style by choosing casual termsor formal terms for the same concept.
Shown is a casualsentence (left) and a formal sentence (right) on the sametopic.
Alternative paraphrases are ordered casual (top) toformal (bottom).We therefore use a second method, which we re-fer to as ?PP only?, in which we look only at thewords in the text which belong to one of our para-phrase sets (as in Figure 3), allowing us to controlfor topic and focus only on stylistic word choice.
In?PP only?, we consider a word to be formal if it ap-pears on the formal side of the set (i.e.
there are221Formal Low ?
whereupon, the proceedings were adjourned at 4:20 p.m.Formal High ?
mr. president , you have 90 secondsCasual Low ?
is she, what grade is she in?Casual High ?
they bring to you and your loved ones.Complex Low ?
let me abuse the playwright and dismiss the penultimate sceneComplex High ?
revealing to you my family ?s secret because my late dad ?s burial is over.Simple Low ?
you ?re not the only oneSimple High ?
facebook can get you fired , dumped , and yes , evictedTable 7: Style ratings of sentences with high and low levels of human agreement, measured by the variance of thehuman raters?
scores (Low ?
= high agreement).more phrases to its left than to its right).
We thenscore the overall formality of the text as the propor-tion of times a formal phrase was chosen when amore casual paraphrase could have been chosen in-stead.
The intuition is captured in Figure 2: when anauthor is writing about a given topic, she encounterswords for which there exist a range of paraphrases.Her lexical choice in these cases signals the style in-dependent of the topic.Table 8 shows how well our two scoring methodscorrelate with the human judgements of sentences?styles.
The ?all words?
method performs very well,correlating with humans nearly as well as humanscorrelate with each other.
Interestingly, when us-ing paraphrases only we maintain significant corre-lations.
This ability to differentiate stylistic varia-tion without relying on cues from topic words couldbe especially important for tasks such as bias detec-tion (Recasens et al, 2013) and readability (Callan,2004; Kanungo and Orr, 2009).Formality ComplexitySent.
Genre Sent.
GenreInter-anno.
0.47 ?
0.48 ?All words 0.44 0.77 0.43 0.80PP only 0.18 0.63 0.23 0.45Table 8: Spearman ?
of automatic rankings with humanrankings.
Genres are the concatenation of sentences fromthat genre.
In ?all words,?
a text?s score is the averagelog-ratio style score of its words.
In ?PP only,?
a text?sscore is the proportion of times a formal term was chosenwhen more casual paraphrases existed, effectively captur-ing style independent of topic.5 DiscussionCharacterization of style at the lexical level is animportant first step in complex natural languagetasks, capturing style information in a way that isportable across topics and applications.
An inter-esting open question is the extent to which style isdefined at the lexical level versus at the sententiallevel: how strongly are human perceptions of styleinfluenced by topic and context as opposed to by lex-ical choice?
One interesting phenomenon we ob-serve is that inter-annotator correlations are lowerat the sentence level (?
?
0.5) than at the word-and phrase-level (?
?
0.65).
Tables 7 offers someinsight: for many of the sentences for which hu-man agreement is low, there seems to be some mis-match between the topic and the typical style of thattopic (e.g.
talking formally about family life, ortalking in relatively complex terms about Facebook).When humans are making judgements at the lexicallevel, such contextual mismatches don?t arise, whichmight lead to higher overall agreements.
Interestingfuture work will need to explore how well humansare able to separate style from topic at the sentence-and document-level, and how the lexical choice ofthe author/speaker affects this distinction.6 ConclusionWe present a simple and scalable method for learn-ing fine-grained stylistic variation of phrases.
Wedemonstrate good preliminary results on two rele-vant applications: identifying stylistic differencesin paraphrase, and characterizing variations betweengenres.
Our method offers a simple and flexible wayof acquiring stylistic annotations at web-scale, mak-ing it a promising approach for incorporating nu-anced linguistic information into increasingly com-plex language applications.33All human and log-ratio scores discussed are available athttp://www.seas.upenn.edu/?nlp/resources/style-scores.tar.gz222ReferencesJulian Brooke and Graeme Hirst.
2013a.
Hybrid mod-els for lexical acquisition of correlated styles.
In Pro-ceedings of the Sixth International Joint Conferenceon Natural Language Processing, pages 82?90.Julian Brooke and Graeme Hirst.
2013b.
A multi-dimensional bayesian approach to lexical style.
InProceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 673?679.Julian Brooke, Tong Wang, and Graeme Hirst.
2010.
Au-tomatic acquisition of lexical formality.
In Proceed-ings of the 23rd International Conference on Compu-tational Linguistics: Posters, pages 90?98.Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vin-cent J. Della Pietra, and Jenifer C. Lai.
1992.
Class-based n-gram models of natural language.
Comput.Linguist., 18(4):467?479, December.Kevyn Collins-Thompson Jamie Callan.
2004.
A lan-guage modeling approach to predicting reading diffi-culty.William Coster and David Kauchak.
2011.
Simple en-glish wikipedia: a new text simplification task.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies: short papers-Volume 2, pages 665?669.Association for Computational Linguistics.Cristian Danescu-Niculescu-Mizil, Justin Cheng, JonKleinberg, and Lillian Lee.
2012.
You had me athello: How phrasing affects memorability.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics: Long Papers-Volume1, pages 892?901.
Association for Computational Lin-guistics.Jesse Dodge, Amit Goyal, Xufeng Han, Alyssa Men-sch, Margaret Mitchell, Karl Stratos, Kota Yamaguchi,Yejin Choi, Hal Daum?e III, Alexander C. Berg, andTamara L. Berg.
2012.
Detecting visual text.
InHuman Language Technologies: Conference of theNorth American Chapter of the Association of Com-putational Linguistics, Proceedings,, pages 762?772.Philip Edmonds and Graeme Hirst.
2002.
Near-synonymy and lexical choice.
Computational linguis-tics, 28(2):105?144.Song Feng, Jun Seok Kang, Polina Kuznetsova, and YejinChoi.
2013.
Connotation lexicon: A dash of senti-ment beneath the surface meaning.
In Proceedings ofthe 51st Annual Meeting of the Association for Com-putational Linguistics, ACL, pages 1774?1784.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
PPDB: The paraphrasedatabase.
In Proceedings of NAACL-HLT, pages 758?764, Atlanta, Georgia, June.
Association for Compu-tational Linguistics.Mary Gardiner and Mark Dras.
2007.
Corpus statisticsapproaches to discriminating among near-synonyms.Stephan Greene and Philip Resnik.
2009.
More thanwords: Syntactic packaging and implicit sentiment.In Proceedings of human language technologies: The2009 annual conference of the north american chapterof the association for computational linguistics, pages503?511.
Association for Computational Linguistics.Nancy Ide, Christiane Fellbaum, Collin Baker, and Re-becca Passonneau.
2010.
The manually annotatedsub-corpus: A community resource for and by the peo-ple.
In Proceedings of the ACL 2010 conference shortpapers, pages 68?73.
Association for ComputationalLinguistics.Heng Ji and Dekang Lin.
2009.
Gender and animacyknowledge discovery from web-scale n-grams for un-supervised person mention detection.
In Proceedingsof the 23rd Pacific Asia Conference on Language, In-formation and Computation, PACLIC, pages 220?229.Tapas Kanungo and David Orr.
2009.
Predicting thereadability of short web summaries.
In Proceedingsof the Second ACM International Conference on WebSearch and Data Mining, pages 202?211.
ACM.Annie Louis and Ani Nenkova.
2013.
What makes writ-ing great?
first experiments on article quality predic-tion in the science journalism domain.
TACL, 1:341?352.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and discrimi-native training.
In HLT-NAACL 2004: Main Proceed-ings, pages 337?342.Rebecca J. Passonneau, Nancy Ide, Songqiao Su, andJesse Stuart.
2014.
Biber redux: Reconsidering di-mensions of variation in american english.
In Pro-ceedings of COLING 2014, the 25th InternationalConference on Computational Linguistics: Techni-cal Papers, pages 565?576, Dublin, Ireland, August.Dublin City University and Association for Computa-tional Linguistics.Marta Recasens, Cristian Danescu-Niculescu-Mizil, andDan Jurafsky.
2013.
Linguistic models for analyz-ing and detecting biased language.
In ACL (1), pages1650?1659.Philip Resnik.
1995.
Using information content to eval-uate semantic similarity in a taxonomy.
In Proceed-ings of the Fourteenth International Joint Conferenceon Artificial Intelligence, IJCAI, pages 448?453.Attapol Rutherford and Nianwen Xue.
2014.
Discov-ering implicit discourse relations through brown clus-ter pair representation and coreference patterns.
In223Proceedings of the 14th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, EACL, pages 645?654.Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-nan, and Ryan T. McDonald.
2010.
The viabilityof web-derived polarity lexicons.
In Human Lan-guage Technologies: Conference of the North Amer-ican Chapter of the Association of Computational Lin-guistics, Proceedings,, pages 777?785.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of the Conferenceon Human Language Technology and Empirical Meth-ods in Natural Language Processing, HLT ?05, pages347?354.Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, andColin Cherry.
2012.
Paraphrasing for style.
In COL-ING, pages 2899?2914.224
