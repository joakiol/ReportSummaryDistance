Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 73?80,New York City, June 2006. c?2006 Association for Computational LinguisticsA (very) Brief Introduction to Fluid Construction GrammarLuc Steels(1,2) and Joachim de Beule(1)(1) University of Brussels (VUB AI Lab)(2) SONY Computer Science Lab - Parissteels@arti.vub.ac.beAbstractFluid Construction Grammar (FCG) is anew linguistic formalism designed to ex-plore in how far a construction gram-mar approach can be used for handlingopen-ended grounded dialogue, i.e.
dia-logue between or with autonomous em-bodied agents about the world as experi-enced through their sensory-motor appa-ratus.
We seek scalable, open-ended lan-guage systems by giving agents both theability to use existing conventions or on-tologies, and to invent or learn new onesas the needs arise.
This paper contains abrief introduction to the key ideas behindFCG and its current status.1 IntroductionConstruction grammar is receiving growing atten-tion lately, partly because it has allowed linguiststo discuss a wide range of phenomena which weredifficult to handle in earlier frameworks (Goldberg,1995; OstmanFried, 2005; Croft, 2001), and partlybecause it has allowed psychologists to describe ina more satisfactory way early language develop-ment (TomaselloBrooks, 1999).
There were alreadysome attempts to formalise construction grammar(KayFillmore, 1999) and build a computational im-plementation (BergenChang, 2003), but many openproblems remain and at this early stage of fun-damental research, it makes sense to explore al-ternative approaches.
In our team, we focus onopen-ended grounded dialogue, in other words howit is possible for a speaker to formulate an utter-ance about the world and for a hearer to under-stand what is meant (ClarkBrennan, 1991).
Thepresent paper briefly reports on the formalisationof construction grammar called Fluid Construc-tion Grammar (FCG) that we have developed forthis research.
Although the formalism is novel inseveral fundamental aspects, it also builds heav-ily on the state of the art in formal and computa-tional linguistics, particularly within the tradition ofunification-based feature structure grammars such asHPSG (PollardSag, 1994).
FCG has been under de-velopment from around 2001 and an implementa-tion on a LISP substrate has been released throughhttp://arti.vub.ac.be/FCG/ in 2005.
The FCG coreengine (for parsing and production) is fully opera-tional and has already been used in some large-scaleexperiments in language grounding (SteelsLoetzsch,2006).
We do not claim to have a complete solu-tion for all linguistic issues that arise in constructiongrammar, and neither do we claim that the solutionswe have adopted so far are final.
On the contrary, weare aware of many difficult technical issues that stillremain unresolved and welcome any discussion thatwould bring us forward.2 MotivationsFCG grew out of efforts to understand the creativebasis of language.
Language creativity is more thanthe application of an existing set of rules (even ifthe rules are recursive and thus allow an infinite setof possible sentences).
Human language users oftenstretch and expand rules whenever the need arises,73Figure 1: Typical experimental setup.
The bot-tom shows two robots moving around in an envi-ronment that contains balls and boxes.
The robotsare equiped with a complex sensory-motor system,able to detect the objects and build an analog worldmodel of their location and trajectories (as shown inthe right top corner).and occasionally invent totally new ones.
So weneed to understand how new aspects of language(new concepts and conceptualisations, new lexicalitems, new syntactic and semantic categories, newgrammatical constructions, new interaction patterns)may arise and spread in a population, the same waybiologists try to understand how new life forms mayarise (Steels, 2003).This motivation leads immediately to some require-ments.
First of all we always use multi-agent sim-ulations so that we can investigate the spreading ofconventions in a population.
Agents take turns be-ing speaker and hearer and build up competences inconceptualisation and verbalisation (for production)and parsing and interpretation (for understanding).They must be able to store an inventory of rules andapply them in either processing direction, and theymust be able to expand their inventories both by in-venting new constructions if necessary and by adopt-ing those used by others.
Second, the agents musthave something to talk about.
We are interested ingrounded language, which means dialogue about ob-jects and events in the world as perceived through asensory-motor apparatus.
We take embodiment lit-erally.
Our experiments use physical robots (SonyAIBOs) located in a real world environment (see fig-ure 1 from (SteelsLoetzsch, 2006)) Third, the agentsmust be motivated to say and learn something.
Weachieve this by programming the robots with scriptsto play language games.
A language game sets upa joint attentional frame so that robots share gen-eral motives for interaction, a specific communica-tive goal (for example draw attention to an object),and give feedback to enable repair of miscommu-nication (for example through pointing).
We typi-cally perform experiments in which a population ofagents starts with empty conceptual and linguisticrepertoires and then builds from scratch a communi-cation system that is adequate for a particular kind oflanguage game.
Agents seek to maximise commu-nicative success while minimising cognitive effort.One advantage of grounded language experimentsis that we can clearly monitor whether the capaci-ties given to the agents are adequate for bootstrap-ping a language system and how efficient and suc-cessful they are.
By starting from scratch, we canalso test whether our objective of understanding lan-guage creativity has been achieved.
Of course suchexperiments will never spontaneously lead to theemergence of English or any other human language,but we can learn a great deal about the processes thathave given rise and are still shaping such languages.3 MeaningThe information about an utterance is organized ina semantic and a syntactic structure.
The seman-tic structure is a decomposition of the utterance?smeaning and contains language-specific semanticre-categorisations (for example a put-event is cate-gorised as a cause-move-location with an agent, apatient and a location).
The syntactic structure isa decomposition of the form of the utterance intoconstituents and morphemes and contains additionalsyntactic categorisations such as syntactic features(like number and gender), word order constraints,etc.We follow a procedural semantics approach, in thesense that the meaning of an utterance is a programthat the hearer is assumed to execute (Winograd,1972; Johnson-Laird, 1997).
Hence conceptualisa-tion becomes a planning process (to plan the pro-gram) and interpretation becomes the execution ofa program.
For example, the meaning of a phraselike ?the box?
is taken to be a program that in-volves the application of an image schema to theflow of perceptual images and anchor it to a partic-74ular physical object in the scene.
So we do not as-sume some pre-defined or pre-processed logic-stylefact base containing the present status of the world(as this is extremely difficult to extract and main-tain from real world perception in a noisy and fastchanging world) but view language as playing anactive role in how the world is perceived and cate-gorised.
It is in principle possible to use many dif-ferent programming languages, but we have optedfor constraint based processing and designed a newconstraint programming language IRL (IncrementalRecruitment Language) and implemented the neces-sary planning, chunking and execution mechanismsof constraint networks (SteelsBleys, 2005).
A sim-ple example of a constraint network for ?the box?
isas follows1:1.
(equal-to-context ?s)2.
(filter-set-prototype ?r ?s ?p)3.
(prototype ?p [box])4.
(select-element ?o ?r ?d)5.
(determiner ?d [single-unique])Equal-to-context, select-element,etc.
are primitive constraints that implement funda-mental cognitive operators.
Equal-to-contextgrabs the set of elements in the current contextand binds it to ?s.
Filter-set-prototypefilters this set with a prototype ?p which is boundin (3) to [box].
Select-element selects anelement ?o from ?r according to the determiner?d which is bound to [single-unique] in(5), meaning that ?r should be a singleton.
Theconstraints are powerful enough to be used both ininterpretation, when semantic objects such as pro-totypes, determiners, categories, relations, etc.
aresupplied through language and values need to befound for other variables, and in conceptualisation,when these values are known but the objective isto find the semantic objects.
Moreover, duringconceptualization the constraints may extend therepertoire of semantic objects (e.g.
introducing anew prototype) if needed, allowing the agents toprogressively build up their ontologies.1We use prefix notation.
Order does not play a role as theconstraint interpreter cycles through the network until all vari-ables are bound or until no further progress can be made.
Sym-bols starting with a question mark represent variables.Figure 2: Left: decomposition of the constraint pro-gram for ?the ball?
in the semantic structure.
Right:related syntactic structure.
In reality both structurescontain a lot more information.4 Syntactic and Semantic StructuresAs mentioned, FCG organises the information aboutan utterance in feature structures, similar to otherfeature-structure based formalisms (as first intro-duced by Kay (Kay, 1984)) but with some impor-tant differences.
An FCG feature structure containsunits which correspond (roughly) to words (moreprecisely morphemes) and constituents.A unit has a name and a set of features.
Hierarchicalstructure is not implicitly represented by embeddingone unit in another one, but explicitly by the fea-tures syn-subunits (for the syntactic structure) andsem-subunits (for the semantic structure).
There is astrong correspondence between the syntactic and se-mantic structure built up for the same utterance (seefigure 2) although there can be units which only ap-pear in the syntactic structure (for example for gram-matical function words) and vice versa.
The cor-respondence is maintained by using the same unitnames in both the semantic and syntactic structure.Units in syntactic structures have three features: (1)syn-subunits, (2) syn-cat which contains the syn-tactic categories, and (3) form containing the formassociated with the unit.
Units in semantic struc-tures have four features: (1) sem-subunits, (2) sem-cat containing the semantic categories, (3) meaningwhich is the part of the utterance?s meaning coveredby the unit, and (4) context which contains variablesthat occur in the meaning but are ?external?
in thesense that they are linked to variables occurring inthe meaning of other units.
An example semanticstructure (in list-notation) for the left structure infigure 2 is shown in figure 3.
FCG is a completelyopen-ended formalism in the sense that all linguistic75Figure 3: Semantic structure in list-notation.categories (syntactic or semantic) are open and inprinciple language-specific (as in radical construc-tion grammar (Croft, 2001).)
Thus the set of lexicalcategories (noun, verb, adjective, etc.
), of possiblesemantic roles (agent, patient, etc.
), of syntactic fea-tures (number, gender, politeness, etc.
), and so on,are all open.
The value of the syn-cat and sem-catfeatures consists of a conjunction of predicates (eachpossibly having arguments.)
New categories can beintroduced at any time and used as (part of) a pred-icate.
The form of the utterance is described in adeclarative manner, using predicates like precedes ormeets which define linear ordering relations amongthe form of units or any other aspect of surface formincluding prosodic contour or stress.5 RulesA rule (also called template) typically expressesconstraints on possible meaning-form mappings.Each rule has a score which reflects the successthat the agent has had in using it.
All else be-ing equal, agents prefer rules with higher scores,thus reflecting frequency effects.
A rule has twopoles.
A left pole which typically contains con-straints on semantic structure formulated as a fea-ture structure with variables, and a right pole whichtypically contains constraints on syntactic structureagain formulated as a feature structure with vari-ables.
Rules are divided into rule subsets whichhelp constrain the order of rule-application and de-sign large-scale grammars.
Thus we make a distinc-tion between morph-rules, which decompose a wordinto a stem and pending morphemes and introducesyntactic categories; lex-stem-rules, which associatemeaning with the stem as well as valence informa-tion and a role-frame; con-rules, which correspondto grammatical constructions that associate parts ofsemantic structure with parts of syntactic structure;and sem and syn-rules which perform inference oversemantic or syntactic categories to expand semanticor syntactic structure.All rules are bi-directional.
Typically, during pro-duction, the left pole is ?unified?
with the semanticstructure under construction, possibly yielding a setof bindings.
If successful, the right pole is ?merged?with the syntactic structure under construction.
Themerge operation can be understood as a partial uni-fication, but extending the structure with those partsof the pole that were missing.
During parsing, theright pole is unified with the syntactic structure andparts of the left pole are added to the semanticstructure.
The unification phase is thus used to seewhether a rule is triggered and the merge phase rep-resents the actual application of the rule.
The FCGUnify and Merge operators are defined in great for-mal detail in (SteelsDeBeule, 2006).
During pro-duction lex-stem-rules are applied before the con-rules and the morph-rules.
During parsing the lex-stem-rules are applied right after the morph-rules.The con-rules then build higher order structure.
Itis enormously challenging to write rules that workin both directions but this strong constraint is veryhelpful to achieve a compact powerful grammar.6 Building HierarchyOne of the innovative aspects of FCG is the way ithandles hierarchy.
Both the left-pole and the right-pole of a construction can introduce hierarchicalstructure with the J-operator (DeBeuleSteels, 2005).This way, the semantic pole of constructions (lexicalor grammatical) can decompose the meaning to beexpressed (which originally resides in the top nodeof the semantic structure) and the syntactic pole cangroup units together into a larger constituent.
Con-straints governed by the J-operator do not have tomatch during the unification phase.
Instead they areused to build additional structure during the merge76Figure 4: Example lexical entry for ?put?
and illus-tration of the J-operator.phase.
This may include the construction of a newunit as well as pending from an existing unit and ab-sorbing some other units.Figure 4 shows an example which will be used fur-ther in the next section.
It is a lexical rule prepar-ing a resultative construction (GoldbergJackendoff,2004).
The semantic pole of the rule combinessome stretch of meaning (the introduction of anevent-type, namely a put-event) with a frame (cause-move-location with roles for agent, patient and loca-tion).
These are associated with a lexical stem ?put?in the right pole which also adds a valence frameSVOL (triggering the subject-verb-object-locationconstruction).
In production, this rule triggers whena ?put?
event-type is part of the meaning (?==?
means?includes but may also contain additional expres-sions?).
When merging the semantic pole with thesemantic structure, a new unit hanging from ?top iscreated and the specified value of the meaning fea-ture copied down.
The new unit also receives thecontext and sem-cat features as specified by the J-operator.
At the same time, the syntactic pole ismerged with the syntactic structure and so the ?new-unit (which is already bound) is added as a subunitof ?top in the syntactic structure as well.
The J-operator will then add stem and valence informa-tion.
Thus the semantic structure of figure 5 willbe transformed into the one of figure 6.
And the cor-responding syntactic structure becomes as in figure7.
In parsing, an existing syntactic unit with stem((unit-2(meaning( ..(event-type ev-type1(put (put-1 o1) (put-2 o11)(put-3 o22))) ... ))))Figure 5: Semantic structure triggering the rule infigure 4 in production.
((unit-2(sem-subunits (... unit-3 ...)))(unit-3(meaning((event-typeev-type1(put (put-1 o1) (put-2 o11)(put-3 o22)))))(context ((link ev-type1)))(sem-cat((sem-event-typeev-type1(cause-move-location(agent o1) (patient o11)(location o22))))))... )Figure 6: Resulting semantic structure after apply-ing the rule in figure 4 to the semantic structure offigure 5.
((unit-2(syn-subunits (... unit-3 ...)))(unit-3(form ((stem unit-3 "put")))(syn-cat ((valence SVOL))))... )Figure 7: Resulting syntactic structure after apply-ing the rule in figure 4.?put?
is required to trigger the rule.
If found, therule will add the valence information to it and on77the semantic side the meaning as well as the seman-tic categorisation in terms of a cause-move-locationframe are added.7 Implementing ConstructionsLexical constructions provide frame and valence in-formation for word stems and parts of meaning.Grammatical constructions bind all this together.Figure 8 shows an example of a grammatical con-struction.
It also uses the J-operator to build hier-archy, both on the semantic side (to decompose oradd meaning) and on the syntactic side (to groupconstituents together.)
An example of a SVOL-construct is Mary puts the milk in the refrigerator.Before application of the construction, various unitsshould already group together the words making upa nounphrase for the subject (which will be boundto ?subject-unit), a nounphrase for the direct object(bound to the ?object-unit) and a prepositional noun-phrase (bound to ?oblique-unit).
Each of these unitsalso will bind variables to their referents, commu-nicated as context to the others.
On the semanticside the cause-move-location frame with its variousroles aids to make sure that all the right variablebindings are established.
On the syntactic side theconstruction imposes word-order constraints (ex-pressed with the meets-predicate), the valence of theverb, and specific types of constituents (nounphrase,verbphrase, prepositional nounphrase).
The SVOLconstruction operates again in two directions.
Inproduction it is triggered when the semantic struc-ture built so far unifies with the semantic pole, andthen the syntactic structure is expanded with themissing parts from the syntactic pole.
Constraintson the syntactic pole (e.g.
valence) may preventthe application of the construction.
In parsing, theSVOL construction is triggered when the syntacticstructure built so far unifies with the syntactic poleand the semantic structure is then expanded with themissing parts from the semantic pole.
Again ap-plication may be constrained when semantic con-straints in the construction prevent it.8 Fluidity, Conventionalisation andMeta-grammarsAlthough FCG must become adequate for dealingwith the typical phenomena that we find in humannatural languages, our main target is to make scien-tific models of the processes that underly the originsof language, in other words of the creative processby which language users adapt or invent new formsto express newmeanings that unavoidably arise in anopen world and negotiate tacitly the conventions thatthey adopt as a group.
We have already carried outa number of experiments in this direction and hereonly a brief summary can be given (for more dis-cussion see: (Steels, 2004; DeBeuleBergen, 2006;SteelsLoetzsch, 2006)).In our experiments, speaker and hearer are cho-sen randomly from a population to play a languagegame as part of a situated embodied interaction thatinvolves perception, joint attention and feedback.When the speaker conceptualizes the scene, he mayconstruct new semantic objects (for example newcategories) or recruit new constraint networks inorder to achieve the communicative goal imposedby the game.
Also when the speaker is trying toverbalise the constraint network that constitutes themeaning of an utterance, there may be lexical itemsmissing or new constructions may have to be built.We use a meta-level architecture with reflection toorganise this process.
The speaker goes through thenormal processing steps, using whatever inventory isavailable.
Missing items may accumulate and thenthe speaker moves to a meta-level, trying to repairthe utterance by stretching existing constructions,re-using them by analogy for new purposes, or in-troducing other linguistic items.
The speaker alsoengages in self-monitoring by re-entering the utter-ance and comparing what he meant to say to inter-pretations derived by parsing his own utterance.
Thespeaker can thus detect potential problems for thelistener such as combinatorial explosions in pars-ing, equalities among variables which were not ex-pressed, etc.
and these problems can be repaired bythe introduction of additional rules.The hearer receives an utterance and tries to go asfar as possible in the understanding process.
Theparser and interpreter are not geared towards check-ing for grammaticality but capable to handle utter-ances even if a large part of the rules are missing.The (partial) meaning is then used to arrive at an in-terpretation, aided by the fact that the context andcommunicative goals are restricted by the languagegame.
If possible, the hearer gives feedback on how78he understood the utterance and whether an interpre-tation was found.
If there is failure or miscommuni-cation the hearer will then repair his inventory basedon extra information provided by the speaker.
Thiscan imply the introduction of new concepts extend-ing the ontology, storing new lexical items, intro-ducing new constructions, assigning certain wordsto new syntactic classes, etc.
Speaker and heareralso update the scores of all rules and concepts.
Incase of success, scores go up of the items that wereused and competitors are decreased to achieve lat-eral inhibition and hence a positive feedback loopbetween success and use.
In case of failure, scoresgo down so that the likelihood of using the failingsolution diminishes.
In our simulations, games areplayed consecutively by members of a populationand we have been able to show ?so far for relativelysimple forms of language?
that shared communi-cation systems can emerge from scratch in popula-tions.
Much work remains to be done in researchingthe repair strategies needed and when they should betriggered.
The repair strategies themselves shouldalso be the subject of negotiation among the agentsbecause they make use of a meta-grammar that de-scribes in terms of rules (with the same syntax andprocessing as the FCG rules discussed here) how re-pairs are to be achieved.9 ConclusionsFCG is a tool offered to the community of re-searchers interested in construction grammar.
It al-lows the precise formal definition of constructions ina unification-based feature structure grammar styleand contains the necessary complex machinery forbuilding an utterance starting from meaning andreconstructing meaning starting from an utterance.FCG does not make linguistic theorising superflu-ous, on the contrary, the formalism is open to anyframework of linguistic categories or organisationof grammatical knowledge as long as a constructiongrammar framework is adopted.
There is obviouslya lot more to say, not only about how we handlevarious linguistic phenomena (such as inheritanceof properties by a parent phrasal unit from its headsubunit) but also what learning operators can pro-gressively build fluid construction grammars drivenby the needs of communication.
We refer the readerto the growing number of papers that provide moredetails on these various aspects.10 AcknowledgementThis research was conducted at the Sony ComputerScience Laboratory in Paris and the University ofBrussels VUB Artificial Intelligence Laboratory.
Itis partially sponsored by the EU ECAgents project(FET IST-1940).
FCG and the experiments in lan-guage evolution are team work and major contribu-tions were made by Joris Bleys, Martin Loetzsch,Nicolas Neubauer, Wouter Van den Broeck, RemyVan Trijp, and Pieter Wellens.ReferencesBergen, B.K.
and N.C. Chang.
(2003) Embodied Con-struction Grammar in Simulation-Based LanguageUnderstanding.
Technical Report 02-004, Interna-tional Computer Science Institute, Berkeley.Clark, H. and S. Brennan (1991) Grounding in com-munication.
In: Resnick, L. J. Levine and S.
Teasley(eds.)
Perspectives on Socially Shared Cognition.
APABooks, Washington.
p. 127-149.Croft, William A.
(2001).
Radical Construction Gram-mar; Syntactic Theory in Typological Perspective.
Ox-ford: Oxford University Press.De Beule, J. and L. Steels (2005) Hierarchy in FluidConstruction Grammar.
In: Furbach, U.
(eds) (2005)Proceedings of KI-2005.
Lecture Notes in AI 3698.Springer-Verlag, Berlin.
p.1-15.De Beule, J. and B. Bergen (2006) On the Emergenceof Compositionality.
Proceedings of the Evolution ofLanguage Conference VI, Rome.Goldberg, A.E.
(1995) Constructions.
: A ConstructionGrammar Approach to Argument Structure.
Univer-sity of Chicago Press, ChicagoGoldberg, A. and R. Jackendoff (2004) The English Re-sultative as a Family of Constructions.
Language 80532-568.Johnson-Laird, P.N.
(1997) Procedural Semantics.
Cog-nition, 5 (1977) 189-214.Goldberg, A.
(2003) Constructions: A new theoreticalapproach to language Trends in Cognitive Science.Volume 7, Issue 5, May 2003 , pp.
219-224.Kay, P. and C. Fillmore (1999) Grammatical construc-tions and linguistic generalizations: the Whats X do-ing Y?
construction.
Language 75(1), 133.79Kay, M. (1984) Functional unification grammar: A for-malism for machine translation.
Proceedings of theInternational Conference of Computational Linguis-tics.Pollard, C.and I.
Sag (1994) Head-driven Phrase Struc-ture Grammar.
CSLI Stanford Univ, Calif.Ostman, Jan-Ola and Mirjam Fried (eds.)
(2005) Con-struction Grammars: Cognitive grounding and theo-retical extensions.
W. Benjamins, Amsterdam.Steels, L. (2003) Evolving grounded communication forrobots.
Trends in Cognitive Science.
Volume 7, Issue7, July 2003 , pp.
308-312.Steels, L. (2004) Constructivist Development ofGrounded Construction Grammars.
In D. Scott, W.Daelemans and M. Walker (Eds.
), Proceedings AnnualMeeting of Association for Computational LinguisticsConference.
Barcelona: ACL , (pp.
9-16).Steels, L. and J.
De Beule (2006) Unify and Merge inFCG.
In: Vogt, P. et.al.
(eds.)
Proceedings of EELC III.Lecture Notes in Computer Science.
Springer-Verlag,Berlin.Steels, L. and J. Bleys (2005) PlanningWhat To Say: Sec-ond Order Semantics for Fluid Construction Gram-mars.
In: Proceedings of CAEPIA 2005.
Santiago deCompostella.Steels, L. and M. Loetzsch (2006) Perspective Alignmentin Spatial Language.
In: Coventry, K., J. Batemanand T. Tenbrink (2006) Spatial Language in Dialogue.Oxford University Press.
Oxford.Tomasello, M. and P.J.
Brooks (1999) Early syntacticdevelopment: A Construction Grammar approach In:Barrett, M.
(ed.)
(1999) The Development of LanguagePsychology Press, London.
pp.
161-190.Winograd, T. (1972) Understanding natural language.New York, Academic Press.
(def-con-rule SVOL-Phrase((?top(sem-subunits(== ?subject-unit ?verb-unit?object-unit ?oblique-unit)))(?subject-unit(context (== (link ?subject))))(?verb-unit(context (== (link ?event ?event-type)))(sem-cat(== (sem-event-type ?event-type(cause-move-location(agent ?subject)(patient ?object)(location ?oblique))))))(?object-unit(context (== (link ?object))))(?oblique-unit(context (== (link ?oblique))))((J ?new-unit ?top(?subject-unit ?verb-unit?object-unit ?oblique-unit))(context (== (link ?event)))))<-->((?top(form(==(meets ?subject-unit ?verb-unit)(meets ?verb-unit ?object-unit)(meets ?object-unit?oblique-unit)))(syn-subunits(== ?subject-unit ?verb-unit?object-unit ?oblique-unit)))(?subject-unit(syn-cat(== (constituent NounPhrase))))(?verb-unit(syn-cat(== (constituent VerbPhrase)(valence SVOL))))(?object-unit(syn-cat(== (constituent NounPhrase))))(?oblique-unit(syn-cat(== (constituent PrepNounPhrase))))((J ?new-unit ?top(?subject-unit ?verb-unit?object-unit ?oblique-unit))(syn-cat(== (constituent sentence))))))Figure 8: A resultative construction.80
