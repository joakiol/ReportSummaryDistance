Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
306?314, Prague, June 2007. c?2007 Association for Computational LinguisticsProbabilistic Coordination Disambiguationin a Fully-lexicalized Japanese ParserDaisuke KawaharaNational Institute of Information andCommunications Technology,3-5 Hikaridai Seika-cho, Soraku-gun,Kyoto, 619-0289, Japandk@nict.go.jpSadao KurohashiGraduate School of Informatics,Kyoto University,Yoshida-Honmachi, Sakyo-ku,Kyoto, 606-8501, Japankuro@i.kyoto-u.ac.jpAbstractThis paper describes a probabilistic modelfor coordination disambiguation integratedinto syntactic and case structure analy-sis.
Our model probabilistically assessesthe parallelism of a candidate coordinatestructure using syntactic/semantic similari-ties and cooccurrence statistics.
We inte-grate these probabilities into the frameworkof fully-lexicalized parsing based on large-scale case frames.
This approach simulta-neously addresses two tasks of coordinationdisambiguation: the detection of coordinateconjunctions and the scope disambiguationof coordinate structures.
Experimental re-sults on web sentences indicate the effective-ness of our approach.1 IntroductionCoordinate structures are a potential source of syn-tactic ambiguity in natural language.
Since their in-terpretation directly affects the meaning of the text,their disambiguation is important for natural lan-guage understanding.Coordination disambiguation consists of the fol-lowing two tasks:?
the detection of coordinate conjunctions,?
and finding the scope of coordinate structures.In English, for example, coordinate structures aretriggered by coordinate conjunctions, such as andand or.
In a coordinate structure that consists ofmore than two conjuncts, commas, which have var-ious usages, also function like coordinate conjunc-tions.
Recognizing true coordinate conjunctionsfrom such possible coordinate conjunctions is a taskof coordination disambiguation (Kurohashi, 1995).The other is the task of identifying the range of co-ordinate phrases or clauses.Previous work on coordination disambiguationhas focused on the task of addressing the scope am-biguity (e.g., (Agarwal and Boggess, 1992; Gold-berg, 1999; Resnik, 1999; Chantree et al, 2005)).Kurohashi and Nagao proposed a similarity-basedmethod to resolve both of the two tasks for Japanese(Kurohashi and Nagao, 1994).
Their method, how-ever, heuristically detects coordinate conjunctionsby considering only similarities between possibleconjuncts, and thus cannot disambiguate the follow-ing cases1:(1) a. kanojo-toshe-cmigakkou-nischool-accittawent(?
went to school with her)b. kanojo-toshe-cnjwatashi-gaI-nomgoukaku-shitapassed an exam(she and I passed an exam)In sentence (1a), postposition ?to?
is used as a comi-tative case marker, but in sentence (1b), postposition?to?
is used as a coordinate conjunction.To resolve this ambiguity, predicative case framesare required.
Case frames describe what kinds of1In this paper, we use the following abbreviations:nom (nominative), acc (accusative), abl (ablative), cmi (comi-tative), cnj (conjunction) and TM (topic marker).306Table 1: Case frame examples (Examples are writ-ten in English.
Numbers following each examplerepresent its frequency.
).CS Examplesga I:18, person:15, craftsman:10, ?
?
?yaku (1) wo bread:2484, meat:1521, cake:1283, ?
?
?
(broil) de oven:1630, frying pan:1311, ?
?
?yaku (2) ga teacher:3, government:3, person:3, ?
?
?
(have wo fingers:2950difficulty) ni attack:18, action:15, son:15, ?
?
?ga maker:1, distributor:1yaku (3) wo data:178, file:107, copy:9, ?
?
?
(burn) ni R:1583, CD:664, CDR:3, ?
?
?.........ga dolphin:142, student:50, fish:28, ?
?
?oyogu (1) wo sea:1188, underwater:281, ?
?
?
(swim) de crawl:86, breaststroke:49, stroke:24, ?
?
?.........ga I:4, man:4, person:4, ?
?
?migaku (1) wo tooth:5959, molar:27, foretooth:12(brush) de brush:38, salt:13, powder:12, ?
?
?.........nouns are related to each predicate.
For example, acase frame of ?iku?
(go) has a ?to?
case slot filledwith the examples such as ?kanojo?
(she) or human.On the other hand, ?goukaku-suru?
(pass an exam)does not have a ?to?
case slot but does have a ?ga?case slot filled with ?kanojo?
(she) and ?watashi?(I).
These case frames provide the information fordisambiguating the postpositions ?to?
in sentences(1a) and (1b): (1a) is not coordinate and (1b) is co-ordinate.This paper proposes a method for integrating co-ordination disambiguation into probabilistic syntac-tic and case structure analysis.
This method simul-taneously addresses the two tasks of coordinationdisambiguation by utilizing syntactic/semantic par-allelism in possible coordinate structures and lexi-cal preferences in large-scale case frames.
We usethe case frames that were automatically constructedfrom the web (Table 1).
In addition, cooccurrencestatistics of coordinate conjuncts are incorporatedinto this model.2 Related WorkPrevious work on coordination disambiguation hasfocused mainly on finding the scope of coordinatestructures.Agarwal and Boggess proposed a method foridentifying coordinate conjuncts (Agarwal andBoggess, 1992).
Their method simply matches partsof speech and hand-crafted semantic tags of thehead words of the coordinate conjuncts.
They testedtheir method using the Merck Veterinary Manualand found their method had an accuracy of 81.6%.Resnik described a similarity-based approach forcoordination disambiguation of nominal compounds(Resnik, 1999).
He proposed a similarity measurebased on the notion of shared information content.He conducted several experiments using the PennTreebank and reported an F-measure of approxi-mately 70%.Goldberg applied a cooccurrence-based proba-bilistic model to determine the attachments of am-biguous coordinate phrases with the form ?n1 p n2cc n3?
(Goldberg, 1999).
She collected approxi-mately 120K unambiguous pairs of two coordinatewords from a raw newspaper corpus for a one-yearperiod and estimated parameters from these statis-tics.
Her method achieved an accuracy of 72% usingthe Penn Treebank.Chantree et al presented a binary classifier for co-ordination ambiguity (Chantree et al, 2005).
Theirmodel is based on word distribution informationobtained from the British National Corpus.
Theyachieved an F-measure (?
= 0.25) of 47.4% usingtheir own test set.The previously described methods focused on co-ordination disambiguation.
Some research has beenundertaken that integrated coordination disambigua-tion into parsing.Kurohashi and Nagao proposed a Japanese pars-ing method that included coordinate structure detec-tion (Kurohashi and Nagao, 1994).
Their methodfirst detects coordinate structures in a sentence, andthen heuristically determines the dependency struc-ture of the sentence under the constraints of the de-tected coordinate structures.
Their method correctlyanalyzed 97 Japanese sentences out of 150.Charniak and Johnson used some features of syn-tactic parallelism in coordinate structures for theirMaxEnt reranking parser (Charniak and Johnson,2005).
The reranker achieved an F-measure of91.0%, which is higher than that of their genera-tive parser (89.7%).
However, they used a numer-ous number of features, and the contribution of the307Table 2: Expressions that indicate coordinate struc-tures.
(a) coordinate noun phrase:,(comma) to ya toka katsu oyobi ka aruiwa ...(b) coordinate predicative clause:-shi ga oyobi ka aruiwa matawa ...(c) incomplete coordinate structure:,(comma) oyobi narabini aruiwa ...parallelism features is unknown.Dubey et al proposed an unlexicalized PCFGparser that modified PCFG probabilities to condi-tion the existence of syntactic parallelism (Dubeyet al, 2006).
They obtained an F-measure increaseof 0.4% over their baseline parser (73.0%).
Experi-ments with a lexicalized parser were not conductedin their work.A number of machine learning-based approachesto Japanese parsing have been developed.
Amongthem, the best parsers are the SVM-based depen-dency analyzers (Kudo and Matsumoto, 2002; Sas-sano, 2004).
In particular, Sassano added some fea-tures to improve his parser by enabling it to detectcoordinate structures (Sassano, 2004).
However, theadded features did not contribute to improving theparsing accuracy.
This failure can be attributed tothe inability to consider global parallelism.3 Coordination Ambiguity in JapaneseIn Japanese, the bunsetsu is a basic unit of depen-dency that consists of one or more content words andthe following zero or more function words.
A bun-setsu corresponds to a base phrase in English and?eojeol?
in Korean.Coordinate structures in Japanese are classifiedinto three types.
The first type is the coordinate nounphrase.
(2) nagailongenpitsu-topencil-cnjkeshigomu-woeraser-acckattabought(bought a long pencil and an eraser)We can find these phrases by referring to the wordslisted in Table 2-a.The second type is the coordinate predicativeclause, in which two or more predicates form a co-ordinate structure.bnAn: Partial matrixA = (a(i, j))Coordination key bunsetsua(n, m)a(pm-n, n+1)a pathSimilarity betweenbn and bmFigure 1: Method using triangular matrix.
(3) kanojo-toshe-cmikekkon-shimarriedie-wohouse-acckattabought(married her and bought a house)We can find these clauses by referring to the wordsand ending forms listed in Table 2-b.The third type is the incomplete coordinate struc-ture, in which some parts of coordinate predicativeclauses are present.
(4) Tom-waTom-TMinu-wo,dog-accJim-waJim-TMneko-wocat-acckaubuys(Tom (buys) a dog, and Jim buys a cat)We can find these structures by referring to thewords listed in Table 2-c and also the correspon-dence of case-marking postpositions.For all of these types, we can detect the possibilityof a coordinate structure by looking for a coordina-tion key bunsetsu that accompanies one of the wordslisted in Table 2 (in total, we have 52 coordinationexpressions).
That is to say, the left and right sides ofa coordination key bunsetsu constitute possible pre-and post-conjuncts, and the key bunsetsu is locatedat the end of the pre-conjunct.
The size of the con-juncts corresponds to the scope of the coordination.4 Calculating Similarity between PossibleCoordinate ConjunctsWe assess the parallelism of potential coordinatestructures in a probabilistic parsing model.
In this308puroguramingu gengo-wa 2 2 0 2 2 2 0 0 2 0 (prog.
language)mondai kaiketsu-no 2 0 2 4 2 0 0 2 0 (problem solution)arugorizumu-wo 0 2 2 4 0 0 2 0 (algorithm)hyogen dekiru 0 0 0 2 4 0 2 (can express)kijutsuryoku-to 2 2 0 0 2 0 (descriptive power)keisanki-no 2 0 0 2 0 (computer)kinou-wo 0 0 2 0 (function)jubun-ni 2 0 2 (sufficiently)kudou dekiru 0 2 (can drive)wakugumi-ga 0 (framework)hitsuyou-dearu.
(require)(Programming language requires descriptive power to express an algorithm forsolving problems and a framework to sufficiently drive functions of a computer.
)post-conjunctpre-conjunctFigure 2: Example of calculating path scores.section, we describe a method for calculating simi-larities between potential coordinate conjuncts.To measure the similarity between potential pre-and post-conjuncts, a lot of work on the coordi-nation disambiguation used the similarity betweenconjoined heads.
However, not only the conjoinedheads but also other components in conjuncts havesome similarity and furthermore structural paral-lelism.
Therefore, we use a method to calculate thesimilarity between two whole coordinate conjuncts(Kurohashi and Nagao, 1994).
The remainder of thissection contains a brief description of this method.To calculate similarity between two series of bun-setsus, a triangular matrix, A, is used (illustrated inFigure 1).A = (a(i, j)) (0 ?
i ?
l; i ?
j ?
l) (1)where l is the number of bunsetsus in a sentence,diagonal element a(i, j) is the i-th bunsetsu, and el-ement a(i, j) (i < j) is the similarity value betweenbunsetsus bi and bj .
A similarity value betweentwo bunsetsus is calculated on the basis of POSmatching, exact word matching, and their semanticcloseness in a thesaurus tree (Kurohashi and Nagao,1994).
We use the Bunruigoihyo thesaurus, whichcontains 96,000 Japanese words (The National In-stitute for Japanese Language, 2004).To detect a coordinate structure involving a keybunsetsu, bn, we consider only a partial matrix (de-noted An), that is, the upper right part of bn (Figure1).An = (a(i, j)) (0 ?
i ?
n;n + 1 ?
j ?
l) (2)To specify correspondences between bunsetsus inpotential pre- and post-conjuncts, a path is definedas follows:path ::= (a(p1,m), a(p2,m?
1), .
.
.
,a(pm?n, n + 1)) (3)where n+1 ?
m ?
l, a(p1,m) 6= 0, p1 = n, pi ?pi+1, (1 ?
i ?
m?
n?
1).That is, a path represents a series of elements froma non-zero element in the lowest row in An to anelement in the leftmost column in An.
The path hasan only element in each column and extends towardthe upper left.
The series of bunsetsus on the left sideof the path and the series under the path are potentialconjuncts for key bn.
Figure 2 shows an example ofa path.A path score is defined based on the following cri-teria:?
the sum of each element?s points on the path?
penalty points when the path extends non-diagonally (which causes conjuncts of unbal-anced lengths)?
bonus points on expressions signaling the be-ginning or ending of a coordinate structure,such as ?kaku?
(each) and nado?
(and so on)?
the total score of the above criteria is dividedby the square root of the number of bunsetsuscovered by the path for normalizationThe score of each path is calculated using a dy-namic programming method.
We consider each pathas a candidate of pre- and post-conjuncts.3095 Integrated Probabilistic Model forSyntactic, Coordinate and CaseStructure AnalysisThis section describes a method of integrating coor-dination disambiguation into a probabilistic parsingmodel.
The integrated model is based on a fully-lexicalized probabilistic model for Japanese syntac-tic and case structure analysis (Kawahara and Kuro-hashi, 2006b).5.1 Outline of the ModelThis model gives a probability to each possible de-pendency structure, T , and case structure, L, of theinput sentence, S, and outputs the syntactic, coordi-nate and case structure that have the highest proba-bility.
That is to say, the model selects the syntacticstructure, T best, and the case structure, Lbest, thatmaximize the probability, P (T,L|S):(T best, Lbest) = argmax (T,L)P (T,L|S)= argmax (T,L)P (T,L, S)P (S)= argmax (T,L)P (T,L, S) (4)The last equation is derived because P (S) is con-stant.The model considers a clause as a generation unitand generates the input sentence from the end of thesentence in turn.
The probability P (T,L, S) is de-fined as the product of probabilities for generatingclause Ci as follows:P (T,L, S) =?i=1..nP (Ci, relihi |Chi) (5)where n is the number of clauses in S, Chi is Ci?smodifying clause, and relihi is the dependency re-lation between Ci and Chi .
The main clause, Cn,at the end of a sentence does not have a modify-ing head, but a virtual clause Chn = EOS (End OfSentence) is inserted.
Dependency relation relihi isfirst classified into two types C (coordinate) and D(normal dependency), and C is further divided intofive classes according to the binned similarity (pathscore) of conjuncts.
Therefore, relihi can be one ofthe following six classes.relihi = {D,C0, C1, C2, C3, C4} (6)For instance, C0 represents a coordinate relationwith a similarity of less than 1, and C4 representsa coordinate relation with a similarity of 4 or more.bentou-watabete-tekaet-ta(go home)bentou-watabete-tekaet-ta(go home) EOSEOS)|,( EOSDtakaetP ?
)|,( EOSDtakaetwabentouP ??
)|,( takaetDtetabewabentouP ???
)|,( takaetwabentouDtetabeP ???
(eat)(lunchbox)(eat)(lunchbox))|,( EOSDtakaetP ?
)|,( EOSDtakaetwabentouP ??
)|0,( takaetCtetabewabentouP ???
)|0,( takaetwabentouCtetabeP ???
(1) (3)(4)(2)Dependency structure Dependency structure21,TT 43 ,TTDT :1 0:2 CT DT :3 0:4 CTFigure 3: Example of probability calculation.For example, consider the sentence shown in Fig-ure 3.
There are four possible dependency structuresin this figure, and the product of the probabilitiesfor each structure indicated below the tree is calcu-lated.
Finally, the model chooses the structure withthe highest probability (in this case T 1 is chosen).Clause Ci is decomposed into its clause type,f i, (including the predicate?s inflection and functionwords) and its remaining content part Ci?.
ClauseChi is also decomposed into its content part, Chi ?,and its clause type, fhi .P (Ci, relihi |Chi) = P (Ci?, f i, relihi |Chi?, fhi)= P (Ci?, relihi |f i, Chi?, fhi)?
P (f i|Chi?, fhi)?
P (Ci?, relihi |f i, Chi?)?
P (f i|fhi) (7)Equation (7) is derived because the content part, Ci?,is usually independent of its modifying head type,fhi , and in most cases, the type, f i, is independentof the content part of its modifying head, Chi .We call P (Ci?, relihi |f i, Chi ?)
generative prob-ability of a case and coordinate structure, andP (f i|fhi) generative probability of a clause type.The latter is the probability of generating func-tion words including topic markers and punctuationmarks, and is estimated using a syntactically an-notated corpus in the same way as (Kawahara andKurohashi, 2006b).The generative probability of a case and coordi-nate structure can be rewritten as follows:P (Ci?, relihi |f i, Chi?
)= P (Ci?|relihi , f i, Chi?)?
P (relihi |f i, Chi?)?
P (Ci?|relihi , f i, Chi?)?
P (relihi |f i) (8)310Equation (8) is derived because dependency rela-tions (coordinate or not) heavily depend on mod-ifier?s types including coordination keys.
We callP (Ci?|relihi , f i, Chi ?)
generative probability of acase structure, and P (relihi |f i) generative proba-bility of a coordinate structure.
The following twosubsections describe these probabilities.5.2 Generative Probability of CoordinateStructureThe most important feature to decide whether twoclauses are coordinate is coordination keys.
There-fore, we consider a coordination key, ki, as clausetype f i.
The generative probability of a coordinatestructure, P (relihi |f i), is defined as follows:P (relihi |f i) = P (relihi |ki) (9)We classified coordination keys into 52 classes ac-cording to the classification proposed by (Kurohashiand Nagao, 1994).
If type f i does not contain a co-ordination key, the relation is always D (normal de-pendency), that is P (relihi |f i) = P (D|?)
= 1.The generative probability of a coordinate struc-ture was estimated from a syntactically annotatedcorpus using maximum likelihood.
We used theKyoto Text Corpus (Kurohashi and Nagao, 1998),which consists of 40K Japanese newspaper sen-tences.5.3 Generative Probability of Case StructureWe consider that a case structure consists of a pred-icate, vi, a case frame, CF l, and a case assignment,CAk.
Case assignment CAk represents correspon-dences between the input case components and thecase slots shown in Figure 4.
Thus, the generativeprobability of a case structure is decomposed as fol-lows:P (Ci?|relihi , f i, Chi?
)= P (vi, CF l, CAk|relihi , f i, Chi?
)= P (vi|relihi , f i, Chi?)?
P (CF l|relihi , f i, Chi?, vi)?
P (CAk|relihi , f i, Chi?, vi, CF l)?
P (vi|relihi , f i, whi)?
P (CF l|vi)?
P (CAk|CF l, f i) (10)bentou-watabete(lunchbox)(eat)?lunchbox, bread, ?woman, student, ?gataberu1 (eat)Case Frame CFlCaseAssignmentCAk(no correspondence)Dependency Structure of SFigure 4: Example of case assignment.The above approximation is given because it is nat-ural to consider that the predicate vi depends on itsmodifying head whi instead of the whole modifyingclause, that the case frame CF l only depends on thepredicate vi, and that the case assignment CAk de-pends on the case frame CF l and the clause type f i.The generative probabilities of case frames andcase assignments are estimated from case framesthemselves in the same way as (Kawahara and Kuro-hashi, 2006b).
The remainder of this section de-scribes the generative probability of a predicate,P (vi|relihi , f i, whi).The generative probability of a predicate cap-tures cooccurrences of coordinate or non-coordinatephrases.
This kind of information is not handledin case frames, which aggregate only predicate-argument relations.The generative probability of a predicate mainlydepends on a coordination key in the clause type, f i,as well as the generative probability of a coordinatestructure.
We define this probability as follows:P (vi|relihi , f i, whi) = P (vi|relihi , ki, whi)If Ci?
is a nominal clause and consists of a nounni, we consider the following probability in stead ofequation (10):Pn(Ci?|relihi , f i, Chi?)
?
P (ni|relihi , f i, whi)This is because a noun does not have a case frameand any case components in the current framework.To estimate these probabilities, we first applied aconventional parsing system with coordination dis-ambiguation to a huge corpus, and collected coor-dinate bunsetsus from the parses.
We used KNP2(Kurohashi and Nagao, 1994) as the parser and aweb corpus consisting of 470M Japanese sentences(Kawahara and Kurohashi, 2006a).
The generativeprobability of a predicate was estimated from the2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html311collected coordinate bunsetsus using maximum like-lihood.5.4 Practical IssueThe proposed model considers all the possible de-pendency structures including coordination ambigu-ities.
To reduce this high computational cost, we in-troduced the CKY framework to the search.Each parameter in the model is smoothed by usingseveral back-off levels in the same way as (Collins,1999).
Smoothing parameters are optimized using adevelopment corpus.6 ExperimentsWe evaluated the coordinate structures and depen-dency structures that were outputted by our model.The case frames used in this paper were automati-cally constructed from 470M Japanese sentences ob-tained from the web.
Some examples of the caseframes are listed in Table 1 (Kawahara and Kuro-hashi, 2006a).In this work, the parameters related to unlexicaltypes are calculated from a small tagged corpus ofnewspaper articles, and lexical parameters are ob-tained from a huge web corpus.
To evaluate the ef-fectiveness of our fully-lexicalized model, our ex-periments are conducted using web sentences.
Asthe test corpus, we prepared 759 web sentences 3.The web sentences were manually annotated usingthe same criteria as the Kyoto Text Corpus.
We alsoused the Kyoto Text Corpus as a development corpusto optimize the smoothing parameters.
The systeminput was automatically tagged using the JUMANmorphological analyzer 4.We used two baseline systems for comparativepurposes: the rule-based dependency parser, KNP(Kurohashi and Nagao, 1994), and the probabilis-tic model of syntactic and case structure analysis(Kawahara and Kurohashi, 2006b), in which coor-dination disambiguation is the same as that of KNP.6.1 Evaluation of Detection of CoordinateStructuresFirst, we evaluated detecting coordinate structures,namely whether a coordination key bunsetsu triggers3The test set was not used to construct case frames and esti-mate probabilities.4http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.htmlTable 3: Experimental results of detection of coor-dinate structures.baseline proposedprecision 366/460 (79.6%) 361/435 (83.0%)recall 366/447 (81.9%) 361/447 (80.8%)F-measure ?
(80.7%) ?
(81.9%)a coordinate structure.
Table 3 lists the experimen-tal results.
The F-measure of our method is slightlyhigher than that of the baseline method (KNP).
Inparticular, our method achieved good precision.6.2 Evaluation of Dependency ParsingSecondly, we evaluated the dependency structuresanalyzed by the proposed model.
Evaluating thescope ambiguity of coordinate structures is sub-sumed within this dependency evaluation.
The de-pendency structures obtained were evaluated withregard to dependency accuracy ?
the proportion ofcorrect dependencies out of all dependencies exceptfor the last dependency in the sentence end 5.
Ta-ble 4 lists the dependency accuracy.
In this table,?syn?
represents the rule-based dependency parser,KNP, ?syn+case?
represents the probabilistic parserof syntactic and case structure (Kawahara and Kuro-hashi, 2006b), and ?syn+case+coord?
represents ourproposed model.
The proposed model significantlyoutperformed both of the baseline systems (McNe-mar?s test; p < 0.01).In the table, the dependency accuracies are clas-sified into four types on the basis of the bunsetsuclasses (PB: predicate bunsetsu and NB: noun bun-setsu) of a dependent and its head.
?syn+case?outperformed ?syn?.
In particular, the accuracyof predicate-argument relations (?NB?PB?)
wasimproved, but the accuracies of ?NB?NB?
and?PB?PB?
decreased.
?syn+case+coord?
outper-formed the two baselines for all of the types.
Notonly the accuracy of predicate-argument relations(?NB?PB?)
but also the accuracies of coordinatenoun/predicate bunsetsus (related to ?NB?NB?
and?PB?PB?)
were improved.
These improvementsare conduced by the integration of coordination dis-ambiguation and syntactic/case structure analysis.5Since Japanese is head-final, the second last bunsetsu un-ambiguously depends on the last bunsetsu, and the last bunsetsuhas no dependency.312Table 4: Experimental results of dependency parsing.syn syn+case syn+case+coordall 3,833/4,436 (86.4%) 3,852/4,436 (86.8%) 3,893/4,436 (87.8%)NB?PB 1,637/1,926 (85.0%) 1,664/1,926 (86.4%) 1,684/1,926 (87.4%)NB?NB 1,032/1,136 (90.8%) 1,029/1,136 (90.6%) 1,037/1,136 (91.3%)PB?PB 654/817 (80.0%) 647/817 (79.2%) 659/817 (80.7%)PB?NB 510/557 (91.6%) 512/557 (91.9%) 513/557 (92.1%)To compare our results with a state-of-the-art dis-criminative dependency parser, we input the sametest corpus into an SVM-based Japanese dependencyparser, CaboCha6(Kudo and Matsumoto, 2002).Its dependency accuracy was 86.3% (3,829/4,436),which is equivalent to that of ?syn?
(KNP).
This lowaccuracy is attributed to the out-of-domain trainingcorpus.
That is, the parser is trained on a newspa-per corpus, whereas the test corpus is obtained fromthe web, because of the non-availability of a taggedweb corpus that is large enough to train a supervisedparser.6.3 DiscussionFigure 5 shows some analysis results, where thedotted lines represent the analysis by the baseline,?syn+case?, and the solid lines represent the analysisby the proposed method, ?syn+case+coord?.
Thesesentences are incorrectly analyzed by the baselinebut correctly analyzed by the proposed method.
Forinstance, in sentence (1), the noun phrase coordina-tion of ?apurikeesyon?
(application) and ?doraiba?
(driver) can be correctly analyzed.
This is becausethe case frame of ?insutooru-sareru?
(installed) islikely to generate ?doraiba?, and ?apurikeesyon?and ?doraiba?
are likely to be coordinated.One of the causes of errors in dependency parsingis the mismatch between analysis results and anno-tation criteria.
As per the annotation criteria, eachbunsetsu has only one modifying head.
Therefore, insome cases, even if analysis results are semanticallycorrect, they are judged as incorrect from the view-point of the annotation.
For example, in sentence(4) in Figure 6, the baseline method, ?syn?, correctlyrecognized the head of ?iin-wa?
(commissioner-TM)as ?hirakimasu?
(open).
However, the proposedmethod incorrectly judged it as ?oujite-imasuga?(offer).
Both analysis results can be considered tobe semantically correct, but from the viewpoint of6http://chasen.org/?taku/software/cabocha/our annotation criteria, the latter is not a syntacticrelation (i.e., incorrect), but an ellipsis relation.
Thiskind of error is caused by the strong lexical prefer-ence considered in our method.To address this problem, it is necessary to simul-taneously evaluate not only syntactic relations butalso indirect relations, such as ellipses and anaphora.This kind of mismatch also occurred for the detec-tion of coordinate structures.Another errors were caused by an inherent char-acteristic of generative models.
Generative modelshave some advantages, such as their application tolanguage models.
However, it is difficult to incor-porate various features that seem to be useful foraddressing syntactic and coordinate ambiguity.
Weplan to apply discriminative reranking to the n-bestparses produced by our generative model in the sameway as (Charniak and Johnson, 2005).7 ConclusionThis paper has described an integrated probabilisticmodel for coordination disambiguation and syntac-tic/case structure analysis.
This model takes advan-tage of lexical preference of a huge raw corpus andlarge-scale case frames and performs coordinationdisambiguation and syntactic/case analysis simulta-neously.
The experiments indicated the effective-ness of our model.
Our future work involves incor-porating ellipsis resolution to develop an integratedmodel for syntactic, case, and ellipsis analysis.AcknowledgmentThis research is partially supported by special coor-dination funds for promoting science and technol-ogy.ReferencesRajeev Agarwal and Lois Boggess.
1992.
A simple butuseful approach to conjunct identification.
In Proceed-ings of ACL1992, pages 15?21.313??
(1) insutooru-sareteiru apurikeesyon-oyobi doraiba-tono kyougou-niyori dousa-shinai baai-ga arimasu.installed application driver conflict not work case-nom exist(due to the conflict between installed application and driver, there is a case that (it) does not work.)?
?
(2) ... kuroji-wa 41oku-doru-to, zennen-yori 10oku-doru gensyou-shita.surplus-TM 4.1 billion dollars preceding year-abl 1 billion dollars reduced(... surplus was 4.1 billion dollars and was reduced by 1 billion dollars from the preceding year.)??
(3) ... gurupu-wa sugu ugokidasu-node wakaru-nodaga, ugokidasa-nai gurupu-mo aru.group-TM soon start to work see not start to work group also be(... can see the groups that start to work soon, but there are groups that do not start to work.
)Figure 5: Examples of correct analysis results.
The dotted lines represent the analysis by the baseline,?syn+case?, and the solid lines represent the analysis by the proposed method, ?syn+case+coord?.??
(4) iin-wa, jitaku-de minasan-karano gosoudan-ni oujite-imasuga, ... soudansyo-wo hirakimasucommissioner-TM at home all of you consultation-acc offer window open(the commissioner offers consultation to all of you at home, but opens a window ...)Figure 6: An example of incorrect analysis results caused by the mismatch between analysis results andannotation criteria.Francis Chantree, Adam Kilgarriff, Anne de Roeck, andAlistair Wills.
2005.
Disambiguating coordinationsusing word distribution information.
In Proceedingsof RANLP2005.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of ACL2005, pages 173?180.Michael Collins.
1999.
Head-Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.Amit Dubey, Frank Keller, and Patrick Sturt.
2006.
In-tegrating syntactic priming into an incremental prob-abilistic parser, with an application to psycholinguis-tic modeling.
In Proceedings of COLING-ACL2006,pages 417?424.Miriam Goldberg.
1999.
An unsupervised model forstatistically determining coordinate phrase attachment.In Proceedings of ACL1999, pages 610?614.Daisuke Kawahara and Sadao Kurohashi.
2006a.Case frame compilation from the web usinghigh-performance computing.
In Proceedings ofLREC2006.Daisuke Kawahara and Sadao Kurohashi.
2006b.
Afully-lexicalized probabilistic model for Japanese syn-tactic and case structure analysis.
In Proceedings ofHLT-NAACL2006, pages 176?183.Taku Kudo and Yuji Matsumoto.
2002.
Japanese depen-dency analysis using cascaded chunking.
In Proceed-ings of CoNLL2002, pages 29?35.Sadao Kurohashi and Makoto Nagao.
1994.
A syntacticanalysis method of long Japanese sentences based onthe detection of conjunctive structures.
ComputationalLinguistics, 20(4):507?534.Sadao Kurohashi and Makoto Nagao.
1998.
Buildinga Japanese parsed corpus while improving the parsingsystem.
In Proceedings of LREC1998, pages 719?724.Sadao Kurohashi.
1995.
Analyzing coordinate structuresincluding punctuation in English.
In Proceedings ofIWPT1995, pages 136?147.Philip Resnik.
1999.
Semantic similarity in a taxonomy:An information-based measure and its application toproblems of ambiguity in natural language.
Journal ofArtificial Intelligence Research, 11:95?130.Manabu Sassano.
2004.
Linear-time dependency anal-ysis for Japanese.
In Proceedings of COLING2004,pages 8?14.The National Institute for Japanese Language.
2004.Bunruigoihyo.
Dainippon Tosho, (In Japanese).314
