Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 218?221,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsISTI@SemEval-2 Task #8:Boosting-Based Multiway Relation ClassificationAndrea Esuli, Diego Marcheggiani, Fabrizio SebastianiIstituto di Scienza e Tecnologie dell?InformazioneConsiglio Nazionale delle Ricerche56124 Pisa, Italyfirstname.lastname@isti.cnr.itAbstractWe describe a boosting-based supervisedlearning approach to the ?Multi-Way Clas-sification of Semantic Relations betweenPairs of Nominals?
task #8 of SemEval-2.
Participants were asked to determinewhich relation, from a set of nine relationsplus ?Other?, exists between two nomi-nals, and also to determine the roles of thetwo nominals in the relation.Our participation has focused, rather thanon the choice of a rich set of features,on the classification model adopted to de-termine the correct assignment of relationand roles.1 IntroductionThe ?Multi-Way Classification of Semantic Rela-tions between Pairs of Nominals?
(Hendrickx etal., 2010) we faced can be seen as the compositionof two sub-tasks:1.
Determining which relation r, from a set ofrelations R (see Table 1), exists between twoentities e1and e2.2.
Determining the direction of the relation, i.e.,determining which of r(e1, e2) or r(e2, e1)holds.The set R is composed by nine ?semanticallydetermined?
relations, plus a special Other rela-tion which includes all the pairs which do not be-long to any of the nine previously mentioned rela-tions.The two novel aspects of this task with respect tothe similar task # 4 of SemEval-2007 (Girju et al,2007) (?Classification of Semantic Relations be-tween Nominals?)
are (i) the definition of the taskas a ?single-label?
classification task and (ii) the1 Cause-Effect2 Instrument-Agency3 Product-Producer4 Content-Container5 Entity-Origin6 Entity-Destination7 Component-Whole8 Member-Collection9 Message-TopicTable 1: The nine relations defined for the task.need of determining the direction of the relation(i.e., Item 2 above).The classification task described can be formal-ized as a single-label (aka ?multiclass?)
text clas-sification (SLTC) task, i.e., as one in which exactlyone class must be picked for a given object out ofa set of m available classes.Given a set of objects D (ordered pairs of nom-inals, in our case) and a predefined set of classes(aka labels, or categories) C = {c1, .
.
.
, cm},SLTC can be defined as the task of estimatingan unknown target function ?
: D ?
C, thatdescribes how objects ought to be classified, bymeans of a function??
: D ?
C called the classi-fier1.In the relation classification task which is theobject of this evaluation, the set C of classes iscomposed of 19 elements, i.e., the nine relationsof Table 1, each one considered twice because itmay take two possible directions, plus Other.2 The learnerAs the learner for our experiments we have used aboosting-based learner called MP-BOOST (Esuliet al, 2006).
Boosting is among the classes of su-pervised learning devices that have obtained thebest performance in several learning tasks and,at the same time, have strong justifications fromcomputational learning theory.
MP-BOOST is a1Consistently with most mathematical literature we usethe caret symbol (?)
to indicate estimation.218variant of ADABOOST.MH (Schapire and Singer,2000), which has been shown in (Esuli et al,2006) to obtain considerable effectiveness im-provements with respect to ADABOOST.MH.MP-BOOST works by iteratively generating, foreach class cj, a sequence?
?j1, .
.
.
,?
?jSof classifiers(called weak hypotheses).
A weak hypothesis is afunction?
?js: D ?
R, where D is the set of doc-uments and R is the set of real numbers.
The signof?
?js(di) (denoted by sgn(?
?js(di))) represents thebinary decision of?
?json whether dibelongs to cj,i.e.
sgn(?
?js(di)) = +1 (resp.,?1) means that diisbelieved to belong (resp., not to belong) to cj.
Theabsolute value of?
?js(di) (denoted by |?
?js(di)|)represents instead the confidence that?
?jshas inthis decision, with higher values indicating higherconfidence.At each iteration s MP-BOOST tests the effec-tiveness of the most recently generated weak hy-pothesis?
?json the training set, and uses the resultsto update a distributionDjsof weights on the train-ing examples.
The initial distribution Dj1is uni-form by default.
At each iteration s all the weightsDjs(di) are updated, yieldingDjs+1(di), so that theweight assigned to an example correctly (resp., in-correctly) classified by?
?jsis decreased (resp., in-creased).
The weight Djs+1(di) is thus meant tocapture how ineffective?
?j1, .
.
.
,?
?jshave been inguessing the correct cj-assignment of di(denotedby ?j(di)), i.e., in guessing whether training doc-ument dibelongs to class cjor not.
By using thisdistribution, MP-BOOST generates a new weakhypothesis?
?js+1that concentrates on the exam-ples with the highest weights, i.e.
those that hadproven harder to classify for the previous weak hy-potheses.The overall prediction on whether dibelongs tocjis obtained as a sum?
?j(di) =?Ss=1?
?js(di) ofthe predictions made by the weak hypotheses.
Thefinal classifier?
?jis thus a committee of S clas-sifiers, a committee whose S members each casta weighted vote (the vote being the binary deci-sion sgn(?
?js(di)), the weight being the confidence|?
?js(di)|) on whether dibelongs to cj.
For the finalclassifier?
?jtoo, sgn(?
?j(di)) represents the bi-nary decision as to whether dibelongs to cj, while|?
?j(di)| represents the confidence in this decision.MP-BOOST produces a multi-label classifier,i.e., a classifier which independently classifies adocument against each class, possibly assigninga document to multiple classes or no class at?<e1>People</e1> have been moving back into<e2>downtown</e2>.
?Entity-Destination(e1,e2)F People FS Peopl FH group FP NNPFS1 have FS1S have FS1H have FS1P VBPFS2 been FS2S been FS2H be FS2P VBNFP3 moving FP3S move FP3H travel FP3P VBGSP3 moving SP3S move SP3H travel SP3P VBGSP2 back SP2S back SP2H O SP2P RBSP1 into SP1S into SP1H O SP1P INS downtown SS downtown SH city district SP NNSS1 .
SS1S .
SS1H O SS1P .Table 2: A training sentence and the features ex-tracted from it.all.
In order to obtain a single-label classifier,we compare the outcome of the |C| binary clas-sifiers, and the class which has obtained the high-est?
?j(di) value is assigned to di, i.e.,??
(di) =arg maxj?
?j(di).3 Vectorial representationWe have generated the vectorial representations ofthe training and test objects by extracting a numberof contextual features from the text surroundingthe two nominals whose relation is to be identified.An important choice we have made is to ?nor-malize?
the representation of the two nominalswith respect to the order in which they appear inthe relation, and not in the sentence.
Thus, if e2appears in a relation r(e2, e1), then e2is consid-ered to be the first (F) entity in the feature genera-tion process and e1is the second (S) entity.We have generated a number of features foreach term denoting an entity and also for the threeterms preceding each nominal (P1, P2, P3) and forthe three terms following it (S1, S2, S3):T : the term itself;S : the stemmed version of the term, obtainedusing a Porter stemmer;P : the POS of the term, obtained using the BrillTagger;H : the hypernym of the term, taken from Word-Net (?O?
if not available).Features are prefixed with a proper compositionof the above labels in order to identify their rolein the sentence.
Table 2 illustrates a sentence fromthe training set and its extracted features.219If an entity is composed by k > 1 terms, entity-specific features are generated for all the term n-grams contained in the entity, for all n ?
[1, ..., k].E.g., for ?phone call?
features are generated forthe n-grams: ?phone?, ?call?, ?phone call?.In all the experiments described in this paper,MP-BOOST has been run for S = 1000 iterations.No feature weighting has been performed, sinceMP-BOOST requires binary input only.4 Classification modelThe classification model we adopted in our exper-iments splits the two tasks of recognizing the rela-tion type and the one of determining the directionof the relation in two well distinct phases.4.1 Relation type determinationGiven the training set Tr of all the sentences forwhich the classifier outcome is known, vectorialrepresentations (see Section 3) are built in a waythat ?normalizes?
the direction of the relation, i.e.:?
if the training object belongs to one of thenine relevant relations, the features extractedfrom the documents are given proper identi-fiers in order to mark their role in the relation,not the order of appearance in the sentence;?
if the training object belongs to Other thetwo distinct vectorial representations are gen-erated, one for relation Other(e1, e2) and onefor Other(e2, e1).The produced training set has thus a larger num-ber of examples than the one actually provided.The training set provided for the task yielded 9410training examples from the original 8000 sen-tences.
A 10-way classifier is then trained on thevectorial representation.4.2 Relation direction determinationThe 10-way classifier is thus able to assign a rela-tion, or the Other relation, to a sentence, but not toreturn the direction of the relation.
The directionof the relation is determined at test time, by classi-fying two instances of each test sentence, and thencombining the outcome of the two classificationsin order to produce the final classification result.More formally, given a test sentence d belong-ing to an unknown relation r, two vectorial repre-sentations are built: one, d1,2, under the hypoth-esis that r(e1, e2) holds, and one, d2,1, under thehypothesis that r(e2, e1) holds.Both d1,2and d2,1are classified by??:?
if both classifications return Other, then d isassigned to Other;?
if one classification returns Other and theother returns a relation r, then r, with theproper direction determined by which vec-torial representation determined the assign-ment, is assigned to d;?
if the two classifications return two relationsr1,2and r2,1different from Other (of thesame or of different relation type), then theone that obtains the highest??
value deter-mines the relation and the direction to be as-signed to d.5 ExperimentsWe have produced two official runs.The ISTI-2 run uses the learner, vectorial rep-resentation, and classification model described inthe previous sections.The ISTI-1 run uses the same configuration ofISTI-2, with the only difference being how theinitial distribution Dj1of the boosting method isdefined.
Concerning this, we followed the ob-servations of (Schapire et al, 1998, Section 3.2)on boosting with general utility functions; the ini-tial distribution in the ISTI-1 run is thus set to beequidistributed between the portion Tr+jof pos-itive examples of the training set and the portionTr?jof negative examples, for each class j, i.e.,Dj1(di) =12|Tr+j|iff di?
Tr+j(1)Dj1(di) =12|Tr?j|iff di?
Tr?j(2)This choice of initial distribution, which givesmore relevance to the less frequent type of ele-ments of the training set (namely, the positive ex-amples), is meant to improve the performance onhighly imbalanced classes, thus improving effec-tiveness at the the macro-averaged level.We have also defined a third method for an addi-tional run, ISTI-3; unfortunately we were not ableto produce it in time, and there is thus no offi-cial evaluation for this run on the test data.
Themethod upon which the ISTI-3 run is based re-lies on a more ?traditional?
approach to the clas-sification task, i.e., a single-label classifier trained220Run pi??
?F?1piM?MFM1Official resultsISTI-1 72.01% 67.08% 69.46% 71.12% 66.24% 68.42%ISTI-2 73.55% 63.54% 68.18% 72.38% 62.34% 66.65%10-fold cross-validationISTI-1 73.60% 69.34% 71.41% 72.44% 68.17% 69.95%ISTI-2 75.34% 65.92% 70.32% 73.96% 64.65% 68.52%ISTI-3 68.52% 61.58% 64.86% 66.19% 59.75% 62.31%Table 3: Official results (upper part), and results of the three relation classification methods when used ina 10-fold cross-validation experiment on training data (lower part).
Precision, recall, and F1are reportedas percentages for more convenience.on the nine relations plus Other, not consideringthe direction, coupled with nine binary classifierstrained to determined the direction of each rela-tion.
We consider this configuration as a reason-able baseline to evaluate the impact of the originalclassification model adopted in the other two runs.Table 3 summarizes the experimental results.The upper part of the table reports the official re-sults for the two official runs.
The lower partreports the results obtained by the three rela-tion classification methods when used in a 10-fold cross-validation experiment on the trainingdata.
The evaluation measures are precison (pi),recall (?
), and the F1score, computed both ina microaveraged (??)
and a macroaveraged(?M) way (Yang, 1999).The results for ISTI-1 and ISTI-2 in the 10-foldvalidation experiment are similar both in trend andin absolute value to the official results, allowingus to consider the ISTI-3 results in the 10-foldvalidation experiment as a good prediction of theefficacy of the ISTI-3 method on the test data.The classification model of ISTI-2, which usesan initial uniform distribution for the MP-BOOSTlearner as ISTI-3, improves FM1over ISTI-3 by9.97%, and F?1by 8.42%.The use of aF1-customized distribution in ISTI-1 results in a F1improvement with respect toISTI-2 (FM1improves by 2.66% in official re-sults, 2.09% in 10-fold validation results), whichis mainly due to a relevant improvement in recall.Comparing ISTI-1 with ISTI-3 the total im-provement is 12.26% for FM1and 10.10% for F?1.6 Conclusion and future workThe original relation classification model we haveadopted has produced a relevant improvement inefficacy with respect to a ?traditional?
approach.We have not focused on the development of arich set of features.
In the future we would like toapply our classification model to the vectorial rep-resentations generated by the other participants, inorder to evaluate the distinct contributions of thefeature set and the classification model.The use of a F1-customized initial distributionfor the MP-BOOST learner has also produced arelevant improvement, and it will be further inves-tigated on more traditional text classification tasks.ReferencesAndrea Esuli, Tiziano Fagni, and Fabrizio Sebastiani.2006.
MP-Boost: A multiple-pivot boosting al-gorithm and its application to text categorization.In Proceedings of the 13th International Sympo-sium on String Processing and Information Retrieval(SPIRE?06), pages 1?12, Glasgow, UK.Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-pakowicz, Peter Turney, and Deniz Yuret.
2007.Semeval-2007 task 04: Classification of semanticrelations between nominals.
In Proceedings of theFourth International Workshop on Semantic Evalu-ations (SemEval-2007), pages 13?18, Prague, CZ.Association for Computational Linguistics.Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,Preslav Nakov, Diarmuid?O S?eaghdha, SebastianPad?o, Marco Pennacchiotti, Lorenza Romano, andStan Szpakowicz.
2010.
Semeval-2010 task 8:Multi-way classification of semantic relations be-tween pairs of nominals.
In Proceedings of the 5thSIGLEX Workshop on Semantic Evaluation, Upp-sala, Sweden.Robert E. Schapire and Yoram Singer.
2000.
Boostex-ter: A boosting-based system for text categorization.Machine Learning, 39(2/3):135?168.Robert E. Schapire, Yoram Singer, and Amit Singhal.1998.
Boosting and rocchio applied to text filtering.In SIGIR ?98: Proceedings of the 21st annual inter-national ACM SIGIR conference on Research anddevelopment in information retrieval, pages 215?223, New York, NY, USA.
ACM.Yiming Yang.
1999.
An evaluation of statistical ap-proaches to text categorization.
Information Re-trieval, 1(1/2):69?90.221
