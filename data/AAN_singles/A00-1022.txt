Message  C lass i f i ca t ion  in the  Ca l l  CenterStephan Busemann, Seen Schmeier~ Roman G. ArensDFKI GmbHStuhlsatzenhausweg 3, D-66123 Saarbriicken, Germanye-mail: {busemann, schmeier, arens}@dfki.deAbstractCustomer care in technical domains is increasinglybased on e-mail communication, allowing for the re-production of approved solutions.
Identifying thecustomer's problem is often time-consuming, as theproblem space changes if new products are launched.This paper describes a new approach to the classifi-cation of e-mail requests based on shallow text pro-cessing and machine learning techniques.
It is im-plemented within an assistance system for call centeragents that is used in a commercial setting.1 I n t roduct ionCustomer care in technical domains is increasinglybased on e-mail communication, allowing for the re-production of approved solutions.
For a call cen-ter agent, identifying the customer's problem is of-ten time-consuming, as the problem space changesif new products are launched or existing regulationsare modified.
The typical task of a call center agentprocessing e-mail requests consists of the followingsteps:Recogn ize  the  prob lem(s) :  read and understandthe e-mail request;Search  a solut ion:  identify and select predefinedtext blocks;P rov ide  the  solut ion:  if necessary, customizetext blocks to meet the current request, andsend the text.This task can partly be automated by a systemsuggesting relevant solutions for an incoming e-mail.This would cover the first two steps.
The last stepcan be delicate, as its primary goal is to keep thecustomer satisfied.
Thus human intervention seemsmandatory to allow for individual, customized an-swers.
Such a system will?
reduce the training effort required since agentsdon't have to know every possible solution forevery possible problem;?
increase the agents' performance since agentscan more quickly select a solution among severaloffered than searching one;?
improve the quality of responses ince agentswill behave more homogeneously - both as agroup and over time - and commit fewer errors.Given that free text about arbitrary topics mustbe processed, in-depth approaches to language un-derstanding are not feasible.
Given further that thetopics may change over time, a top-down approachto knowledge modeling is out of the question.
Rathera combination of shallow text processing (STP) withstatistics-based machine learning techniques (SML)is called for.
STP gathers partial information abouttext such as part of speech, word stems, negations,or sentence type.
These types of information can beused to identify the linguistic properties of a largetraining set of categorized e-mails.
SML techniquesare used to build a classifier that is used for new,incoming messages.
Obviously, the change of topicscan be accommodated by adding new categories ande-mails and producing a new classifier on the basisof old and new data.
We call this replacement of aclassifier "relearning".This paper describes a new approach to the clas-sification of e-mail requests along these lines.
It isimplemented within the ICe-MAIL system, whichis an assistance system for call center agents thatis currently used in a commercial setting.
Section 2describes important properties of the input data, i.e.the e-mail texts on the one hand, and the categorieson the other.
These properties influenced the systemarchitecture, which is presented in Section 3.
Vari-ous publicly available SML systems have been testedwith different methods of STP-based preprocessing.Section 4 describes the results.
The implementationand usage of the system including the graphical userinterface is presented in Section 5.
We conclude bygiving an outlook to further expected improvements(Section 6).2 Data  Character ist icsA closer look at the data the ICe-MAIL system isprocessing will clarify the task further.
We carriedout experiments with unmodified e-mail data accu-mulated over a period of three months in the callcenter database.
The total amount was 4777 e-mails.158We used 47 categories, which contained at least 30documents.
This minimum amount of documentsturned out to render the category sufficiently dis-tinguishable for the SML tools.
The database con-tained 74 categories with at least 10 documents, butthe selected ones covered 94% of all e-malls, i.e.
4490documents.It has not yet generally been investigated how thetype of data influences the learning result (Yang,1999), or under which circumstances which kind ofpreprocessing and which learning algorithm is mostappropriate.
Several aspects must be considered:Length of the documents, morphological and syn-tactic well-formedness, the degree to which a docu-ment can be uniquely classified, and, of course, thelanguage of the documents.In our application domain the documents differvery much from documents generally used in bench-mark tests, for example the Reuters corpus 1.
Firstof all, we have to deal with German, whereas theReuters data are in English.
The average length ofour e-mails is 60 words, whereas for documents ofReuters-21578 it is 129 words.
The number of cat-egories we used compares to the top 47 categoriesof the Reuters TOPICS category set.
While wehave 5008 documents, TOPICS consists of 13321 in-stances 2.
The Reuters documents usually are mor-phologically and syntactically well-formed.
As e-mails are a more spontaneously created and infor-mal type of document, they require us to cope witha large amount of jargon, misspellings and gram-matical inaccuracy.
A drastic example is shown inFigure 2.
The bad conformance to linguistic stan-dards was a major argument in favor of STP insteadof in-depth syntactic and semantic analysis.The degree to which a document can be uniquelyclassified is hard to verify and can only be inferredfrom the results in general terms.
3 It is, however,dependent on the ability to uniquely distinguish theclasses.
In our application we encounter overlappingand non-exhaustive categories as the category sys-tem develops over time.3 Integrating Language TechnologyWith  Machine LearningSTP and SML correspond to two differentparadigms.
STP tools used for classification taskspromise very high recall/precision or accuracy val-ues.
Usually human experts define one or severaltemplate structures to be filled automatically by ex-tracting information from the documents (cf.
e.g.
(Ciravegna et al, 1999)).
Afterwards, the partiallylhttp ://~wv.
research, a~t.
com/'le~is/reuters21578.html2We took only uniquely classified ocuments into account.3Documents containing multiple requests can at presentonly be treated manually, as described in Section 5.filled templates are classified by hand-made rules.The whole process brings about high costs in analyz-ing and modeling the application domain, especiallyif it is to take into account he problem of changingcategories in the present application.SML promises low costs both in analyzing andmodeling the application at the expense of a loweraccuracy.
It is independent of the domain on theone hand, but does not consider any domain specificknowledge on the other.By combining both methodologies in ICe -MAIL ,we achieve high accuracy and can still preserve a use-ful degree of domain-independence.
STP may useboth general inguistic knowledge and linguistic al-gorithms or heuristics adapted to the application inorder to extract information from texts that is rele-vant for classification.
The input to the SML tool isenriched with that information.
The tool builds oneor several categorizers 4 that will classify new texts.In general, SML tools work with a vector epresen-tation of data.
First, a relevancy vector of relevantfeatures for each class is computed (Yang and Ped-ersen, 1997).
In our case the relevant features con-sist of the user-defined output of the linguistic pre-processor.
Then each single document is translatedinto a vector of numbers isomorphic to the definingvector.
Each entry represents the occurrence of thecorresponding feature.
More details will be given inSection 4The ICe-MAIL architecture is shown in Figure 1.The workflow of the system consists of a learningstep carried out off-line (the light gray box) and anonline categorization step (the dark gray box).
Inthe off-line part, categorizers are built by processingclassified data first by an STP and then by an SMLtool.
In this way, categorizers can be replaced by thesystem administrator as she wants to include newor remove expired categories.
The categorizers areused on-line in order to classify new documents afterthey have passed the linguistic preprocessing.
Theresulting category is in our application associatedwith a standard text that the call center agent usesin her answer.
The on-line step provides new clas-sified data that is stored in a dedicated ICe-MAILdatabase (not shown in Figure 1).
The relearningstep is based on data from this database.3.1 Shal low Text  ProcessingLinguistic preprocessing of text documents is car-ried out by re-using sines, an information extrac-tion core system for real-world German text pro-cessing (Neumann et al, 1997).
The fundamentaldesign criterion of sines is to provide a set of basic,powerful, robust, and efficient STP components and4Almost all tools we examined build a single multi-categorizer except for SVM-Light, which builds multiple bi-nary classifiers.1 I ;Q  159Cate gorY)JFigure 1: Architecture of the ICC-MAIL System.generic linguistic knowledge sources that can eas-ily be customized to deal with different asks in aflexible manner, sines includes a text tokenizer, alexical processor and a chunk parser.
The chunkparser itself is subdivided into three components.
Inthe first step, phrasal fragments like general nominalexpressions and verb groups are recognized.
Next,the dependency-based structure of the fragments ofeach sentence is computed using a set of specific sen-tence patterns.
Third, the grammatical functionsare determined for each dependency-based structureon the basis of a large subcategorization lexicon.The present application benefits from the high mod-ularity of the usage of the components.
Thus, it ispossible to run only a subset of the components andto tailor their output.
The experiments described inSection 4 make use of this feature.3.2 Statistics-Based Machine LearningSeveral SML tools representing different learningparadigms have been selected and evaluated in dif-ferent settings of our domain:Lazy Learning: Lazy Learners are also knownas memory-based, instance-based, exemplar-based, case-based, experience-based, or k-nearest neighbor algorithms.
They store alldocuments as vectors during the learning phase.In the categorization phase, the new documentvector is compared to the stored ones and iscategorized to same class as the k-nearest neigh-bors.
The distance is measured by computinge.g.
the Euclidean distance between the vectors.By changing the number of neighbors k or thekind of distance measure, the amount of gener-alization can be controlled.We used IB (Aha, 1992), which is part ofthe MLC++ library (Kohavi and Sommerfield,1996).Symbolic Eager Learning: This type of learnersconstructs a representation for document vec-tors belonging to a certain class during thelearning phase, e.g.
decision trees, decision rulesor probability weightings.
During the catego-rization phase, the representation is used to as-sign the appropriate class to a new documentvector.
Several pruning or specialization heuris-tics can be used to control the amount of gen-eralization.We used ID3 (Quinlan, 1986), C4.5 (Quinlan,1992) and C5.0, R IPPER (Cohen, 1995), andthe Naive Bayes inducer (Good, 1965) con-tained in the MLCq-q- library.
ID3, C4.5 andC5.0 produce decision trees, R IPPER i sa  rule-based learner and the Naive Bayes algorithmcomputes conditional probabilities of the classesfrom the instances.Support Vector Machines (SVMs) :  SVMs aredescribed in (Vapnik, 1995).
SVMs are binarylearners in that they distinguish positive andnegative examples for each class.
Like eagerlearners, they construct a representation dur-ing the learning phase, namely a hyper planesupported by vectors of positive and negativeexamples.
For each class, a categorizer is builtby computing such a hyper plane.
During thecategorization phase, each categorizer is appliedto the new document vector, yielding the prob-abilities of the document belonging to a class.The probability increases with the distance ofthevector from the hyper plane.
A documentis said to belong to the class with the highestprobability.We chose SVM_Light (Joachims, 1998).Neura l  Networks :  Neural Networks are a specialkind of "non-symbolic" eager learning algo-1 60rithm.
The neural network links the vector el-ements to the document categories The learn-ing phase defines thresholds for the activationof neurons.
In the categorization phase, a newdocument vector leads to the activation of a sin-gle category.
For details we refer to (Wiener etal., 1995).In our application, we tried out the LearningVector Quantization (LVQ) (Kohonen et al,1996).
LVQ has been used in its default config-uration only.
No adaptation to the applicationdomain has been made.4 Exper iments  and  Resu l tsWe describe the experiments and results we achievedwith different linguistic preprocessing and learningalgorithms and provide some interpretations.We start out from the corpus of categorized e-mails described in Section 2.
In order to normalizethe vectors representing the preprocessing results oftexts of different length, and to concentrate on rel-evant material (cf.
(Yang and Pedersen, 1997)), wedefine the relevancy vector as follows.
First, all doc-uments are preprocessed, yielding a list of resultsfor each category.
From each of these lists, the 100most frequent results - according to a TF / IDF  mea-sure - are selected.
The relevancy vector consists ofall selected results, where doubles are eliminated.Its length was about 2500 for the 47 categories; itslightly varied with the kind of preprocessing used.During the learning phase, each document is pre-processed.
The result is mapped onto a vector ofthe same length as the relevancy vector.
For ev-ery position in the relevancy vector, it is determinedwhether the corresponding result has been found.
Inthat case, the value of the result vector element is 1,otherwise it is 0.In the categorization phase, the new document ispreprocessed, and a result vector is built as describedabove and handed over to the categorizer (cf.
Fig-ure 1).While we tried various kinds of linguistic prepro-cessing, systematic experiments have been carriedout with morphological nalysis (MorphAna), shal-low parsing heuristics (STP-Heuristics), and a com-bination of both (Combined).MorphAna:  Morphological Analysis provided bysines yields the word stems of nouns, verbs andadjectives, as well as the full forms of unknownwords.
We are using a lexicon of approx.
100000word stems of German (Neumann et al, 1997).STP-Heur i s t i cs :  Shallow parsing techniques areused to heuristically identify sentences contain-ing relevant information.
The e-mails usuallycontain questions and/or descriptions of prob-lems.
The manual analysis of a sample ofthe data suggested some linguistic constructionsfrequently used to express the problem.
We ex-pected that content words in these construc-tions should be particularly influential to thecategorization.
Words in these constructionsare extracted and processed as in MorphAna,and all other words are ignored.
5 The heuris-tics were implemented in ICC-MAIL  using sines.The constructions of interest include negationsat the sentence and the phrasal level, yes-noand wh-questions, and declaratives immediatelypreceding questions.
Negations were found todescribe a state to be changed or to refer tomissing objects, as in I cannot read my emailor There is no correct date.
We identified themthrough negation particles.
8 Questions most of-ten refer to the problem in hand, either directly,e.g.
How can I start my email program.
~ or in-directly, e.g.
Why is this the case?.
The lat-ter most likely refers to the preceding sentence,e.g.
My system drops my e-mails.
Questions areidentified by their word order, i.e.
yes-no ques-tions start with a verb and wh-questions with awh-particle.Combined:  In order to emphasize words foundrelevant by the STP heuristics without losingother information retrieved by MorphAna, theprevious two techniques are combined.
Empha-sis is represented here by doubling the numberof occurrences of the tokens in the normaliza-tion phase, thus increasing their TF / IDF  value.Call center agents judge the performance of ICC-MAIL  most easily in terms of accuracy: In what per-centage of cases does the classifier suggest the correcttext block?
In Table 1, detailed information aboutthe accuracy achieved is presented.
All experimentswere carried out using 10-fold cross-validation  thedata described in Section 2.In all experiments he SVM_Light system outper-formed other learning algorithms, which confirmsYang's (Yang and Liu, 1999) results for SVMs fedwith Reuters data.
The k-nearest neighbor algo-rithm IB performed surprisingly badly although dif-ferent values ofk were used.
For IB, ID3, C4.5, C5.0,Naive Bayes, R IPPER and SVM_Light, linguis-tic preprocessing increased the overall performance.In fact, the method performing best, SVM_Light,gained 3.5% by including the task-oriented heuris-tics.
However, the boosted R IPPER and LVQ scoreda decreased accuracy value there.
For LVQ the de-crease may be due to the fact that no adaptations to5If no results were found this way, MorphAna was appliedinstead.6We certainly would have benefited from lexical semanticinformation, e.g.
The correct date is missing would not becaptured by our approach.161Neural NetsLazy LearnerSymbolic EagerLearnersSupport Vectors \[\]SML algorithmLVQIBNaive BayesID3R IPPERBoosted RipperC4.5C5.0SVM_L ightMorphAnaBest Best535.6633.8133.8338.5347.0852.7352.0052.6053.85 74.91STP-HeuristicsBest Best522.2933.0133.7638.1149.3849.9652.9053.2054.84 78.05CombinedBest Best525.9735.1434.0140.0250.5450.7853.4054.2056.23 78.17Table 1: Results of Experiments.
Most SML tools deliver the best result only.
SVM_Light produces rankedresults, allowing to measure the accuracy of the top five alternatives (Best5).the domain were made, such as adapting the numberof codebook vectors, the initial learning parametersor the number of iterations during training (cf.
(Ko-honen et al, 1996)).
Neural networks are rather sen-sitive to misconfigurations.
The boosting for RIP-PER seems to run into problems of overfitting.
Wenoted that in six trials the accuracy could be im-proved in Combined compared to MorphAna, but infour trials, boosting led to deterioration.
This effectis also mentioned in (Quinlan, 1996).These figures are slightly lower than the ones re-ported by (Neumann and Schmeier, 1999) that wereobtained from a different data set.
Moreover, thesedata did not contain multiple queries in one e-mall.It would be desirable to provide explanations forthe behavior of the SML algorithms on our data.
Aswe have emphasized in Section 2, general methodsof explanation do not exist yet.
In the applicationin hand, we found it difficult to account for the ef-fects of e.g.
ungrammatical text or redundant cate-gories.
For the time being, we can only offer somespeculative and inconclusive assumptions: Some ofthe tools performing badly - IB, ID3, and the NaiveBayes inducer of the MLC++ library - have no orlittle pruning ability.
With rarely occurring data,this leads to very low generalization rates, whichagain is a problem of overfitting.
This suggests thata more canonical representation for the many waysof expressing a technical problem should be soughtfor.
Would more extensive linguistic preprocessinghelp?Other tests not reported in Table 1 looked at im-provements hrough more general and sophisticatedSTP such as chunk parsing.
The results were verydiscouraging, leading to a significant decrease com-pared to MorphAna.
We explain this with the badcompliance of e-mall texts to grammatical standards(cf.
the example in Figure 2).However, the practical usefulness of chunk parsingor even deeper language understanding such as se-mantic analysis may be questioned in general: In amoving domain, the coverage of linguistic knowledgewill always be incomplete, as it would be too expen-sive for a call center to have language technologyexperts keep pace with the occurrence of new to~ics.
Thus the preprocessing results will often differfor e-mails expressing the same problem and hencenot be useful for SML.As a result of the tests in our application domain,we identified a favorite statistical tool and found thattask-specific linguistic preprocessing is encouraging,while general STP is not.5 Imp lementat ion  and  UseIn this section we describe the integration of theICC-MAIL system into the workflow of the call cen-ter of AOL Bertelsmann Online GmbH & Co. KG,which answers requests about the German versionof AOL software.
A client/server solution was builtthat allows the call center agents to connect asclients to the ICe-MAIL server, which implementsthe system described in Section 3.
For this purpose,it was necessary to?
connect the server module to AOL's own Sybasedatabase that delivers the incoming mail anddispatches the outgoing answers, and to I ce -MAIL'S own database that stores the classifiede-mall texts;?
design the GUI of the client module in a self-explanatory and easy to use way (cf.
Figure 2).The agent reads in an e-mall and starts ICe-MAILusing GUI buttons.
She verifies the correctness ofthe suggested answer, displaying and perhaps se-lecting alternative solutions.
If the agent finds theappropriate answer within these proposals, the asso-ciated text is filled in at the correct position of theanswer e-mall.
If, on the other hand, no proposedsolution is found to be adequate, the ICe-MAIL toolcan still be used to manually select any text block1620" ~ GPF~) ~ In~allatice,~AOL.\[~CD, $o'el~alt, Ha~du~te~) FAO - (fmllnr~ i$ON\[~ Me4emBefore deinstalling the AOL-Soltware please check your folders for-downloaded data-saved passwordsand copy them into a backup folder.Then remove the AOL-Software using the Windows Control Panel andreinstall it from your CD.Alter reinstallation please copy the data from the bac~p folder intothe dght destinations.Figure 2: The GUI of the ICe-MAIL Client.
All labels and texts were translated by the authors.
The Englishinput is based on the following original text, which is similarly awkward though understandable: Wie macheich zurn mein Programm total deinstalieren, und wieder neu instalierem, mit, wen Sic mir senden Version4.0 ??????????????.
The suggested answer text is associated with the category named "Delete & ReinstallAOL 4.0".
Four alternative answers can be selected using the tabs.
The left-hand side window displays theactive category in context.from the database.
The ICe-MAIL client had to pro-vide the functionality of the tool already in use sincean additional tool was not acceptable to the agents,who are working under time pressure.In the answer e-mail window, the original e-mailis automatically added as a quote.
If an e-mail con-tains several questions, the classification process canbe repeated by marking each question and iterativelyapplying the process to the marked part.
The agentcan edit the suggested texts before sending them off.In each case, the classified text together with the se-lected category is stored in the ICe-MAIL databasefor use in future learning steps.Other features of the ICe-MAIL client module in-clude a spell checker and a history view.
The latterdisplays not only the previous e-mails of the sameauthor but also the solutions that have been pro-posed and the elapsed time before an answer wassent.The assumed average time for an agent to an-swer an e-mail is a bit more than two minutes withAOL's own mail processing system.
~With the ICC-MAIL system the complete cycle of fetching the mail,checking the proposed solutions, choosing the ap-propriate solutions, inserting additional text frag-ments and sending the answer back can probablybe achieved in half the time.
Systematic tests sup-~This system does not include automatic analysis of mails.porting this claim are not completed yet, s but thefollowing preliminary results are encouraging:?
A test under real-time conditions at the call-center envisaged the use of the ICe -MAIL  sys-tem as a mail tool only, i.e.
without taking ad-vantage of the system's intelligence.
It showedthat the surface and the look-and-feel is ac-cepted and the functionality corresponds to thereal-time needs of the call center agents, as userswere slightly faster than within their usual en-vironment.?
A preliminary test of the throughput achievedby using the STP and SML technology in I ce -MAIL showed that experienced users take about50-70 seconds on average for one cycle, as de-scribed above.
This figure was gained throughexperiments with three users over a duration ofabout one hour each.Using the system with a constant set of categorieswill improve its accuracy after repeating the off-linelearning step.
If a new category is introduced, theaccuracy will slightly decline until 30 documents aremanually classified and the category is automaticallyincluded into a new classifier.
Relearning may takeplace at regular intervals.
The definition of new cat-egories must be fed into ICe-MAIL by a "knowledge8As of end of February 2000.163engineer", who maintains the system.
The effects ofnew categories and new data have not been testedyet.The optimum performance of ICe-MAIL can beachieved only with a well-maintained category sys-tem.
For a call center, this may be a difficult taskto achieve, espescially under severe time pressure,but it will pay off.
In particular, all new categoriesshould be added, outdated ones should be removed,and redundant ones merged.
Agents should only usethese categories and no others.
The organizationalstructure of the team should reflect this by defin-ing the tasks of the "knowledge ngineer" and herinteractions with the agents.6 Conc lus ions  and  Future  WorkWe have presented new combinations of STP andSML methods to classify unrestricted e-mail text ac-cording to a changing set of categories.
The currentaccuracy of the ICC-MAIL system is 78% (correct so-lution among the top five proposals), correspondingto an overall performance of 73% since ICC-MAILprocesses only 94% of the incoming e-mails.
Theaccuracy improves with usage, since each relearningstep will yield better classifiers.
The accuracy is ex-pected to approximate that of the agents, but notimprove on it.
With ICe-MAIL, the performance ofan experienced agent can approximately be doubled.The system is currently undergoing extensive testsat the call center of AOL Bertelsmann Online.
De-tails about the development of the performance de-pending on the throughput and change of categoriesare expected to be available by mid 2000.Technically, we expect improvements from the fol-lowing areas of future work.?
Further task-specific heuristics aiming at gen-eral structural inguistic properties hould bedefined.
This includes heuristics for the identi-fication of multiple requests in a single e-mailthat could be based on key words and keyphrases as well as on the analysis of the doc-ument structure.?
Our initial experiments with the integrationof GermaNet (Hamp and Feldweg, 1997), theevolving German version of WordNet, seem toconfirm the positive results described for Word-Net (de Buenaga Rodriguez et al, 1997) andwill thus be extended.?
A reorganization f the existing three-level cate-gory system into a semantically consistent treestructure would allow us to explore the non-terminal nodes of the tree for multi-layeredSML.
This places additional requirements onthe knowledge ngineering task and thus needsto be thoroughly investigated for pay-off.?
Where system-generated answers are acceptableto customers, a straightforward extension ofICe-MAIL can provide this functionality.
Forthe application in hand, this was not the case.The potential of the technology presented extendsbeyond call center applications.
We intend to ex-plore its use within an information broking assis-tant in document classification.
In a further indus-trial project with German Telekom, the ICC-MAILtechnology will be extended to process multi-lingualpress releases.
The nature of these documents willallow us to explore the application of more sophis-ticated language technologies during linguistic pre-processing.AcknowledgmentsWe are grateful to our colleagues Giinter Neumann,Matthias Fischmann, Volker Morbach, and MatthiasRinck for fruitful discussions and for support withsines modules.
This work was partially supported bya grant of the Minister of Economy and Commerceof the Saarland, Germany, to the project ICC.ReferencesDavid W. Aha.
1992.
Tolerating noisy, irrelevantand novel attributes in instance based learning al-gorithms.
International Journal of Man-MachineStudies, 36(1), pages 267-287.Fabio Ciravegna, Alberto Lavelli, Nadia Mana, Jo-hannes Matiasek, Luca Gilardoni, Silvia Mazza,Massimo Ferraro, William J.Black, Fabio RJ-naldi, and David Mowatt.
1999.
Facile: Classi-fying texts integrating pattern matching and in-formation extraction.
In Proceedings of IJCAI'99,Stockholm, pages 890-895.William W. Cohen.
1995.
Fast effective rule induc-tion.
In Proceedings of the Twelfth InternationalConference on Machine Learning, Lake Tahoe,California.Manuel de Buenaga Rodriguez, Jose Maria Gomez-Hidalgo, and Belen Diaz-Agudo.
1997.
UsingWordNet to complement training information intext categorization.
In Proceedings of the SecondInternational Conference on Recent Advances inNatural Language Processing, Montreal, Canada.I.J.
Good.
1965.
The Estimation of Probabilities.An Essay on Modern Bayesian Methods.
MIT-Press.Birgit Hamp and Helmut Feldweg.
1997.
GermaNet- a lexical-semantic net for German.
In Proceed-ings of A CL workshop Automatic Information Ex-traction and Building of Lexical Semantic Re-sources for NLP Applications, Madrid, SpainThorsten Joachims.
1998.
Text categorization withsupport vector machines - learning with meanyrelevant features.
In Proceedings of the Euro-164pean Conference on Machine Learning (ECML),Chemnitz, Germany, pages 137-142.Ronny Kohavi and Dan Sommerfield, 1996.MLC++ Machine Learning library in C++.http://www.sgi.com/Technology/mlc.Teuvo Kohonen, Jussi Hynninen, Jari Kangas,Jorma Laaksonen, and Kari Torkkola.
1996.LVQ-PAK the learning vector quantization pro-gram package.
Technical Report A30, HelsinkiUniversity of Technology.G/inter Neumann, Rolf Backofen, Judith Baur,Markus Becket, and Christian Braun.
1997.
Aninformation extraction core system for real worldGerman text processing.
In Proceedings of 5thANLP, Washington, pages 209-216.G/inter Neumann and Sven Schmeier.
1999.
Com-bining shallow text processing and macine learn-ing in real world applications.
In Proceedings ofIJCAI workshop on Machine Learning for Infor-mation Filtering, Stockholm, pages 55-60.J.R.
Quinlan.
1986.
Induction of Decision Trees.Reprinted in Shavlik, Jude W. and Dietterich,Thomas G, Readings in machine learning.
Ma-chine learning series.
Morgan Kaufmann (1990)J.R. Quinlan.
1992.
C4.5: Programs for MachineLearning.
Morgan Kaufmann, San Mateo, Cali-fornia.J.R.
Quinlan.
1996.
Bagging, Boosting and C4.5.
InProceedings of AAAI'96, Portland, pages 725-730.Vladimir N. Vapnik.
1995.
The Nature of StatisticalLearning Theory.
Springer.E.D.
Wiener, J. Pedersen, and A.S. Weigend.
1995.A neural network approach to topic spotting.
InProceedings of the SDAIR.Y.
Yang and Xin Liu.
1999.
A re-examination ftext categorization methods.
In Proceedings ofA CMSIGIR Conference on Research and Devel-opment in Information Retrieval, Berkley, Calfor-nia.Y.
Yang and J.P. Pedersen.
1997.
A comparativestudy on feature selection.
In Proceedings of theFourteenth International Conference on MachineLearning (ICML '97).Y.
Yang.
1999.
An evaluation of statistical ap-proaches to text categorization.
Information Re-trieval Journal (May 1999).165
