Language Model Adaptation for Statistical Machine Translationwith Structured Query ModelsBing Zhao    Matthias Eck     Stephan VogelCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA, 15213, USA{bzhao, matteck, vogel+}@cs.cmu.eduAbstractWe explore unsupervised language modeladaptation techniques for Statistical MachineTranslation.
The hypotheses from themachine translation output are converted intoqueries at different levels of representationpower and used to extract similar sentencesfrom very large monolingual text collection.Specific language models are then build fromthe retrieved data and interpolated with ageneral background model.
Experimentsshow significant improvements whentranslating with these adapted languagemodels.1 IntroductionLanguage models (LM) are applied in manynatural language processing applications, such asspeech recognition and machine translation, toencapsulate syntactic, semantic and pragmaticinformation.
For systems which learn from givendata we frequently observe a severe drop inperformance when moving to a new genre or newdomain.
In speech recognition a number ofadaptation techniques have been developed to copewith this situation.
In statistical machinetranslation we have a similar situation, i.e.
estimatethe model parameter from some data, and use thesystem to translate sentences which may not bewell covered by the training data.
Therefore, thepotential of adaptation techniques needs to beexplored for machine translation applications.Statistical machine translation is based on thenoisy channel model, where the translationhypothesis is searched over the space defined by atranslation model and a target language (Brown etal, 1993).
Statistical machine translation can beformulated as follows:)()|(maxarg)|(maxarg* tPtsPstPttt?==where t is the target sentence, and s is the sourcesentence.
P(t) is the target language model andP(s|t) is the translation model.
The argmaxoperation is the search, which is done by thedecoder.In the current study we modify the targetlanguage model P(t), to represent the test databetter, and thereby improve the translation quality.
(Janiszek, et al 2001) list the following approachesto language model adaptation:?
Linear interpolation of a general and a domainspecific model (Seymore, Rosenfeld, 1997).?
Back off of domain specific probabilities withthose of a specific model (Besling, Meier,1995).?
Retrieval of documents pertinent to the newdomain and training a language model on-linewith those data (Iyer, Ostendorf, 1999,Mahajan et.
al.
1999).?
Maximum entropy, minimum discriminationadaptation (Chen, et.
al., 1998).?
Adaptation by linear transformation of vectorsof bigram counts in a reduced space (DeMori,Federico, 1999).?
Smoothing and adaptation in a dual space vialatent semantic analysis, modeling long-termsemantic dependencies, and triggercombinations.
(J. Bellegarda, 2000).Our approach can be characterized asunsupervised data augmentation by retrieval ofrelevant documents from large monolingualcorpora, and interpolation of the specific languagemodel, build from the retrieved data, with abackground language model.
To be more specific,the following steps are carried out to do thelanguage model adaptation.
First, a baselinestatistical machine translation system, using a largegeneral language model, is applied to generateinitial translations.
Then these translationshypotheses are reformulated as queries to retrievesimilar sentences from a very large text collection.A small domain specific language model is buildusing the retrieved sentences and linearlyinterpolated with the background language model.This new interpolated language model in applied ina second decoding run to produce the finaltranslations.There are a number of interesting questionspertaining to this approach:?
Which information can and should used togenerate the queries: the first-best translationonly, or also translation alternatives.?
How should we construct the queries, just assimple bag-of-words, or can we incorporate morestructure to make them more powerful.?
How many documents should be retrieved tobuild the specific language models, and on whatgranularity should this be done, i.e.
what is adocument in the information retrieval process.The paper is structured as follows:  section 2outlines the sentence retrieval approach, and threebag-of-words query models are designed andexplored; structured query models are introducedin section 3.
In section 4 we present translationexperiments are presented for the different query.Finally, summary is given in section 5.2 LM Adaptation via Sentence RetrievalOur language model adaptation is an unsuperviseddata augmentation approach guided by querymodels.
Given a baseline statistical machinetranslation system, the language model adaptationis done in several steps shown as follows:?
Generate a set of initial translationhypotheses H = {h1 ?hn} for sourcesentences s, using either the baseline MTsystem with the background languagemodel or only the translation model?
Use H  to build query?
Use query to retrieve relevant sentencesfrom the large corpus?
Build specific language models fromretrieved sentences?
Interpolate the specific language modelwith the background language?
Re-translate sentences s with adaptedlanguage modelFigure-1: Adaptation AlgorithmThe specific language model )|( hwP iA  and thegeneral background model )|( hwP iB  are combinedusing linear interpolation:)|()1()|()|(?
hwPhwPhwP iAiBi ??
?+=  (1)The interpolation factor ?
can be simplyestimated using cross validation or a grid search.As an alternative to using translations for thebaseline system, we will also describe an approach,which uses partial translations of the sourcesentence, using the translation model only.
In thiscase, no full translation needs to be carried out inthe first step; only information from the translationmodel is used.Our approach focuses on query model building,using different levels of knowledge representationsfrom the hypothesis set or from the translationmodel itself.
The quality of the query models iscrucial to the adapted language model?sperformance.
Three bag-of-words query modelsare proposed and explained in the followingsections.2.1 Sentence Retrieval ProcessIn our sentence retrieval process, the standard tf/idf(term frequency and inverse document frequency)term weighting scheme is used.
The queries arebuilt from the translation hypotheses.
We follow(Eck, et al, 2004) in considering each sentence inthe monolingual corpus as a document, as theyhave shown that this gives better results comparedto retrieving entire news stories.Both the query and the sentences in the textcorpus are converted into vectors by assigning aterm weight to each word.
Then the cosinesimilarity is calculated proportional to the innerproduct of the two vectors.
All sentences areranked according to their similarity with the query,and the most similar sentences are used as the datafor building the specific language model.
In ourexperiments we use different numbers of similarsentences, ranting from one to several thousand.2.2 Bag-of-words Query ModelsDifferent query models are designed to guide thedata augmentation efficiently.
We first define?bag-of-words?
models, based on different levelsof knowledge collected from the hypotheses of thestatistical machine translation engine.2.2.1 First-best Hypothesis as a Query ModelThe first-best hypothesis is the Viterbi path in thesearch space returned from the statistical machinetranslation decoder.
It is the optimal hypothesisthe statistical machine translation system cangenerate using the given translation and languagemodel, and restricted by the applied pruningstrategy.
Ignoring word order, the hypothesis isconverted into a bag-of-words representation,which is then used as a query:}|),{(),,( 1211 TiiilT VwfwwwwQ ?== Lwhere iw is a word in the vocabulary 1TV of the Top-1 hypothesis.
if  is the frequency of iw ?soccurrence in the hypothesis.The first-best hypothesis is the actual translationwe want to improve, and usually it capturesenough correct word translations to secure a soundadaptation process.
But it can miss someinformative translation words, which could lead tobetter-adapted language models.2.2.2  N-Best Hypothesis List as a Query ModelSimilar to the first-best hypothesis, the n-besthypothesis list is converted into a bag-of-wordsrepresentation.
Words which occurred in severaltranslation hypotheses are simply repeated in thebag-of-words representations.
}|),{(),,;;,,( ,2,1,,12,11,1 1TNiiilNNNlTNVwfwwwwwwwQN?== LLLwhere TNV  is the combined vocabulary from all n-best hypotheses and if  is the frequency of iw ?soccurrence in the n-best hypothesis list.TNQ  has several good characteristics:  First itcontains translation candidates, and thus is moreinformative than 1TQ .
In addition, the confidentlytranslated words usually occur in every hypothesisin the n-best list, therefore have a stronger impacton the retrieval result due to the higher termfrequency (tf) in the query.
Thirdly, most of thehypotheses are only different from each other inone word or two.
This means, there is not so muchnoise and variance introduced in this query model.2.2.3 Translation Model as a Query ModelTo fully leverage the available knowledge from thetranslation system, the translation model can beused to guide the language model adaptationprocess.
As introduced in section 1, the translationmodel represents the full knowledge of translatingwords, as it encodes all possible translationscandidates for a given source sentence.
Thus thequery model based on the translation model, haspotential advantages over both 1TQ  and TNQ .To utilize the translation model, all the n-gramsfrom the source sentence are extracted, and thecorresponding candidate translations are collectedfrom the translation model.
These are thenconverted into a bag-of-words representation asfollows:}|),{(),,;;,,( ,2,1,,2,1, 1111TMiiinsssnsssTMVwfwwwwwwwQIIII?== LLLwhere is  is a source n-gram, and I is the number ofn-grams in the source sentence.
jsiw ,  is a candidatetarget word as translation of is .
Thus thetranslation model is converted into a collection oftarget words as a bag-of-word query model.There is no decoding process involved to buildTMQ .
This means TMQ  does not incorporate anybackground language model information at all,while both 1TQ  and TNQ  implicitly use thebackground language model to prune the words inthe query.
Thus TMQ  is a generalization, and 1TQand TNQ  are pruned versions.
This also means TMQis subject to more noise.3 Structured Query ModelsWord proximity and word order is closely relatedto syntactic and semantic characteristics.However, it is not modeled in the query modelspresented so far, which are simple bag-of-wordsrepresentations.
Incorporating syntactic andsemantic information into the query models canpotentially improve the effectiveness of LMadaptation.The word-proximity and word orderinginformation can be easily extracted from the first-best hypothesis, the n-best hypothesis list, and thetranslation lattice built from the translation model.After extraction of the information, structuredquery models are proposed using the structuredquery language, described in the Section 3.1.3.1 Structured Query LanguageThis query language essentially enables the use ofproximity operators (ordered and unorderedwindows) in queries, so that it is possible to modelthe syntactic and semantic information encoded inphrases, n-grams, and co-occurred word pairs.The InQuery implementation (Lemur 2003) isapplied.
So far 16 operators are defined inInQuery to model word proximity (ordered,unordered, phrase level, and passage level).
Fourof these operators are used specially for ourlanguage model adaptation:Sum Operator: #sum( 1t ?
nt )The terms or nodes ( 1t ?
nt ) are treated ashaving equal influence on the final retrieval result.The belief values provided by the arguments of thesum are averaged to produce the belief value of the#sum node.Weighted Sum Operator: #wsum( 11 : tw , ?
)The terms or nodes ( 1t ?
nt ) contributeunequally to the final result according to theweight ( iw ) associated with each it .Ordered Distance Operator: #N( 1t ?
nt )The terms must be found within N words ofeach other in the text in order to contribute to thedocument's belief value.
An n-gram phrase can bemodeled as an ordered distance operator with N=n.Unordered Distance Operator: #uwN( 1t ?
nt )The terms contained must be found in any orderwithin a window of N words in order for thisoperator to contribute to the belief value of thedocument.3.2 Structured Query ModelsGiven the representation power of the structuredquery language, the Top-1 hypothesis, Top-N Besthypothesis list, and the translation lattice can beconverted into three Structured Query Modelsrespectively.For first-best and n-best hypotheses, we collectrelated target n-grams of a given source wordaccording to the alignments generated in theViterbi decoding process.
While for the translationlattice, similar to the construction of TMQ , wecollect all the source n-grams, and translate theminto target n-grams.
In either case, we get a set oftarget n-grams for each source word.
Thestructured query model for the whole sourcesentence is a collection of such subsets of target n-grams.
},,,{21 IssssttttQvLvv=istvis a set of target n-grams for the source word is :}}{;},{;},{{ 311211 LLLvgramiiigramiigramis ttttttt i ?+?
?+?=In our experiments, we consider up to trigram forbetter retrieval efficiency, but higher order n-gramscould be used as will.
The second simplification isthat every source word is equally important, thuseach n-gram subsetistvwill have an equalcontribution to the final retrieval results.
The lastsimplification is each n-gram within the set ofistvhas an equal weight, i.e.
we do not use thetranslation probabilities of the translation model.If the system is a phrase-based translation system,we can encode the phrases using the ordereddistance operator (#N) with N equals to the numberof the words of that phrase, which is denoted as the#phrase operator in InQuery implementation.
The2-grams and 3-grams can be encoded using thisoperator too.Thus our final structured query model is a sumoperator over a set of nodes.
Each nodecorresponds to a source word.
Usually each sourceword has a number of translation candidates(unigrams or phrases).
Each node is a weightedsum over all translation candidates weighted bytheir frequency in the hypothesis set.
An exampleis shown below, where #phrase indicates the use ofthe ordered distance operator with varying n:#q=#sum( #wsum(2 eu  2 #phrase(european union) )#wsum(12 #phrase(the united states)1 american 1 #phrase(an american) )#wsum(4 are 1 is )#wsum(8 markets  3 market))#wsum(7 #phrase(the main)  5 primary ) );4 ExperimentsExperiments are carried out on a standardstatistical machine translation task defined in theNIST evaluation in June 2002.
There are 878 testsentences in Chinese, and each sentence has fourhuman translations as references.
NIST score(NIST 2002) and Bleu score (Papineni et.
al.
2002)of mteval version 9 are reported to evaluate thetranslation quality.4.1  Baseline Translation SystemOur baseline system (Vogel et al, 2003) givesscores of 7.80 NIST and 0.1952 Bleu for Top-1hypothesis, which is comparable to the best resultsreported on this task.For the baseline system, we built a translationmodel using 284K parallel sentence pairs, and atrigram language model from a 160 million wordsgeneral English news text collection.
This LM isthe background model to be adapted.With the baseline system, the n-best hypotheseslist and the translation lattice are extracted to buildthe query models.
Experiments are carried out onthe adapted language model using the three bag-of-words query models: 1TQ , TNQ  and TMQ , and thecorresponding structured query models.4.2 Data: GigaWord CorporaThe so-called GigaWord corpora (LDC, 2003) arevery large English news text collections.
There arefour distinct international sources of Englishnewswire:AFE Agence France Press English ServiceAPW Associated Press Worldstream English ServiceNYT The New York Times Newswire ServiceXIE The Xinhua News Agency English ServiceTable-1 shows the size of each part in word counts.AFE APW NYT XIE170,969K 539,665K 914,159K 131,711KTable-1: Number of words in the differentGigaWord corporaAs the Lemur toolkit could not handle the twolarge corpora (APW and NYT) we used only 200million words from each of these two corpora.In the preprocessing all words are lowercasedand punctuation is separated.
There is no explicitremoval of stop words as they usually fade out bytf.idf weights, and our experiments showed notpositive effects when removing stop words.4.3 Bag-of-Words Query ModelsTable-2 shows the size of 1TQ , TNQ  and TMQ  interms of number of tokens in the 878 queries:1TQ  TNQ  TMQ|| Q  25,861 231,834 3,412,512Table-2: Query size in number of tokensAs words occurring several times are reduced toword-frequency pairs, the size of the queriesgenerated from the 100-best translation lists is only9 times as big as the queries generated from thefirst-best translations.
The queries generated fromthe translation model contain many moretranslation alternatives, summing up to almost 3.4million tokens.
Using the lattices the wholeinformation of the translation model is kept.4.3.1 Results for Query 1TQIn the first experiment we used the first-besttranslations to generate the queries.
For each ofthe 4 corpora different numbers of similarsentences (1, 10, 100, and 1000) were retrieved tobuild specific language models.
Figure-2 showsthe language model adaptation after tuning theinterpolation factor ?
by a grid search over [0,1].Typically ?
is around 0.80.1-Best/NIST Scores7.75007.80007.85007.90007.95008.0000AFE APW NYT XIETop1Top10Top100Top1000Baseline1-Best/BLEU-Scores0.19000.19200.19400.19600.19800.20000.20200.2040AFE APW NYT XIETop1Top10Top100Top1000BaselineFigure-2: NIST and Bleu scores1TQWe see that each corpus gives an improvementover the baseline.
The best NIST score is 7.94,and the best Bleu score is 0.2018.
Both best scoresare realized using top 100 relevant sentencescorpus per source sentence mined from the AFE.4.3.2 Results for Query TNQFigure-3 shows the results for the query model TNQ .The best results are 7.99 NIST score, and 0.2022Bleu score.
These improvements are statisticallysignificant.
Both scores are achieved at the samesettings as those in 1TQ , i.e.
using top 100 retrievedrelevant sentences mined from the AFE corpus.100-Best/NIST-Scores7.75007.80007.85007.90007.95008.0000AFE APW NYT XIETop1Top10Top100Top1000Baseline100-Best/BLEU-Scores0.19000.19200.19400.19600.19800.20000.20200.2040AFE APW NYT XIETop1Top10Top100Top1000BaselineFigure-3: NIST and Bleu scores from TNQUsing the translation alternatives to retrieve thedata for language model adaptation gives animprovement over using the first-best translationonly for query construction.
Using only onetranslation hypothesis to build an adapted languagemodel has the tendency to reinforce thattranslation.4.3.3 Results for Query TMQThe third bag-of-words query model uses alltranslation alternatives for source words and sourcephrases.
Figure-4 shows the results of this querymodel TMQ .
The best results are 7.91 NIST scoreand 0.1995 Bleu.
For this query model best resultswere achieved using the top 1000 relevantsentences mined from the AFE corpus per sourcesentence.The improvement is not as much as the othertwo query models.
The reason is probably that alltranslation alternatives, even wrong translationsresulting from errors in the word and phrasealignment, contribute alike to retrieve similarsentences.
Thereby, an adapted language model isbuilt, which reinforces not only good translations,but also bad translations.All the three query models showedimprovements over the baseline system in terms ofNIST and Bleu scores.
The best bag-of-wordsquery model is TNQ  built from the N-Best list.
Itprovides a good balance between incorporatingtranslation alternatives in the language modeladaptation process and not reinforcing wrongtranslations.Lattice/NIST-Scores7.75007.80007.85007.90007.95008.0000AFE APW NYT XIETop1Top10Top100Top1000BaselineLattice/BLEU-Scores0.19000.19200.19400.19600.19800.20000.20200.2040AFE APW NYT XIETop1Top10Top100Top1000BaselineFigure-4: NIST and Bleu scores from TMQ4.4 Structured Query ModelsThe next series of experiments was done tostudy if using word order information inconstructing the queries could help to generatemore effective adapted language models.
By usingthe structured query language we converted thesame first-best hypothesis, the 100-best list, andthe translation lattice into structured query models.Results are reported for the AFE corpus only, asthis corpus gave best translation scores.Figure-5 shows the results for all three structuredquery models, built from the first-best hypothesis(?1-Best?
), the 100 best hypotheses list (?100-Best?
), and translation lattice (?TM-Lattice?
).Using these query models, different numbers ofmost similar sentences, ranging from 100 to 4000,where retrieved from the AFE corpus.
The givenbaseline results are the best results achieved fromthe corresponding bag-of-words query models.Consistent improvements were observed onNIST and Bleu scores.
Again, optimalinterpolation factors to interpolate the specificlanguage models with the background languagemodel were used, which typically were in therange of [0.6, 0.7].
Structured query models givemost improvements when using more sentences forlanguage model adaptation.
The effect is morepronounced for Bleu then for NIST score.Structured query/NIST-Scores7.75007.80007.85007.90007.95008.00008.05008.10008.1500Baseline Top100 Top500 Top1000 Top2000 Top40001-Best100-BestTM-LatticeStructured query/BLEU-Scores0.19200.19400.19600.19800.20000.20200.20400.20600.2080Baseline Top100 Top500 Top1000 Top2000 Top40001-Best100-BestTM-LatticeFigure-5: NIST and Bleu scores from thestructured query modelsThe really interesting result is that the structuredquery model TMQ gives now the best translationresults.
Adding word order information to thequeries obviously helps to reduce the noise in theretrieved data by selecting sentences, which arecloser to the good translations,The best results using the adapted languagemodels are NIST score 8.12 for using the 2000most similar sentences, whereas Bleu score goesup to 0.2068 when using 4000 sentences forlanguage model adaptation.4.5 ExampleTable-3 shows translation examples for the 17thChinese sentence in the test set.
We applied thebaseline system (Base), the bag-of-word querymodel (Hyp1), and the structured query model(Hyp2) using AFE corpus.Ref The police has already blockade the scene of the explosion.Base At present, the police had cordoned off the explosion.Hyp1 At present, police have sealed off the explosion.Hyp2 Currently, police have blockade on the scene of the explosion.Table-3 Translation examples4.6 Oracle ExperimentFinally, we run an oracle experiments to seehow much improvement could be achieved if weonly selected better data for the specific languagemodels.
We converted the four available referencetranslations into structured query models andretrieved the top 4000 relevant sentences fromAFE corpus for each source sentence.
Using theselanguage models, interpolated with the backgroundlanguage model gave a NIST score of 8.67, and aBleu score of 0.2228.
This result indicates thatthere is room for further improvements using thislanguage model adaptation technique.The oracle experiment suggests that better initialtranslations lead to better language models andthereby better 2nd iteration translations.
This leadto the question if we can iterate the retrievalprocess several times to get further improvement,or if the observed improvement results form usingfor (good) translations, which have more diversitythan the translations in an n-best list.On the other side the oracle experiment alsoshows that the optimally expected improvement islimited by the translation model and decodingalgorithm used in the current SMT system.5 SummaryIn this paper, we studied language modeladaptation for statistical machine translation.Extracting sentences most similar to the initialtranslations, building specific language models foreach sentence to be translated, and interpolatingthose with the background language models givessignificant improvement in translation quality.Using structured query models, which captureword order information, leads to better results thatplain bag of words models.The results obtained suggest a number ofextensions of this work:  The first question is ifmore data to retrieve similar sentences from willresult in even better translation quality.
A secondinteresting question is if the translationprobabilities can be incorporated into the queries.This might be especially useful for structuredquery models generated from the translationlattices.ReferencesJ.
Bellegarda.
2000, Exploiting Latent SemanticInformation in Statistical Language Modeling.
InProceedings of the IEEE, 88(8), pp.
1279-1296.S.
Besling and H.G.
Meier 1995.
Language ModelSpeaker Adaptation, Eurospeech 1995, Madrid,Spain.Peter F Brown., Stephen A Della Pietra., Vincent J.Della Pietra and Mercer Robert L., 1993.
TheMathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguistics,19(2), pp.
263?311.S.F Chen., K. Seymore, and R. Rosenfeld 1998.
TopicAdaptation for Language Modeling usingUnnormalized Exponential Models.
IEEEInternational Conference on Acoustics, Speech andSignal Processing 1998, Seattle WA.Renato DeMori and Marcello Federico 1999.
LanguageModel Adaptation, In Computational Models ofSpeech Pattern Processing, Keith Pointing (ed.
),NATO ASI Series, Springer Verlag.Matthias Eck, Stephan Vogel, and Alex Waibel, 2004.Language Model Adaptation for StatisticalMachine Translation based on Information Retrieval,International Conference on Language Resources andEvaluation, Lisbon, Portugal.R.
Iyer and M. Ostendorf, 1999.
Modeling LongDistance Dependence in Language: Topic Mixturesvs.
Dynamic Cache Models, IEEE Transactions onSpeech and Audio Processing, SAP-7(1): pp.
30-39.David Janiszek, Renato DeMori and Frederic Bechet,2001.
Data Augmentation and Language Modeladaptation, IEEE International Conference onAcoustics, Speech and Signal Processing 2001, SaltLake City, UT.LDC, Gigaword Corpora.
http://wave.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2003T05Lemur, The Lemur Toolkit for Language Modeling andInformation Retrieval, http://www.cs.cmu.edu/~lemur/Milind Mahajan, Doug Beeferman and X.D.
Huang,1999.
Improved Topic-Dependent LanguageModeling Using Information Retrieval Techniques,IEEE International Conference on Acoustics, Speechand Signal Processing 1999, Phoenix, AZ.NIST Report: 2002, Automatic Evaluation of MachineTranslation Quality Using N-gram Co-OccurrenceStatistics.
http://www.nist.gov/speech/tests/mt/doc/ngram-study.pdf .Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu, 2002.
BLEU: A Method for AutomaticEvaluation of Machine Translation.
In Proc of the40th Annual Meeting of the Association forComputational Linguistics.
2002, Philadelphia, PA.Kristie Seymore and Ronald Rosenfeld, 1997.
UsingStory Topics for Language Model Adaptation.
InProc.
Eurospeech 1997, Rhodes, Greece.Stephan Vogel, Ying Zhang, Fei Huang, Alicia Tribble,Ashish Venogupal, Bing Zhao, Alex Waibel, 2003.The CMU Statistical Translation System, Proceedingsof MT-Summit IX, 2003, New Orleans, LA.
