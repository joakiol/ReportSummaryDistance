c?
2003 Association for Computational LinguisticsAutomatic Association of Web Directorieswith Word SensesCelina Santamar??a?
Julio Gonzalo?
Felisa Verdejo?UNED, Madrid UNED, Madrid UNED, MadridWe describe an algorithm that combines lexical information (from WordNet 1.7) with Web di-rectories (from the Open Directory Project) to associate word senses with such directories.
Suchassociations can be used as rich characterizations to acquire sense-tagged corpora automatically,cluster topically related senses, and detect sense specializations.
The algorithm is evaluated forthe 29 nouns (147 senses) used in the Senseval 2 competition, obtaining 148 (word sense, Webdirectory) associations covering 88% of the domain-specific word senses in the test data with 86%accuracy.
The richness of Web directories as sense characterizations is evaluated in a supervisedword sense disambiguation task using the Senseval 2 test suite.
The results indicate that, whenthe directory/word sense association is correct, the samples automatically acquired from the Webdirectories are nearly as valid for training as the original Senseval 2 training instances.
The re-sults support our hypothesis that Web directories are a rich source of lexical information: cleaner,more reliable, and more structured than the full Web as a corpus.1.
IntroductionCombining the size and diversity of the textual material on the World Wide Webwith the power and efficiency of current search engines is an attractive possibility foracquiring lexical information and corpora.
A widespread example is spell-checking:Many Web users routinely use search engines to assess which is the ?correct?
(i.e.
withmore hits in the Web) spelling of words.
Among NLP researchers, Web search engineshave already been used as a point of departure for extraction of parallel corpora,automatic acquisition of sense-tagged corpora, and extraction of lexical information.Extraction of parallel corpora.
In Resnik (1999), Nie, Simard, and Foster (2001),Ma and Liberman (1999), and Resnik and Smith (2002), the Web is harvested in searchof pages that are available in two languages, with the aim of building parallel corporafor any pair of target languages.
This is a very promising technique, as many machinetranslation (MT) and cross-language information retrieval (CLIR) strategies rely onthe existence of parallel corpora, which are still a scarce resource.
Such Web-minedparallel corpora have proved to be useful, for instance, in the context of the CLEF(Cross-Language Evaluation Forum) CLIR competition, in which many participantsuse such parallel corpora (provided by the University of Montreal) to improve theperformance of their systems (Peters et al 2002).Automatic acquisition of sense-tagged corpora.
The description of a word sensecan be used to build rich queries in such a way that the occurrences of the word inthe documents retrieved are, with some probability, associated with the desired sense.If the probability is high enough, it is then possible to acquire sense-tagged corpora?
ETS Ingenier?
?a Informa?tica de la UNED, c/ Juan del Rosal, 16, Ciudad Universitaria, 28040 Madrid,Spain.
E-mail: {celina,julio,felisa}@lsi.uned.es486Computational Linguistics Volume 29, Number 3in a fully automatic fashion.
Again, this is an exciting possibility that would solve thecurrent bottleneck of supervised word sense disambiguation (WSD) methods (namely,that sense-tagged corpora are very costly to acquire).One example of this kind of technique is Mihalcea and Moldovan (1999), in whicha precision of 91% is reported over a set of 20 words with 120 senses.
In spite of thehigh accuracy obtained, such methodology did not perform well in the comparativeevaluation reported in Agirre and Mart?
?nez (2000), perhaps indicating that examplesobtained from the Web may have topical biases (depending on the word), and thatfurther refinement is required.
For instance, a technique that behaves well with a smallset of words might fail in the common cases in which a new sense is predominanton the Web (e.g., oasis or nirvana as music groups, tiger as a golfer, jaguar as a carbrand).Extraction of lexical information.
In Agirre et al (2000), search engines and theWeb are used to assign Web documents to WordNet concepts.
The resulting sets ofdocuments are then processed to build topic signatures, that is, sets of words withweights that enrich the description of a concept.
In Grefenstette (1999), the number ofhits in Web search engines is used as a source of evidence to select optimal translationsfor multiword expressions.
For instance, apple juice is selected as a better translationthan apple sap for the German ApfelSaft because apple juice hits a thousand times moredocuments in AltaVista.
Finally, in Joho and Sanderson (2000) and Fujii and Ishikawa(1999), the Web is used as a resource to provide descriptive phrases or definitions fortechnical terms.A common problem to all the above applications is how to detect and filter outall the noisy material on the Web, and how to characterize the rest (Kilgarriff 2001b).Our starting hypotheses is that Web directories (e.g., Yahoo, AltaVista or Googledirectories, the Open Directory Project [ODP]), in which documents are mostly manu-ally classified in hierarchical topical clusters, are an optimal source for acquiring lexicalinformation; their size is not comparable to the full Web, but they are still enormoussources of semistructured, semifiltered information waiting to be mined.In this article, we describe an algorithm for assigning Web directories (from theOpen Directory Project ?http://dmoz.org?)
as characterizations for word senses inWordNet 1.7 noun synsets (Miller 1990).
For instance, let us consider the noun circuit,which has six senses in WordNet 1.7.
These senses are grouped in synsets, togetherwith their synonym terms, and linked to broader (more general) synsets via hyper-nymy relations:6 senses of circuitSense 1: {circuit, electrical circuit, electric circuit} => {electrical device}Sense 2: {tour, circuit} => {journey, journeying}Sense 3: {circuit} => {path, route, itinerary}Sense 4: {circuit (judicial division)} => {group, grouping}Sense 5: {racing circuit, circuit} => {racetrack, racecourse, raceway, track}Sense 6: {lap, circle, circuit} => {locomotion, travel}Our algorithm associates circuit 1 (electric circuit) with ODP directories such asbusiness/industries/electronics and electrical/contract manufacturers487Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word Senseswhereas circuit 5 (racing circuit) is tagged with directories such assports/motorsports/auto racing/trackssports/equestrian/racing/trackssports/motorsports/auto racing/formula oneEvery ODP directory has an associated URL, which contains a description of thedirectory and a number of Web sites that have been manually listed as pertaining to thedirectory topic, accompanied by brief descriptions of each site.
This information is com-pleted with a list of subdirectories, each containing more Web sites and subdirectories.Finally, some directories also have pointers to the same category in other languages.For instance, the Web page for the directory sports/motorsports/auto racing/tracks can beseen in Figure 1.
This directory contains links and descriptions for 846 Web sites orga-nized in 12 subdirectories, a link to a related directory (sports/motorsports/karting/tracks)and a link to the same category in French.The association of word senses with Web directories is related to the assignmentof domain labels to WordNet synsets as described in Magnini and Cavaglia (2000), inwhich WordNet is (manually) enriched with domain categories from the Dewey Dec-imal Classification (DDC).
Some clear differences between the two are that directoriesfrom the ODP are assigned automatically, are richer and deeper and, more importantly,Figure 1Contents of an ODP Web directory associated with circuit 5 (racing circuit).488Computational Linguistics Volume 29, Number 3come with a large amount of associated information directly retrievable from the Web.DDC categories, on the other hand, are a stable domain characterization compared toWeb directories.As WordNet and ODP are both hierarchical structures, connecting them is alsorelated to research in mapping thesauruses for digital libraries, ontologies, and datastructures in compatible databases.
A salient feature of our task is, however, that wedo not intend to map both structures, as they are of a quite different nature (lexicalizedEnglish concepts versus topics on the Web).
Our goal is rather to associate individualitems in a many-to-many fashion.
A word sense may be characterized with severalWeb directories, and a Web directory may be suitable for many word senses.The most direct applications of word sense/Web directory associations are?
Clustering of senses with identical or very similar categories.?
Refinement of senses into specialized variants (e.g., equestrian circuit andformula one circuit as specializations of racing circuit in the example above).?
Extraction of sense-tagged corpora from the Web sites listed under theappropriate directories.In Section 2 we describe the proposed algorithm.
In Section 3, we evaluate theprecision and recall of the algorithm for the set of nouns used in the Senseval 2 WSDcompetition.
In Section 4, we make a preliminary experiment using the material fromODP directories as training corpora for a supervised WSD system.
In section 5, wepresent the results of applying the algorithm to most WordNet 1.7 nouns.
Finally, inSection 6 we draw some conclusions.2.
AlgorithmOverall, the system takes a WordNet 1.7 noun as input, generates and submits a setof queries into the ODP, filters the information obtained from the search engine, andreturns a set of ODP directories classified as (1) pseudo?domain labels for some wordsense, (2) noise, and (3) salient noise (i.e., directories that are not suitable for any sensein WordNet but could reveal and characterize a new relevant sense of the noun).
Incase (1), the WordNet sense ?
ODP directory association also receives a probabilityscore.
A detailed description of the algorithm steps follows.2.1 Querying ODP StructureFor every sense wi of the noun w, a query qi is generated, including w as compulsoryterm, the synonyms and direct hypernyms of wi as optional terms, and the synonymsof other senses of w as negated (forbidden) terms.
These queries are submitted to ODP,and a set of directories is retrieved.
For instance, for circuit, the following queries aregenerated and sent to the ODP search engine:1q1= [+circuit "electrical circuit" "electric circuit" "electrical device" -tour-"racing circuit" -lap -circle]q2= [+circuit tour journey journeying -"electrical circuit" -"electric circuit"-"electrical device" -"racing circuit" -lap -circle]1 In ODP queries, compulsory terms are denoted by + and forbidden terms by ?.489Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word Sensesq3= [+circuit path route itinerary -"electrical circuit" -"electric circuit"-"electrical device" -tour -"racing circuit" -lap -circle ]q4= [+circuit group grouping -"electrical circuit" -"electric circuit"-"electrical device" -tour -"racing circuit" -lap -circle]q5= [+circuit "racing circuit" racetrack racecourse raceway track -"electrical circuit"-"electric circuit" -"electrical device" -tour -lap -circle]q6= [+circuit lap circle locomotion travel -"electrical circuit" -"electric circuit"-"electrical device" -tour -"racing circuit" -lap -circle]2.2 Representing Retrieved Directory DescriptionsFor every directory d, a list of words l(d) is obtained removing stopwords and pre-serving all content words in the directory path.
For instance, one of the directoriesproduced by the circuit queries isd = business/industries/electronics and electrical/contract manufacturerswhich is characterized by the following word list:l(d) = [business, industries, electronics, electrical, contract, manufacturers]2.3 Representing WordNet SensesFor every sense wj, a list l(wj) of words is made with?
all nouns in the hypernym chain of maximal length 6?
all hyponyms?
all meronyms, holonyms, and coordinate termsof wj in WordNet.
l(wj) is used as a description of the sense wj.
For instance, circuit 1receives the following description:l(circuit1) = [electrical circuit, electric circuit, electrical device, bridge,bridge circuit, Wheatstone bridge, bridged-T, closed circuit, loop, parallel circuit,shunt circuit, computer circuit, gate, logic gate, AND circuit, AND gate, NAND circuit,NAND gate, OR circuit, OR gate, X-OR circuit, XOR circuit, XOR gate, integrated circuit,(..)instrumentality, instrumentation, artifact, artefact, object, physical object, entity]2.4 Sense/Directory ComparisonsFor every sense description l(wj), a comparison is made with the terms in the directorydescription l(d).
This comparison is based on the hypothesis that the terms in anappropriate directory for a word sense will have some correlation with the sensedescription via WordNet semantic relations.
In other words, our assumption is that thepath to the directory in the ODP topical structure will have some degree of overlappingwith the hyponymy path to the word sense in the WordNet hierarchical structure.For this comparison, we simply count the number of co-occurrences betweenwords in l(wj) and words in l(d).
Repeated terms are not discarded, as repetitionis correlated with stronger associations.
Other, better-grounded comparisons, such asthe cosine between l(wj) and l(d), were empirically discarded because of the small sizeand small amount of overlapping of the average vectors.490Computational Linguistics Volume 29, Number 32.5 Candidate Sense/Directory AssociationsThe association vector v(d, w) has as many components as senses for w in WordNet 1.7;the ith component, v(d, w)i represents the number of matches between the directoryl(d) and the sense descriptor l(wj).
For instance, the association vector ofbusiness/industries/electronics and electrical/contract manufacturerswith circuit isv(d, circuit) = (6, 0, 0, 0, 0, 0)that is, six coincidences for sense 1 (the electric circuit sense), which has the associatedvector shown in the previous section (which includes five occurrences of electrical andone occurrence of electronic).
The rest of the sense descriptions have no coincidenceswith the directory description.v(d, w) is the basis for making candidate assignments of suitable senses for direc-tory d: If one of the components v(d, w)j is not null, we assign the sense wj to thedirectory d. If all components are null, the directory is provisionally classified as noiseor new sense.
If more than one component is not null, the senses i with maximalv(d, w)i are all considered candidates.
These candidate assignments are confirmed ordiscarded after passing a number of filters and receiving a confidence score C(d, wj),both of which are described below.2.6 FiltersFilters are simple heuristics that contribute to a more accurate classification of therelations predicted by the co-ocurrence vector v(d, w).
We are currently using twofilters: One differentiates nouns and noun modifiers to prevent wrong associations,and another detects sense specializations.2.6.1 Modifiers.
Frequently, the ODP search engine retrieves directories in which thenoun to be searched, w, has as a noun modifier role.
Such cases usually produceerroneous associations.
For instance, the directorylibrary/sciences/animals & wildlife/mammals/tamarins/golden lion tamarinis erroneously associated with the mammal sense of lion, which is here a modifier fortamarin.Modifiers are detected with a set of simple patterns, as the syntactic properties ofdescriptions in directories are quite simple.
In particular, we discard most cases usingthe structure of the ODP hierarchy, as in this case.
The filter analyzes the structure ofthe directory, detects that the parent category of golden lion tamarin is tamarin, thereforeassumes that golden lion tamarin is a specialization of tamarin, and assigns the directoryto a suitable sense of tamarin (tamarin 1 in WordNet).An additional filter (weaker than the previous one) discards compounds accordingto the position (the searched noun precedes another noun), as inpersonal/kids/arts & entertainment/movies/animals/lion kingThis directory could be associated with lion 1 because it contains the word animal, butthe assignment is rejected because of the modifier filter.
In general, on such occasionsthe searched noun plays a modifier role (as adjective or noun); discarding all suchcases favors precision over recall.
In this case, the label is classified as noise.491Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word Senses2.6.2 Sense Specializations (Hyponyms).
A retrieved directory might be appropriateas a characterization of a sense specialization for some of the word senses being con-sidered; our algorithm tries to detect such cases, creating a hyponym of the sense andcharacterizing the directory with the hyponym.The filter identifies a directory as a candidate hyponym if it contains explicitly amodifier w pattern (where w is the noun being searched).
This filter detects explicitspecializations, such as office chair as a hyponym of chair 1, or fox family channel as ahyponym of channel 7, but fails to identify, for instance, memorial day as a hyponymof holiday.If the candidate hyponym, as a compound, is not present in WordNet, then it isincorporated and described with the directory.
If it is already present in WordNet, anadditional checking of the hyponymy relation is made.
For instance, the directorybusiness/industries/electronics and electrical/components/integrated circuitsis assigned to the WordNet entry integrated circuit, because integrated circuit is alreadya hyponym of circuit in WordNet.2.7 Confidence ScoreFinally, a confidence score C(d, wj) for every potential association (d, wj) is calculatedusing four empirical criteria:1.
Checking whether d was directly retrieved for the query associated to wj.2.
Checking whether the system associates d with one or more senses of theword w.3.
Checking the number of coincidences between l(d) and l(wj).4.
Comparing the previous number with the number of coincidencesbetween l(d) and the other sense descriptions {l(w)i, i = j}.The confidence score is a linear combination of these factors, weighted according toan empirical estimation of their relevance:C(d, wj) =4?i=1?iCi(d, wj)whereC1(d, wj) ={1, if query(wj) retrieves d0, otherwiseC2(d, wj) = 1 ?knC3(d, wj) =??
?1, if vj ?
5(vj + 5)/10, if 1 < vj ?
40.5, if vj = 1C4(d, wj) =vj ?
maxi=j(vi),?ni=1 viwhere v is the association vector v(d, w), n the number of senses, k the number of sensesfor which vj is non-null, and ?i are coefficients empirically adjusted to (?1,?2,?3,?4) =492Computational Linguistics Volume 29, Number 3(0.1, 0.15, 0.4, 0.35).
The value of C(d, wj) ranges between 0 and 1 (all Ci range between0 and 1, and the sum of the linear coefficients ?i is 1).
Note that C2 cannot reach 1 (butcan get asymptotically close to 1), and note also that C4 cannot take negative values,because, as (d, wj) is a candidate association, vj is maximal in v(d, w), and thereforevj ?
maxi=j(vi) ranges between 0 and vj.Let us see an example of how this confidence measure works, calculating C(d, wj)for the directoryd = business/industries/electronics and electrical/contract manufacturerswith circuit 1 (electric circuit):?
C1.
This directory has been retrieved from the queryq1= [+circuit "electrical circuit" "electric circuit" "electrical device"-tour -"racing circuit" -lap -circle]corresponding to circuit 1, which agrees with the association made by thesystem.
Hence C1 = 1.?
C2.
The association vector v(d, w) = (6, 0, 0, 0, 0, 0) presents only onenon-null coordinate; therefore C2 = 1 ?
16 = 0.83.
Note that, in general,this factor prevents C from reaching the upper bound 1.?
C3.
As v1 = 6, C3 = 1.
This factor increases along with the number ofcoincidences between the sense and directory characterizations.?
C4.
As all other components of v are null, the highest value of thecomponents different from sense 1 is also null (maxi=j(vi) = 0); therefore,C4 = 1.
This factor measures the strength of the association (d, w1)compared with the other possibilities.
It decreases when v(d, w) includesmore than one non-null coordinate, and their values are similar.?
C. Finally, applying the ?i coefficients, we obtain C(d, circuit 1) = 0.975.The confidence score can be used to set a threshold for accepting/discarding associ-ations.
A higher threshold should produce a lower number of highly precise associa-tions; a lower threshold would produce more associations with less accuracy.
For theevaluation below, we have retained all directories, regardless of their confidence score,in order to assess how well this empirical measure correlates with correct and usefulassignments.An example of the results produced by the algorithm can be seen in Table 1.
Thesystem assigns directories to senses 1, 2, and 5 of circuit (six, two, and three directories,respectively).
Some of them are shown in the table, together with a sense specialization,integrated circuit, for sense 1 (electrical circuit).
Senses 3, 4, and 6, which did not receiveany directory association, do not appear to have domain specificity, but are insteadgeneral terms.3.
EvaluationWe have analyzed the results of the algorithm for the set of nouns in the Senseval 2WSD English lexical sample test bed (Kilgarriff 2001a).
The Senseval campaigns (Ed-monds and Cotton 2001; Kilgarriff and Palmer 2000) are devoted to the comparativeevaluation of word sense disambiguation systems in many languages.
In the Senseval2 lexical sample task, a large number of instances (occurrences in context extracted493Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word SensesTable 1Results of the association algorithm for circuit.circuit 1 (electrical circuit)ODP directories Cbusiness/industries/electronics and electrical/contract manufacturers 0.98manufacturers/printed circuit boards/fabrication 0.88computers/cad/electronic design automation 0.78...sense specializations (hyponyms)business/industries/electronics and electrical/components/integrated circuits 0.98circuit 2 (tour, journey around a particular area)ODP directoriessports/cycling/travel/travelogues/europe/france 0.58regional/asia/nepal/travel and tourism/travel guides 0.66circuit 5 (racing circuit)ODP directoriessports/motorsports/auto racing/stock cars/drivers and teams 0.78sports/motorsports/auto racing/tracks 0.82sports/motorsports/auto racing/driving schools 0.78from corpora) for a fixed set of words had to be tagged with the appropriate senseby the participating WSD systems.
For English, the sense inventory was a prereleaseof WordNet 1.7, and two sets of manually tagged instances were made available: Afirst set was intended for training supervised systems, and a second set for evaluationof all systems attempting the task.
Altogether, the Senseval 2 lexical sample test bedis one of the most widely used resources for studying and comparing word sensedisambiguation approaches.For our evaluation, we have considered the fraction of the Senseval 2 test bed thatdeals with English nouns: 29 polysemous nouns with a total of 147 word senses.We have applied the algorithm to this set of nouns and examined the results interms of coverage and quality of the sense/directory associations.
Coverage measureshow many senses can be characterized with directories, assuming that every domain-specific sense should receive at least one directory.
Quality is measured in terms ofprecision (are the assignments correct?
), relevance (are the assignments useful?
), andconfidence (does the confidence score correlate well with precision and relevance ofthe associations?
).3.1 CoverageTable 2 shows the 148 directories retrieved by our algorithm, an average of 1.0 directo-ries per sense.
The directories, however, are not evenly distributed among senses, cov-ering only 43 different senses with unique directories and 28 specialized (hyponym)senses.
In addition, 9 senses are identified as part of potential clusters (i.e., havingnonunique directories).In order to measure the real coverage of the system, we have to estimate howmany word senses in the Senseval 2 sample are susceptible to receiving a domainlabel.
For instance, sense in common sense is not associated with any particular topicor domain, whereas sense in word sense can be associated with linguistics or language-related topics.The decision as to whether or not a word sense might receive a domain label isnot always a simple, binary one.
Hence we have manually tagged all word senses494Computational Linguistics Volume 29, Number 3Table 2Coverage of nouns in the Senseval 2 test bed.Senseval 2NounsNumber ofSensesNumber ofDirectoriesNumber of LabeledSensesNumber ofHyponymsart 4 6 1 1authority 7 4 2 1bar 13 3 3 0bum 4 0 0 0chair 4 4 1 0channel 7 5 1 1child 4 12 2 0church 3 24 2 4circuit 6 11 3 1day 10 15 1 14detention 2 1 1 0dyke 2 1 1 0facility 5 10 3 0fatigue 4 0 0 0feeling 6 2 1 0grip 7 3 2 0hearth 3 5 2 0holiday 2 2 2 0lady 3 0 0 0material 5 9 2 3mouth 8 0 0 0nation 4 4 1 1nature 5 0 0 0post 8 14 5 0restraint 6 4 3 0sense 5 0 0 0spade 3 3 1 1stress 5 5 2 1yew 2 1 1 0Total 147 148 43 28with two criteria (with each tagging performed by a different human annotator): astrict one (only word senses that can clearly receive a domain label are marked aspositive) and a loose one (only word senses that are completely generic are marked asnegative).
The strict judgment gave 59 domain-specific senses in the sample; the loosejudgment gave 71.With these manual judgments, the coverage of the algorithm is between 73% (loosejudgment) and 88% (strict judgment).
This coverage can be increased by?
Propagating a directory/word sense association to all members of theWordNet synset to which the word sense belongs.?
Propagating directories via hyponymy chains, as in Magnini andCavaglia (2000).3.2 QualityWe have used three criteria to evaluate the directory/sense associations produced:?
Precision.
Is the directory correct (suitable) for the word sense or not?495Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word Senses?
Relevance.
Is the directory useful for characterizing the word sense??
Confidence.
How well is the confidence value C(d, wj) correlated withthe precision and relevance of the associations?3.2.1 Precision.
An assignment (d, wj) is considered correct (d is suitable for wj) unless1.
d adjusts better to some other sense wi.
For instance, the association ofregional/north america/united states/government/agencies/independent/federal labor relations authorityas a hyponym ofauthority4 : assurance, self -assurance, confidence , self -confidence , authority ,surenessis considered an error, as the directory would be better suited for ahyponym of sense 5 (authority as administrative unit).2.
The terms in l(d) are contradictory to the definition of the word sense orare better suited for a sense that is not listed in the dictionary.
This is thecase ofarts/music/bands and artists/offspringwhich is erroneously assigned to child 2: human offspring of any age.The results of this manual evaluation can be seen in Table 3.
The overall precision is86%.Regarding potential topical clusters (directories associated with more than onesense of the same word), these are considered correct if (1) the associated directoryis correct for all the senses in the cluster and (2) the occurrences of the word on theWeb page associated with the directory can be loosely assigned to any of the clustersenses.
Twelve out of the 13 clusters extracted are correct according to this criterion.3.2.2 Confidence Measures.
Table 4 shows the distribution of directories accordingto the confidence measure.
Eighty-four percent of the directories have a confidence Cover 0.7, and 41% over 0.8.
This skewed distribution is consistent with the algorithmfilters, which are designed to favor precision rather than recall.Table 5 shows the distribution of errors in levels of confidence.
The percentageof errors in directories with a confidence level below .6 is 25%.
This error percentageTable 3Precision over Senseval 2 nouns.Directories Associatedwith WordNet SensesNumber ofDirectories Number of Correct Number of ErrorsUnique sense 148 127 21Potential clustering 13 12 1Total 161 139 (86%) 22 (14%)496Computational Linguistics Volume 29, Number 3Table 4Confidence distribution.Confidence C ?
0.7 0.7 < C ?
0.8 0.8 < CNumber of directories 24 63 61Table 5Correlation between confidence and correctness.Confidence Number of Directories Percentage of ErrorsC ?
0.7 24 25%0.7 < C ?
0.8 63 19%C > 0.8 61 5%Total 148 14%decreases with increasing levels of confidence, down to 5% for associations with Cover .8.
Table 5 indicates that the confidence value, which is assigned heuristically, isindeed correlated with precision.3.2.3 Relevance.
Besides correctness of the associations, we want to measure the use-fulness of the directories: How well can they be used to characterize the associatedword senses?
How much information do they provide about the word senses?We have performed a manual, qualitative classification of the directories extractedas irrelevant, mildly relevant, or very relevant.
An irrelevant directory is compatiblewith the word sense but does not provide any useful characterization; a mildly rele-vant directory illustrates the word sense, but not centrally or in some particular aspector domain.
A very relevant directory provides a rich characterization per se and canbe considered a domain label for the word sense.An example of a very relevant directory isbusiness/industries/electronics and electrical/components/integrated circuitassociated as hyponym of circuit 1 (electrical circuit) with a confidence of 98%.
Anexample of mildly relevant association isregional/north america/united states/texas/../society and culture/religionassociated with church 1 (Christian church) with a 73% confidence.
Obviously, Texas isnot correlated with church, but the directory contains a lot of material (for instance,the Web page of the Northcrest Community Church and many others) that mightbe used, for instance, to acquire topical signatures for the concept.
Hence the mildlyrelevant judgment.
Finally, an example of an irrelevant association isregional/north america/united states/new york/localities/uticaassociated with art 1 (fine art) with a confidence of 66% (the directory contains a sectionon Arts at Utica, which would be considered mildly relevant if pointed to explicitlyby the label).
For the purposes of measuring relevance, all the directories that werejudged as incorrect are counted as irrelevant.497Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word SensesTable 6Relevance of the directories in the test set.Relevance Irrelevant MildlyRelevantHighlyRelevantC ?
0.7 7 4 130.7 < C ?
0.8 13 12 380.8 < C 3 9 49Total 23 (15%) 25 (17%) 100 (67%)The overall relevance figures, and the correlation of relevance with the confidencevalue, can be seen in Table 6.
Sixty-seven percent of the directories are highly relevantto characterize word senses, which is an encouraging result.
Also, the set of irrele-vant directories (15%) is almost identical to the set of erroneous directories (with justone addition), indicating that (almost) all directories that are correct can be used tocharacterize word senses to some extent.4.
Example Application: Automatic Acquisition of Sense-Tagged CorporaEach ODP directory contains links to related subdirectories and to a large number ofWeb sites that have been manually classified there.
Every link to a Web site includesthe name of the site and a short description.
For instance, underbusiness/industries/electronics and electrical/components/integrated circuitwe find over 30 descriptions, such as ?
?Multilink Technology corporation: Manufacture ofintegrated circuits, modules, and boards for use in both data and telecommunications??.
Inorder to perform a first experiment on extraction of sense-tagged corpora, we haveused only such descriptions (without exploring the associated Web sites) to build asense-tagged corpus for Senseval 2 nouns.Notice that we are not using the contents of the Web sites that belong to a directory,but only the manually added descriptions of Web sites in the directory.
Using the Websites themselves is also an attractive possibility that would produce a much largercorpus at the expense of lower precision.The extraction is straightforward: When a word sense wi has an associated direc-tory d, we scan the site descriptions on the ODP page that corresponds to the directoryd and extract all contexts in which w occurs, assuming that in all of them w is used inthe sense i.
Some examples of the training material for circuit can be seen in Table 7.On average, these examples are shorter than Senseval 2 training instances.The goal is to compare the performance of a supervised word sense disambigua-tion system using Senseval 2 training data (hand made for the competition) to thatusing the sense-tagged corpus from ODP (automatically extracted).
We have chosenthe Duluth system (Pedersen 2001) to perform the comparison.
The Duluth system isa freely available supervised WSD system that participated in the Senseval 2 compe-tition.
As we are not concerned with absolute performance, we simply adopted thefirst of the many available versions of the system (Duluth 1).An obstacle to performing such comparative evaluation is that, as expected, ouralgorithm assigns ODP directories only to a fraction of all word senses, partly becausenot every sense is domain-specific, and partly because of lack of coverage.
In order to498Computational Linguistics Volume 29, Number 3Table 7Examples of training material for circuit.circuit 1 (electrical circuit)Electromechanical products for brand name firms; offers printed circuit boards (..)Offers surface mount, thru-hole, and flex circuit assembly, in circuit and functional (..)circuit 2 (tour, journey around a particular area)The Tour du Mont-Blanc is a circuit of 322km based in the northern French Alps.A virtual tour of the circuit by Raimon Bach.circuit 5 (racing circuit)The Circuit is a smooth 536 yards of racing for Hot Rod and Stock Car?s at the East of (..)(..) History of the circuit and its banked track and news of Formula 1 (..)circumvent this problem, we have considered only the subset of 10 Senseval nouns forwhich our system tags at least two senses: bar, child, circuit, facility, grip, holiday, material,post, restraint, and stress.
We have then projected the Senseval 2 training corpus, andthe test material, onto the annotations for the word senses already in our ODP-basedmaterial.
Hence we will evaluate the quality of the training material obtained fromWeb directories, not the coverage of the approach.Table 8 shows the training material obtained for that subset of Senseval 2 nouns.A total of 66 directories are used as a source of training instances, of which 17% areincorrect and will presumably incorporate noise into the training.
Table 9 compares thetraining material for the word senses in this sample, and the results of the supervisedWSD algorithm with the Senseval and the ODP training instances.We have measured the performance of the system in terms of Senseval recall: thenumber of correctly disambiguated instances over the total number of test instances.Overall, using the Senseval training set gives .73 recall, and training with the automat-ically extracted ODP instances gives .58 (21% worse).
A decrease of 21% is significantbut nevertheless encouraging, because the Senseval training set is the gold standardfor the Senseval test set: It is larger than the ODP set (773 versus 547 instances in thissubset), well balanced, built with redundant manual annotations, and part of the samecorpus as the test set.Table 8Training material obtained for the WSD experiment.WordSensesNumber of Directoriesper SenseNumber of IncorrectDirectoriesNumber of TrainingInstancesbar 1,10 1,1 0,0 1,1child 1,2 3,9 0,0 3,80circuit 1,2,5 6,2,3 0,0,0 229,2,5facility 1,4 4,5 0,0 4,18grip 2,7 2,1 0,1 17,6holiday 1,2 1,1 0,1 5,17material 1,4 6,3 2,1 63,10post 2,3,4,7,8 1,5,1,4,3 1,1,1,0,3 2,7,1,9,3restraint 1,4,6 2,1,1 0,0,0 2,2,2stress 1,2 1,4 0,0 8,50Total 66 11 547499Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word SensesTable 9Results of supervised WSD.WordSensesNumber ofinstancesSensevalTrainingNumber ofinstancesODPTrainingNumber of TestInstancesRecallSensevalTrainingRecallODPTrainingbar 1,10 127,11 1,1 62,6 .91 .50child 1,2 39,78 3,80 35,27 .57 .44circuit 1,2,5 67,6,7 229,2,5 23,2,8 .70 .70facility 1,4 26,61 4,18 15,28 .79 .67grip 2,7 6,1 17,6 4,0 1.00 1.00holiday 1,2 4,57 5,17 26,2 .96 .96material 1,4 65,7 63,10 30,9 .79 .79post 2,3,4,7,8 1,64,20,11,7 2,7,1,9,3 2,25,13,12,4 .45 .25restraint 1,4,6 17,32,11 2,2,2 8,14,4 .65 .50stress 1,2 3,45 8,50 1,19 .95 .95Total 773 547 379 .73 .58The most similar experiment in the literature is Agirre and Mart?
?nez (2000), inwhich the sense-tagged instances obtained using a high-performance Web-mining al-gorithm (Mihalcea and Moldovan 1999) performed hardly better than a random base-line as WSD training instances.
A difference between the two experiments is thatAgirre et al do not limit their experiments to the fraction of the test set for whichthey have automatically extracted training samples; hence a direct comparison of theresults is not possible.A detailed examination of the results indicates that the difference in performanceis related to the smaller number of training instances rather than to the quality ofindividual instances:?
In all four cases in which ODP provides a comparable?orlarger?number of training instances (circuit, grip, material, stress), ODPtraining equals hand-tagged training.
In one additional case (holiday), thenumber of ODP instances is smaller, but still the recall is the same.
Forthe other five words, the number of ODP instances is substantiallysmaller and the recall is worse.?
Remarkably, incorrect directories harm recall substantially only for post,which accumulates six erroneous associations (out of 11 errors).
Theother five errors (in material 1, 4, holiday 2, grip 7) do not affect the finalrecall for these words.
There are two possible reasons for this behavior:?
Erroneous directories tend to be less productive in terms oftraining instances.
Indeed, this fact could be incorporated as anadditional filter for candidate directories.
This is the case, forinstance, of material 1, for which correct directories providemuch more training material than the incorrect one.?
Erroneous directories are more frequent with rare (less frequent)word senses.
This is correlated with a smaller number of testinstances (hence the influence on average recall is lower) andalso of training instances (and then the reference, hand-taggedmaterial does not provide good training data either).
This is the500Computational Linguistics Volume 29, Number 3case of grip 7 or holiday 2, which have zero and two testinstances, respectively.Overall, our results suggest that directory-based instances, in spite of being shorterand automatically extracted, are not substantially worse for supervised WSD than thehand-tagged material provided by the Senseval organization.
The limitation of theapproach is currently the low coverage of word senses and the amount of trainingsamples.
Two strategies may help in overcoming such limitations: first, propagatingdirectories via synonymy (attaching directories to synsets rather than word senses)and semantic relationships (propagating directories via hyponymy relations); second,retrieving instances not only from the ODP page describing the directory contents, butfrom the Web pages listed in the directory.The only fundamental limitation of our approach for the automatic extractionof annotated examples is the fact that directories are closely related to topics anddomains, and therefore word senses that do not pertain to any domain cannot receivedirectories and training instances from them.
Still, the approach can be very usefulfor language engineering applications in which only domain disambiguation (versussense disambiguation) is required, such as information retrieval (Gonzalo et al 1998)and content-based user modeling (Magnini and Strapparava 2000).5.
Massive Processing of WordNet NounsWe have applied the association algorithm to all noncompound nouns in WordNetwithout nonalphabetic characters (e.g., sea lion and 10 are not included in the bulkprocessing).
The results can be seen in Table 10.
Overall, the system associates at leastone directory with 13,375 nouns (28% of the candidate set).The most direct way of propagating directories in the WordNet structure is ex-tending sense/directory associations to synset/directory relations (i.e., if a word sensereceives a directory, then all word senses in the same synset receive the same direc-tory).
For instance, cable 2 (transmission line) receives the following directories:business/industries/electronics and electricalbusiness/industries/electronics and electrical/hardware/connectors and terminalsbusiness/industries/electronics and electrical/contract manufacturersAs cable 2 is part of the synset {cable 2, line 9, transmission line 1}, line 9 and transmissionline 1 inherit the three directories.With this (quite conservative) strategy, the number of characterized nouns andword senses almost doubles: 24,558 nouns and 27,383 senses, covering 34% of the can-Table 10Massive association of ODP directories with WordNet 1.7 nouns.With PropagationCandidate nouns 51,168Candidate senses 73,612Associated directories 29,291Characterized nouns 13,375 24,558Characterized senses 14,483 27,383Hyponyms 1,800501Santamar?
?a, Gonzalo, and Verdejo Association of Web Directories with Word Sensesdidate nouns plus 7,027 multiword terms that were not in the candidate set.
The resultsof this massive processing, together with the results for the Senseval 2 test (includingtraining material) are available for public inspection at ?http://nlp.uned.es/ODP?.6.
ConclusionsOur algorithm is able to associate ODP directories with WordNet senses with 86%accuracy over the Senseval 2 test, and with coverage between 73% and 88% of thedomain-specific senses.
Such associations can be used as rich characterizations forword senses: as a source of information to cluster senses according to their topicalrelatedness, to extract topic signatures, to acquire sense-tagged corpora, etc.
The onlyintrinsic limitation of the approach is that Web directories are not appropriate forcharacterizing general word senses (versus domain-specific ones).
If such characteri-zation is necessary for a particular natural language application, the method shouldbe complemented by other means of acquiring lexical information.In the supervised WSD experiment we have carried out, the results suggest that thecharacterization of word senses with Web directories provides cleaner data, withoutfurther sophisticated filtering, than a direct use of the full Web.
Indeed the WSDresults using training material from ODP directories gives better results than could beexpected from previous cross-validations of training and test WSD materials.Our ongoing work is extending the algorithm?which works independently forevery input word?to combine and propagate sense/directory associations over theentire WordNet.
The initial coverage of WordNet nouns is 34%, but we hope to improvethis figure by taking advantage of the WordNet structure.Perhaps the main conclusion of our work is that Web directories are a much morestructured and reliable corpus than the whole Web.
In spite of being manually su-pervised, Web directories offer immense structured corpora that deserve our attentionas sources of linguistic information.
In particular, listing word sense/ODP directoryassociations has the additional advantage, compared to other Web-mining approaches,of providing a wealth of lexical information in a very condensed manner.AcknowledgmentsThis work has been partially supported bythe Spanish government through projectHermes (TIC2000-0335-C03-01).ReferencesAgirre, E., O. Ansa, E. Hovy, andD.
Mart??nez.
2000.
Enriching very largeontologies using the WWW.
In Proceedingsof the Ontology Learning Workshop, Berlin.Agirre, E. and D.
Mart??nez.
2000.
Exploringautomatic word sense disambiguationwith decision lists and the Web.
InProceedings of the COLING Workshop onSemantic Annotation and Intelligent Content,Luxembourg.Edmonds, P. and S. Cotton.
2001.Senseval-2: Overview.
In Proceedings ofSenseval 2.
Association for ComputationalLinguistics, New Brunswick, NJ.Fujii, A. and T. Ishikawa.
1999.
Utilizing theWorld Wide Web as an encyclopedia:Extracting term descriptions fromsemi-structured texts.
In Proceedings ofACL-99.
Association for ComputationalLinguistics, New Brunswick, NJ.Gonzalo, J., F. Verdejo, I. Chugur, andJ.
Cigarra?n.
1998.
Indexing with Wordnetsynsets can improve text retrieval.
InCOLING/ACL?98 Workshop on Usage ofWordNet in Natural Language ProcessingSystems.
Association for ComputationalLinguistics, New Brunswick, NJ.Grefenstette, G. 1999.
The WWW as aresource for example-based MT tasks.
InProceedings of ASLIB-99, London.Joho, H. and M. Sanderson.
2000.
Retrievingdescriptive phrases from large amounts offree text.
In Proceedings of the 9th ACMCIKM Conference, McLean, VA.Kilgarriff, A.
2001a.
English lexical sampletask description.
In Proceedings of Senseval2.
Association for ComputationalLinguistics, New Brunswick, NJ.Kilgarriff, A.
2001b.
Web as corpus.
In502Computational Linguistics Volume 29, Number 3Proceedings of Corpus Linguistics 2001,Lancaster, England.Kilgarriff, A. and M. Palmer.
2000.Introduction to the special issue onSenseval.
Computers and the Humanities,34(1?2).Ma, X. and M. Liberman.
1999.
Bits: Amethod for bilingual text search over theWeb.
In Proceedings of the MachineTranslation Summit VII, Singapore.Magnini, B. and G. Cavaglia.
2000.Integrating subject field codes intoWordNet.
In Proceedings of LREC-2000,Second International Conference on LanguageResources and Evaluation, Athens.Magnini, B. and C. Strapparava.
2000.Experiments in word domaindisambiguation for parallel texts.
InACL-2000 Workshop on Word Sense andMultilinguality.
Association forComputational Linguistics, NewBrunswick, NJ.Mihalcea, R. and D. Moldovan.
1999a.
Anautomatic method for generating sensetagged corpora.
In Proceedings of AAAI ?99,Orlando, FL, July, pages 461?466.Miller, G. 1990.
Wordnet: An on-line lexicaldatabase.
Special issue.
InternationalJournal of Lexicography, 3(4).Nie, Jian-Yun, Michel Simard, and GeorgeFoster.
2001.
Multilingual informationretrieval based on parallel texts from theWeb.
In Carol Peters, Editor,Cross-Language Information Retrieval andEvaluation: Workshop of Cross-LanguageEvaluation Forum (CLEF 2000), Lisbon,Portugal, September 21?22, 2000, RevisedPapers.
Lecture Notes in ComputerScience 2069.
Berlin, Springer-Verlag,pages 188?200.Pedersen, T. 2001.
Machine Learning withlexical features: The Duluth approach toSenseval-2.
In Proceedings of Senseval-2.Association for ComputationalLinguistics, New Brunswick, NJ.Peters, C., M. Braschler, J. Gonzalo, andM.
Kluck, editors.
2002.
Evaluation ofCross-Language Information RetrievalSystems.
Lecture Notes in ComputerScience 2406.
Springer-Verlag.Resnik, P. 1999.
Mining the Web forbilingual text.
In Proceedings of the 37thAnnual Meeting of the Association forComputational Linguistics, College Park,MD.Resnik, P. and N. Smith.
2002.
The Web as aparallel corpus.
Technical ReportUMIACS-TR-2002, University ofMaryland.
