Some apparently disjoint aims and requirements for grammardevelopment environments: the case of natural languagegenerationJ ohn  BatemanLanguage and Communication ResearchUniversity of Stirling, Stirling, UK(J .
a. bat eman~st  Jr. ac.
uk)mmmnmmmm-mUmmUmnmmAbst rac tGrammar development environ-ments (GDE's) for analysis and for gener-ation have not yet come together.
Despitethe fact that analysis-oriented GDE's (suchas ALEP) may include some possibility ofsentence generation, the development tech-niques and kinds of resources suggested areapparently not those required for practi-cal, large-scale natural language generationwork.
Indeed, there is no use  of 'standard'(i.e., analysis-oriented) GDE's in currentprojects/applications targetting the gener-ation of fluent, coherent exts.
This un-satisfactory situation requires ome analy-sis and explanation, which this paper at-tempts using as an example an extensiveGDE for generation.
The support pro-vided for distributed large-scale grammardevelopment, multilinguality, and resourcemaintenance are discussed and contrastedwith analysis-oriented approaches.1 In t roduct ion :  a problemGrammar development environments (GDE's) foranalysis and for generation have not yet come to-gether.
In fact, the mainstay of design for linguisticresource development environments i  skewed veryfar from that necessary for generation; this is illus-trated well by the following remark from an EAGLES(Expert Advisory Group for Language EngineeringStandards) report describing the current "conver-gence" of opinion concerning the required function-ality for development platforms:"The necessary functionality of a develop-ment platform is more or less agreed uponby grammar writers .
.
.
.
They should havea parser for testing the developed gram-mars with respect o an input string, andpossibly also a generator to test for over-generation."
(EAGLES, 1996, p117)This marginalization of the generation process nat-urally impacts on the kinds of development and de-bugging tools that are provided.
For example, per-haps the most extensive workbench developed withinthe European Union, the Advanced Language Engi-neering Platform (ALEP: cf.
(Simpkins et al, 1993)),while forced to adopt a so-called 'lean' formalism inorder to achieve acceptable fficiency, neverthelessorients itself most closely to 'mainstream' linguis-tic formalisms uch as HPSG and LFG.
Neither ofthese formalisms have however found widespread usein larger-scale generation contexts.There also continue to be substantial projectswhose specific goals are to build or collect linguis-tic resources for language engineering--including,for example, projects such as Acquilex, Eagles,TransTerm, EuroWordNet and others} However,these projects have not apparently been configuredto provide the kinds of resources that generationrequires.
This can be seen in the virtually zerotake-up of such 'mainstream' (i.e., analysis-oriented)resources in generation projects (both monolingualand multilingual) where the goal has been to provideefficient generation of realistic, useful texts.Thus, not only is there a lack of uptake of lin-guistic resources, there is also virtually no use  of'standard' (i.e., analysis-oriented) GDE's in currentprojects/applications targetting the generation offluent, coherent texts.
This unsatisfactory situationcertainly requires ome analysis and explanation--which this paper attempts.
To do this, we firstbriefly illustrate our claim that the grammar de-velopment environments and approaches that areadopted in natural anguage generation are by andlarge disjoint o those developed in natural anguage1Sch/itz (Schiitz, 1996) provides a useful overviewof current language ngineering projects where multilin-guality plays a role.analysis.
We then show how the main property thateffectively distinguishes successful generation gram-mars from analysis grammars (regardless of whatthe grammars are used for) is their orientation tocommunicative-function andthat it is precisely thisproperty that plays a crucial role in creating power-ful and efficient grammar development environmentsthat are suited to the generation task.We illustrate this relationship between resourceorganization and development ools by focus-ing on techniques for developing and maintain-ing large-scale linguistic resources (mostly grammarand semantics-grammar mappings), for distributedgrammar development, and for supporting multilin-guality that have developed for generation work.
Adirect question raised by the paper is then the ex-tent to which the techniques discussed could also berelevant and applicable to analysis-oriented develop-ment environments.2 The  lack of  use of ana lys i s -basedGDE's  for generat ionThere is clearly a partially 'sociological' explana-tion to the lack of exchange between approachesin analysis and generation: the groups working onanalysis and text generation are by and large dis-joint and the questions and issues thus central inthese groups are also at best only partially overlap-ping.
This is not, however, sufficient.
Most inputto analysis-oriented work (e.g., (Pulman, 1991)) hasattempted to achieve a workable level of generalityand formal well-foundedness that would guaranteethe widespread applicability and re-usability of theirresults.
If this were sufficient and had been success-ful, one could expect generation developers to haveavailed themselves of these results.
But uptake forgeneration continues to be restricted to those work-ing in the analysis-oriented tradition, mostly in thepursuit of 'bi-directional' sentence generation on thebasis of resources developed primarily for analysis.
'Core' text generation activities remain untouched.One, more contentful, reason for this is thatthe particular equirements of generation favour anorganization of linguistic resources that has itselfproved supportive of powerful development and gen-eration environments.
To clarify the needs of gen-eration and the relation to the GDE's adopted, wecan cross-classify approaches adopted for generationaccording to the kind of generation targetted.
Thislargely corresponds to the size of linguistic unit gen-erated.
Thus we can usefully distinguish generationof single phrases, generation of single sentence orutterance generation (such as might also still occurin MT most typically or in utterance generation indialogue systems), generation of connected texts ofa single selected text type, and generation of con-nected texts of a variety of text types (e.g., showingvariation for levels of user expertise, etc.).
These aredistinguished precisely because it is well known fromgeneration work that different issues play a role forthese differing functionalities.Three generation 'environments' cover the ma-jority of projects concerned with text generationwhere generation for some practical purpose(s) isthe main aim, not the development of some par-ticular linguistic treatment or pure research intoproblems of generation or NLP generally.
Theseare Elhadad's (Elhadad, 1990) 'Functional Unifi-cation Formalism' (FUF), the KPML/Penman sys-tems (Mann and Matthiessen, 1985; Bateman,1997), and approaches within the Meaning-TextModel (cf.
(Mel'Suk and Zholkovskij, 1970)) as usedin the CoGenTex-family of generators.
Here re-sources appropriate for real generation are accord-ingly understood as broad coverage (with respectto a target application or set of applications) lin-guistic descriptions of languages that provide map-pings from enriched semantic specifications (includ-ing details of communicative effects and textual or-ganization) to corresponding surface strings in closeto real-time.
In addition, there are many systemsthat adopt in contrast a template-based approachto generation--now often combined with full gen-eration in so-called 'hybrid' frameworks.
While,finally, there is a very small number of serious,large-scale and/or practical projects where analysis-derived grammatical resources are adopted.
Thisdistribution is summarized in Table 1.
Importantly,it is only for the approaches in the final righthandcolumn that standard analysis-based GDE's appearto be preferred or even applicable.
23 Communicat ive  funct ion:  acommon thread  in generat ionresourcesIt is well known in natural language generation(NLG) that functional information concerning thecommunicative intent of some utterance provides aconvenient and necessary organization for generatordecisions (cf.
(McDonald, 1980; Appelt, 1985; McK-eown, 1985)).
Different approaches focus the roleof communcative functions to a greater or less de-2For references to individual systems ee the Webor a detailed current state of the art such as Zock andAdorni (Zock and Adorni, 1996) or Bateman (Bateman,to appear).connectedtexts(differ-ing texttypes)connectedtexts(singletexttype)singlesen-tences  /utter-singlephrasesfunctional approachesKPML/Penman I FUFTechDocHealthDocKOMETGISTDrafterA GILESpeak!PanglossPlanDocStreakCometsomesomedependency ap-proachMTMFOGLFSMultiMeteomanytemplateapproachPeba-IIseveralmanystructuralapproachVerbmobilCLEIDASA NTHEMProjects given in italics are essentially multilingual--i.e., they are concerned with the generationof texts in at least two languages.Table 1: Distribution of generation systems by task and approachgree.
Some subordinate it entirely to structure, someattempt to combine structure and function felici-tously, others place communicative function clearlyin the foreground.
Among these latter, approachesbased on systemic-functional linguistics (SFL) havefound the widest application.
Both the FUF andKPML/Penman environments draw heavily on SFL.This is to emphasize the role of the paradigmaticorganization of resources in contrast o their syn-tagmatic, structural organization.
It turns out thatit is this crucial distinction that provides the clean-est account of the difference between a GDE such asALEP and one such as KPML.Viewed formally, a paradigmatic description ofgrammar such as that of SFL attempts to placeas much of the work of the description in the typelattice constituting the grammar.
The role of con-straints over possible feature structures is minimal.Moreover, the distinctions represented in the typelattice subsume all kinds of grammatical variation--including variations that in, for example, an HPSG-style account might be considered as examples of theapplication of lexical rules.
Diathesis alternationsare one clear example; differing focusing construc-tions are another.
These are all folded into the typelattice.
Generation with such a resource is then re-duced to traversing the type lattice, generally fromleast-specific to most-specific types, collecting con-straints on structure.
A grammatical unit is thenexhaustively described by the complete list of typesselected uring a traversah this is called a selectionexpression.
Additional mechanisms (in particular,the 'choosers') serve to enforce determinism: thatis, rather than collect parallel compatible partial se-lection expressions, deterministic generation is en-forced by appealing to semantic or lexical informa-tion as and when required.
This approach, which istheoretically less than ideal, in fact supports quiteefficient generation.
It can be equated with the useof 'lean' formalisms in analysis-oriented GDE's.This paradigmatic design sketched here hasproved to have significant consequences for the de-sign of appropriate development environments.
Theproperties of these development environments arealso directly inferable from the properties of the lin-guistic descriptions they are to support.
Among theresults are:?
a much improved mode of resource debugging,?
a powerful treatment of multilinguality in lin-guistic resources,?
and strong support for distributed large-scalegrammar development.We will briefly note these features and then presentsome derivative functionalities that also representdifferences between analysis and generated orientedGDE's.
For the functional approaches, our con-crete descriptions will be based on KPML: FUF is?
: .
.
.
.
: .
.
: :  :.
:: : : ?
.
.
: .
: .
; :  .. : : .
.
.
:, :~,v,,  ' ' " " ' ~ : : : : ~ :  .....r ~ J : :+T~:"  .
.. .
.
.
?
sub~titul:ion-~alli~ f. .
.
.
.
: : .
.
.
.
.
: : :: .
.
.
, .
.
:  : .
: .
:: .
.
: ?
, : : .
.
.
.
.
: : : .
!
::: .
.
.
.
.
: : .
.
.
.
.
: : : i: ' : : ' ' : : ' ' : ?
?
: i : ?
: :  ?
~ n ~ - - ^ ~  .
.
.
.
.
.
.
: : .
.
.
.
.
: : : .
.
.
.
.
: :.
.
.
.
.
i "  ~.
.
.
.
.
: : i~ ~ : f ~  ~:+ut~ .~ .~.~ , ~ :  : : : ?
?
.
: : : : :  .
.
.
.
.
: :~ - ~ .?
$~.
.
.
.
.
.
.
.H 0 ~  .
.
.
.
.
.
.
.
.
: .
.
.
.
.
.
.
.
.
.
: c0~0f~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.~ ~ .
.
.
.
.
.
.
: : .
.
.
.
: :.
:Oal~l'ii~r~E: " ":~w~ .
.
.
.
.
.
.
.
: :?
.
.
.
.
.
.
.
.
: :: : :+ : . '
.
.
:+  ?
.
?
: : : ?
: .
:  : ?
: i .
?
?
?
!
!~ m ~ .
:  : ?
.
.
.
.
: : ?
?
.
.
: :,:.
:~+~ t ~ t .
~ . '
.
!
~ u ~  ~ .
.
.
.
.
.
.
.
.?
?
: : : : .
i  ?
?
?
: :Figure 1: Accessing points in the grammatical type lattice from a generated structurenot explicitly multilingual and has as yet few vi-sualization tools for resource development (limited,for example, to basic graphs of tile type lattice).KPML is more similar in its stage of developmentto, for example, ALEP, in that it offers a range ofvi-sualisation techniques for both the static resourcesand their dynamic use during generation, as well assupport methods for resource construction, includ-ing versioning, resource merging, and distinct kindsof modularity for distributed evelopment.
FUF isstill mostly concerned with the underlying enginefor generation and represents a programming envi-ronment analogous to CUF or TDL.Beyond in teract ive  t rac ingExperiences with debugging and maintaininglarge generation grammars lead to the conclusionthat 'tracing' or 'stepping' during execution of theresources i usually not a useful way to proceed.
Thiswas the favored (i.e., only) mode of interaction with,for example, the Penman system in the 80s.
This hasbeen refined subsequently, both in Penman and inKPML and FUF ,  so  that particular tracing can occur,interactively if required, only when selected linguis-tic objects (e.g., particular disjunctions, particulartypes of 'knowledge base' access, etc.)
are touchedduring generation or when particular events in thegeneration process occurred.
However, although al-ways necessary as a last resort and for novices, thismode of debugging has now in KPML given way com-pletely to 'result focusing'.
Here the generated result(which can be partial in cases where the resourcesfail to produce a final generated string) serves as apoint of entry to all decisions taken during gener-ation.
This can also be mediated by the syntacticstructure generated.This is an effective means of locating resourceproblems ince, with the very conservative 'formal-ism' supported (see above), there are only two pos-sible sources of generation errors: first, when thelinguistic resources defined cover the desired gen-eration result but an incorrect grammatical featureis selected (due to incorrect semantic mappings, orto wrongly constrained grammatical selections else-where); and second, when the linguistic resourcesdo not cover the desired result.
This means that thedebugging task always consists of locating where inthe feature selections made during generation--i.e.,in the selection expressions for the relevant gram-matical units--an inappropriate selection occurred.The selection expression list is accessed from theuser interface by clicking on any constituent, eitherfrom the generated string directly or from a graphi-cal representation f the syntactic structure.
The listitself can be viewed in three ways: (i) as a simple listfunctioning as a menu, (ii) as a graphical representa-tion of the type lattice (always a selected subregionof the lattice as a whole) with the selected featureshighlighted, and (iii) as a animated graphical traceof the 'traversal' of the type lattice during genera-tion.
In addition, all the structural details of a gen-erated string are controlled by syntactic onstraintsthat have single determinate positions in the typelattice.
It is therefore also possible to directly in-terrogate the generated string to ask where particu-lar structural features of the string were introduced.This is a more focused way of selecting particularpoints in the type lattice as a whole for inspection.Figure 1 shows a screenshot during this latter kindof user activity.
The user is attempting to find outwhat where the lexical constraints responsible forthe selection of the noun "TIME" in the phrase "Atthe same TIME" were activated.
Selecting to see thelexical class constraints imposed on this constituent(THING#3 in the structure top-right) gives a listingof applied constraints (lower-right).
This indicateswhich lexical constraints were applicable (e.g., NOUN,COMMON-NOUN, etc.)
and where in the type latticethese constraints were introduced (e.g., at the dis-junction named HEAD-SUBSTITUTION, etc.).
Click-ing on the disjunction name brings up a graphicalview of the disjunction with the associated struc-tural constraints (upper-left).
The feature selectedfrom a disjunction is highlighted in a different color(or shade of grey: lex ica l - th ing) .
The 'paradig-matic context' of the disjunction (i.e., where in thetype lattice it is situated) is given to the left of thedisjunction proper: this is a boolean expression overtypes presented in standard systemic notation.Several directions are then open to the user.
Theuser can either follow the decisions made in the typelattice to the left (less specific) or to the right (morespecific): navigating in either case a selected sub-graph of the type lattice.
Alternatively, the user caninspect the semantic decisions that were responsiblefor the particular selection of grammatical feature ina disjunction.
This 'upward' move is also supportedgraphically.
The particular decisions made and theirpaths through semantic hoice experts ('choosers')associated with each (grammatical) disjunction areshown highlighted.
Since all objects presented to theuser are mouse-sensitive, navigation and inspectionproceeds by direct manipulation.
All objects pre-sented can be edited (either in situ or within auto-matically linked Emacs buffers).
Any such changesare accumulated to define a patch version of theloaded resources; the user can subsequently createa distinct patch for the resources, or elect to acceptthe patches in the resource set.
Generation itself isfast (due to a simple algorithm: see above), and socreating a new 'result string' for further debuggingin the face of changes made is the quickest and mostconvenient way to conduct further tests.
This elim-inates any need for backtracking at the user devel-opment level.
It is possible to examine contrastivelythe use of resources across distinct generation cycles.One useful way of viewing this kind of activity isby contrast o the state of affairs when debuggingprograms.
KPML maintains the linguistic structureas an explicit record of the process of generation.
Allof the decisions that were made during generationare accessible via the traces they left in the generatedstructure.
Such information is typically not availablewhen debugging a computer program since when theexecution stack has been unwound intermediate r -sults have been lost.
If certain intermediate r sultsmust consequently be re-examined, it is necessaryto introduce tracing at appropriate points--a pro-cedure that can now usually be avoided resulting insignificantly faster cycles of debugging/testing.Mul t i l ingua l  representat ionsThe use of multilingual system networks has beenmotivated by, for example, Bateman, Matthiessen,Nanri and Zeng (Bateman et al, 1991).
KPMLprovides upport for such resources, including con-trastive graphical displays of the type lattices for dis-tinct languages.
In addition, it is possible to mergeautomatically monolingual or multilingual resourcedefinitions and to separate them out again as re-quired.
Importing segments of a type lattice for onelanguage to form a segment for a distinct languageis also supported.
This has shown that it is not nec-essary to maintain a simple division between, for ex-ample, 'core' grammar and variations.
Indeed, sucha division is wasteful since language pairs differ inthe areas they share.
The support for this multi-linguality is organized entirely around the paradig-matic type lattice.
The support tools provided formanipulating such language-conditionalized latticesin KPML appear to significantly reduce the devel-opment time for generation resources for new lan-guages.
A black-and-white r presentation f a con-trastive view based on the Eagles morphology rec-ommendations is shown in Figure 2.
The graph em-phasizes areas held in common and explicitly labelsparts of the lattice that are restricted in their lan-guage applicability.The possibilities upported for working multilin-gually (e.g., inheritance, merging resources) rely en-Rm~m~o GJ,apm~ cmi~m?
c~1~tm~ Fsmmmm~sDispk~f Modes ~ ~lt~nUon ToI ~ l t  ~ Show ~ V~IJl Collecl~d Feat\]uresRegxa~ ~ TYPES : Langum~g: O ~0 .
.
.
.
~)))+IW~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Figure 2: Views on a multilingual resourcetirely on the relative multilingual applicability of theparadigmatic organization of the grammar.
It ap-pears a fact of multilingual description that paradig-matic functional organizations are more likely toshow substantial similarities across languages thanare the syntagmatic structural descriptions.
In anoverview of resource definitions across 6 languages,it was found that the multilingual description onlycontains 32% of the number of objects that wouldbe need if the 6 grammars were represented sepa-rately.
Significant degrees of overlap have also beenreported whenever a description of one languagehas been attempted on the basis of another (cf.,e.g., (Alshawi et al, 1992; Rayner et al, 1996)).The paradigmatic basis simply extends the rangeof similarities that can be represented and providesthe formal basis for providing computational toolsthat support the user when constructing languagedescriptions 'contrastively'.D is t r ibuted  large-scale grammardeve lopmentThe paradigmatic organization of a large-scalegrammar shows a further formal property that isutilized throughout the KPML GDE.
Early work onsystemic descriptions of English noted that emer-gence of 'functional regions': i.e., areas of the gram-mar overall that are concerned with particular areasof meaning.
As Halliday notes:"These \[functional\] components are re-flected in the lexicogrammatical systemin the form of discrete networks of op-tions.
Each .
.
.
is  characterized by stronginternal but weak external constraints: forexample, any choice made in transitivity\[clause complementation\] has a significanteffect on other choices within the transi-tivity systems, but has very little effecton choices within the mood \[speech acttypes\] or theme \[information structuring\]systems."
(Halliday, 1978, pl13).This organization was first used computationally inthe development of the Nigel grammar of Englishwithin the Penman project.
Nigel was probably thefirst large-scale computational grammar whose pre-cise authorship is difficult to ascertain because of thenumber of different linguists who have contributedto it at different imes and locations.The basis for this successful example of dis-tributed grammar development is the organizationof the overall type lattice of the grammar into mod-ular functional regions.
This has now been takenas a strong design principle within KPML where alluser access to the large type lattices making up agrammar is made through specific functional regions:for example, asking to graph the lattice will by de-fault only present information within a single re-gion (with special pointers out of the region to indi-cate broader connectivity).
This is the paradigmaticequivalent of maintaining a structural grammar inmodules related by particular syntactic forms.
How-ever, whereas the latter information is not stronglyorganizing for work on a generation grammar, theformer is: work on a generation resource typicallyproceeds by expanding a selected area of expressivepotential--i.e., the ability of the grammar to expresssome particular set of semantic requirements.
Thiscan include a range of grammatical forms and isbest modularized along the paradigmatic dimensionrather than the syntagmatic.The relative strength of intra-region connectionsin contrast o extra-region connections has provideda solid basis for distributed grammar development.Developers typically announce that they are inter-ested in the expressive potential of some functionalregion.
This both calls for others interested in thesame functional region to exchange results coopera-tively and warns generally that a functional regionmay be subject o imminent change.
When a revisedversion of the region is available it replaces the pre-vious version used.
Integration of the new regionis facilitated by a range of visualization tools andconnectivity checks: the final test of acceptabilitym\[\]mmmmmmmmmmm\[\]mmm\[\]mmmmmmmI PPSPATIOTIPORAL CIRClRSTA\]~*IAL 32 systems 2 6  systems 4 inputs 10 inputs 1 output55 systems21 inputs9 outputs12 systemI inputs5 outputs\\Figure 3: Functional region connectivity for English (extract)is that all test suites (see next subsection) generatethe same results as with the previous region versionand that a new test suite is provided that demon-strates the increased or revised functionality of thenew region.Regions are defined across languages: the currentmultilingual resources released with KPML includearound 60 regions.
A partial region connectivitygraph for the English grammar is shown in Figure 3.This graph also serves as a 'menu' for accessing fur-ther graphical views of the type lattice as well asselections from test suites illustrating use of the re-sources contained within a region.
Dependencies be-tween regions are thus clearly indicated.In tegrated  test  suitesSets of linguistic resources for generation are typ-ically provided with test suites: such test suites con-sist minimally of a semantic specification and thestring that should result when generating.
In KPMLthese are indexed according to the grammatical fea-tures that are selected uring their generation.
Thispermits examples of the use and consequences of anyfeature from the type lattice to be presented uringdebugging.
This is one particularly effective way notonly of checking the status of resources but also fordocumenting the resources.
The complete genera-tion history of examples can be examined in exactlythe same way as newly generated strings.
An inter-esting line of development underway is to investigatecorrespondences between the paradigmatic featuresdescribing features in a KPML-example set and thosefeatures used in the TSNLP initiative.4 Discuss ionThe basic premises of a generation-oriented GDEsuch  as KPML differ in certain respects to those thoseof an analysis-oriented GDE such as ALEP.
This alsostretches to the style of interaction with the system.For example, interaction with the KPML GDE is,as with Smalltalk and ALEP, object-oriented but, incontrast o ALEP, the objects to which a user hasaccess are strongly restricted to just those linguisticconstructs that are relevant for generation.
This sep-arates development environment details from the re-sources that are being developed.
This is, of course,both possible and desirable because KPML is not in-tended to be tailored for particular types of resourceby the user: the theoretical orientation is fixed.The benefits of this approach seem to far outweighthe apparent limitations.
First, the visualizationsprovided are exactly tailored to the details of thelinguistic objects supported and their use in genera-tion.
Thus resource sets, networks, systems (disjunc-tions), semantic hoice experts, dynamic traversal ofthe network, syntactic structures, etc.
all have theirown distinctive graphical representations: this es-tablishes a clear modularity in the conception of theuser that is easily obscured when a single more gen-eration representation style (e.g., feature structurepresented in a feature structure ditor) is used for awide range of information.
This clarifies the differ-ence in information modules and thus helps devel-opment.
It is then also possible to 'fold' generationdecisions into the visualizations in a natural way:thus supporting the 'result focusing' mode of devel-opment described above.
Thus, whenever esourcesare inspected, their use during selected cycles of gen-eration is also displayed by highlighting or annotat-ing the appropriate objects shown.This also influences the kind of user for which theGDE is appropriate.
The central areas in generationare still primarily functional and pragmatic ratherthan structural and syntactic.
It is less common thatlinguists and developers concerned with pragmaticsand text linguistics are fully comfortable with con-straint logic programming.
The dedicated graphicalpresentation of linguistic objects provided in KPMLappears to provide a more generally accessible toolfor constructing linguistic descriptions.
Grammarcomponents have been written using KPML by com-puter scientists without training in computationallinguistics, by functional text linguists, by transla-tors and technical writers, as well as by computa-tional and systemic-functional linguists.Finally, however, the well understood relationshipbetween systemic-functional style descriptions and,for example, typed feature representations providesa bridge from the less formal, more functional styleof description back to the kind of representationsfound in NLA-oriented GDE's.
It is therefore tobe expected that a broader ange of linguistic inputand development work will be encouraged to feedinto large-scale resource development than would bepossible if the kind of development were limited tothat practised for purposes of analysis.ReferencesHiyan Alshawi, David Carter, BjSrn Gamb?ck, andManny Rayner.
1992.
Swedish-English QLF trans-lation.
In Hiyan Alshawi, editor, The Core LanguageEngine, pages 277 - 319.
MIT Press.Douglas E. Appelt.
1985.
Planning Natural LanguageUtterances.
Cambridge University Press, Cambridge,England.John A. Bateman, Christian M.I.M.
Matthiessen, KeizoNanri, and Licheng Zeng.
1991.
The re-use of linguis-tic resources across languages in multilingual gener-ation components.
In Proceedings of the 1991 Inter-national Joint Conference on Artificial Intelligence,Sydney, Australia, volume 2, pages 966 - 971.
MorganKaufmann Publishers.John A. Bateman, 1997.
KPML Development Envi-ronment: multilingual linguistic resource developmentand sentence generation.
German National Centerfor Information Technology (GMD), Institute for in-tegrated publication and information systems (IPSI),Darmstadt, Germany, January.
(Release 1.1).John A. Bateman.
to appear.
Automatic discourse gen-eration.
In Allen Kent, editor, Encyclopedia of Li-brary and Information Science.
Marcel Dekker, Inc.,New York.EAGLES.
1996.
Formalisms working group final report.Expert advisory group on language ngineering stan-dards document, September.Michael Elhadad.
1990.
Types in functional unificationgrammars.
In Proceedings of the 28th.
Annual Meet-ing of the Association for Computational Linguistics,pages 157 -164.
Association for Computational Lin-guistics.Michael A.K.
Halliday.
1978.
Language as social semi-otic.
Edward Arnold, London.William C. Mann and Christian M.I.M.
Matthiessen.1985.
Demonstration of the Nigel text genera-tion computer program.
In James D. Benson andWilliam S. Greaves, editors, Systemic Perspectives onDiscourse, Volume 1, pages 50-83.
Ablex, Norwood,New Jersey.David D. McDonald.
1980.
Natural Language Pro-duction as a Process of Decision Making under Con-straint.
Ph.D. thesis, MIT, Cambridge, Mass.Kathleen R McKeown.
1985.
Text Generation: UsingDiscourse Strategies and Focus Constraints to Gen-erate Natural Language Text.
Cambridge UniversityPress, Cambridge, England.A.
Mel'~uk, Igor and A.K.
Zholkovskij.
1970.
Towards afunctioning "meaning-text" model of language.
Lin.guistics, 57:10-47.Stephen G. Pulman, editor.
1991.
EUROTRA ET6/ I :rule formalism and virtual machine design study - fi-nal report.
Commission of the European Communi-ties, Luxembourg.
Contributors: H. Alshawi, D.J.Arnold, R. Backofen, D.M.
Carter, J. Lindop, K. Net-ter, S.G. Pulman, J. Tsujii and H. Uszkoreit.M.
Rayner, D. Carter, and P. Bouillon.
1996.
Adaptingthe core language ngine to french and spanish.
InProceedings of NLP-IA-96, Moncton, new Brunswick,May.JSrg Sch/itz.
1996.
European Research and Develop-ment in Machine Translation.
MT News Interna-tional, 15:8-11, October.
(Newsletter of the Interna-tional Association for Machine Translation).N.K.
Simpkins, G. Cruickshank, and P.E International.1993.
ALEP-0 Virtual Machine extensions.
Technicalreport, CEC.Michael Zock and Giovanni Adorni.
1996.
Introduction.In Giovanni Adorni and Michael Zock, editors, Trendsin natural language generation: an artificial intelli-gence perspective, number 1036 in Lecture Notes inArtificial Intelligence, pages 1-16.
Springer-Verlag.
