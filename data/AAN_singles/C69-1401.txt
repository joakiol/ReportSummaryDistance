Applications of~a Com~uter Systemfor Transformational Grammar*byJoyce FriedmanThe University of MichiganAnn Arbor, Michigan, U.S.A.Writing a transformational grammar for even a fragment of anatural language is a task of a high order of complexity.
Not onlymust the individual rules of the grammar perform as intended inisolation, but the rules must work correctly together in order topro~nce the desired results.
The details of grammar-writing arelikely to be regarded as secondary by the linguist, who is mostconcerned with what is in the language and how it is generated, andwould generally prefer to pay less attention to formal and notationaldetail.
It is thus natural to ask if a computer can be used to assistthe linguist in  developing a grammar.
The model is formal; thereare a large number of details to be worked out; the rules interactwith one another in ways which may not be foreseen.
Most of theerrors which occur in writing grammars can be corrected if only theyare brought to the attention of the linguist.
Those which cannotbe so corrected should be of even greater interest to the writer ofthe grsmmar.This research was supported in part by the United States AirForce Electronic Systems Division under Contract F19628-C-00353 andby the National Science Foundation under Grant GS-2271.A computer system which attempts to provide this assistanceto the writer of a grammar is now available at both the University1 of Michigan and Stanford University.
The system is written inFortran IV and runs on the II~ 360/67 computer.The linguistic model embodied by the system is the theory oftransformational grammar, roughly as described by Chomsky inof the Theory of Syntax.
\[2\] The programs represent the linguisticmetatheory.
Grammars are accepted by the programs as data.
Theprogram handles all three components of a transformational grammar:phrase structure, lexicon, and transformations.
It carries out thefull process of sentence generationj including phrase structuregeneration, lexical insertion, and transformation.The technical details of the particular model of transformationalgrammar have been described elsewhere \[3\].
This presentation willemphasize the ways in which the programs can be used, and willdescribe experiences in using them both in grammar writing and inteaching.An example of a grammarThe notation for grammars and the use of the programs will notbe described formally here, but will be illustrated by an extendedexample.
The example consists of a small grarmnar and a sample deri-vation.
Each part will be presented twice, first as initiallyiThis system was designed and programmed by the author 3 withT.
H. Bredt, E. W. Doran~ T. S. Martner, and B.W.
Pollack.prepared by linguists at the University of Montreal \[i\], and thenas redone in the computer system.
The grammar has been greatlyreduced by selecting only those transformations which were used inthe derivation of the sample sentence selected.In Figures i and 2 the phrase-structure rules are given inparallel, first as written by the linguists, secondly as preparedfor input to the computer system.
The computer form can be seen tobe a linearization of the usual form, with both parentheses andcurly brackets represented by parentheses.
No ambiguity arises fromthis since the presence of a comma distinguishes the choices fromthe options.
The only other differences are minor: the symbol"~"  has been replaced by "DELTA", the sentence symbol "P" has beentranslated into English "S", and accents have been omitted.
None ofthese changes is of any consequence.Figure 5 is a listing of a-partial lexicon.
This component ispresent only implicitly in the original French gran~nar, where thecomplex symbols are indicated in the base trees.
The lexicon specifiesfirst the features which are used in the grammar.
The list of cate-gory features also determines the order in which lexical insertiontakes place.
The inherent features include some which are includedin complex symbol s in the lexicon, and others which are added onlyby transformations.
Contextual features are defined in the lexiconby giving a structural analysis of the context in which the item canappear.
The location in which the word may be inserted is indicatedby an underline symbol.
Thus, common nouns are marked +NCOM, whichmeans that they can occur only following a determiner (DET) in aPPRENEGPREDADVINSTSVSACOPSNCOMPLDETDEFANAPHDEMCARDFigure iPhrase Structure Rules, from \[i\]--, # ( PRE ) SN PRED #_ ,  (i~) (~m~)ne pasINSTv (co~)cop ADJ  (CO~L)_, estICDE~) N( | quel| ) (CARD)- "  I~HItDEM J-~ I cele ( la )-~  ce ( i~~PLURJ"MONTREAL FRENCH"PHRASES LRUCTURE$ = # (PRE)  SN PRED # .PRE : ( IN / )  (NEG) .NE~ : NE PAS.PRED : (SV (ADVINS),SA).ADVI~S = PAR (SN,DEL~A).SV = V (COMPL).SA = COP AD,J (CONPL) .COP = EST.SN : ((SN) S, (DET) N).COMPL : (SN,5) (SAD.DET : ((DEF,QUEL))(CARD).DEF : (ANAPH,DEM).ANAPH = (CE ((CI,LA)),LE).DEM = CE ((CI,LA)).CARD = (SING,PLUR).SING : UN.PLUR = (PROCARD,QUELQUES,DEUX,IROIS).PROCARD : NO~SRE DE.$ENDPSGFigure 2Phrase Structure RulesFigure 3Lexicon^AZ~ ^AO VZ~JO9 Vr~ ~ Q_ ~,~ ~'  n---j m-- ~-- t~.l ^ I=.I I.~I E? "
' .
~ I  0 .
-3~ A E O<=I :L  z Q"  _-3 IQ.. - -  L}0 "~' I-,,I - ,  O <1: l.,.. =~ VO {'1~ E I.~ o z {)~ :3I.
U'IL,L.\] "--~ ~ ~ CY') V V~"  n ~r" ~"~ Q. .
- - I  V~'--I "-q ~ I IrE :?
:  {'--" "--~0 '~,.~ L=J ~-' C.) ' '~"--~ '~E "~" 0.
JL~L~L , J  +/ /J J  ( :30  .
-~'Z'JE (3 (3  / /( :30  Z :~- :E_  ~-( 3 ( 3 / + + O O~"  Z :.~E (30,?~ rE  :=~- ...l .
J  0,,-I .- J  I 0 --~ :3  D-I L  l: I .
rE  - - I .
- I  Ji i ::::3.
'E_ E I~.
r~.- - I  L~J tTJ I t .'ELI.
l .~ I.~ L~I I--, "--1LL I : :3 r '~  I t ,~:: i /~/} O,) I=.
-E  ~,LI .,~ 0?
'~ - ,~  -F + l*J..r~ r~ I r-.
00 0 r~r:- FE i - "  r', n L~ - -  OQ.
.
- 0I I O0~/ ' l l - - , l -~ :  ~ I ~'~I  "-~{~ ~ I - ,  I-., -I.=J I~1 I~: / '  {/~ / :3,:Y 'E  I I 0 .
.D '}  ~ ' f} l - ,  l :~ ::3L,~I +E l ,= .l.,.ll..~.l I r~: , "E , , - I  + I- ' ,  1~: (:3 IL~\]~.
I  + + +O , 'n '~  ~ +  O ~LEL , J~ :~;~.
P_.
/ /0 : :3  r~ L )  + ~L, rE/ / '  ~1~ O O I"1 ) I'--I ~"~ ~" "1" LIJ h~ I X+t ' J+  + ' "~ + :~ '--' "~  a .
.
.
- I/ rh  0 / :>  + l.,.I L.~ <l: <I: O i : :~I.~11.,J + ~,.I i - ,  ..~.. ~ {/~ / + 1.~1noun phrase (SN).After the preliminary definitions, the lexicon contains a setof lexical entries.
In a computer derivation of a sentence, lexicalitems will be selected at random from those of the appropriate cate-gory which match inhereht, features already in the tree and have con-textual features, satisfied by the tree.Figures ~ and 5 are presentations of the transformationalcomponent.
In the computer version a transformation consists ofthree parts, identification, structural description (SD), andstructural chan~e (SC).
The identification contains the number andname of the transformation, plus information to be used in deter-mining when it is to be invoked.
This includes a group numberrepetition parameters, keywords, etc.
The structural description issimilar to the linguistic form, but allows also subanalysis to anydepth.
Representation of the structural change by a sequence ofelementary operations removes any possible ambiguity from the state-ment.
In addition to adjunctions and substitutions, there are alsoelementary operations which alter complex symbols.
\+PASSIF \ MERGEFadds a new feature specification to the complex symbol of term 4.\*FEM *PERS\ MOVEF 4 7 will change those two features of term 7 sothat they are the same as for term 4.It may be noted that the transformation LOWESTS and the controlprogram of Figure 5 have no correspondents in Figure 4.
They areneeded because the program requires that the traffic rules be givenexplicitly as part of a grammar.
LOWESTS selects the lowest sentence\ [~\ ]  ~ST-~J# (P~)  SN V SN (SN) p~ A #i 2 3 4 5 6 7 8 9 =>l 2 8 4 5 6 7 3 9\[Tg\] ANTEP-OBL.
OBL# .
(P~) A v SN (sN) p~+SN #1 2 3 4 5 6 7 8 =~i 2 5 4 <+passif ~ 6 7 8\[TI3\] AC-PRED# (PRE) \[(DET)l 2 3li fem ~ (P)\]sN pers |2 pers~p1~ IN4 5i 2 3 4 5OBL(cop)COND: 7 $ ~fempers~2 pers~plur\[T33?
ELLIPSE ### X1 22#3Figure 4Transformations, from \[I\]OBL0BLAD7#9=>7~ ~fem~pers,~2 pers~plur9\[ ~ l \ ]\[~52\]M-PASS.x <+~ssif>1 2l+est 2(+~cow: 2~+~TR- TRAITS- PASSX est1 2i 2 ?
~progr( d futur( ~preterit( ~per s<42 pers<~fem(gplur(~infCON\]), 2~4prog~futur~preteritYV3 =>le+ 3~+passif ~~progrfutur~preterit~pers2 persa infafem4plurV0BL0BLv4 =>4Figure 4 (Continued)~0Figure 5Transformationsv<~0o oL~,<~<~~ 2: I--.. , ,~  ~ ~0 "- '  .
-~ + "U: ~ ~"  *V r.~ ~ .--I '-~ "~ r'-- (,")/l "10o C~, L~I / l.J.I,~, I~.. C~ C'< / ~..~ L.z.
,m--(~  C.~ L~ ~....4 r~(~ '~ C.) <~ ,,::~ / ""t.--.1 r< L,...I > .
.
,m ....I IT~ I--, C:~~ ?,'~ ~0, ,1  I-.-, C%I ~ J  I:1...,m C< L, .
.
I  r , ,~ /0?~0~ J t - - '~ ZO 0ILLII.
'-4.~o~AV(~(0O...1Figure 6Base Tree, from \[1\]"VI I I Iv v v v V  d}i I " '~ JI "  ' ~OJ 0.. ~ ?-t ~&'} + I I 1 I E',V V V V Vt ,I~J.QI 'r~L~p4,Q@E-~i2"which contains boundaries.
The control program specifies that thecyclic transformations are to be carried out for this lowestsentence.
After a cycle the boundaries are erased and the nexthighest sentence becomes lowest.
The postcyclic transformations willthen be carried out.A particular tree, created as an example in Ill, is presentedin Figures 6 and 7.
Figure 7 contains two alternative versions, afixed-field format and a bracketted free-field form.
Either of theseis acceptable to the programs.
The  sentence at the top of the figureis merely a title; it will not be processed by the program.
Thelexical items "Trudeau", "deGaulle", and "berne" have not been in-cluded, although they could have been.
If these items had beenentered in the tree, the lexical insertion process would merely haveadded the appropriate complex symbols for them.Figure 8 gives the derivation as presented in Ill.
Figure 9 isthe final part of the listing of the computer output.The use of the ~ro6ramsThe system was designed to be used by a linguist who is in theprocess of writing a transformational grammar.
As lexical items ortransformations are added they can be tested in the context of allprevious rules and their effect can be examined.The easiest errors to detect and repair in a grammar aresyntactic errors.
As a grammar is read in by the program a check ismade for formal correctness.
For each error a comment is producedwhich attempts to explain what is wrong.
The program then continues~3Figure 7Alternative forms of Base Tree~ Z,..IlxJt~A^AVAVU'/VAV(f lV' - Ir~AVV14Figure 8Derivation, from \[ l\]e.Az ~...-~ ,-4,-4 ~ r40 P. Z.
~/~ l-i l @0 ~ E~ ..~ ~~n ~ 0 Z>~ ~1~1~ ~ ~+.~ I !
I I .~"v v vv!
^ I "zU I I I I I-i,,~ v v v v ~!Z>+Z0 ,-q~50E0r~A A A A A A A AFigure 9Computer DerivationI ,db4Eb.IO!IL l(/1,_,1 {f)  ,,~ :~ZN/, - IA !^~ oV !V ~*, .~23 I.-.IE ~* EL,..I\ [ t lQ C~I O/{ ;1  //+r,,t~4-I-,,"lO ^I , .
I::~ rd'}I .~ V!
!
:3  -m. - I  ._J!
$E E b,4* 4 -I.s.Ir~ 0..O O!
I!
I+ ~/ /2:> ZE ,-..,.
- JI.s.Ic~r~b J\[.0L:.,If~.
J  <~zO O 'O  OA ' A A A A A A ~ A A A A A A A A A A16to read in the rest of the gra~nar, recovering as best it can fromthe error.
In most cases a single error will cause a small part ofthe grammar to be read badly, but the rest of the grammar will beread in and used in whatever tests were requested.
An effort wasmade to make the error com~aents as clear and explicit as possible,and to make the program continue despite input errors.Deeper errors arise when a grammar is syntactically correct,but does not correctly describe the language of which it purports tobe a grammar.
~lese errors of intent cannot be detected directly bythe program, since it has no standard of comparison.
The programattempts to provide enough feedback to the linguist so that he willbe able to detect and investigate the errors.The information produced by the program consists of derivationswhich may be partially controlled by the user.
Since random deriva-tions have been found to be of r@latively little interest, the systemallows the user to control the sentences to be generated so thatthey are relevant to his current problem.
(The device used for thispurpose has been described in \[g\].)
It is only in the sense ofproviding feedback to the user that the system can be called a"grammar tester"; it does not directly seek out errors in a gran~nar,nor does it evaluate the grammar.For a standard run of the system the inputs are a grammar, atSMAIN card, and some trees.
The grammar consists of one or more ofphrase structure, lexicon, and transformations.
The SMAIN card isa specification of the type of run to be made.
The system must bei7told (i) what type of input trees to expect:TRIN, for fixed-field treeFTRIN, ffor free-field bracketted tree(2) whether to generate a tree around a skeletal input or whether itis only necessary to insert lexical items:GEN, to generate a tree and insert lexical itemsLEX, to insert lexical itemsand (3) whether or not transformations are to be applied:TRAN, if transformations are to be invoked.The general form of the SMAIN card can be represented asSMAIN I TRIFTR~N~ ( (n ) I~ l ) (TRAN)  .The integer n specifies the number of time each input tree is to beused.An an example,$MAIN TRIN GEN TRAN .specifies a run in which a skeletal tree is read, a full tree isgenerated including lexical items, and the transformations areapplied.The specification$~u~ ~I~ 5 u~x T~.might be used in testing a lexicon and transformations against afixed base tree.
The tree will be read and five cases of lexical/~8insertion plus transformation will be carried out.SMA~N ~IN 4 nEX .would do four examples of lexical insertion for each input.After the process is completed for one input, another input isread and the cycle repeats.
A run terminates when there are no moreinputs.Computer experiments in transformational ~rammarThe system has been in use since February 1968, although notfully complete at that time.
The first experiments were carried outby the designers of the system, using granrnars based on material inthe linguistic literature.
This was done to provide test materialfor the programs, but, more importantly, to help ensure that thenotational conventions would be adequate.
A fragment of grammarfrom Chomsky's Aspects was used to test ideas and programs forlexical insertion.
The II~ Core Grammar of Rosenbaum and Lochak\[6\] was used in developing and testing the transformational component.Both of these projects led to valuable teaching materials, as weshall discuss later.Aspects and Core provided us with separate examples of lexiconand transformations.
There was at first no single source which con-tained both.
A relatively formal grammar was needed, even though afinal translation into the notation of the system would still ofcourse be necessary.
Elizabeth Closs Traugott's Dee~0 and surfacestructure in Alfredian Prose \[ 7 \] appeared at about that time andwas the first grammar which was formalized in the notation after the19fact.
Considerable effort had gone into designing the notation; wewere anxious to see if it would now seem natural for a grammar whichwas new to us.
Alfred was thus the first real test for the system.As it turned out there were a few difficulties which arose because thenotation had not been explained clearly enough, but the results of therun were also revealing about the grsm~nar.One general effect which was noticed in these first few caseshad continued to be striking: the need for complete precision inthe statement of a grammar forces the linguist to consider problemswhich are important, but of which he would otherwise be unaware.Also during the spring of 1969 Barbara Hall Partee made twosets of runs with preliminary versions of a grammar of English beingdeveloped by the U.C.L.A.
Air Force English Syntax Project.
Thisgrammar presented another kind of challenge to the system, becauseit was not based directly on the Aspects model, but incorporated somerecent ideas of Fillmore.
As before, these runs assisted in cleaningup the programs but were also of interest to the linguist.
The majoradvantages from the linguistic point of view seem to have been, first,that the notational system of the computer model provided a frameworkin which grammars could be stated, and second, that the computer runsmade it easier todetect  certain errors in the grammars.
In the main,these errors were not particularly subtle, and could have been caughtby working over the grammar carefully.The program was also used by L. Klevansky~ who wrote a grammarof Swahili for the dual purposes of testing the programs and learningthe language.20These early experiments are described in a report \[5\] whichgives the gran~nars as well as a detailed discussion of the resultsof the computer runs.The form of the French grammar used in the extended exampleabove is based on the form of the Core grammar; it was thereforeeasily translated into the notation of the system.
Shortly afterthe grsmmnar was received, a large part of it was running on thecomputer.
Minor errors in the grammar have been found and corrected;it will now be available to students as another example of a trans-formational grammar.The next experiment planned using the system is a projectproposed by Susumu Nagara and Donald Smith at the University ofM ich ig~,  who plan to use the system to aid in writing a grammar ofJapanese.Modifications to grammars based on computer runsIn almost all cases the gran~nars used with the system havebeen sufficiently complete for at least informal distribution.
Theprograms were really designed to make it easier to write grammars,not to test completed grammars.
Nonetheless, on the basis of computerruns, certain types of changes have been found to be needed in thegrammars.
The cotangents which follow are based on all the grammars;they do not all apply to any one of them.iTrivial correctionsThe most co~on errors are typographical errors in transcriptionof the grammar.
These are not errors in the grammar itself; having2ito deal with them is one of the prices of using the computer.
Ingeneral, these can be caught with relative ease.More than one grammar has had simple errors with respect torepetition of a transformation.
Number agreement transformationsare written so that they produce CAT S S S ... where CAT S is wanted.
(The grammar as written calls for an infinite sequence of S's to beadded.
The program, more cautious, adds ten S's, then complains andgoes on to the next transformation.
)Transformations are often stated so that they fail to apply inall cases where it is intended they apply.
For example, thestructural description of PASSIVE asSD # (PRE) 3NP AUX 5V (PREP) 7NP % PREP 10P % # ,WHERE 3EQ7.fails to take into account some additional parts of the VP.
Thecorrection toSD # (PRE) ~NP AUX (HAVE EN)(BE ING) 5V (PREP) 7NPPREP lOP ~ #, WHERE 3 EQ 7-will allow PASSIVE to work in the additional cases.
Similarly, aNOMINAL-AGREemeNT transformation which marks subjects as +NOMIN mustapply not only to pronouns which precede verbs but also to those whichprecede copulas.
Thus the structural descriptionSD # ~ 3(~ON, REL) V ~ # .must be replaced bySD # ~ 3(PRON, REL) (V, COP) % # .22Interrelatedness of transformationsA slightly more interesting set of problems found in thecomputer runs are those which arise through the interrelatedness oftwo or more transformations.
For example, in one of the grsmm~arsthere ~ere both WH-questions and TAG-questions.
It was found thatthe TAG transformations was (optionally) applicable to any question,so that for exampleTOM HAS PREFER EN WHAT GIRL HAS TOM NOTwas produced.
This error was easily repaired once it was detected.On the other hand, a similar problem which was not easilyfixed arose with another transformation which was marked optional.Testing showed that for certain base trees the ~esult was bad if thetr~usformation did not apply; however3 when the transformation wasltemporarily changed to obligatory, the grammsx then failed to producesome intended sentences.
The proper correction to the grammar wouldhave required specification of the contexts in which the transforma-tion was obligatory.Incompleteness of grammarsFormal gram~nars so fa r  have each attempted to describe somesubset of a language.
In computer testing many problems outsidethe scope of the grammar are evident.
If, for example, a grammardoes not treat prepositions seriously, then once this becomes apparent,ithe computer runs need to be designed to avoid prepositions.Dee~ structure ~roblemsTwo of the grammars which have been studied suffer problemsZ3with the WH-morpheme when it occurs in non-sentences and not as arelative marker.
Thus, for example, sentences such asWHAT BLAME MAY NT BE BE INGandWHICH THING MUST HAVE BE EN APPROVE ING OFWHAT TABLEare in fact even worse than they appear, because they are notquestions.
Although this problem has no simple solution in thecurrent framework, the inputs to the program can be controlled toavoid generating sentences of this form.Inadequacies in the linguistic modelAn interesting change to the system was suggested by theattempt to formalize the Core grammar.
In both the WH-attractionand the Question-transformations the structural description containsa two-part choice between a PREP NP pair and simply an NP.
This isof the form:% (PREP NP, ~P)where ~ is a variable.
Any structure which satls~iesthe first part of the choice will also satisfy the second, and anyanalysis algorithm must have some order of search which will eitheralways select PREP NP or always select NP only.
But the intent isthat there should be a genuine choice, so that the grammar producesbothABOUT WHAT DID JOHN SPEAKand24WHAT DID JOHN SPEAK ABOUTThe solution which was found for the problem was to add an additionalvalue (AAC) for the repetition parameter for a transformation.If a transformation is marked AAC, all possible analyses willbe found, but only one of them, selected at random, will be used asthe basis for structural change.
This seined the appropriate way tosolve the problem for the Core grammar, and it turned out also tosolve a slightly different repetition problem in the grammar of A1-fredian prose.
Notice that this i s  really an observation about theform of grammars, rather than about a particular grammar.
Yet itarose by consideration of particular examples.Surface structureThe surface Structure associated with a sentence derivation ismuch easier to study if it can be produced automatically.
In severalcases it has been apparent from the information provided by the computerruns that revisions in the grammar were needed if the surface structureis to be at all reasonable.
This is a case where the computer runs arecertainly not necessary, but where they reduce the tediousness ofstudying the problem.In stmmmary, it seems to me that main value in computer testingof a completed grsm~nar is that the need for a precise statementbrings to the consideration of the linguist problems which are other-lwise below the surface.
These problems may be in the grammar itselfor they may be in the linguistic model itself.
For a grammar inprocess of being written the greatest advantage is in allowing rules25to be checked as they are added, and in bringing out the interactionbetween rules.Instructional use of the s~stemThe system has now been used by Sziliard Szabo in teaching~eneral linguistics at the University of San Francisco, by MichaelO'Malley in a course in natural language structure at the Universityof Michigan, and by the author in courses in co~0utational linguisticsat Stanford and Michigan.The method of use is to make available to the students a fileof one or more grammars to be used as examples and as bases formodifications.
The fragments from Aspects and the IEM Core grammarhave been most useful3 although small grammar written for this purposehave also been used.
The students are then asked to make modificationsand additions to the grammars.For graduate students, a reasonable exercise for a term paperis to read a current journal article on transformational grammar, andthen show how the results can be incorporated into the basic grammar,or show why they cannot be.
The papers chosen by the students havegenerally been ones in which transformations are actually given.This project has been very successful as am introduction to trans-formational grammar for computer science students.Other students have chosen simply to use the computer to obtainfully developed examples of derivations illustrating aspects ofgrammar in which they are interested.These experiences have confirmed our belief that specific26examples presented by the computer, and the feedback provided whena student modifies a grammar, are valuable in enabling the udentto understand the notion of trausformational grammar.27References\[i\] Colmerauer, C., M. Courval, M. Poirier, and Antonio A. M. Querido.Grammaire- I~ Description s~ntaxi~ue d'un sous-ensemble du francais,Universite de Montreal, (March3 1969).\[2\] Chomsky, N. Aspects of the Theory of S~ntax.
M.I.T.
Press,Cambridge, Massachusetts (1965).\[3\] Friedman, Joyce.
A computer system for transformational grammar.Cosnn.
ACM (to appear).\[4\] Friedman, Joyce.
Directed random generation of sentences.
Comm.AC_~M, 12, pp.
4O-46.\[5\] Friedman, Joyce.
(Ed.)
Computer Experiments in TransformationalGrammar, CS-108, Computer Science Dept., Stanford University,(August, 1968).\[6\] Rosenbaum, R., and Lochak, D. The I~M core grammar of English.In Lieberman, D.
(Ed.)
Specification and utilization of atransformational grammar.
AFCRL-66-270 (1966).\[7\] Traugott, Elizabeth C. Deep and surface structure in Alfredianprose.
Mimeographed.
PEGS Paper #14 (August, 1967).
