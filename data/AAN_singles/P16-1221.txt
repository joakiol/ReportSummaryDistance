Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2337?2346,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsVector-space topic models for detecting Alzheimer?s diseaseMaria YanchevaDepartment of Computer Science,University of TorontoToronto, Ontario, Canadayancheva@cs.toronto.eduFrank RudziczToronto Rehabilitation Institute; andDepartment of Computer Science,University of TorontoToronto, Ontario, Canadafrank@cs.toronto.eduAbstractSemantic deficit is a symptom of languageimpairment in Alzheimer?s disease (AD).We present a generalizable method for au-tomatic generation of information contentunits (ICUs) for a picture used in a stan-dard clinical task, achieving high recall,96.8%, of human-supplied ICUs.
We usethe automatically generated topic model toextract semantic features, and train a ran-dom forest classifier to achieve an F-scoreof 0.74 in binary classification of controlsversus people with AD using a set of only12 features.
This is comparable to re-sults (0.72 F-score) with a set of 85 man-ual features.
Adding semantic informa-tion to a set of standard lexicosyntactic andacoustic features improves F-score to 0.80.While control and dementia subjects dis-cuss the same topics in the same contexts,controls are more informative per secondof speech.1 IntroductionAlzheimer?s disease (AD) is the most commoncause of neurodegenerative dementia, and affectsmore than 24.3 million people worldwide (Bal-lard et al, 2011).
Importantly, early detection en-ables some therapeutic intervention and disease-modifying treatment (Sperling et al, 2011).Longitudinal studies of people with autopsy-confirmed AD indicate that linguistic changes aredetectable in the prodromal stages of the disease;these include a decline in grammatical complexity,word-finding difficulties, and semantic content de-ficiencies, such as low idea density (i.e., the ratioof semantic units to the total number of words ina speech sample), and low efficiency (i.e., the rateof semantic units over the duration of the speechsample) (Bayles and Kaszniak, 1987; Snowdon etal., 1996; Le et al, 2011; Ahmed et al, 2013b).In the present study, we investigate methods ofautomatically assessing the semantic content ofspeech, and use it to distinguish people with ADfrom healthy older adults.A standard clinical task for eliciting sponta-neous speech, with high sensitivity to language inearly AD, is picture description.
In it, a participantis asked to provide a free-form verbal descriptionof a visual stimulus (Goodglass and Kaplan, 1983;Bayles and Kaszniak, 1987).
The picture is asso-ciated with a set of human-supplied informationcontent units (hsICUs) representing componentsof the image, such as subjects, objects, locations,and actions (Croisile et al, 1996).
The semanticcontent of the elicited speech can then be scoredby counting the hsICUs present in the descrip-tion.
Previous studies found that, even in the earli-est stages, descriptions by those with AD are lessinformative compared to those of healthy olderadults, producing fewer information units out of apre-defined list of units, and having less relevantcontent and lower efficiency (Hier et al, 1985;Croisile et al, 1996; Giles et al, 1996; Ahmedet al, 2013a).Using a pre-defined list of annotated hsICUs issubject to several limitations: (i) it is subjective ?different authors use a different number of hsICUsfor the same picture (e.g., from 7 to 25 for CookieTheft in the Boston Diagnostic Aphasia Examina-tion (BDAE)) (Hier et al, 1985; Croisile et al,1996; Forbes-McKay and Venneri, 2005; Lai etal., 2009); (ii) it may not be optimal for detectinglinguistic impairment ?
the manually-annotatedhsICUs are neither exhaustive of all details presentin the picture, nor necessarily reflective of the con-tent units which differ most across groups; (iii)it is not generalizable ?
hsICUs are specific toa particular picture, and new visual stimuli (e.g.,2337required for longitudinal assessments) need to beannotated manually.
In addition to requiring timeand effort, this may result in inconsistencies, sincethe methodology for identifying hsICUs was neverclearly defined in previous work.Automatic scoring of semantic content inspeech to detect cognitive impairment has sofar required manual hsICUs.
Hakkani-T?ur etal.
(2010) used unigram recall among hsICUsin the Western Aphasia Battery?s Picnic picture(Kertesz, 1982) and obtained a correlation of 0.93with manual hsICU counts.
Pakhomov et al(2010) counted N -grams (N = 1, 2, 3, 4) ex-tracted from a list of hsICUs for the Cookie Theftpicture to assess semantic content in the speech ofpatients with frontotemporal lobar degeneration.Fraser et al (2016) counted instances of lexical to-kens extracted from a list of hsICUs, using depen-dency parses of Cookie Theft picture descriptions,and combined them with other lexicosyntactic andacoustic features to obtain classification accuracyof 81.9% in identifying people with AD from con-trols.
While those automated methods for scor-ing the information content in speech used man-ual hsICUs, we have found none that attempted toproduce ICUs automatically.In this paper, we present a generalizable methodfor automatically generating information contentunits for any given picture (or spontaneous speechtask), using reference speech.
Since clinical datacan be sparse, we present a method for buildingword vector representations using a large generalcorpus, then augment it with local context win-dows from a smaller clinical corpus.
We eval-uate the generated ICUs by computing recall ofhsICUs and use the constructed topic models tocompare the speech of participants with and with-out dementia, and compute topic alignment.
Sec-ond, we automatically score new picture descrip-tions by learning semantic features extracted fromthese generated ICU models, using a random for-est classifier; we assess performance with recall,precision, and F-score.
Third, we propose a setof clinically-relevant features for identifying ADbased on differences in topic, topic context, ideadensity and idea efficiency.2 Methodology2.1 DataDementiaBank is one of the largest public, lon-gitudinal datasets of spontaneous speech from in-dividuals with and without dementia.
It was col-lected at the University of Pittsburgh (Becker etal., 1994) and contains verbal descriptions of thestandard Cookie Theft picture (Goodglass and Ka-plan, 1983), along with manual transcriptions.In our study, we use 255 speech samples fromparticipants diagnosed with probable or possibleAD (collectively referred to as the ?AD?
class), and241 samples from healthy controls (collectivelyreferred to as the ?CT?
class), see Table 1.
Weremove all CHAT-format annotations (MacWhin-ney, 2015), filled pauses (e.g., ?ah?
and ?um?
),phonological fragments (e.g., ?b b boy?
becomes?boy?
), repairs (e.g., ?in the in the kitchen?
be-comes ?in the kitchen?
), non-standard forms (e.g.,?gonna?
becomes ?going to?
), and punctuation(e.g., commas are removed).
These corrections areall provided in the database.
We ignore transcriptsof the investigator?s speech, as irrelevant.
Subjectdata were randomly partitioned into training, vali-dation, and test sets using a 60-20-20 split.Table 1: Distribution of dataset transcriptions.Class Subjects Samples TokensAD 168 255 24,753CT 98 241 26,654Total 266 496 51,4072.2 Human-supplied ICUs (hsICUs)We combine all hsICUs in previous work for theCookie Theft picture (Hier et al, 1985; Croisile etal., 1996; Forbes-McKay and Venneri, 2005; Laiet al, 2009) with hsICUs obtained from a speechlanguage pathologist (SLP) at the Toronto Reha-bilitation Institute (TRI).
The annotations of theSLP overlap completely with previously identifiedhsICUs, except for one (apron).
The first threecolumns of Table 2 summarize these manually-produced hsICUs.2.3 Automatic generation of ICUsOur novel method of identifying ICUs is basedon simple topic modelling using clusters of globalword-vector representations from picture descrip-tions.
First, we train a word-vector model on alarge normative general-purpose corpus, allowingus to avoid sparsity in the clinical data?s word-word co-occurrence matrix.
Then, we extract thevector representations of words in the Dementia-2338Table 2: Information units above the double line are human-supplied ICUs (hsICUs) found in previouswork, except those marked with?which were annotated by an SLP for this study; those below are ad-ditionally analyzed.
Over 1,000 clustering configurations based on word vectors extracted from Controland Dementia reference transcriptions, ?
is the mean of the scaled distance (Eq.
1) of each hsICU to itsclosest cluster centroid, ?
is the standard deviation, and ?
= (?dementia?
?control).
Statistical signifi-cance of ?
was tested using an independent two-sample, two-tailed t-test; *** = p < .001, ** = p < .01,* = p < .05, ns = not significant.Control DementiaType ID hsICU ?
?
?
?
?
pSubject S1 boy -0.510 0.102 -0.860 0.204 -0.350 ***Subject S2 girl -0.357 0.203 -0.545 0.284 -0.187 ***Subject S3 woman 0.171 0.468 0.140 0.433 -0.031 nsSubject S4 mother -0.533 0.206 -0.187 0.300 0.345 ***Place P1 kitchen 0.667 0.650 0.901 0.710 0.234 ***Place P2 exterior 1.985 0.601 1.947 0.530 -0.039 nsObject O1 cookie -1.057 0.221 -0.943 0.230 0.114 ***Object O2 jar 0.243 0.486 0.146 0.453 -0.097 ***Object O3 stool -0.034 0.674 -0.162 0.623 -0.128 ***Object O4 sink -0.839 0.433 -0.600 0.631 0.239 ***Object O5 plate 0.564 0.593 0.639 0.608 0.076 **Object O6 dishcloth 4.509 1.432 3.989 1.154 -0.521 ***Object O7 water -0.418 0.582 -0.567 0.530 -0.149 ***Object O8 cupboard 0.368 0.613 0.453 0.637 0.085 **Object O9 window -0.809 0.425 -0.298 0.452 0.511 ***Object O10 cabinet 2.118 0.556 2.154 0.496 0.036 nsObject O11 dishes 0.037 0.503 -0.083 0.406 -0.120 ***Object O12 curtains -0.596 0.594 0.121 0.707 0.717 ***Object O13 faucet 1.147 0.567 1.016 0.547 -0.131 ***Object O14 floor -0.466 0.384 -0.932 0.451 -0.466 ***Object O15 counter 0.202 0.427 0.449 0.323 0.247 ***Object O16 apron?-0.140 0.433 0.181 0.688 0.321 ***Action A1 boy stealing cookies 1.219 0.373 0.746 0.462 -0.473 ***Action A2 boy/stool falling over -0.064 0.465 -0.304 0.409 -0.240 ***Action A3 woman washing dishes -0.058 0.539 0.009 0.611 0.068 **Action A4 woman drying dishes -0.453 0.469 -0.385 0.541 0.068 **Action A5 water overflowing in sink 0.147 0.804 0.282 0.791 0.135 ***Action A6 girl?s actions towards boy, girlasking for a cookie0.800 0.555 0.620 0.861 -0.179 ***Action A7 woman daydreaming, unawareor unconcerned about overflow0.049 0.774 0.092 0.561 0.043 nsAction A8 dishes already washed sittingon worktop-0.224 0.535 -0.597 0.426 -0.373 ***Action A9 woman being indifferent to thechildren0.781 0.795 0.881 0.585 0.100 **Relation brother 2.297 0.510 1.916 0.344 -0.380 ***Relation sister 0.862 0.273 0.737 0.349 -0.125 ***Relation son 2.140 0.443 1.818 0.312 -0.322 ***Relation daughter 0.916 0.356 0.904 0.421 -0.012 ns2339Bank corpus, and optionally augment them withlocal context windows from the clinical dataset.We use GloVe v1.2 (Pennington et al, 2014) toobtain embedded word representations and trainon a combined corpus of Wikipedia 20141+Gigaword 52.
The trained model consists of400,000 word vectors, in 50 dimensions.Transcriptions in DementiaBank are lowercasedand tokenized using NLTK v3.1, and each wordtoken is converted to its vector space representa-tion using the trained GloVe model.
There are atotal of 26,654 word vectors (1,087 unique vec-tors) in the control data, and 24,753 (1,131 unique)in the dementia data.
Since we aim to con-struct a model of semantic content, only nounsand verbs are retained prior to clustering.
The re-sulting dataset consists of 9,330 word vectors (801unique vectors) in the control data, and 8,021 (843unique) in the dementia data.We use k-means clustering with whitening, ini-tialization with the Forgy method, and a distor-tion threshold of 10?5as the stopping condition,where distortion is defined as the sum of the dis-tances between each vector and its correspond-ing centroid.
We train a control cluster model onthe control training set (see Fig.
1 for a 2D pro-jection of cluster vectors using principal compo-nent analysis), and a dementia cluster model onthe dementia training set.
Clusters represent top-ics, or groups of semantically related word vec-tors, discussed by the respective group of subjects.While prior work is based on hsICUs that are ex-pected to be discussed by healthy speakers, weconstruct a separate cluster model for the controland dementia groups since it is unclear whetherthe topics discussed by both groups overlap.
Wevary k (= 1, 5, 10, 15, 20, 30, 40, 50), complet-ing 1,000 runs for each value, and use the Elbowmethod to select the optimal number of clusters onthe respective validation set.
The optimal setting,k = 10, optimizes the tradeoff between the per-centage of variance explained by the clusters, andtheir total number.
The resulting clusters representtopics that can be compared against hsICUs.3 Experiments3.1 Recall of hsICUsIn order to assess (i) how well the automaticallygenerated clusters match clinical hsICUs for this1http://dumps.wikimedia.org/enwiki/20140102/2https://catalog.ldc.upenn.edu/LDC2011T07Figure 1: Control cluster model.
The word vectorsbelonging to a given cluster are shown in the samecolour.
The most frequent words in each clusterare displayed.image, and (ii) how much the two generated topicmodels differ, we analyze the vector space dis-tance between each hsICU and its closest clustercentroid (dEuclidean) in each of the control and de-mentia models.
Since some clusters are more dis-persed than others, we need to scale the distanceappropriately.
To do so, for each cluster in eachmodel, we compute the mean distortion, ?cl, of thevectors in the cluster, and the associated standarddeviation ?cl.
For each hsICU vector, we com-pute the scaled distance between the vector and itsclosest cluster centroid in each generated model asfollows:dscaled=(dEuclidean?
?cl)?cl(1)The scaled distance is equivalent to the num-ber of standard deviations above the mean ?
avalue below zero indicates hsICUs which are veryclose to an automatically generated cluster cen-troid, while a large positive value indicates hsICUsthat are far from a cluster centroid.
To account forthe fact that k-means is a stochastic algorithm, weperform clustering multiple times and average theresults.
Table 2 shows the mean, ?, and standarddeviation, ?, of dscaled, for each hsICU, over 1,000cluster configurations for each model.To quantify the recall of hsICUs using each gen-erated cluster model, we consider hsICUs with?
?
3.0 to be recalled (i.e., the distance to theassigned cluster centroid is not greater than thoseof 99.7% of the datapoints in the cluster, given aGaussian distribution of distortion).
The recall of2340hsICUs, for both the control and dementia mod-els, is 96.8%.
Since the optimal number of gen-erated clusters is k = 10, while the number ofhsICUs is 31, multiple hsICUs can be grouped inrelated themes (e.g., one automatically generatedcluster corresponds to the description of animatesubjects in the picture, capturing four hsICUs: S1?S4).
Both the control and dementia models do notrecall hsICU O6, dishcloth, which suggests that itis a topic that neither study group discusses.
Allremaining hsICUs are recalled by both the controland dementia models, indicating that the hsICUtopics are discussed by both groups.However, to assess whether they are discussedto the same extent, i.e.
to evaluate whether thetwo topic models differ, we conducted an indepen-dent two-sample two-tailed t-test to compare themean scaled distance, ?, of each hsICU to its clos-est cluster centroid, in each cluster model (see ?
inTable 2).
As anticipated, since they involve infer-ence of attention, the control model is better at ac-counting for the topics of the overflowing sink andthe mother?s indifference: overflowing (t(1998) =?3.78, p < .001); sink (t(1998) = ?9.85, p <.001); indifferent (t(1998) = ?3.20, p < .01).While there is no significant difference in the termwoman between the two groups, the control modelpredicts the term mother better than the demen-tia model (t(1998) = ?30.05, p < .001).
Toinvestigate whether healthy participants are morelikely to identify relations between the subjectsthan participants with cognitive impairment, werepeated the recall experiment with the followingnew hsICUs: brother, sister, son, daughter.
In-terestingly, the dementia cluster model containsa cluster which aligns significantly more closely,than any in the control model, with all four ofthese relation words: brother (t(1998) = 19.53,p < .001); sister (t(1998) = 8.93, p < .001); son(t(1998) = 18.78, p < .001).
While the controlparticipants mention relation words as often as theparticipants with dementia3, the generated clus-ter models show that the ratio of relation wordsto non-relation words is higher for the dementiagroup4.3An independent two-sample two-tailed t-test of the effectof group on the number of occurrences of each relation wordshows no statistical significance: son (t(494) = 0.65, p >.05), daughter (t(494) = 0.63, p > .05), brother (t(494) =0.97, p > .05), sister (t(494) = 1.65, p > .05).4An independent two-sample two-tailed t-test of the ef-fect of group on this ratio shows a significant difference inthe ratio of sister to mother, with the control group having aThe new hsICU, apron, which was not identi-fied in previous literature but was labelled by anSLP for this study, is significantly more likely tobe discussed by the control population (t(1998) =?12.46, p < .001), suggesting at the impor-tance of details for distinguishing cognitively im-paired individuals.
In a similar vein, control par-ticipants are significantly more likely to identifyobjects in the background of the scene, such asthe window (t(1998) = ?26.04, p < .001),curtains (t(1998) = ?24.54, p < .001), cup-board (t(1998) = ?3.03, p < .01), or counter(t(1998) = ?14.59, p < .001).3.2 Cluster model alignmentWhile prior work counted the frequency withwhich fixed topics are mentioned, our data-drivencluster models allow greater exploration of dif-ferences between the set of topics discussed byeach subject group, and the alignment betweenthem.
Since prior work has found that subjectswith cognitive impairment produce more irrele-vant content, we quantify the amount of dispersionwithin each cluster through the standard deviationof its distortion and its type-to-token ratio (TTR),as shown in Table 3.
Further, we compute direc-tional alignment between pairs of clusters in eachmodel.
For each cluster in one model, alignment isdetermined by computing the closest cluster in theother model for each vector, and taking the major-ity assignment label (see a in Table 3).
To quan-tify the alignment, the Euclidean distance of eachvector to the assigned cluster in the other modelis computed, scaled by the mean and standard de-viation of the cluster distortion; the mean of thescaled distance, ?a, is reported in Table 3.To quantify the alignment of clusters in eachmodel, we consider clusters to be recalled if theirdistance to the closest cluster in the other modelis ?a?
3.
Notably, all control clusters (C0-C9)are recalled by the dementia model, while one de-mentia cluster, D7, is not recalled by the controlmodel.
This exemplifies the fact that while thedementia group mentions all topics discussed bycontrols, they also mention a sufficient number ofextraneous terms which constitute a new heteroge-neous topic cluster, having the highest TTR.lower ratio (t(494) = ?4.10, p < .001).2341Table 3: Cluster statistics for control (C*) and dementia (D*) models, with computed cluster alignment.Cluster words are the 5 most frequently occurring words.
fvecis the fraction of all vectors which belongto the given cluster.
?cland ?clare the mean and standard deviation of the cluster distortion.
fnis thefraction of nouns among cluster vectors; (1?
fn) is the fraction of verbs.
TTR is the type-to-token ratio.a is the ID of the aligned cluster, and ?ais the mean scaled distance to the aligned cluster centroid.ID Cluster words fvec?cl?clfnTTR a ?aControlC0 window, floor, curtains, plate, kitchen 0.14 5.42 1.18 0.94 0.14 D4 0.69C1 dishes, dish 0.04 1.62 1.11 1.00 0.01 D1 0.01C2 running, standing, action, hand, counter 0.18 4.97 1.25 0.57 0.22 D8 0.16C3 water, sink, drying, overflowing, washing 0.17 5.18 1.13 0.66 0.09 D6 0.04C4 stool, legged 0.03 0.53 1.26 0.96 0.01 D4 -0.28C5 mother, boy, girl, sister, children 0.11 3.49 1.08 1.00 0.04 D2 -0.08C6 cookie, cookies, sakes, cream 0.06 2.00 1.15 1.00 0.01 D0 -0.08C7 jar, cups, lid, dried, bowl 0.04 3.88 2.30 0.97 0.04 D5 0.63C8 see, going, getting, looks, know 0.18 3.84 1.16 0.38 0.13 D3 0.18C9 reaching, falling, fall, summer, growing 0.05 4.18 1.41 0.38 0.16 D8 0.21DementiaD0 cookie, cookies, cake, baking, apples 0.07 2.18 0.74 1.00 0.02 C6 0.09D1 dishes, dish, eating, bowls, dinner 0.05 1.42 1.72 0.98 0.03 C1 0.05D2 boy, girl, mother, sister, lady 0.11 3.63 1.25 0.99 0.05 C5 0.20D3 going, see, getting, get, know 0.24 3.67 1.06 0.38 0.11 C8 -0.11D4 stool, floor, window, chair, curtains 0.10 5.10 1.00 0.97 0.13 C0 0.08D5 jar, cups, jars, dried, honey 0.04 2.00 2.26 0.98 0.03 C7 -0.44D6 sink, drying, washing, spilling, overflowing 0.14 5.36 1.20 0.52 0.19 C3 0.36D7 mama, huh, alright, johnny, ai 0.01 6.24 1.34 0.95 0.55 C8 4.13D8 running, fall, falling, reaching, hand 0.18 4.97 1.29 0.47 0.25 C2 0.15D9 water, dry, food 0.05 0.39 1.13 1.00 0.01 C3 -0.593.3 Local context weighted vectorsSince there is significant overlap in the topics dis-cussed between the control and dementia groups,we proceed by investigating whether the overlap-ping topics are discussed in the same contexts.
Tothis end, we augment the word vector represen-tations with local context windows from Demen-tiaBank.
Each word vector is constructed usinga linear combination of its global vector from thetrained GloVe model, and the vectors of the ?Nsurrounding context words, where each contextword is weighted inversely to its distance from thecentral word:?w= vw+?1?i=?N?i?
vi+N?i=1?i?
vi(2)Here, ?wis the local-context-weighted vectorfor word w, vwis the GloVe vector for word w, viis the GloVe vector for word iwithin the context ofw, and ?iis the weighting of word i, inversely andlinearly proportional to the distance between con-text and central word.
Following previous work(Fraser and Hirst, 2016), we use a context windowof size N = 3.
We extract local-context-weightedvectors for all control and dementia transcripts,and construct two topic models as before.To quantify whether the dementia contexts dif-fer significantly from the control contexts for thesame word, we extract all word usages as local-context-weighted vectors, and find the centroid ofthe control usages, along with the mean and stan-dard deviation of the control vectors from theircentroids.
Then, we compute the average scaledEuclidean distance, dscaled, of the dementia vec-tors from the control centroid, as in Eq.
1.
Wordswith dscaled> 3 (i.e., where the dementia contextvectors are further from the control centroid thanthe majority of control context vectors) are con-sidered to have different context usage across thecontrol and dementia groups.Interestingly, all of the control cluster words areused in the same contexts by both healthy partici-pants and those with dementia.
However, the aver-age number of times these words are used per tran-script is significantly higher in the control group(1.07, s.d.
= 0.12) than in the dementia group(0.77, s.d.
= 0.14; t(18) = 1.87, p < .05).While the two groups discuss the same topicsgenerally and use the same words in the same con-texts, not all participants in the dementia groupidentify all of the control topics or discuss themwith the same frequency.
A contextual analy-sis reveals that certain words are discussed in adistinct number of limited contexts, while othersare discussed in more varied contexts.
For in-2342Figure 2: All usages of the word cookie in Demen-tiaBank.
Control usages are represented with bluecircles; dementia with red crosses.stance, while we identified a control cluster as-sociated with the topic of the cookie in Section3.2, there are two clearly distinct contexts in whichthis word is used, by both groups, as illustrated inFig.
2.
The two clusters in context space corre-spond to: (i) the usage of cookie in the compoundnoun phrase cookie jar, and (ii) referring to a sin-gle cookie, e.g.
reaching for a cookie, hand her acookie, getting a cookie.3.4 ClassificationTo classify speakers as having AD or not, weextract the following types of features fromour automatically-generated cluster models: (i)distance-based metrics for each of the controlmodel clusters, C0?C9, (ii) distance-based metricsfor each of the dementia model clusters, D0?D9,(iii) idea density, and (iv) idea efficiency.
Giventhe vectors associated with a transcript?s nounsand verbs, feature Ci(and equivalently, Di) iscomputed by finding the average scaled distance,dscaled(Eq.
1), of all vectors assigned to clusterCi.
A feature value below zero indicates that thetranscript words assigned to the cluster are verywell predicted by it (i.e., their distance from thecluster centroid is less than the average clusterdistortion).
Conversely, clusters which representtopics not discussed in the transcript have largepositive feature values.
We chose these distance-based metrics to evaluate topic recall in the tran-script since a continuous measure is more appro-priate for modelling the non-discrete nature of lan-guage and semantic similarity.
We compute ideadensity as the number of expected topics men-tioned5divided by the total number of words inthe transcript, and idea efficiency as the numberof expected topics mentioned divided by the totalduration of the recording (in seconds).
The ex-pected topics used for computation of idea den-sity and idea efficiency are the ICUs from theautomatically-produced cluster models.We perform classification using a random for-est, whose parameters are optimized on the valida-tion set, and performance reported on the test set.We vary the following experimental settings: clus-ter model (control; dementia; combined), featureset (distance-based; distance-based + idea density+ idea efficiency), and context (no context; contextwith N = 3).
A three-way ANOVA is conductedto examine the effects of these settings on averagetest F-score.
There is a significant interaction be-tween feature set and context, F (1, 110) = 9.07,p < 0.01.
Simple main effect analysis showsthat when using the extended feature set, vectorsconstructed without local context windows fromthe clinical dataset yield significantly better resultsthan those with context (p < 0.001), but thereis no effect when using only distance-based fea-tures (p = 0.87).
There is no main effect of clus-ter model on test performance, F (2, 117) = 2.30,p = 0.11, which is expected since cluster align-ment revealed significant overlap between the top-ics discussed by the control and dementia groups(Section 3.2).
Notably, there is a significant effectof feature set on test performance, whereby addingthe idea density and idea efficiency features resultsin significantly higher F-scores, both when usinglocal context for vector construction (p < 0.05),and otherwise (p < 0.001).As a baseline, we use a list of hsICUs extractedby Fraser et al (2016) in a state-of-the-art au-tomated method for separating AD and controlspeakers in DementiaBank.
These features consistof (i) counts of lexical tokens representing hsICUs(e.g., boy, son, and brother are used to identifywhether hsICU S1 (Table 2) was discussed, and(ii) Boolean values which indicate whether eachhsICU was mentioned or not.
Overall, this consti-tutes 85 features.
Additionally, Fraser et al (2016)identified a list of lexicosyntactic and acoustic(LS&A) features which are indicative of cogni-tive impairment.
We compute the performance ofeach set of features independently, and then com-5I.e., the number of word vectors in the transcript whosescaled distance is within 3 s.d.
?s from the mean cluster distor-tion of at least one cluster.2343Table 4: Binary classification (AD:CT) using a random forest classifier, with 10-fold cross-validation.All cluster models are trained on vectors with no local context.
LS&A are lexicosyntactic and acousticfeatures as described by Fraser et al (2016).
The reported precision, recall, and F-score are a weightedaverage over the two classes.Model Features Accuracy Precision Recall F-scoreBaseline hsICUs 0.73 0.74 0.73 0.72Baseline LS&A 0.76 0.77 0.76 0.76Baseline hsICUs + LS&A 0.80 0.80 0.80 0.80control distance-based 0.68 0.69 0.68 0.68dementia distance-based 0.66 0.67 0.66 0.66combined distance-based 0.68 0.69 0.68 0.68control distance-based + idea density + idea efficiency 0.74 0.76 0.74 0.74dementia distance-based + idea density + idea efficiency 0.74 0.75 0.74 0.74combined distance-based + idea density + idea efficiency 0.74 0.75 0.74 0.74control distance-based + idea density + idea efficiency + LS&A 0.79 0.79 0.79 0.79dementia distance-based + idea density + idea efficiency + LS&A 0.77 0.78 0.77 0.77combined distance-based + idea density + idea efficiency + LS&A 0.80 0.80 0.80 0.80bine them.
Table 4 summarizes the results; thefirst column indicates the cluster model (e.g., con-trol indicates a cluster model trained on the controltranscriptions), and the second column specifiesthe feature set.
Our 12 automatically generatedfeatures (i.e., the combined set of distance-basedmeasures, idea density, and idea efficiency) re-sult in higher F-scores (0.74) than using 85 manu-ally generated hsICUs (0.72); a two-sample pairedt-test shows no difference (using control clustermodel: t(9) = 1.10, p = 0.30; using dementiacluster model: t(9) = 0.74, p = 0.48) indicatingthe similarity of our method to the manual goldstandard.
Furthermore, we match state-of-the-artresults (F-score of 0.80) when we augment the setof LS&A features with our automatically gener-ated semantic features.4 DiscussionWe demonstrated a method for generating topicmodels automatically within the context of clinicalassessment, and confirmed that low idea densityand low idea efficiency are salient indicators ofcognitive impairment.
In our data, we also foundthat speakers with and without Alzheimer?s dis-ease generally discuss the same topics and in thesame contexts, although those with AD give morespurious descriptions, as exemplified by the irrel-evant topic cluster D7 (Table 3).Using a fully automated topic generation andfeature extraction pipeline, we found a small setof features which perform as well as a large set ofmanually constructed hsICUs in binary classifica-tion experiments, achieving an F-score of 0.80 in10-fold cross-validation on DementiaBank.
Thefeatures which correlate most highly with classinclude: idea efficiency (Pearson?s r = ?0.41),which means that healthy individuals discuss moretopics per unit time; distance from cluster C4(r = 0.34), which indicates that speakers with ADfocus less on the topic of the three-legged stool;and idea density (r = ?0.26), which shows thathealthy speakers need fewer words to express thesame number of topics.While we anticipated that combining a largenormative corpus with local context windows froma clinical corpus would produce optimal vectors,using the former exclusively actually performsbetter.
This phenomenon is being investigated.This implies that word-vector representations donot need to be adapted with context windows inspecific clinical data in order to be effective.A limitation of the current work is its re-quirement of high-quality transcriptions of speech,since high word-error rates (WERs) could com-promise semantic information.
We are thereforegenerating automatic transcriptions of the Demen-tiaBank audio using the Kaldi speech recogni-tion toolkit6.
So far, a triphone model with thestandard insertion penalty (0) and language modelscale (20) on DementiaBank gives the best averageWER of 36.7?3.6% with 10-fold cross-validation.Continued optimization is the subject of ongoingresearch but preliminary experiments with thesetranscriptions indicate significantly lower perfor-6http://kaldi.sourceforge.net/2344mance of the baseline model (0.68 F-score; t(9) =3.52, p < 0.01).
While the eventual aim is a com-pletely automatic system, our methodology over-comes several major challenges in the manual se-mantic annotation of clinical images for cogni-tive assessment, even with manual transcriptions.Specifically, our methodology is fully objective,sensitive to differences between groups, and gen-eralizable to new stimuli which is especially im-portant if longitudinal analysis is to avoid the so-called ?practice effect?
by using multiple stimuli.Across many domains, to extract useful seman-tic features (such as idea density and idea effi-ciency), one needs to first identify informationcontent units in speech or text.
Our method can beapplied to any picture or contentful stimuli, given asufficient amount of normative data, with no mod-ification.
Although we apply this generalizablemethod to a single (albeit important) image usedin clinical practice in this work, we note that weobtain better accuracies with this completely auto-mated method than a completely manual alterna-tive.AcknowledgmentsThe authors would like to thank Selvana Morcos,a speech language pathologist at the Toronto Re-habilitation Institute, for her generous help withproviding professional annotations of informationcontent units for the BDAE Cookie Theft picture.ReferencesS.
Ahmed, C. A. de Jager, A. F. Haigh, and P. Garrard.2013a.
Semantic processing in connected speechat a uniformly early stage of autopsy-confirmedAlzheimer?s disease.
Neuropsychology, 27(1):79?85.S.
Ahmed, A. F. Haigh, C. A. de Jager, and P. Garrard.2013b.
Connected speech as a marker of diseaseprogression in autopsy-proven Alzheimer?s disease.Brain, 136(12):3727?3737.C.
Ballard, S. Gauthier, A. Corbett, C. Brayne, D. Aars-land, and E. Jones.
2011.
Alzheimer?s disease.
TheLancet, 377(9770):1019?1031.K.
A. Bayles and A. W. Kaszniak.
1987.
Communi-cation and cognition in normal aging and dementia.Little, Brown, Boston.J.
T. Becker, F. Boller, O. L. Lopez, J. Saxton, andK.
L. McGonigle.
1994.
The natural historyof Alzheimer?s disease.
Archives of Neurology,51:585?594.B.
Croisile, B. Ska, M. J. Brabant, A. Duchene, Y. Lep-age, G. Aimard, and M. Trillet.
1996.
Compara-tive study of oral and written picture description inpatients with Alzheimer?s disease.
Brain and Lan-guage, 53(1):1?19.K.
E. Forbes-McKay and A. Venneri.
2005.
De-tecting subtle spontaneous language decline in earlyAlzheimer?s disease with a picture description task.Neurological Sciences, 26(4):243?254.K.
C. Fraser and G. Hirst.
2016.
Detecting seman-tic changes in Alzheimer?s disease with vector spacemodels.
In Dimitrios Kokkinakis, editor, Proceed-ings of LREC 2016 Workshop: Resources and Pro-cessing of Linguistic and Extra-Linguistic Data fromPeople with Various Forms of Cognitive/PsychiatricImpairments (RaPID-2016), pages 1?8, Portoro?z,Slovenia.
Link?oping University Electronic Press.K.
C. Fraser, J.
A. Meltzer, and F. Rudzicz.
2016.Linguistic features identify Alzheimer?s disease innarrative speech.
Journal of Alzheimer?s Disease,49(2):407?422.E.
Giles, K. Patterson, and J. R. Hodges.
1996.
Per-formance on the Boston Cookie Theft picture de-scription task in patients with early dementia of theAlzheimer?s type: missing information.
Aphasiol-ogy, 10(4):395?408.H.
Goodglass and E. Kaplan.
1983.
The assessmentof aphasia and related disorders.
Lea and Febiger,Philadelphia.D.
Hakkani-T?ur, D. Vergyri, and G. Tur.
2010.Speech-based automated cognitive status assess-ment.
In 11th Annual Conference of the Interna-tional Speech Communication Association, pages258?261.D.
B. Hier, K. Hagenlocker, and A. G. Shindler.
1985.Language disintegration in dementia: effects of eti-ology and severity.
Brain and Language, 25(1):117?133.A.
Kertesz.
1982.
The Western aphasia battery.
Gruneand Stratton, New York.Y.
H. Lai, H. H. Pai, and Y. T. Lin.
2009.
Tobe semantically-impaired or to be syntactically-impaired: linguistic patterns in Chinese-speakingpersons with or without dementia.
Journal of Neu-rolinguistics, 22(5):465?475.X.
Le, I. Lancashire, G. Hirst, and R. Jokel.
2011.Longitudinal detection of dementia through lexicaland syntactic changes in writing: a case study ofthree British novelists.
Literary and Linguistic Com-puting, 26(4):435?461, may.B.
MacWhinney.
2015.
The CHILDES Project: Toolsfor analyzing talk.
Lawrence Erlbaum Associates,Mahwah, NJ, 3rd edition.2345S.
V. S. Pakhomov, G. E. Smith, D. Chacon, Y. Feli-ciano, N. Graff-Radford, R. Caselli, and D. S. Knop-man.
2010.
Computerized analysis of speech andlanguage to identify psycholinguistic correlates offrontotemporal lobar degeneration.
Cognitive andBehavioral Neurology, 23(3):165?177.J.
Pennington, R. Socher, and C. D. Manning.
2014.GloVe: Global vectors for word representation.
InConference on Empirical Methods on Natural Lan-guage Processing (EMNLP), pages 1532?1543.D.
A. Snowdon, S. J. Kemper, J.
A. Mortimer, L. H.Greiner, D. R. Wekstein, and W. R. Markesbery.1996.
Linguistic ability in early life and cognitivefunction and Alzheimer?s disease in late life.
Find-ings from the Nun Study.
JAMA: the Journal of theAmerican Medical Association, 275(7):528?532.R.
A. Sperling, P. S. Aisen, L. A. Beckett, D. A. Ben-nett, S. Craft, A. M. Fagan, T. Iwatsubo, C. R. Jack,J.
Kaye, T. J. Montine, D. C. Park, E. M. Reiman,C.
C. Rowe, E. Siemers, Y. Stern, K. Yaffe, M. C.Carrillo, B. Thies, M. Morrison-Bogorad, M. V.Wagster, and C. H. Phelps.
2011.
Toward definingthe preclinical stages of Alzheimer?s disease: rec-ommendations from the National Institute on Aging-Alzheimer?s Association workgroups on diagnosticguidelines for Alzheimer?s disease.
Alzheimer?s &Dementia: the Journal of the Alzheimer?s Associa-tion, 7(3):280?292.2346
