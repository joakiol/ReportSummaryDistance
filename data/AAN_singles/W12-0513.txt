Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 97?105,Avignon, France, April 23 2012. c?2012 Association for Computational LinguisticsA Generalised Hybrid Architecture for NLPAlistair WillisDepartment of ComputingThe Open University,Milton Keynes, UKa.g.willis@open.ac.ukHui YangDepartment of ComputingThe Open University,Milton Keynes, UKh.yang@open.ac.ukAnne De RoeckDepartment of ComputingThe Open University,Milton Keynes, UKa.deroeck@open.ac.ukAbstractMany tasks in natural language process-ing require that sentences be classified froma set of discrete interpretations.
In thesecases, there appear to be great benefits inusing hybrid systems which apply multipleanalyses to the test cases.
In this paper, weexamine a general principle for building hy-brid systems, based on combining the re-sults of several, high precision heuristics.By generalising the results of systems forsentiment analysis and ambiguity recogni-tion, we argue that if correctly combined,multiple techniques classify better than sin-gle techniques.
More importantly, the com-bined techniques can be used in tasks whereno single classification is appropriate.1 IntroductionThe success of hybrid NLP systems has demon-strated that complex linguistic phenomena andtasks can be successfully addressed using a com-bination of techniques.
At the same time, it isclear from the NLP literature, that the perfor-mance of any specific technique is highly depen-dent on the characteristics of the data.
Thus, aspecific technique which performs well on onedataset might perform very differently on another,even on similar tasks, and even if the two datasetsare taken from the same domain.
Also, it is possi-ble that the properties affecting the effectivenessof a particular technique may vary within a singledocument (De Roeck, 2007).As a result of this, for many important NLPapplications there is no single technique whichis clearly to be preferred.
For example, recentapproaches to the task of anaphora resolutioninclude syntactic analyses (Haghighi and Klein,2009), Maximum Entropy models (Charniak andElsner, 2009) and Support Vector Machines (Yanget al, 2006; Versley et al, 2008).
The perfor-mance of each of these techniques varies depend-ing upon the particular choice of training and testdata.This state of affairs provides a particular op-portunity for hybrid system development.
Theoverall performance of an NLP system dependson complex interactions between the various phe-nomena exhibited by the text under analysis, andthe success of a given technique can be sensitiveto the different properties of that text.
In partic-ular, the text?s or document?s properties are notgenerally known until the document comes to beanalysed.
Therefore, there is a need for systemswhich are able to adapt to different text styles atthe point of analysis, and select the most appropri-ate combination of techniques for the individualcases.
This should lead to hybridising techniqueswhich are robust or adaptive in the face of varyingtextual styles and properties.We present a generalisation of two hybridi-sation techniques first described in Yang et al(2012) and Chantree et al (2006).
Each useshybrid techniques in a detection task: the first isemotion detection from suicide notes, the secondis detecting nocuous ambiguity in requirementsdocuments.
The distinguishing characteristic ofboth tasks is that a successful solution needs toaccommodate uncertainty in the outcome.
Thegeneralised methodology described here is partic-ularly suited to such tasks, where as well as se-lecting between possible solutions, there is a needto identify a class of instances where no single so-lution is most appropriate.972 Hybridisation as a Solution toClassification TasksThe methodology described in this paper pro-poses hybrid systems as a solution to NLP taskswhich attempt to determine an appropriate inter-pretation from a set of discrete alternatives, in par-ticular where no one outcome is clearly prefer-able.
One such task is nocuous ambiguity detec-tion.
For example, in sentence (1), the pronoun hecould refer to Bill, John or to John?s father.
(1) When Bill met John?s father, he was pleased.Here, there are three possible antecedents for he,and it does not follow that all human readerswould agree on a common interpretation of theanaphor.
For example, readers might divide be-tween interpreting he as Bill or as John?s father.Or perhaps a majority of readers feel that thesentence is sufficiently ambiguous that they can-not decide on the intended interpretation.
Theseare cases of nocuous ambiguity (Chantree et al,2006), where a group of readers do not interpret apiece of text in the same way, and may be unawarethat the misunderstanding has even arisen.Similarly, as a classification task, sentimentanalysis for sentences or fragments may needto accommodate instances where multiple senti-ments can be identified, or possibly none at all.Example (2) contains evidence of both guilt andlove:(2) Darling wife, ?
I?m sorry for everything.Hybrid solutions are particularly suited to suchtasks, in contrast to approaches which use a singletechnique to select between possible alternatives.The hybrid methodology proposed in this paperapproaches such tasks in two stages:1.
Define and apply a set of heuristics, whereeach heuristic captures an aspect of the phe-nomenon and estimates the likelihood of aparticular interpretation.2.
Apply a combination function to either com-bine or select between the values contributedby the individual heuristics to obtain betteroverall system performance.The model makes certain assumptions aboutthe design of heuristics.
They can draw on a mul-titude of techniques such as a set of selection fea-tures based on domain knowledge, linguistic anal-ysis and statistical models.
Each heuristic is apartial descriptor of an aspect of a particular phe-nomenon and is intended as an ?expert?, whoseopinion competes against the opinion offered byother heuristics.
Heuristics may or may not be in-dependent.
The crucial aspect is that each of theheuristics should seek to maximise precision orcomplement the performance of another heuristic.The purpose of step 2 is to maximise the contri-bution of each heuristic for optimal performanceof the overall system.
Experimental results anal-ysed below show that selecting an appropriatemode of combination helps accommodate dif-ferences between datasets and can introduce ad-ditional robustness to the overall system.
Theexperimental results also show that appropriatecombination of the contribution of high precisionheuristics significantly increases recall.For the tasks under investigation here, it provespossible to select combination functions that al-low the system to identify behaviour beyond clas-sifying the subject text into a single category.
Be-cause the individual heuristics are partial descrip-tions of the whole language model of the text, itis possible to reason about the interaction of thesepartial descriptions, and identify cases where ei-ther none, or many, of the potential interpretationsof the text are possible.
The systems use either amachine learning technique or a voting strategiesto combine the individual heuristics.In sections 3 and 4, we explore how the pre-viously proposed solutions can be classed as in-stances of the proposed hybridisation model.3 Case study: Sentiment AnalysisFollowing Pang et al (2002) and the release of thepolarity 2.0 dataset, it is common for sentimentanalysis tasks to attempt to classify text segmentsas either of positive or negative sentiment.
Thetask has been extended to allow sentences to beannotated as displaying both positive and negativesentiment (Wilson et al, 2009) or indicating thedegree of intensity (Thelwall et al, 2010).The data set used for the 2011 i2b2 shared chal-lenge (Pestian et al, 2012) differs from this modelby containing a total of 15 different sentiments toclassify the sentences.
Each text fragment waslabelled with zero, one or more of the 15 senti-ments.
For example, sentence (2) was annotatedwith both Love and Guilt.
The fragments variedbetween phrases and full sentences, and the taskaims to identify all the sentiments displayed by98each text fragment.In fact, several of the proposed sentiments wereidentified using keyword recognition alone, so thehybrid framework was applied only to recognisethe sentiments Thankfulness, Love, Guilt, Hope-lessness, Information and Instruction; instancesof the other sentiments were too sparse to be reli-ably classified with the hybrid system.
A keywordcue list of 984 terms was manually constructedfrom the training data based on their frequency inthe annotated set; no other public emotion lexiconwas used.
This cue list was used both to recognisethe sparse sentiments, and as input to the CRF.3.1 ArchitectureAn overview of the architecture is shown in figure1.
Heuristics are used which operate at the wordlevel (Conditional Random Fields), and at thesentence level (Support Vector Machine, NaiveBayes and Maximum Entropy).
These are com-bined using a voting strategy that selects the mostappropriate combination of methods in each case.Inputtext?Preprocesstext?Negationdetection?
?Combinevalues?Token level Sentence levelclassifier classifiersCRF SVMNBMEFigure 1: Architecture for sentiment classification taskThe text is preprocessed using the tokeniser,POS tagger and chunker from the Genia tagger,and parsed using the Stanford dependency parser.This information, along with a negation recog-niser, is used to generate training vectors for theheuristics.
Negation is known to have a major ef-fect on sentiment interpretation (Jia et al, 2009).3.2 Sentiment recognition heuristicsThe system uses a total of four classifiers for eachof the emotions to be recognised.
The only token-level classification was carried out using CRFs(Lafferty et al, 2001) which have been success-fully used on Named Entity Recognition tasks.However, both token- and phrase-level recogni-tion are necessary to capture cases where sen-tences convey more than one sentiment.
TheCRF-based classifiers were trained to recogniseeach of the main emotions based on the main key-word cues and the surrounding context.
The CRFis trained on the set of features shown in figure 2,and implemented using CRF++1.Feature DescriptionWords word, lemma, POS tag, phrasechunk tagContext 2 previous words and 2 followingwords with lemma, POS tags andchunk tagsSyntax Dependency relation label andthe lemma of the governer wordin focusSemantics Is it negated?Figure 2: Features used for CRF classifierThree sentence-level classifiers were trainedfor each emotion, those being Naive Bayes andMaximum Entropy learners implemented by theMALLET toolkit2, and a Support Vector Machinemodel implemented using SVM light3 with thelinear kernel.
In each case, the learners weretrained using a feature vector using the two fea-ture vectors as shown in figure 3.Feature vector DescriptionWords word lemmasSemantics negation terms identified bythe negative term lexicon,and cue terms from the emo-tion term lexiconFigure 3: Features used for sentence-level classifiersA classifier was built for each of the main emo-tions under study.
For each of the six emotions,four learners were trained to identify whether thetext contains an instance of that emotion.
That is,an instance of text receives 6 groups of results,and each group contains 4 results obtained fromdifferent classifiers estimating whether one par-ticular emotion occurs.
The combination func-tion predicts the final sentiment(s) exhibited bythe sentence.1http://crfpp.sourceforge.net/2http://mallet.cs.umass.edu/3http://svmlight.joachims.org/993.3 Combination functionTo combine the outputs of the heuristics, Yang etal.
(2012) use a voting model.
Three differentcombination methods are investigated:Any If a sentence is identified as an emotion in-stance by any one of the ML-based models, itis considered a true instance of that emotion.Majority If a sentence is identified as an emotioninstance by two or more of the ML-basedmodels, it is considered a true instance ofthat emotion.Combined If a sentence is identified as an emo-tion instance by two or more of the ML-based models or it is identified as an emo-tion instance by the ML-based model withthe best precision for that emotion, it is con-sidered a true instance of that emotion.This combined measure reflects the intuitionthat where an individual heuristic is reliable for aparticular phenomenon, then that heuristic?s voteshould be awarded a greater weight.
The preci-sion scores of the individual heuristics is shownin table 1, where the heuristic with the best preci-sion for that emotion is highlighted.Emotion CRF NB ME SVMThankfulness 60.6 58.8 57.6 52.6Love 76.2 68.5 77.6 76.9Guilt 58.1 46.8 35.3 58.3Hopelessness 73.5 63.3 68.7 74.5Information 53.1 41.0 48.1 76.2Instruction 76.3 63.6 70.9 75.9Table 1: Precision scores (%) for individual heuristics3.4 ResultsTable 2 reports the system performance on 6 emo-tions by both individual and combined heuristics.In each case, the best performer among the fourindividual heuristics is highlighted.
As can beseen from the table, the Any combinator and theCombined combinators both outperform each ofthe individual classifiers.
This supports the hy-pothesis that hybrid systems work better overall.3.5 Additional commentsThe overall performance improvement obtainedby combining the individual measures raises thequestion of how the individual elements interact.Table 3 shows the performance of the combinedsystems on the different emotion classes.
Foreach emotion, the highest precision, recall and f-measure is highlighted.As we would have expected, the Any strategyhas the highest recall in all cases, while the Major-ity strategy, with the highest bar for acceptance,has the highest precision for most cases.
TheAny and Combined measures appear to be broadlycomparable: for the measures we have used, it ap-pears that the precision of the individual classi-fiers is sufficiently high that the combination pro-cess of improving recall does not impact exces-sively on the overall precision.A further point of interest is that table 2 demon-strates that the Naive Bayes classifier often re-turns the highest f-score of the individual classi-fiers, even though it never has the best precision(table 1).
This supports our thesis that a success-ful hybrid system can be built from multiple clas-sifiers with high precision, rather than focussingon single classifiers which have the best individ-ual performance (the Combined strategy favoursthe highest precision heuristic).4 Nocuous ambiguity detectionIt is a cornerstone of NLP that all text containsa high number of potentially ambiguous words orconstructs.
Only some of those will lead to misun-derstandings, where two (or more) participants ina text-mediated interchange will interpret the textin different, and incompatible ways, without real-ising that this is the case.
This is defined as nocu-ous ambiguity (Willis et al, 2008), in contrast toinnocuous ambiguity, where the text is interpretedin the same way by different readers, even if thattext supports different possible analyses.The phenomenon of nocuous ambiguity is par-ticularly problematic in high stake situations.
Forexample, in software engineering, a failure toshare a common interpretation of requirementsstated in natural language may lead to incorrectsystem implementation and the attendant risk ofsystem failure, or higher maintenance costs.
Thesystems described by Chantree et al (2006) andYang et al (2010a) aim not to resolve ambigu-100Individual heuristics Hybrid modelsEmotion CRF NB ME SVM Any Majority CombinedThankfulness 59.5 59.6 61.9 60.3 63.9 63.0 64.2Love 63.7 69.3 66.5 61.5 72.0 70.3 71.0Guilt 35.3 40.5 27.7 37.8 46.3 29.9 45.8Hopelessness 63.2 64.1 59.9 57.0 67.3 65.4 67.3Information 42.3 47.7 43.7 43.4 50.2 45.5 47.8Instruction 65.7 65.7 63.4 58.8 72.1 65.4 72.0Table 2: F-scores (%) for individual and combined heuristics (sentiment analysis)Any Majority CombinedP R F P R F P R FThankfulness 52.6 81.6 63.9 60.6 65.7 63.0 55.0 77.1 64.2Love 68.7 75.6 72.0 77.9 64.0 70.3 74.6 67.7 71.0Guilt 46.6 46.2 46.3 50.0 21.4 29.9 50.5 41.9 45.8Hopelessness 64.1 70.8 67.3 80.3 55.2 65.4 66.3 68.4 67.3Information 40.9 64.9 50.2 49.9 41.8 45.5 45.2 50.7 47.8Instruction 68.5 76.1 72.1 80.8 54.9 65.4 70.3 73.7 72.0Table 3: Precision, recall and F-scores (%) for the combined systems (sentiment analysis)ous text in requirements, but to identify where in-stances of text might display nocuous ambiguity.These systems demonstrate how, for hybridsystems, the correct choice of combination func-tion is crucial to how the individual heuristicswork together to optimise overall system perfor-mance.4.1 Nocuous Ambiguity: CoordinationChantree et al (2006) focus on coordination at-tachment ambiguity, which occurs when a mod-ifier can attach to one or more conjuncts of acoordinated phrase.
For example, in sentence(3), readers may divide over whether the modi-fier short attaches to both books and papers (widescope), or only to books (narrow scope).
(3) I read some short books and papers.In each case, the coordination involves a nearconjunct, (books in (3)), a far conjunct, (papers)and a modifier (short).
The modifier might alsobe a PP, or an adverb in the case where a VP con-tains the conjunction.
In disambiguation, the taskwould be to identify the correct scope of the mod-ifier (i.e.
which of two possible bracketings is thecorrect one).
For nocuous ambiguity detection,the task is to identify to what extent people inter-pret the text in the same way, and to flag the in-stance as nocuous if they diverge relative to somethreshold.4.1.1 The dataset17 human judgements were collected for eachof 138 instances of sentences exhibiting coor-dination ambiguity drawn from a collection ofsoftware requirements documents.
The majorityof cases (118 instances) were noun compounds,with some adjective and some preposition modi-fiers (36 and 18 instances respectively).
Partici-pants were asked to choose between wide scopeor narrow scope modifier attachment, or to indi-cate that they experienced the example as ambigu-ous.
Each instance is assigned a certainty for wideand narrow scope modification reflecting the dis-tribution of judgements.
For instance, if 12 judgesfavoured wide scope for some instance, 3 judgesfavoured narrow scope and 1 judge thought theinstance ambiguous, then the certainty for widescope is 71% (12/17), and the certainty for nar-row scope is 18% (3/17).A key concept in nocuous ambiguity is that ofan ambiguity threshold, ?
.
For some ?
:?
if at least ?
judges agree on the interpretation101of the text, then the ambiguity is innocuous,?
otherwise the ambiguity is nocuous.So for ?
= 70%, at least 70% of the judges mustagree on an interpretation.
Clearly, the higher ?is set, the more agreement is required, and thegreater the number of examples which will beconsidered nocuous.4.1.2 Selectional heuristicsA series of heuristics was developed, each cap-turing information that would lead to a preferencefor either wide or narrow scope modifier attach-ment.
Examples from Chantree et al (2006) pro-pose seven heuristics, including the following:Co-ordination Matching If the head wordsof the two conjuncts are frequently co-ordinated, this is taken to predict widemodifier scope.Distributional Similarity If the head words ofthe two conjuncts have high distributionalsimilarity (Lee, 1999), this is taken to pre-dict wide modifier scope.Collocation Frequency If the head word of thenear conjunct has a higher collocation withthe modifier than the far conjunct, this istaken to predict narrow modifier scope.Morphology If the conjunct headwords havesimilar morphological markers, this is takento predict wide modifier scope (Okumuraand Muraki, 1994).As with the sentiment recognition heuristics(section 3.2), each predicts one interpretation ofthe sentence with high precision, but potentiallylow recall.
Recall of the system is improved bycombining the heuristics, as described in the nextsection.
Note that for the first three of theseheuristics, Chantree et al (2006) use the BritishNational Corpus4, accessed via the Sketch Engine(Kilgarriff et al, 2004), although a domain spe-cific corpus could potentially be constructed.4.1.3 Combining the heuristicsChantree et al (2006) combine the heuristicsusing the logistic regression algorithms containedin the WEKA machine learning package (Wittenand Frank, 2005).
The regression algorithm was4http://www.natcorp.ox.ac.uk/trained against the training data so that the textwas interpreted as nocuous either if there was ev-idence for both wide and narrow modifier scopeor if there was no evidence for either.This system performed reasonably for mid-range ambiguity thresholds (around 50% < ?
<80%; for high and low thresholds, naive base-lines give very high accuracy).
However, in sub-sequent work, Yang et al (2010b) have demon-strated that by combining the results in a similarway, but using the LogitBoost algorithm, signifi-cant improvements can be gained over the logis-tic regression approach.
Their paper suggests thatLogitBoost provides an improvement in accuracyof up to 21% in the range of interest for ?
overthat of logistic regression.We believe that this improvement reflects thatLogitBoost handles interacting variables betterthan logistic regression, which assumes a linearrelationship between individual variables.
Thissupports our hybridisation method, which as-sumes that the individual heuristics can interact.In these cases, the heuristics bring into play dif-ferent types of information (some structural, somedistributional, some morphological) where eachrelies on partial information and favours one par-ticular outcome over another.
It would be unusualto find strong evidence of both wide and narrowscope modifier attachment from a single heuristicand the effect of one heuristic can modulate, orenhance the effect of another.
This is supported byChantree et al?s (2006) observation that althoughsome of the proposed heuristics (such as the mor-phology heuristic) perform poorly on their own,their inclusion in the regression model does im-prove the overall performance of the systemTo conclude, comparing the results of Chantreeet al (2006) and Yang et al (2010b) demonstratesthat the technique of combining individual, highprecision heuristics is a successful one.
However,the combination function needs careful consider-ation, and can have as large an effect on the finalresults as the choice of the heuristics themselves.4.2 Nocuous Ambiguity: AnaphoraAs example (1) demonstrates, nocuous ambigu-ity can occur where there are multiple possibleantecedents for an anaphor.
Yang et al (2010a)have addressed the task of nocuous ambiguity de-tection for anaphora in requirements documents,in sentences such as (4), where the pronoun it has102three potential antecedents (italicised).
(4) The procedure shall convert the 24 bit imageto an 8 bit image, then display it in a dynamicwindow.As with the coordination task, the aim is toidentify nocuous ambiguity, rather than attempt todisambiguate the sentence.4.2.1 The datasetThe data set used for the anaphora task con-sisted of 200 sentences collected from require-ments documents which contained a third personpronoun and multiple possible antecedents.
Eachinstance was judged by at least 13 people.The concept of ambiguity threshold, ?
, remainscentral to nocuous ambiguity for anaphora.
Thedefinition remains the same as in section 4.1.1, sothat an anaphor displays innocuous ambiguity ifthere is an antecedent that at least ?
judges agreeon, and nocuous ambiguity otherwise.
So if, say,75% of the judges considered an 8 bit image tobe the correct antecedent in (4), then the sentencewould display nocuous ambiguity at ?
= 80%,but innocuous ambiguity at ?
= 70%.For innocuous cases, the potential antecedentNP with certainty of at least ?
is tagged as Y,and all other NPs are tagged as N. For nocuouscases, potential antecedents with ?
greater than 0are tagged as Q (questionable), or are tagged Notherwise (?
= 0, ie.
unselected).4.2.2 Selectional HeuristicsThe approach to this task uses only one selec-tion function (Naive Bayes), but uses the outputto support two different voting strategies.
Twelveheuristics (described fully in Yang et al (2010a))fall broadly into three types which signal the like-lihood that the NP is a possible antecedent:linguistic such as whether the potential an-tecedent is a definite or indefinite NPcontextual such as the potential antecedent?s re-cency, andstatistical such as collocation frequencies.To treat a sentence, the classifier is applied toeach of the potential antecedents and assigns apair of values: the first is the predicted class ofthe antecedent (Y, N or Q), and the second is theassociated probability of that classification.Given a list of class assignments to potential an-tecedents with associated probabilities, a weakpositive threshold, WY , and a weak negativethreshold, WN :if the list of potential antecedents contains:one Y, no Q, one or more Norno Y, one Q, one or more N but no weaknegativesorone strong positive Y , any number of Q or Nthenthe ambiguity is INNOCUOUSelsethe ambiguity is NOCUOUSwhere a classification Y is strong positive if itsassociated probability is greater than WY , and aclassification N is weak negative if its associatedprobability is smaller than WN .Figure 4: Combination function for nocuous anaphoradetection with weak thresholds4.2.3 The combination functionAs suggested previously, the choice of com-bination function can strongly affect the systemperformance, even on the same set of selectionalheuristics.
Yang et al (2010a) demonstrate twodifferent combination functions which exploit theselectional heuristics in different ways.
Bothcombination functions use a voting strategy.The first voting strategy states that a sentenceexhibits innocuous ambiguity if either:?
there is a single antecedent labelled Y, and allothers are labelled N, or?
there is a single antecedent labelled Q, andall others are labelled N.The second strategy is more sophisticated, anddepends on the use of weak thresholds: intu-itively, the aim is to classify the text as innocu-ous if is (exactly) one clearly preferred antecedentamong the alternatives.
The combination functionis shown in figure 4.
The second clause statesthat a single potential antecedent labelled Q canbe enough to suggest innocuous ambiguity if allthe alternatives are N with a high probability.103Model without Model withweak thresholds weak thresholds?
P R F P R F0.50 27.2 55.0 45.7 24.1 95.0 59.70.60 33.9 67.5 56.3 30.9 97.5 68.10.70 45.1 76.2 66.9 43.9 98.4 78.80.80 58.0 85.0 77.7 56.1 97.9 85.50.90 69.1 88.6 83.9 67.4 98.4 90.11.0 82.2 95.0 92.1 82.0 99.4 95.3Table 4: Precision, Recall and f-measure (%) for thetwo combination functions (anaphora)Task SelectionalheuristicsCombinationfunctionsSentiment CRF Votinganalysis NB - anySVM - majorityME - combinedNocuous 3 distributional logisticambiguity metrics regression(coordin-ation) 4 others LogitBoostNocuous NB Votingambiguity(anaphora) Voting(+ threshold)Table 5: Hybridisation approaches usedThe performance of the two voting strategiesis shown in table 4.
It is clear that the improvedoverall performance of the strategy with weakthresholds is due to the improved recall when thefunctions are combined; the precision is compa-rable in both cases.
Again, this shows the desiredcombinatorial behaviour; a combination of highprecision heuristics can yield good overall results.5 ConclusionThe hybridised systems we have considered aresummarised in table 5.
This examination suggeststhat hybridisation can be a powerful technique forclassifying linguistic phenomena.
However, thereis currently little guidance on principles regardinghybrid system design.
The studies here show thatthere is room for more systematic study of the de-sign principles underlying hybridisation, and forinvestigating systematic methodologies.This small scale study suggests several prin-ciples.
First, the sentiment analysis study hasshown that a set of heuristics and a suitable com-bination function can outperform the best individ-ually performing heuristic or technique.
In partic-ular, our results suggest that hybrid systems of thekind described here are most valuable when thereis significant interaction between the various lin-guistic phenomena present in the text.
This occursboth with nocuous ambiguity (where competitionbetween the different interpretations creates dis-agreement overall), and with sentiment analysis(where a sentence can convey multiple emotions).As a result, hybridisation is particularly power-ful where there are multiple competing factors, orwhere it is unclear whether there is sufficient evi-dence for a particular classification.Second, successful hybrid systems can be builtusing multiple heuristics, even if each of theheuristics has low recall on its own.
Our casestudies show that with the correct choice of hy-bridisation functions, high precision heuristicscan be combined to give good overall recall whilemaintaining acceptable overall precision.Finally, the mode of combination matters.
Thevoting system is successful in the sentiment anal-ysis task, where different outcomes are not exclu-sive (the presence of guilt does not preclude thepresence of love).
On the other hand, the log-itBoost combinator is appropriate when the dif-ferent interpretations are exclusive (narrow modi-fier scope does preclude wide scope).
Here, logit-Boost can be interpreted as conveying the degreeof uncertainty among the alternatives.
The coor-dination ambiguity case demonstrates that the in-dividual heuristics do not need to be independent,but if the method of combining them assumes in-dependence, the benefits of hybridisation will belost (logistic regression compared to LogitBoost).This analysis has highlighted the interplay be-tween task, heuristics and combinator.
Currently,the nature of this interplay is not well understood,and we believe that there is scope for investigatingthe broader range of hybrid systems that might beapplied to different tasks.AcknowledgmentsThe authors would like to thank the UK Engi-neering and Physical Sciences Research Coun-cil who funded this work through the MaTRExproject (EP/F068859/1), and the anonymous re-viewers for helpful comments and suggestions.104ReferencesFrancis Chantree, Bashar Nuseibeh, Anne De Roeck,and Alistair Willis.
2006.
Identifying nocuousambiguities in natural language requirements.
InProceedings of 14th IEEE International Require-ments Engineering conference (RE?06), Minneapo-lis/St Paul, Minnesota, USA, September.Eugene Charniak and Micha Elsner.
2009.
EM worksfor pronoun anaphora resolution.
In Proceedings ofthe 12th Conference of the European Chapter of theAssociation for Computational Linguistics (EACL?09), pages 148?156.Anne De Roeck.
2007.
The role of data in NLP:The case for dataset profiling.
In Nicolas Nicolov,Ruslan Mitkov, and Galia Angelova, editors, Re-cent Advances in Natural Language Processing IV,volume 292 of Current Issues in Linguistic Theory,pages 259?266.
John Benjamin Publishing Com-pany, Amsterdam.Aria Haghighi and Dan Klein.
2009.
Simple coref-erence resolution with rich syntactic and semanticfeatures.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing, pages 1152?1161, Singapore, August.Lifeng Jia, Clement Yu, and Weiyi Meng.
2009.The effect of negation on sentiment analysis andretrieval effectiveness.
In The 18th ACM Confer-ence on Information and Knowledge Management(CIKM?09), Hong Kong, China, November.Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and DavidTugwell.
2004.
The sketch engine.
Technical Re-port ITRI-04-08, University of Brighton.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of the InternationalConference on Machine Learning (ICML-2001),pages 282?289.Lillian Lee.
1999.
Measures of distributional simi-larity.
In Proceedings of the 37th Annual Meetingof the Association for Computational Linguistics,pages 25?32, College Park, Maryland, USA, June.Association for Computational Linguistics.Akitoshi Okumura and Kazunori Muraki.
1994.
Sym-metric pattern matching analysis for english coor-dinate structures.
In Proceedings of the 4th Con-ference on Applied Natural Language Processing,pages 41?46.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 79?86, Philadelphia, July.John P. Pestian, Pawel Matykiewicz, Michelle Linn-Gust, Brett South, Ozlem Uzuner, Jan Wiebe,K.
Bretonnel Cohen, John Hurdle, and ChristopherBrew.
2012.
Sentiment analysis of suicide notes:A shared task.
Biomedical Informatics Insights,5(Suppl 1):3?16.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,Di Cai, and Arvid Kappas.
2010.
Sentiment inshort strength detection informal text.
Journal ofthe American Society for Information Science &Technology, 61(12):2544?2558, December.Yannick Versley, Alessandro Moschitti, Massimo Poe-sio, and Xiaofeng Yang.
2008.
Coreference sys-tems based on kernels methods.
In Proceedingsof the 22nd International Conference on Compu-tational Linguistics (Coling 2008), pages 961?968,Manchester, August.Alistair Willis, Francis Chantree, and Anne DeRoeck.2008.
Automatic identification of nocuous ambigu-ity.
Research on Language and Computation, 6(3-4):355?374, December.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2009.
Recognizing contextual polarity: An explo-ration of features for phrase-level sentiment analy-sis.
Computational Linguistics, 35(3):399?433.Ian H. Witten and Eibe Frank.
2005.
Data mining:Practical machine learning tools and techniques.Morgan Kaufmann, 2nd edition.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2006.Kernel-based pronoun resolution with structuredsyntactic knowledge.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and 44th Annual Meeting of the ACL, pages 41?48, Sydney, July.Hui Yang, Anne De Roeck, Vincenzo Gervasi, Al-istair Willis, and Bashar Nuseibeh.
2010a.
Ex-tending nocuous ambiguity analysis for anaphorain natural language requirements.
In 18th Interna-tional IEEE Requirements Engineering Conference(RE?10), Sydney, Australia, Oct.Hui Yang, Anne De Roeck, Alistair Willis, and BasharNuseibeh.
2010b.
A methodology for automaticidentification of nocuous ambiguity.
In 23rd Inter-national Conference on Computational Linguistics(COLING 2010), Beijing, China.Hui Yang, Alistair Willis, Anne De Roeck, and BasharNuseibeh.
2012.
A hybrid model for automaticemotion recognition in suicide notes.
BiomedicalInformatics Insights, 5(Suppl.
1):17?30, January.105
