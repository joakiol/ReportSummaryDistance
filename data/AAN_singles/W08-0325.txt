Proceedings of the Third Workshop on Statistical Machine Translation, pages 167?170,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsTectoMT: Highly Modular MT Systemwith Tectogrammatics Used as Transfer Layer?Zdene?k Z?abokrtsky?, Jan Pta?c?ek, Petr PajasInstitute of Formal and Applied LinguisticsCharles University, Prague, Czech Republic{zabokrtsky,ptacek,pajas}@ufal.mff.cuni.czAbstractWe present a new English?Czech machinetranslation system combining linguisticallymotivated layers of language description (asdefined in the Prague Dependency Treebankannotation scenario) with statistical NLP ap-proaches.1 IntroductionWe describe a new MT system (called Tec-toMT) based on the conventional analysis-transfer-synthesis architecture.
We use the layers of languagedescription defined in the Prague Dependency Tree-bank 2.0 (PDT for short, (Hajic?
and others, 2006)),namely (1) word layer ?
raw text, no linguisticannotation, (2) morphological layer ?
sequence oftagged and lemmatized tokens, (3) analytical layer?
each sentence represented as a surface-syntacticdependency tree, and (4) tectogrammatical layer ?each sentence represented as a deep-syntactic de-pendency tree in which only autosemantic words dohave nodes of their own; prefixes w-, m-, a-, or t-will be used for denoting these layers.1We use ?Praguian?
tectogrammatics (introducedin (Sgall, 1967)) as the transfer layer becausewe believe that, first, it largely abstracts fromlanguage-specific (inflection, agglutination, func-tional words.
.
. )
means of expressing non-lexical?The research reported in this paper is financially supportedby grants GAAV C?R 1ET101120503 and MSM0021620838.1In addition, we use also p-layer (phrase structures) as ana-layer alternative, the only reason for which is that we do nothave a working a-layer parser for English at this moment.meanings, second, it allows for a natural transferfactorization, and third, local tree contexts in t-treescarry more information (esp.
for lexical choice) thanlocal linear contexts in the original sentences.In order to facilitate separating the transfer of lex-icalization from the transfer of syntactization, we in-troduce the concept of formeme.
Each t-node?s hasa formeme attribute capturing which morphosyntac-tic form has been (in the case of analysis) or willbe (synthesis) used for the t-node in the surface sen-tence shape.
Here are some examples of formemeswe use for English: n:subj (semantic noun (sn) insubject position), n:for+X (sn with preposition for),n:X+ago (sn with postposition ago), n:poss (posses-sive form of sn), v:because+fin (semantic verb (sv)as a subordinating finite clause introduced by be-cause), v:without+ger (sv as a gerund after without),adj:attr (semantic adjective (sa) in attributive posi-tion), adj:compl (sa in complement position).The presented system intensively uses the PDTtechnology (data formats, software tools).
Specialattention is paid to modularity: the translation is im-plemented (in Perl) as a long sequence of processingmodules (called blocks) with relatively tiny, well-defined tasks, so that each module is independentlytestable, improvable, or substitutable.
TectoMT al-lows to easily combine blocks based on differentapproaches, from blocks using complex probabilis-tic solutions (e.g., B2, B6, B35, see the next section),through blocks applying simpler Machine Learningtechniques (e.g., B69) or empirically based heuris-tics (e.g., B7, B25, B36, B71), to blocks implementing?crisp?
linguistic rules (e.g., B48-B51, B59).
There arealso blocks for trivial technical tasks (e.g., B33, B72).167English m-layerSheshe PRP hashave VBZ nevernever RB laughedlaugh VBN inin IN herher PRP$ newnew JJ bossboss NN 's's POS officeoffice NN .. .NPBShe hasEnglish p-layerSADVPneverVPlaughedinVPher newPPNPBboss 'sNPBoffice .English a-layerShe has neverlaughedinher newboss'soffice.English t-layer#PersPronn:subj neveradv:laughv:fin#PersPronn:poss newadj:attrbossn:possofficen:in+XCzech t-layer#PersPronn:1 nikdyadv:sm?t_sev:fin ?
?adn:v+6#PersPronadj:attr nov?adj:attr?
?fn:2Czech a-layerNikdyD........1A...
seP7nesm?laVpFS...3..NA..vR??aduN.IS6.....A...sv?hoP8MS2.........
nov?hoAAMS2....1A...?
?faN.MS2.....A....ZFigure 1: MT ?pyramid?
as implemented in TectoMT.
All the representations are rooted with artificial nodes, servingonly as labels.
Virtually, the pyramid is bottomed with the input sentence on the source side (She has never laughed inher new boss?s office.)
and its automatic translation on the target side (Nikdy se nesma?la v u?r?adu sve?ho nove?ho s?e?fa.
).2 Translation ProcedureThe structure of this section directly renders the se-quence of blocks currently used for English-Czechtranslation in TectoMT.
The intermediate stages ofthe translation process are illustrated in Figure 1;identifiers of the blocks affecting on the translationof the sample sentence are typeset in bold.2.1 From English w-layer to English m-layerB1: Segment the source English text into sentences.B2: Split the sentences into sequences of tokens,roughly according to Penn Treebank (PTB for short;(Marcus et al, 1994)) conventions.
B3: Tag thetokens with PTB-style POS tags using a tagger(Brants, 2000).
B4: Fix some tagging errors sys-tematically made by the tagger using a rule-basedcorrector.
B5: Lemmatize the tokens using morpha,(Minnen et al, 2000).2.2 From English m-layer to English p-layerB6: Build PTB-style phrase-structure tree for eachsentence using a parser (Collins, 1999).2.3 From English p-layer to English a-layerB7: In each phrase, mark the head node (using a setof heuristic rules).
B8: Convert phrase-structure treesto a-trees.
B9: Apply some heuristic rules to fix ap-position constructions.
B10: Apply another heuris-tic rules for reattaching incorrectly positioned nodes.B11: Unify the way in which multiword prepositions(such as because of ) and subordinating conjunctions(such as provided that) are treated.
B12: Assign an-alytical functions (only if necessary for a correcttreatment of coordination/apposition constructions).2.4 From English a-layer to English t-layerB13: Mark a-nodes which are auxiliary (such asprepositions, subordinating conjunctions, auxiliaryverbs, selected types of particles, etc.)
B14: Mark notas an auxiliary node too (but only if it is connected toa verb form).
B15: Build t-trees.
Each a-node clusterformed by an autosemantic node and possibly sev-eral associated auxiliary nodes is ?collapsed?
into asingle t-node.
T-tree dependency edges are derivedfrom a-tree edges connecting the a-node clusters.B16: Explicitely distinguish t-nodes that are mem-bers of coordination (conjuncts) from shared modi-fiers.
It is necessary as they all are attached belowthe coordination conjunction t-node.
B17: Modifyt-lemmas in specific cases.
E.g., all kinds of per-sonal pronouns are represented by the ?artificial?
t-lemma #PersPron.
B18: Assign functors that are nec-essary for proper treatment of coordination and ap-position constructions.
B19: Distribute shared auxil-iary words in coordination constructions.
B20: Markt-nodes that are roots of t-subtrees corresponding tofinite verb clauses.
B21: Mark passive verb forms.B22: Assign (a subset of) functors.
B23: Mark t-nodescorresponding to infinitive verbs.
B24: Mark t-nodeswhich are roots of t-subtrees corresponding to rel-ative clauses.
B25: Identify coreference links be-tween relative pronouns (or other relative pronom-inal word) and their nominal antecedents.
B26: Mark168t-nodes that are the roots of t-subtrees correspond-ing to direct speeches.
B27: Mark t-nodes that arethe roots of t-subtrees corresponding to parenthe-sized expressions.
B28: Fill the nodetype attribute(rough classification of t-nodes).
B29: Fill the sem-pos attribute (fine-grained classification of t-nodes).B30: Fill the grammateme attributes (semantically in-dispensable morphological categories, such as num-ber for nouns, tense for verbs).
B31: Determine theformeme of each t-node.
B32: Mark personal names,distinguish male and female first names if possible.2.5 From English t-layer to Czech t-layerB33: Initiate the target-side t-trees, simply by cloningthe source-side t-trees.
B34: In each t-node, trans-late its formeme.2 B35: Translate t-lemma in eacht-node as its most probable target-language counter-part (which is compliant with the previously chosenformeme), according to a probabilistic dictionary.3B36: Apply manual rules for fixing the formeme andlexeme choices, which are otherwise systematicallywrong and are reasonably frequent.
B37: Fill the gen-der grammateme in t-nodes corresponding to deno-tative nouns (it follows from the chosen t-lemma).4B38: Fill the aspect grammateme in t-nodes corre-sponding to verbs.
Information about aspect (perfec-tive/imperfective) is necessary for making decisionsabout forming complex future tense in Czech.
B39:Apply rule-based correction of translated date/timeexpressions (several templates such as 1970?s, July1, etc.).
B40: Fix grammateme values in places wherethe English-Czech grammateme correspondence isnot trivial (e.g., if an English gerund expressionis translated using Czech subordinating clause, the2The translation mapping from English formemes to Czechformemes was obtained as follows: we analyzed 10,000 sen-tence pairs from the WMT?08 training data up to the t-layer(using a tagger shipped with the PDT and parser (McDonald etal., 2005) for Czech), added formemes to t-trees on both sides,aligned the t-trees (using a set of weighted heuristic rules, simi-larly to (Menezes and Richardson, 2001)), and from the alignedt-node pairs extracted for each English formeme its most fre-quent Czech counterpart.3The dictionary was created by merging the translation dic-tionary from PCEDT ((Cur??
?n and others, 2004)) and a trans-lation dictionary extracted from a part of the parallel corpusCzeng ((Bojar and Z?abokrtsky?, 2006)) aligned at word-level byGiza++ ((Och and Ney, 2003)).4Czech nouns have grammatical gender which is (amongothers) important for resolving grammatical agreement.tense grammateme has to be filled).
B41: Negateverb forms where some arguments of the verbs bearnegative meaning (double negation in Czech).
B42:Verb t-nodes in active voice that have transitive t-lemma and no accusative object, are turned to re-flexives.
B43: The t-nodes with genitive formemeor prepositional-group formeme, whose counterpartEnglish t-nodes are located in pre-modification po-sition, are moved to post-modification position.
B44:Reverse the dependency orientation between nu-meric expressions and counted nouns, if the valueof the numeric expression is greater than four andthe noun without the numeral would be expressed innominative or accusative case.
B45: Find coreferencelinks from personal pronouns to their antecedents,if the latter are in subject position (needed later forreflexivization).2.6 From Czech t-layer to Czech a-layerB46: Create initial a-trees by cloning t-trees.
B47:Fill the surface morphological categories (gender,number, case, negation, etc.)
with values derivedfrom values of grammatemes, formeme, seman-tic part of speech etc.
B48: Propagate the valuesof gender and number of relative pronouns fromtheir antecedents (along the coreference links).
B49:Propagate the values of gender, number and personaccording to the subject-predicate agreement (i.e.,from subjects to the finite verbs).
B50: Resolve agree-ment of adjectivals in attributive positions (copyinggender/number/case from their governing nouns).B51: Resolve complement agreement (copying gen-der/number from subject to adjectival complement).B52: Apply pro-drop ?
deletion of personal pronounsin subject positions.
B53: Add preposition a-nodes(if implied by the t-node?s formeme).
B54: Add a-nodes for subordinating conjunction (if implied bythe t-node?s formeme).
B55: Add a-nodes corre-sponding to reflexive particles for reflexiva tantumverbs.
B56: Add an a-node representing the auxiliaryverb by?t (to be) in the case of compound passiveverb forms.
B57: Add a-nodes representing modalverbs, accordingly to the deontic modality gram-mateme.
B58: Add the auxiliary verb by?t in imperfec-tive future-tense complex verb forms.
B59: Add verbforms such as by/bys/bychom expressing conditionalverb modality.
B60: Add auxiliary verb forms suchas jsem/jste in past-tense complex verb forms.
B61:169Partition a-trees into finite clauses (a-nodes belong-ing to the same clause are coindexed).
B62: In eachclause, a-nodes which represent clitics are moved tothe so called second position in the clause (accord-ing to Wackernagel?s law).
B63: Add a-nodes cor-responding to sentence-final punctuation mark.
B64:Add a-nodes corresponding to commas on bound-aries between governing and subordinated clauses.B65: Add a-nodes corresponding to commas in frontof conjunction ale and also commas in multiple co-ordinations.
B66: Add pairs of parenthesis a-nodes.B67: Choose morphological lemmas in a-nodes cor-responding to personal pronouns.
B68: Generatethe resulting word forms (derived from lemmas andtags) using Czech word form generator described in(Hajic?, 2004).
B69: Vocalize prepositions k, s, v, andz (accordingly to the prefix of the following word).B70: Capitalize the first word in each sentence as wellas in each direct speech.2.7 From Czech a-layer to Czech w-layerB71: Create the resulting sentences by flattening thea-trees.
Heuristic rules for proper spacing aroundpunctuation marks are used.
B72: Create the resultingtext by concatenating the resulting sentences.3 Final remarksWe believe that the potential contribution of tec-togrammatical layer of language representation forMT is the following: it abstracts from manylanguage-specific phenomena (which could reducethe notorious data-sparsity problem) and offers anatural factorization of the translation task (whichcould be useful for formulating independence as-sumptions when building probabilistic models).
Ofcourse, the question naturally arises whether theseproperties can ever outbalance the disadvantages, es-pecially cumulation and interference of errors madeon different layers, considerable technical complex-ity, and the need for detailed linguistic insight.
Inour opinion, this question still remains open.
Onone hand, the translation quality offered now by Tec-toMT is below the state-of-the-art system accordingto the preliminary evaluation of the WMT08 SharedTask.
But on the other hand, the potential of tec-togrammatics has not been used fully, and more-over there are still many components with only pilotheuristic implementation which increase the numberof translation errors and which can be relatively eas-ily substituted by corpus-based solutions.
In the nearfuture, we plan to focus especially on the transferblocks, which are currently based on the naive as-sumption of isomorphism of the source and targett-trees and which do not make use of the target lan-guage model, so far.ReferencesOndr?ej Bojar and Zdene?k Z?abokrtsky?.
2006.
CzEng:Czech-English Parallel Corpus, Release version 0.5.Prague Bulletin of Mathematical Linguistics, 86:59?62.Thorsten Brants.
2000.
TnT - A Statistical Part-of-Speech Tagger .
pages 224?231, Seattle.Michael Collins.
1999.
Head-driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania, Philadelphia.Jan Cur??
?n et al 2004.
Prague Czech - English Depen-dency Treebank, Version 1.0.
CD-ROM, LinguisticsData Consortium, LDC Catalog No.
: LDC2004T25,Philadelphia.Jan Hajic?
et al 2006.
Prague Dependency Treebank 2.0.CD-ROM, Linguistic Data Consortium, LDC CatalogNo.
: LDC2006T01, Philadelphia.Jan Hajic?.
2004.
Disambiguation of Rich Inflection ?Computational Morphology of Czech.
Charles Uni-versity ?
The Karolinum Press, Prague.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a Large AnnotatedCorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-Projective Dependency Pars-ing using Spanning Tree Algorithms.
In Proceedingsof HTL/EMNLP, pages 523?530, Vancouver, Canada.Arul Menezes and Stephen D. Richardson.
2001.
A best-first alignment algorithm for automatic extraction oftransfer mappings from bilingual corpora.
In Proceed-ings of the workshop on Data-driven methods in ma-chine translation, volume 14, pages 1?8.Guido Minnen, John Carroll, and Darren Pearce.
2000.Robust Applied Morphological Generation.
In Pro-ceedings of the 1st International Natural LanguageGeneration Conference, pages 201?208, Israel.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19?51.Petr Sgall.
1967.
Generativn??
popis jazyka a c?eska?
dek-linace.
Academia, Prague.170
