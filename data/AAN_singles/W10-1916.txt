Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 126?127,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsSemantic role labeling of gene regulation events: preliminary resultsRoser MoranteCLiPS - University of AntwerpPrinsstraat 13, B-2000 Antwerpen, BelgiumRoser.Morante@ua.ac.beAbstractThis abstract describes work in progresson semantic role labeling of gene regula-tion events.
We present preliminary resultsof a supervised semantic role labeler thathas been trained and tested on the GRECcorpus.1 IntroductionSemantic role labeling (SRL) is a natural languageprocessing task that consists of identifying the ar-guments of predicates within a sentence and as-signing a semantic role to them.
This task cansupport the extraction of relations from biomedi-cal texts.
Recent research has produced a rich va-riety of SRL systems to process general domaincorpora.
However, only a few systems have beendeveloped to process biomedical corpora (Tzong-Han Tsai et al 2007; Bethard et al, 2008).
Inthis abstract, we present preliminary results ofa new system that is trained on the GREC cor-pus (Thompson et al, 2009).The GREC corpus consists of 240 MEDLINEabstracts, in which gene regulation events havebeen annotated with different types of informa-tion, like the span of the event and of its argu-ments, and the semantic role of the arguments.Events can be verbs (58%) and nominalised verbs(42%).
The corpus is divided into two species-specific subcorpora: E. coli (167 abstracts, 2394events) and human (73 abstracts, 673 events).2 System descriptionWe perform two preprocessing steps.
First, weextract the text and parse it with the GDepparser (Sagae and Tsujii, 2007) and then we con-vert the corpus from xml into CoNLL format.
Ta-ble 1 shows a preprocessed sentence.
The sys-tem performs argument identification and seman-tic role assignment in a single step, assuming goldstandard event identification.
It consists of oneclassifier that classifies an instance into one of thesemantic role classes or the NONE class.
An in-stance represents a combination of an event and apotential argument (PA).
In order to generate thePAs, the system relies on information from thedependency syntax tree, which means that errorsin the syntactic tree influence directly the perfor-mance of the system.
We consider that the fol-lowing tokens or combinations of tokens can bePAs: main verbs, nouns, adjectives, pronouns andadverbs; main verbs, nouns, adjectives, pronounsand adverbs with their modifiers to the left in thestring of words; main verbs, nouns, adjectives,pronouns, adverbs, prepositions and relative pro-nouns with their modifiers to the left and to theright in the string of words.The features extracted to perform the classifica-tion task are the following:?
About the event and the PA: chain of words, lemmas,POS, and dependency labels of all the tokens; lemma, POSand dependency label of head token, first token and last token;lemma and POS of syntactic father of head; lemma, POS,and dependency label of previous and next three tokens inthe string of words; even type.?
About the dependency tree: feature indicating who is theancestor (event, PA, other); lemma, POS, and dependency la-bel of the first common ancestor of event and PA, if thereis one; chain of dependency labels and chain of POS fromevent to common ancestor, and from PA to common ances-tor, if there is one; chain of dependency labels and chain ofPOS from PA to event, if event is ancestor of PA; chain of de-pendency labels and chain of POS from event to PA, if PA isancestor of event; chain of dependency labels and POS fromevent to ROOT and from PA to ROOT.?
Normalised distance in number of tokens between eventan potential argument in the string of words.We use an IB1 memory?based algorithm as im-plemented in TiMBL (version 6.1.2) 1(Daelemanset al, 2009), a memory-based classifier based onthe k-nearest neighbor rule.
The IB1 algorithmwas parameterised by using Jeffrey divergence asthe similarity metric, gain ratio for feature weight-ing, using 5 k-nearest neighbors, and weighting1TiMBL: http://ilk.uvt.nl/timbl126# WORD LEMMA CHUNK POS DEP LABEL #E TYPE ROLES1 Lrp Lrp B-NP NN 2 SUB B-Agent B-Agent B-Agent2 binds bind B-VP VBZ 0 ROOT E1 GRE3 to to B-PP TO 2 VMOD4 two two B-NP CD 5 NMOD5 regions region I-NP NNS 3 PMOD6 in in B-PP IN 5 NMOD7 the the B-NP DT 10 NMOD B-Destination8 dadAX dadAX I-NP NN 10 NMOD I-Destination9 promoter promoter I-NP NN 10 NMOD I-Destination10 region region I-NP NN 6 PMOD I-Destination11 of of B-PP IN 10 NMOD12 Escherichia Escherichia B-NP FW 13 NMOD13 coli coli I-NP FW 11 PMOD14 to to B-VP TO 15 VMOD15 repress repress I-VP VB 13 NMOD E2 Gene Repression16 and and I-VP CC 15 VMOD17 activate activate I-VP VB 15 VMOD E3 Gene Activation18 transcription transcription B-NP NN 17 OBJ B-Theme B-Theme19 directly directly B-ADVP RB 17 VMOD B-Manner B-Manner20 .
.
O .
2 PTable 1: Sentence 1 from abstract 10216857 in E. coli corpus.
Column # contains the token number;WORD, the word; LEMMA to LABEL contain information provided by the GDEP parser; #E, the eventnumber; TYPE, the type of event, and ROLES contains columns with argument labels for each eventfollowing textual order, i.e., the first column corresponds to the first event in #E, the second column tothe second event, etc.the class vote of neighbors as a function of theirinverse distance.3 Preliminary resultsWe provide 5 fold cross-validation (CV) andcross-domain (CD) results in Table 2.
The CV re-sults are obtained by training and testing on dif-ferent partitions of the same corpus.
The CD re-sults are obtained by training on one corpus andtesting on the other.
Although we cannot directlycompare this results with results of other systemson exactly the same corpus, Sasaki et al (2008)report CV results on a corpus of 677 MEDLINEabstracts on E. Coli gene regulation events.
Theprecision achieved by their system is 49.00 andthe recall 18.60.
We consider that the results ofour system are encouraging to proceed with fur-ther research.Corpus Precision Recall F1E coli CV 59.72 32.29 41.92E coli CD 49.87 18.07 26.53Human CV 47.98 22.43 30.57Human CD 56.57 25.90 35.53Table 2: F1, precision and recall for argumentidentification and labeling.4 Future workFuture work will deal with incorporating domainspecific knowledge and with improving the ma-chine learning techniques.
We will experimentwith other algorithms, like Conditional RandomFields, which are well known sequence labelers.Additionally, we will implement also a constraintsatisfaction algorithm.AcknowledgmentsThis preliminary study was made possible throughfinancial support from the University of Antwerp(GOA project BIOGRAPH).ReferencesS.
Bethard, Z. Lu, J.H.
Martin, and L. Hunter.
2008.
Se-mantic role labeling for protein transport predicates.
BMCBioinformatics, 9:277.W.
Daelemans, J. Zavrel, K. Van der Sloot, and A.
Van denBosch.
2009.
TiMBL: Tilburg memory based learner, ver-sion 6.2, reference guide.
Technical Report Series 09-01,ILK, Tilburg, The Netherlands.K.
Sagae and J. Tsujii.
2007.
Dependency parsing and do-main adaptation with LR models and parser ensembles.
InProc.
of CoNLL 2007: Shared Task, pages 82?94, Prague,Czech Republic.Y.
Sasaki, P. Thompson, Ph.
Cotter, J. McNaught, and S. Ana-niadou.
2008.
Event frame extraction based on a generegulation corpus.
In Proc.
of Coling 2008, pages 761?768, Manchester, UK.P.
Thompson, S. A Igbal, J. McNaught, and S. Ananiadou.2009.
Construction of an annotated corpus to supportbiomedical information extraction.
BMC Bioinformatics,10:349.R.
Tzong-Han Tsai et al 2007.
BIOSMILE: A semantic rolelabeling system for biomedical verbs using a maximum-entropy model with automatically generated template fea-tures.
BMC Bioinformatics, 8:325.127
