OSU-2: Generating Referring Expressionswith a Maximum Entropy ClassifierEmily JamisonDepartment of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USAjamison@ling.osu.eduDennis MehayDepartment of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USAmehay@ling.osu.eduAbstractSelection of natural-sounding referring ex-pressions is useful in text generation and in-formation summarization (Kan et al, 2001).We use discourse-level feature predicates ina maximum entropy classifier (Berger et al,1996) with binary and n-class classification toselect referring expressions from a list.
Wefind that while mention-type n-class classifi-cation produces higher accuracy of type, bi-nary classification of individual referring ex-pressions helps to avoid use of awkward refer-ring expressions.1 IntroductionReferring expression generation is the task of insert-ing noun phrases that refer to a mentioned extra-linguistic entity into a text.
REG is helpful for taskssuch as text generation and information summariza-tion (Kan et al, 2001).2 Task DescriptionThe Referring Expressions Generation Chal-lenge (Belz and Gatt, 2008) includes a task basedon the GREC corpus, a collection of introductorytexts from Wikipedia that includes articles aboutcities, countries, rivers, people, and mountains.In this corpus, the main topic of each text (MSR)has been replaced with a list of possible referringexpressions (REs).
The objective of the task is toidentify the most appropriate referring expressionfrom the list for each mention of the MSR, giventhe surrounding text and annotated syntactic andsemantic information.3 PredicatesWe created 13 predicates, in addition to the six pred-icates available with the corpus.
All predicates canbe used with the binary classification method; onlynon-RE-level predicates can be used with the n-classclassification method.
Predicates describe: stringsimilarity of the RE and the title of the article, themention?s order in the article, distance between pre-vious mention and current mention, and detection ofa contrastive discourse entity in the text.14 Maximum Entropy ClassifierWe defined indicator feature functions for a numberof contextual predicates, each describing a pairing ofsome potential property of the syntactico-semanticand discourse context of a RE (a ?predicate?)
and alabel.
These feature functions fi were used to traina maximum entropy classifier (Berger et al, 1996)(Le, 2004) that assigns a probability to a RE re givencontext cx as follows:p(re | cx) = Z(cx) expn?i=1?ifi(cx, re)where Z(cx) is a normalizing sum and the ?i are theparameters (feature weights) learned.
Two classifi-cation systems were used: binary and n-class.
Withthe binary method, the classifier estimates the like-lihood of a possible referring expression?s correctinsertion into the text, and inserts the RE with thehighest ?yes?
probability.
With the n-class method,1More details at http://www.ling.ohio-state.edu/?jamison196Predicates Used Single CombinationsGREC predicates 40.40% 50.91%all predicates 50.30% 58.54%no contrasting entities 50.30% 59.30%all non-RE-level preds 44.82% 51.07%Table 1: Results with binary classification.Predicates Used Single Combinationsall non-RE-level preds 61.13% 62.50%Table 2: Results with n-class classification.the mention is classified according to type of refer-ring expression (proper name, common noun, pro-noun, empty) and a RE of the proper type is chosen.A predicate combinator was implemented to cre-ate pairs of predicates for the classifier.5 ResultsOur results are shown in tables 1 and 2; table 3shows further per-category results.
N-class classi-fication has a higher type accuracy than the binarymethod(single: 61.13% versus 44.82%).
Addedpredicates made a notable difference (single, orig-inal predicates: 40.40%; with added predicates:50.30%).
However, the predicates that detected con-trasting discourse entities proved not to be helpful(combinations: 59.30% declined to 58.54%).
Fi-nally, the predicate combinator improved all results(binary, all predicates: 50.30% to 58.54%).6 DiscussionThe n-class method does not evaluate characteristicsof each individual referring expression.
However,the accuracy measure is designed to judge appro-priateness of a referring expression based only onwhether its type is correct.
A typical high-accuracyn-class result is shown in example 1.System City Ctry Mnt River Ppleb-all 53.54 57.61 49.58 75.00 65.85b-nonRE 51.52 53.26 45.83 40.00 57.07n-nonRE 53.54 63.04 61.67 65.00 67.32Table 3: Challenge-submitted results by category.Example 1: AlbaniaThe Republic of Albania itself is aBalkan country in Southeastern Europe.Which itself borders Montenegro to thenorth, the Serbian province of Kosovo tothe northeast, the Republic of Macedoniain the east, and Greece in the south.In example 1, both mentions are matched with an REthat is the proper type (proper name and pronoun,respectively), yet the result is undesireable.A different example typical of the binary classifi-cation method is shown in example 2.Example 2: Alfred NobelAlfred Nobel was a Swedish chemist,engineer, innovator, armaments manufac-turer and the inventor of dynamite.
[...] Inhis last will, Alfred Nobel used his enor-mous fortune to institute the Nobel Prizes.In example 2, the use of predicates specific to eachRE besides the type causes use of the RE ?AlfredNobel?
as a subject, and the RE ?his?
as a posses-sive pronoun.
The text, if mildly repetitive, is stillcomprehensible.7 ConclusionIn this study, we used discourse-level predicates andbinary and n-class maximum entropy classifiers toselect referring expressions.
Eventually, we planto combine these two approaches, first selecting allREs of the appropriate type and then ranking them.ReferencesAnya Belz and Albert Gatt.
2008.
REGChallenge 2008: Participants Pack.http://www.nltg.brighton.ac.uk/research/reg08/.A.
L. Berger, S. D. Pietra, and V. D. Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistcs, 22(1):39?71.Min-Yen Kan, Kathleen R. McKeown, and Judith L. Kla-vans.
2001.
Applying natural language generation toindicative summarization.
EWNLG ?01: Proceedingsof the 8th European workshop on Natural LanguageGeneration.Zhang Le.
2004.
Maximum EntropyModeling Toolkit for Python and C++.http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.197
