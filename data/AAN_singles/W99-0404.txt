Multimedia Computer Technology and Performance-BasedLanguage Testing: A Demonstration of the Computerized OralProficiency Instrument (COPI)Valerie A. MALABONGACenter for Applied Linguistics4646 40 ~ Street, NWWashington, DC 20016valene@cal.orgDorry M. KENYONCenter for Applied Linguistics4646 40 .h Street, NWWashington, DC 20016dorry@cal.orgAbstractThe field of language testing has long ledthe way in integrative, performance-basedassessment.
However, the use of technologyin language testing has often meant limitingassessment options.
We believe computer-mediated language assessment can enrichopportunities for language learners todemonstrate what they are able to do withtheir second language.
In this paper, wedescribe the rationale and operation of theComputerized Oral Proficiency Instrument(COPI), a multimedia, computer-administered oral proficiency test.
While atpresent speech performances on the COPIare evaluated by trained raters using anational standard, the COPI affords anexcellent opportunity to investigate the useof Natural Language Processing forcomputer-assisted evaluation.IntroductionThe Computerized Oral Proficiency Instrument(COPI) is a multi-media, computer-administeredadaptation of the tape-mediated Simulated OralProficiency Interview (SOPI).
Both the SOPIand the COPI are oral proficiency tests based onthe Speaking Proficiency Guidelines of theAmerican Council on the Teaching of ForeignLanguages (ACTFL).
Oral proficiency tests likethe SOPI and COPI use simulated real life tasksto elicit speech ratable by the ACTFL Guidelines'criteria.
The purpose of the COPI is to use theadvantages of multi-media computer technologyto improve the SOPI by giving examinees morecontrol over various aspects of the testingsituation and increasing raters' efficiency inscoring the test.In this paper we primarily discuss the Spanishversion of the COPI, although an Arabic and aChinese version are also being prepared.
Thispaper provides the context for the COPI,discusses its rationale, its components and itsphases, and introduces the scoring program usedby raters who assess an examinee's peechperformances using the criteria of the ACTFLGuidelines.1.
Computer Technology in Performance-Based Assessments of Speaking AbilityTechnology has no doubt been a part oflanguage testing since 'before the invention ofthe pencil.
Electronic technology, through thephonograph record, reel-to-reel and later casettetape, and the compact disc, has enhanced theassessment of listening skills for decades.Computers allowed for the development ofcomputer-adaptive and computer-administeredtests in second languages.
Since June of 1998,the Educational Testing Service (ETS) hasadministered the Test of English as a ForeignLanguage (TOEFL) by computer in many partsof the world.
With almost one million test takersa year, the TOEFL is the world's largestlanguage test.
The use of computer technologyhas allowed ETS to introduce a new variety ofselected-response type items not easily presentedin paper and pencil format.
In addition, thecomputer-based TOEFL allows examinees theoption of word-processing a written essay, asopposed to writing it longhand.
Of all sectionsof the current TOEFL, only the essay can be16regarded as performance-based, since examineesprovide a demonstration of their linguisticabilities through producing a text.While some have argued that multiple-choicetests of listening comprehension can provide aproxy measure of speaking ability, speakingskills have traditionally been assessed throughsome type of performance-based assessment,typically a live face-to-face oral interviewprocedure.
The best known formal procedure isthe Oral Proficiency Interview (OPI).
The OPI isused by various government agencies involvedwith language training, including the ForeignService Institute, where it was originallydeveloped in the 1950s to assess the readiness ofUS personnel for functioning in overseesdiplomatic posts.
In US academia, the AmericanCouncil on the Teaching of Foreign Languages(ACTFL) has promulgated the OPI since theearly 1980s through professional developmentworkshops and tester training programs(Stansfield, 1996).In the mid-1980s, the Center for AppliedLinguistics (CAL) began a program of researchand development in using technology to elicitspeech samples from examinees that can beassessed following the same criteria used in theACTFL OPI.
The impetus for this program wasthe need to assess peaking skills of students ofless-commonly-taught-languages in instructionalprograms throughout the nation where there wasno trained OPI interviewer.
Performanceselicited by and recorded on tape could then besent to trained OPI testers for evaluation.
Theformat developed by CAL came to be known asthe Simulated Oral Proficiency Interview(SOPI).
High correlations (averaging .92) werefound between performances on the SOPI andthe OPI across a variety of languages (Stansfieldand Kenyon, 1992).
The testing format was alsofound to be useful in large-scale testingapplications where it was necessary to ensurethat all examinees received the same highquality test, and the SOPI format has been usedin or adapted for a variety of language testingprojects.
Other variations of the SOPI appeared,most notably the Video Oral CommunicationInstrument (VOCI), developed by the LanguageAcquisition Resource Center at San Diego StateUniversity.
The VOCI uses a video rather thanan audio tape and test booklet o elicit examineespeech performances.Based on its work with the SOPI, CAL iscurrently developing a format for a computer-administered assessment of oral proficiencyknown as the Computerized Oral ProficiencyInstrument (COPI).2.
Importance of National ProficiencyStandardsTape-mediated speaking tests existed prior to thedevelopment of the SOPI.
One example is theoriginal version of the Test of Spoken English(TSE), developed by ETS and used to assess theoral language skills (particularlycomprehensibility) of foreign teachingassistants.
There are now many tape-mediatedspeaking tests or portions of larger tests thatassess peaking skills through the use of a tape.Tests including tape-mediated speaking portionsinclude the Advanced Placement Exams inmodern languages and the PRAXIS examinationused by states to certify language teachers.
Themain difference between these tests and theSOPI and now the COPI, however, is that suchtests are assessed using criteria developedspecifically for the exam, whereas the SOPI isassessed using the A CTFL Speaking ProficiencyGuidelines (American Council on the Teachingof Foreign Languages, 1986, 1999), which existoutside the context of the assessment.The ACTFL Guidelines tand in a tradition oforal proficiency testing in the United States thatdates to the 1950s, when the then Secretary ofState called for the creation of criteria that couldbe used to identify the foreign languageproficiency of U.S. government employees(Stansfield, 1996).
The result was a 0-5 scale,ranging from "no knowledge" to "total mastery,"with a brief definition of proficiency associatedwith each point on the scale.
Since their originalcreation, the definitions have undergone anumber of revisions, but are still in use andknown today as the lnteragency LanguageRoundtable (ILR) Skill Level Descriptions.In the early 1980s, the government's definitionswere adapted and disseminated by ACTFL for17use in the nation's secondary schools andcolleges.
These definitions have come to beknown as the ACTFL Guidelines.
First publishedin a provisional version in 1982, they wererevised and published for large-scale use in 1986(American Council on the Teaching of ForeignLanguages, 1986).
While the Guidelines coverall four language skills, the Speaking ProficiencyGuidelines have been recently revised and re-published in 1999 (American Council on theTeaching of Foreign Languages, 1999).The ACTFL Guidelines define proficiency as"the ability to use the language ffectively andappropriately in real-life situations" (Buck,Byrnes, and Thompson, 1989, 1.1).
TheGuidelines posit four levels of proficiency:Novice, Intermediate, Advanced and Superior.The first three levels are further broken intothree sublevels: Low, Mid, and High.
Thus, theGuidelines define 10 levels of proficiency:Novice Low, Novice Mid, Novice High,Intermediate Low, Intermediate Mid,Intermediate High, Advanced Low, AdvancedMid, Advanced High, and Superior.The Guidelines define proficiency in terms ofthe global tasks or functions the speaker canhandle, the contexts in which he or she caneffectively communicate, the content aboutwhich the speaker can communicate, and theaccuracy with which he or she communicates.Accuracy is typically considered in terms of howwell the speaker is understood by his or herinterlocutors.Thus, unlike other technology-based speakingtests, the overriding oal of the SOPI and theCOPI is to use technology to provide a validsurrogate assessment to the face-to-face OPI.
Inother words, the performance must be ratableusing the criteria of the ACTFL Guidelines andan examinee should be assessed at the sameACTFL proficiency level using any technique.Because the ACTFL Guidelines have had amajor national impact and are so widely used inthe US in both academia nd government, wefeel that this is the best way for our currentproject o have the greatest national impact.3.
A Collaboration between Examinee andComputer in the Production of theRatable Speech SampleThe goal of general oral proficiency tests such asthe OPI, SOPI, VOCI, or COPI is to allowexaminees to demonstrate to a trained raterfeatures of oral language proficiency at one ofthe main global proficiency levels theyconsistently control.
In other words, examineesdemonstrate what they can do with the languageregardless of how they learned it.
In order tomake appropriate assessments, he test must givethe rater evidence that examinees assessed at aparticular level do not control the features of thenext higher level of proficiency.In the OPI, examinees have a certain amount ofinput into the procedure.
The interviewer adaptsthe level of difficulty of the questions to theproficiency level displayed by the examinee.Examinees control the length of their responsesto the interviewer's questions.
They have somecontrol over the content of the interview in thatthe interviewer is trained (particularly at lowerlevels) to follow up on topics nominated by theexaminee.In tape-mediated tests, much of this control islost.
In general, timed pauses prescribe for theexaminee how much time he or she has to thinkabout and give a response.
All examinees mustperform all tasks presented to them on the tape;there is no selection of the tasks.The main goal of the COPI is to use computertechnology to allow the examinee and computerto work together to produce a speech sampleratable using the ACTFL criteria.
The programmust enable the examinee to show what he orshe can do in a second language.
Thus, the COPIallows examinee control over several aspects ofthe test administration.
This is made possible bythe large amount of electronic data that can bestored in computers and by the random-accessnature of data retrieval.
Underlying the COPI isa large pool of assessment tasks that cover awide variety of content areas and topics.
TheCOPI allows examinees to have control of thetime they take to prepare for and respond to atask.
While a maximum time limit needs to beenforced to make sure the testing process18continues, that limit is long enough to allow formost examinees toexperience ontrol.The COPI allows examinees some choice in thedifficulty level of the tasks presented tothem.
Inorder to ensure that examinees are pushed toshow the full extent of their ability, the difficultylevel of all tasks cannot be examinee-selected.Raters need to hear examinees attempt askshigher than their proficiency level to ascertaintheir consistent level of performance.
Bykeeping track of the examinee's choices, aprogram can ensure that this occurs.
Limitedexaminee selection may, however, assure thatthe tasks administered are as appropriate aspossible to each examinee's level of ability.4.
Description of the Test AdministrationProgram for the Spanish COPI4.1 Technical RequirementsThe COPI program works well with a Windows95 operating system, or higher, with a Pentiumprocessor and 64 MB of RAM.
The examinees'responses can be recorded on internal or externalzip drives, or the hard drive.
We do notrecommend the use of Windows NT or laptopcomputers because the small memory space inthese types of computers makes recordingresponses difficult.4.2 Assessment TasksAt the core of the COPI is a pool of about 100assessment tasks.
These tasks are based on taskssuccessfully used in SOPIs.
Each task has atargeted ACTFL level (Novice, Intermediate,Advanced, or Superior) and is coded for itsspeaking function and content/topic area.
Eachtask is a separate master computer file composedof a single-sentence d scription of the task,written and audio directions in English, writtenand audio directions in Spanish (for tasks at theAdvanced and Superior levels), a graphic file ofa picture that accompanies the task (for thosetasks that have pictures) and an audio promptfrom a native Spanish-speaker.
Depending onthe choices that the examinee makes, the testtakes anywhere from 30-50 minutes.The COPI uses an algorithm which allowsexaminees (within some limits) to choose thefollowing aspects of the test: amount ofpreparation and response time, speakingfunction, topic, level of difficulty (i.e., ACTFLlevel of task), and language of the directions(English or Spanish for Advanced and Superiorlevel tasks) for each performance task.Figure 1 shows the screen for the sample task atlevel B (ACTFL Intermediate).19. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ISample.
Task, at Level B~:~ : :~?
:.
:~:i.~ :./, L " " ,.
.
i Click '!I'm :Ready to begnClick "l!m Finished" to:stop.I Beach Descriptioni i i i i  IImagine:that:you are visiting friends ;in Ecuador.Your:ffiendS: are talking ab:out going tO thebeach, One,of:your friends, Pablo,~ asks~ you todesCi~ibe;the;kinds:of activities people usually doat the beach in:theU.S.
Use your ownexperience or the picture: provided as a sourceof ideas: A~er Pablo :askshis qu!estion,describe the kindsofactivities peopleusually do ~ at,the beach;,I oo,oo,OlFigure 14.3 How Examinee Choice isOperationalized4.3.1 TimeThe COPI provides time for examinees to thinkabout their response and time to give theirresponse.
The total amount given for each task isshown by balls in a timer at the bottom righthand of the screen.
Each ball represents 15seconds.
More preparation and response time isallotted for higher-level than for lower-lowerlevel tasks, but examinees still have the choiceto use all the time allotted or to click on a buttonwhen they are ready to speak, or when they havefinished speaking.
Plenty of time is allotted andin our pilot testing to date, no examinee hasindicated feeling pressured by the time factor.4.3.2 Speaking Functions and TopicsIn total, an examinee generally responds toseven tasks on the COPI.
Examinees are alwaysgiven a choice of three tasks, from which theychoose one.
At the Intermediate level, forexample, they may choose from the followingtask descriptions: "Ask a Spanish exchangestudent some questions about her family,""Describe your leisure time activities to avisiting Bolivian student."
Or "Tell a studentfrom the Dominican Republic about your plansfor the weekend."
An algorithm in the programensures that examinees perform each speakingfunction (e.g., narrating in the past) and talkabout each content area/topic (e.g., food) onlyonce during the collaborative development ofthe speech sample.
Examinees are thus exposedto a variety of tasks and can select tasks andtopics they feel most comfortable with.204.3.3 ACTFL Level of the COPI TaskThe ACTFL level of the first COPI taskadministered is determined by the examinees'self-assessment scores and the level of thesample tasks practiced (described morecompletely in 4.4.3).
Following the first task,examinees are given the choice to select asks atthe same level of challenge, a less challengingtask, or a more challenging task, after everyother task.
An algorithm in the program ensuresthat examinees are offered tasks at a level higherthan the one they have generally chosen, toallow the rater to evaluate whether or not theycan fulfill the criteria for performance atthe nexthigher level.4.3.4 Language of DirectionsAt present, examinees are given the choice toread and hear the directions to the performancetask in Spanish or English only for the twohighest levels of tasks.
Lower level examineesreceive all directions only in English.
Followingpiloting testing of the Spanish COPI, however,we will experiment with including both Englishand Spanish directions for lower-level speakers.This is to provide more target language supportfor the lower-level speakers.Results from the pilot test of the COPI showedthat the examinees felt more comfortable andless anxious because they were given choicesthat made the test more flexible.
This, we feel, isan improvement from the SOPI, where suchchoices were unavailable.4.4 Phases of the COPIWhen taking the COPI, the examinee goesthrough the following nine phases: welcome,information on the purpose and structure of theCOPI; input and correction of personalinformation; self-assessment of proficiencylevel; listening to an adequate response to (a)sample task(s); practice with the same sampletask(s); responding to performance tasks (theactual test); feedback about the levels of thetasks that the examinee took, and closing.
Aphotograph of a friendly, female "guide"accompanies the screens.
The guide' sphotograph is present in all the screens thatwelcome, give instructions, and close theprogram.
Notes on these phases follow.4.4.1 Welcome~Information on the Purposeand Structure of the COPIThe purpose of these two phases is to introduceexaminees to the COPI and help them feel atease.4.4.2 Input and Correction of PersonalInformationExaminees enter their personal data and aregiven an opportunity to correct any wronginformation.
The information is used to identifythe examinees and to allow the program to selecttasks appropriate to the examinees' profiles.
Forinstance, in Arabic culture (for the ArabicCOPI), it is inappropriate for unmarried personsof the opposite sex to do certain activitiestogether (e.g., share an apartment).
Therefore, analgorithm in the Arabic COPI ensures that afemale or male version of these tasks ispresented to the examinee depending on whetherthe examinee is identified as a female or male,respectively.4.4.3 Self-Assessment of One's ProficiencyLevelExaminees answer 18 questions about theirabilities to communicate in the test language; forexample, give directions, ask questions,hypothesize, and so on.
Kenyon (1996) showedthat the correlation between examinees' answersto these 18 self-assessment questions and theiractual ACTFL assessments was .78.
The COPIprogram uses examinees' score on the self-assessment to determine at which level theyreceive the first sample task.4.4.4 Listening to and Practice on SampleTasksExaminees are given an opportunity to listen toan adequate response to a sample task.
They arethen asked to respond to the same sample taskfor practice.
This is the point in the program atwhich the directions for navigating the tasks areexplained.
After giving their performance on thesample task, examinees are asked if they want topractice with a more challenging or a lesschallenging task before going on to the actualtest.4.4.5 Responding toPerformance TasksExaminees can select the level of their firstperformance task based on their self-assessmentresults and experience with the sample task(s).21The program algorithm is set to ensure thatexaminees respond to a minimum of four tasksat the level of the first task selected and three atthe next higher level (or next lower level if theirself-assessment level is already at Superior) for aminimum of seven tasks.
Depending on thechoices examinees make, however, they can beadministered a maximum of 11 tasks, thoughthis is very rare.4.4.6 Feedback on the Levels of the Tasks thatExaminees Took~ClosingAfter completing the last performance task,examinees receive feedback about the levels oftasks they have taken and are thanked for theirparticipation.5.
Description of the Current ScoringProgramAs with the SOPI, performances on the COPIare assessed following the criteria of the ACTFLSpeaking Proficiency Guidelines.
The scoringprogram allows raters to hear the examinees'responses for each task and to listen to theexaminees' tasks in any order.
As raters assesseach task, elements of the task, such as itsACTFL level, the picture accompanying thetask, the directions and the Spanish promptappear on the screen.
These elements give ratersbackground information about each task andfacilitate the assessment of the performances.Raters can also rewind each examinee'sresponse for a particular task and they canlikewise go back to previously rated tasks.The program also allows raters to write notes toexaminees so that, aside from providing a globalrating (i.e., the ACTFL proficiency level atwhich the examinee demonstrated consistentperformance), raters are also able to give overallcomments and task-specific feedback to eachexaminee.
In addition, the COPI allows raters tolisten to performances on only those tasks thatare necessary to give an accurate assessment ofthe examinees' ACTFL proficiency level,thereby increasing raters' efficiency.
Forexample, if an examinee responded to fourSuperior tasks and three Advanced tasks, wesuggest that the rater start assessing the highestlevel (Superior) tasks first.
If the examinee isclearly a Superior speaker based on his or herperformance on the four Superior-level tasks,then it is not necessary for the rater to listen tohis or her performances on the three Advanced-level tasks.6.
Opportunities for Interfacing withNatural Language ProcessingPerformances on the current version of the COPIare assessed by trained human raters.
While theCOPI scoring program is designed to improveefficiency in rating, assessing speechperformances elicited by the COPI using thecriteria of the ACTFL Guidelines remains alabor-intensive ffort.
The COPI harnessestechnology to provide examinees an opportunityto demonstrate their oral proficiency without helabor intensity involved on the part of a testadministrator (as compared to the individuallyadministered face-to-face OPI).
In a similarmanner, we feel that this program providesopportunities for interfacing with naturallanguage processing to provide technologicalassistance in assessing examinee speechperformances.
While that discussion is outsidethe scope of this paper, we feel implementationof oral proficiency assessment, particularly forlower-level learners, would increase were itpossible for technology to assist in theevaluation of speech performances.
An increasein the practicability of large-scaletechnologically mediated oral assessments hasthe potential for a great washback effect in ournation's classrooms to promote the developmentof oral proficiency in second languages.Educational practitioners have long understoodthat ultimately what gets assessed is what getstaught and practiced.ConclusionWe believe the COPI offers significantimprovements in terms of administration oftechnologically mediated oral proficiencyassessments over tape- or video-mediatedassessments.
Pilot testing to date indicates thatexaminees are comfortable with theadministration format and understand what isrequired of them.
A validation study is plannedfor the near future to compare performances onthe COPI with those on the SOPI and OPI.
Otherrefinements suggested by the piloting testing arebeing incorporated into the Arabic and Chineseversions.
If such improvements are found to be22helpful through pilot testing, they will bebrought into the Spanish version.AcknowledgmentsSupport for the development of the COPI isprovided by grant P017A70019-98, InternationalResearch and Studies Program, InternationalEducation and Graduate Program Service, U.S.Department ofEducation.
The work presented inthis paper builds on continuing research anddevelopment projects in technologically-mediated oral proficiency testing over the past15 years at the Center for Applied Linguistics.
Itis !mpossible to properly acknowledge all whohave contributed irectly or indirectly to thecurrent efforts.
However, we do acknowledgeour colleagues at CAL contributing to the COPIproject, including Weiping Wu, Kate Jerris, JaneHerlihy, Deanne Marein-Efron, HelenCarpenter, David MacGregor, CharlesStansfield, and Suzy Meyer, COPI programmer.ReferencesAmerican Council on the Teaching of ForeignLanguages.
(1986) Proficiency guidelines.Hastings-on-Hudson, NY: Author.American Council on the Teaching of ForeignLanguages.
(1999) ACTFL proficiencyguidelines--speaking: Revised 1999.Hastings-on-Hudson, NY: Author.Buck, K., Byrnes, H. and Thompson, I.
(Eds.)
(1989)The ACTFL oral proficiency interview testertraining manual.
Yonkers, NY: ACTFL.Kenyon D. M. (1996, November) Self-assessmentand speaking tasks: Research and application.Workshop, Annual Meeting of the AmericanCouncil on the Teaching of Foreign Languages,Philadelphia, PA.Stansfield, C. W. (1996) Test development handbook:Simulated oral proficiency interview.
Washington,DC: Center for Applied Linguistics.Stansfield, C. W. and Kenyon, D. M. (1992)Research on the comparability of the OralProficiency Interview and the Simulated OralProficiency Interview.
System, 20, 347-64.23
