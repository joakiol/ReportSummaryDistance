Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1587?1596,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsShared common ground influences information density in microblog textsGabriel DoyleDept.
of PsychologyStanford UniversityStanford, CA, USA, 94305gdoyle@stanford.eduMichael C. FrankDept.
of PsychologyStanford UniversityStanford, CA, USA, 94305mcfrank@stanford.eduAbstractIf speakers use language rationally, theyshould structure their messages to achieveapproximately uniform information density(UID), in order to optimize transmission viaa noisy channel.
Previous work identified aconsistent increase in linguistic informationacross sentences in text as a signature of theUID hypothesis.
This increase was derivedfrom a predicted increase in context, but thecontext itself was not quantified.
We usemicroblog texts from Twitter, tied to a sin-gle shared event (the baseball World Series),to quantify both linguistic and non-linguisticcontext.
By tracking changes in contextualinformation, we predict and identify grad-ual and rapid changes in information contentin response to in-game events.
These find-ings lend further support to the UID hypoth-esis and highlights the importance of non-linguistic common ground for language pro-duction and processing.1 IntroductionThere are many ways express a given message innatural language, so how do speakers decide be-tween potential structures?
One prominent hypothe-sis is that they aim for structures that best convey theintendeed message in the context of the communi-cation.
On this view, the use of natural languages isassumed to follow optimal information transmissionresults from information theory (Shannon, 1948).In particular, speakers should structure their mes-sages to approximate uniform information densityacross symbols (words and phonemes), which isoptimal for transmission of information through anoisy channel.At least three lines of evidence suggest that speak-ers do make choices to increase the uniformity ofinformation density across their utterances.
First,speakers phonologically reduce more predictablematerial (Aylett and Turk, 2004; Aylett and Turk,2006; Bell et al, 2003).
Second, they omit or reduceoptional lexical material in cases where the subse-quent syntactic information is relatively more pre-dictable (Levy and Jaeger, 2007; Frank and Jaeger,2008; Jaeger, 2010).
Third, and most relevant to ourcurrent hypothesis, speakers appear to increase thecomplexity of their utterances as a discourse devel-ops (Genzel and Charniak, 2002; Genzel and Char-niak, 2003; Qian and Jaeger, 2012).
We expand onthis finding below.Following the UID hypothesis, Genzel and Char-niak 2002 proposed that H(Yi), the total entropy ofpart i of a message (e.g., a word) is constant.
Theycompute this expression by considering Xi, the ran-dom variable representing the precise word that willappear at position i, conditioned on all the previ-ously observed words.
They then further factor thisexpression into two terms:H(Yi) = H(Xi|Ci, Li)= H(Xi|Li)?
I(Xi;Ci|Li) (1)where the first term H(Xi|Li) is the dependence ofthe current word on only the local linguistic context(e.g.
within the rest of the sentence Li) and the sec-ond is the mutual information between the currentword and the broader linguistic context Ci, giventhe rest of the current sentence.
On their logic, with1587greater amounts of contextual information, the pre-dictability of linguistic material based on context,I(Xi|Ci, Li), must go up.
Therefore, they predictedthat H(Xi|Li) should also increase, so as to main-tain a constant total amount of information.Genzel and Charniak then approximatedH(Xi|Li) using a number of methods and showedthat it did increase systematically in documents.Later work showed that this increase was strongestwithin paragraphs and was general across documenttypes (Genzel and Charniak, 2003) and languages(Qian and Jaeger, 2012).
This work, however,did not attempt to measure shared context (and itsinfluence on message expectations) directly.
Thischallenge is the focus of our current work.1.1 Contextual effects on complexityIn psycholinguistics, the notion of shared commonground is a more precise replacement for the generalnotion of ?context?
(Clark, 1996).
Common groundis defined as the knowledge that participants in a dis-course have and that participants know other partici-pants have, including the current conversational con-text.
A large literature supports the idea that speak-ers consider referential context and other linguisticcommon ground in selecting the appropriate expres-sion to refer to a particular physical object (Brennanand Clark, 1996; Metzing and Brennan, 2003; Daleand Reiter, 1995; Sedivy et al, 1999).
In principle,Genzel and Charniak?s formulation can be consid-ered as capturing the relationship between all of theshared common ground?both linguistic and non-linguistic?and the predictability of language, eventhough in the previous work only linguistic informa-tion was considered.When there is both linguistic and non-linguisticinformation passing through the noisy channel, therelevant quantity is not the marginal entropy of onlythe linguistic stream but the joint entropy of bothstreams.
Let Tjbe the linguistic information in partj of the discourse, and Ejbe the non-linguistic in-formation in part j. IfCjis the built-up context fromthe preceding parts {1, ?
?
?
, j ?
1} of the discourse,then we can break down the joint entropy as:H(Tj, Ej|Cj)= H(Tj|Ej, Cj) +H(Ej|Cj)= H(Tj|Cj)?
I(Tj;Ej|Cj) +H(Ej|Cj)= H(Tj)?
I(Tj;Cj)?I(Tj;Ej|Cj) +H(Ej|Cj)= H(Tj)?
I(Tj;Ej, Cj) +H(Ej|Cj) (2)By the UID hypothesis, we expect the left-handside of this equation, the information content of eachpart of the discourse, to be constant.
The first termof the right-hand side is the out-of-context entropyof the linguistic information.
The second term is themutual information of the linguistic information andthe union of the preceding context plus the currentnon-linguistic information (the events occurring atthe time).
The third term is the entropy of the non-linguistic information, given the preceding context.This breakdown suggests that rational participantsin a discourse will exhibit both slow and fast adapta-tion to context in order to maintain overall constantentropy.
As context slowly builds, the mutual infor-mation term grows (and the non-linguistic entropylikely shrinks), resulting in the time-based increasein H(Tj) that previous work has found.
In addition,an individual event can have high or low informationcontent given the context, without having a large ef-fect on the mutual information term.
To maintainconstant entropy, high-information events shouldbe accompanied by low-information linguistic re-sponses, and vice versa.
With an operationalizationof shared context, we should be able to observe thesetwo types of adaptation directly, not just via the in-creasing trend shown in previous work (Genzel andCharniak, 2002; Qian and Jaeger, 2012).To test this prediction, we leverage Twitter, a pop-ular microblogging service, to operationalize com-mon ground.
Because of its structure, Twitter isan ideal platform for this investigation.
One com-mon method of using Twitter is to mark messageswith hashtags, which serve as ad-hoc categories, al-lowing anyone interested in a topic to find the mes-sages relevant to that topic.
This strategy is espe-cially used when users are commenting on an exter-nal event (e.g.
a sporting, media, or political event).We focus here on the World Series of baseball, anannual sporting event with large viewership and asingle broadcast stream; in this case, the hashtag is#worldseries.
Hashtagged messages are part ofa discourse with extremely limited prior linguisticcontext, as no two tweeters will have seen the sameset of tweets.
The total shared context with the au-1588dience that can be assumed by the writer of a tweetis the non-linguistic content of the event being hash-tagged.We begin by describing our corpus and ourmethod of calculating linguistic content (by comput-ing entropy within a simple n-gram model).
We theninvestigate gradual changes in word-by-word infor-mation content as the event goes on (testing adap-tation driven by contextual mutual information inEquation 2, replicating Genzel and Charniak 2002)and rapid changes in the total information contentof tweets in response to important in-game events(testing adaptation driven by non-linguistic informa-tion in Equation 2).
We end by considering con-trol analyses that provide evidence against alterna-tive accounts of our results.2 Corpus and Methods2.1 #Worldseries CorpusOur current analysis looked at tweets during the2014 World Series, a series of seven baseball gamesin late October 2014.
We obtained these tweetsby searching publicly-available tweets through theTwitter API, using an adaptation of SeeTweet(Doyle, 2014) to compile tweets containing thehashtag #WorldSeries.
To synchronize tweetswith game events, we used the Major League Base-ball Advance Media XML repository,1which con-tains pitch-by-pitch data including the ongoing stateof the game and timestamps at the start of each at-bat.
Using this timestamp information, we binnedtweets by at-bats so that they could be co-registeredwith other in-game statistics.
These bins extendfrom the time of the first pitch in an at-bat to the be-ginning of the next at-bat, and thus provide time forreactions to the events of the at-bat.2The mean at-bat length was 2.76 minutes, and there were 512 to-tal at-bats.
We limited our analysis to tweets times-tamped during one of these at-bats, resulting in atotal corpus of 109,207 tweets.
Each game had itsfirst pitch at approximately 0008 UTC, and lastedbetween three and four hours.1http://gd2.mlb.com/components/game/mlb/2We tested a series of potential offset times in case Twitterand MLB used different clocks or at-bats were not long enoughto capture reactions.
We did not adjust the times as there was nosignificant increase in the correlation between Leverage Index(Sect.
5.1) and tweet rate for these offsets.Our tweet corpus was compiled from the ?garden-hose?
Twitter search API, which returns a subsetof all relevant tweets.
Our searches captured ap-proximately 4% of all relevant tweets; Twitter re-ported 420,329 relevant tweets during Game 1 ofthe World Series3, and our dataset contained 17,538tweets during the same time period.
We address po-tential confounds from this sampling process in Sec-tion 5.2.2.2 Entropy ComputationEstimating the linguistic information content of eachtweet is a key task in this work.
Social media texthas been described as ?bad language?
(Eisenstein,2013): It can be difficult to model due to its idiosyn-cratic abbreviations, typographic errors, and othernon-standard forms.
Relevant to our goal of assess-ing information content, it can also be difficult tocreate an appropriate training corpus for languagemodels, since the vocabulary and composition oftweets of change rapidly (Eisenstein, 2013).We attempted to minimize these difficulties in twoways.
First, we estimated language models withdomain-specific corpora.
In particular, for tweetsfrom each game we used a training corpus consist-ing of the tweets from all the other games.
Thistraining set provided a vocabulary and structure thatwas similar in topic and style to the test set.
We re-moved all punctuation and emoji except word-initial@ and #, which refer to users and hashtags, re-spectively.
Usernames were replaced with [MEN-TION] to reduce sparsity; hashtags were not altered,as these often function as words or phrases withinthe tweet?s syntax.
Words with fewer than 5 occur-rences in the training corpus were marked as out-of-vocabulary items.
We estimated trigram modelsusing a modification of NLTK (Bird, 2006)4withWitten-Bell smoothing, and estimated per-word andtotal entropy for each tweet from these models.Second, we included tweet length (in characters)as an alternative metric of information content (seeSection 5.2).
Unless information rate varies sys-3http://Twitter.com/TwitterData/status/5249725459303014404Smoothing on n-gram models in NLTK can be inaccurate(see http://github.com/nltk/nltk/issues/367),so we used a modified version courtesy of B. C. Roy (personalcommunication).1589lllllllllllllllllllllllllllllllllllllllllllllllll llllllllllllllllllllllll5.05.56.06.57.00 1 2 3 4Time (hrs)Per?wordentropyGame #l 1234567Time vs. per?word entropyFigure 1: Per-word entropy increases with time for thefirst two hours of the games, then levels off and slightlydeclines.
Color reflects in-game time; line shows loess fitwith 95% confidence intervals.tematically and substantially across tweets of dif-ferent lengths?counter to existing results suggest-ing uniform information density operates at multi-ple structural levels (e.g., Qian and Jaeger 2009)?longer tweets will generally carry more information.3 Gradual Changes in Information RateOur first analytic goal was to examine changes inthe information content of tweets due to the long-term build-up of context in a shared event.
We pre-dicted that we would see similar developments ininformation structure as in more traditional conver-sational settings, even though there was no formalconversation or explicit linguistic history to developcommon ground.
Specifically, we predicted that thebuild-up of contextual information would cause thecontext-independent per-word entropy to rise overtime, replicating the effect that has been observedacross languages and genres (Genzel and Charniak,2003; Qian and Jaeger, 2012).Figure 1 shows evidence for changes in per-wordentropy over the course of games.
Per-word entropyrises throughout in the first two hours of each game,slowly levels off and finally declines slightly overtime.
This pattern is consistent with the constant en-tropy rate proposal of Genzel and Charniak 2002,and more specifically with the context decay modelof Qian and Jaeger 2012.55A late decline in per-word entropy also appeared in Qianand Jaeger 2012?s analysis of Swedish.We used mixed-effects linear regression to quan-tify this relationship, using the time of an at-bat topredict both per-word and per-tweet entropy duringthe at-bat.
Specifically, we used the logarithm oftime as our fixed-effect predictor, per the context-decay models of Qian and Jaeger 2012.
We addedgame-specific random intercepts and slopes of log-time to capture cross-game variation.
This modelshowed significant positive effects of time on en-tropy, using likelihood-ratio tests for both models(per-word entropy: .348 ?
.045; p < .001, ?2(3) =104.6, per-tweet entropy: 10.31 ?
2.08; p =.001, ?2(3) = 74.65).We hypothesize that this finding?greater linguis-tic entropy for later tweets?is due to the accrualof common ground across users from shared non-linguistic information.
As they watch more of thegame, they share more referents and have strongerexpectations about what aspects of the game willbe discussed.
This shared common ground licensesmore complex language and more sophisticated lin-guistic references.
Table 1 gives example tweetsat different time points; as a game progresses, ref-erences can expand from generic references to theteams or series, to specific individuals and events,and eventually to sequences of events.While this finding is consistent with previouswork on the effect of context, it expands the defini-tion of context.
In previous work, the context camefrom explicit linguistic information built up throughparagraphs in a formally-structured, written docu-ment.
In the Twitter dataset, the context comes fromreal-world events during the games, as there is nocanonical shared sequence of tweets that the tweet-ers can refer back to (indeed, two random users ofthe #Worldseries hashtag probably have relativelylittle Twitter context in common).
In sum, contex-tual influences on entropy need not be explicitly lin-guistic, so long as discourse participants have rea-son to believe that the other participants share theirknowledge.4 Fast Changes In Information ContentIntuitively, after an exciting, game-changing event,tweets will be shorter and make more reference tothe shared knowledge that this event has just hap-pened.
Such events should also generate more re-1590Minute Tweet Per-word entropy0 It?s finally here!
#WorldSeries 4.740 #WorldSeries Play Ball 4.960IDEA: @mayoredlee, #SanFrancisco can pledge to throw our @SFGiantsan #OrangeOctober parade regardless of #WorldSeries outcome!
#SFGiants8.2012 The guy with the Marlins sweater is behind home plate again.
#worldseries 4.2612 The Giants 3-0!
#WorldSeries 5.4312Something about Hunter Pence really, really bothers me.
Don?t ask mewhat, cause I havent figured it out, but I don?t like him.
#WorldSeries6.6473Three HORRIBLE at-bats (mixed in with Cain?s walk) prevent Royals frombreaking through in the third.
#WorldSeries9.39130As Hardy Boy #2, Joe Panik just pulled the mask off of Vargas and discov-ered it?s Old Man Withers from down the street.
#WorldSeries8.12178#WorldSeries it?s funny the non body names have a great hits.
Frm now non consider the Postseson as Cinderla run.
No names needed, #MLB10.04Table 1: Example tweets, grouped by minutes since the first pitch.llll lllllll ll lllll lllllllllllllll lllllll lllll llllll lllllll l llllllllllllllllll l llllllllllllllllllllllll ll lllllllllllll lllll lllllll lllllllllllllllllllllllllllllllll lllllllllll lllll llllllllllllll l lllllllll lllllllllllllllllllllllllllllllllllllllllllll ll l lllllllllllllll llllll llllll lllllllllllll lllllllllll lll lllllllllll llllllllllllllll lllllllllllllllllll llllll lllllllllll lllllllllllllllll ll lll l5070901101301.0 1.5 2.0 2.5 3.0Log_10 Tweet RatePer?tweetentropy123Time(hrs)Log tweet rate vs. per?tweet entropyFigure 2: Total tweet entropy plotted against log tweetrate.
Color reflects in-game time; line shows loess fit with95% confidence intervals.sponses, suggesting that the number of tweets perunit time can serve as a proxy for the informationcontent of an event.
This relationship is captured byEquation 2, in which unexpected events have largeinformation content, so linguistic information con-tent should be reduced correspondingly to maintainconstant entropy.
Our next set of analyses test thisrelationship.The examples shown in Table 2 provide anecdotalevidence for the hypothesized relationship betweenin-game events and linguistic complexity, with ex-amples of consecutive tweets from high-rate andlow-rate at-bats, along with their information con-tent.
The top triplet comes from one of the highest-rate at-bats, in which Gregor Blanco committed acrucial error in the last inning of the last game.
Thebottom triplet comes from a low-rate at-bat, mid-game, with one team well ahead of the other; in thiscase, tweets all refer to different events as there is nosingle salient shared event.We quantified the predicted relationship by againfitting a mixed-effect linear regression model, in thiscase using the logarithm of per-minute tweet rateas a predictor of tweet entropy.
Given its signifi-cance in the previous model, we included log(time)as a control factor in this analysis, and added by-game random intercepts and slopes for log(rate) andlog(time).
The log of the tweet rate had a sig-nificant negative effect on per-word and per-tweetentropy by likelihood-ratio tests (per-word-entropy:?.333 ?
.073; p < .001, ?2(4) = 59.37, per-tweet-entropy: ?21.82?
2.43; p < .001, ?2(4) = 194.6).Log(time) retained significance (p < .001) asa predictor for both entropy measures even whenrate was accounted for, showing evidence for both1591LograteTweet Per-word entropy2.49 Holy shitballs, @Royals!
#WorldSeries #Game7 3.992.49 Just when you thought the #WorldSeries was over.... #E8 4.762.49 Fuck you, Blanco.
#Giants #WorldSeries 5.541.66 Lets Go Giants!!!
5-0 #SFGiants #WorldSeries 3.261.66The guy in Marlins gear behind home plate needs to escorted off propertyfor annoying everybody.
#WorldSeries #WhoDoesThat4.851.66I suppose I appreciate Bochy?s ?ASG?
approach with Bumgarner.
Of course,who are any of us to question him in late October?
#WorldSeries7.42Table 2: Example tweets, grouped by the per-minute tweet rate during each at-bat.slow and fast adaptation occurring in the discourse.The effects are both in the predicted directions: En-tropy increases with time as more informative con-text builds up, but decreases with tweet rate asmore exciting events encourage less information-laden tweets.5 Control Analyses5.1 Non-Rate Metrics of ContextSince tweet rate is an organic reflection of the in-terest accrued by in-game events, it is an impor-tant metric for examining fast adaptation.
Never-theless, it could be confounded with other factorsinfluencing tweet production.
For instance, there isevidence that online interactions exhibit rational re-sponses to information overload, the state where theamount of incoming information exceeds a user?sability to process it (Miller, 1956; Schoberth et al,2003).
Previous investigations into forum postingbehavior have shown that users adapt to overload byposting shorter messages (Jones et al, 2001b; Joneset al, 2001a; Whittaker et al, 2003; Schoberth et al,2003), and a similar result was found for the moreexplicitly conversational setting of IRC chat chan-nels (Jones et al, 2008).To show that the changes in information con-tent are not merely reactions to increased tweetcompetition?that they have independent informa-tional motivations?we need metrics of event im-portance and predictability that are not dependent onsocial media behavior.
Luckily, baseball has a longhistory of statistical analysis, and as a result, therell lllll llllllllllll lllllllllllllllllllllllllllllllllllllllll4060801001200.0 0.1 0.2WPAPer?tweetentropyGame #l 1234567Win Prob.
Added vs. per?tweet entropyFigure 3: Total entropy decreases for at-bats with greaterwin probability changes.
Loess curve fitting with 95%confidence intervals.are independently-derived metrics that fit this bill.Two that are appropriate for this purpose are Lever-age Index (LI)6and Win Probability Added (WPA)(Tango et al, 2007).LI is an estimate of how critical an at-bat is to theoutcome of the game.
It is based on the differencein resultant win probability if the current batter getsa hit or an out, normalized by the mean change inwin probability over all at-bats.
1 is the average LI,and greater LI indicates greater importance.
LI, as ameasure of the expected change in win probability,is similar to non-linguistic entropy term in Equation2.WPA depends on the result of an at-bat, and es-6http://www.hardballtimes.com/crucial-situations/1592timates how much the win probability changed as aresult of what happened during the at-bat.
WPA thusprovides an estimate of how much information aboutthe game outcome this at-bat has provided, condi-tioned on the current game context.
These mea-sures are well-correlated (Kendall?s ?
= .77), sincea high-LI at-bat?s value comes from its ability to af-fect win probability.As high LI or WPA values indicate an at-batwhose result has a large effect on the game, thesemetrics provide an estimate for non-linguistic infor-mativity that is independent of medium-specific in-fluences on tweet production.
To assess their ef-fects, we constructed four mixed-effects linear re-gression models, using LI and WPA to predict per-word and per-tweet entropy in all pairwise combi-nations (we built separate models for LI and WPAdue to their high collinearity).
Fixed- and by-gamerandom-effects of log(time) and log(rate) were in-cluded as controls in all models; if there is an effectof LI or WPA beyond the effect of rate, this effectcan be interpreted as evidence of speaker adaptationto non-linguistic information content.Both LI and WPA had significant negative ef-fects on per-tweet entropy (LI: ?1.52 ?
.43; p =.001, ?2(5) = 20.1, WPA: ?2.27 ?
.40; p <.001, ?2(5) = 44.18), over and above the effect oftweet rate.
Per-word entropy did not show a signifi-cant effect of LI or WPA when rate was included asa control factor.
Each was a significant factor on per-word entropy (p = .008, p = .005) when rate wasnot included as a control, though, suggesting that theexplanatory power of these independent metrics maybe subsumed in the more complex factor of tweetrate.5.2 Speaker NormalizationA second alternative hypothesis for the observed be-havioral changes with tweet rate is that they arisenot from changes in the behavior of individuals butrather from a change in demographics.
It is plausiblethat rising tweet rates come from an influx of newtweeters using the hashtag, and that these new tweet-ers simply produce shorter, less informative tweetsin general.
For instance, spambots often includetrending hashtags in their spam tweets (Martinez-Romo and Araujo, 2013).
To account for this, wetreated the users whose tweets are in our corpus asll llllllllllllll lllllllll llllllllllllllllllllllllllllllllllll?40?200200.0 0.1 0.2WPACharactersaboveaverage Game #l 1234567Win Prob.
Added vs. normalized tweet lengthFigure 4: Speaker-normalized tweet length also decreasesfor at-bats with greater win probability changes.
Loesscurve fitting with 95% confidence intervals.a ?computational focus group?
(Lin et al, 2013; Linet al, 2014), and used the Twitter API to collected afurther 100 tweets from each user outside the time-frame of the games.
We used these tweets to esti-mate an average tweet length for each user, and sub-tracted this value from the length of their #world-series tweets during the games.7If this baselinedmetric displays the same effects as shown above, wehave reason to believe that users are in fact changingtheir individual behaviors in response to informationfactors, rather than that a demographic shift is mim-icking a behavioral shift.For this analysis, we created a mixed-effectsmodel with WPA, log(rate) and log(time) as predic-tors of tweet length.
All three factors were signifi-cant (WPA: ?1.64 ?
.36; p < .001, ?2(5) = 72.3;log(rate): ?6.15 ?
.47; p < .001, ?2(5) = 303.6;log(time): .82 ?
.40; p = .001, ?2(5) = 20.6).
Wethen created a second model using the same factorsto predict the mean change in tweet length from thebaseline length.
Again, all three factors were signif-icant (WPA: ?2.01 ?
.29; p < .001, ?2(5) = 70.2;log(rate): ?5.10 ?
.49; p < .001, ?2(5) = 252.6;log(time): .61 ?
.35; p = .016, ?2(5) = 14.0).By ruling out demographic shifts (e.g., an influxof terser tweeters), this analysis provides additionalsupport for the idea that tweeters indeed shift theirbehavior in response to in-game information.7Note that these analyses are conducted over tweet length,rather than total entropy, as there was no obvious way of nor-malizing entropy by speaker.15936 DiscussionWe investigated the hypothesis that speakers opti-mize their language production so as to approximateuniform information density, a signature of efficientcommunication through a noisy channel (Shannon,1948; Levy and Jaeger, 2007).
Previous work hadobserved indirect evidence for UID via increases inlinguistic complexity (which were hypothesized toreflect increasing discourse/contextual knowledge),but this work neither measured contextual informa-tion directly nor included non-linguistic measuresof context (Genzel and Charniak, 2002; Genzel andCharniak, 2003; Qian and Jaeger, 2012).
Our cur-rent work takes a first step towards addressing theseissues by using microblog texts around shared events(baseball games) as a case study in which a knowncontext can be characterized more precisely.
Withthis approach, we find systematic differences in in-formation rate and total information content as afunction of nonlinguistic factors.We successfully replicated the effect found in pre-vious work: a gradual increase in entropy rate overthe course of individual baseball games.
But inaddition to this effect, we found a striking patternof short-timescale changes in total message entropy(reflected in the changing lengths of messages).When in-game events were exciting, unpredictable,and outcome-relevant (hence, highly informative),message length and total entropy went down.
Thisregularity suggests that Twitter users were regulat-ing the information content of their messages rela-tive to the total communicative content of the con-text more broadly, a prediction that can be deriveddirectly from the UID model.Our work highlights the importance of non-linguistic context for the informational content oflanguage.
This relationship is widely acknowledgedin theories of pragmatic communication (Grice,1975; Sperber and Wilson, 1986; Clark, 1996; Frankand Goodman, 2012), but has been largely ab-sent in information-theoretic treatments of linguis-tic complexity.
The omission of this informationhas largely been for pragmatic, rather than theoret-ical, reasons: As Genzel and Charniak 2002 note,it is typically very difficult to compute semantic?let alne non-linguistic?information content.
Ourwork suggests that internet communications sur-rounding shared media events may be a promisingsource of grounded language use where context canbe quantified more effectively due to the existenceof substantial metadata.A growing literature suggests that the informationcontent of language is the critical variable for un-derstanding processing difficulty in language com-prehension (Levy, 2008; Demberg and Keller, 2008;Boston et al, 2008; Smith and Levy, 2013).
Un-der surprisal theory (Hale, 2001; Levy, 2008), theoverall predictability of individual elements of lan-guage is assumed to be due to a predictive modelof its likelihood in the current context.
Given thismodel of processing difficulty, our work here makesa strong prediction: that the information processingdifficulty of a word or sentence should track with itstotal information content (including its relationshipto the non-linguistic context), rather than its linguis-tic information content alone.
Some preliminary ev-idence supports this idea.
In a study of the process-ing complexity of negative utterances, Nordmeyerand Frank 2014 found that the processing cost ofnegation was predicted by the surprisal of encoun-tering the negation in a particular pragmatic context.But future work should test this hypothesis across awider variety of structures and contexts.In sum, our work contributes to the growingbody of evidence in favor of the UID hypothesis.The mechanisms underlying the tendency to regu-late information content are still unknown, however.While UID would follow from a strong form of au-dience design, in which speakers explicitly considerthe processing difficulty of different content (Clark,1996), the UID hypothesis could also emerge fromsimpler production processes.
Untangling these pos-sibilities will not be trivial.
Regardless of the reso-lution of this issue, however, UID appears to be animportant descriptive tool in capturing how speakersmake production choices.AcknowledgmentsWe gratefully acknowledge the support of ONRGrant N00014-13-1-0287.1594ReferencesMatthew Aylett and Alice Turk.
2004.
The smooth sig-nal redundancy hypothesis: A functional explanationfor relationships between redundancy, prosodic promi-nence, and duration in spontaneous speech.
Languageand Speech, 47(1):31?56.Matthew Aylett and Alice Turk.
2006.
Language redun-dancy predicts syllabic duration and the spectral char-acteristics of vocalic syllable nuclei.
The Journal ofthe Acoustical Society of America, 119(5):3048?3058.Alan Bell, Daniel Jurafsky, Eric Fosler-Lussier, CynthiaGirand, Michelle Gregory, and Daniel Gildea.
2003.Effects of disfluencies, predictability, and utteranceposition on word form variation in English conversa-tion.
The Journal of the Acoustical Society of America,113(2):1001?1024.Steven Bird.
2006.
NLTK: the natural language toolkit.In Proceedings of the COLING/ACL on Interactivepresentation sessions, pages 69?72.
Association forComputational Linguistics.Marisa Boston, John Hale, Reinhold Kliegl, Umesh Patil,and Shravan Vasishth.
2008.
Parsing costs as pre-dictors of reading difficulty: An evaluation using thepotsdam sentence corpus.
Journal of Eye MovementResearch, 2(1):1?12.Susan E Brennan and Herbert H Clark.
1996.
Concep-tual pacts and lexical choice in conversation.
Journalof Experimental Psychology: Learning, Memory, andCognition, 22(6):1482.Herbert H Clark.
1996.
Using language, volume 1996.Cambridge University Press Cambridge.Robert Dale and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the gener-ation of referring expressions.
Cognitive Science,19(2):233?263.Vera Demberg and Frank Keller.
2008.
Data from eye-tracking corpora as evidence for theories of syntacticprocessing complexity.
Cognition, 109(2):193?210.Gabriel Doyle.
2014.
Mapping dialectal variation byquerying social media.
In Proceedings of the Euro-pean Chapter of the Association for ComputationalLinguistics.Jacob Eisenstein.
2013.
What to do about bad languageon the internet.
In Proceedings of the 2013 Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 359?369.Michael C Frank and Noah D Goodman.
2012.
Predict-ing pragmatic reasoning in language games.
Science,336(6084):998?998.Austin Frank and T Florian Jaeger.
2008.
Speaking ratio-nally: Uniform information density as an optimal strat-egy for language production.
In Proceedings of the30th Annual Meeting of the Cognitive Science Society,pages 933?938.
Cognitive Science Society Washing-ton, DC.Dmitriy Genzel and Eugene Charniak.
2002.
Entropyrate constancy in text.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 199?206.
Association for Computa-tional Linguistics.Dmitriy Genzel and Eugene Charniak.
2003.
Variationof entropy and parse trees of sentences as a function ofthe sentence number.
In Proceedings of the 2003 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 65?72.
Association for Computa-tional Linguistics.H Paul Grice.
1975.
Logic and conversation.
Syntax andSemantics, 3:41?58.John Hale.
2001.
A probabilistic earley parser as a psy-cholinguistic model.
In Proceedings of the 2nd Meet-ing of the North American Chapter of the Associationfor Computational Linguistics on Language Technolo-gies, pages 1?8.
Association for Computational Lin-guistics.T Florian Jaeger.
2010.
Redundancy and reduction:Speakers manage syntactic information density.
Cog-nitive Psychology, 61(1):23?62.Quentin Jones, Gilad Ravid, and Sheizaf Rafaeli.
2001a.Empirical evidence for information overload in massinteraction.
In CHI?01 Extended Abstracts on HumanFactors in Computing Systems, pages 177?178.
ACM.Quentin Jones, Gilad Ravid, and Sheizaf Rafaeli.
2001b.Information overload and virtual public discourseboundaries.
In INTERACT?01: 13th InternationalConference on Human-Computer Interaction, page 43.IOS Press.Quentin Jones, Mihai Moldovan, Daphne Raban, andBrian Butler.
2008.
Empirical evidence of informa-tion overload constraining chat channel community in-teractions.
In Proceedings of the 2008 ACM Confer-ence on Computer Supported Cooperative Work, pages323?332.
ACM.Roger Levy and T Florian Jaeger.
2007.
Speakers opti-mize information density through syntactic reduction.In Advances in Neural Information Processing Sys-tems, pages 849?856.Roger Levy.
2008.
Expectation-based syntactic compre-hension.
Cognition, 106(3):1126?1177.Yu-Ru Lin, Drew Margolin, Brian Keegan, and DavidLazer.
2013.
Voices of victory: A computational fo-cus group framework for tracking opinion shift in realtime.
In Proceedings of the 22nd international confer-ence onWorld WideWeb, pages 737?748.
InternationalWorld Wide Web Conferences Steering Committee.1595Yu-Ru Lin, Brian Keegan, Drew Margolin, and DavidLazer.
2014.
Rising tides or rising stars?
: Dynam-ics of shared attention on twitter during media events.PLoS One, 9(5):e94093.Juan Martinez-Romo and Lourdes Araujo.
2013.
Detect-ing malicious tweets in trending topics using a statis-tical analysis of language.
Expert Systems with Appli-cations, 40(8):2992?3000.Charles Metzing and Susan E Brennan.
2003.
Whenconceptual pacts are broken: Partner-specific effectson the comprehension of referring expressions.
Jour-nal of Memory and Language, 49(2):201?213.George A Miller.
1956.
The magical number seven, plusor minus two: some limits on our capacity for process-ing information.
Psychological Review, 63(2):81.Ann E Nordmeyer and Michael C Frank.
2014.
A prag-matic account of the processing of negative sentences.In Proceedings of the 36th Annual Meeting of the Cog-nitive Science Society.Ting Qian and T Florian Jaeger.
2009.
Evidence for effi-cient language production in Chinese.
In Proceedingsof the 31st Annual Meeting of the Cognitive ScienceSociety.Ting Qian and T Florian Jaeger.
2012.
Cue effective-ness in communicatively efficient discourse produc-tion.
Cognitive Science, 36(7):1312?1336.Thomas Schoberth, Jennifer Preece, and Armin Heinzl.2003.
Online communities: A longitudinal analysisof communication activities.
In Proceedings of the36th Annual Hawaii International Conference on Sys-tem Sciences, pages 10?18.
IEEE.Julie C Sedivy, Michael K Tanenhaus, Craig G Cham-bers, and Gregory N Carlson.
1999.
Achieving in-cremental semantic interpretation through contextualrepresentation.
Cognition, 71(2):109?147.Claude E Shannon.
1948.
Bell system tech.
j.
27 (1948)379; ce shannon.
Bell System Tech.
J, 27:623.Nathaniel J Smith and Roger Levy.
2013.
The effectof word predictability on reading time is logarithmic.Cognition, 128(3):302?319.Dan Sperber and Deirdre Wilson.
1986.
Relevance:Communication and Cognition.
Harvard UniversityPress, Cambridge, MA.Tom M Tango, Mitchel G Lichtman, and Andrew E Dol-phin.
2007.
The book: Playing the percentages inbaseball.
Potomac Books, Inc.Steve Whittaker, Loen Terveen, Will Hill, and LynnCherny.
2003.
The dynamics of mass interaction.
InFrom Usenet to CoWebs, pages 79?91.
Springer.1596
