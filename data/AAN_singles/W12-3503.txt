Proceedings of the 1st Workshop on Speech and Multimodal Interaction in Assistive Environments, pages 13?17,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsToward a Virtual Assistant for Vulnerable Users:Designing Careful InteractionRamin YaghoubzadehSociable Agents Group, CITECBielefeld University; PO Box 10013133501 Bielefeld, Germanyryaghoub@techfak.uni-bielefeld.deStefan KoppSociable Agents Group, CITECBielefeld University; PO Box 10013133501 Bielefeld, Germanyskopp@techfak.uni-bielefeld.deAbstractThe VASA project develops a multimodal as-sistive system mediated by a virtual agent thatis intended to foster autonomy of communica-tion and activity management in older peopleand people with disabilities.
Assistive systemsintended for these user groups have to taketheir individual vulnerabilities into account.
Avariety of psychic, emotional as well as behav-ioral conditions can manifest at the same time.Systems that fail to take them into accountmight not only fail at joint tasks, but also riskdamage to their interlocutors.
We identify im-portant conditions and disorders and analyzetheir immediate consequences for the designof careful assistive systems.1 IntroductionIn 2001, the World Health Organization consoli-dated previous taxonomies of somatic and mentalfunctions and the everyday needs of human beingsinto the comprehensive International Classificationof Functioning, Disability and Health ICF (WHO,2001).
Older people, as well as people with im-pairments, often need support from others to satisfythose basic needs, among which are activities relatedto self-care, to mobility, but also to communicationand management of the daily activities and the so-cial environment.
For many older people, a catas-trophic event, most often either a fall or the passingof their spouse, leads to their sudden loss of auton-omy and subsequent submission into stationary care.In the latter case, the loss of their day structure isfrequently the intermediate cause.
The same effectcan be observed for many disabled people of all ageswho must make a transition from assisted living tostationary care.
Here, specialized systems that assistin preserving autonomy in a spectrum of daily needfulfillment can potentially be of great benefit.The present paper introduces the VASA project(?Virtual Assistants and their Social Acceptability?
),which in cooperation with a health-care foundationexamines how both older patients and people withvarious impediments, congenital or acquired, bothin stationary and assisted living, can be providedwith technical assistance to maintain autonomy foras long as possible.
Importantly, we are not focus-ing on physical assistance, but on supporting a per-son?s capability for organizing a social environment(WHO ICF d9205: ?Socializing?)
and managing theday structure generally (d230: ?Carrying out dailyroutine?).
These two tasks turned out to be crucial inour analysis with the health care personnel.
We thusaim to develop an assistive system for (1) managingdaily routine and weekly appointments with the user,and (2) accessing a video call interface for contact-ing acquaintances or care personnel (d360: ?Usingcommunication devices and techniques?
).But how should such a system meet its user, andwhat criteria should guide the system interface de-sign?
Research has shown that older users arefar more likely to employ a ?social?
conversationstyle with a system (Wolters et al, 2009).
TheVASA project explores the use of a ?virtual assis-tant?, an humanoid conversational agent that fea-tures natural-language and touchscreen input andhuman-like communicative behavior (speech, ges-ture; see Fig.
1 for the current running prototype).13Figure 1: The VASA system.
Left side: natural-languagecalendar management; right side: video call interface.In this paper we review work on related systems forolder people and people with disabilities.
We thenargue that beside the general goal of maximizing us-ability for this specific user group, there is an en-hanced vulnerability of these users that calls for spe-cial care in interaction design; we substantiate thisview by an analysis of potential mental conditionsof the prospective users along with discussions ofwhat requirements arise from them.2 Related workGenerally, assistive systems are driven by task rea-soning systems as well as components for human-computer interaction, which can be specialized forolder or disabled persons.
Modern systems thatattempt to provide a ?natural?
interaction are be-ing developed and evaluated, including touch-screenand haptic interfaces and interfaces capable of un-derstanding and generating natural language, all ofthem providing an immediacy between communica-tive intentions and their execution that makes themsuitable especially for users without technical exper-tise, with reduced sensorimotor skills or reduced ca-pability for learning new interaction paradigms, as isfrequently the case with older or impaired persons.The performance of such systems in terms of suit-able operation in interaction, successful task com-pletion, and user-reported satisfaction, has beensubject to systematic evaluation under controlledconditions: The performance of speech recogni-tion systems has been compared between base-lineusers and people with varying degrees of dysarthria(breathiness, dysfluencies, involuntary noises).
Off-the-shelf speech recognition systems have higherfailure rates with dysarthric speakers (Raghaven-dra et al, 2001).
Mildly and moderately dysarthricspeakers can attain a recognition accuracy of 80%in dictation systems, breath exercises and phonationtraining improve performance (Young and Mihai-lidis, 2010).
Vipperla et al (2009) compared speechrecognition for younger and older users, reportingan 11% baseline increase in word error rates for thelatter group, attributed to both acoustic and linguis-tic causes.
The Stardust project succeeded in veryhigh single-word recognition rates on small dictio-naries in patients with severe dysarthria, enablingthem to control their environment by voice (Hawleyet al, 2007).
Fager et al (2010) implemented a mul-timodal prototype system that combined ASR witha word prediction model and a capability to enter aninitial letter, leading to an accuracy of > 80%; not-ing that other conditions, such as a reduced visualfield or ataxia, had to be addressed with technicalsolutions for each individual.
Jian et al (2011) de-signed a system for direction giving for seniors, sug-gesting specific design guidelines addressing typi-cal perceptive, motor, attentive and cognitive impair-ments of older users.
The evaluation of their multi-modal system (speech and touch/image) led to posi-tive results with respect to effectivity, efficiency anduser-reported satisfaction.3 Careful Interaction with VulnerablePeople: AnalysisThe more autonomously assistive systems act, thehigher the potential negative effects they can conse-quentially cause.
This is especially true for roboticsystems, since their extension into the physicalworld entails possible harmful effects if proper rea-soning or safety precautions should be breached byunanticipated events.
But even without physical ma-nipulation, real damage can still be done.
This mightbe due to misunderstandings, leading to wrong as-sumptions in the system, and hence to actions be-ing performed on behalf, but actually to the detri-ment, of the user.
It might, however, also be due tothe wrong things being communicated, or communi-cated in an inappropriate manner, leading to unnec-essary negative appraisal, discomfort, or triggeringof a negative psychic condition in the user.
Whileunlikely to cause damage in an interaction with theaverage healthy interactant, this issue is of the ut-most importance for many potential user groups.14Frail or potentially unstable users are arguablyamong those who can derive the greatest benefitsfrom easily accessible assistive systems, enablingthem to perform tasks which they might else not,or no longer, perform, thus preserving their auton-omy.
However, they are at the same time affected bya multitude of possible cognitive, psychic and emo-tional conditions and behavioral anomalies that canoccur simultaneously.
Each of these conditions en-tails special constraints for interactive systems, ei-ther for the interaction channels, for the contents,or for both.
Several factors have been accountedfor in existing systems: Reduced perceptive faculty(vision, hearing), reduced motor abilities (ataxia),and attention and memory impairments, mitigatedby best-practice rules (Jian et al, 2011).
Attemptsto account for users with mild dementia have beenmade, such as in the ISISEMD project.
Avoidinga deep hierarchy of dialogue structures and provid-ing extra information (repetition, paraphrase) ratherthan maximum parsimony are paramount in cases ofimpaired memory and abstraction faculty, whereaspeople with learning difficulties need a system thatoperates without extensive training (of the user).For systems that strive to provide long-term sup-port to a specific person, adaptation to that per-son is of vital importance ?
by employing usermodels that are adapted either manually or usinglearning algorithms.
System behavior should beadapted both in the content provided as well as theform it is provided in, to enable a working rela-tionship that is both effective and pleasant for theuser (Yaghoubzadeh and Kopp, 2011).
This alonehowever is insufficient; since the vulnerability ofthe actual clientele in VASA is considerable, eachof the encountered mental conditions has to be an-alyzed and additional dialogue constraints be en-forced before autonomous interactions can be per-mitted.
There is a variety of such factors thathave not yet been comprehensively addressed, butmight cause critical damage to some interactantsif not considered.
The following section capturesthe most frequently encountered phenomena, whichwere identified in dialogue with care personnel:?
Depression and Bipolar Disorder: Roughlyten percent of the population suffer from de-pression at some point in their lives.
Depres-sion increases the risk for suicide ten- to twen-tyfold (Sadock et al, 2007).
Bipolar disor-der manifests in episodic effects, where sen-sations of racing thoughts and heightened ac-tivity (mania) and listlessness and social pas-sivity (severe depression) alternate or occur si-multaneously; depressive relapses in particularare points of vulnerability (Hill and Shepherd,2009).
There are successes in detecting depres-sive states from facial and voice cues at > 80%rate (Cohn et al, 2009).
A good practice isto employ mitigation strategies when breakingbad news to the user (Brown and Levinson,1987; Fraser, 1980), e.g.
by presenting obliga-tions as options (Williams, 2011), or present-ing the ?bad news?
simultaneously with ?goodnews?.
We provide for discussion another re-quirement for interactive systems in this case:The system must not produce ambiguously in-terpretable answers ?
consider a catastrophicanswer of ?okay?
as an affirmative response toa wrongly parsed utterance that was actually anexpression of intent for suicide, a frequent phe-nomenon with risk patients (Kelly, 2009).?
Borderline Personality Disorder: This typeof disorders, characterized by emotional insta-bility, can lead to anxiety, social insecurity anddepression, but also inappropriate outbursts ofanger.
Anger management techniques are em-ployed to inhibit the expression of such anger(Swaffer and Hollin, 2009).
An assistive sys-tem should be able to cope with impulses ofanger, and as a bare minimum interrupt the in-teraction and offer to resume it at a later point.The EmoVoice system, for instance, can clas-sify emotional features in natural language withgood rates (Vogt et al, 2008), and could beused to identify anger.?
Epilepsy: Patients with acquired brain injuriesfrequently suffer from epilepsy.
Even short (pe-tit mal) epileptic seizures can lead to tempo-rary absence and periods of confusion and dis-orientation (APA, 2000).
In such a situation,the patient may utter irrational sentences or besilent altogether.
An assistive system should beable to detect these irrational deviations from15the course of conversation, and fill the user inagain, abort the conversation, or call for help.?
Panic: Proneness to panic attacks can resultfrom a multitude of afflictions and is hard topredict.
In the event of a panicking interactant,the system should not take steps that could fur-ther exacerbate the situation.
According to lit-erature (Gournay and Denford, 2009), panic at-tacks are generally unable to do any real harmand subside quickly.
Therefore, passivity fromthe system?s side, in a neutral mode, is the mini-mal appropriate behavior.
Panicking people aremost likely not able to perform in interaction assuccessfully as usual ?
systems that should stillbe operable by a user in this situation must pro-vide minimalistic shortcuts to essential features(i.e.
a ?panic button?
for emergencies).?
Anxiety: Special care must be taken in the de-sign of systems aimed at people with socialanxiety.
Interactants might be hesitant to opena conversation even with an artificial system.The system could take the initiative by simplyopening with a short utterance about the taskdomain (Williams, 2011).?
Phobias and Impulse Control Disorders:Phobic disorders and obsessive-compulsivedisorders can be triggered by environmentalcues (Gournay and Denford, 2009).
User inter-faces have to take this into account, and avoidpresenting stimuli that could act as potentialtriggers (e.g.
people with an insect phobiashould neither be presented with pictures of in-sects, nor their verbal mention).
The same pre-cautions are valid in the case of addictions.Any interactive system, and in particular systemsthat do not only provide information but can also bemade to perform tasks autonomously on behalf ofthe user, must be designed with all possible afflic-tions of all possible users in mind, not only as a wiselegal precaution, but also as an ethical obligation tothe designer.
We argue that, quite unlike the ?bestpractices?
of user interface design, there is no degreeof optionality to the implementation of the aboveconstraints and countermeasures, but that it must beperformed with all musterable diligence.
Some con-straints are especially hard to meet in open-worldsystems (e.g.
with free Internet access), since thecontents presented are harder to predict.Note that the set of conditions presented aboveis by no means comprehensive.
For instance, wehave, for now, altogether omitted an incorporationof autism-spectrum disorders or of functional psy-choses such as schizophrenia, paraphrenia and para-noia ?
which are not uncommon in the older popu-lation (Ashton and Keady, 2009).4 SummaryThe VASA project is developing a multimodalnatural-language agent-mediated assistance systemfor older people and patients with disabilities forenhancing their autonomy in the everyday tasksof communication and activity management.
Theclientele is afflicted with a variety of cognitive, psy-chic, and emotional conditions that have to be dealtwith with extreme care and entail a necessity for spe-cific safety mechanisms which will be implementedfor VASA in coordination with the care person-nel.
We attempted to identify common conditionsof older and impaired patients that should be con-sidered and resolved in any assistive system (or in-deed any autonomous interactive system) that mightcommunicate with them.
Factors that could leadto a detrimental outcome of such an interaction in-clude depression, emotional instability, disorienta-tion, panic, anxiety and phobia.
Some constraintson the design rationale for such systems can pro-vide a mitigation of those risks: avoiding ambigu-ity in the system?s utterances, coping with anger, ir-rationality and panic by employing appropriate sys-tem responses, capability for system-side initiative,and preventing inadvertent stimulation of disorders.Since the field of potential interactants for genericassistive systems is vast, as any inspection of a largerhealth-care institution will show, more discussion inthe research community should aim at establishing astable ontology of their special needs and the rami-fications for the design of careful assistive systems.AcknowledgmentsThis research is supported by the DeutscheForschungsgemeinschaft (DFG) in the Center ofExcellence in Cognitive Interaction Technology(CITEC).16ReferencesAmerican Psychiatric Association.
2000.
Diagnosticand Statistical Manual of Mental Disorders DSM-IV-TR, Fourth Edition.
American Psychiatric Publishing,Inc., Arlington, VA.Peter Ashton and John Keady.
2009.
Mental disordersof older people.
Newell & Gournay (eds.
), MentalHealth Nursing: an Evidence-Based Approach, 341?370.
Churchill Livingstone, Philadelphia, PA.Paul Brown and Stephen Levinson.
1987.
Politeness.Some Universals in Language Usage.
Cambridge Uni-versity Press, Cambridge.Jeffrey F. Cohn, Tomas Simon Kruez, Iain Matthews,Ying Yang, Minh Hoai Nguyen, MargaraTejera Padilla, Feng Zhou, and Fernando de la Torre.2009.
Detecting Depression from Facial Actions andVocal Prosody.
Proceedings of the 3rd InternationalConference on Affective Computing and IntelligentInteraction and Workshops (ACII 2009), 1?7.
IEEE,Amsterdam.Susan K. Fager, David R. Beukelman, Tom Jakobs, andJohn-Paul Hosom.
2010.
Evaluation of a SpeechRecognition Prototype for Speakers with Moderateand Severe Dysarthria: A Preliminary Report Aug-mentative and Alternative Communication, 26(4):267-277.Bruce Fraser.
1980.
Conversational mitigation.
Journalof Pragmatics, 4:341?350.Kevin Gournay and Lindsay Denford.
2009.
Pho-bias and Rituals.
Newell & Gournay (eds.
), MentalHealth Nursing: an Evidence-Based Approach, 207?224.
Churchill Livingstone, Philadelphia, PA.Mark S. Hawley, Pam Enderby, Phil Green, Stuart Cun-ningham, Simon Brownsell, James Carmichael, MarkParker, Athanassios Hatzis, Peter ONeill, and RebeccaPalmer.
2007.
A speech-controlled environmentalcontrol system for people with severe dysarthria.
Med-ical Engineering & Physics, 29(5):586?593.Robert Gareth Hill and Geoff Shepherd.
2009.
Disordersof Mood: Depression and Mania.
Newell & Gournay(eds.
), Mental Health Nursing: an Evidence-BasedApproach, 165?185.
Churchill Livingstone, Philadel-phia, PA.Cui Jian, Nadine Sasse, Nicole von Steinbu?chel-Rheinwall, Frank Schafmeister, Hui Shi, CarstenRachuy, and Holger Schmidt.
2011.
Towards effec-tive, efficient and elderly-friendly multimodal interac-tion.
Proceedings of the 4th International Conferenceon Pervasive Technologies Related to Assistive Envi-ronments (PETRA 2011), article 45, 1?8.
ACM, NewYork, NY.Sarah Kelly.
2009.
Suicide and Self-Harm.
Newell &Gournay (eds.
), Mental Health Nursing: an Evidence-Based Approach, 187?206.
Churchill Livingstone,Philadelphia, PA.Parimala Raghavendra, Elisabet Rosengren, and SheriHunnicutt.
2001.
An investigation of different de-grees of dysarthric speech as input to speaker-adaptiveand speaker-dependent recognition systems.
Augmen-tative and Alternative Communication, 17(4):265-275.Benjamin J. Sadock, Harold I. Kaplan, and Virginia A.Sadock.
2007.
Kaplan & Sadock?s Synopsis of Psychi-atry: Behavioral Sciences/Clinical Psychiatry.
Lip-pincott Williams & Wilkins, Philadelphia.Tracey Swaffer and Clive R. Hollin.
2009.
Anger andImpulse Control.
Newell & Gournay (eds.
), MentalHealth Nursing: an Evidence-Based Approach, 267?289.
Churchill Livingstone, Philadelphia, PA.Ravichander Vipperla, Maria Wolters, Kallirroi Georgila,and Steve Renals.
2009.
Speech input from olderusers in smart environments: Challenges and perspec-tives.
HCI (6): Universal Access in Human-ComputerInteraction, Intelligent and Ubiquitous Interaction En-vironments , LNCS 5615:117?126.
Springer, Heidel-berg.Thurid Vogt, Elisabeth Andre?, and Nikolaus Bee.
2008.EmoVoice - A framework for online recognition ofemotions from voice.
Proceedings of the 4th IEEEtutorial and research workshop on Perception and In-teractive Technologies for Speech-Based Systems (PIT2008), 188?199.
Springer, Heidelberg.Val Williams.
2011.
Disability and discourse : analysinginclusive conversation with people with intellectualdisabilities.
Wiley-Blackwell, Chichester, West Sus-sex / Malden, MA.World Health Organization.
2001. International Clas-sification of Functioning, Disability and Health: ICF,WHO, Geneva, Switzerland.Maria Wolters, Kallirroi Georgila, Johanna D. Moore,and Sarah E. MacPherson.
2009.
Being Old Doesn?tMean Acting Old: How Older Users Interact with Spo-ken Dialog Systems.
ACM Transactions on AccessibleComputing (TACCESS), 2(1):1?39.Ramin Yaghoubzadeh and Stefan Kopp.
2011.
Creat-ing familiarity through adaptive behavior generationin human-agent interaction.
Proceedings of the 11thInternational Conference on Intelligent Virtual Agents(IVA 2011), LNCS(LNAI) 6895:195?201.
Springer,Heidelberg.Victoria Young and Alex Mihailidis.
2010.
Difficulties inAutomatic Speech Recognition of Dysarthric Speakersand Implications for Speech-Based Applications Usedby the Elderly: A Literature Review.
Assistive Tech-nology, 22(2):99?112.17
