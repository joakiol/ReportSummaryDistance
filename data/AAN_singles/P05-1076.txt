Proceedings of the 43rd Annual Meeting of the ACL, pages 614?621,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAutomatic Acquisition of Adjectival Subcategorization from CorporaJeremy Yallop?, Anna Korhonen, and Ted BriscoeComputer LaboratoryUniversity of Cambridge15 JJ Thomson AvenueCambridge CB3 OFD, UKyallop@cantab.net, {Anna.Korhonen, Ted.Briscoe}@cl.cam.ac.ukAbstractThis paper describes a novel systemfor acquiring adjectival subcategorizationframes (SCFs) and associated frequencyinformation from English corpus data.The system incorporates a decision-treeclassifier for 30 SCF types which testsfor the presence of grammatical relations(GRs) in the output of a robust statisti-cal parser.
It uses a powerful pattern-matching language to classify GRs intoframes hierarchically in a way that mirrorsinheritance-based lexica.
The experimentsshow that the system is able to detect SCFtypes with 70% precision and 66% recallrate.
A new tool for linguistic annotationof SCFs in corpus data is also introducedwhich can considerably alleviate the pro-cess of obtaining training and test data forsubcategorization acquisition.1 IntroductionResearch into automatic acquisition of lexical in-formation from large repositories of unannotatedtext (such as the web, corpora of published text,etc.)
is starting to produce large scale lexical re-sources which include frequency and usage infor-mation tuned to genres and sublanguages.
Suchresources are critical for natural language process-ing (NLP), both for enhancing the performance of?Part of this research was conducted while this author wasat the University of Edinburgh Laboratory for Foundations ofComputer Science.state-of-art statistical systems and for improving theportability of these systems between domains.One type of lexical information with particularimportance for NLP is subcategorization.
Accessto an accurate and comprehensive subcategoriza-tion lexicon is vital for the development of success-ful parsing technology (e.g.
(Carroll et al, 1998b),important for many NLP tasks (e.g.
automatic verbclassification (Schulte im Walde and Brew, 2002))and useful for any application which can benefitfrom information about predicate-argument struc-ture (e.g.
Information Extraction (IE) (Surdeanu etal., 2003)).The first systems capable of automatically learn-ing a small number of verbal subcategorizationframes (SCFs) from English corpora emerged overa decade ago (Brent, 1991; Manning, 1993).
Subse-quent research has yielded systems for English (Car-roll and Rooth, 1998; Briscoe and Carroll, 1997; Ko-rhonen, 2002) capable of detecting comprehensivesets of SCFs with promising accuracy and demon-strated success in application tasks (e.g.
(Carroll etal., 1998b; Korhonen et al, 2003)), besides systemsfor a number of other languages (e.g.
(Kawahara andKurohashi, 2002; Ferrer, 2004)).While there has been considerable research intoacquisition of verb subcategorization, we are notaware of any systems built for adjectives.
Al-though adjectives are syntactically less multivalentthan verbs, and although verb subcategorization dis-tribution data appears to offer the greatest potentialboost in parser performance, accurate and compre-hensive knowledge of the many adjective SCFs canimprove the accuracy of parsing at several levels614(from tagging to syntactic and semantic analysis).Automatic SCF acquisition techniques are particu-larly important for adjectives because extant syntaxdictionaries provide very limited coverage of adjec-tive subcategorization.In this paper we propose a method for automaticacquisition of adjectival SCFs from English corpusdata.
Our method has been implemented using adecision-tree classifier which tests for the presenceof grammatical relations (GRs) in the output of theRASP (Robust Accurate Statistical Parsing) system(Briscoe and Carroll, 2002).
It uses a powerful task-specific pattern-matching language which enablesthe frames to be classified hierarchically in a waythat mirrors inheritance-based lexica.
As reportedlater, the system is capable of detecting 30 SCFswith an accuracy comparable to that of best state-of-art verbal SCF acquisition systems (e.g.
(Korhonen,2002)).Additionally, we present a novel tool for linguisticannotation of SCFs in corpus data aimed at alleviat-ing the process of obtaining training and test data forsubcategorization acquisition.
The tool incorporatesan intuitive interface with the ability to significantlyreduce the number of frames presented to the userfor each sentence.We discuss adjectival subcategorization in sec-tion 2 and introduce the system for SCF acquisitionin section 3.
Details of the annotation tool and theexperimental evaluation are supplied in section 4.Section 5 provides discussion on our results and fu-ture work, and section 6 summarises the paper.2 Adjectival SubcategorizationAlthough the number of SCF types for adjectivesis smaller than the number reported for verbs(e.g.
(Briscoe and Carroll, 1997)), adjectives never-theless exhibit rich syntactic behaviour.
Besides thecommon attributive and predicative positions thereare at least six further positions in which adjec-tives commonly occur (see figure 1).
Adjectives inpredicative position can be further classified accord-ing to the nature of the arguments with which theycombine ?
finite and non-finite clauses and nounphrases, phrases with and without complementisers,etc.
?
and whether they occur as subject or ob-ject.
Additional distinctions can be made concern-Attributive ?The young man?Predicative ?He is young?Postpositive ?Anyone [who is] young can do it?Predeterminer ?such a young man?
;?so young a man?Fused modifier-head ?the younger of them?
; ?the young?Predicative adjunct ?he died young?Supplementive clause ?Young, he was plainin appearance?Contingent clause ?When young, he was lonely?Figure 1: Fundamental adjectival framesing such features as the mood of the complement(mandative, interrogative, etc.
), preferences for par-ticular prepositions and whether the subject is extra-posed.Even ignoring preposition preference, there aremore than 30 distinguishable adjectival SCFs.
Somefairly extensive frame sets can be found in large syn-tax dictionaries, such as COMLEX (31 SCFs) (Wolffet al, 1998) and ANLT (24 SCFs) (Boguraev et al,1987).
While such resources are generally accu-rate, they are disappointingly incomplete: none ofthe proposed frame sets in the well-known resourcessubsumes the others, the coverage of SCF types forindividual adjectives is low, and (accurate) informa-tion on the relative frequency of SCFs for each ad-jective is absent.The inadequacy of manually-created dictionariesand the difficulty of adequately enhancing and main-taining the information by hand was a central moti-vation for early research into automatic subcatego-rization acquisition.
The focus heretofore has re-mained firmly on verb subcategorization, but this isnot sufficient, as countless examples show.
Knowl-edge of adjectival subcategorization can yield fur-ther improvements in tagging (e.g.
distinguishingbetween ?to?
as an infinitive marker and as a truepreposition), parsing (e.g.
distinguishing betweenPP-arguments and adjuncts), and semantic analysis.For example, if John is both easy and eager to pleasethen we know that he is the recipient of pleasure inthe first instance and desirous of providing it in thesecond, but a computational system cannot deter-mine this without knowledge of the subcategoriza-tion of the two adjectives.
Likewise, a natural lan-guage generation system can legitimately apply theextraposition transformation to the first case, but notto the second: It is ?easy to please John?, but not615?eager?
to do so, at least if ?it?
be expletive.
Similarexamples abound.Many of the difficulties described in the litera-ture on acquiring verb subcategorization also arisein the adjectival case.
The most apparent is datasparsity: among the 100M-word British NationalCorpus (BNC) (Burnard, 1995), the RASP tools find124,120 distinct adjectives, of which 70,246 occuronly once, 106,464 fewer than ten times and 119,337fewer than a hundred times.
There are fewer than1,000 adjectives in the corpus which have more than1,000 occurrences.
Both adjective and SCF frequen-cies have Zipfian distributions; consequently, eventhe largest corpora may contain only single instancesof a particular adjective-SCF combination, which isgenerally insufficient for classification.3 Description of the SystemBesides focusing on adjectives, our approach to SCFacquisition differs from earlier work in a numberof ways.
A common strategy in existing systems(e.g.
(Briscoe and Carroll, 1997)) is to extract SCFsfrom parse trees, introducing an unnecessary depen-dence on the details of a particular parser.
In our ap-proach the patterns are extracted from GRs ?
repre-sentations of head-complement relations which aredesigned to be largely parser-independent ?
mak-ing the techniques more widely applicable and al-lowing classification to operate at a higher level.Further, most existing systems work by classifyingcorpus occurrences into individual, mutually inde-pendent SCFs.
We adopt instead a hierarchical ap-proach, viewing frames that share features as de-scendants of a common parent frame.
The benefitsare severalfold: specifying each feature only oncemakes the system both more efficient and easier tounderstand and maintain, and the multiple inheri-tance hierarchy reflects the hierarchy of lexical typesfound in modern grammars where relationships be-tween similar frames are represented explicitly1 .Our acquisition process consists of two mainsteps: 1) extracting GRs from corpus data, and 2)feeding the GRs as input to the classifier which in-crementally matches parts of the GR sets to decidewhich branches of a decision-tree to follow.
The1Compare the cogent argument for a inheritance-based lexi-con in (Flickinger and Nerbonne, 1992), much of which can beapplied unchanged to the taxonomy of SCFs.dependentmod arg mod arg aux conjsubj or dobjncmod xmod cmod detmodsubj compncsubj xsubj csubj obj clausaldobj obj2 iobj xcomp ccompFigure 2: The GR hierarchy used by RASPleaves of the tree correspond to SCFs.
The details ofthese two steps are provided in the subsequent sec-tions, respectively2 .3.1 Obtaining Grammatical RelationsAttempts to acquire verb subcategorization havebenefited from increasingly sophisticated parsers.We have made use of the RASP toolkit (Briscoe andCarroll, 2002) ?
a modular statistical parsing sys-tem which includes a tokenizer, tagger, lemmatiser,and a wide-coverage unification-based tag-sequenceparser.
The parser has several modes of operation;we invoked it in a mode in which GRs with asso-ciated probabilities are emitted even when a com-plete analysis of the sentence could not be found.
Inthis mode there is wide coverage (over 98% of theBNC receives at least a partial analysis (Carroll andBriscoe, 2002)) which is useful in view of the in-frequent occurrence of some of the SCFs, althoughcombining the results of competing parses may insome cases result in an inconsistent or misleadingcombination of GRs.The parser uses a scheme of GRs between lemma-tised lexical heads (Carroll et al, 1998a; Briscoe etal., 2002).
The relations are organized as a multiple-inheritance subsumption hierarchy where each sub-relation extends the meaning, and perhaps the argu-ment structure, of its parents (figure 2).
For descrip-tions and examples of each relation, see (Carroll etal., 1998a).The dependency relationships which the GRs em-body correspond closely to the head-complement2In contrast to almost all earlier work, there was no filteringstage involved in SCF acquisition.
The classifier was designedto operate with high precision, so filtering was less necessary.61626666664SUBJECT NP 1 ,ADJ-COMPS*PP"PVAL ?for?NP 3#,VP2664MOOD to-infinitiveSUBJECT 3OMISSION 13775+37777775Figure 3: Feature structure for SCFadj-obj-for-to-inf(|These:1_DD2| |example+s:2_NN2| |of:3_IO||animal:4_JJ| |senses:5_NN2| |be+:6_VBR||relatively:7_RR| |easy:8_JJ| |for:9_IF||we+:10_PPIO2| |to:11_TO| |comprehend:12_VV0|)...xcomp(_ be+[6] easy:[8])xmod(to[11] be+[6] comprehend:[12])ncsubj(be+[6] example+s[2] _)ncmod(for[9] easy[8] we+[10])ncsubj(comprehend[12] we+[10], _)...Figure 4: GRs from RASP for adj-obj-for-to-infstructure which subcategorization acquisition at-tempts to recover, which makes GRs ideal input tothe SCF classifier.
Consider the arguments of ?easy?in the sentence:These examples of animal senses are rel-atively easy for us to comprehend as theyare not too far removed from our own ex-perience.According to the COMLEX classification, this is anexample of the frame adj-obj-for-to-inf, shownin figure 3, (using AVM notation in place of COMLEXs-expressions).
Part of the output of RASP for thissentence (the full output includes 87 weighted GRs)is shown in figure 43.Each instantiated GR in figure 4 corresponds toone or more parts of the feature structure in figure3.
xcomp( be[6] easy[8]) establishes be[6] asthe head of the VP in which easy[8] occurs as acomplement.
The first (PP)-complement is ?for us?,as indicated by ncmod(for[9] easy[8] we+[10]),with ?for?
as PFORM and we+ (?us?)
as NP.
Thesecond complement is represented by xmod(to[11]be+[6] comprehend[12]): a to-infinitive VP.
TheNP headed by ?examples?
is marked as the subjectof the frame by ncsubj(be[6] examples[2]), andncsubj(comprehend[12] we+[10]) corresponds tothe coindexation marked by 3 : the subject of the3The format is slightly more complicated than that shownin (Carroll et al, 1998a): each argument that corresponds to aword consists of three parts: the lexeme, the part of speech tag,and the position (index) of the word in the sentence.xcomp(_, [*;1;be-verb], ?
)xmod([to;*;to], 1, [*;2;vv0])ncsubj(1, [*;3;noun/pronoun], _)ncmod([for;*;if], ?, [*;4;noun/pronoun])ncsubj(2, 4)Figure 5: A pattern to match the frameadj-obj-for-to-infVP is the NP of the PP.
The only part of the featurestructure which is not represented by the GRs is coin-dexation between the omitted direct object 1 of theVP-complement and the subject of the whole clause.3.2 SCF Classifier3.2.1 SCF FramesWe used for our classifier a modified version ofthe fairly extensive COMLEX frameset, including 30SCFs.
The COMLEX frameset includes mutually in-consistent frames, such as sentential complementwith obligatory complementiser that and sententialcomplement with optional that.
We modified theframeset so that an adjective can legitimately instan-tiate any combination of frames, which simplifiesclassification.
We also added simple-predicativeand attributive SCFs to the set, since these ac-count for a substantial proportion of frame instances.Finally, frames which could only be distinguishedby information not retained in the GRs scheme of thecurrent version of the shallow parser were merged(e.g.
the COMLEX frames adj-subj-to-inf-rs(?She was kind to invite me?)
and adj-to-inf (?Shewas able to climb the mountain?
)).3.2.2 ClassifierThe classifier operates by attempting to match theset of GRs associated with each sentence against var-ious patterns.
The patterns were developed by acombination of knowledge of the GRs and examin-ing a set of training sentences to determine which re-lations were actually emitted by the parser for eachSCF.
The data used during development consistedof the sentences in the BNC in which one of the 23adjectives4 given as examples for SCFs in (Macleod4The adjectives used for training were: able, anxious, ap-parent, certain, convenient, curious, desirable, disappointed,easy, happy, helpful, imperative, impractical, insistent, kind,obvious, practical, preferable, probable, ridiculous, unaware,uncertain and unclear.617et al, 1998) occur.In our pattern matching language a pattern is adisjunction of sets of partially instantiated GRs withlogic variables (slots) in place of indices, augmentedby ordering constraints that restrict the possible in-stantiations of slots.
A match is considered success-ful if the set of GRs can be unified with any of thedisjuncts.
Unification of a sentence-relation and apattern-relation occurs when there is a one-to-onecorrespondence between sentence elements and pat-tern elements that includes a mapping from slots toindices (a substitution), and where atomic elementsin corresponding positions share a common subtype.Figure 5 shows a pattern for matching the SCFadj-obj-for-to-inf.
For a match to suc-ceed there must be GRs associated with the sen-tence that match each part of the pattern.
Each ar-gument matches either anything at all (*), the ?cur-rent?
adjective (?
), an empty GR argument ( ), a[word;id;part-of-speech] 3-tuple or a nu-meric id.
In a successful match, equal ids in differentparts of the pattern must match the same word posi-tion, and distinct ids must match different positions.The various patterns are arranged in a tree, wherea parent node contains the elements common to allof its children.
This kind of once-only representa-tion of particular features, together with the succes-sive refinements provided by child nodes reflects theorganization of inheritance-based lexica.
The inher-itance structure naturally involves multiple inheri-tance, since each frame typically includes multiplefeatures (such as the presence of a to-infinitivecomplement or an expletive subject argument) inher-ited from abstract parent classes, and each feature isinstantiated in several frames.The tree structure also improves the efficiency ofthe pattern matching process, which then occurs instages: at each matching node the classifier attemptsto match a set of relations with each child patternto yield a substitution that subsumes the substitutionresulting from the parent match.Both the patterns and the pattern language itselfunderwent successive refinements after investigationof the performance on training data made it increas-ingly clear what sort of distinctions were useful toexpress.
The initial pattern language had no slots; itwas easy to understand and implement, but insuffi-ciently expressive.
The final refinement was the ad-unspecified 285 improbable 350unsure 570 doubtful 1147generous 2052 sure 13591difficult 18470 clear 19617important 33303Table 1: Test adjectives and frequencies in the BNCdition of ordering constraints between instantiatedslots, which are indispensable for detecting, e.g., ex-traposition.4 Experimental Evaluation4.1 DataIn order to evaluate the system we selected a set of9 adjectives which between them could instantiateall of the frames.
The test set was intentionally keptfairly small for these first experiments with adjec-tival SCF acquisition so that we could carry out athorough evaluation of all the test instances.
We ex-cluded the adjectives used during development andadjectives with fewer than 200 instances in the cor-pus.
The final test set, together with their frequen-cies in the tagged version of the BNC, is shown in ta-ble 1.
For each adjective we extracted 200 sentences(evenly spaced throughout the BNC) which we pro-cessed using the SCF acquisition system described inthe previous section.4.2 Method4.2.1 Annotation Tool and Gold StandardOur gold standard was human-annotated data.Two annotators associated a SCF with each sen-tence/adjective pair in the test data.
To alleviate theprocess we developed a program which first uses re-liable heuristics to reduce the number of SCF choicesand then allows the annotator to select the preferredchoice with a single mouse click in a browser win-dow.
The heuristics reduced the average numberof SCFs presented alongside each sentence from 30to 9.
Through the same browser interface we pro-vided annotators with information and instructions(with links to COMLEX documentation), the abilityto inspect and review previous decisions and deci-sion summaries5 and an option to record that partic-5The varying number of SCFs presented to the user and theability to revisit previous decisions precluded accurate measure-618Figure 6: Sample classification screen for web an-notation toolular sentences could not be classified (which is use-ful for further system development, as discussed insection 5).
A screenshot is shown in figure 6.
Theresulting annotation revealed 19 of the 30 SCFs inthe test data.4.2.2 Evaluation MeasuresWe use the standard evaluation metrics: type andtoken precision, recall and F-measure.
Token recallis the proportion of annotated (sentence, frame) pairsthat the system recovered correctly.
Token precisionis the proportion of classified (sentence, frame) pairsthat were correct.
Type precision and type recall areanalogously defined for (adjective, frame) pairs.
TheF-measure (?
= 1) is a weighted combination ofprecision and recall.4.3 ResultsRunning the system on the test data yielded the re-sults summarised in table 2.
The greater expres-siveness of the final pattern language resulted in aclassifier that performed better than the ?regression?versions which ignored either ordering constraints,or both ordering constraints and slots.
As expected,removing features from the classifier translated di-rectly into degraded accuracy.
The performance ofthe best classifier (67.8% F-measure) is quite simi-lar to that of the best current verbal SCF acquisitionsystems (e.g.
(Korhonen, 2002)).Results for individual adjectives are given in table3.
The first column shows the number of SCFs ac-quired for each adjective, ranging from 2 for unspec-ments of inter-annotator agreement, but this was judged less im-portant than the enhanced ease of use arising from the reducedset of choices.Type performanceSystem Precision Recall FFinal 69.6 66.1 67.8No order constraints 67.3 62.7 64.9No slots 62.7 51.4 56.5Token performanceSystem Precision Recall FFinal 63.0 70.5 66.5No order constraints 58.8 68.3 63.2No slots 58.3 67.6 62.6Table 2: Overall performance of the classifier and ofregression systems with restricted pattern-matchingified to 11 for doubtful.
Looking at the F-measure,the best performing adjectives are unspecified, diffi-cult and sure (80%) and the worst performing unsure(50%) and and improbable (60%).There appears to be no obvious connection be-tween performance figures and the number of ac-quired SCF types; differences are rather due to thedifficulty of detecting individual SCF types ?
an is-sue directly related to data sparsity.Despite the size of the BNC, 5 SCFs were notseen at all, either for the test adjectives or for anyothers.
Frames involving to-infinitive complementswere particularly rare: 4 such SCFs had no exam-ples in the corpus and a further 3 occurred 5 times orfewer in the test data.
It is more difficult to developpatterns for SCFs that occur infrequently, and the fewinstances of such SCFs are unlikely to include a setof GRs that is adequate for classification.
The ef-fect on the results was clear: of the 9 SCFs whichthe classifier did not correctly recognise at all, 4 oc-curred 5 times or fewer in the test data and a further2 occurred 5?10 times.The most common error made by the clas-sifier was to mistake a complex frame (e.g.adj-obj-for-to-inf, or to-inf-wh-adj)for simple-predicative, which subsumes allsuch frames.
This occurred whenever the GRs emit-ted by the parser failed to include any informationabout the complements of the adjective.5 DiscussionData sparsity is perhaps the greatest hindrance bothto recovering adjectival subcategorization and tolexical acquisition in general.
In the future, we planto carry out experiments with a larger set of adjec-619Adjective SCFs Precision Recall F-measureunspecified 2 66.7 100.0 80.0generous 3 60.0 100.0 75.0improbable 5 60.0 60.0 60.0unsure 6 50.0 50.0 50.0important 7 55.6 71.4 62.5clear 8 83.3 62.5 71.4difficult 8 85.7 75.0 80.0sure 9 100.0 66.7 80.0doubtful 11 66.7 54.5 60.0Table 3: SCF count and classifier performance foreach adjective.tives using more data (possibly from several corporaand the web) to determine how severe this problemis for adjectives.
One possible way to address theproblem is to smooth the acquired SCF distributionsusing SCF ?back-off?
(probability) estimates basedon lexical classes of adjectives in the manner pro-posed by (Korhonen, 2002).
This helps to correct theacquired distributions and to detect low frequencyand unseen SCFs.However, our experiment also revealed otherproblems which require attention in the future.One such is that GRs output by RASP (the ver-sion we used in our experiments) do not re-tain certain distinctions which are essential fordistinguishing particular SCFs.
For example,a sentential complement of an adjective witha that-complementiser should be annotated withccomp(that, adjective, verbal-head), but thisrelation (with that as the type argument) does notoccur in the parsed BNC.
As a consequence the clas-sifier is unable to distinguish the frame.Another problem arises from the fact that our cur-rent classifier operates on a predefined set of SCFs.The COMLEX SCFs, from which ours were derived,are extremely incomplete.
Almost a quarter (477 of1931) of sentences were annotated as ?undefined?.For example, while there are SCFs for sententialand infinitival complement in subject position withwhat6, there is no SCF for the case with a what-prefixed complement in object position, where thesubject is an NP.
The lack is especially perplexing,because COMLEX does include the correspondingSCFs for verbs.
There is a frame for ?He wondered6(adj-subj-what-s: ?What he will do is uncertain?
;adj-subj-what-to-inf: ?What to do was unclear?
), to-gether with the extraposed versions (extrap-adj-what-sand extrap-adj-what-to-inf).what to do?
(what-to-inf), but none for ?He wasunsure what to do?.While we can easily extend the current frame-set by looking for further SCF types from dictio-naries and from among the corpus occurrences la-belled by our annotators as unclassified, we also planto extend the classifier to automatically induce pre-viously unseen frames from data.
A possible ap-proach is to use restricted generalization on sets ofGRs to group similar sentences together.
General-ization (anti-unification) is an intersection operationon two structures which retains the features commonto both; generalization over the sets of GRs associ-ated with the sentences which instantiate a particularframe can produce a pattern such as we used for clas-sification in the experiments described above.
Thisapproach also offers the possibility of associatingconfidence levels with each pattern, correspondingto the degree to which the generalized pattern cap-tures the features common to the members of theassociated class.
It is possible that frames couldbe induced by grouping sentences according to the?best?
(e.g.
most information-preserving) general-izations for various combinations, but it is not clearhow this can be implemented with acceptable effi-ciency.The hierarchical approach described in this papermay also helpful in the discovery of new frames:missing combinations of parent classes can be ex-plored readily, and it may be possible to combine thevarious features in an SCF feature structure to gen-erate example sentences which a human could theninspect to judge grammaticality.6 ConclusionWe have described a novel system for automati-cally acquiring adjectival subcategorization and as-sociated frequency information from corpora, alongwith an annotation tool for producing training andtest data for the task.
The acquisition system, whichis capable of distinguishing 30 SCF types, performssophisticated pattern matching on sets of GRs pro-duced by a robust statistical parser.
The informa-tion provided by GRs closely matches the structurethat subcategorization acquisition seeks to recover.The figures reported demonstrate the feasibility ofthe approach: our classifier achieved 70% type pre-620cision and 66% type recall on the test data.
The dis-cussion suggests several ways in which the systemmay be improved, refined and extended in the fu-ture.AcknowledgementsWe would like to thank Ann Copestake for all herhelp during this work.ReferencesB.
Boguraev, J. Carroll, E. Briscoe, D. Carter, andC.
Grover.
1987.
The derivation of a grammatically-indexed lexicon from the Longman Dictionary of Con-temporary English.
In Proceedings of the 25th AnnualMeeting of the Association for Computational Linguis-tics, pages 193?200, Stanford, CA.Michael R. Brent.
1991.
Automatic acquisition of sub-categorization frames from untagged text.
In Meet-ing of the Association for Computational Linguistics,pages 209?214.E.
J. Briscoe and J. Carroll.
1997.
Automatic Extractionof Subcategorization from Corpora.
In Proceedingsof the 5th Conference on Applied Natural LanguageProcessing, Washington DC, USA.E.
Briscoe and J. Carroll.
2002.
Robust accurate sta-tistical annotation of general text.
In Proceedings ofthe Third International Conference on Language Re-sources and Evaluation, pages 1499?1504, Las Pal-mas, Canary Islands, May.E.
Briscoe, J. Carroll, Jonathan Graham, and Ann Copes-take.
2002.
Relational evaluation schemes.
In Pro-ceedings of the Beyond PARSEVAL Workshop at the3rd International Conference on Language Resourcesand Evaluation, pages 4?8, Las Palmas, Gran Canaria.Lou Burnard, 1995.
The BNC Users Reference Guide.British National Corpus Consortium, Oxford, May.J.
Carroll and E. Briscoe.
2002.
High precision extrac-tion of grammatical relations.
In Proceedings of the19th International Conference on Computational Lin-guistics, pages 134?140, Taipei, Taiwan.Glenn Carroll and Mats Rooth.
1998.
Valence inductionwith a head-lexicalized pcfg.
In Proc.
of the 3rd Con-ference on Empirical Methods in Natural LanguageProcessing, Granada, Spain.J.
Carroll, E. Briscoe, and A. Sanfilippo.
1998a.
Parserevaluation: a survey and a new proposal.
In Proceed-ings of the 1st International Conference on LanguageResources and Evaluation, pages 447?454, Granada,Spain.John Carroll, Guido Minnen, and Edward Briscoe.1998b.
Can Subcategorisation Probabilities Helpa Statistical Parser?
In Proceedings of the 6thACL/SIGDAT Workshop on Very Large Corpora, pages118?126, Montreal, Canada.
Association for Compu-tational Linguistics.Eva Esteve Ferrer.
2004.
Towards a Semantic Clas-sification of Spanish Verbs Based on Subcategorisa-tion Information.
In ACL Student Research Workshop,Barcelona, Spain.Dan Flickinger and John Nerbonne.
1992.
Inheritanceand complementation: A case study of easy adjec-tives and related nouns.
Computational Linguistics,18(3):269?309.Daisuke Kawahara and Sadao Kurohashi.
2002.
Fertil-ization of Case Frame Dictionary for Robust JapaneseCase Analysis.
In 19th International Conference onComputational Linguistics.Anna Korhonen, Yuval Krymolowski, and Zvika Marx.2003.
Clustering Polysemic Subcategorization FrameDistributions Semantically.
In Proceedings of the 41stAnnual Meeting of the Association for ComputationalLinguistics, pages 64?71, Sapporo, Japan.Anna Korhonen.
2002.
Subcategorization acquisition.Ph.D.
thesis, University of Cambridge Computer Lab-oratory, February.Catherine Macleod, Ralph Grishman, and Adam Meyers,1998.
COMLEX Syntax Reference Manual.
ComputerScience Department, New York University.Christopher D. Manning.
1993.
Automatic Acquisitionof a Large Subcategorization Dictionary from Cor-pora.
In Meeting of the Association for ComputationalLinguistics, pages 235?242.S.
Schulte im Walde and C. Brew.
2002.
Inducinggerman semantic verb classes from purely syntacticsubcategorisation information.
In 40th Annual Meet-ing of the Association for Computational Linguistics,Philadephia, USA.Mihai Surdeanu, Sanda Harabagiu, JohnWilliams, andPaul Aarseth.
2003.
Using predicate-argument struc-tures for information extraction.
In Proc.
of the 41stAnnual Meeting of the Association for ComputationalLinguistics, Sapporo.Susanne Rohen Wolff, Catherine Macleod, and AdamMeyers, 1998.
COMLEX Word Classes Manual.
Com-puter Science Department, New York University ,June.621
