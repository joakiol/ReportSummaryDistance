Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 54?61,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsParticipant Subjectivity and Involvement as a Basis for DiscourseSegmentationJohn Niekrasz and Johanna MooreHuman Communication Research CentreSchool of InformaticsUniversity of Edinburgh{jniekras,jmoore}@inf.ed.ac.ukAbstractWe propose a framework for analyzingepisodic conversational activities in termsof expressed relationships between theparticipants and utterance content.
Wetest the hypothesis that linguistic featureswhich express such properties, e.g.
tense,aspect, and person deixis, are a useful ba-sis for automatic intentional discourse seg-mentation.
We present a novel algorithmand test our hypothesis on a set of inten-tionally segmented conversational mono-logues.
Our algorithm performs betterthan a simple baseline and as well as orbetter than well-known lexical-semanticsegmentation methods.1 IntroductionThis paper concerns the analysis of conversationsin terms of communicative activities.
Examples ofthe kinds of activities we are interested in includerelating a personal experience, making a group de-cision, committing to future action, and giving in-structions.
The reason we are interested in thesekinds of events is that they are part of partici-pants?
common-sense notion of the goals and ac-complishments of a dialogue.
They are part of par-ticipants?
subjective experience of what happenedand show up in summaries of conversations suchas meeting minutes.
We therefore consider theman ideal target for the practical, common-sense de-scription of conversations.Activities like these commonly occur as cohe-sive episodes of multiple turns within a conver-sation (Korolija, 1998).
They represent an inter-mediate level of dialogue structure ?
greater thana single speech act but still small enough to havea potentially well-defined singular purpose.
Theyhave a temporal granularity of anywhere from afew seconds to several minutes.Ultimately, it would be useful to use descrip-tions of such activities in automatic summariza-tion technologies for conversational genres.
Thiswould provide an activity-oriented summary de-scribing what ?happened?
that would complementone based on information content or what the con-versation was ?about?.
Part of our research goal isthus to identify a set of discourse features for seg-menting, classifying, and describing conversationsin this way.1.1 Participant subjectivity and involvementThe approach we take to this problem is foundedupon two basic ideas.
The first is that the activitieswe are interested in represent a coarse level of theintentional structure of dialogue (Grosz and Sid-ner, 1986).
In other words, each activity is unifiedby a common purpose that is shared between theparticipants.
This suggests there may be linguis-tic properties which are shared amongst the utter-ances of a given activity episode.The second idea concerns the properties whichdistinguish different activity types.
We proposethat activity types may be usefully distinguishedaccording to two complex properties of utterances,both of which concern relationships between theparticipants and the utterance: participant sub-jectivity and participant involvement.
Participantsubjectivity concerns attitudinal and perspectivalrelationships toward the dialogue content.
Thisincludes properties such as whether the utteranceexpresses the private mental state of the speaker,or the participants?
temporal relationship to a de-scribed event.
Participant involvement concernsthe roles participants play within the dialogue con-54tent, e.g., as the agent of a described event.1.2 Intentional segmentationThe hypothesis we test in this paper is that thelinguistic phenomena which express participant-relational properties may be used as an effectivemeans of intentional discourse segmentation.
Thisis based on the idea that if adjacent discourse seg-ments have different activity types, then they aredistinguishable by participant-relational features.If we can reliably extract such features, then thiswould allow segmentation of the dialogue accord-ingly.We test our hypothesis by constructing an algo-rithm and examining its performance on an exist-ing set of intentionally segmented conversationalmonologues (i.e., one person speaks while anotherlistens) (Passonneau and Litman, 1997, henceforthP&L).
While our long term goal is to apply ourtechniques to multi-party conversations (and toa somewhat coarser-grained analysis), using thisdataset is a stepping-stone toward that end whichallows us to compare our results with existing in-tentional segmentation algorithms.An example dialogue extract from the datasetis shown in Dialogue 1.
Two horizontal lines in-dicate a segment boundary which was identifiedby at least 3 of 7 annotators.
A single horizon-tal line indicates a segment boundary which wasidentified by 2 or fewer annotators.
In the exam-PearStories-09 (Chafe, 1980)21.2 okay.22.1 Meanwhile,22.2 there are three little boys,22.3 up on the road a little bit,22.4 and they see this little accident.23.1 And u-h they come over,23.2 and they help him,23.3 and you know,23.4 help him pick up the pears and everything.24.1 A-nd the one thing that struck me about the- threelittle boys that were there,24.2 is that one had ay uh I don?t know what you callthem,24.3 but it?s a paddle,24.4 and a ball-,24.5 is attached to the paddle,24.6 and you know you bounce it?25.1 And that sound was really prominent.26.1 Well anyway,26.2 so- u-m tsk all the pears are picked up,26.3 and he?s on his way again,Dialogue 1: An example dialogue extract showingintentional segment boundaries.ple, there are three basic types of discourse activitydistinguishable according to the properties of par-ticipant subjectivity and participant involvement.The segments beginning at 22.1 and 26.2 share theuse of the historical present tense ?
a type of par-ticipant subjectivity ?
in a narrative activity type.Utterances 24.1 and 25.1, on the other hand, areabout the prior perceptions of the speaker, a typeof participant involvement in a past event.
Thesegment beginning at 24.2 is a type of generic de-scription activity, exhibiting its own distinct con-figuration of participant relational features, suchas the generic you and present tense.We structure the rest of the paper as follows.First, we begin by describing related and support-ing theoretical work.
This is followed by a test ofour main hypothesis.
We then follow this with asimilar experiment which contextualizes our workboth theoretically and in practical terms with re-spect to the most commonly studied segmentationtask: topic segmentation.
We finish with a generaldiscussion of the implications of our experiments.2 Background and Related WorkThe influential work of Grosz and Sidner (1986)provides a helpful starting point for understand-ing our approach.
Their theory suggests that in-tentions (which equate to the goals and purposesof a dialogue) are a foundation for the structure ofdiscourse.
The individual discourse purposes thatemerge in a dialogue relate directly to the naturalaggregation of utterances into discourse segments.The attentional state of the dialogue, which con-tains salient objects and relations and allows forthe efficient generation and interpretation of utter-ances, is then dependent upon this interrelated in-tentional and linguistic structure in the emergingdialogue.Grosz and Sidner?s theory suggests that atten-tional state is parasitic upon the underlying inten-tional structure.
This implication has informedmany approaches which relate referring expres-sions (an attentional phenomenon) to discoursestructure.
One example is Centering theory (Groszet al, 1995), which concerns the relationship ofreferring expressions to discourse coherence.
An-other is P&L, who demonstrated that co-referenceand inferred relations between noun phrases area useful basis for automatic intentional segmen-tation.Our approach expands on this by highlighting55the fact that objects that are in focus within theattentional state have an important quality whichmay be exploited: they are focused upon by theparticipants from particular points of view.
In ad-dition, the objects may in fact be the participantsthemselves.
We would expect the linguistic fea-tures which express such relationships (e.g., as-pect, subjectivity, modality, and person deixis) totherefore correlate with intentional structure, andto do so in a way which is important to partici-pants?
subjective experience of the dialogue.This approach is supported by a theory put forthby Chafe (1994), who describes how speakers canexpress ideas from alternative perspectives.
Forexample, a subject who is recounting the events ofa movie of a man picking pears might say ?the manwas picking pears?, ?the man picks some pears?,or ?you see a man picking pears.?
Each variant isan expression of the same idea but reflects a dif-ferent perspective toward, or manner of participa-tion in, the described event.
The linguistic vari-ation one sees in this example is in the proper-ties of tense and aspect in the main clause (and inthe last variant, a perspectival superordinate clausewhich uses the generic you).
We have observedthat discourse coheres in these perspectival terms,with shifts of perspective usually occurring at in-tentional boundaries.Wiebe (1994; 1995) has investigated a phe-nomenon closely related to this: point-of-viewand subjectivity in fictional narrative.
She notesthat paragraph-level blocks of text often share acommon objective or subjective context.
Thatis, sentences may or may not be conveyed fromthe point-of-view of individuals, e.g., the authoror the characters within the narrative.
Sentencescontinue, resume, or initiate such contexts, andshe develops automatic methods for determiningwhen the contexts shift and whose point-of-viewis being taken.
Her algorithm provides a de-tailed method for analyzing written fiction, buthas not been developed for conversational or non-narrative genres.Smith?s (2003) analysis of texts, however,draws a more general set of connections betweenthe content of sentences and types of discoursesegments.
She does this by analyzing texts atthe level of short passages and determines a non-exhaustive list of five basic ?discourse modes?
oc-curring at that level: narrative, description, report,information, and argument.
The mode of a pas-sage is determined by the type of situations de-scribed in the text (e.g., event, state, general sta-tive, etc.)
and the temporal progression of the sit-uations in the discourse.
Situation types are inturn organized according to the perspectival prop-erties of aspect and temporal location.
A narrativepassage, for example, relates principally specificevents and states, with dynamic temporal advance-ment of narrative time between sentences.
On theother hand, an information passage relates primar-ily general statives with atemporal progression.3 Automatic Segmentation ExperimentThe analysis described in the previous sectionssuggests that participant-relational features corre-late with the intentional structure of discourse.
Inthis section we describe an experiment which teststhe hypothesis that a small set of such features, i.e.,tense, aspect, and first- and second-person pro-nouns, are a useful basis for intentional segmen-tation.3.1 DataOur experiment uses the same dataset as P&L, acorpus of 20 spoken narrative monologues knownas the Pear Stories (Chafe, 1980).
Chafe askedsubjects to view a silent movie and then sum-marize it for a second person.
Their speechwas then manually transcribed and segmented intoprosodic phrases.
This resulted in a mean 100phrases per narrative and a mean 6.7 words perphrase.
P&L later had each narrative segmentedby seven annotators according to an informal defi-nition of communicative intention.
Each prosodicphrase boundary was a possible discourse segmentboundary.
Using Cochran?s Q test, they concludedthat an appropriate gold standard could be pro-duced by using the set of boundaries assigned byat least three of the seven annotators.
This is thegold standard we use in this paper.
It assigns aboundary at a mean 16.9% (?
= 4.5%) of the pos-sible boundary sites in each narrative.
The result isa mean discourse segment length of 5.9 prosodicphrases, (?
= 1.4 across the means of each narra-tive).3.2 AlgorithmThe basic idea behind our algorithm is to distin-guish utterances according to the type of activ-ity in which they occur.
To do this, we iden-tify a set of utterance properties relating to par-56ticipant subjectivity and participant involvement,according to which activity types may be distin-guished.
We then develop a routine for automati-cally extracting the linguistic features which indi-cate such properties.
Finally, the dialogue is seg-mented at locations of high discontinuity in thatfeature space.
The algorithm works in four phases:pre-processing, feature extraction, similarity mea-surement, and boundary assignment.3.2.1 Pre-processingFor pre-processing, disfluencies are removed bydeleting repeated strings of words and incompletewords.
The transcript is then parsed (Klein andManning, 2002), and a collection of typed gram-matical dependencies are generated (de Marneffeet al, 2006).
The TTT2 chunker (Grover and To-bin, 2006) is then used to perform tense and aspecttagging.3.2.2 Feature extractionFeature extraction is the most important andnovel part of our algorithm.
Each prosodic phrase(the corpus uses prosodic phrases as sentence-likeunits, see Data section) is assigned values for fivebinary features.
The extracted features correspondto a set of utterance properties which were iden-tified manually through corpus analysis.
The firstfour relate directly to individual activity types andare therefore mutually exclusive properties.first-person participation [1P] ?
helps to distin-guish meta-discussion between the speakerand hearer (e.g., ?Did I tell you that??
)generic second-person [2P-GEN] ?
helps to dis-tinguish narration told from the perspectiveof a generic participant (e.g., ?You see a manpicking pears?
)third-person stative/progressive [3P-STAT]?
helps to distinguish narrative activitiesrelated to ?setting the scene?
(e.g., ?
[There isa man | a man is] picking pears?
)third-person event [3P-EVENT] ?
helps to dis-tinguish event-driven third-person narrativeactivities (e.g.
?The man drops the pears?
)past/non-past [PAST] ?
helps to distinguish nar-rative activities by temporal orientation (e.g.
?The man drops the pears?
vs. ?The mandropped the pears?
)Feature extraction works by identifying the lin-guistic elements that indicate each utterance prop-erty.
First, prosodic phrases containing a first- orsecond-person pronoun in grammatical subject orobject relation to any clause are identified (com-mon fillers like you know, I think, and I don?t knoware ignored).
Of the identified phrases, those withfirst-person pronouns are marked for 1P, while theothers are marked for 2P-GEN. For the remain-ing prosodic phrases, those with a matrix clauseare identified.
Of those identified, if either itshead verb is be or have, it is tagged by TTT2 ashaving progressive aspect, or the prosodic phrasecontains an existential there, then it is marked for3P-STAT.
The others are marked for 3P-EVENT.Finally, if the matrix clause was tagged as pasttense, the phrase is marked for PAST.
In caseswhere no participant-relational features are iden-tified (e.g., no matrix clause, no pronouns), theprosodic phrase is assigned the same features asthe preceding one, effectively marking a continua-tion of the current activity type.3.2.3 Similarity measurementSimilarity measurement is calculated accordingto the cosine similarity cos(vi, ci) between the fea-ture vector vi of each prosodic phrase i and aweighted sum ci of the feature vectors in the pre-ceding context.
The algorithm requires a parame-ter l to be set for the desired mean segment length.This determines the window w = floor(l/2) ofpreceding utterances to be used.
The weightedsum representing the preceding context is com-puted as ci =?wj=1((1 + w ?
j)/w)vi?j , whichgives increasingly greater weight to more recentphrases.3.2.4 Boundary assignmentIn the final step, the algorithm assigns bound-aries where the similarity score is lowest, namelyprior to prosodic phrases where cos is less than thefirst 1/l quantile for that discourse.3.3 Experimental Method and EvaluationOur experiment compares the performance ofour novel algorithm (which we call NM09) witha naive baseline and a well-known alternativemethod ?
P&L?s co-reference based NP algorithm.To our knowledge, P&L is the only existing publi-cation describing algorithms designed specificallyfor intentional segmentation of dialogue.
TheirNP algorithm exploits annotations of direct and57inferred relations between noun phrases in adja-cent units.
Inspired by Centering theory (Groszet al, 1995), these annotations are used in a com-putational account of discourse focus to measurecoherence.
Although adding pause-based featuresimproved results slightly, the NP method was theclear winner amongst those using a single featuretype and produced very good results.The NP algorithm requires co-reference anno-tations as input, so to create a fully-automaticversion (NP-AUTO) we have employed a state-of-the-art co-reference resolution system (Poesio andKabadjov, 2004) to generate the required input.We also include results based on P&L?s originalhuman co-reference annotations (NP-HUMAN).For reference, we include a baseline that ran-domly assigns boundaries at the same mean fre-quency as the gold-standard annotations, i.e., a se-quence drawn from the Bernoulli distribution withsuccess probability p = 0.169 (this probability de-termines the value of the target segment length pa-rameter l in our own algorithm).
As a top-line ref-erence, we calculate the mean of the seven anno-tators?
scores with respect to the three-annotatorgold standard.For evaluation we employ two types of mea-sure.
On one hand, we use P (k) (Beeferman et al,1999) as an error measure designed to accommo-date near-miss boundary assignments.
It is usefulbecause it estimates the probability that two ran-domly drawn points will be assigned incorrectlyto either the same or different segments.
On theother hand, we use Cohen?s Kappa (?)
to evalu-ate the precise placement of boundaries such thateach potential boundary site is considered a binaryclassification.
While ?
is typically used to evalu-ate inter-annotator agreement, it is a useful mea-sure of classification accuracy in our experimentfor two reasons.
First, it accounts for the strongclass bias in our data.
Second, it allows a directand intuitive comparison with our inter-annotatortop-line reference.
We also provide results for thecommonly-used IR measures F1, recall, and pre-cision.
These are useful for comparing with pre-vious results in the literature and provide a morewidely-understood measure of the accuracy of theresults.
Precision and recall are also helpful in re-vealing the effects of any classification bias the al-gorithms may have.The results are calculated for 18 of the 20 narra-tives, as manual feature development involved theTable 1: Mean results for the 18 test narratives.P (k) ?
F1 Rec.
Prec.Human .21 .58 .65 .64 .69NP-HUMAN .35 .38 .40 .52 .46NM09 .44 .11 .24 .23 .28NP-AUTO .52 .03 .27 .71 .17Random .50 .00 .15 .14 .17use of two randomly selected narratives as devel-opment data.
The one exception is NP-HUMAN,which is evaluated on the 10 narratives for whichthere are manual co-reference annotations.3.4 ResultsThe mean results for the 18 narratives, calculatedin comparison to the three-annotator gold stan-dard, are shown in Table 1.
NP-HUMAN and NM09are both superior to the random baseline for allmeasures (p?0.05).
NP-AUTO, however, is onlysuperior in terms of recall and F1 (p?0.05).3.5 DiscussionThe results indicate that the simple set of featureswe have chosen can be used for intentional seg-mentation.
While the results are not near humanperformance, it is encouraging that such a simpleset of easily extractable features achieves resultsthat are 19% (?
), 24% (P (k)), and 18% (F1) ofhuman performance, relative to the random base-line.The other notable result is the very high recallscore of NP-AUTO, which helps to produce a re-spectable F1 score.
However, a low ?
reveals thatwhen accounting for class bias, this system is ac-tually not far from the performance of a high recallrandom classifier.Error analysis showed that the reason for theproblems with NP-AUTO was the lack of referencechains produced by the automatic co-referencesystem.
While the system seems to have per-formed well for direct co-reference, it did not dowell with bridging reference.
Inferred relationswere an important part of the reference chains pro-duced by P&L, and it is now clear that these playa significant role in the performance of the NP al-gorithm.
Our algorithm is not dependent on thisdifficult processing problem, which typically re-quires world knowledge in the form of training onlarge datasets or the use of large lexical resources.584 Topic vs.
Intentional SegmentationIt is important to place our experiment on inten-tional segmentation in context with the most com-monly studied automatic segmentation task: topic-based segmentation.
While the two tasks are dis-tinct, the literature has drawn connections betweenthem which can at times be confusing.
In this sec-tion, we attempt to clarify those connections bypointing out some of their differences and similar-ities.
We also conduct an experiment comparingour algorithm to well-known topic-segmentationalgorithms and discuss the results.4.1 Automatic segmentation in the literatureOne of the most widely-cited discourse segmen-tation algorithms is TextTiling (Hearst, 1997).Designed to segment texts into multi-paragraphsubtopics, it works by operationalizing the notionof lexical cohesion (Halliday and Hasan, 1976).TextTiling and related algorithms exploit the col-location of semantically related lexemes to mea-sure coherence.
Recent improvements to thismethod include the use of alternative lexical sim-ilarity metrics like LSA (Choi et al, 2001) andalternative segmentation methods like the mini-mum cut model (Malioutov and Barzilay, 2006)and ranking and clustering (Choi, 2000).
Re-cently, Bayesian approaches which model top-ics as a lexical generative process have been em-ployed (Purver et al, 2006; Eisenstein and Barzi-lay, 2008).
What these algorithms all share is afocus on the semantic content of the discourse.Passonneau and Litman (1997) is another of themost widely-cited articles on discourse segmenta-tion.
Their overall approach combines an investi-gation of prosodic features, cue words, and entityreference.
As described above, their approach tousing entity reference is motivated by Centeringtheory (Grosz et al, 1995) and the hypothesis thatintentional structure is exhibited in the attentionalrelationships between discourse referents.Hearst and P&L try to achieve different goals,but their tasks are nonetheless related.
One mightreasonably hypothesize, for example, that eitherlexical similarity or co-reference could be use-ful to either type of segmentation on the groundsthat the two phenomena are clearly related.
How-ever, there are also clear differences of intent be-tween the two studies.
While there is an ob-vious difference in the dataset (written exposi-tory text vs. spoken narrative monologue), the an-notation instructions reflect the difference mostclearly.
Hearst instructed naive annotators to markparagraph boundaries ?where the topics seem tochange,?
whereas P&L asked naive annotators tomark prosodic phrases where the speaker had be-gun a new communicative task.The results indicate that there is a differencein granularity between the two tasks, with inten-tional segmentation relating to finer-grained struc-ture.
Hearst?s segments have a mean of about 200words to P&L?s 40.
Also, two hierarchical topicsegmentations of meetings (Hsueh, 2008; Gruen-stein et al, 2008) have averages above 400 wordsfor the smallest level of segment.To our knowledge, P&L is the only existingstudy of automatic intention-based segmentation.However, their work has been frequently cited as astudy of topic-oriented segmentation, e.g., (Galleyet al, 2003; Eisenstein and Barzilay, 2008).
Also,recent research in conversational genres (Galley etal., 2003; Hsueh and Moore, 2007) analyze eventslike discussing an agenda or giving a presentation,which resemble more intentional categories.
Inter-estingly, these algorithms demonstrate the bene-fit of including non-lexical, non-semantic features.The results imply that further analysis is needed tounderstand the links between different types of co-herence and different types of segmentation.4.2 Experiment 2We have extended the above experiment to com-pare the results of our novel algorithm with ex-isting topic segmentation methods.
We employChoi?s implementations of C99 (Choi, 2000) andTEXTTILING (Hearst, 1997) as examples of well-known topic-oriented methods.
While we ac-knowledge that there are newer algorithms whichimprove upon this work, these were selected forbeing well studied and easy to apply out-of-the-box.
Our method and evaluation is the same as inthe previous experiment.The mean results for the 18 narratives are shownin Table 2, with the human and baseline score re-produced from the previous table.
All three auto-matic algorithms are superior to the random base-line in terms of P (k), ?, and F1 (p?0.05).
Theonly statistically significant difference (p?0.05)between the three automatic methods is betweenNM09 and TEXTTILING in terms of F1.
The ob-served difference between NM09 and TEXTTIL-ING in terms of ?
is only moderately significant59Table 2: Results comparing our method to topic-oriented segmentation methods.NP-auto P (k) ?
F1 Rec.
Prec.Human .21 .58 .65 .64 .69NM09 .44 .11 .24 .24 .28C99 .44 .08 .22 .20 .24TEXTTILING .41 .05 .18 .16 .21Random .50 .00 .15 .14 .17(p?0.08).
The observed differences between be-tween NM09 and C99 are minimally significant(p?0.24) .4.3 DiscussionThe comparable performance achieved by oursimple perspective-based approach in comparisonto lexical-semantic approaches suggests two mainpoints.
First, it validates our novel approach inpractical applied terms.
It shows that perspective-oriented features, being simple to extract and ap-plicable to a variety of genres, are potentially veryuseful for automatic discourse segmentation sys-tems.Second, the results show that the teasing apartof topic-oriented and intentional structure may bequite difficult.
Studies of coherence at the level ofshort passages or episodes (Korolija, 1998) sug-gest that coherence is established through a com-plex interaction of topical, intentional, and othercontextual factors.
In this experiment, the majorportion of the dialogues are oriented toward thebasic narrative activity which is the premise of thePear Stories dataset.
This means that there aremany times when the activity type does not changeat intentional boundaries.
At other times, the ac-tivity type changes but neither the topic nor the setof referents is significantly changed.
The differ-ent types of algorithms we have tried (i.e., topical,referential, and perspectival) seem to be operatingon somewhat orthogonal bases, though it is dif-ficult to say quantitatively how this relates to thetypes of ?communicative task?
transitions occur-ring at the boundaries.
In a sense, we have pro-posed an algorithm for performing ?activity typecohesion?
which mimics the methods of lexicalcohesion but is based upon a different dimensionof the discourse.
The results indicate that these areboth related to intentional structure.5 General Discussion and Future WorkFuture work in intentional segmentation is needed.Our ultimate goal is to extend this work to moreconversational domains (e.g., multi-party planningmeetings) and to define the richer set of perspec-tives and related deictic features that would beneeded for them.
For example, we hypothesizethat the different uses of second-person pronounsin conversations (Gupta et al, 2007) are likely toreflect alternative activity types.
Our feature setand extraction methods will therefore need to befurther developed to capture this complexity.The other question we would like to address isthe relationship between various types of coher-ence (e.g., topical, referential, perspectival, etc.
)and different types (and levels) of discourse struc-ture.
Our current approach uses a feature spacethat is orthogonal to most existing segmentationmethods.
This has allowed us to gain a deeperunderstanding of the relationship between certainlinguistic features and the underlying intentionalstructure, but more work is needed.In terms of practical motivations, we also planto address the open question of how to effectivelycombine our feature set with other feature setswhich have also been demonstrated to contributeto discourse structuring and segmentation.ReferencesDoug Beeferman, Adam Berger, and John D. Lafferty.1999.
Statistical models for text segmentation.
Ma-chine Learning, 34(1-3):177?210.Wallace L. Chafe, editor.
1980.
The Pear Stories:Cognitive, Cultural, and Linguistic Aspects of Nar-rative Production, volume 3 of Advances in Dis-course Processes.
Ablex, Norwood, NJ.Wallace L. Chafe.
1994.
Discourse, Consciousness,and Time: The Flow and Displacement of ConsciousExperience in Speaking and Writing.
University ofChicago Press, Chicago.Freddy Y. Y. Choi, Peter Wiemer-Hastings, and Jo-hanna Moore.
2001.
Latent semantic analysis fortext segmentation.
In Proc.
EMNLP, pages 109?117.Freddy Y. Y. Choi.
2000.
Advances in domain inde-pendent linear text segmentation.
In Proc.
NAACL,pages 26?33.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProc.
LREC, pages 562?569.60Jacob Eisenstein and Regina Barzilay.
2008.
Bayesianunsupervised topic segmentation.
In Proc.
EMNLP,pages 334?343.Michel Galley, Kathleen McKeown, Eric Fosler-Lussier, and Hongyan Jing.
2003.
Discourse seg-mentation of multi-party conversation.
In Proc.ACL, pages 562?569.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Com-putational Linguistics, 12(3):175?204.Barbara J. Grosz, Aravind Joshi, and Scott Weinstein.1995.
Centering: A framework for modelling thelocal coherence of discourse.
Computational Lin-guistics, 21(2):203?225.Claire Grover and Richard Tobin.
2006.
Rule-basedchunking and reusability.
In Proc.
LREC.Alexander Gruenstein, John Niekrasz, and MatthewPurver.
2008.
Meeting structure annotation: Anno-tations collected with a general purpose toolkit.
InL.
Dybkjaer and W. Minker, editors, Recent Trendsin Discourse and Dialogue, pages 247?274.Surabhi Gupta, John Niekrasz, Matthew Purver, andDaniel Jurafsky.
2007.
Resolving ?you?
in multi-party dialog.
In Proc.
SIGdial, pages 227?230.M.
A. K. Halliday and Ruqayia Hasan.
1976.
Cohe-sion in English.
Longman, New York.Marti Hearst.
1997.
TextTiling: Segmenting text intomulti-paragraph subtopic passages.
ComputationalLinguistics, 23(1):33?64.Pei-Yun Hsueh and Johanna D. Moore.
2007.
Com-bining multiple knowledge sources for dialogue seg-mentation in multimedia archives.
In Proc.
ACL,pages 1016?1023.Pei-Yun Hsueh.
2008.
Meeting Decision Detection:Multimodal Information Fusion for Multi-Party Di-alogue Understanding.
Ph.D. thesis, School of In-formatics, University of Edinburgh.Dan Klein and Christopher D. Manning.
2002.
Fastexact inference with a factored model for naturallanguage parsing.
In NIPS 15.Natascha Korolija.
1998.
Episodes in talk: Construct-ing coherence in multiparty conversation.
Ph.D. the-sis, Link?ping University, The Tema Institute, De-partment of Communications Studies.Igor Malioutov and Regina Barzilay.
2006.
Minimumcut model for spoken lecture segmentation.
In Proc.COLING-ACL, pages 25?32.Rebecca J. Passonneau and Diane J. Litman.
1997.Discourse segmentation by human and automatedmeans.
Computational Linguistics, 23(1):103?139.Massimo Poesio and Mijail A. Kabadjov.
2004.
Ageneral-purpose, off-the-shelf anaphora resolutionmodule: Implementation and preliminary evalua-tion.
In Proc.
LREC.Matthew Purver, Konrad K?rding, Thomas Griffiths,and Joshua Tenenbaum.
2006.
Unsupervised topicmodelling for multi-party spoken discourse.
InProc.
COLING-ACL, pages 17?24.Carlota S. Smith.
2003.
Modes of Discourse.
Camb-drige University Press, Cambridge.Janyce M. Wiebe.
1994.
Tracking point of view in nar-rative.
Computational Linguistics, 20(2):233?287.Janyce M. Wiebe.
1995.
References in narrative text.In Judy Duchan, Gail Bruder, and Lynne Hewitt, ed-itors, Deixis in Narrative: A Cognitive Science Per-spective, pages 263?286.61
