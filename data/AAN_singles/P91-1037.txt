PREDICT ING INTONATIONAL PHRASING FROM TEXTMichelle Q. WangChurchill CollegeCambridge UniversityCambridge UKJulia HirschbergAT&T Bell Laboratories600 Mountain AvenueMurray Hill, NJ 07974AbstractDetermining the relationship between the intona-tional characteristics of an utterance and otherfeatures inferable from its text is important bothfor speech recognition and for speech synthesis.This work investigates the use of text analysisin predicting the location of intonational phraseboundaries in natural speech, through analyzing298 utterances from the DARPA Air Travel In-formation Service database.
For statistical model-ing, we employ Classification and Regression Tree(CART) techniques.
We achieve success rates ofjust over 90%, representing a major improvementover other attempts at boundary prediction fromunrestricted text.
1Int roduct ionThe relationship between the intonational phras-ing of an utterance and other features which canbe inferred from its transcription represents animportant source of information for speech syn-thesis and speech recognition.
In synthesis, morenatural intonational phrasing can be assigned iftext analysis can predict human phrasing perfor-mance.
In recognition, better calculation of prob-able word durations is possible if the phrase-final-lengthening that precedes boundary sites can bepredicted.
Furthermore, the association of intona-tional features with syntactic and acoustic infor-mation can also be used to reduce the number ofsentence hypotheses under consideration.Previous research on the location of intonationalboundaries has largely focussed on the relation-ship between these prosodic boundaries and syn-tactic constituent boundaries.
While current re-search acknowledges the role that semantic anddiscourse-level information play in boundary as-I We thank Michael Riley for helpful discussions.
Codeimplementing the CART techniques employed here waswritten by Michael Riley and Daryi Pregibon.
Part-of-speech tagging employed Ken Church's tagger, and syn-tactic analysis used Don Hindle's parser, Fiddltch.signment, most authors assume that syntactic on-figuration provides the basis for prosodic 'defaults'that may be overridden by semantic or discourseconsiderations.
While most interest in boundaryprediction has been focussed on synthesis (Geeand Grosjean, 1983; Bachenko and Fitzpatrick,1990), currently there is considerable interest inpredicting boundaries to aid recognition (Osten-doff et al, 1990; Steedman, 1990).
The mostsuccessful empirical studies in boundary locationhave investigated how phrasing can disambiguatepotentially syntactically ambiguous utterances inread speech (Lehiste, 1973; Ostendorf et al, 1990).Analysis based on corpora of natural speech (Abtenberg, 1987) have so far reported very limitedsuccess and have assumed the availability of syn-tactic, semantic, and discourse-level informationwell beyond the capabilities of current NL systemsto provide.To address the question of how boundaries areassigned in natural speech - -  as well as the needfor classifying boundaries from information thatcan be extracted automatically from text - -  weexamined a multi-speaker corpus of spontaneouselicited speech.
We wanted to compare perfor-mance in the prediction of intonational bound-aries from information available through simpletechniques of text analysis, to performance us-ing information currently available only come fromhand labeling of transcriptions.
To this end,we selected potential boundary predictors basedupon hypotheses derived from our own observa-tions and from previous theoretical and practi-cal studies of boundary location.
Our corpus forthis investigation is 298 sentences from approxi-mately 770 sentences of the Texas Instruments-collected portion of the DARPA Air Travel In-formation Service (ATIS) database(DAR, 1990).For statistical modeling, we employ classificationand regression tree techniques (CART) (Briemanet al, 1984), which provide cross-validated de-cision trees for boundary classification.
We ob-tain (cross-validated) success rates of 90% for bothautomatically-generated information and hand-285labeled data on this sample, which representsa major improvement over previous attempts topredict intonational boundaries for spontaneousspeech and equals or betters previous (hand-crafted) algorithms tested for read speech.Intonational PhrasingIntuitively, intonational phrasing divides an ut-terance into meaningful 'chunks' of information(Bolinger, 1989).
Variation in phrasing can changethe meaning hearers assign to tokens of a givensentence.
For example, interpretation of a sen-tence like 'Bill doesn't drink because he's unhappy.
'will change, depending upon whether it is utteredas one phrase or two.
Uttered as a single phrase,this sentence is commonly interpreted as convey-ing that Bill does indeed drink - -  but the causeof his drinking is not his unhappiness.
Uttered astwo phrases, it is more likely to convey that Billdoes sot drink - -  and the reason for his abstinenceis his unhappiness.To characterize this phenomenon phonologi-cally, we adopt Pierrehumbert's theory of into-national description for English (Pierrehumbert,1980).
In this view, two levels of phrasing are sig-nificant in English intonational structure.
Bothtypes are composed of sequences of high and lowtones in the FUNDAMENTAL FREQUENCY (f0) con-tour.
An INTERMEDIATE (or minor) PHRASE con-slats of one or more PITCH ACCENTS (local f0 min-ima or maxima) plus a PHRASE ACCENT (a simplehigh or low tone which controls the pitch fromthe last pitch accent of one intermediate phraseto the beginning of the next intermediate phraseor the end of the utterance).
INTONATIONAL (ormajor) PHRASES consist of one or more intermedi-ate phrases plus a final BOUNDARY TONE, whichmay also be high or low, and which occurs at theend of the phrase.
Thus, an intonational phraseboundary necessarily coincides with an intermedi-ate phrase boundary, but not vice versa.While phrase boundaries are perceptual cate-gories, they are generally associated with certainphysical characteristics of the speech signal.
Inaddition to the tonal features described above,phrases may be identified by one of more of thefollowing features: pauses (which may be filledor not), changes in amplitude, and lengtheningof the final syllable in the phrase (sometimes ac-companied by glottalization of that syllable andperhaps preceding syllables).
In general, ma-jor phrase boundaries tend to be associated withlonger pauses, greater tonal changes, and more fi-nal lengthening than minor boundaries.The ExperimentsThe Corpus  and  Features  Used  inAna lys i sThe corpus used in this analysis consists of 298utterances (24 minutes of speech from 26 speak-ers) from the speech data collected by Texas In-struments for the DARPA Air Travel InformationSystem (ATIS) spoken language system evaluationtask.
In a Wizard-of-Oz simulation, subjects wereasked to make travel plans for an assigned task,providing spoken input and receiving teletype out-put.
The quality of the ATIS corpus is extremelydiverse.
Speaker performance ranges from close toisolated-word speech to exceptional fluency.
Manyutterances contain hesitations and other disfluen-cies, as well as long pauses (greater than 3 sec.
insome cases).To prepare this data for analysis, we labeled thespeech prosodically by hand, noting location andtype of intonational boundaries and presence orabsence of pitch accents.
Labeling was done fromboth the waveform and pitchtracks of each utter-ance.
Each label file was checked by several a-belers.
Two levels of boundary were labeled; inthe analysis presented below, however, these arecollapsed to a single category.We define our data points to consist of all po-tential boundary locations in an utterance, de-fined as each pair of adjacent words in the ut-terance < wi, wj >, where wi represents theword to the left of the potential boundary siteand wj represents the word to the right.
2 Giventhe variability in performance we observed amongspeakers, an obvious variable to include in ouranalysis is speaker identity.
While for applica-tions to speaker-independent recognition this vari-able would be uninstantiable, we nonetheless needto determine how important speaker idiosyncracymay be in boundary location.
We found no signif-icant increase in predictive power when this vari-able is used.
Thus, results presented below arespeaker-independent.One easily obtainable class of variable involvestemporal information.
Temporal variables includeutterance and phrase duration, and distance of the2See the appendix for a partial ist of variables em-ployed, which provides a key to the node labels for theprediction trees presented in Figures 1 and 2.286potential boundary from various strategic pointsin the utterance.
Although it is tempting to as-sume that phrase boundaries represent a purelyintonational phenomenon, it is possible that pro-cessing constraints help govern their occurrence.That is, longer utterances may tend to includemore boundaries.
Accordingly, we measure thelength of each utterance both in seconds and inwords.
The distance of the boundary site fromthe beginning and end of the utterance is anothervariable which appears likely to be correlated withboundary location.
The tendency to end a phrasemay also be affected by the position of the poten-tial boundary site in the utterance.
For example,it seems likely that positions very close to the be-ginning or end of an utterance might be unlikelypositions for intonational boundaries.
We measurethis variable too, both in seconds and in words.The importance of phrase length has also beenproposed (Gee and Grosjean, 1983; Bachenko andFitzpatrick, 1990) as a determiner ofboundary lo-cation.
Simply put, it seems may be that consecu-tive phrases have roughly equal ength.
To capturethis, we calculate the elapsed distance from thelast boundary to the potential boundary site, di-vided by the length of the last phrase ncountered,both in time and words.
To obtain this informa-tion automatically would require us to factor priorboundary predictions into subsequent predictions.While this would be feasible, it is not straightfor-ward in our current classification strategy.
So, totest the utility of this information, we have usedobserved boundary locations in our current anal-ysis.As noted above, syntactic onstituency infor-mation is generally considered a good predictorof phrasing information (Gee and Grosjean, 1983;Selkirk, 1984; Marcus and Hindle, 1985; Steed-man, 1990).
Intuitively, we want to test the notionthat some constituents may be more or less likelythan others to be internally separated by intona-tional boundaries, and that some syntactic on-stituent boundaries may be more or less likely tocoincide with intonational boundaries.
To test theformer, we examine the class of the lowest node inthe parse tree to dominate both wi and wj, usingHindle's parser, Fidditch (1989) To test the latterwe determine the class of the highest node in theparse tree to dominate wi, but not wj, and theclass of the highest node in the tree to dominatewj but not wi.
Word class has also been usedoften to predict boundary location, particularlyin text-to-speech.
The belief that phrase bound-aries rarely occur after function words forms thebasis for most algorithms used to assign intona-tional phrasing for text-to-speech.
Furthermore,we might expect hat some words, such as preposi-tions and determiners, for example, do not consti-tute the typical end to an intonational phrase.
Wetest these possibilities by examining part-of-speechin a window of four words surrounding each poten-tial phrase break, using Church's part-of-speechtagger (1988).Recall that each intermediate phrase is com-posed of one or more pitch accents plus a phraseaccent, and each intonational phrase is composedof one or more intermediate phrases plus a bound-ary tone.
Informal observation suggests thatphrase boundaries are more likely to occur in someaccent contexts than in others.
For example,phrase boundaries between words that are deac-cented seem to occur much less frequently thanboundaries between two accented words.
To testthis, we look at the pitch accent values of wi andwj for each < wi, wj >, comparing observed valueswith predicted pitch accent information obtainedfrom (Hirschberg, 1990).In the analyses described below, we employvarying combinations of these variables to pre-dict intonational boundaries.
We use classificationand regression tree techniques to generate decisiontrees automatically from variable values provided.C lass i f i ca t ion  and  Regress ion  TreeTechn iquesClassification and regression tree (CART) analy-sis (Brieman et al, 1984) generates decision treesfrom sets of continuous and discrete variables byusing set of splitting rules, stopping rules, andprediction rules.
These rules affect the internalnodes, subtree height, and terminal nodes, re-spectively.
At each internal node, CART deter-mines which factor should govern the forking oftwo paths from that node.
Furthermore, CARTmust decide which values of the factor to associatewith each path.
Ideally, the splitting rules shouldchoose the factor and value split which minimizesthe prediction error rate.
The splitting rules inthe implementation employed for this study (Ri-ley, 1989) approximate optimality by choosing ateach node the split which minimizes the predictionerror rate on the training data.
In this implemen-tation, all these decisions are binary, based uponconsideration ofeach possible binary partition ofvalues of categorical variables and consideration fdifferent cut-points for values of continuous vari-ables.287Stopping rules terminate the splitting processat each internal node.
To determine the besttree, this implementation uses two sets of stoppingrules.
The first set is extremely conservative, re-sulting in an overly large tree, which usually lacksthe generality necessary to account for data out-side of the training set.
To compensate, the secondrule set forms a sequence of subtrees.
Each treeis grown on a sizable fraction of the training dataand tested on the remaining portion.
This step isrepeated until the tree has been grown and testedon all of the data.
The stopping rules thus have ac-cess to cross-validated rror rates for each subtree.The subtree with the lowest rates then defines thestopping points for each path in the full tree.
Treesdescribed below all represent cross-validated data.The prediction rules work in a straightforwardmanner to add the necessary labels to the termi-nal nodes.
For continuous variables, the rules cal-culate the mean of the data points classified to-gether at that node.
For categorical variables, therules choose the class that occurs most frequentlyamong the data points.
The success of these rulescan be measured through estimates of deviation.In this implementation, the deviation for continu-ous variables is the sum of the squared error for theobservations.
The deviation for categorical vari-ables is simply the number of misclassified obser-vations.ResultsIn analyzing boundary locations in our data, wehave two goals in mind.
First, we want to dis-cover the extent to which boundaries can be pre-dicted, given information which can be gener-ated automatically from the text of an utter-ance.
Second, we want to learn how much predic-tive power can be gained by including additionalsources of information which, at least currently,cannot be generated automatically from text.
Indiscussing our results below, we compare predic-tions based upon automatically inferable informa-tion with those based upon hand-labeled ata.We employ four different sets of variables dur-ing the analysis.
The first set includes observedphonological information about pitch accent andprior boundary location, as well as automati-cally obtainable information.
The success rate ofboundary prediction from the variable set is ex-tremely high, with correct cross-validated classi-fication of 3330 out of 3677 potential boundarysites - -  an overall success rate of 90% (Figure 1).Furthermore, there are only five decision points inthe tree.
Thus, the tree represents a clean, sim-ple model of phrase boundary prediction, assum-ing accurate phonological information.Turning to the tree itself, we that the ratio ofcurrent phrase length to prior phrase length is veryimportant in boundary location.
This variablealone (assuming that the boundary site occurs be-fore the end of the utterance) permits correct clas-sification of 2403 out of 2556 potential boundarysites.
Occurrence of a phrase boundary thus ap-pears extremely unlikely in cases where its pres-ence would result in a phrase less than half thelength of the preceding phrase.
The first and lastdecision points in the tree are the most trivial.The first split indicates that utterances virtuallyalways end with a boundary - -  rather unsurpris-ing news.
The last split shows the importance ofdistance from the beginning of the utterance inboundary location; boundaries are more likely tooccur when more than 2 ?
seconds have elapsedfrom the start of the utterance.
3 The third node inthe tree indicates that noun phrases form a tightlybound intonational unit.
The fourth split in 1shows the role of accent context in determiningphrase boundary location.
If wi is not accented,then it is unlikely that a phrase boundary will oc-cur after it.The significance of accenting in the phraseboundary classification tree leads to the questionof whether or not predicted accents will have asimilar impact on the paths of the tree.
In the sec-ond analysis, we substituted predicted accent val-ues for observed values.
Interestingly, the successrate of the classification remained approximatelythe same, at 90%.
However, the number of splitsin the resultant tree increased to nine and failed toinclude the accenting of wl as a factor in the clas-sification.
A closer look at the accent predictionsthemselves reveals that the majority of misclas-sifications come from function words preceding aboundary.
Although the accent prediction algo-rithm predicted that these words would be deac-cented, they were in fact accented.
This appearsto be an idiosyncracy of the corpus; such wordsgenerally occurred before relatively long pauses.Nevertheless, classification succeeds well in the ab-sence of accent information, perhaps suggestingthat accent values may themselves be highly cor-related with other variables.
For example, bothpitch accent and boundary location appear sen-sitive to location of prior intonational boundariesand part-of-speech.3This fact may be idiosyncratic to our data, given thefact that we observed a trend towards initial hesitations.288In the third analysis, we eliminate the dynamicboundary percentage measure.
The result remainsnearly as good as before, with a success rate of89%.
The proposed decision tree confirms the use-fulness of observed accent status of wi in bound-ary prediction.
By itself (again assuming that thepotential boundary site occurs before the end ofthe utterance), this factor accounts for 1590 out of1638 potential boundary site classifications.
Thisanalysis also confirms the strength of the intona-tional ties among the components of noun phrases.In this tree, 536 out of 606 potential boundarysites receive final classification from this feature.We conclude our analysis by producing a clas-sification tree that uses automatically-inferrableinformation alone.
For this analysis we use pre-dicted accent values instead of observed values andomit boundary distance percentage measures.
Us-ing binary-valued accented predictions (i.e., are< wl, wj > accented or not), we obtain a suc-cess rate for boundary prediction of 89%, andusing a four-valued distinction for predicted ac-cented (cliticized, deaccented, accented, 'NA') weincreased this to 90%.
The tree in Figure 2)presents the latter analysis.Figure 2 contains more nodes than the treesdiscussed above; more variables are used to ob-tain a similar classification percentage.
Note thataccent predictions are used trivially, to indicatesentence-final boundaries (ra='NA').
In figure 1,this function was performed by distance of poten-tial boundary site from end of utterance (at).
Thesecond split in the new tree does rely upon tem-poral distance - -  this time, distance of boundarysite from the beginning of the utterance.
Togetherthese measurements correctly predict nearly fortypercent of the data (38.2%).
Th classifier nextuses a variable which has not appeared in earlierclassifications - - the part-of-speech of wj.
In 2,in the majority of cases (88%) where wj is a func-tion word other than 'to,' 'in,' or a conjunction(true for about half of potential boundary sites), aboundary does not occur.
Part-of-speech ofwi andtype of constituent dominating wi but not wj arefurther used to classify these items.
This portionof the classification is reminiscent of the notion of'function word group' used commonly in assigningprosody in text-to-speech, in which phrases are de-fined, roughly, from one function word to the next.Overall rate of the utterance and type of utteranceappear in the tree, in addition to part-of-speechand constituency information, and distance of po-tential boundary site from beginning and end ofutterance.
In general, results of this first stage ofanalysis suggest -- encouragingly -- that there isconsiderable redundancy in the features predict-ing boundary location: when some features areunavailable, others can be used with similar ratesof 8UCCe88.DiscussionThe application of CART techniques to the prob-lem of predicting and detecting phrasing bound-aries not only provides a classification procedurefor predicting intonational boundaries from text,but it increases our understanding of the impor-tance of several among the numerous variableswhich might plausibly be related to boundary lo-cation.
In future, we plan to extend the set ofvariables for analysis to include counts of stressedsyllables, automatic NP-detection (Church, 1988),MUTUAL INFORMATION, GENERALIZED MUTUALINFORMATION scores can serve as indicators ofintonational phrase boundaries (Magerman andMarcus, 1990).We will also examine possible interactionsamong the statistically important variables whichhave emerged from our initial study.
CART tech-niques have worked extremely well at classifyingphrase boundaries and indicating which of a set ofpotential variables appear most important.
How-ever, CART's  step-wise treatment of variables, Ol>-timization heuristics, and dependency on binarysplits obscure the possible relationships that ex-ist among the various factors.
Now that we havediscovered a set of variables which do well at pre-dicting intonational boundary location, we need tounderstand just how these variables interact.ReferencesBengt Altenberg.
1987.
Prosodic Patterns in Spo-ken English: Studies in the Correlation betweenProsody and Grammar for Tezt-to-Speech Con-version, volume 76 of Land Studies in English.Lund University Press, Lund.J.
Bachenko and E. Fitzpatrick.
1990.
A compu-tational grammar of discourse-neutral prosodicphrasing in English.
Computational Linguistics.To appear.Dwight Bolinger.
1989.
Intonation and Its Uses:Melody in Grammar and Discourse.
EdwardArnold, London.289Leo Brieman, Jerome H. Friedman, Richard A. Ol-shen, and Charles J.
Stone?
1984.
Classificationand Regression Trees.
Wadsworth & Brooks,Monterrey CA.K.
W. Church.
1988.
A stochastic parts pro-gram and noun phrase parser for unrestrictedtext.
In Proceedings of the Second Conferenceon Applied Natural Language Processing, pages136-143, Austin.
Association for ComputationalLinguistics.DARPA.
1990.
Proceedings of the DARPA Speechand Natural Language Workshop, Hidden ValleyPA, June.J.
P. Gee and F. Grosjean.
1983.
Performancestructures: A psycholinguistic and linguistic ap-praisal.
Cognitive Psychology, 15:411-458.D.
M. Hindle.
1989.
Acquiring disambiguationrules from text.
In Proceedings of the 27th An-nual Meeting, pages 118-125, Vancouver.
Asso-ciation for Computational Linguistics.Julia Hirschberg.
1990.
Assigning pitch accentin synthetic speech: The given/new distinc-tion and deaccentability.
In Proceedings of theSeventh National Conference, pages 952-957,Boston.
American Association for Artificial In-telligence.I.
Lehiste.
1973.
Phonetic disambiguation f syn-tactic ambiguity.
Giossa, 7:197-222.David M. Magerman and Mitchel P. Marcus.1990.
Parsing a natural language using mu-tual information statistics.
In Proceedings ofAAAI-90, pages 984-989.
American Associationfor Artifical Intelligence.Mitchell P. Marc'us and Donald Hindle.
1985.
A?
computational ccount of extra categorial ele-ments in japanese.
In Papers presented at theFirst SDF Workshop in Japanese Syntaz.
Sys-tem Development Foundation.M.
Ostendorf, P. Price, J.
Bear, and C. W. Wight-man.
1990.
The use of relative duration insyntactic disambiguation.
In Proceedings of theDARPA Speech and Natural Language Work-shop.
Morgan Kanfmann, June.Janet B. Pierrehumbert.
1980.
The Phonologyand Phonetics of English Intonation.
Ph.D.thesis, Massachusetts Institute of Technology,September.Michael D. Riley.
1989.
Some applications of tree-based modelling to speech and language.
InProceedings.
DARPA Speech and Natural Lan-guage Workshop, October.E.
Selkirk.
1984.
Phonology and Syntaz.
MITPress, Cambridge MA.M.
Steedman.
1990.
Structure and intonation inspoken language understanding.
In Proceedingsof the ~Sth Annual Meeting of the Associationfor Computational Linguistics.Appendix: Key to Figuresfor eachtypetttwstetSWewlarapertperj{1-4}f{slr}potential boundary, < w~, wj >utterance typetotal # seconds in utterancetotal # words in utterancedistance (sec.)
from start to wjdistance (sec.)
from wj to enddistance (words) from start to wjdistance (words) from wj to endis wi accented or not/or, cliticized, deaecented, accentedis wj accented or not/or, cliticized, deaccented, accented\[distance (words) from last boundary\]/\[length (words) of last phrase\]\[distance (sec.)
from last boundary\]/\[length (see.)
of last phrase\]part-of-speech of wl- l,ldd + 1v = verb b - be-verbm -- modifier f = fn wordn = noun p = prepositionw=WHcategory ofs = smallest constit dominating wl,wj1 = largest eonstit dominating w~, not wjr = largest constit dominating wj, not wim = modifier d = determinerv = verb p = prepositionw -- WH n = nouns = sentence f = fn word290noel i5yes no01564564\[ no j2403/2556fsn:NnoIAno318/367nola'/1 no111/137 ....... "st <~t49455St:>2.~455Ino I,e l61/81 157/238Figure 1: Predictions from Automatically-Acquired an  Observed Data, 90%2911108/1118tr:<lot:>O1511198tr:>1.~11265tr:<ltr:<lIndNvh1718E~7-JB682ER,~ID,VBN,VBZ,NA.~D, IN,NAFigure 2: Phrase Boundary Predictions from Automatically-Inferred Information, 90%292
