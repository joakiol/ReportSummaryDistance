Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 55?64,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsSubjectivity and Sentiment Analysis of Modern Standard Arabic and ArabicMicroblogsAhmed Mourad and Kareem DarwishQatar Computing Research InstituteQatar FoundationDoha, Qatar{amourad, kdarwish}@qf.org.qaAbstractThough much research has been conductedon Subjectivity and Sentiment Analysis (SSA)during the last decade, little work has fo-cused on Arabic.
In this work, we focus onSSA for both Modern Standard Arabic (MSA)news articles and dialectal Arabic microblogsfrom Twitter.
We showcase some of the chal-lenges associated with SSA on microblogs.We adopted a random graph walk approach toextend the Arabic SSA lexicon using Arabic-English phrase tables, leading to improve-ments for SSA on Arabic microblogs.
Weused different features for both subjectivityand sentiment classification including stem-ming, part-of-speech tagging, as well as tweetspecific features.
Our classification featuresyield results that surpass Arabic SSA resultsin the literature.1 IntroductionSubjectivity and Sentiment Analysis has gained con-siderable attention in the last few years.
SSA hasmany applications ranging from identifying con-sumer sentiment towards products to voters?
reac-tion to political adverts.
A significant amount ofwork has focused on analyzing English text withmeasurable success on news articles and product re-views.
There has been recent efforts pertaining toexpanding SSA to languages other than English andto analyzing social text such as tweets.
To enable ef-fective SSA for new languages and genres, two mainrequirements are necessary: (a) subjectivity lexiconsthat broadly cover sentiment carrying words in thegenre or language; and (b) tagged corpora to trainsubjectivity and sentiment classifiers.
These twoare often scarce or nonexistent when expanding tonew languages or genres.
In this paper we focuson performing SSA on Arabic news articles and mi-croblogs.
There has been some recent work on Ara-bic SSA.
However, the available resources continueto lag in the following ways:(1) The size of existing subjectivity lexicons issmall, with low coverage in practical application.
(2) The available tagged corpora are limited to thenews domain, with no publicly available tagged cor-pora for tweets.To address the issue of limited lexicons, we appliedtwo methods to build large coverage lexicons.
In thefirst, we used Machine Translation (MT) to trans-late an existing English subjectivity lexicon.
In thesecond, we employed a random graph walk methodto automatically expand a manually curated Ara-bic lexicon.
For the later method, we used Arabic-English MT phrase tables that include both ModernStandard Arabic (MSA) as well as dialectal Arabic.As for tagged corpora, we annotated a new corpusthat includes 2,300 Arabic tweets.
We describe indetail the process of collecting tweets and some ofthe major attributes of tweets.The contribution of this paper is as follows:- We introduce strong baselines that employ Arabicspecific processing including stemming, POS tag-ging, and tweets normalization.
The baseline outper-forms state-of-the-art subjectivity classification forthe news domain.- We provide a new annotated dataset for Arabictweet SSA.- We employ a random graph walk algorithm to ex-55pand SSA lexicons, leading to improvements forSSA for Arabic tweets.The remainder of this paper is organized as fol-lows: Section 2 surveys related work; section 3introduces some of the challenges associated withArabic SSA; section 4 describes the lexicons weused; section 5 presents the experimental setup andresults; and section 6 concludes the paper and dis-cusses future work.2 Related WorkThere has been a fair amount work on SSA.Liu (2010) offers a thorough survey of SSA re-search.
He defines the problem of sentiment anal-ysis including associated SSA terms such as ob-ject, opinion, opinion holder, emotions, sentencesubjectivity, etc.
He also discusses the more popu-lar two stage sentiment and subjectivity classifica-tion approach at different granularities (documentand sentence levels) using different machine learn-ing approaches (supervised and unsupervised) alongwith different ways to construct the required data re-sources (corpora and lexicon).
In our work, we clas-sify subjectivity and sentiment in a cascaded fashionfollowing Wilson et al(2005).2.1 Subjectivity AnalysisOne of most prominent features for subjectivityanalysis is the existence of words in a subjectivitylexicon.
Mihalcea et al(2007) translated an ex-isting English subjectivity lexicon from Wiebe andRiloff (2005) using a bilingual dictionary.
They alsoused a subjectivity classifier to automatically anno-tate the English side of an English-Romanian paral-lel corpus and then project the annotations to the Ro-manian side.
The projected annotations were usedto train a subjectivity classifier.
In follow on work,Banea et al(2010) used MT to exploit annotatedSSA English corpora for other languages, includingArabic.
They also integrated features from multiplelanguages to train a combined classifier.
In Baneaet al(2008), they compared the automatic annota-tion of non-English text that was machine translatedinto English to automatically or manually translatingannotated English text to train a classifier in the tar-get language.
In all these cases, they concluded thattranslation can help avail the need for building lan-guage specific resources.
In performing both subjec-tivity and sentiment classification, researchers haveused word, phrase, sentence, and topic level fea-tures.
Wilson et al(2005) report on such featuresin detail, and we use some of their features in ourbaseline runs.
For Arabic subjectivity classification,Abdul-Mageed et al(2011) performed sentence-level binary classification.
They used a manually cu-rated subjectivity lexicon and corpus that was drawnfrom news articles (from Penn Arabic tree bank).They used features that are akin to those devel-oped by Wilson et al(2005).
In later work, Abdul-Mageed et al(2012) extended their work to socialcontent including chat sessions, tweets, Wikipediadiscussion pages, and online forums.
Unfortunately,their tweets corpus is not publicly available.
Theyadded social media features such as author informa-tion (person vs. organization and gender).
Theyalso explored Arabic specific features that includestemming, POS tagging, and dialect vs. MSA.
Theirmost notable conclusions are: (a) POS tagging helpsand (b) Most dialectal Arabic tweets are subjective.Concerning work on subjectivity classification onEnglish tweets, Pak and Paroubek (2010) created acorpus of tweets for SSA.
They made a few funda-mental assumptions that do not generalize to Arabicwell, namely:- They assumed that smiley and sad emoticons implypositive and negative sentiment respectively.
Dueto the right-to-left orientation of Arabic text, smi-ley and sad emoticons can be easily interchanged bymistake in Arabic.- They also assumed that news tweets posted bynewspapers Twitter accounts are neutral.
This as-sumption is not valid for Arabic news articles be-cause many Arabic newspapers are overly critical orbiased in their reporting of news.
Thus, the major-ity of news site tweets have sentiment.
Consider thefollowing headline:?J?K ?????Y?
@ 	??
@ ?
?m' P@Q?J?
@ ?k.
A?E?JKY?@?Jj.
??
@Yg.
A???
@?
?K@meaning: Religious Council critical of State Secu-rity over interference in hiring of clerics.- They constructed their tweet sets to be uniformlydistributed between subjective and objective classes.However, our random sample of Arabic tweetsshowed that 70% of Arabic tweets are subjective.So this kind of training is misleading especially for aNa?
?ve Bayesian classifier that utilizes the prior prob-ability of classes.2.2 Sentiment AnalysisAbbasi et al(2008) focused on conducting senti-ment classification at document level.
They used56syntactic, stylistic, and morphological (for Arabic)features to perform classification.
Abdul-Mageed etal.
(2011) performed sentence-level sentiment clas-sification for MSA.
They concluded that the ap-pearance of a positive or negative adjective, basedon their lexicon, is the most important feature.
Inlater work, Abdul-Mageed et al(2012) extendedtheir work to social text.
They concluded that: (a)POS tags are not as effective in sentiment classifi-cation as in the subjectivity classification, and (b)most dialectal Arabic tweets are negative.
Lastly,they projected that extending/adapting polarity lex-icon to new domains; e.g.
social media; would re-sult in higher gains.
Kok and Brockett (2010) in-troduced a random-walk-base approach to generateparaphrases from parallel corpora.
They proved tobe more effective in generating more paraphrases bytraversing paths of lengths longer than 2.
El-Kahkyet al(2011) applied graph reinforcement on translit-eration mining problem to infer mappings that wereunseen in training.
We used this graph reinforce-ment method in our work.3 Challenges for SSA of ArabicArabic SSA faces many challenges due to the poor-ness of language resources and to Arabic-specificlinguistic features.Lexicon: Lexicons containing words with priorpolarity are crucial feature for SSA.
The most com-mon English lexicon that has been used in liter-ature is the Multi-Perspective Question Answer-ing (MPQA) lexicon, which contains 8,000 words.Some relied on the use of MT to translate Englishlexicons to languages that lack SSA resources (Mi-halcea et al 2007).
A lexicon that is translatedinto Arabic may have poor coverage due to the mor-phological and orthographic complexities of Arabic.Arabic nouns and verbs are typically derived from aset of 10,000 roots that are cast into stems using tem-plates that may add infixes, double letters, or removeletters.
Stems can accept the attachment of prefixesor suffixes, such as prepositions, determiners, pro-nouns, etc.
The number of possible Arabic surfaceforms is in the order of billions.
In this work, weemployed stemming and graph reinforcement to im-prove the converge of lexicons.Negation: Negation in dialects can be expressedin many ways.
In MSA, the word ??
(meaning?not?)
is typically used to negate adjectives.
Dialectsuse many words to negate adjectives including:??A?,?
?, ?
?, A?, ?
J?, etc.
These words can have othermeanings also.
For example, ??A?
also means ?whatis?.
As for verbs, some dialects like Egyptian andLevantine use a negation construct akin to the ?ne... pas?
construct in French.
All these make detect-ing negation hard.
We use word n-gram features toovercome this problem.Emoticons: Another challenge has to do withthe limited usefulness of emoticons, because Ara-bic?s smileys and sad emoticons are often mistak-enly interchanged.
Thus, many tweets have wordsand emoticons that are contradictory in sentiment.For example:): ??A?
@ 	??
?J??
?<?
@ ???
.meaning: with the help of God over your pain (pos-itive) : followed by a sad face(: A?D??
?<?
@ ??.
?k Ik@' ?YJ?
AK@meaning: I have a sister from which I seek the pro-tection of Allah (negative) : followed by a smilieUse of dialects: Though most Arabic speakerscan read and understand MSA, they generally usedifferent Arabic dialects in their daily interactionsincluding online social interaction 1.
There are6 dominant dialects, namely Egyptian, Moroccan,Levantine, Iraqi, Gulf, and Yemeni.
Dialects intro-duce many new words into the language, particularlystopwords (ex.
YgA?
and ?
J ?
mean ?no one?
and?what?
respectively).
Dialects lack spelling stan-dards (ex.
? 	Q??A?
and ? 	Q???
are varying spellingsof ?I did not know?
in Egyptian).
Different dialectsmake different lexical choices for concepts (ex.
?
?AK.and ??A?
mean ?good?
in Morrocan and Libyan re-spectively).
Due to morphological divergence of di-alectal text from MSA, word prefixes and suffixescould be different.
For example, Egyptian and Lev-antine tend to insert the letter H.
(?ba?)
before verbsin present tense.
Building lexicons that cover multi-ple dialects is cumbersome.
Further, using MT tobuild SSA lexicons would be suboptimal becausemost MT systems perform poorly on dialects of Ara-1http://en.wikipedia.org/wiki/Varieties_of_Arabic57bic.Tweet specific phenomena: Tweets may con-tain transliterated words (?LOL?
?
???)
and non-Arabic words, particularly hashtags such as #syria.Tweets are often characterized by the informalityof language and the presence of name mentions(@user mention), hashtags, and URL?s.
Further,tweets often contain a significant percentage of mis-spelled words.Contradictory language: Often words with neg-ative sentiment are used to express positive senti-ment:???K.
ZYJ.K?
, ?K.
?A?J?B@ ?Y??
X?Q.
?
AK.
??KA?
@ Q?A?JK??A?
@ Yg ??
@ ??
?
?K IKA?
A?E@' ???
@ .
.
??
?Z?K Y??A??
@'meaning: a female pretends to be cold and uninter-ested and may even use hurtful words.
Know thatshe painfully loves you.Other observations: We also observed the fol-lowing:- Users tend to express their feelings through ex-tensive use of Quranic verses, Prophetic sayings,proverbs, and poetry.- Of the annotated tweets in our corpus, nearly13.5% were sarcastic.- People primarily use tweets to share their thoughtsand feelings and to report facts to a lesser extent.
Inthe set we annotated, 70% of the tweets were sub-jective and 30% were objective.
Of the subjectivetweets (positive and negative only), the percentageof positive tweets was 66% compared to 34% fornegative tweets.4 SSA LexiconWe employed two lexicons that were available to us,namely:- The MPQA lexicon, which contains 8,000 Englishwords that were manually annotated as strong sub-jective (subjective in most contexts) or weak sub-jective (subjective in some contexts) and with theirprior polarity (positive, negative, neutral, or both).We used the Bing online MT system 2 to translatethe MPQA lexicon into Arabic.- The ArabSenti lexicon (Abdul-Mageed et al2011) containing 3,982 adjectives that were ex-tracted from news data and labeled as positive, neg-2http://www.bing.com/translator/Figure 1: Example mappings seen in phrase tableative, or neutral.
We optionally used graph rein-forcement to expand the ArabSenti lexicon usingMT phrase tables, which were modeled as a bipar-tite graph (El-Kahky et al 2011).
As shown in Fig-ure 1, given a seed lexicon, graph reinforcement isthen used to enrich the lexicon by inferring addi-tional mappings.
Specifically, given the word withthe dotted outline, it may map to the words ?unfair?and ?unjust?
in English that in turn map to other Ara-bic words, which are potentially synonymous to theoriginal word.
We applied a single graph reinforce-ment iteration over two phrase tables that were gen-erated using Moses (Koehn et al 2007).
The twophrase tables were:- an English-MSA phrase table, which was trainedon a set of 3.69 million parallel sentences contain-ing 123.4 million English tokens.
The sentenceswere drawn from the UN parallel data along witha variety of parallel news data from LDC and theGALE project.
The Arabic side was stemmed (byremoving just prefixes) using the Stanford word seg-menter (Green and DeNero, 2012).- an English-Dialect phrase table, which was trainedon 176K short parallel sentences containing 1.8MEgyptian, Levantine, and Gulf dialectal words and2.1M English words (Zbib et al 2012).
The Ara-bic side was also stemmed using the Stanford wordsegmenter.More formally, Arabic seed words and their En-glish translations were represented using a bipartitegraph G = (S, T, M), where S was the set of Arabicwords, T was the set of English words, and M wasthe set of mappings (links or edges) between S andT.
First, we found all possible English translationsT ?
?
T for each Arabic word si ?
S in the seedlexicon.
Then, we found all possible Arabic trans-lations S?
?
S of the English translations T ?.
Themapping score m(sj ?
S?|si) would be computed58as:1??
?sj ,si?S,t?T ?
(1?p(t|si)?t p(si|t)p(sj |t)?sjp(t|sj)) (1)where the terms in the denominator are normaliza-tion factors and the product computes the probabilitythat a mapping is not correct given all the paths fromwhich it was produced.
Hence, the score of an in-ferred mapping would be boosted if it was obtainedfrom multiple paths, because the product would havea lower value.5 Experimental Setup5.1 Corpus, Classification, and ProcessingFor subjectivity and sentiment classification exper-iments on Arabic MSA news, we used the trans-lated MPQA dataset and the ArabSenti dataset re-spectively.
As for SSA on Arabic tweets, to thebest of our knowledge, there is no publicly avail-able dataset.
Thus, we built our own.
We crawledTwitter using the Twitter4j API (Yanamoto, 2011)using the query ?lang:ar?
to restrict tweets to Ara-bic ones only.
In all, we collected 65 million uniqueArabic tweets in the time period starting from Jan-uary to December 2012; we made sure that dupli-cate tweets were ignored during crawling.
Then werandomly sampled 2300 tweets (nearly 30k words)from the collected set and we gave them to two na-tive Arabic speakers to manually annotate.
If the twoannotators disagreed on the annotation of a tweet,they discussed it to resolve the disagreement.
If theycouldn?t resolve the disagreement, then the tweetwas discarded, which would somewhat affect theSSA effectiveness numbers.
They applied one offive possible labels to the tweets, namely: neutral,positive, negative, both, or sarcastic.
For subjectiv-ity analysis, all classes other than neutral were con-sidered subjective.
As for sentiment analysis, weonly considered positive and negative tweets.
Forboth subjectivity and sentiment classification exper-iments, we used 10-fold cross validation with 90/10training/test splits.
We used the NLTK (Bird, 2006)implementation of the Na?
?ve Bayesian classifier forall our experiments.
In offline experiments, theBayesian classifier performed slightly better than anSVM classifier.
The classifier assigned a sentence ortweet the class c ?
C that maximizes:argmaxc?CP (c)n?i=1P (fi|c) (2)where f is the feature vector and C is the set ofpre-defined classes.
As for stemming and POSTagging, we used an in-house reimplementation ofAMIRA (Diab, 2009).
We report accuracy as wellas precision, recall and F-measure for each class.5.2 Baseline: SSA for MSA5.2.1 Subjectivity ClassificationAs mentioned in section 2, we employed some ofthe SSA features that were shown to be successful inthe literature (Wiebe and Riloff, 2005; Wilson et al2005; Yu and Hatzivassiloglou, 2003) to constructour baseline objective-subjective classifier.
We usedthe automatically translated MPQA and the Arab-Senti lexicons.
We tokenized and stemmed all wordsin the dataset and the lexicon.
Part of the tokeniza-tion involved performing letter normalization wherethe variant forms of alef (@,@, and @) were normal-ized to the bare alef ( @), different forms of hamza (?
'and Z?')
were normalized to hamza (Z), ta marbouta( ?)
was normalized to ha ( ?
), and alef maqsoura (?
)was normalized to ya (?).
We used the followingfeatures:Stem-level features:- Stem is a binary features that indicates the presenceof the stem in the sentence.- Stem prior polarity as indicated in the translatedMPQA and ArabSenti lexicons (positive, negative,both or neutral).
Stems and their prior polarity werereportedly the most important features in Wilson etal.
(2005).- Stem POS, which has been shown to be effective inthe work done by (Wiebe and Riloff, 2005; Yu andHatzivassiloglou, 2003).
Although Abdul-Mageedet al(2011) used a feature to indicate if a stemis an adjective or not, other tags, such as adverbs,nouns, and verbs, may be good indicators of senti-ment.
Thus, we used a feature that indicates the POStag of a stem as being: adjective, adverb, noun, IV,PV, or other, concatenated with the stem.
For exam-ple, the stem ?play?
may be assigned ?play-noun?if it appears as a noun in a sentence.
We chose thisreduced POS set based on the frequency distribution59Acc Prec Rec F-MeasObj Subj Obj Subj Obj SubjBanea et al(2010) 72.2 72.6 72.0 60.8 81.5 66.2 76.4Baseline-MPQA 77.2 83.4 74.2 61.4 90.0 70.7 81.4Baseline-ArabSenti 76.7 82.4 73.9 60.9 89.5 70.0 80.9Expanded-ArabSenti-MSA 76.7 83.2 73.6 60.0 90.2 69.7 81.0Expanded-ArabSenti-MSA+Dialect 76.7 82.9 73.7 60.4 89.9 69.9 81.0Table 1: Baseline Results for MSA Subjectivity Classifier.Acc Prec Rec F-MeasPos Neg Pos Neg Pos NegBaseline-MPQA 80.6 75.4 84.0 78.0 82.5 76.5 83.2Baseline-ArabSenti 80.5 75.4 84.6 78.6 81.5 76.8 82.9Expanded-ArabSenti-MSA 80.0 74.9 83.9 77.8 81.4 76.2 82.6Expanded-ArabSenti-Dialect 79.2 73.7 82.8 76.0 81.2 74.6 81.9Table 2: Baseline Results for MSA Polarity Classifier.of POS tags and subjectivity classes in the trainingdata.- Stem context as the stem bi-gram containing thestem along with the previous stem.
We experi-mented with higher order stem n-grams, but bigramsyielded the best results.Sentence features: These features have beenshown to be effective by Wiebe and Riloff (2005).They include:- Counts of stems belonging to so-called reliabil-ity classes (Wiebe and Riloff, 2005), which are ba-sically either strong-subjective and weak-subjectivetokens (as indicated in the SSA lexicon).- Counts of POS tags where we used the counts ofthe POS tags that used for stem features (adjective,adverb, noun, IV, and PV).We compared our baseline results with the resultsreported by Banea et al(2010) for Arabic subjec-tivity classification.
We used their Arabic MPQAcorpus that has been automatically translated fromEnglish and then projected subjectivity labels withthe same training/test splits.
The 9,700 sentencesin this corpus are nearly balanced with a 55/45 sub-jective/objective ratio.
Table 1 shows the results forMSA subjectivity classification compared to the re-sults of Banea et al(2010).
Our baseline system im-proved upon the results of Banea et al(2010) by 5%(absolute) in accuracy with significant gains in bothprecision and recall.
Using MPQA or ArabSenti lex-icons yielded comparable results with MPQA yield-ing marginally better results.
We think that muchof improvement that we achieve over the results ofBanea et al(2010) could be attributed to stemmingand POS tagging.5.2.2 Polarity ClassificationFor polarity classification experiments, we usedthe positive and negative sentences from the Arab-Senti dataset (Abdul-Mageed and Diab, 2011).From the 2,855 sentences in ArabSenti, 45% wereobjective, 17.2% were positive, 24.1% were nega-tive and the rest were both.
We employed the fol-lowing features:Stem-level features:- Stem, Stem prior polarity, and Stem POS tag as insubjectivity classification- Stem context where we considered a stem and thetwo preceding stems.
In offline experiments, wetried looking at more and less context and using thetwo previous stems yielded the best results.
The in-tuition to use stem context is to compensate for thedifficulties associated with ?negation?
in Arabic (asmentioned earlier section 3).Sentence-level features: We used only one bi-nary feature that checks for the occurrence of pos-itive adjectives in the sentence.
We experimentedwith other features that aggregate other POS tagswith their prior polarity including negative adjec-tives and all led to worse classification results.Table 2 reports on the baseline results of doingsentiment classification.
The results of using eitherMPQA or ArabSenti lexicons were comparable.60Acc Prec Rec F-MeasObj Subj Obj Subj Obj SubjBaseline-Majority-Class 70.0 0.0 70.0 0.0 100.0 0.0 83.0Baseline-MSA 55.1 53.8 56.4 54.5 55.8 54.1 56.1Baseline-MPQA 64.8 44.9 81.4 66.5 64.0 53.5 71.5Baseline-ArabSenti 63.9 43.8 80.8 65.9 62.9 52.5 70.7Expanded-ArabSenti-MSA 64.1 44.2 81.1 66.3 63.3 52.8 71.0Expanded-ArabSenti-Dialect 63.1 43.2 80.3 65.5 62.1 51.9 70.0Table 3: Baseline Results for Arabic Tweets Subjectivity Classifier.Acc Prec Rec F-MeasPos Neg Pos Neg Pos NegBaseline-MSA 54.8 63.2 45.7 55.5 53.8 59.1 49.4Baseline-MPQA 72.2 85.9 57.0 69.0 77.8 76.3 65.5Baseline-Arabsenti 71.1 83.9 55.9 69.2 74.8 75.8 63.8Expanded-ArabSenti-MSA 72.5 86.1 57.7 69.1 79.3 76.5 66.4Expanded-ArabSenti-Dialect 71.3 85.5 56.3 68.0 77.8 75.6 65.1Table 4: Baseline Results for Arabic Tweets Polarity Classifier.5.3 Baseline: SSA of Arabic Microblogs5.3.1 Subjectivity ClassificationWe have four baselines for subjectivity classifica-tion of Arabic tweets, namely:Baseline-Majority-Class for which we consideredall the tweets to be subjective, where ?subjective?was the majority class.Baseline-MSA for which we used the aforemen-tioned MSA subjectivity classifier using the MPQAlexicon (section 5.2).Baseline-MPQA and Baseline-ArabSenti forwhich we used microblog specific features and theMPQA and ArabSenti lexicons respectively.
Weused the following features:Stem-level features:- Stems, where we normalized words using thescheme described by Darwish et al(2012).
Theirwork extended the basic Arabic normalization tohandle non-Arabic characters that were borrowedfrom Farsi and Urdu for decoration decorate andwords elongation and shortening.
After normaliza-tion, words were stemmed.- MSA or dialect, which is a binary feature that indi-cates whether the stem appears in a large MSA stemlist (containing 82,380 stems) which was extractedfrom a large Arabic news corpus from Aljazeera.net.- Stem prior polarity and Stem POS as those forMSA subjectivity classification.Tweets-specific features: Following Barbosa andFeng (2010) and Kothari et al(2013), we took ad-vantage of tweet specific features, namely:- Presence of hashtag (#tag).- Presence of user mention (@some user) and posi-tion in the tweet (start, end and middle).- Presence of URL and position in the tweet (start,end and middle).- Presence of retweet symbol ?RT?
and position inthe tweet (start, end and middle).?RT?
and URL?s usually appear in the beginningand end of tweets respectively, particularly whenretweeting news articles.
A change in their positionmay indicate that the person retweeting added textto the tweet, often containing opinions or sentiment.Language-independent features: These are bi-nary features that look for non-lexical markers thatmay indicate sentiment.
They are:- Usage of decorating characters.
e.g.
?
instead of?.- Elongation (detecting both repeated uni-gram & bi-gram character patterns.
e.g.
??????
(looool), A?A?A?
(hahaha).- Punctuation; exclamation and question marks.- Elongated punctuation marks (e.g.
??
?, !!!!!
)- Emoticons (e.g.
:), :(, :P ...
etc.
).Sentence-level features: We used the counts ofso-called reliability classes, which count the numberof strong-subjective and weak-subjective words.Table 3 shows the results for subjectivity anal-ysis on tweets.
Baseline-Majority-Class was thebest given that most Arabic tweets were subjec-61tive.
Tweet-specific features were not discrimina-tive enough to outperform Baseline-Majority-Class.Thus, assuming that all tweets are subjective seemsto be the most effective option.
However, it is worthnoting that using a classifier that was trained on di-alectal tweets yielded better results than using a clas-sifier that was trained on news in MSA.
Again usingeither lexicon made little difference.5.3.2 Polarity ClassificationOur work on MSA showed that stem and stemprior polarity are the most important features forthis task.
We used these two features, and we addeda third binary feature that indicates the presence ofpositive emoticons.
Negative emoticons appearedinfrequently in both training and test sets.
Hence us-ing a feature that indicates the presence of negativeemoticons would be unreliable.
Again we used theMPQA or ArabSenti lexicons, both of which wereconstructed from news domain (Baseline-MPQAand Baseline-ArabSenti respectively).
For refer-ence, we used the sentiment classifier trained on theMSA news set as a reference (Baseline-MSA).
Ta-ble 4 shows the results for sentiment classificationon tweets.
Training a classifier with in-domain data(tweets) enhanced classification effectiveness signif-icantly with a gain of 17.4% (absolute) in accuracyand 17.2% and 16.1% (absolute) improvement inF-measure for positive and negative classes respec-tively.
We saw that MPQA led to slightly better re-sults than ArabSenti.5.4 Lexicon ExpansionWe chose to expand the ArabSenti lexicon usinggraph reinforcement instead of the MPQA lexi-con because the ArabSenti was curated manually.The MPQA lexicon had many translation errorsand automatic expansion would have likely mag-nified the errors.
We repeated all our Baseline-ArabSenti experiments using the expanded Arab-Senti lexicon.
We expanded using the English-MSA(Expanded-ArabSenti-MSA) and the English-Dialect (Expanded-ArabSenti-Dialect) phrase ta-bles.Table 1 reports on the expansion results for MSAnews subjectivity classification.
The expanded lexi-con marginally lowered classification effectiveness.This is surprising given that the number of tokensthat matched the lexicon increased more than fivefold compared to the baseline (105k matches forthe baseline and 567k and 550k matches for theEnglish-MSA and English-Dialect phrase tables re-spectively).
As shown in Table 2, we observed asimilar outcome for the expanded lexicon results,compared to baseline results, for MSA sentimentclassification.
Though expansion had little effecton classification, we believe that the expanded lex-icon can help generalize the lexicon to new out-of-domain data.Tables 3 and 4 report subjectivity and sentimentclassification of Arabic tweets respectively.
Lexi-con expansion had some positive impact on subjec-tivity classification with improvements in both accu-racy, precision, and recall.
Lexicon expansion had alarger effect on sentiment classification for tweetswith improvement accuracy, precision, and recallwith improvements ranging between 1-3% (abso-lute).
The coverage of the lexicon increased nearly4-folds compared to the baseline (19k matches forbaseline compared to 75k matches with expansionfor subjectivity, and 7k matches for baseline com-pared to 28k matches with expansion for sentimentclassification).
For both subjectivity and sentimentclassification, using the English-MSA phrase tablewas better than using the English-Dialect phrase ta-ble.
This is not surprising given the large differencein size between the two phrase tables.6 Conclusion and Future WorkIn this paper we presented a strong baseline systemfor performing SSA for Arabic news and tweets.
Inour baseline, we employed stemming and POS tag-ging, leading to results that surpass state-of-the-artresults for MSA news subjectivity classification.
Wealso introduced a new tweet corpus for SSA, whichwe plan to release publicly.
We also employed tweetspecific language processing to improve classifica-tion.
Beyond our baseline, we employed graph rein-forcement based on random graph walks to expandthe SSA lexicon.
The expanded lexicon had muchbroader coverage than the original lexicon.
This ledto improvements in both subjectivity and sentimentclassification for Arabic tweets.For future work, we plan to explore other featuresthat may be more discriminative.
We would like to62investigate automatic methods to increase the sizeof SSA training data.
This can be achieved by eitherutilizing bootstrapping methods or applying MT onlarge English tweets corpora.
Another problem thatdeserves thorough inspection is the identification ofpolarity modifiers such as negation.ReferencesAhmed Abbasi, Hsinchun Chen, and Arab Salem.
2008.Sentiment analysis in multiple languages: Featureselection for opinion classification in web forums.ACM Transactions on Information Systems (TOIS),26(3):12, 2008.Muhammad Abdul-Mageed, Mona Diab, and Mo-hammed Korayem.
2011.
Subjectivity and sentimentanalysis of modern standard arabic.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 587?591, 2011.Muhammad Abdul-Mageed and Mona T. Diab.
2011.Subjectivity and sentiment annotation of modern stan-dard arabic newswire.
ACL HLT 2011, page 110,2011.Muhammad Abdul-Mageed, Sandra Ku?bler, and MonaDiab.
2012.
Samar: A system for subjectivity and sen-timent analysis of arabic social media.
WASSA 2012,page 19, 2012.Carmen Banea, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivity analy-sis using machine translation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 127?135.Carmen Banea, Rada Mihalcea, and Janyce Wiebe.
2010.Multilingual subjectivity: are more languages better?In Proceedings of the 23rd International Conferenceon Computational Linguistics, pages 28?36.
Associa-tion for Computational Linguistics, 2010.Luciano Barbosa and Junlan Feng.
2010.
Robust senti-ment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, pages 36?44.Association for Computational Linguistics.Steven Bird.
2006.
NLTK: the natural language toolkit.In Proceedings of the COLING/ACL on Interactivepresentation sessions, pages 69?72.
Association forComputational Linguistics, 2006.Kareem Darwish, Walid Magdy, and Ahmed Mourad.2012.
Language processing for arabic microblog re-trieval.
In Proceedings of the 21st ACM internationalconference on Information and knowledge manage-ment, pages 2427?2430.
ACM, 2012.Mona Diab.
2009.
Second Generation Tools (AMIRA2.0): Fast and Robust Tokenization, POS tagging, andBase Phrase Chunking.
In 2nd International Confer-ence on Arabic Language Resources and Tools, 2009.Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein,Mohamed Abd El-Wahab, Ahmed Hefny, and WaleedAmmar.
2011.
Improved transliteration mining usinggraph reinforcement.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 1384?1393.
Association for Computa-tional Linguistics, 2011.Spence Green and John DeNero.
2012.
A Class-BasedAgreement Model for Generating Accurately InflectedTranslations.
ACL 2012.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, and others.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Annual meeting-association for computational linguistics.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time HLT-NAACL-2010, pages145?153.Alok Kothari, Walid Magdy, Kareem Darwish, AhmedMourad, and Ahmed Taei.
2013.
Detecting Com-ments on News Articles in Microblogs ICWSM, pages145?153.Bing Liu.
2010.
Sentiment analysis and subjectiv-ity.
Handbook of Natural Language Processing, pages627?666, 2010.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2007.Learning multilingual subjective language via cross-lingual projections.
In ACL-2007, volume 45, page976, 2007.Alexander Pak and Patrick Paroubek.
2010.
Twitter as acorpus for sentiment analysis and opinion mining.
InProceedings of LREC, volume 2010, 2010.Janyce Wiebe and Ellen Riloff.
2005.
Creating sub-jective and objective sentence classifiers from unan-notated texts.
In Proceedings of CICLing 2005.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity: An explo-ration of features for phrase-level sentiment analysis.Computational linguistics, 35(3):399?433, 2009.Yusuke Yanamoto.
2011.
Twitter4j: A java library forthe twitter api, 2011.Hong Yu and Vasileios Hatzivassiloglou 2003.
Towardsanswering opinion questions: Separating facts fromopinions and identifying the polarity of opinion sen-tences In EMNLP-2003, pages 129?136.
Associationfor Computational Linguistics.Rabih Zbib, Erika Malchiodi, Jacob Devlin, DavidStallard, Spyros Matsoukas, Richard Schwartz, John63Makhoul, Omar F. Zaidan and Chris Callison-Burch.2012.
Machine translation of arabic dialects.
In Pro-ceedings of NAACL.64
