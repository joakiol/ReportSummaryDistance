Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 324?333,Honolulu, October 2008. c?2008 Association for Computational LinguisticsImproving Chinese Semantic Role Classificationwith Hierarchical Feature Selection StrategyWeiwei DingInstitute of Computational LinguisticsPeking UniversityBeijing, 100871, Chinaweiwei.ding.pku@gmail.comBaobao ChangInstitute of Computational LinguisticsPeking UniversityBeijing, 100871, Chinachbb@pku.edu.cnAbstractIn recent years, with the development of Chi-nese semantically annotated corpus, such asChinese Proposition Bank and NormalizationBank, the Chinese semantic role labeling(SRL) task has been boosted.
Similar to Eng-lish, the Chinese SRL can be divided into twotasks: semantic role identification (SRI) andclassification (SRC).
Many features were in-troduced into these tasks and promising re-sults were achieved.
In this paper, we mainlyfocus on the second task: SRC.
After exploit-ing the linguistic discrepancy between num-bered arguments and ARGMs, we built a se-mantic role classifier based on a hierarchicalfeature selection strategy.
Different from theprevious SRC systems, we divided SRC intothree sub tasks in sequence and trained modelsfor each sub task.
Under the hierarchical ar-chitecture, each argument should first be de-termined whether it is a numbered argumentor an ARGM, and then be classified into fine-gained categories.
Finally, we integrated theidea of exploiting argument interdependenceinto our system and further improved the per-formance.
With the novel method, the classi-fication precision of our system is 94.68%,which outperforms the strong baseline signifi-cantly.
It is also the state-of-the-art on Chi-nese SRC.1 IntroductionSemantic Role labeling (SRL) was first defined inGildea and Jurafsky (2002).
The purpose of SRLtask is to identify and classify the semantic roles ofeach predicate in a sentence.
The semantic rolesare marked and each of them is assigned a tagwhich indicates the type of the semantic relationwith the related predicate.
Typical tags includeAgent, Patient, Source, etc.
and some adjunctssuch as Temporal, Manner, Extent, etc.
Since thearguments can provide useful semantic information,the SRL is crucial to many natural language proc-essing tasks, such as Question and Answering (Na-rayanan and Harabagiu 2004), Information Extrac-tion (Surdeanu et al 2003),  and Machine Transla-tion(Boas 2002).
With the efforts of many re-searchers (Carreras and M?rquez 2004, 2005, Mo-schitti 2004, Pradhan et al2005, Zhang et al2007),different machine learning methods and linguisticsresources are applied in this task, which has madeSRL task progress fast.Compared to the research on English, the re-search on Chinese SRL is still in its infancy stage.Previous work on Chinese SRL mainly focused onhow to transplant the machine learning methodswhich has been successful with English, such asSun and Jurafsky (2004), Xue and Palmer (2005)and Xue (2008).
Sun and Jurafsky (2004) did thepreliminary work on Chinese SRL without anylarge semantically annotated corpus of Chinese.They just labeled the predicate-argument structuresof ten specified verbs to a small collection of Chi-nese sentences, and used Support Vector Machinesto identify and classify the arguments.
This papermade the first attempt on Chinese SRL and pro-duced promising results.
After the PropBank (Xueand Palmer 2003) was built, Xue and Palmer (2005)and Xue (2008) have produced more complete andsystematic research on Chinese SRL.Moschitti et al (2005) has made some prelimi-nary attempt on the idea of hierarchical semantic324role labeling.
However, without considerations onhow to utilize the characteristics of linguisticallysimilar semantic roles, the purpose of the hierar-chical system is to simplify the classification proc-ess to make it less time consuming.
So the hierar-chical system in their paper performs a little worsethan the traditional SRL systems, although it ismore efficient.Xue and Palmer (2004) did very encouragingwork on the feature calibration of semantic rolelabeling.
They found out that different featuressuited for different sub tasks of SRL, i.e.
semanticrole identification and classification.
For semanticanalysis, developing features that capture the rightkind of information is crucial.
Experiments onChinese SRL (Xue and Palmer 2005, Xue 2008)reassured these findings.In this paper, we mainly focus on the semanticrole classification (SRC) process.
With the find-ings about the linguistic discrepancy of differentsemantic role groups, we try to build a 2-step se-mantic role classifier with hierarchical feature se-lection strategy.
That means, for different sub tasks,different models will be trained with different fea-tures.
The purpose of this strategy is to capture theright kind of information of different semantic rolegroups.
It is hard to do manual selection of featuressince there are too many feature templates whichhas been proven to be useful in SRC; so, we de-signed a simple feature selection algorithm to se-lect useful features automatically from a large setof feature templates.
With this hierarchical featureselection architecture, our system can outperformprevious systems.
The selected feature templatesfor each process of SRC can in turn reassure theexistence of the linguistic discrepancy.
At last, wealso integrate the idea of exploiting argument in-terdependence to make our system perform better.The rest of the paper is organized as follows.
Insection 2, the semantically annotated corpus - Chi-nese Propbank is discussed.
The architecture of ourmethod is described in section 3.
The feature selec-tion strategy is discussed in section 4.
The settingsof experiments can be found in section 5.
The re-sults of the experiments can be found in section 6,where we will try to make some linguistic explana-tions of the selected features.
Section 7 is conclu-sions and future work.Figure 1. an example from PropBank2 The Chinese PropBankThe Chinese PropBank has labeled the predicate-argument structures of sentences from the ChineseTreeBank (Xue et al 2005).
It is constituted of twoparts.
One is the labeled data, which indicates thepositions of the predicates and its arguments in theChinese Treebank.
The other is a dictionary whichIP??
??
???
?P NN NTNP-PN-SBJ VPPP-BNF VPVVNP-OBJ NPNN??
??
?
?f1 NN?????
?AD NN PARG2ADVPARG0 PP-TMP ARGM-TMPhas the Sanxia Project insurance provideARGM-ADVARG1service forthe insurance company now untilUntil now,          the insurance company     has       provided   insurance services       for       the Sanxia Project.325lists the frames of all the labeled predicates.
Figure1 is an example from the PropBank1.
We put theword-by-word translation and the translation of thewhole sentence below the example.It is quite a complex sentence, as there are manysemantic roles in it.
In this sentence, all the seman-tic roles of the verb ??
(provide) are presented inthe syntactic tree.
We can separate the semanticroles into two groups.The first group of semantic roles can be calledthe core arguments, which capture the core rela-tions.
In this sentence, there are three arguments ofverb ??
(provide) in this sentence.
????
(the insurance company) is labeled as ARG0,which is the proto-agent of the verb.
Specifically tothe verb ??
(provide), it is the provider.
????
(insurance services) is the direct object of theverb, and it is the proto-patient, which is labeled asARG1.
Specifically to the verb ??
(provide), itrepresents things provided.
?????
(for theSanxia Project) is  another kind of argument,which is labeled as ARG1, and it represents thereceiver.The other group of semantic roles is called ad-juncts.
They are always used to reveal the periph-eral information.
There are two adjuncts of the tar-get verb in this sentence: ????
(until recently)and ?
(has), both of which are labeled as ARGM.However, the two ARGMs reveal information ofdifferent aspects.
Besides the ARGM tags, the sec-ondary tags ?TMP?
and ?ADV?
are assigned to thetwo semantic roles respectively.
?TMP?
indicatesthat????
(until recently)  is a modifier repre-senting the temporal information, and ?ADV?
in-dicates that?
(has) is an adverbial modifier.In the Chinese PropBank, the difference of thetwo groups is obvious.
The core arguments are alllabeled with numbers, and they are also called thenumbered arguments.
The numbers range from 0 to4 in Chinese PropBank.
The adjuncts are labeledwith ?ARGM?.3 Building a Hierarchical Semantic RoleClassifierIn this section, we will discuss the linguistic fun-daments of the construction of a hierarchical se-1 This sentence is extracted from chtb_082.fid of ChinesePropBank 1.0, and we made some simplifications on it.mantic role classifier.
We use ?hierarchical?
to dis-tinguish our classifier from the previous ?flat?
ones.3.1 Linguistic Discrepancy of Different Se-mantic Role GroupsThe purpose of the SRC task is to assign a tag toall the semantic roles which have been identified.The tags include ARG0-4, and 17 kinds ofARGMs (with functional tags).
Previous SRC sys-tems treat all the tags equally, and view the SRC asa multi-category classification task.
However, wehave different opinions of the traditional architec-ture.Due to the discussions in section 2, we noticedthat the semantic roles can be divided into twogroups naturally according to the different kinds ofsemantic information represented by them.
Herewe will make some linguistic analysis of the twosemantic role groups.
Conversely to the process ofthe syntactic realization of semantic roles, we wantto find out what linguistic features make a con-stituent ARG0 instead of ARG1, or another con-stituent ARGM-TMP instead of ARGM-ADV, i.e.what features capture the most crucial informationof the two groups.As what we have assumed, the linguistic fea-tures which made a syntactic constituent labeled aseither one of the core arguments or one of the ad-juncts varies greatly.
Take the sentence in section 2as an example, even if the only information wehave about the phrase ????
(until now) is thatit is an adjunct of the verb, we can almost confirm,no matter where this node takes place in the pars-ing tree, this constituent will be labeled as ARGM-TMP.
?
(has) is also the same.
According to itsmeaning, the only category can be assigned to it isARGM-ADV.
But, things are quite different to thecore argument.
In the same sentence, ????
(the insurance company) is a good example.
If welimit our observation to the phrase itself, we canhardly assert that it is the ARG0 of the target verb.Only when we extend our observation to the syn-tactic structure level,  find out it is the subject ofthis sentence, and the voice of the sentence is ac-tive, the semantic type of????
(the insurancecompany) is finally confirmed.
If we have anothersentence in which ????
(the insurance com-pany) is not the subject, but rather the object, andthe target verb is ??
(set up), then it will proba-bly be labeled as ARG1.326Due to the analysis above, we can conclude thelinguistic discrepancy of the two semantic rolegroups as follows.
Core arguments and adjunctsshare different kinds of inner linguistic consistencyrespectively.
For the core arguments, the specifictype cannot be determined with the information ofthe arguments only.
At this level, the core argu-ments are dependent on other information exceptthe information about themselves.
For example, theinformation of syntactic structures is crucial to thedetermination of the types of core arguments, andtrivial differences of the syntactic structures willlead to the different output.
Because of this, we cansay that the core arguments are sensitive to thesyntactic structures.
Compared to the core argu-ments, adjuncts are the opposite.
They are rela-tively independent on other information, sincemost of the adjuncts can be easily classified justbased on the information about themselves2.
Andalthough the positions of the adjuncts in the syntac-tic structure can vary, the types of the adjuncts arefixed.
In this sense, the adjuncts are insensitive tothe syntactic structures.After we made the linguistic discrepancy of thetwo semantic role groups, we can make a bold as-sumption that the differences of the two groups canbe reflected in the capability of different kinds offeatures to capture the crucial information for thetwo groups.
For example, the ?voice?
featuresseems to be crucial to the core arguments but use-less to the adjuncts.
This assumption provided uswith the idea of a hierarchical feature selection sys-tem.In this system, we first classify the constituentsinto two classes: core arguments and adjuncts.
Andthen, the system classifies core arguments and ad-juncts separately.
For different subtasks we onlyselect the most useful features and discard the lesspertinent ones.
We hope to take utilization of themost crucial features to improve semantic roleclassification.3.2 System ArchitecturePrevious semantic role classifiers always did theclassification problem in one-step.
However, inthis paper, we did SRC in two steps.
The architec-tures of hierarchical semantic role classifiers can2 Extra features e.g.
predicate may be still useful because thatthe information, provided by the high-level description of self-descriptive features, e.g.
phrase type, are limited.be found in figure 2, which is similar with that inMoschitti et al (2005).Figure 2.
The architecture of our hierarchical SRCsystemAs what has been shown in figure 2, a semanticrole will first be determined whether it is a num-bered argument or an ARGM by a binary-categoryclassifier.
And, then if the semantic role is a num-bered argument, it will be determined by a 5-category classifier designed for ARGX, i.e.
thenumbered arguments.
If it is an ARGM, the func-tional tag will be assigned by a 17-category classi-fier built for ARGMs.
Accordingly, with this hier-archical architecture, the SRC problem is dividedinto 3 sub tasks, each of which has an independentclassifier.3.3 Integrating the Idea of Exploiting Argu-ment InterdependenceJiang et al (2005) has built a semantic role classi-fier exploiting the interdependence of semanticroles.
It has turned the single point classificationproblem into the sequence labeling problem withthe introduction of semantic context features.
Se-mantic context features indicates the features ex-tracted from the arguments around the current one.We can use window size to represent the scope ofthe context.
Window size [-m, n] means that, in thesequence that all the arguments has constructed,the features of previous m and following n argu-ments will be utilized for the classification of cur-rent semantic role.
There are two kinds of argu-ment sequences in Jiang et al (2005), and we onlytest the linear sequence.
Take the sentence in fig-ure 1 as an example.
The linear sequence of thearguments in this sentence is: ????
(until then),Input Semantic RolesA binary-category classifierA 5-categoryclassifier forARGXsA 17-categoryclassifier forARGMsOutput: Semantic Role tags327????
(the insurance company), ?
(has), ?????
(for the Sanxia Project), ????
(in-surance services).
For the argument?
(has), if thesemantic context window size is [-1,2], the seman-tic context features e.g.
headword, phrase type andetc.
of  ????
(the insurance company), ?????
(for the Sanxia Project) and ????
(insurance services) will be utilized to serve theclassification task of?
(has).While their paper has improved the SRC per-formance on English, it also has one potential dis-advantage, which is that they didn?t separate thecore arguments and ARGMs.
The influence andexplanations of this defect are presented in Section6.
But in our hierarchical system, this problem canbe solved.
Since in the first step, we have separatedthe numbered arguments and ARGMs.
We supposethat with the separation of the two semantic rolegroups, the system performance will be further im-proved.4 Feature Selection StrategyDue to what we have discussed in the section 3.1,we need to select different features for the threesub task of SRC.
In this paper, we did not make theselection manually; however, we make a simplegreedy strategy for feature selection to do it auto-matically.
Although the best solution may not befound, automatic selection of features can try farmore combinations of feature templates than man-ual selection.
Because of this, this strategy possiblycan produce a better local optional solution.First, we built a pool of feature templates whichhas proven to be useful on the SRC.
Most of thefeature templates are standard, so only the newones will be explained.
The candidate feature tem-plates include:Voice from Sun and Jurafsky (2004).Head word POS, Head Word of PrepositionalPhrases, Constituent tree distance, from Pradhanetc.
(2004).Position, subcat frame, phrase type, first word,last word, subcat frame+, predicate, path, headword and its POS, predicate + head word, predi-cate + phrase type, path to BA and BEI, verbclass 3 , verb class + head word, verb class +phrase type, from Xue (2008).3 It is a bit different from Xue (2008), since we didn?t use thesyntactic alternation information.predicate POS, first word +  last word, phrasetype of the sibling to the left, phrase type of thesibling to the right, verb + subcate frame+, verbPOS + subcat frame+, the amount of VPs in path,phrase type + phrase type of parent node, whichcan be easily understood by name.voice position, indicates whether the voicemarker (BA, BEI) is before or after the constituentin focus.subcat frame*, the rule that expands the parentnode of the constituent in focus.subcat frame@, the rule that expands the con-stituent in focus.layer of the constituent in focus, the number ofconstituents in the ascending part of the path sub-tracted by the number of those in the descendingpart of path, e.g.
if the path is PP-BNF?VP?VP?VV, the feature extracted by this template willbe -1.SemCat (semantic category) of predicate, Sem-Cat of first word, SemCat of head word, SemCat oflast word, SemCat of predicate + SemCat of  firstword, SemCat of predicate + SemCat of  last word,predicate + SemCat of head word, SemCat ofpredicate + head word.
The semantic categories ofverbs and other words are extracted from the Se-mantic Knowledge-base of Contemporary Chinese(Wang et al 2003).verb AllFrameSets, the combination of all theframesets of a predicate.verb class + verb AllFrameSets, verb AllFra-meSets + head word, verb AllFrameSets + phrasetype.There are more than 40 feature templates, and itis quite difficult to traverse all the possible combi-nations and get the best one.
So we use a greedyalgorithm to get an approximate optimal solution.The feature selection algorithm is as follows.Each time we choose one of the feature templatesand add it into the system.
The one, after which isadded, the performance is the highest, will be cho-sen. Then we continue to choose feature templatesuntil there are no one left.
In the end, there are aseries of feature sets, which recorded the processof feature selection.
Then we choose the feature setwhich can perform the best on development set.The code of feature selection algorithm is designedin Figure 3.3281. add all feature templates to set S ,the set ofselected feature templates C0 is null2.
for i = 0 to n-1, n is the number of elementsin S3.
Pi =04.
for each feature template ftj in set S5.
C?i  = Ci + ftj6.
train a model with features extractedby C?
i and test on development set7.
if the result P?
> Pi8.
Pi = P?
, k= j9.
end for10.
Ci+1  = Ci + ftk11.
S  = S ?
ftk12.
end for13.
the set Cm correspondent to Pm, which isthe highest, will be chosen.Figure 3. the greedy feature selection algorithmTo make a comparison, we also built a tradi-tional 1-step semantic role classifier based on thisfeature selection strategy.
We will take this classi-fier as the baseline system.5 Experiment Settings5.1 ClassifierIn our SRL system, we use a Maximum Entropytoolkit with tunable Gaussian Prior and L-BFGSparameter estimation, which is implemented byZhang Le.
This toolkit is available athttp://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html.
It can wellhandle the multi-category classification problemand it is quite efficient.5.2 DataWe use Chinese PropBank 1.0 (LDC number:LDC2005T23) in our experiments.
PropBank 1.0includes the annotations for files chtb_001.fid tochtb_931.fid, or the first 250K words of theChinese TreeBank 5.1.
For the experiments, thedata of PropBank is divided into three parts.
648files (from chtb_081 to chtb_899.fid) are used asthe training set.
The development set includes 40files, from chtb_041.fid to chtb_080.fid.
The testset includes 72 files, which are chtb_001 tochtb_041, and chtb_900 to chtb_931.
We use thesame data setting with Xue (2008), however a bitdifferent from Xue and Palmer (2005).6 Results and DiscussionThe results of the feature selection are presented intable1.
In this table, ?Baseline?
indicates the 1-steparchitecture, and ?Hierarchical?
indicates the ?hi-erarchical feature selection architecture?
imple-mented in this paper.
?X_M?, ?ARGX?
and?ARGM?
indicate the three sub-procedures of thehierarchical architecture, which are ?ARGX andARGM separation?, ?ARGX classification?,?ARGM classification?
respectively.
?Y?
in thetable indicates that the feature template has beenselected for the sub task.According to table 1, we can find some interest-ing facts, which in turn prove what we found aboutsemantic role groups in section 3.1.In table 1, feature templates related to the syn-tactic structure includes: voice-related group (voice,voice information, path to BA and BEI), frame-related group (verb class, verb class + head word,verb class + phrase type, all frames of verb, verbclass + all frames of verb), the layer of argument,position and 4 kinds of subcat frames.
As we as-sumed before, these features are crucial to corearguments but of little use to adjuncts.
The resultshave proven this assumption.
Of the entire 14 syn-tactic structure-related feature templates, 8 wereselected by the ARGX process but only 2 was se-lected by the ARGM process.
The two exceptionsshould be viewed as the result of random impact,which cannot be avoided in automatic feature se-lection.Compared with the different features selected bythese tasks, we can find other interesting results.Few of the features selected by the X_M processalso have related with the verb or the syntacticstructures, which is quite similar with the ARGMprocess.
This is probably because most of ARGMsare easy to be identified without syntactic structureinformation, which makes the opposite of ARGMs,i.e.
the ARGXs easy to be filtered.
Besides, thefeatures selected by the baseline system have muchin common with those selected by the ARGXprocess.
This can be explained by the fact that bothin the development and test set, the amount of corearguments outperforms that of adjuncts.
The pro-portions between core arguments and adjuncts are1.79:1 on the development set, and 1.63:1 on thetest set.
Because of the bias, the baseline systemwill tend to choose more syntactic structure-relatedfeatures to label core arguments precisely.329HierarchicalBaselineX_M ARGX ARGMFeature NameY  predicateY  Y  predicate POSY  Y first wordY first word + last wordY  Y  head wordY    head word POSY Y   phrase typeY  Y phrase type + phrase type of parent nodeY phrase type of the sibling to the leftY  Y  phrase type of the sibling to the rightY Y   positionY  voiceY    voice positionY  Y  path to BA and BEIY Y Y  verb classY verb class + head wordY Y   verb class + phrase typeY  Y  verb AllFrameSetsY  Y  verb class + verb AllFrameSetsY  subcat frameY   subcat frame*Y  subcate frame@Y subcat frame+Y  Y  layer of the constituent in focusY Y Y predicate + head wordY Y Y Y predicate + phrase typeY Y Y  SemCat of predicateY    SemCat of first wordY  Y  SemCat of last wordY SemCat of predicate + SemCat of last wordY  Y  SemCat of head wordTable 1.
Feature selection results for the baseline and the hierarchical systemBaseline HierarchicalDEV 95.15% 95.94%TEST 93.38% 94.31%Table 2.
Comparison of the performance between thebaseline and hierarchical systemWith this new architecture, we have achievedimprovement on the performance of the semanticrole classification, which can be found in table 2.Our classifier performs better both on the devel-opment and the test set.
The labeled precision onthe development set is from 95.15% to 95.94%,and the test set is from 93.38% to 94.31%, with anERR (error reduction rate) of 14.05%.
Both of theimprovements are statistically significant (?2 testwith p= 0.05).
The errors of SRC have three ori-gins, which are correspondent to the three subtasks of the hierarchical architecture.
Detailed in-formation of the comparison between the two sys-tems can be found in table 3, which can tell uswhere the improvements come from.Baseline HierarchicalARGX/ARGM errors 1.66% 1.75%inner ARGX errors 3.59% 2.75%inner ARGM errors 1.37% 1.19%TOTAL 6.62% 5.69%Table 3 Error rate analysis on the test set330In table 3, the percentages are calculated theway that the number of the errors was divided bythe number of the arguments in the test set.ARGX/ARGM errors represent the errors that thesemantic roles are classified into wrong group, e.g.ARGXs are labeled as ARGMs and vice versa.
Theinner errors represent the errors in a group, e.g.ARG0 are labeled as ARG1.
From this table, wecan find that ARGX is the most difficult task.
X-Mand ARGM are less challenging.
Besides the rela-tively little error reduction in the ARGM process,the greatest part of improvement comes from theprocess of the most difficult sub task: the ARGXsub task.
It is a bit surprising that the first step ofthe X_M in the hierarchical system process did notperform better than that in the baseline system.Baseline Hierarchical SumARG0 96.14% 96.58% 2046ARG1 92.75% 94.60% 2428ARG2 78.46% 78.85% 260ARG3 60.00% 76.00% 25ARG4 40.00% 100.00% 5ARGM-ADV 96.64% 96.85% 1490ARGM-ASP 100.00% 0.00% 1ARGM-BNF 91.30% 86.96% 23ARGM-CND 77.78% 77.78% 9ARGM-CRD N/A N/A 0ARGM-DGR N/A N/A 0ARGM-DIR 54.84% 58.06% 31ARGM-DIS 79.38% 79.38% 97ARGM-EXT 50.00% 25.00% 8ARGM-FRQ N/A N/A 0ARGM-LOC 90.91% 92.21% 308ARGM-MNR 89.92% 91.13% 248ARGM-PRD N/A N/A 0ARGM-PRP 97.83% 97.83% 46ARGM-TMP 95.41% 96.30% 675ARGM-TPC 33.33% 8.33% 12TBERR4 0.00% 0.00% 2Table 4 Detailed labeled precision on the test setTable 4 presented the labeled precision of eachtype of semantic role.
It demonstrates that withrespect to ARGMs and ARGXs, the hierarchicalsystem outperforms the baseline system.
Further-more, the improvement on ARGXs is greater than4 From the name, TBERR possibly indicates the labeled errorsin Chinese PropBank.
However, we did not find any explana-tions, so we just put it here and group it to ARGM.that of ARGMs.
All types of numbered argumentsget improvement in the hierarchical architecture,especially ARG1, ARG4 and ARG3.
Although theperformances of some types of the ARGMs de-creased, the performances of all types of theARGMs which occurs more than 100 times in-creased, including ADV (adverbials), LOC (loca-tives), MNR (manner markers) and TMP (temporalmarkers).After the hierarchical system was built, we triedto integrate the idea of exploiting argument inter-dependence into our system.
We extract the seman-tic context features in a linear order, with the win-dow size from [0,0] to [-3,3].
Larger window sizesare of little value since too few arguments havemore than 6 other arguments in context.
The re-sults are presented in table 5.Baseline HierarchicalBase 93.38% 94.31%+window selection 93.38% 94.68%Table 5 integrating window selection into our system?Base?
stands for the hierarchical system builtabove, without semantic context features.
?+window selection?
indicates the new systemwhich has utilized the idea of exploiting argumentinterdependence.
The best window sizes for thebaseline system, ARGX and ARGM processes inthe hierarchical system are [0,0], [-1,1], [0,0] re-spectively, which were determined by testing onthe development set.
We can find that only for theARGX process, the semantic context features areuseful.
For the baseline system and the ARGMprocess, exploiting argument interdependence doesnot help improve the performance.
This conclusionis different from Jiang et al (2004), but it can beexplained in the following way.In fact, the interdependence only exists amongcore arguments.
For ARGMs, it is a different thing.An ARGM cannot provide any information aboutthe type of the arguments close to it and the seman-tic context features does not help the classificationof ARGMs.
Also, take the sentence in section 2 asan example, the fact that ????
(until now) isARGM-TMP cannot raise the probability that????
(the insurance company) is ARG0 or ?
(has)is ARGM-ADV and vice versa.
However, if weknow that ????
(the insurance company) isARG0, at least the phrase ????
(insuranceservices) can never be ARG0.
The semantic con-text features extracted from or for ARGMs will do331harm to the improvement of the system, since theyare irrelative information.
Because of the same rea-son, the performance of base system also decreasedwhen semantic context features were extracted,since the core arguments and the ARGMs aremixed together in the baseline system.But for the ARGX sub task of our hierarchicalsystem, since we have separated the numbered ar-guments and ARGMs first, the influences ofARGMs can be eliminated.
This made the interde-pendence of core arguments can be directly ex-plored from the extraction of semantic context fea-tures.
So the ARGX sub task is improved.To prove that our method is effective, we alsomake a comparison between the performances ofour system and Xue and Palmer (2005), Xue(2008).
Xue (2008) is the best SRL system untilnow and it has the same data setting with ours.
Theresults are presented in Table 6.X & P (2005) Xue(2008) Ours93.9% 94.1% 94.68%Table 6.
Comparison with previous systemsWe have to point out that all the three systemsare based on Gold standard parsing.
From the table6, we can find that our system is better than both ofthe related systems.
Our system has outperformedXue (2008) with a relative error reduction rate of9.8%.7 Conclusions and Future WorkIn this paper, we have divided all the semanticroles into two groups according to their semanticrelations with the verb.
After the grouping of thesemantic roles was made, we designed a hierarchi-cal semantic role classifier.
To capture the accurateinformation of different semantic role groups, wedesigned a simple feature selection algorithm tocalibrate features for each sub task of SRC.
It wasvery encouraging that the hierarchical SRC systemoutperformed the strong baseline built with tradi-tional methods.
And the selected features could beexplained, which in turn proves that the linguisticdiscrepancy of semantic role groups not only existsbut also can be captured.
Then we integrated theidea of exploiting argument interdependence tofurther improve the performance of our system andexplained linguistically why the results of our sys-tem were different from the ones in previous re-search.Although we make discriminations of argumentsand adjuncts, the analysis is still coarse-grained.
Yiet al (2007) has made the first attempt working onthe single semantic role level to make further im-provement.
However, the impact of this idea islimited due to that the amount of the research tar-get, ARG2, is few in PropBank.
What if we couldextend the idea of hierarchical architecture to thesingle semantic role level?
Would that help theimprovement of SRC?AcknowledgementsThis work was supported by National Natural Sci-ence Foundation of China under Grant No.60303003 and National Social Science Foundationof China under Grant No.
06BYY048.We want to thank Nianwen Xue, for his gener-ous help at the beginning of this work.
And thanksto the anonymous reviewers, for their valuablecomments on this paper.ReferencesBaker, Collin F., Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In Proceed-ings of the 17th international conference on Compu-tational linguistics, Montreal, Canada.Boas, Hans C. 2002.
Bilingual FrameNet dictionariesfor machine translation.
In Proceedings of LREC2002, Las Palmas, Spain.Carreras, Xavier and Llu?s M?rquez.
2004.
Introductionto the conll-2004 shared task: Semantic role labeling.In Proceedings of the Eighth Conference on NaturalLanguage Learning, Boston, Massachusetts.Carreras, Xavier and Llu?s M?rquez.
2005.
Introductionto the conll-2005 shared task: Semantic role labeling.In Proceedings of the Nineth Conference on NaturalLanguage Learning, Ann Arbor, Michigan.M?rquez, Llu?s, Xavier Carreras, Kenneth C. Litkowski,Suzanne Stevenson.
2008.
Semantic Role Labeling:An Introduction to the Special Issue, Computationallinguistics.
34(2):146-159..Gildea, Daniel and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguistics,28(3): 245-288.Jiang, Zheng Ping, Jia Li, Hwee Tou Ng.
2005.
Seman-tic Argument Classification Exploiting Argument In-terdependence.
In 19th International Joint Confer-ence on Artificial Intelligence.
Edinburgh, Scotland.332Kingsbury, Paul and Martha Palmer.
2002.
From Tree-Bank to PropBank.
In Proceedings of the 3rd Interna-tional Conference on Language Resources andEvaluation, Las Palmas, Spain.Kipper, Karin, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.
InProceedings of the Seventeenth National Conferenceon Artificial Intelligence and Twelfth Conference onInnovative Applications of Artificial Intelligence,Austin, Texas, USA.Moschitti.
Alessandro.
2004.
A Study on ConvolutionKernels for Shallow Statistic Parsing.
In Proceedingsof the 42nd Meeting of the Association for Computa-tional Linguistics, Barcelona, Spain.Moschitti, Alessandro, Ana-Maria Giuglea, Bonaven-tura Coppola, and Roberto Basili.
2005.
Hierarchicalsemantic role labeling.
In Proceedings of the NinethConference on Natural Language Learning, Ann Ar-bor, Michigan.Narayanan, Srini and Sanda Harabagiu.
2004.
Questionanswering based on semantic structures.
In Proceed-ings of the 20th International Conference on Compu-tational Linguistics, Geneva, Switzerland.Pradhan, Sameer, Kadri Hacioglu, Valerie Kruglery,Wayne Ward, James H. Martin, Daniel Jurafskyz.2004.
Support vector learning for semantic argumentclassification.
Machine Learning Journal, 60(1-3):11-39.Sun, Honglin and Daniel Jurafsky.
2004.
Shallow Se-mantic Parsing of Chinese.
In Proceedings of theHuman Language Technology Conference of theNorth American Chapter of the Association for Com-putational Linguistics, Boston, Massachusetts.Surdeanu, Mihai, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argument struc-tures for information extraction.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics, Ann Arbor, Michigan.Wang, Hui, Weidong Zhan, Shiwen Yu.
2003.
TheSpecification of The Semantic Knowledge-base ofContemporary Chinese, In Journal of Chinese Lan-guage and Computing, 13(2):159-176.Xue, Nianwen and Martha Palmer.
2003.
Annotating thePropositions in the Penn Chinese Treebank.
In Pro-ceedings of the 2nd SIGHAN Workshop on ChineseLanguage Processing, Sapporo, Japan.Xue, Nianwen and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, Barcelona, Spain.Xue, Nianwen and Martha Palmer.
2005.
Automaticsemantic role labeling for Chinese verbs.
In 19th In-ternational Joint Conference on Artificial Intelligence.Edinburgh, Scotland.Xue, Nianwen, Fei Xia, Fu dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese TreeBank: PhraseStructure Annotation of a Large Corpus.
NaturalLanguage Engineering, 11(2):207?238.Xue, Nianwen.
2008.
Labeling Chinese predicates withsemantic roles.
Computational linguistics.
34(2):225-255.Yi, Szu-ting, Edward Loper, Martha Palmer.
2007.
CanSemantic Roles Generalize Across Genres?
In Pro-ceedings of Human Language Technologies  and TheConference of the North American Chapter of the As-sociation for Computational Linguistics, Rochester,NY, USA.Zhang, Min, Wanxiang Che, Ai Ti Aw, Chew Lim Tan,Guodong Zhou, Ting Liu, Sheng Li.
2007.
A Gram-mar-driven Convolution Tree Kernel for SemanticRole Classification, in Proceedings of the 45th An-nual Meeting of the Association of ComputationalLinguistics, Prague, Czech Republic.333
