Proceedings of the ACL-HLT 2011 Student Session, pages 105?110,Portland, OR, USA 19-24 June 2011. c?2011 Association for Computational LinguisticsExploiting Morphology in Turkish Named Entity Recognition SystemReyyan Yeniterzi ?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA, 15213, USAreyyan@cs.cmu.eduAbstractTurkish is an agglutinative language withcomplex morphological structures, thereforeusing only word forms is not enough for manycomputational tasks.
In this paper we an-alyze the effect of morphology in a NamedEntity Recognition system for Turkish.
Westart with the standard word-level representa-tion and incrementally explore the effect ofcapturing syntactic and contextual propertiesof tokens.
Furthermore, we also explore a newrepresentation in which roots and morphologi-cal features are represented as separate tokensinstead of representing only words as tokens.Using syntactic and contextual properties withthe new representation provide an 7.6% rela-tive improvement over the baseline.1 IntroductionOne of the main tasks of information extraction isthe Named Entity Recognition (NER) which aims tolocate and classify the named entities of an unstruc-tured text.
State-of-the-art NER systems have beenproduced for several languages, but despite all theserecent improvements, developing a NER system forTurkish is still a challenging task due to the structureof the language.Turkish is a morphologically complex languagewith very productive inflectional and derivationalprocesses.
Many local and non-local syntactic struc-tures are represented as morphemes which at the?The author is also affiliated with iLab and the Center for theFuture of Work of Heinz College, Carnegie Mellon Universityend produces Turkish words with complex morpho-logical structures.
For instance, the following En-glish phrase ?if we are going to be able to make[something] acquire flavor?
which contains the nec-essary function words to represent the meaning canbe translated into Turkish with only one token ?tat-land?rabileceksek?
which is produced from the root?tat?
(flavor) with additional morphemes +lan (ac-quire), +d?r (to make), +abil (to be able), +ecek (aregoing), +se (if) and +k (we).This productive nature of the Turkish results inproduction of thousands of words from a given root,which cause data sparseness problems in modeltraining.
In order to prevent this behavior in ourNER system, we propose several features whichcapture the meaning and syntactic properties of thetoken in addition to the contextual properties.
Wealso propose using a sequence of morphemes repre-sentation which uses roots and morphological fea-tures as tokens instead of words.The rest of this paper is organized as follows:Section 2 summarizes some previous related works,Section 3 describes our approach, Section 4 detailsthe data sets used in the paper, Section 5 reportsthe experiments and results and Section 6 concludeswith possible future work.2 Related WorkThe first paper (Cucerzan and Yarowski, 1999)on Turkish NER describes a language independentbootstrapping algorithm that learns from word inter-nal and contextual information of entities.
Turkishwas one of the five languages the authors experi-mented with.
In another work (Tur et al, 2003),105the authors followed a statistical approach (HMMs)for NER task together with some other InformationExtraction related tasks.
In order to deal with theagglutinative structure of the Turkish, the authorsworked with the root-morpheme level of the wordinstead of the surface form.
A recent work (Ku?cu?kand Yazici, 2009) presents the first rule-based NERsystem for Turkish.
The authors used several in-formation sources such as dictionaries, list of wellknown entities and context patterns.Our work is different from these previous worksin terms of the approach.
In this paper, we presentthe first CRF-based NER system for Turkish.
Fur-thermore, all these systems used word-level tok-enization but in this paper we present a new to-kenization method which represents each root andmorphological feature as separate tokens.3 ApproachIn this work, we used two tokenization methods.
Ini-tially we started with the sequence of words rep-resentation which will be referred as word-levelmodel.
We also introduced morpheme-level modelin which morphological features are represented asstates.
We used several features which were cre-ated from deep and shallow analysis of the words.During our experiments we used Conditional Ran-dom Fields (CRF) which provides advantages overHMMs and enables the use of any number of fea-tures.3.1 Word-Level ModelWord-level tokenization is very commonly used inNER systems.
In this model, each word is repre-sented with one state.
Since CRF can use any num-ber of features to infer the hidden state, we developseveral feature sets which allow us to represent moreabout the word.3.1.1 Lexical ModelIn this model, only the word tokens are used intheir surface form.
This model is effective for manylanguages which do not have complex morpholog-ical structures.
However for morphologically richlanguages, further analysis of words is required inorder to prevent data sparseness problems and pro-duce more accurate NER systems.3.1.2 Root FeatureAn analysis (Hakkani-Tu?r, 2000) on English andTurkish news articles with around 10 million wordsshowed that on the average 5 different Turkish wordforms are produced from the same root.
In order todecrease this high variation of words we use the rootforms of the words as an additional feature.3.1.3 Part-of-Speech and Proper-NounFeaturesNamed entities are mostly noun phrases, such asfirst name and last name or organization name andthe type of organization.
This property has beenused widely in NER systems as a hint to determinethe possible named entities.Part-of-Speech tags of the words depend highlyon the language and the available Part-of-Speechtagger.
Taggers may distinguish the proper nounswith or without their types.
We used a Turkish mor-phological analyzer (Of lazer, 1994) which analyzeswords into roots and morphological features.
An ex-ample to the output of the analyzer is given in Ta-ble 1.
The part-of-speech tag of each word is alsoreported by the tool 1.
We use these tags as addi-tional features and call them part-of-speech (POS)features.The morphological analyzer has a proper namedatabase, which is used to tag Turkish person, lo-cation and organization names as proper nouns.
Anexample name entity with this +Prop tag is givenin Table 1.
Although, the use of this tag is limitedto the given database and not all named entities aretagged with it, we use it as a feature to distinguishnamed entities.
This feature is referred as proper-noun (Prop) feature.3.1.4 Case FeatureAs the last feature, we use the orthographic caseinformation of the words.
The initial letter of mostnamed entities is in upper case, which makes casefeature a very common feature in NER tasks.
Wealso use this feature and mark each token as UC orLC depending on the initial letter of it.
We don?t do1The meanings of various Part-of-Speech tags are as fol-lows: +A3pl - 3rd person plural; +P3sg - 3rd person singularpossessive; +Gen - Genitive case; +Prop - Proper Noun; +A3sg- 3rd person singular; +Pnon - No possesive agreement; +Nom- Nominative case.106Table 1: Examples to the output of the Turkish morphological analyzerWORD + ROOT + POS + MORPHEMESbeyinlerinin (of their brains) + beyin + Noun + A3pl+P3sg+GenAmerika (America) + Amerika + Noun + Prop+A3sg+Pnon+Nomanything special for the first words in sentences.An example phase in word-level model is given inTable 2 2.
In the figure each row represents a state.The first column is the lexical form of the word andthe rest of the columns are the features and the tag isin the last column.3.2 Morpheme-Level ModelUsing Part-of-Speech tags as features introducessome syntactic properties of the word to the model,but still there is missing information of other mor-phological tags such as number/person agreements,possessive agreements or cases.
In order to see theeffect of these morphological tags in NER, we pro-pose a morpheme-level tokenization method whichrepresents a word in several states; one state for aroot and one state for each morphological feature.In a setting like this, the model has to be restrictedfrom assigning different labels to different parts ofthe word.
In order to do this, we use an additionalfeature called root-morph feature.
The root-morphis a feature which is assigned the value ?root?
forstates containing a root and the value ?morph?
forstates containing a morpheme.
Since there are noprefixes in Turkish, a model trained with this featurewill give zero probability (or close to zero probabil-ity if there is any smoothing) for assigning any B-*(Begin any NE) tag to a morph state.
Similarly, tran-sition from a state with B-* or I-* (Inside any NE)tag to a morph state with O (Other) tag will get zeroprobability from the model.In morpheme-level model, we use the followingfeatures:?
the actual root of the word for root and mor-phemes of the token?
the Part-of-speech tag of the word for the rootpart and the morphological tag for the mor-phemes2One can see that Ilias which is Person NE is not tagged asProp (Proper Noun) in the example, mainly because it is missingin the proper noun database of the morphological analyzer.?
the root-morph feature which assigns ?root?
tothe roots and ?morph?
to the morphemes?
the proper-noun feature?
the case featureAn example phrase in root-morpheme-basedchunking is given in Table 3.
In the figure each rowrepresents a state and each word is represented withseveral states.
The first row of each word containsthe root, POS tag and Root value for the root-morphfeature.
The rest of the rows of the same word con-tains the morphemes and Morph value for the root-morph feature.4 Data SetWe used training set of the newspaper articles dataset that has been used in (Tur et al, 2003).
Since wedo not have the test set they have used in their paper,we had to come up with our own test set.
We usedonly 90% of the train data for training and left theremaining for testing.Three types of named entities; person, organiza-tion and location, were tagged in this dataset.
If theword is not a proper name, then it is tagged withother.
The number of words and named entities foreach NE type from train and tests sets are given inTable 4.Table 4: The number of words and named entities in trainand test set#WORDS #PER.
#ORG.
#LOC.TRAIN 445,498 21,701 14,510 12,138TEST 47,344 2,400 1,595 1,4025 Experiments and ResultsBefore using our data in the experiments we appliedthe Turkish morphological analyzer tool (Of lazer,1994) and then used Morphological disambiguator(Sak et al, 2008) in order to choose the correct mor-phological analysis of the word depending on the107Table 2: An example phrase in word-level model with all featuresLEXICAL ROOT POS PROP CASE TAGAyval?k Ayval?k Noun Prop UC B-LOCATIONdog?umlu dog?um (birth) Noun NotProp LC Oyazar yazar (author) Noun NotProp LC OIlias ilias Noun NotProp UC B-PERSONTable 3: An example phrase in morpheme-level model with all featuresROOT POS ROOT-MORPH PROP CASE TAGAyval?k Noun Root Prop UC B-LOCATIONAyval?k Prop Morph Prop UC I-LOCATIONAyval?k A3sg Morph Prop UC I-LOCATIONAyval?k Pnon Morph Prop UC I-LOCATIONAyval?k Nom Morph Prop UC I-LOCATIONdog?um Noun Root NotProp LC Odog?um Adj Morph NotProp LC Odog?um With Morph NotProp LC Oyazar Noun Root NotProp LC Oyazar A3sg Morph NotProp LC Oyazar Pnon Morph NotProp LC Oyazar Nom Morph NotProp LC OIlias Noun Root NotProp UC B-PERSONIlias A3sg Morph NotProp UC I-PERSONIlias Pnon Morph NotProp UC I-PERSONIlias Nom Morph NotProp UC I-PERSONcontext.
In experiments, we used CRF++ 3, whichis an open source CRF sequence labeling toolkit andwe used the conlleval 4 evaluation script to reportF-measure, precision and recall values.5.1 Word-level ModelIn order to see the effects of the features individu-ally, we inserted them to the model one by one it-eratively and applied the model to the test set.
TheF-measures of these models are given in Table 5.
Wecan observe that each feature is improving the per-formance of the system.
Overall the F-measure wasincreased by 6 points when all the features are used.5.2 Morpheme-level ModelIn order to make a fair comparison between theword-level and morpheme-level models, we used allthe features in both models.
The results of theseexperiments are given in Table 6.
According tothe table, morpheme-level model achieved better re-sults than word-level model in person and location3CRF++: Yet Another CRF toolkit4www.cnts.ua.ac.be/conll2000/chunking/conlleval.txtentities.
Even though word-level model got betterF-Measure score in organization entity, morpheme-level is much better than word-level model in termsof recall.Using morpheme-level tokenization to introducemorphological information to the model did not hurtthe system, but it also did not produce a signifi-cant improvement.
There may be several reasons forthis.
One can be that morphological information isnot helpful in NER tasks.
Morphemes in Turkishwords are giving the necessary syntactic meaning tothe word which may not be useful in named entityfinding.
Another reason for not seeing a significantchange with morpheme usage can be our represen-tation.
Dividing the word into root and morphemesand using them as separate tokens may not be thebest way of using morphemes in the model.
Otherways of representing morphemes in the model mayproduce more effective results.As mentioned in Section 4, we do not have thesame test set that has been used in Tur et al (Turet al, 2003).
Even though it is impossible to make afair comparison between these two systems, it would108Table 5: F-measure Results of Word-level ModelPERSON ORGANIZATION LOCATION OVERALLLEXICAL MODEL (LM) 80.88 77.05 88.40 82.60LM + ROOT 83.32 80.00 90.30 84.96LM + ROOT + POS 84.91 81.63 90.18 85.98LM + ROOT + POS + PROP 86.82 82.66 90.52 87.18LM + ROOT + POS + PROP + CASE 88.58 84.71 91.47 88.71Table 6: Results of Morpheme-Level (Morp) and Word-Level Models (Word)PRECISION RECALL F-MEASUREMORP WORD MORP WORD MORP WORDPERSON 91.87% 91.41% 86.92% 85.92% 89.32 88.58ORGANIZATION 85.23% 91.00% 81.84% 79.23% 83.50 84.71LOCATION 94.15% 92.83% 90.23% 90.14% 92.15 91.47OVERALL 91.12% 91.81% 86.87% 85.81% 88.94 88.71Table 7: F-measure Comparison of two systemsOURS (TUR ET AL., 2003)BASELINE MODEL 82.60 86.01BEST MODEL 88.94 91.56IMPROVEMENT 7.6% 6.4%be good to note how these systems performed withrespect to their baselines which is lexical model inboth.
As it can be seen from Table 7, both modelsimproved upon their baselines significantly.6 Conclusion and Future WorkIn this paper, we explored the effects of using fea-tures like root, POS tag, proper noun and case to theperformance of NER task.
All these features seem toimprove the system significantly.
We also exploreda new way of including morphological informationof words to the system by using several tokens for aword.
This method produced compatible results tothe regular word-level tokenization but did not pro-duce a significant improvement.As future work we are going to explore other waysof representing morphemes in the model.
Here werepresented morphemes as separate states, but in-cluding them as features together with the root statemay produce better models.
Another approach wewill also focus is dividing words into characters andapplying character-level models (Klein et al, 2003).AcknowledgmentsThe author would like to thank William W. Cohen,Kemal Of lazer, Go?khan Tur and Behrang Mohit fortheir valuable feedback and helpful discussions.
Theauthor also thank Kemal Of lazer for providing thedata set and the morphological analyzer.
This publi-cation was made possible by the generous support ofthe iLab and the Center for the Future of Work.
Thestatements made herein are solely the responsibilityof the author.ReferencesSilviu Cucerzan and David Yarowski.
1999.
Languageindependent named entity recognition combining mor-phological and contextual evidence.
In Proceedings ofthe Joint SIGDAT Conference on EMNLP and VLC,pages 90?99.Dilek Z. Hakkani-Tu?r.
2000.
Statistical Language Mod-elling for Turkish.
Ph.D. thesis, Department of Com-puter Engineering, Bilkent University.Dan Klein, Joseph Smarr, Huy Nguyen, and Christo-pher D. Manning.
2003.
Named entity recognitionwith character-level models.
In Proceedings of theseventh conference on Natural language learning atHLT-NAACL 2003 - Volume 4, pages 180?183.Dilek Ku?cu?k and Adnan Yazici.
2009.
Named entityrecognition experiments on Turkish texts.
In Proceed-ings of the 8th International Conference on FlexibleQuery Answering Systems, FQAS ?09, pages 524?535,Berlin, Heidelberg.
Springer-Verlag.Kemal Of lazer.
1994.
Two-level description of Turk-109ish morphology.
Literary and Linguistic Computing,9(2):137?148.Has?im Sak, Tunga Gu?ngo?r, and Murat Sarac?lar.
2008.Turkish language resources: Morphological parser,morphological disambiguator and web corpus.
In Ad-vances in Natural Language Processing, volume 5221of Lecture Notes in Computer Science, pages 417?427.Go?khan Tur, Dilek Z. Hakkani-Tu?r, and Kemal Of lazer.2003.
A statistical information extraction system forTurkish.
In Natural Language Engineering, pages181?210.110
