Automatic Discovery of Term Similarities Using Pattern MiningGoran NENADI?, Irena SPASI?
and Sophia ANANIADOUComputer Science, University of SalfordSalford, M5 4WT, UK{G.Nenadic, I.Spasic, S.Ananiadou}@salford.ac.ukAbstractTerm recognition and clustering are key topics in automatic knowledge acquisition and text mining.
Inthis paper we present a novel approach to the automatic discovery of term similarities, which serves asa basis for both classification and clustering of domain-specific concepts represented by terms.
Themethod is based on automatic extraction of significant patterns in which terms tend to appear.
Theapproach is domain independent: it needs no manual description of domain-specific features and it isbased on knowledge-poor processing of specific term features.
However, automatically collectedpatterns are domain specific and identify significant contexts in which terms are used.
Beside featuresthat represent contextual patterns, we use lexical and functional similarities between terms to define acombined similarity measure.
The approach has been tested and evaluated in the domain of molecularbiology, and preliminary results are presented.IntroductionIn a knowledge intensive discipline such asmolecular biology, the vast and constantlyincreasing amount of information demandsinnovative techniques to gather and systematicallystructure knowledge, usually available only fromtext/document resources.
In order to discover newknowledge, one has to identify main concepts,which are linguistically represented by domainspecific terms (Maynard and Ananiadou (2000)).There is an increased amount of new terms thatrepresent newly created concepts.
Since existingterm dictionaries usually do not meet the needs ofspecialists, automatic term extraction tools areindispensable for efficient term discovery anddynamic update of term dictionaries.However, automatic term recognition (ATR) isnot the ultimate aim: terms recognised should berelated to existing knowledge and/or to each other.This entails the fact that terms should be classifiedor clustered so that semantically similar terms aregrouped together.
Classification and/or clusteringof terms are indispensable for improvinginformation extraction, knowledge acquisition, anddocument categorisation.
Classification can also beused for efficient term management and populatingand updating existing ontologies in a consistentmanner.
Both classification and clustering methodsare built on top of a specific similarity measure.The notion of term similarity has been defined andconsidered in different ways: terms can havefunctional and/or structural similarities, thoughthey can be correlated by different relationships(Grefenstette (1994), Maynard and Ananiadou(2000)).
In this paper we suggest a novel, domain-independent method for the automatic discovery ofterm similarities, which can serve as a basis forboth classification and clustering of terms.
Themethod is mainly based on the automatic discoveryof significant term features through pattern mining.Automatically collected patterns are domaindependent and they identify significant contexts inwhich terms tend to appear.
In addition, themeasure combines lexical and syntacticalsimilarities between terms.The paper is organised as follows.
In Section 1we overview term management approaches.Section 2 introduces the term similarity measureand Section 3 presents results and experiments.1   Terminology ManagementSince vast amount of knowledge still remainsunexplored, several systems have been proposed tohelp scientists to acquire relevant knowledge fromscientific literature.
For example, GENIES(Friedman et al (2001)) uses a semantic grammarand substantial syntactic knowledge in order toextract comprehensive information about signal-transduction pathways.
Some of the systems areterminology-based, since technical termssemantically characterise documents and thereforerepresent starting place for knowledge acquisitiontasks.
For example, Mima et al (2002) introduceTIMS, a terminology-based knowledge acquisitionsystem, which integrates automatic termrecognition, term variation management, context-based automatic term clustering, ontology-basedinference, and intelligent tag information retrieval.The system?s aim is to provide efficient access andintegration of heterogeneous biological textual dataand databases.There are numerous approaches to ATR.
Somemethods (Bourigault (1992), Ananiadou (1994))rely purely on linguistic information, namelymorpho-syntactic features of term candidates.Recently, hybrid approaches combining linguisticand statistical knowledge are becomingincreasingly used (Frantzi et al (2000), Nakagawaet al (1998)).There is a range of clustering and classificationapproaches that are based on statistical measures ofword co-occurrences (e.g.
Ushioda (1996)), orsyntactic information derived from corpora (e.g.Grefenstette  (1994)).
However, few of them dealwith term clustering: Maynard and Ananiadou(2000) present a method that uses manuallydefined semantic frames for specific classes,Hatzivassiloglou et al (2001) use machine learningtechniques to disambiguate names of proteins,genes and RNAs, while Friedman et al (2001)describe extraction of specific molecular pathwaysfrom journal articles.In our previous work, an integrated knowledgemining system in the domain of molecular biology,ATRACT, has been developed (Mima et al(2001)).
ATRACT (Automatic Term Recognitionand Clustering for Terms) is a part of the ongoingBioPath1 project, and its main aim is to facilitate anefficient expert-computer interaction during term-based knowledge acquisition.
Term management isbased on integration of automatic term recognitionand automatic term clustering (ATC).
ATR isbased on the C/NC-value method (Frantzi et al1 BioPath is a Eureka funded project, coordinated byLION BioScience (http://www.lionbioscience.com) andfunded by the German Ministry of Research.
(2000)), a hybrid approach combining linguisticknowledge (term formation patterns) and statisticalknowledge (term length, frequency of occurrence,etc).
The extension of the method handlesorthographic, morphological and syntactic termvariants and acronym recognition as an integralpart of the ATR process (Nenadi?
et al (2002a)),providing that all term occurrences of a term areconsidered.
The ATC method is based on theUshioda?s AMI (Average Mutual Information)hierarchical clustering method (Ushioda (1996)).Co-occurrence based term similarities are used asinput, and a dendrogram of terms is generated.22   Term Similarity MeasuresIn this section we introduce a novel hybrid methodto measure term similarity.
Our methodincorporates three types of similarity measures,namely contextual, lexical and syntacticalsimilarity.
We use a linear combination of the threesimilarities in order to estimate similarity betweenterms.
In the following subsections we describeeach of the three similarity measures.2.1   Contextual SimilarityDetermining the similarity of terms based on theircontexts is a standard approach based on thehypothesis that similar terms tend to appear insimilar contexts.
Contextual similarity, however,may be determined in a number of ways dependingon the way in which the context is defined.
Forexample, some approaches consider only termsthat appear in a close proximity to each other(Maynard and Ananiadou (2000)), while in otherapproaches, grammatical roles such as object orsubject are taken into account (Grefenstette(1994)).Our approach to contextual similarity is based onautomatic pattern mining.
The aim is toautomatically identify and learn the most importantcontext patterns in which terms appear.
Contextpattern (CP) is a generalised regular expressionthat corresponds to either left or right context of aterm.
3 The following example shows a sample leftcontext pattern of the term high affinity:2 For the evaluation of the ATR and ATC methodsincorporated in ATRACT, see Mima et al (2001).3 Left and right contexts are treated separately.V:bind TERM:rxr_heterodimers PREP:withLet us now describe the process of constructingCPs and determining their importance.
First, wecollect concordances for all automaticallyrecognised terms.
Context constituents, which weconsider important for discriminating terms (e.g.noun and verb phrases, prepositions, and termsthemselves) are identified by a tagger and byappropriate local grammars, which define syntacticphrases (e.g.
NPs, VPs).
The grammatical andlexical information attached to the contextconstituents is used to construct CPs.
In thesimplest case, contexts are mapped into thesyntactic categories of their constituents.
However,the lemmatised form for each of the syntacticcategories can be used as well.
For example, whenencountered in a context, the preposition with canbe either mapped to its POS tag, i.e.
PREP, orinstead, the lemma can be added, in which case wehave an instantiated chunk: PREP:with.
Further,some of the syntactic categories can be removedfrom the context patterns, as not all syntacticcategories are equally significant in providinguseful contextual information (Maynard andAnaniadou (2000)).
Such CPs will be regarded asnormalised CPs.
In our approach, one can definewhich categories to instantiate and which toremove.
In the examples provided later in thepaper (Section 3) we decided to remove thefollowing categories: adjectives (that are not partof a term), adverbs, determiners and so-calledlinking words (e.g.
however, moreover, etc.
).Also, we instantiated terms and either verbs orprepositions, as these categories are significant fordiscriminating terms.Once we have normalised CPs, we calculate thevalues of a measure called CP-value in order toestimate the importance of the CPs.
CP-value isdefined similarly to the C/NC-value for terms(Frantzi et al (2000)).
It assesses a CP (p)according to its total frequency (f(p)), its length(|p|, as the number of constituents) and thefrequency of its occurrence within other CPs (|Tp|,where Tp is a set of all CPs that contain p):The CPs whose CP-value is above a chosenthreshold are deemed important.
Note that thesepatterns are domain-specific and that they areautomatically extracted from a domain specificcorpus.
Tables 1 and 2 show samples of significantleft context patterns extracted from a MEDLINEcorpus (MEDLINE (2002)).CPs CP-valuePREP   NP 272.65PREP   NP   PREP 186.47.   .
.
.
.
.PREP  NP   V:stimulate 9.32V:indicate   NP 5.00PREP   NP   PREP   V:involve NP 4.64PREP   TERM:transcriptional_activity 4.47V:require   NP   PREP 4.38PREP TERM:nuclear_receptor PREP 4.00Table 1: Sample of left CPs(only terms and most frequent verbs are instantiated)CPs CP-valuePREP:of   NP 121.49V  NP 71.42PREP:of   NP   V 62.83NP   PREP:of   NP 59.72PREP:in   NP 59.55NP   PREP:of 43.37PREP:of   NP  V   NP 37.64PREP:of  TERM:transcriptional_activity 36.60Table 2: Sample of left CPs(only terms and prepositions are instantiated)At this point, each term is associated with a set ofthe most characteristic patterns in which it occurs.We treat CPs as term features, and we use a featurecontrast model (Santini and Jain (1999)) tocalculate similarity between terms as a function ofboth common and distinctive features.
Let us nowformally define the contextual similarity measure.Let C1 and C2 be two sets of CPs associated withterms t1 and t2 respectively.
Then, the contextualsimilarity (CS) between t1 and t2 corresponds to theratio between the number of common anddistinctive contexts:2.2   Lexical SimilarityWe also examine the lexical similarity betweenwords that constitute terms.
For example, if termsshare the same head, they are assumed to have the???=?
; otherwisenestedis not)(||1)(log);(log)(22TpbpbfTpfpppfppCP|\||\|||2||2),(2121212121 CCCCCCCCttCS++?
?=same concept as an (in)direct hypernym (e.g.progesterone receptor and oestrogenreceptor).
Further, if one of such terms hasadditional modifiers, this may indicate conceptspecialisation (e.g.
nuclear receptor andorphan nuclear receptor).
Bearing that inmind, we base the definition of lexical similarityon having a common head and/or modifier(s).Formally, if t1 and t2 are terms, H1 and H2 theirheads, and M1 and M2 the sets of the stems of theirmodifiers, then their lexical similarity (LS) iscalculated according to the following formula:where a and b are weights such that a > b, since wegive higher priority to shared heads over sharedmodifiers.Note that the lexical similarity between twodifferent terms can have a positive value only if atleast one of them is a multiword term.
Also, whencalculating lexical similarity between terms thatare represented by corresponding acronyms, weuse normalised expanded forms.
42.3   Syntactical SimilarityBy analysing the distribution of similar terms incorpora, we observed that some general (i.e.domain independent) lexico-syntactic patternsindicate functional similarity between terms.
Forinstance, the following example:... steroid receptors such asestrogen receptor, glucocorticoidreceptor,and progesterone receptor.suggests that all the terms involved are highlycorrelated, since they appear in an enumeration(represented by the such-as pattern) whichindicates their similarity (based on the is_arelationship).
Some of these patterns have beenpreviously used to discover hyponym relationsbetween words (Hearst (1992)).
We generalised4 For our approach to acronym acquisition and termnormalisation, see Nenadic et al (2002).the approach by taking into account patterns inwhich the terms are used concurrently within thesame context.
We hypothesise that the parallelusage of terms within the same context, as aspecific type of co-occurrence, shows theirfunctional similarity.
Namely, all the terms withina parallel structure have the same syntacticfunction within the sentence (e.g.
object or subject)and are used in combination with the same verb orpreposition.
This fact is used as an indicator oftheir semantic similarity.In our approach, several types of lexico-syntactical patterns are considered: enumerationexpressions, coordination, apposition, andanaphora.
However, currently we do notdiscriminate between different similarityrelationships among terms (which are representedby different patterns), but instead, we considerterms appearing in the same syntactical roles ashighly semantically correlated.A sample of enumeration patterns is shown inTable 3.
5 Manually defined patterns are applied assyntactic filters in order to retrieve sets of similarterms.
These patterns provide relatively good recalland precision.
We also used coordination patterns(Klavans et al (1997)) as another type of parallelsyntactic structure.
Two types of argumentcoordination and two types of head coordinationpatterns were considered (see Table 4).
However,not all the sequences that match the coordinationpatterns are coordinated structures (see Table 5).Therefore, these patterns provide relatively goodrecall, but not high precision if one wants toretrieve terms involved in such expression.6However, both term coordination and (nominal)conjunction of terms indicate their similarity.Based on co-occurrence of terms in these parallellexico-syntactical patterns, we define thesyntactical similarity (SS) measure for a pair ofterms as 1 if the two terms appear together in anyof the patterns, and 0 otherwise.5 Non-terminal syntactic categories are given in anglebrackets.
Non-terminal <&> denotes a conjunctive wordsequence, i.e.
the following regular expression: (aswell as)| (and[/or])|(or[/and]).
Specialcharacters (, ), [, ], |, and * have the usualinterpretation in regular expression notation.6 In the experiments that we have performed, theprecision of expanding terms from coordinatedstructures was 70%.
( +?+= ||1),( 21*21 HHabattLS)|\||\|||2||221212121* MMMMMMMMb++?
?+<TERM>([(](such as)|like|(e.g.
[,])) <TERM> (,<TERM>)* [[,] <&> <TERM>] [)]<TERM> (,<TERM>)* [,] <&> other <TERM><TERM> [,] (including|especially) <TERM> (,<TERM>)* [[,] <&> <TERM>]both <TERM> and <TERM>either <TERM> or <TERM>neither <TERM> nor <TERM>Table 3: Sample of enumeration lexico-syntactic patterns(<N>|<Adj>) (,(<N>|<Adj>))* [,] <&> (<N>|<Adj>) <TERM>(<N>|<Adj>)/(<N>|<Adj>) <TERM>(<N>|<Adj>) <TERM> (,<TERM>)* [,] <&> <TERM>(<N>|<Adj>) <TERM>/<TERM>Table 4: Sample of coordination patternshead coordination [adrenal [glands and gonads]]term conjunction [adrenal glands] and [gonads]Table 5: Ambiguities of coordinated structures2.4   Hybrid CLS SimilarityNone of the similarities introduced so far issufficient on its own to reliably estimate similaritybetween two arbitrary terms.
For example, if aterm appears infrequently or within very specificCPs, the number of its significant CPs willinfluence its contextual similarity to other terms.Further, there are concepts that have idiosyncraticnames (e.g.
a protein named Bride ofsevenless), which thus cannot be classifiedrelying exclusively on lexical similarity.
Ourexperiments also show that syntactical similarityprovides high precision, but low recall when usedon its own, as not all terms appear in a parallellexico-syntactical expression.Therefore, we introduce a hybrid term similaritymeasure, called the CLS similarity, as a linearcombination of the three similarity measures:CLS(t1, t2) = ?
CS(t1, t2) + ?
LS(t1, t2) + ?
SS(t1, t2)The choice of the weights ?, ?, and ?
in theprevious formula is not a trivial problem.
In ourpreliminary experiments (Section 3) we usedmanually chosen values.
However, the parametershave also been fine-tuned automatically bysupervised learning method based on a geneticalgorithm approach (Spasi?
et al (2002)).
Adomain specific ontology has been used to evaluatethe generated similarity measures and to set thedirection of their convergence.
The differencesbetween results based on the various parametersare presented in the following section.3   Results, Evaluation and DiscussionThe CLS measure was tested on a corpus of 2008abstracts retrieved from MEDLINE database(MEDLINE (2002)) with manually chosen values0.3, 0.3 and 0.4 for ?, ?, and ?
respectively.Random samples of results have been evaluated bya domain expert, and the combined measureproved to be a good indicator of semanticsimilarity.
Table 6 shows the similarity of termretinoic acid receptor to a number ofterms.
The examples point out the importance ofcombining different types of term similarities.
Forinstance, the low value of contextual similarity7 forretinoid X receptor is balanced out by theother two similarity values, thus correctlyindicating it as a term similar to term retinoicacid receptor.
Similarly, the high value of thecontextual similarity for signal transductionpathway is neutralised by the other two similarity7 The low value is caused by relatively low frequency ofthe term?s occurrences in the corpus.values, hence preventing it as being labelled assimilar to retinoic acid receptor.Term CS SS LS CLSnuclear receptor 0.58 1.00 0.50 0.72retinoid X receptor 0.32 1.00 0.33 0.60retinoic acid 0.31 0.00 1.00 0.39receptor complex 0.52 0.00 0.50 0.31progesteron receptor 0.35 0.00 0.50 0.25signal transductionpathway0.75 0.00 0.00 0.22Table 6: Similarity values between retinoicacid receptor and other termsThe combined measure also proved to beconsistent in the sense that similar terms share thesame "friends" (Maynard and Ananiadou (2000)).For example, the similarity values of two similarterms glucocorticoid receptor andestrogen receptor (the value of theirsimilarity is 0.68) with respect to other terms aremainly approximate (Table 7).Term glucocotricoidreceptorestrogenreceptorsteroid receptor 0.66 0.64progesterone receptor 0.55 0.59human estrogent0.28 0.37retinoid x receptor 0.27 0.36nuclear receptor 0.30 0.33receptor complex 0.31 0.33retinoic acid receptor 0.27 0.28retinoid nucleart0.26 0.26Table 7: Similarity values for glucocorticoidreceptor and estrogen receptorThe supervised learning of parameters resulted inthe values 0.13, 0.81 and 0.06 for ?, ?, and ?respectively (see Spasi?
et al (2002)).
Themeasure with these values showed a higher degreeof stability relative to the ontology-based similaritymeasure.
Note that the lexical similarity appears tobe the most important and the syntactical similarityto be insignificant.
The ontology used as a seed forlearning term similarities contained well-structured, standardised and preferred terms whichresulted in promoting the lexical similarity as themost significant.
On the other hand, the SSsimilarity is corpus-dependent: the size of thecorpus and the frequency with which theconcurrent lexico-syntactic patterns are realised init, affect the syntactical similarity.
In the trainingcorpus such patterns occurred infrequently relativeto the number of terms, which indicates that abigger corpus is needed in the training phase.
Inorder to increase the number of concurrentpatterns, we also aim at including additionalpatterns that describe appositions andimplementing procedures for resolution of co-referring terms.
We also plan to experiment withparametrising the values of syntactical similaritydepending on the number and type of patterns inwhich two terms appear simultaneously.The main purpose of discovering termsimilarities is to produce a similarity matrix toidentify term clusters.
In Nenadi?
et al (2002b) wepresent some preliminary results on term clusteringusing the CLS hybrid term similarity measure.
Twodifferent methods (namely the nearest neighbourand the Ward?s method) have been used, and bothachieved around 70% precision in clusteringsemantically similar terms.Conclusions and Further ResearchIn this paper we have presented a novel method forthe automatic discovery of term similarities.
Themethod is based on the combination of contextual,lexical and syntactical similarities between terms.Lexical similarity exposes the resemblancebetween the words that constitute terms, whilesyntactical similarity is based on mutual co-occurrence in parallel lexico-syntactic patterns.Contextual similarity is based on the automaticdiscovery of significant contexts throughcontextual pattern mining.
Although the approachis domain independent and knowledge-poor,automatically collected patterns are domainspecific and they identify significant contexts inwhich terms tend to appear.
However, in order tolearn domain-appropriate term similarityparameters, we need to customise the method byincorporating domain-specific knowledge.
Forexample, we have used an ontology to representsuch knowledge.The preliminary results in the domain ofmolecular biology have shown that the measureproves to be a good indicator of semantic similaritybetween terms.
Furthermore, the similaritymeasure is consistent at assigning weights: similarterms tend to share the same ?friends?, i.e.
there isa significant degree of overlapping between termsthat are similar.
These results are encouraging, asterms are grouped reliably according to theircontextual, syntactical and lexical similarities.Besides term clustering (presented in Nenadi?
etal.
(2002b)), the similarity measure can be used forseveral term-oriented knowledge managementtasks.
Our future work will focus on the termclassification and the consistent population andupdate of ontologies.
However, specific termrelationship identification that will direct placingterms in a hierarchy is needed.
Further, termsimilarities can be used for term sensedisambiguation as well, which is essential forresolving terminological confusion occurring inmany domains.AcknowledgementWe would like to thank Dr. Sylvie Albert and Dr.Dietrich Schuhmann from LION Bioscience for theevaluation of the results.ReferencesAnaniadou S. (1994): A Methodology for AutomaticTerm Recognition.
Proceedings of COLING-94,Kyoto, Japan.Bourigault D. (1992): Surface Grammatical Analysis forthe Extraction of Terminological Noun Phrases.Proceedings of 14th International Conference onComputational Linguistics, Nantes, France, pp.
977-981.Frantzi K.T., Ananiadou S. and Mima H. (2000):Automatic Recognition of Multi-Word Terms: the C-value/NC-value method.
International Journal onDigital Libraries, 3/2, pp.
115-130.Friedman C., Kra P., Yu H., Krauthammer M. andRzhetsky A.
(2001): GENIES: A Natural LanguageProcessing System for the Extraction of MolecularPathways from Journal Articles.
Bioinformatics, 17/1,pp.
S74-S82.Grefenstette G. (1994): Exploration in AutomaticThesaurus Discovery.
Kluwer Academic Publishers,Massachusetts, p. 302.Hatzivassiloglou V., Duboue P. and Rzetsky A.
(2001):Disambiguating Proteins, Genes, and RNA in Text: AMachine Learning Approach.
Bioinformatics, 17/1,pp.
S97-S106Hearst M.A.
(1992): Automatic acquisition of hyponymsfrom large text corpora.
Proceedings of the 14thInternational Conference on ComputationalLinguistics, Nantes, France.Klavans J. L., Tzoukermann E. and Jacquemin C.(1997): A Natural Language Approach to Multi-WordTerm Conflation.
Proceedings of Workshop DELOS,Zurich, pp.
33-40.Maynard D. and Ananiadou S. (2000): IdentifyingTerms by Their Family and Friends.
Proceedings ofCOLING 2000, Luxembourg, pp.530-536.MEDLINE (2002): National Library of Medicine.http://www.ncbi.nlm.nih.gov/PubMed/Mima H., Ananiadou S. and Nenadi?
G. (2001):ATRACT Workbench: An Automatic TermRecognition and Clustering of Terms.
Text, Speechand Dialogue - TSD 2001, LNAI 2166, Springer-Verlag, Berlin, pp.
126-133.Mima H., Ananiadou S., Nenadi?
G. and Tsujii J.
(2002): A Methodology for Terminology-basedKnowledge Acquisition and Integration.
Proceedingsof COLING 2002, TaiwanNakagawa H. and Mori, T. (2000): Nested Collocationand Compound Noun for Term Recognition.Proceedings of the First Workshop on ComputationalTerminology COMPUTERM 98, pp.
64-70.Nenadi?
G., Spasi?
I. and Ananiadou S. (2002a):Automatic Acronym Acquisition and Term VariationManagement within Domain-specific Texts.Proceedings of LREC 2002, Las Palmas, Spain, pp.2155-2162.Nenadi?
G., Spasi?
I. and Ananiadou S. (2002b): TermClustering using a Corpus-Based Similarity Measure.Text, Speech and Dialogue - TSD 2002, LNAI series,Springer-Verlag, BerlinSantini S. and Jain R. (1999): Similarity Measures.IEEE Transactions on Pattern Analysis and MachineIntelligence, 21/9, pp.
871-88Spasi?
I., Nenadi?
G. and Ananiadou S. (2002):Supervised Learning of Term Similarities.
IDEAL2002, LNAI series, Springer-Verlag, BerlinUshioda A.
(1996): Hierarchical Clustering of Words.Proceedings of COLING ?96, Copenhagen, pp.
1159-1162.
