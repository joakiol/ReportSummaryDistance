Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 120?127,Columbus, June 2008. c?2008 Association for Computational LinguisticsA Frame-Based Probabilistic Framework for Spoken Dialog Manage-ment Using Dialog ExamplesKyungduk Kim, Cheongjae Lee, Sangkeun Jung and Gary Geunbae LeeDepartment of Computer Science and EngineeringPohang University of Science & Technology (POSTECH)San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea{getta, lcj80, hugman, gblee}@postech.ac.krAbstractThis paper proposes a probabilistic frameworkfor spoken dialog management using dialogexamples.
To overcome the complexity prob-lems of the classic partially observable Mar-kov decision processes (POMDPs) baseddialog manager, we use a frame-based beliefstate representation that reduces the complexi-ty of belief update.
We also used dialog ex-amples to maintain a reasonable number ofsystem actions to reduce the complexity of theoptimizing policy.
We developed weather in-formation and car navigation dialog systemthat employed a frame-based probabilisticframework.
This framework enables people todevelop a spoken dialog system using a prob-abilistic approach without complexity prob-lem of POMDP.1 IntroductionA robust dialog manager is an essential part ofspoken dialog systems, because many such sys-tems have failed in practice due to errors in speechrecognition.
Speech recognition errors can bepropagated to spoken language understanding(SLU), so the speech input must be considered er-ror-prone from a standpoint of dialog management.Therefore robust dialog managers are necessary todevelop practical spoken dialog systems.One approach to dialog management uses thepartially observable Markov decision process(POMDP) as a statistical framework, because thisapproach can model the uncertainty inherent inhuman-machine dialog (Doshi and Roy, 2007).The dialog manager uses a probabilistic, ratherthan deterministic, approach to manage dialog.
Asmore information becomes available, the dialogmanager updates its belief states.
A POMDP-baseddialog manager can learn the optimized policy thatmaximizes expected rewards by reinforcementlearning.But applying classic POMDP to a practical di-alog system incurs a scalability problem.
The com-putational complexity of updating belief states andoptimizing the policy increases rapidly with thesize of the state space in a slot-filling dialog task.To solve this scalability problem, the method ofcompressing states or mapping the original statespace to summarized space can be used (Williamsand Young, 2006; Roy et al,2005), but these algo-rithms tend to approximate the state space exces-sively.
The complexity problem of POMDP comesfrom updating beliefs that are out of the user?s in-tention, and from calculating the reward of systemactions that do not satisfy user?s objective.In this paper, we propose a new probabilisticframework for spoken dialog management usingdialog examples.
We adopted a frame-based beliefstate representation to reduce the complexity ofbelief update.
Furthermore, we used an example-based approach to generate only a reasonablenumber of system action hypotheses in a newframework.
We developed a dialog system by us-ing our new framework in weather informationservice and car navigation service.1202 OverviewWe try to address two problems of applyingPOMDP to slot-filling dialog management.
1)Computational complexity of belief update: it isdifficult to maintain and update all belief states atevery turn of dialog since there are too many di-alog states in slot-filling dialog tasks.
2) Computa-tional complexity of policy optimizing: optimizingcomplexity depends on both the space size of di-alog states, and the number of available machineactions.
In slot-filling dialog tasks, a system actioncan have various slot values so that the systemneeds to choose an action among a large number ofaction hypotheses.In our new probabilistic framework (Figure 1),we try to solve these problems.
Our approach uses1) the frame-based belief state representation tosolve the computational complexity problem ofbelief update and 2) the dialog examples to gener-ate action hypotheses to solve the computationalcomplexity of policy optimizing by reducing thenumber of system action hypotheses.
First, the sys-tem groups belief states dynamically using frame-based belief state representation according to us-er?s utterance and its SLU result.
Then the systemuses an example-based approach to generate onlysystem action hypotheses that are suitable for cur-rent belief states.
If there are too many hypothesesfor calculating expected utility, the system prunesthem away until only a reasonable number of hy-potheses remains.
The following describes the de-tails of each system?s component and the dialogmanaging process.User?s UtteranceSLU ResultFrame-bas d BeliefSt te Re r sentationDialogExample DBCalculatingUtilitiesSystem actionUser?s Intention,Semantic Frame,Dialog HistoryPruningHypothesesLexico-semanticSimilarityGeneratingHypothesesFigure 1.
Overview of the system operation.
Bold ar-rows indicate the control flow.
Thin arrows indicate thedata flow.3 Frame-based Belief State RepresentationWe assumed that the machine?s internal represen-tation of the dialog state sm consists of three com-ponents: user?s goal su, user?s last action au anddialog history sd.
This section briefly describes thebasic introduction of POMDP framework and ex-plains each component of machine?s internal statein the standpoint of our frame-based probabilisticframework.3.1 POMDP for spoken dialog managementA POMDP is defined as a tuple that consists of sixsubstates: (S, A, P, R, ?, O) where S is a set ofstate, A is a set of action, P is a transition proba-bility P(s?|s,a), R is a reward function R(s,a,s?
), ?is a set of observation and O is an observationmodel P(o|s,a).
The current state is not determinis-tic in a POMDP framework while it is determinedas a specific state in a Markov decision process(MDP) framework.
In a POMDP, the probabilitydistribution over all states s?S, which is referredas a belief state b(s), is maintained instead of de-terministic state.
At each time instant t, the systemchooses an action a?A, and this causes the systemto move from current state s to next state s?
withthe transition probability P(s?
|s,a).
Then, the sys-tem is granted a reward R(s,a) while the systemreceives an observation o with probability ofP(o|s?,a).
The system computes the belief state inthe next time instance b?(s?)
as a following:?
?????
s sbassPasoPksb )(),|(),|()(where k is a normalizing factor.
This process isreferred as belief update.Optimizing a POMDP policy is a process offinding a mapping function from belief states toactions that maximizes the expected reward.
Thesystem should compute a value function over be-lief spaces to find optimized actions.
However,unlike as in a MDP, each value in a POMDP is afunction of an entire probability distribution andbelief spaces are very complex, so that a POMDPhas a scale problem of computing the exact valuefunction.A POMDP for spoken dialog system is wellformulated in (Williams and Young, 2007).
First, astate s can be factored to three substates: (su, au, sd)121where su is a user goal state, au is a user action, andsd is a dialog history.
A system action am and useraction au can be cast as action a and observation orespectively.
With some independence assumptionbetween variables, the belief update equation canbe rewritten as following:,),,(),,|(),|(),|()|~(),,()(??
????????????????????
?uu daduus smdudmuumuuuuduusasbasasPassPasaPaaPksasbbwhereua~?
is an automatic speech recognizer (ASR)and SLU recognition result of user action.
In ourframework, belief update is done based on this eq-uation.
But applying this directly to a spoken di-alog system can have a problem because theprobabilities used in the equation are hard to esti-mate from the corpus due to the data sparseness.Therefore, we adopted Young?s (2007) belief up-date formula that is simplified from the originalequation.3.2 User goal stateIn a slot-filling dialog system, the user?s goal canbe represented as a fully-filled frame in which allslots of the frame contain values specified by theuser?s intention.
Therefore, if a dialog system hasW slots and each slot can have a value among Vcandidates, then VW user goals can be representedas frames.
This means that the number of usergoals is related exponentially to the number ofslots.
This number of user goals is intractable inpractical dialog systems.Therefore, a method is needed to reduce the sizeof the state space rather than maintaining all beliefstates.
To do this, we developed a frame-based be-lief state representation in which the system dy-namically groups set of equivalent states to a high-level frame state.
Frame state, which is a similarconcept to the partition in the hidden informationstate (HIS) approach (Young et al 2007)represents the indistinguishable classes of user?sgoals.
The biggest difference between frame-basedrepresentation and partition-based representation isthat the former uses only user input to split theframe state, whereas the latter uses the user inputand external ontology rules such as a prior proba-bility for belief of split partition.
Therefore, theframe-based representation has relatively high do-main portability because it does not need that kindof external domain dependent information.In the frame-based belief state representation, apartially-filled frame state represents the currentuser?s goal state for which the unfilled slot can befilled in the future, while a fully-filled frame staterepresents  co plete user?s goal state.
Figure 2describes an example of the ubsumption relation-ship between partially filled frames and fully filledframes.Figure 2.
Subsumption relationship between partiallyfilled frame and fully filled frame.
The left frame is par-tially filled and three frames in the right side are fullyfilled.At the start of a dialog, all states belong to theroot frame state f0.
As the dialog progresses, thisroot frame state is split into smaller frame stateswhenever the value of a slot is filled by the user?sinput (Figure 3).
First, if the user?s input [A=a]fills the slot of the root frame state f0, then it splitsinto two frame states: f1, which includes all usergoal states with the slot A having ?a?
as a value;and {f0-f1}, which is the relative complement of f1.Next, if the user?s input [B=b] is entered to thesystem, each frame f1 and {f0-f1} is split into small-er frame states.
The system updates not all beliefstates but only the beliefs of the frame states, sothat the computational complexity remains rela-tively small.If each user?s goal has uniform distribution, thebelief of frame state b(f) can be calculated as fol-lows:# of user goals contained in frame ( ) # of all user goalsfb f ?This can be computed as follows:122t0t1t2...RootFrame Statef00( ) 1b f ?
{f0- f1}0 149({ })50b f f?
?f1(A = a)11( )b ff3(A = a)(B = b)3 21( )50b f ?{f1?
f3}(A = a)1 3 249({ })50b f f?
?f2(B = b)2 249( )50b f ?
{{f0- f1} - f2}20 1 2 249({{ } })50b f f f?
?
?A = aA != af1 { f0 - f1}f0A = aB = bA = aB != bA != aB = bA != aB != bf3{f1?
f3}f2{{f0- f1} - f2}User InputA = aUser InputB = bUser InputC = cFrame Splitting State SpaceFigure 3.
Splitting frame states and their beliefs with three user?s inputs.
f0, f1, f2, ?
denote frame states and b(f)means the belief of frame state f. A, B, C are the slot labels and a, b, c are the respective values of these slots.where Sfilled means the set of slots that are filled bythe user?s input in frame state f, and SnotFilled meansthe set of empty slots.
Vs denotes the set of availa-ble values for slot s, and Vs?
stands for the set ofvalues for slot s that were specified by the user inother frame states.3.3 User actionThe SLU result of current user's utterance is usedfor the user action.
The result frame of SLU con-sists of a speech act, a main goal, and severalnamed-entity component slots for each user's utter-ance.
The speech act stands for the surface-levelspeech act per single utterance and the main goalslot is assigned from one of the predefined classeswhich classify the main application actions in aspecific domain such as ?search the weather(SEARCH_WEATHER)?
or ?search the tempera-ture (SEARCH_TEMPERATURE)?
in the weatherinformation service domain.
The tasks for fillingthe named-entity component slots, such as, nameof the city, name of the state, are viewed as a se-quence labeling task.
The Figure 4 shows someexamples of predefined classes for SLU semanticframe in weather information service dialog systemOur SLU module was developed based on theconcept spotting approach, which aims to extractonly the essential information for predefined mean-ing representation slots, and was implemented byapplying a conditional random field model (Lee etal., 2007).Figure 4 Example predefined classes for semantic frameof SLU in weather information service dialog system.3.4 Dialog historySimilar to the traditional frame-based dialogmanagement approach, a frame can represent thehistory of the dialog.
The difference between thetraditional frame-based dialog manager and ourframework is that traditional frame-based dialog123manager maintains only one frame while ourframework can maintain multiple dialog hypothes-es.
Moreover, each hypothesis in our frameworkcan have a probability as in the belief state of theclassic POMDP.4 Example-based System Action Genera-tion4.1 Example-based system action hypothesisgenerationIt is impossible to consider all of the system ac-tions as hypotheses because the number of possibleactions is so large.
We used an example-based ap-proach to generate a reasonable number of systemaction hypotheses as hinted in (Lee et al, 2006).
Inthis approach, the system retrieves the best dialogexample from dialog example database (DEDB)which is semantically indexed from a dialog cor-pus.
To query a semantically close example for thecurrent situation, the system uses the user?s inten-tion (speech act and main goal), semantic frame(component slots) and discourse history as searchkey constraints (Lee et al, 2006).
These searchkeys can be collected with SLU output (e.g., userintention and semantic frame) and discourse histo-ry in a dialog manager.
Figure 5 describes an ex-ample of search key for DEDB on a weatherinformation service system.User?s utterance  What will the temperature be tomorrow?Weather_Type  Time_DateSearch keyconstraintsSpeech Act = wh_questionMain Goal = search_temperatureWEATHER_TYPE = 1 (filled)TIME_DATE = 1 (filled)LOC_CITY = 0 (unfilled)LOC_STATE = 0 (unfilled)Lexico-semanticInputWhat will the [WEATHER_TYPE] be[TIME_DATE]?Figure 5.
Example search key constraints for dialogexample database.For each frame state f1, ?, fn, the system gene-rates one or more system action hypotheses byquerying the DEDB respectively.
Queried actionsmay inconsistent with the current frame state be-cause the situation of indexed dialog examplesmay different from current dialog situation.
There-fore, the system maps the contents of dialog exam-ple to information of current frame state.
Slotvalues of frame state and information from contentdatabase (e.g., weather information database) areused for making the action consistent.
If the systemretrieves more than a threshold number of systemaction hypotheses using the search key constrains,then the system should prune away dialog exam-ples to maintain only a reasonable number of hypo-theses.
We used lexico-semantic similaritybetween the user utterance and the retrieved exam-ples to limit the number of hypotheses.
To measurethe lexico-semantic similarity, we first replace theslot values in the user utterance by its slot names togenerate lexico-semantic input, and calculate thenormalized edit distance between that input andretrieved examples (Figure 5).
In the normalizededit distance, we defined following cost functionC(i,j) to give a weight to the term which is re-placed by its slot name.1, 2,1, 2, 1, 2, _1, 2, 1, 2, _0  if( , ) 1  if  and ,1.5  if  and ,i ji j i j slot namei j i j slot namew wC i j w w w w Sw w w w S?
???
?
???
?
?
?where w1,i is ith word of user?s utterance, w2,j is jthword of dialog example?s utterance, and Sslot_name isthe set of slot names.
According to the lexico-semantic similarity, the system appends the top Nh-ranked hypotheses to the final action hypotheses(where Nh is the rank threshold).Many existing systems used heuristics or rule-based approaches to reduce the number of systemaction hypotheses (Young et al, 2007).
But thesemethods are not flexible enough to handle all di-alog flows because a system developer should de-sign new heuristics or rules whenever the systemneeds to support a new kind of dialog flow.
Theexample-based approach, on the contrary, can in-stantly refine the control of dialog flows by addingnew dialog examples.
This is a great advantagewhen a system developer wants to change or refinea dialog control flow.4.2 Calculating Expected UtilitiesWe adopted the principle of maximum expectedutility to determine the optimized system actionsamong the hypotheses (Paek and Horvitz, 2004).124* argmax ( | )argmax ( | ) ( , )argmax ( ) ( , )maa hha EU aP H h u a hb h u a h????
????
?where ?
denotes all information about the envi-ronment, u(a,h) means the utility of taking an ac-tion when the internal state of the machine is h,which consists of three substates, (f, au, sd) : f is aframe state, au is a user?s last action, and sd is adialog history.
The utility function u(a,h) can bespecific to each application.
We defined ahandcrafted utility function to calculate the ex-pected utility.5 ExperimentsWe performed two evaluations.
1) Real user evalu-ation: we measured the user satisfaction with vari-ous factors by human.
2) Simulated userevaluation: we implemented user simulator tomeasure the system performance with a largenumber of dialogs.
We built dialog corpora in twodomains: weather information service and car na-vigation.5.1 Real user evaluationWe built a dialog corpus in weather informationservice to measure the performance of the dialogsystem using our approach by real user evaluation.This corpus consists of 99 dialogs with 503 userutterances (turns).
User?s utterances were anno-tated with the semantic frame including speechacts, main goal and component slots for trainingthe SLU module and indexing the DEDB.To evaluate the preliminary performance, fourtest volunteers among computer science peopleevaluated our dialog system with five differentweather information-seeking tasks.
The volunteerstyped their utterances with a keyboard rather thanusing a real ASR because it is hard to control theWER.
We employed a simulated ASR error chan-nel by generating random errors to evaluate theperformance of dialog management under variouslevels of WER.
We will explain the details of ourASR channel simulator in Section 5.2.
The WER iscontrolled by this ASR channel simulator while thevolunteers were interacting with computer.
Tomeasure the user perception of task completionrate (TCR), the volunteers evaluated the system?sresponse in each dialog to measure the success turnrate (STR) and decided whether the entire dialogwas successful or not.
We evaluated the perfor-mance of our dialog system based on criteria out-lined in (Litman and Pan, 2004) by measuring usersatisfaction, which is defined with a linear combi-nation of three measures: TCR, Mean RecognitionAccuracy (MRA), and STR.User Satisfaction = ?TCR +?STR + ?MRAIn our evaluation, we set ?, ?
and ?
to 1/3, sothat the maximum value of the user satisfaction isone.Figure 6 Dialog system performance with various worderror rates in weather information seeking tasks.
Dottedline is TCR; dashed line is STR; solid line is user satis-faction.TCR, STR and user satisfaction decreased withWER.
User satisfaction has relatively high valuewhen the WER is smaller than 20% (Figure 6).
Ifthe WER is equal or over 20%, user satisfactionhas small value because the TCR decreases rapidlyin this range.Generally, TCR has a higher value than STR,because although a dialog turn may fail, users stillhave a chance to use other expressions which canbe well recognized by the system.
As a result ofthis, even when some dialog turns fail, the task canbe completed successfully.TCR decreases rapidly when WER ?20%.When WER is high, the probability of losing the125information in a user utterance is also large.
Espe-cially, if words contain important meaning, i.e.,values of component slots in SLU, it is difficult forthe system to generate a proper response.STR is 0.83 when WER is zero, i.e., although alluser inputs are correctly recognized, the systemsometimes didn?t generate proper outputs.
Thisfailure can be caused by SLU errors or malfunctionof the dialog manager.
SLU errors can be propa-gated to the dialog manager, and this leads the sys-tem to generate a wrong response because SLUresults are inputs of dialog manger.If the WER is 20%, user satisfaction is relativelysmall because TCR decreases rapidly in this range.This means that our approach is useful in a systemdevoted to providing weather information, and isrelatively robust to speech errors if the WER is lessthan 20%.5.2 Simulated user evaluationWe built another dialog corpus in car navigationservice to measure the performance of the dialogsystem by simulated user evaluation.
This corpusconsists of 123 dialogs with 510 user utterances(turns).
The SLU result frame of this corpus has 7types of speech acts, 8 types of main goals, and 5different component slots.The user simulator and ASR channel simulator hasbeen used for evaluating the proposed dialog man-agement framework.
The user simulator has twocomponents: an Intention Simulator and a SurfaceSimulator.
The Intention Simulator generates thenext user intention given current discourse context,and the Surface Simulator generates user sentenceto express the generated intention.ASR channel simulator simulates the speechrecognition errors including substitution, deletion,and insertions errors.
It uses the phoneme confu-sion matrix to estimate the probability distributionfor error simulation.
ASR channel simulator dis-torts the generated user utterance from Surface Si-mulator.
By simulating user intentions, surfaceform of user sentence and ASR channel, we cantest the robustness of the proposed dialog system inboth speech recognition and speech understandingerrors.We defined a final state of dialog to automati-cally measure TCR of a simulated dialog.
If a di-alog flow reaches the final state, the evaluatorregards that the dialog was successfully completed.TCRs and average dialog lengths were measuredunder various WER conditions that were generatedby ASR channel simulator.
Until the SLU result isan actual input of the dialog manager, we alsomeasured the SLU accuracy.
If a SLU result issame as a user?s intention of the Intention Simula-tor, then the evaluator considers that the result iscorrect.
Unlike in the real user evaluation, the di-alog system could be evaluated with relativelylarge amount of simulated dialogs in the simulateduser evaluation.
5000 simulated dialogs were gen-erated for each WER condition.Figure 7 TCR, SLU accuracy, and average dialog lengthof the dialog system under various WER conditions.We found that the SLU accuracy and TCR li-nearly decreased with the WER.
Similar in thehuman evaluation, TCR is about 0.9 when WER iszero, and it becomes below 0.7 when WER ishigher than 20%.
Average dialog length, on con-trary, increased with WER, and it has similar val-ues when WER is less than 10% although itincreased relatively rapidly when WER is higherthan 15%.6 ConclusionsThis paper proposed a new probabilistic method tomanage the human-machine dialog by using theframe-state belief state representation and the ex-ample-based system action hypothesis generation.The frame-based state representation reduces thecomputational complexity of belief update bygrouping the indistinguishable user goal states.And the system generates the system action hypo-126theses with the example-based approach in order torefine the dialog flows easily.
In addition, this ap-proach employed the POMDP formalism to main-tain belief distribution over dialog states so that thesystem can be robust to speech recognition errorsby considering the uncertainty of user?s input.A prototype system using our approach has beenimplemented and evaluated by real and simulateduser.
According to the preliminary evaluation, ourframework can be a useful approach to manage aspoken dialog system.We plan to progress the research on adopting aformalized online search to determine the optimalsystem action (Ross and Chaib-draa, 2007).
Withthe online searching, system doesn?t need to be-have the useless computation because this ap-proach searches only possible path.
We expect thatthis property of the online searching show the syn-ergetic effect on dialog management if it combineswith example-based approach.Similar to example-based approach, the case-based reasoning approach (Eliasson, 2006) can behelpful for our future research.
Some propertiessuch as using previous cases to process currentcase can be shared with our approach.
We thinkthat some other properties including the concept ofonline learning can be useful for making our ap-proach concreteAcknowledgmentsThis research was supported by the MKE (Min-istry of Knowledge Economy), Korea, under theITRC (Information Technology Research Center)support program supervised by the IITA (Institutefor Information Technology Advancement) (IITA-2008-C1090-0801-0045)ReferencesChangki Lee, Jihyun Eun, Minwoo Jeong, and GaryGeunbae Lee, Y. Hwang, M. Jang, ?A multi-strategicconcept-spotting approach for robust understandingof spoken Korean,?
ETRI Journal, vol.
29, No.2, pp.179-188, 2007.Cheongjae Lee, Sangkeun Jung, Jihyun Eun, MinwooJeong and Gary Geunbae Lee, ?A situation-based di-alogue management using dialogue examples,?
inProceedings of International conference on Acoustics,Speech, and Signal Processing, Toulouse, 2006.Diane J. Litman and Shimei Pan, ?Empirically evaluat-ing an adaptable spoken dialogue system,?
in Pro-ceedings of the 8th International Conference onSpoken Language Processing, pp.
2145-2148, 2004.Finale Doshi and Nicholas Roy, ?Efficient ModelLearning for Dialog Management,?
in Proceeding ofthe ACM/IEEE international conference on Human-robot interaction, Washington DC, 2007.Jason D. Williams and Steve Young, "Scaling POMDPsfor dialog management with composite summarypoint-based value iteration (CSPBVI)," in Proceed-ings of AAAI Workshop on Statistical and EmpiricalApproaches for Spoken Dialogue Systems, Boston,2006.Jason D. Williams and Steve Young, " Partially Observ-able Markov Decision Processes for Spoken DialogSystems."
Computer Speech and Language 21(2):231-422, 2007Karolina Eliasson, ?The Use of Case-Based Reasoningin a Human-Robot Dialog System?, Licentiate ofEngineering Thesis of Link?ping Institute of Tech-nology at Link?ping University, 2006Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun,?Finding approximate pomdp solutions through be-lief compression,?
Journal of Artificial IntelligenceResearch, vol.
23, pp.1?40, 2005.Spt?phane Ross, Brahim Chaib-draa, ?AEMS: An Any-time Online Search Algorithm for Approximate Poli-cy Refinement in Large POMDPs?, in Proceedingsof the 20th International Joint Conference on Artifi-cial Intelligence, 2007Steve Young, Jost Schatzmann, Karl Weilhammer andHui Ye, "The hidden information state approach todialog management," in Proceedings of InternationalConference on Acoustics, Speech, and SignalProcessing, Honolulu, 2007.Tim Paek and Eric Horvitz, ?Optimizing automated callrouting by integrating spoken dialog models withqueuing models,?
in Proceedings of HLT-NAACL, pp.41-48, Boston, 2004.127
