Towards Abstract Categorial GrammarsPhilippe de GrooteLORIA UMR no 7503 ?
INRIACampus Scientifique, B.P.
23954506 Vand?uvre le`s Nancy Cedex ?
Francedegroote@loria.frAbstractWe introduce a new categorial formal-ism based on intuitionistic linear logic.This formalism, which derives fromcurrent type-logical grammars, is ab-stract in the sense that both syntax andsemantics are handled by the same setof primitives.
As a consequence, theformalism is reversible and providesdifferent computational paradigms thatmay be freely composed together.1 IntroductionType-logical grammars offer a clear cut betweensyntax and semantics.
On the one hand, lexicalitems are assigned syntactic categories that com-bine via a categorial logic akin to the Lambek cal-culus (Lambek, 1958).
On the other hand, wehave so-called semantic recipes, which are ex-pressed as typed ?-terms.
The syntax-semanticsinterface takes advantage of the Curry-Howardcorrespondence, which allows semantic readingsto be extracted from categorial deductions (vanBenthem, 1986).
These readings rely upon ahomomorphism between the syntactic categoriesand the semantic types.The distinction between syntax and semanticsis of course relevant from a linguistic point ofview.
This does not mean, however, that it mustbe wired into the computational model.
On thecontrary, a computational model based on a smallset of primitives that combine via simple compo-sition rules will be more flexible in practice andeasier to implement.In the type-logical approach, the syntactic con-tents of a lexical entry is outlined by the followingpatern:<atom> : <syntactic category>On the other hand, the semantic contents obeysthe following scheme:<?-term> : <semantic type>This asymmetry may be broken by:1. allowing ?-terms on the syntactic side(atomic expressions being, after all, partic-ular cases of ?-terms),2. using the same type theory for expressingboth the syntactic categories and the seman-tic types.The first point is a powerfull generalization ofthe usual scheme.
It allows ?-terms to be usedat a syntactic level, which is an approach thathas been advocated by (Oehrle, 1994).
The sec-ond point may be satisfied by dropping the non-commutative (and non-associative) aspects of cat-egorial logics.
This implies that, contrarily tothe usual categorial approaches, word order con-straints cannot be expressed at the logical level.As we will see this apparent loss in expressivepower is compensated by the first point.2 Definition of a multiplicative kernelIn this section, we define an elementary gram-matical formalism based on the ideas presentedin the introduction.
This elementary formalism isfounded on the multiplicative fragment of linearlogic (Girard, 1987).
For this reason, we call ita multiplicative kernel.
Possible extensions basedon other fragments of linear logic are discussed inSection 5.2.1 Types, signature, and ?-termsWe first introduce the mathematical apparatus thatis needed in order to define our notion of an ab-stract categorial grammar.Let A be a set of atomic types.
The set T (A)of linear implicative types built upon A is induc-tively defined as follows:1. if a ?
A, then a ?
T (A);2. if ?, ?
?
T (A), then (???
?)
?
T (A).We now introduce the notion of a higher-orderlinear signature.
It consists of a triple ?
=?A,C, ?
?, where:1.
A is a finite set of atomic types;2.
C is a finite set of constants;3. ?
: C ?
T (A) is a function that assigns toeach constant in C a linear implicative typein T (A).Let X be a infinite countable set of ?-variables.The set ?(?)
of linear ?-terms built upon ahigher-order linear signature ?
= ?A,C, ??
is in-ductively defined as follows:1. if c ?
C, then c ?
?(?);2.
if x ?
X , then x ?
?(?);3.
if x ?
X , t ?
?(?
), and x occurs free in texactly once, then (?x.
t) ?
?(?);4.
if t, u ?
?(?
), and the sets of free variablesof t and u are disjoint, then (t u) ?
?(?).?(?)
is provided with the usual notion of cap-ture avoiding substitution, ?-conversion, and ?-reduction (Barendregt, 1984).Given a higher-order linear signature ?
=?A,C, ?
?, each linear ?-term in ?(?)
may be as-signed a linear implicative type in T (A).
Thistype assignment obeys an inference system whosejudgements are sequents of the following form:?
??
t : ?where:1. ?
is a finite set of ?-variable typing declara-tions of the form ?x : ??
(with x ?
X and?
?
T (A)), such that any ?-variable is de-clared at most once;2. t ?
?(?);3.
?
?
T (A).The axioms and inference rules are the following:??
c : ?
(c) (cons)x : ?
??
x : ?
(var)?, x : ?
??
t : ?
(abs)?
??
(?x.
t) : (???
?)?
??
t : (???
?)
?
??
u : ?
(app)?,?
??
(t u) : ?2.2 Vocabulary, lexicon, grammar, andlanguageWe now introduce the abstract notions of a vocab-ulary and a lexicon, on which the central notion ofan abstract categorial grammar is based.A vocabulary is simply defined to be a higher-order linear signature.Given two vocabularies ?1 = ?A1, C1, ?1?
and?2 = ?A2, C2, ?2?, a lexicon L from ?1 to ?2(in notation, L : ?1 ?
?2) is defined to be apair L = ?F,G?
such that:1.
F : A1 ?
T (A2) is a function that inter-prets the atomic types of ?1 as linear im-plicative types built upon A2;2.
G : C1 ?
?
(?2) is a function that interpretsthe constants of ?1 as linear ?-terms builtupon ?2;3. the interpretation functions are compatiblewith the typing relation, i.e., for any c ?
C1,the following typing judgement is derivable:?
?2 G(c) : F?
(?1(c)),where F?
is the unique homomorphic exten-sion of F .As stated in Clause 3 of the above defini-tion, there exists a unique type homomorphismF?
: T (A1) ?
T (A2) that extends F .
Simi-larly, there exists a unique ?-term homomorphismG?
: ?
(?1) ?
?
(?2) that extends G. In the se-quel, when ?L ?
will denote a lexicon, it will alsodenote the homorphisms F?
and G?
induced by thislexicon.
In any case, the intended meaning willbe clear from the context.Condition 3, in the above definition of a lexi-con, is necessary and sufficient to ensure that thehomomorphisms induced by a lexicon commutewith the typing relations.
In other terms, for anylexicon L : ?1 ?
?2 and any derivable judge-mentx0 : ?0, .
.
.
, xn : ?n ?
?1 t : ?the following judgementx0 : L (?0), .
.
.
, xn : L (?n) ?
?2 L (t) : L (?
)is derivable.
This property, which is reminis-cent of Montague?s homomorphism requirement(Montague, 1970b), may be seen as an abstractrealization of the compositionality principle.We are now in a position of giving the defini-tion of an abstract categorial grammar.An abstract categorial grammar (ACG) is aquadruple G = ?
?1,?2,L , s?
where:1.
?1 = ?A1, C1, ?1?
and ?2 = ?A2, C2, ?2?are two higher-order linear signatures; ?1is called the abstract vovabulary and ?2 iscalled the object vovabulary;2.
L : ?1 ?
?2 is a lexicon from the abstractvovabulary to the object vovabulary;3. s ?
T (A1) is a type of the abstract vocabu-lary; it is called the distinguished type of thegrammar.Any ACG generates two languages, an abstractlanguage and an object language.
The abstractlanguage generated by G (A(G )) is defined asfollows:A(G ) = {t ?
?
(?1) | ?
?1 t : s is derivable}In words, the abstract language generated by Gis the set of closed linear ?-terms, built upon theabstract vocabulary ?1, whose type is the distin-guished type s. On the other hand, the object lan-guage generated by G (O(G )) is defined to be theimage of the abstract language by the term homo-morphism induced by the lexicon L :O(G ) = {t ?
?
(?2) | ?u ?
A(G ).
t = L (u)}It may be useful of thinking of the abstract lan-guage as a set of abstract grammatical structures,and of the object language as the set of concreteforms generated from these abstract structures.Section 4 provides examples of ACGs that illus-trate this interpretation.2.3 ExampleIn order to exemplify the concepts introduced sofar, we demonstrate how to accomodate the PTQfragment of Montague (1973).
We concentrate onMontague?s famous sentence:John seeks a unicorn (1)For the purpose of the example, we make the twofollowing assumptions:1. the formalism provides an atomic type?string?
together with a binary associativeoperator ?+?
(that we write as an infix op-erator for the sake of readability);2. we have the usual logical connectives andquantifiers at our disposal.We will see in Section 4 and 5 that these two as-sumptions, in fact, are not needed.In order to handle the syntactic part of the ex-ample, we define an ACG (G12).
The first stepconsists in defining the two following vocabular-ies:?1 = ?
{n,np, s}, {J, Sre , Sdicto , A, U},{J 7?
np, Sre 7?
(np ??
(np ??
s)),Sdicto 7?
(np ??
(np ??
s)),A 7?
(n??
np), U 7?
n} ?
?2 = ?
{string}, {John, seeks,a,unicorn},{John 7?
string , seeks 7?
string ,a 7?
string ,unicorn 7?
string} ?Then, we define a lexicon L12 from the abstractvocabulary ?1 to the object vocabulary ?2:L12 = ?
{n 7?
string ,np 7?
string ,s 7?
string},{J 7?
John,Sre 7?
?x.
?y.
x+ seeks+ y,Sdicto 7?
?x.
?y.
x+ seeks+ y,A 7?
?x.a+ x,U 7?
unicorn} ?Finally we have G12 = ?
?1,?2,L12, s?.The semantic part of the example is handled byanother ACG (G13), which shares with G12 thesame abstract language.
The object language ofthis second ACG is defined as follows:?3 = ?
{e, t},{JOHN, TRY-TO, FIND, UNICORN},{JOHN 7?
e,TRY-TO 7?
(e??
((e??
t)??
t)),FIND 7?
(e??
(e??
t)),UNICORN 7?
(e??
t)} ?Then, a lexicon from ?1 to ?3 is defined:L13 = ?
{n 7?
(e??
t),np 7?
((e??
t)??
t),s 7?
t},{J 7?
?P.
P JOHN,Sre 7??P.
?Q.Q (?x.
P(?y.
TRY-TO y (?z.
FIND z x))),Sdicto 7??P.
?Q.P(?x.
TRY-TO x(?y.Q (?z.
FIND y z))),A 7?
?P.
?Q.
?x.
P x ?Qx,U 7?
?x.
UNICORN x} ?This allows the ACG G13 to be defined as?
?1,?3,L13, s?.The abstract language shared by G12 and G13contains the two following terms:Sre J (AU) (2) Sdicto J (AU) (3)The syntactic lexiconL12 applied to each of theseterms yields the same image.
It ?-reduces to thefollowing object term:John+ seeks+ a+ unicornOn the other hand, the semantic lexicon L13yields the de re reading when applied to (2):?x.
UNICORN x ?
TRY-TO JOHN (?z.
FIND z x)and it yields the de dicto reading when applied to(3):TRY-TO JOHN (?y.?x.
UNICORN x ?
FIND y x)Our handling of the two possible readingsof (1) differs from the type-logical account ofMorrill (1994) and Carpenter (1996).
The maindifference is that our abstract vocabulary con-tains two constants corresponding to seek.
Con-sequently, we have two distinct entries in the se-mantic lexicon, one for each possible reading.This is only a matter of choice.
We could haveadopt Morrill?s solution (which is closer to Mon-tague original analysis) by having only one ab-stract constant S together with the following typeassignment:S 7?
(np??
(((np??
s)??
s)??
s))Then the types of J and A, and the two lexiconsshould be changed accordingly.
The semantic lex-icon of this alternative solution would be simpler.The syntactic lexicon, however, would be moreinvolved, with entries such as:S 7?
?x.
?y.
x+ seeks+ y (?z.
z)A 7?
?x.
?y.
y (a+ x)3 Three computational paradigmsCompositional semantics associates meanings toutterances by assigning meanings to atomic items,and by giving rules that allows to compute themeaning of a compound unit from the meaningsof its parts.
In the type logical approach, follow-ing the Montagovian tradition, meanings are ex-pressed as typed ?-terms and combine via func-tional application.Dalrymple et al (1995) offer an alternative tothis applicative paradigm.
They present a deduc-tive approach in which linear logic is used as aglue language for assembling meanings.
Theirapproach is more in the tradition of logic pro-gramming.The grammatical framework introduced in theprevious section realizes the compositionalityprinciple in a abstract way.
Indeed, it providescompositional means to associate the terms ofa given language to the terms of some otherlanguage.
Both the applicative and deductiveparadigms are available.3.1 Applicative paradigmIn our framework, the applicative paradigm con-sists simply in computing, according to the lex-icon of a given grammar, the object image ofan abstract term.
From a computational point ofview it amounts to performing substitution and ?-reduction.3.2 Deductive paradigmThe deductive paradigm, in our setting, answersthe following problem: does a given term, builtupon the object vocabulary of an ACG, belongto the object language of this ACG.
It amountsto a kind of proof-search that has been de-scribed by Merenciano and Morrill (1997) and byPogodalla (2000).
This proof-search relies on lin-ear higher-order matching, which is a decidableproblem (de Groote, 2000).3.3 Transductive paradigmThe example developped in Section 2.3 suggestsa third paradigm, which is obtained as the com-position of the applicative paradigm with the de-ductive paradigm.
We call it the transductiveparadigm because it is reminiscent of the math-ematical notion of transduction (see Section 4.2).This paradigm amounts to the transfer from oneobject language to another object language, usinga common abstract language as a pivot.4 Relating ACGs to other grammaticalformalismsIn this section, we illustrate the expressive powerof ACGs by showing how some other families offormal grammars may be subsumed.
It must bestressed that we are not only interested in a weakform of correspondence, where only the gener-ated languages are equivalent, but in a strong formof correspondence, where the grammatical struc-tures are preserved.First of all, we must explain how ACGs maymanipulate strings of symbols.
In other words,we must show how to encode strings as linear ?-terms.
The solution is well known: it sufficesto represent strings of symbols as compositionsof functions.
Consider an arbitrary atomic type?, and define the type ?string?
to be (?
??
?
).Then, a string such as ?abbac?
may be repre-sented by the linear ?-term ?x.
a (b (b (a (c x)))),where the atomic strings ?a?, ?b?, and ?c?
aredeclared to be constants of type (?
??
?).
Inthis setting, the empty word () is representedby the identity function (?x.
x) and concatena-tion (+) is defined to be functional composition(?f.
?g.
?x.
f (g x)), which is indeed an associa-tive operator that admits the identity function as aunit.4.1 Context-free grammarsLet G = ?T,N, P, S?
be a context-free grammar,where T is the set of terminal symbols, N is theset of non-terminal symbol, P is the set of rules,and S is the start symbol.
We write L(G) for thelanguage generated by G. We show how to con-struct an ACG GG = ?
?1,?2,L , S?
correspond-ing to G.The abstract vocabulary ?1 = ?A1, C1, ?1?
isdefined as follows:1.
The set of atomic types A1 is defined to bethe set of non-terminal symbols N .2.
The set of constants C1 is a set of symbols in1-1-correspondence with the set of rules P .3.
Let c ?
C1 and let ?X ?
??
be the rule cor-responding to c. ?1 is defined to be the func-tion that assigns the type [[?
]]X to c, where[[?
]]X obeys the following inductive defini-tion:(a) [[]]X = X;(b) [[Y ?
]]X = (Y ??
[[?
]]X), for Y ?
N ;(c) [[a?
]]X = [[?
]]X , for a ?
T .The definition of the object vocabulary ?2 =?A2, C2, ?2?
is as follows:1.
A2 is defined to be {?}.2.
The set of constants C2 is defined to be theset of terminal symbols T .3.
?2 is defined to be the function that assignsthe type ?string?
to each c ?
C2.It remains to define the lexicon L = ?F,G?:1.
F is defined to be the function that interpretseach atomic type a ?
A1 as the type ?string?.2.
Let c ?
C1 and let ?X ?
??
bethe rule corresponding to c. G is de-fined to be the function that interprets c as?x1 .
.
.
.
?xn.
|?|, where x1 .
.
.
xn is the se-quence of ?-variables occurring in |?|, and| ?
| is inductively defined as follows:(a) || = ?x.
x;(b) |Y ?| = y + |?|, for Y ?
N , and wherey is a fresh ?-variable;(c) |a?| = a+ |?|, for a ?
T .It is then easy to prove that GG is such that:1. the abstract language A(GG) is isomorphicto the set of parse-trees of G.2.
the language generated by G coincides withthe object language of GG, i.e., O(GG) =L(G).For instance consider the CFG whose produc-tion rules are the following:S ?
,S ?
aSb,which generates the language anbn.
The cor-responding ACG has the following abstract lan-guage, object language, and lexicon:?1 = ?
{S}, {A,B},{A 7?
S,B 7?
((S ??
S)} ?
?2 = ?
{?
}, {a, b},{a 7?
string , b 7?
string} ?L = ?
{S 7?
string},{A 7?
?x.
x,B 7?
?x.
a+ x+ b} ?4.2 Regular grammars and rationaltransducersRegular grammars being particular cases ofcontext-free grammars, they may be handled bythe same construction.
The resulting ACGs(which we will call ?regular ACGs?
for the pur-pose of the discussion) may be seen as finite stateautomata.
The abstract language of a regularACG correspond then to the set of accepting se-quences of transitions of the corresponding au-tomaton, and its object language to the acceptedlanguage.More interestingly, rational transducers mayalso be accomodated.
Indeed, two regular ACGsthat shares the same abstract language correspondto a regular language homomorphism composedwith a regular language inverse homomorphism.Now, after Nivat?s theorem (Nivat, 1968), any ra-tional transducer may be represented as such a bi-morphism.4.3 Tree adjoining grammarsThe construction that allows to handle the treeadjoining grammars of Joshi (Joshi and Schabes,1997) may be seen as a generalization of the con-struction that we have described for the context-free grammars.
Nevertheless, it is a little bit moreinvolved.
For instance, it is necessary to triplicatethe non-terminal symbols in order to distinguishthe initial trees from the auxiliary trees.We do not have enough room in this paper forgiving the details of the construction.
We willrather give an example.
Consider the TAG withthe following initial tree and auxiliary tree:SSNA{{{{{{CCCCCCa S|||||||BBBBBBBdb S?NA cIt generates the non context-free languageanbncndn.
This TAG may be represented by theACG, G = ?
?1,?2,L , S?, where:?1 = ?
{S, S?, S??
}, {A,B,C},{A 7?
((S??
??
S?)??
S),B 7?
(S??
??
((S??
??
S?)??
S?
)),C 7?
(S??
??
S?)}
?
?2 = ?
{?
}, {a, b, c, d},{a 7?
string , b 7?
string ,c 7?
string , d 7?
string} ?L = ?
{S 7?
string , S?
7?
string ,S??
7?
string},{A 7?
?f.
f (?x.
x),B 7?
?x.
?g.
a+ g (b+ x+ c) + d,C 7?
?x.
x} ?One of the keystones in the above translation isto represent an adjunction node A as a functionalparameter of type A??
??A?.
Abrusci et al (1999)use a similar idea in their translation of the TAGsinto non-commutative linear logic.5 Beyond the multiplicative fragmentThe linear ?-calculus on which we have basedour definition of an ACG may be seen as a rudi-mentary functional programming language.
Theresults in Section 4 indicate that, in theory, thisrudimentary language is powerful enough.
Never-theless, in practice, it would be useful to increasethe expressive power of the multiplicative kerneldefined in Section 2 by providing features suchas records, enumerated types, conditional expres-sions, etc.From a methodological point of view, there isa systematic way of considering such extensions.It consists of enriching the type system of theformalism with new logical connectives.
Indeed,each new logical connective may be interpreted,through the Curry-Howard isomorphism, as a newtype constructor.
Nonetheless, the possible addi-tional connectives must satisfy the following re-quirements:1. they must be provided with introduction andelimination rules that satisfy Prawitz?s inver-sion principle (Prawitz, 1965) and the result-ing system must be strongly normalizable;2. the resulting term language (or at least an in-teresting fragment of it) must have a decid-able matching problem.The first requirement ensures that the new typescome with appropriate data constructors and dis-criminators, and that the associated evaluationrule terminates.
This is mandatory for the applica-tive paradigm of Section 3.
The second require-ment ensures that the deductive paradigm (andconsequently the transductive paradigm) may befully automated.The other connectives of linear logic are naturalcandidates for extending the formalism.
In partic-ular, they all satisfy the first requirement.
On theother hand, the satisfaction of the second require-ment is, in most of the cases, an open problem.5.1 AdditivesThe additive connectives of linear logic ?&?
and???
corresponds respectively to the cartesianproduct and the disjoint union.
The cartesianproduct allows records to be defined.
The dis-joint union, together with the unit type ?1?, al-lows enumerated types and case analysis to bedefined.
Consequently, the additive connectivesoffer a good theoretical ground to provide ACGwith feature structures.5.2 ExponentialsThe exponentials of linear logic are modal oper-ators that may be used to go beyond linearity.
Inparticular, the exponential ?!?
allows the intuition-istic implication ???
to be defined, which cor-responds to the possibility of dealing with non-linear ?-terms.
A need for such non-linear ?-terms is already present in the example of Sec-tion 2.3.
Indeed, the way of getting rid of thesecond assumption we made at the beginning ofsection 2.3 is to declare the logical symbols (i.e.,the existential quantifier and the conjunction thatoccurs in the interpretation of A in Lexicon L13)as constants of the object vocabulary ?3.
Then,the interpretation of A would be something like:?P.
?Q.
EXISTS (?x.
AND (P x) (Qx)).Now, this expression must be typable, which isnot possible in a purely linear framework.
Indeed,the ?-term to which EXISTS is applied is not linear(there are two occurrences of the bound variablex).
Consequently, EXISTS must be given ((e ?t)??
t) as a type.5.3 QuantifiersQuantifiers may also play a part.
Uses of first-order quantification, in a type logical setting, areexemplified by Morrill (1994), Moortgat (1997),and Ranta (1994).
As for second-order quantifi-cation, it allows for polymorphism.6 Grammars as first-class citizenThe difference we make between an abstract vo-cabulary and an object vocabulary is purely con-ceptual.
In fact, it only makes sense relatively toa given lexicon.
Indeed, from a technical pointof view, any vocabulary is simply a higher-orderlinear signature.
Consequently, one may think ofa lexicon L12 : ?1 ?
?2 whose object lan-guage serves as abstract language of another lex-icon L23 : ?2 ?
?3.
This allows lexicons to besequentially composed.
Moreover, one may eas-ily construct a third lexicon L13 : ?1 ?
?3 thatcorresponds to the sequential composition of L23with L12.
From a practical point of view, thismeans that the sequential composition of two lex-icons may be compiled.
From a theoretical pointof view, it means that the ACGs form a categorywhose objects are vocabularies and whose arrowsare lexicons.
This opens the door to a theorywhere operations for constructing new grammarsfrom other grammars could be defined.7 ConclusionThis paper presents the first steps towards the de-sign of a powerful grammatical framework basedon a small set of computational primitives.
Thefact that these primitives are well known fromprogramming theory renders the framework suit-able for an implementation.
A first prototype iscurrently under development.ReferencesM.
Abrusci, C.
Fouquere?, and J. Vauzeilles.
1999.Tree-adjoining grammars in a fragment of theLambek calculus.
Computational Linguistics,25(2):209?236.H.P.
Barendregt.
1984.
The lambda calculus, its syn-tax and semantics.
North-Holland, revised edition.J.
van Benthem.
1986.
Essays in Logical Semantics.Reidel, Dordrecht.B.
Carpenter.
1996.
Type-Logical Semantics.
MITPress, Cambridge, Massachussetts and LondonEngland.M.
Dalrymple, M. Lamping, F. Pereira, andV.
Saraswat.
1995.
Linear logic for meaning as-sembly.
In G. Morrill and D. Oehrle, editors, For-mal Grammar, pages 75?93.
FoLLI.J.-Y.
Girard.
1987.
Linear logic.
Theoretical Com-puter Science, 50:1?102.Ph.
de Groote.
2000.
Linear higher-order matchingis NP-complete.
In L. Bachmair, editor, RewritingTechniques and Applications, RTA?00, volume 1833of Lecture Notes in Computer Science, pages 127?140.
Springer.A.
K. Joshi and Y. Schabes.
1997.
Tree-adjoininggrammars.
In G. Rozenberg an A. Salomaa, editor,Handbook of formal languages, volume 3, chap-ter 2.
Springer.J.
Lambek.
1958.
The mathematics of sentence struc-ture.
Amer.
Math.
Monthly, 65:154?170.J.
M. Merenciano and G. Morrill.
1997.
Generation asdeduction on labelled proof nets.
In C.
Retore?, ed-itor, Logical Aspects of Computational Linguistics,LACL?96, volume 1328 of Lecture Notes in Artifi-cial Intelligence, pages 310?328.
Springer Verlag.R.
Montague.
1970a.
English as a formal language.In B. Visentini et al, editor, Linguaggi nella So-cieta` e nella Tecnica, Milan.
Edizioni di Commu-nita`.
Reprinted: (Montague, 1974, pages 188?221).R.
Montague.
1970b.
Universal grammar.
Theoria,36:373?398.
Reprinted: (Montague, 1974, pages222?246).R.
Montague.
1973.
The proper treatment of quan-tification in ordinary english.
In J. Hintikka,J.
Moravcsik, and P. Suppes, editors, Approaches tonatural language: proceedings of the 1970 Stanfordworkshop on Grammar and Semantics, Dordrecht.Reidel.
Reprinted: (Montague, 1974, pages 247?270).R.
Montague.
1974.
Formal Philosophy: selected pa-pers of Richard Montague, edited and with an intro-duction by Richmond Thomason.
Yale UniversityPress.M.
Moortgat.
1997.
Categorial type logic.
In J. vanBenthem and A. ter Meulen, editors, Handbook ofLogic and Language, chapter 2.
Elsevier.G.
Morrill.
1994.
Type Logical Grammar: Catego-rial Logic of Signs.
Kluwer Academic Publishers,Dordrecht.M.
Nivat.
1968.
Transduction des langages de Chom-sky.
Annales de l?Institut Fourier, 18:339?455.R.
T. Oehrle.
1994.
Term-labeled categorial type sys-tems.
Linguistic & Philosophy, 17:633?678.S.
Pogodalla.
2000.
Generation, Lambek Calculus,Montague?s Semantics and Semantic Proof Nets.
InProceedings of the 18th International Conferenceon Computational Linguistics, volume 2, pages628?634.D.
Prawitz.
1965.
Natural Deduction, A Proof-Theoretical Study.
Almqvist & Wiksell, Stock-holm.A.
Ranta.
1994.
Type theoretical grammar.
OxfordUniversity Press.
