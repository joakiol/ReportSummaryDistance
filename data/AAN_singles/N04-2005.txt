A Multi-Path Architecture for Machine Translation ofEnglish Text into American Sign Language AnimationMatt HuenerfauthComputer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104matthewh@seas.upenn.eduAbstractThe translation of English text into AmericanSign Language (ASL) animation tests thelimits of traditional MT architectural designs.A new semantic representation is proposedthat uses virtual reality 3D scene modelingsoftware to produce spatially complex ASLphenomena called ?classifier predicates.?
Themodel acts as an interlingua within a newmulti-pathway MT architecture design thatalso incorporates transfer and directapproaches into a single system.1 Introduction and MotivationAmerican Sign Language (ASL) is a visual/spatialnatural language used primarily by the half million Deafindividuals in the U.S. and Canada.
ASL has a distinctgrammar, vocabulary, and structure from English, andits visual modality allows it to use linguistic phenomenanot seen in spoken languages (Liddell, 2003; Neidle etal., 2000).
English-to-ASL translation is as complex astranslation between pairs of written languages, and infact, the difference in modality (from a written/spokento a visual/spatial manually performed system) addsnew complexities to the traditional MT problem.Building an English-to-ASL MT system is importantbecause although Deaf students in the U.S. and Canadaare taught written English, the difficulties in acquiring aspoken language for students with hearing impairmentsprevents most Deaf U.S. high school graduates fromreading above a fourth-grade level (students age 18 andolder reading text at a typical 10-year-old level) (Holt,1991).
Unfortunately, many Deaf accessibility aids(e.g.
television closed captioning or teletype telephoneservices) assume that the viewer has strong Englishliteracy skills.
Since many of these individuals arefluent in ASL despite their difficulty reading English, anASL MT system could make more information andservices accessible in situations where Englishcaptioning text is above the reading level of the vieweror a live English-to-ASL interpreter is unavailable.Researchers in graphics and human figure modelinghave built animated models of the human body that arearticulate enough to perform ASL that native signerscan understand (Wideman and Sims 1998).
Mostanimation systems use a basic instruction set to controlthe character?s movements; so, an MT system wouldneed to analyze an English text input and produce a?script?
in this instruction set specifying how thecharacter should perform the ASL translation output.The MT task is conceived of as translation from Englishtext into this script because ASL has no written form.While linguists use various ASL glosses, all weredesigned to facilitate linguistic study, not to serve as anatural writing system, and so they omit certain details.Since there is no ASL orthography used by the Deafcommunity, there are no natural sources of ASLcorpora.
To collect a corpus for statistical MT research,a movement annotation standard must be developed,ASL performances videotaped, and finally the videosmanually transcribed ?
a slow and expensive process(Niedle, 2000).
Motion-capture glove technology mayseem like a solution to this problem, but this type ofdata cannot easily be synthesized into novel and fluentASL animations.
The difficulty in obtaining largecorpora of ASL is why statistical approaches to theEnglish-to-ASL MT problem are not currently practical.2 ASL Linguistic IssuesAs opposed to spoken/written languages, ASL relies onthe multiple simultaneous channels of handshape, handlocation, palm orientation, hand/arm movement, facialexpressions, and other non-manual signals to conveymeaning.
To express additional meaning, ASL maymodify aspects of the manual performance of a sign(handshape, timing, motion path, repetition, etc.
),perform an additional grammatical facial expression, orsystematically use the areas of space around the signer.ASL signers use the space around them for severalgrammatical, discourse, and descriptive purposes.During a conversation, an entity under discussion(whether concrete or abstract) can be ?positioned?
at apoint in the signing space.
Subsequent pronominalreference to this entity can be made by pointing to thislocation, and some verb signs will move toward or awayfrom these points to indicate their arguments.Generally, the locations chosen for this pronominal useof the signing space are not topologically meaningful;that is, one imaginary entity being positioned to the leftof another in the signing space doesn?t necessarilyindicate the entity is left of the other in the real world.Other ASL expressions are more complex in theiruse of space and position invisible objects around thesigner to topologically indicate the arrangement ofentities in a 3D scene being discussed.
Special ASLconstructions called ?classifier predicates?
allow signersto use their hands to represent an entity in the space infront of them and to position, move, trace, or re-orientthis imaginary object in order to indicate the location,movement, shape, or other properties of somecorresponding real world entity under discussion.
Aclassifier predicate generally consists of the hand in oneof a closed set of semantically meaningful shapes as itmoves in a 3D path through space in front of the signer.For example, the sentence ?the car drove down thebumpy road past the cat?
could be expressed in ASLusing two classifier predicates.
First, a signer wouldmove a hand in a ?bent V?
handshape (index and middlefingers extended and bent) forward and downward to apoint in space in front of his or her torso where animaginary miniature cat could be envisioned.
Next, ahand in a ?3?
handshape (thumb, index, middle fingersextended) could trace a path in space past the ?cat?
in anup-and-down fashion as if it were a car bouncing alonga bumpy road.
Generally, ?bent V?
handshapes areused for animals, and ?3?
handshapes, for vehicles.The ability of classifier predicates to topologicallyrepresent a three-dimensional scene make themparticularly difficult to generate using traditionalcomputational linguistic methods and models.
Toproduce this pair of classifier predicates, there must be aspatial model of how the scene is arranged including thelocations of the cat, the road, and the car.
A path for thecar must be chosen with beginning/ending positions,and the hand must be articulated to indicate the contourof the path (e.g.
bumpy, hilly, twisty).
The proximity ofthe road to the cat, the plane of the ground, and thecurve of the road must be selected.
Other properties ofthe objects must be known: (1) cats generally sit on theground and (2) cars usually travel along the ground onroads.
The successful translation of the English textinto these classifier predicates used a great deal ofsemantic analysis, spatial knowledge, and reasoning.3 ASL MT Architectural DesignsThere is an architectural spectrum along which mostMT systems can be classified; loosely they are groupedinto three basic designs: direct, transfer, or interlingua(Dorr et al, 1998).
Direct systems process individualwords of the source language text; translation isachieved without performing any syntactic analysis.Transfer systems do analyze the input text to somesyntactic or semantic level, and then a set of ?transfer?rules produce a corresponding syntactic or semanticstructure in the target language.
Finally, a generationcomponent converts this structure into a target-languagetext.
Interlingual systems take this analysis of the inputtext one step further: the source is analyzed andsemantically processed to produce a typically language-independent semantic representation called an?interlingua,?
and then a generation componentproduces the target-language surface form from there.These design choices are often pictured as a pyramid, asin Figure 1, adapted from a figure in (Dorr et al, 1998).Generally, in the absence of statistical or case-basedinformation, the higher up the pyramid that the sourcetext is analyzed, the more complex and subtle are thedivergences the system can handle.
In particular, at theinterlingual level, a knowledge base can supplement thelinguistic information, producing translations that useworld knowledge and that may convey moreinformation than was present in the source text (devoidof context).
However, any of the approaches canproduce a correct translation for certain inputs since notall sentences require such sophisticated analysis to betranslated ?
some exhibit little translation divergence.Another trend as one goes up the MT pyramid is that theFigure 1: Pyramid of MT Architecture Designs.amount of domain specific development work that mustbe performed increases dramatically.
While directsystems may only require a bilingual lexicon, transfersystems also require analysis and transfer rules.Interlingual systems require interlingual representationsand sometimes domain specific knowledge bases.Non-statistical direct approaches to English-to-ASLMT generally produce simple translations that are oftenlittle more than word-to-sign dictionary look-ups.
Withthe addition of some basic sentence reorderingheuristics, such systems can occasionally produceacceptable output on simple English inputs or on thoseEnglish-ASL sentence pairs that have similar wordorder.1  Since no syntactic analysis is performed, there isno chance that an input sentence will be outside thelinguistic coverage of the system; so, the translationprocess will always produce some output.
Even if anEnglish word is not in the translation lexicon, manualfingerspelling can be used to express the word.Transfer MT designs address most of the linguisticshortcomings of direct systems but do require additionallinguistic resources to be developed.
There have been afew transfer-based English-to-ASL systems built(Huenerfauth, 2003), and several have had success inparticular aspects of the MT task, like expressingadverbials (Zhao et al, 2000) or representing ASLphonological information (Speers, 2001; S?f?r andMarshall, 2001).
These systems show promise that atransfer approach could someday handle most ASLsentences that do not require complex or topological useof the signing space.
As the ?bumpy road?
exampleillustrates, generating classifier predicates would requiremore than a simple syntactic or semantic analysis ?spatial analogy, scene visualization, and/or some degreeof iconicity seem to be involved.2For this reason, ASL transfer systems merely omitclassifier predicates from their coverage; however,many English concepts lack a fluent ASL translationwithout them.
Further, these predicates are common inASL; signers generally produce a classifier predicate atleast once per minute (once per 100 signs) (Morford andMacFarlane, 2003).
So, systems that cannot produceclassifier predicates are not a viable long-term solutionto the English-to-ASL MT problem.
To supply thesemantic understanding, spatial reasoning, and worldknowledge that classifier predicate generation demands,an interlingual approach (one with deeper semanticanalysis and 3D spatial representations) is required.1Direct systems more readily convert English text into asigning system like Signed Exact English, a manually codedform of English, not a distinct natural language, like ASL.2Linguists debate whether classifier predicates areparalinguistic iconic gestures, non-spatial polymorphemicconstructions, or compositional yet spatially-awareexpressions (Liddell, 2003), but transfer approaches to MTseem ill-suited to producing classifier predicates in any case.4 A Multi-Path MT ArchitectureWhile an interlingual approach to the classifierpredicate translation task sounds useful, there is aproblem.
It?s hard to built a true interlingual system foranything but a carefully limited domain; building thelinguistic and knowledge resources needed forinterlingual translation on less restricted texts can entailtoo much overhead to be practical.
What is specialabout the MT problem for ASL ?
and the reason whyinterlingual translation may be possible ?
is that we cancharacterize and identify the ?hard?
input sentences, theones that require classifier predicates for translation.These are spatially descriptive English input texts, thosegenerally containing: spatial verbs describing locations,orientations, or movements; spatial prepositions oradverbials with concrete or animate entities; or lexicalitems related to other common topics or genres in whichclassifier predicates are typically used.
Such genres(e.g.
vehicle motion or furniture arrangement in a room)could be detected using the features mentioned above.While an interlingual approach is needed to translateinto classifier predicates, there are a vast number ofEnglish input sentences for which such deep analysisand reasoning would not be necessary.
As we've seenfrom the direct and transfer discussion above, theseresource-lighter approaches can often produce a correcttranslation from lexical or syntactic information alone.This analysis suggests a new multi-path architecturefor an MT system ?
one that includes a direct, a transfer,and an interlingual pathway.
English input sentenceswithin the implemented interlingua?s limited domaincould follow that processing pathway, those sentencesoutside of the interlingual domain but whose syntacticfeatures fall within the linguistic coverage of theanalysis and transfer rules could use the transferpathway, and all other sentences could use the directpathway with its bilingual dictionary look-up.Limiting the domain that the transfer and interlinguacomponents must handle makes the development ofthese components more manageable.
The transferpathway?s analysis grammar and transfer rules wouldnot have to cover every possible English sentence that itencounters: some sentences would simply use the directtranslation pathway.
Limiting domains has an evenmore dramatic benefit for the interlingual pathway.Instead of building interlingual analysis, representation,and generation resources for every possible domain, theinterlingual development can focus on the specificdomains in which classifier predicates are used: walkingupright figures, moving vehicles, furniture or objectsarranged in a room, giving directions, etc.
In this way,the ?depth?
of divergence-handling power of sometranslation approaches and the ?breadth?
of coverage ofothers can both be part of this multi-path architecture.This design does more than just restrict the domainsfor which the interlingua must be implemented; it alsoreduces the ontological complexity that the entireinterlingua must support.
The domains listed aboveshare a common feature: they all discuss the movement,location, orientation, and physical description of entitiesin three-dimensional scenes.
Some complexphenomena whose handling often makes designing aninterlingual representation quite difficult ?
abstractconcepts, beliefs, intentions, quantification, etc.
?
do notneed to be represented.
In a sense, this multi-patharchitecture doesn?t just limit the things that must berepresented, but the ?type?
of these things as well.Having multiple processing pathways does not meanthat there is necessarily a new problem of choosingwhich to use.
The system could be implemented as a?fall back?
architecture in which the system couldattempt the most complex approach (interlingual) anddrop back to each of the simpler approaches whenever itlacks the proper lexical, syntactic, semantic, orknowledge resources to succeed for the currentpathway.
In this way, the linguistic coverage of each ofthe levels of representation would define exactly howinput sentences would be routed through the system.If the system were to use a more complex pathwaythan was necessary during translation, then, if properlyimplemented, output would be produced that could havebeen created using a simpler pathway.
This is anacceptable, if less efficient, result.
If the system lackedthe linguistic resources to translate a sentence using thesophisticated level of processing it required, then theoutput would be more English-like in structure than itshould.
Because most Deaf users of the system wouldhave had experience interacting with hearing peoplewho used non-fluent English-like signing or manuallysigned forms of English, like Signed Exact English orSign Supported English, then they may still find thisoverly English-like translation useful.5 A Spatial Interlingua for ASL MTWhen ASL signers describe a spatially complex 3Dscene using classifier predicates, they visualize theelements of the scene as occupying an area of space thatis generally within arm?s reach in front of their torso.So, signers have a spatial model of the scene underdiscussion that they can consider when selecting andgenerating classifier predicates to convey information.An automated system for creating classifier predicatesmay be able to use an analogous representation.One way to produce this model is to incorporatevirtual reality 3D scene representation software into theMT system?s interlingual pathway.
After analyzing theEnglish text, the movements of entities under discussioncould be identified, and a 3D virtual reality model of thescene could be constructed and/or modified to reflectthe information in the English text.
This spatial modelcould serve as the basis for generating the 3D andspatially analogous (topological) motions of the signingcharacter?s hands while performing classifier predicates.Fortunately, a system for producing a changing 3Dmodel of a scene from an English text has been built:the Natural Language Instructions for DynamicallyAltering Agent Behaviors system (Bindiganavale et al,2000; Badler et al, 2000) (herein, ?NLI?).
The systemdisplays a 3D virtual reality scene and accepts Englishinput text containing instructions for the characters andobjects in the scene to follow.
It updates the animationso that objects obey the English commands.
NLI hasbeen used in military training and equipment repairdomains and can be extended by augmenting its libraryof Parameterized Action Representations (PARs), tocover additional domains of English input texts.PARs are feature/value structures stored as a libraryof templates with slots specifying: the agent moving, thepath/manner or translational/rotational nature of themotion, terminating conditions, speed/timing, and othermotion information.
English lexicalized syntacticstructures are associated with PARs so that the analysisof a text can be used to select a PAR template and fill itsslots.
PARs serve as 3D motion primitives and are usedas hierarchical planning operators to produce a detailedanimation specification; so, they contain fields likepreconditions and sub-actions used in NLI?s animationplanning process (Badler et al, 2000).
A PAR generallycorresponds to an English motion verb (or a set ofrelated verbs); so, to extend NLI for use in an ASLcontext, additional PARs will be developed for Englishmotion verbs that often produce classifier predicates.The MT system?s interlingual pathway will use theNLI software to analyze the English source text as if itwere commands for the entities mentioned in the text.The NLI can create and maintain a 3D model of thelocation and motion of these entities.
The MT system,unlike other applications of the NLI software, does notcare about the exact shape or appearance of the objectsbeing modeled (generic box-like shapes could be usedfor each).
Instead, the location and motion paths ofthese objects in a generic 3D space are important, sincethese are used to build classifier predicates.The MT system would use the spatial model toinstantiate a transparent miniature animation of theseobjects; this animation would be overlaid on an area ofthe virtual reality space in front of the torso of thecharacter performing the ASL animation output.
In the?bumpy road?
example, a small invisible object wouldbe positioned in space in front of the chest of thesigning character to represent the cat.
Next, a 3Danimation path and location for the car (relative to thecat) would be chosen in front of the character?s chest.When objects in this ?invisible world?
are moved orreoriented to reflect information in the English text, theanimated ASL-signing character can position its handinside of the transparent (possibly moving) object toindicate its new location, orientation, or movement path.By choosing an appropriate handshape for the character,a classifier predicate is thus produced that conveys thespatial information from the English text.
Extensions ofthis design for more complex classifier predicateconstructions are discussed in (Huenerfauth, 2004).This interlingual pathway design would pass alongmost of the spatial modeling and reasoning burdens tothe NLI software, which was designed for this task.
Itcan select relative locations and motion paths for objectsin the 3D scene based on prepositions and adverbials inthe English input text.
It uses collision avoidance,physical constraints, generic and specialized motionprimitives, and hierarchical motion planning operatorsto produce the necessary detail for a 3D animation fromthe limited information in a corresponding English text.The full architectural diagram is shown in Figure 2.This design visually resembles the pyramid in Figure 1:direct pathway at the bottom, transfer across the middle,and interlingual pathway over the top of the pyramid.The three paths no longer represent the design choicespossible for different systems; they are now processingpathways within a single ?pyramidal?
architecture.6 Virtual Reality as InterlinguaThe 3D model produced by the NLI software serves asan intermediary between the English text analysis andthe classifier predicate generation in this architecture,but that does not necessarily make it an interlingua.
Infact, the design differs from interlingual representationselsewhere in the MT literature significantly.
To explorethis issue, consider a general definition of an interlinguaas: a typically language-neutral semantic representationuseful for MT that may incorporate knowledge sourcesbeyond the basic semantics of the input text.First, the model represents those aspects of the inputtext?s meaning significant for translation to classifierpredicates; thus it serves as a semantic representationwithin the 3D motion domain ?
albeit a non-traditionalone due to the ontological simplicity of this domain.Second, this proposed architectural design hasillustrated how this 3D scene representation is useful forMT.
Third, the NLI software?s ability to incorporatephysical constraints, collision detection, and spatialreasoning shows how the 3D model can use knowledgesources beyond the original text during translation.So, the final determinant of this model?s interlingualstatus is its language-neutrality.
The 3D coordinates ofobjects in a virtual reality model are certainly language-neutral.
However, ASL linguists have identifieddiscourse and other factors beyond the 3D scene modelthat can affect how classifier predicates are generated(Liddell, 2003).
If the classifier predicate generatorneeds these features, then the degree to which they aremodeled in a language-neutral manner will affectwhether the pathway is truly interlingual.
Until the finalimplementation of the generator is decided, it is an openissue as to whether this pathway is an interlingua orsimply a spatially rich semantic transfer design.
37 Discussion and Future WorkWhile English-to-ASL MT motivated the multi-pathpyramidal architecture, the design is also useful forother language pairs.
Merging multiple MT approachesin one system alleviates the traditional trade-offbetween divergence-handling power and domainspecificity, thus making resource-intensive approaches(e.g.
interlingual) practical for applications that requirebroad linguistic coverage.
This architecture is usefulwhen a system must translate a variety of texts butperform deeper processing on texts within particularimportant or complex domains.
It is also useful whenthe input is usually (but not always) inside a particularsublanguage.
Transfer or interlingual resources can bedeveloped for the domains of interest, and resource-lighter (broader coverage) pathways can handle the rest.While the English-to-ASL system had no statisticalpathways, nothing prevents their use in a multi-pathpyramidal architecture.
Statistical approaches could beused to develop a direct pathway, and hand-builtanalysis and transfer rules for a subset of the sourcelanguage could create a transfer pathway.
A developercould thus use a stochastic approach for most inputs butmanually override the MT process for certain texts (that3Kipper and Palmer (2000) examined PARs as aninterlingua for translation of motion verbs between verb-frame and satellite-frame languages.
Unlike this system,they did not use PARs within a 3D scene animation; thePAR itself was their interlingua, not the 3D scene.Figure 2: Multi-Path ?Pyramidal?
MT Architecture.are important or whose translation is well understood).Likewise, a transfer pathway may use statisticallyinduced transfer rules and parsers, and an interlingualpathway may be manually built for specific domains.While the pyramidal architecture has applicationsacross many languages, the 3D scene modeling softwarehas benefits specific to ASL processing.
Beyond its usein classifier predicate generation, the 3D model allowsthis system to address ASL phenomena that most MTarchitectures cannot.
The non-topological use of thesigning space to store positioned objects or ?tokens?
(Liddell, 2003) for pronominal reference to entities inthe discourse can easily be implemented in this systemby taking advantage of the invisible overlaid 3D scene.The layout, management, and manipulation of these?tokens?
is a non-trivial problem, and the richness of thevirtual reality spatial model can facilitate their handling.The NLI software makes use of sophisticated humancharacters that can be part of the scenes being controlledby the English text.
These virtual humans possess skillsthat would make them excellent ASL signers for thisproject: they can gaze in specific directions, make facialexpressions useful for ASL output, and point at objectsor move their hand to locations in 3D space in a fluidand anatomically natural manner (Badler et al, 2000).If one of these virtual humans served as the signingcharacter, as one did for (Zhao et al, 2000), then thesame graphics software would control both the invisibleworld model and the ASL-signing character, thussimplifying the implementation of the MT system.Currently, this project is finishing the specificationof the multi-path design and investigating the followingissues: deep generation techniques for creating multipleinterrelated classifier predicates, surface generation ofindividual classifier predicates from compositional rulesor parameterized templates, and ASL morphologicaland syntactic representations for the transfer pathway.Another important issue being examined is how toevaluate the ASL animation output of an MT system ?in particular one that produces classifier predicates.AcknowledgementsI would like to thank my advisors Mitch Marcus andMartha Palmer for their guidance, discussion, andrevisions during the preparation of this work.ReferencesR.
Bindiganavale, W. Schuler, J. Allbeck, N. Badler, A.Joshi, and M. Palmer.
2000.
?Dynamically AlteringAgent Behaviors Using Natural LanguageInstructions.?
4th International Conference onAutonomous Agents.N.
Badler, R. Bindiganavale, J. Allbeck, W. Schuler, L.Zhao, S. Lee, H. Shin, and M. Palmer.
2000.?Parameterized Action Representation and NaturalLanguage Instructions for Dynamic BehaviorModification of Embodied Agents.?
AAAI SpringSymposium.B.
Dorr, P. Jordan, and J. Benoit.
1998.
?A Survey ofCurrent Paradigms in Machine Translation.
?Technical Report LAMP-TR-027, Language andMedia Processing Lab, University of Maryland.J.
Holt.
1991.
Demographic, Stanford Achievement Test- 8th Edition for Deaf and Hard of Hearing Students:Reading Comprehension Subgroup Results.M.
Huenerfauth.
2003.
?Survey and Critique ofAmerican Sign Language Natural LanguageGeneration and Machine Translation Systems.
?Technical Report MS-CIS-03-32, Computer andInformation Science, University of PennsylvaniaM.
Huenerfauth.
2004.
?Spatial Representation ofClassifier Predicates for Machine Translation intoAmerican Sign Language.?
In Proceedings of theWorkshop on the Representation and Processing ofSigned Languages, 4th International Conference onLanguage Resources and Evaluation (LREC 2004).K.
Kipper and M. Palmer.
2000.
?Representation ofActions as an Interlingua.?
In Proceedings of the 3rdWorkshop on Applied Interlinguas, ANLP-NAACL.S.
Liddell.
2003.
Grammar, Gesture, and Meaning inAmerican Sign Language.
UK: Cambridge U. Press.J.
Morford and J. MacFarlane.
?FrequencyCharacteristics of ASL.?
Sign Language Studies, 3:2.C.
Neidle.
2000.
?SignStream?
: A Database Tool forResearch on Visual-Gestural Language.?
AmericanSign Language Linguistic Research Project, ReportNumber 10, Boston University, Boston, MA, 2000.C.
Neidle, J. Kegl, D. MacLaughlin, B. Bahan, and R.G.
Lee.
2000.
The Syntax of American SignLanguage: Functional Categories and HierarchicalStructure.
Cambridge, MA: The MIT Press.?.
S?f?r and I. Marshall.
2001.
?The architecture of anEnglish-text-to-Sign-Languages Translation System.
?In G. Angelova, ed., Recent Advances in NaturalLanguage Processing.
Tzigov Chark, Bulgaria.d'A.
Speers.
2001.
Representation of ASL for MachineTranslation.
Ph.D.
Diss., Linguistics, Georgetown U.C.
Wideman & M. Sims.
1998.
?Signing Avatars.
?Technology & Persons with Disabilities Conference.L.
Zhao, K. Kipper, W. Schuler, C. Vogler, N. Badler,and M. Palmer.
2000.
?A Machine TranslationSystem from English to American Sign Language.
?Association for Machine Translation in the Americas.
