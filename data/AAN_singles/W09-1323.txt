Proceedings of the Workshop on BioNLP, pages 179?184,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsClustering semantic spaces of suicide notes and newsgroups articlesP.
Matykiewicz1,2, W. Duch2, J. Pestian11Cincinnati Children?s Hospital Medical Center, University of Cincinnati,2Nicolaus Copernicus University, Torun?, Poland.AbstractHistorically, suicide risk assessment has re-lied on question-and-answer type tools.
Thesetools, built on psychometric advances, arewidely used because of availability.
Yet thereis no known tool based on biologic and cogni-tive evidence.
This absence often cause a vex-ing clinical problem for clinicians who ques-tion the value of the result as time passes.
Thepurpose of this paper is to describe one exper-iment in a series of experiments to develop atool that combines Biological Markers (Bm)with Thought Markers (Tm), and use machinelearning to compute a real-time index for as-sessing the likelihood repeated suicide attemptin the next six-months.
For this study we fo-cus using unsupervised machine learning todistinguish between actual suicide notes andnewsgroups.
This is important because it givesus insight into how well these methods dis-criminate between real notes and general con-versation.1 IntroductionIt is estimated that each year 800,000 die by suicideworldwide (World Health Organization, 2001).
Inthe United States, suicide ranks second as the lead-ing cause of death among 25-34 year-olds and thethird leading cause of death among 15-25 year-olds(Kung et al, 2008).
The challenge for those whocare for suicide attempters, such as an EmergencyMedicine clinicians, is to assess the likelihood of an-other attempt, a more lethal one.
We believe to fullyasses this risk a tool must be developed that mea-sures both the biological and cognitive state of thepatient.
Such a tool will include Biological Mark-ers (Bm): measured by the concentration of cer-tain biochemical markers, Thought Markers (Tm):measured by artifacts of thought that have been re-duced to writing or transcribe speech, and Clini-cal Markers (Cm): measured by traditional clinicalrisk factors.
In this study we focus on the Tm be-cause of BioNLP?s important role.
Here, we employmachine-learning analysis to examine suicide notesand how these notes compare to newsgroups.
Thisis one experiment in a series of experiments that areintended to provide insight into how best to applylinguistic tools when responding to suicidal patients.To gain insight into the suicidal mind, researchershave suggested empirically analyzing national mor-tality statistics, psychological autopsies, nonfatalsuicide attempts and documents such as suicidenotes (Shneidman and Farberow, 1957; Maris,1981).
Most suicide notes analysis has focusedon classification and theoretical-conceptual analysis.Content analysis has been limited to extracting ex-plicit information from a suicide note, e.g., length ofthe message, words, and parts of speech (Ogilvie etal., 1969).
Classification analysis uses data such asage, sex, marital status, educational level, employ-ment status and mental disorder (Ho et al, 1998;Girdhar et al, 2004; Chavez et al, 2006; Demirelet al, 2007).
Only a very few studies have utilizedtheoretical-conceptual analysis , despite the asser-tion in the first formal study of suicide notes (Shnei-dman and Farberow, 1957) that such an analysis hasmuch promise.
So, the inconclusive nature of themethods of analysis has limited their application topatient care.179Our own research has taken a different approach.In particular we first wanted to determine if mod-ern machine learning methods could be applied tofree-text from those who committed suicide.
Ourfirst experiment focused on the the ability of ma-chine learning to distinguish between real suicidenotes and elicited suicide notes as well as mentalhealth professionals.
This is an important questionsince all current care is based on a mental health pro-fession?s interpretation.
Our findings showed thatmental health professionals accurately selected gen-uine suicide notes 50% of the time and the super-vised machine learning methods were accurate 78%(Pestian et al, 2008).
In this study we shift fromsupervised to unsupervised machine learning meth-ods.
Even though these methods have rich historywe know of no research that has applied them tosuicide notes.
Our rationale for this study, then, isthat since our ultimate goal is to create a SuicideRisk Index that incorporates biological and thoughtmarkers it is important to determine if unsupervisedmethods can distinguish between suicidal and non-suicidal writings.
To conduct this research we de-veloped a corpus of over 800 suicide notes from in-dividuals who had committed suicide, as opposed tothose who attempted or ideated about suicide.
Thisis an important contribution and, as far as we know,it is the largest ever developed.
It spans 70 years ofnotes, and now includes multiple languages.
Detailsof this corpus are described below.
We also createda corpus of data from various newsgroups that actedas non-suicidal writings.
These corpora were usedto conduct the analysis.
The sections below describethe cluster analysis process and results.2 DataSuicide Notes CorpusData for the suicide note database were collectedfrom around the United States.
They were eitherin a hand written or typed written form.
Once thenote was acquired it was scanned into the database.Optical character recognition was attempted on thetyped written notes, but not accurate, so the noteswere read from the scanned version and type into thedatabase exactly as seen.
A second person reviewedwhat was typed.
There were limitation in collectingdeceased demographics.
The table 1 provides vari-ous descriptive statistics.Newsgroup CorpusNewsgroup data was selected because it was conve-nient and as close to normal discourse as we couldfind.
We understood that and ideal comparisongroup would be composed of Internet blogs or e-mails that were written by suicide ideators.
True,a Google query of ?suicide blog?
yields millionsof response, a review of many of these responsesshows that the data are of little use for this analy-sis.
In our opinion, the next suitable corpora wasfound in a 20 newsgroup collection from the Uni-versity of California in Irvine (UCI) machine learn-ing repository1 .
Most of the newsgroups have norelevance to suicide notes.
Since our hypothesisis that unsupervised learning methods can tell thedifference between suicidal and non-suicidal writ-ing we selected discussions that we believed mayhave some similarity to suicide writings.
This se-lection was based on reviewing the newsgroupswith experts.
We had conjectured that if an unsu-pervised method could distinguish between similarclusters those methods could distinguish betweendissimilar clusters.
The newsgroups ultimately se-lected were talk.politics.guns, talk.politics.mideast,talk.politics.misc, talk.religion.misc.
Each news-group contains 1000 articles (newsgroup postings).Headers and quotes from other postings were re-moved.3 MethodsBasic statistics are calculated using variables ex-tracted by Linguistic Inquiry and Word Count ver-sion 2007 software (LIWC2007) (Chung and Pen-nebaker, 2007).
J. W. Pennebaker, C. K. Chung, M.Ireland, A. Gonzales, and R. J. Booth created an an-notated dictionary.
Each word in the dictionary isassigned to at least one of the following high levelcategory: linguistic process, psychological process,personal concern, or spoken category.
These cat-egories provide an efficient and effective methodfor studying the various emotional, cognitive, andstructural components present in individuals?
verbaland written speech samples (Chung and Pennebaker,2007; Pennebaker et al, 2001).
Here it is used toanalyze differences between suicide notes and news-1http://archive.ics.uci.edu/ml/180group articles.Feature space was prepared using open source al-gorithms available in Perl language2 .
First, BrianDuggan spell checking software that uses aspell li-brary was used (Text::SpellChecker module3).
Then,tokenizer created by Aaron Coburn was used (Lin-gua::EN::Tagger module2) to extract words was ap-plied.
After that, words were filtered with 319 ele-ment stop word list 4.
Next, the Richardson/FranzEnglish stemmer was included in the pre-processingstage (Lingua::Stem module2).
Features that ap-peared in less than 10 documents or in more than 500documents were removed.
Documents that had lessthan 10 features or more than 500 were removed.Finally, columns and rows were normalized to haveunitary lengths.
These last steps of pre-processingare used to reduce outliers.Calculations are done using open source softwarecalled R5.
Clustering is done with the following al-gorithms: expectation maximization (EM) (Wittenand Frank, 2000), simple k-means with euclideandistance (SKM) (Witten and Frank, 2000), andsequential information bottleneck algorithm (sIB)(Slonim et al, 2002).
The last approach has beenshown to work well work well when clustering doc-uments.
Specificity, sensitivity and F1 measure areused as performance measures (Rijsbergen, 1979).Multidimensional scaling with euclidean distancemeasures is used for visualization purposes (Coxand Cox, 1994).To extract features that represent each cluster,Pearson correlation coefficient is used.
The correla-tion coefficient r is calculated between each featureand each cluster separately r(wi, cj) where wi is ithword and cj is jth cluster.
N best features with thehighest values for each cluster are selected as mostrepresentative.4 ResultsDescriptive statistics for the data sets are listed intable 1.
It shows syntactic differences between lan-guage use in suicide notes and newsgroups whenLingua::EN::Tagger is used.2http://www.perl.org3http://search.cpan.org4http://www.dcs.gla.ac.uk/idom/ir resources//linguistic utils/stop words5http://www.r-project.orgTable 1: Descriptive statistics of suicide note corpus andnewsgroups.suicidecorpusnewsgroupsSample Size 866 4000 (1000per group)Collection Years 1945-2009 1992-1993Avg tokens per record(SD)105 (154) 243 (582)Range of tokens perrecord1-1837 0-11024Average (SD) nouns 25.21 (34.81) 77.19(181.63)Average (SD) pronouns 16.58 (26.69) 18.05 (63.18)Average (SD) verbs 21.07 (32.82) 41.31(109.23)Average (SD) adjec-tives6.43 (9.81) 16.92 (36.45)Table 2 summarizes information about the lin-guistic and psychological processes of the data.The idea of ?process?
is derived from the Lin-guistic Inquiry and Word Count (LIWC2007) soft-ware (Chung and Pennebaker, 2007).
This softwareconducts traditional natural language processing byplacing various word into categories.
For example,sixltrs includes words that are at least six letters inlength.
A full description of this software, dictio-naries, reliability and validity tests can be found onLIWC?s website.
6.
Table 2 shows that suicide notesare, in many ways, different than normal text.
Forour study this provides inspiration for continued re-search.Table 2: Mean and standard deviation in linguistic andpsychological processes.
Selected categories with small-est p-values (<0.0001) are shown.suicide guns mideast politics religionartcl 3.31 (2.79) 7.80 (3.52) 7.37 (3.34) 7.21 (3.40) 7.07 (3.51)sixltrs 14.20 (7.34) 21.22 (6.32) 23.24 (7.03) 22.41 (7.13) 21.37 (7.87)prnoun 16.75 (6.82) 11.96 (5.15) 10.64 (4.92) 11.77 (5.18) 13.21 (5.76)prepos 10.61 (4.35) 12.13 (3.97) 12.89 (3.89) 12.21 (3.97) 11.75 (4.07)verb 14.69 (5.99) 12.75 (4.72) 11.54 (4.74) 12.72 (4.63) 13.54 (4.97)biolog 2.70 (3.04) 0.93 (1.27) 0.85 (1.50) 1.59 (2.08) 1.10 (1.75)affctiv 7.71 (5.39) 4.83 (2.87) 4.77 (3.45) 4.90 (3.18) 5.10 (3.93)cognitv 12.68 (5.76) 16.14 (5.93) 14.72 (5.62) 16.00 (5.49) 17.14 (6.17)social 10.45 (5.86) 8.10 (4.20) 8.43 (4.71) 8.76 (4.37) 9.06 (5.17)The four newsgroup data sets are combinedas follows: talk.politics.guns + suicide notes= guns, talk.politics.mideast + suicide notes =mideast, talk.politics.misc + suicide notes = politics,6http://www.liwc.net/liwcdescription.php#index1181talk.religion.misc + suicide notes = religion.
Eachdata set contained 1866 documents before documentand feature selection is applied.
Table 3 has finalnumber of features while table 4 has final number ofdocuments.
In general sIB clustering algorithm per-formed best for all data sets with respect to F1 mea-sure (mean = 0.976, sd = 0.008).
The average scorealso did not change when the number of clusters var-ied from two to six (mean = 0.973, sd = 0.012).
Per-formance of k-means and expectation maximizationalgorithm was much worse.
If number of clusterswas varied between two and six for different datasets the algorithms achieved F1 measure 0.146 lowerthan sIB (SKM mean = 0.831, sd = 0.279, EM mean= 0.824, sd = 0.219).
Table 3 summarizes perfor-mance of best algorithms for each data set if twoclusters are chosen.Table 3: Best clustering algorithms for each newsgroupwhen clustered with suicide notes in case of two clus-ters (alg = clustering algorithm, sens = sensitivity, spec= specificity, F1 = F1 measure, #f = number of features,sIB = sequential information bottleneck, SKM = simplek-means).dataset al sens spec F1 #fguns sIB .9689 .9834 .9721 1658mideast sIB .9837 .9942 .9877 2023politics SKM .9705 .9889 .9769 1694religion sIB .9787 .9700 .9692 1553If the desired number of clusters is increased tofour then two major sub-groups are discovered insuicide notes: emotional (represented by words like:love, forgive, hope, and want) and non-emotional(represented by words like: check, bank, and no-tify).
Example of the first type of note might be(suicide note was annonymized and misspellings leftunchanged):Jane I am bitterly sorry for what I have done toyou.
Please try to forgive me.
I can?t live with-out you and you don?t want me.
I can?t blame youthough.
But I love you very much.
I didn?t act like itbut I did and still do.
Please try to be happy, Jane.That is all I ask.
I try hope for the best for you andI guess that is all there is for me to say.
Good by.John Johnson.
Please mail this to Mom.
Mrs. JaneJohnson.
Cincinnati, OH.Example of a non-emotional suicide note might be:There is no use living in pains.
That arthritis andhardening of the arteries are too much for me.
Thereare two hundred and five dollars in the bank, andhere are fifty- five dollars and eight cents.
I hope thatwill be enough for my funeral.
You have to notify theOld Age Assistance Board.
Phone - 99999.Table 4 shows best five ranked features for each clus-ter for each data set according to correlation coeffi-cient CC .
Features are in the order of rank so thatfeature with the highest CC is first.
Even thoughthat we use different newsgroups as control groupssame sub-groups of suicide notes are discovered.sIB is the most stable and best performing algorithmin this experiment so it was used to discover thoseclusters.
Stemmed word that appear in best fiveranked features in at least three data sets are markedbold.Figures 1, 2, 3, and 4 show high-dimensional doc-ument/stemmed word feature space projected on atwo dimensional plane using multidimensional scal-ing (MDS) initialized by principal component analy-sis.
Each figure has different rotation but the shapesare similar.
In addition MDS shows very little mix-ing of suicide notes and newsgroups which is alsoexplained by results in the table 3.Figure 1: MDS showing suicide notes andtalk.politics.guns articles (s character in the figuremeans suicide note while a character depicts newsgrouparticle, colors are used as cluster numbers).182Table 4: Best five features when four clusters are createdby the sIB algorithm (#c = cluster number, #a = numberof newsgroup articles in a cluster, #s = number of suicidenotes in a cluster).
Stemmed word that appear in best fiveranked features in at least three data sets are marked bold.dataset #c stemmed words #a #sguns 1 address, bank, bond, notifi,testam28 204guns 2 clinton, fbi, foreign, jim,spea318 2guns 3 forgiv, god, hope, love,want4 381guns 4 crime, firearm, gun, law,weapon541 8mideast 1 appressian, armenia, arme-nian, ohanu, proceed464 5mideast 2 arab, congress, isra, israel,jew379 4mideast 3 bank, check, funer, insur,testam10 233mideast 4 forgiv, good, hope, love,want2 355politics 1 compound, disclaim, fbi,govern, major593 12politics 2 clayton, cramer, optilink,relat, uunet274 1politics 3 bank, box, check, funer,notifi11 258politics 4 forgiv, good, hope, life,love11 330religion 1 bank, bond, check, notifi,paper36 192religion 2 frank, object, observ, the-ori, valu279 0religion 3 activ, christian, jesu, ko-resh, net502 10religion 4 forgiv, hope, love, sorri,want12 3955 ConclusionsOur findings suggest that unsupervised methods candistinguish between suicide notes and newsgroups,our proxy for general discussion.
This is importantbecause it is helpful in determining if NLP can beuseful when integrating thought markers with bio-logical and clinical markers (f(Bm, Tm, Cm)).
Inother words, can an NLP tools accurately distin-guish between suicidal and normal thought markers(T Sm 6= TNm )?
Moreover these unsupervised meth-ods have shown an ability to find sub-groups of sui-cide notes even when other types of newsgroups arepresent.
In our analysis, one subgroup showed noFigure 2: MDS showing suicide notes andtalk.politics.mideast articles (s character in the fig-ure means suicide notes while a character depictsnewsgroup article, colors are used as cluster numbers).Figure 3: MDS showing suicide notes andtalk.politics.misc articles (s character in the figuremeans suicide note while a character depicts newsgrouparticle, colors are used as cluster numbers).emotional content while the other was emotionallycharged.
This finding is consistent with Tuckman?s,1959 work that showed suicide notes fall into sixemotional categories: emotionally neutral, emotion-ally positive, emotionally negative directed inward,emotionally negative directed outward, emotionallynegative directed inward and outward (Tuckman etal., 1959).
The next step in developing a SuicideRisk Index is to conduct a clinical trail in the Emer-gency Department that will collect Bm, Tm, Cmand test multiple methods for computing the Suicide183Figure 4: MDS showing suicide notes andtalk.religion.misc articles (s character in the figuremeans suicide note while a character depicts newsgrouparticle, colors are used as cluster numbers).Risk Index.ReferencesA.
Chavez, D. Paramo-Castillo, A. Leenaars, andL.
Leenaars.
2006.
Suicide notes in mexico: What dothey tell us?
Suicide and Life-Threatening Behavior,36:709?715.C.K.
Chung and J.W.
Pennebaker, 2007.
Thepsychological functions of function words, pages 343?359.
New York: Psychology Press.T.
F. Cox and M. A.
A. Cox.
1994.
MultidimensionalScaling.
Chapman and Hall.B.
Demirel, T. Akar, A. Sayin, S. Candansayar, andA Leenaars.
2007.
Farewell to the world: Sui-cide notes from turkey.
Suicide and Life-ThreateningBehavior, 38:123?128.S.
Girdhar, A. Leenaars, T.D.
Dogra, L. Leenaars, andG.
Kumar.
2004.
Suicide notes in india: what do theytell us?
Archives of Suicide Research, 8:179?185.T.
Ho, P. Yip, C. Chiu, and P. Halliday.
1998.
Sui-cide notes: what do they tell us?
Acta PsychiatricaScandinavica, 98:467?473.Hsiang-Ching Kung, Donna L. Hoyert, Jiaquan Xu, andSherry L. Murphy.
2008.
Deaths: Final data for 2005.National Vital Statistics Report, 56:1?121.R.
Maris.
1981.
Pathways to suicide.
John HopkinsUniversity Press, Baltimore, MD.D Ogilvie, P. Stone, and E. Shneidman.
1969.
Somecharacteristics of genuine versus simulated suicidenotes.
Bulletin of Suicidology, 1:17?26.J.
W. Pennebaker, M. E. Francis, and R. J. Booth.
2001.Linguistic Inquiry and Word Count: LIWC.
LawrenceErlbaum Associates, Mahwah, NJ, 2nd edition.J.
P. Pestian, P. Matykiewicz, J. Grupp-Phelan,S.
Arszman-Lavanier, J. Combs, and Robert Kowatch.2008.
Using natural language processing to clas-sify suicide notes.
In AMIA Annual SymposiumProceedings, volume 2008.
American Medical Infor-matics Association.C.
J.
Van Rijsbergen.
1979.
Information Retrieval.Butterworth-Heinemann, Newton, MA, USA.E Shneidman and N Farberow.
1957.
Clues to Suicide.McGraw Hill Paperbacks.Noam Slonim, Nir Friedman, and Naftali Tishby.
2002.Unsupervised document classification using sequentialinformation maximization.
In Proceedings of the 25thInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, pages 129?136.Jacob Tuckman, Robert J. Kleiner, and Martha Lavell.1959.
Emotional content of suicide notes.
Am JPsychiatry, 116(1):59?63.Ian H. Witten and Eibe Frank.
2000.
Data mining:practical machine learning tools and techniques withJava implementations.
Morgan Kaufmann PublishersInc., San Francisco, CA, USA.World Health Organization, 2001.
Burden of mental andbehavioral disorders, pages 19?45.
World Health Or-ganization, Geneva.184
