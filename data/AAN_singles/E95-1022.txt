A syntax-based part-of -speech analyserAtro VoutilainenResearch Unit for Multilingual Language TechnologyP.O.
Box 4FIN-00014 University of HelsinkiFinlandAtro.Voutilainen@Helsinki.FIAbstractThere are two main methodologies forconstructing the knowledge base of anatural language analyser: the linguis-tic and the data-driven.
Recent state-of-the-art part-of-speech taggers are basedon the data-driven approach.
Becauseof the known feasibility of the linguis-tic rule-based approach at related levelsof description, the success of the data-driven approach in part-of-speech analy-sis may appear surprising.
In this paper,a case is made for the syntactic natureof part-of-speech tagging.
A new taggerof English that uses only linguistic dis-tributional rules is outlined and empiri-cally evaluated.
Tested against a bench-mark corpus of 38,000 words of previ-ously unseen text, this syntax-based sys-tem reaches an accuracy of above 99%.Compared to the 95-97% accuracy of itsbest competitors, this result suggests thefeasibility of the linguistic approach alsoin part-of-speech analysis.1 Introduct ionPart-of-speech analysis usually consists of (i) in-troduction of ambiguity (lexical analysis) and (ii)disambiguation (elimination of illegitimate alter-natives).
While introducing ambiguity is regardedas relatively straightforward, disambiguation isknown to be a difficult and controversial problem.There are two main methodologies: the linguisticand the data-driven.?
In the linguistic approach, the generalisa-tions are based on the linguist's (poten-tially corpus-based) abstractions about theparadigms and syntagms of the language.Distributional generalisations are manuallycoded as a grammar, a system of constraintrules used for discarding contextually illegit-imate analyses.
The linguistic approach islabour-intensive: skill and effort is needed forwriting an exhaustive grammar.?
In the data-driven approach, frequency-basedinformation is automatically derived fromcorpora.
The learning corpus can consist ofplain text, but the best results seem achiev-able with annotated corpora (Merialdo 1994;Elworthy 1994).
This corpus-based informa-tion typically concerns equences of 1-3 tagsor words (with some well-known exceptions,e.g.
Cutting et al 1992).
Corpus-based infor-mation can be represented e.g.
as neural net-works (Eineborg and Gamb/~c k 1994; Schmid1994), local rules (Brill 1992), or collocationalmatrices (Garside 1987).
In the data-drivenapproach, no human effort is needed for rule-writing.
However, considerable effort may beneeded for determining a workable tag set (cf.Cutting 1994) and annotating the trainingcorpus.At the first flush, the linguistic approach mayseem an obvious choice.
A part-of-speech tagger'stask is often illustrated with a noun-verb ambigu-ous word directly preceded by an unambiguous de-terminer (e.g.
table in the table).
This ambiguitycan reliably be resolved with a simple and obviousgrammar rule that disallows verbs after determin-ers.Indeed, few contest he fact that reliable linguis-tic rules can be written for resolving some part-of-speech ambiguities.
The main problem withthis approach seems to be that resolving part-of-speech ambiguities on a large scale, without intro-ducing a considerable rror margin, is very diffi-cult at best.
At least, no rule-based system witha convincing accuracy has been reported so far.
1As a rule, data-driven systems rely on statisti-cal generalisations about short sequences of wordsor tags.
Though these systems do not usuallyemploy information about long-distance phenom-1There is one potential exception: the rule-basedmorphological disambiguator used in the EnglishConstraint Grammar Parser ENGCG (Voutilainen,Heikkil?
and Anttila 1992).
Its recall is very high(99.7% of all words receive the correct morphologi-cal analysis), but this system leaves 3-7% of all wordsambiguous, trading precision for recall.157ena or the linguist's abstraction capabilities (e.g.knowledge about what is relevant in the context),they tend to reach a 95-97% accuracy in the anal-ysis of several anguages, in particular English(Marshall 1983; Black et aL 1992; Church 1988;Cutting et al 1992; de Marcken 1990; DeRose1988; Hindle 1989; Merialdo 1994; Weischedel etal.
1993; Brill 1992; Samuelsson 1994; Eineborgand Gamb~ick 1994, etc.).
Interestingly, no sig-nificant improvement beyond the 97% "barrier"by means of purely data-driven systems has beenreported so far.In terms of the accuracy of known systems,the data-driven approach seems then to pro-vide the best model of part-of-speech distribu-tion.
This should appear a little curious becausevery competitive results have been achieved us-ing the linguistic approach at related levels of de-scription.
With respect o computational mor-phology, witness for instance the success of theTwo-Level paradigm introduced by Koskenniemi(1983): extensive morphological descriptions havebeen made of more than 15 typologically dif-ferent languages (Kimmo Koskenniemi, personalcommunication).
With regard t.o computationalsyntax, see for instance (GiingSrdii and Oflazer1994; Hindle 1983; Jensen, Heidorn and Richard-son (eds.)
1993; McCord 1990; Sleator and Tem-perley 1991; Alshawi (ed.)
1992; Strzalkowski1992).
The present success of the statistical ap-proach in part-of-speech analysis eems then toform an exception to the general feasibility of therule-based linguistic approach.
Is the level of partsof speech somehow different, perhaps less rule-governed, than related levels?
2We do not need to assume this idiosyncratic sta-tus entirely.
The rest of this paper argues that alsoparts of speech can be viewed as a rule-governedphenomenon, possible to model using the linguis-tic approach.
However, it will also be argued thatthough the distribution of parts of speech can tosome extent be described with rules specific to thislevel of representation, a more natural accountcould be given using rules overtly about the formand function of essentially syntactic ategories.
Asyntactic grammar appears to predict the distri-bution of parts of speech as a "side effect".
In thissense parts of speech seem to differ from morphol-ogy and syntax: their status as an independentlevel of linguistic description appears doubtful.Before proceeding further with the main argu-ment, consider three very recent hybrids - sys-tems that employ linguistic rules for resolvingsome of the ambiguities before using automati-cally generated corpus-based information: collo-cation matrices (Leech, Garside and Bryant 1994),Hidden Markov Models (Tapanainen and Voutilai-nen 1994), or syntactic patterns (Tapanainen and2For related discussion, cf.
Sampson (1987) andChurch (1992).J~irvinen 1994).
What is interesting in these hy-brids is that they, unlike purely data-driven tag-gers, seem capable of exceeding the 97% barrier:all three report an accuracy of about 98.5%.
3 Thesuccess of these hybrids could be regarded as evi-dence for the syntactic aspects of parts of speech.However, the above hybrids till contain a data-driven component, i.e.
it remains an open questionwhether a tagger entirely based on the linguisticapproach can compare with a data-driven system.Next, a new system with the following propertiesis outlined and evaluated:?
The tagger uses only linguistic distributionalrules.?
Tested agMnst a 38,000-word corpus of previ-ously unseen text, the tagger eaches abetteraccuracy than previous ystems (over 99%).?
At the level of linguistic abstraction, thegrammar rules are essentially syntactic.
Ide-ally, part-of-speech disambiguation shouldfall out as a "side effect" of syntactic anal-ysis.Section 2 outlines a rule-based system consist-ing of the ENGCG tagger followed by a finite-state syntactic parser (Voutilainen and Tapanai-nen 1993; Voutilainen 1994) that resolves remain-ing part-of-speech ambiguities as a side effect.In Section 3, this rule-based system is testedagainst a 38,000-word corpus of previously unseentext.
Currently tagger evaluation is only becom-ing standardised; the evaluation method is accord-ingly reported in detail.2 System descriptionThe tagger consists of the following sequentialcomponents:?
Tokeniser?
ENGCG morphological nalyser- Lexicon- Morphological heuristics?
ENGCG morphological disambiguator?
Lookup of alternative syntactic tags?
Finite state syntactic disambiguator2.1 Morphological analysisThe tokeniser is a rule-based system for identify-ing words, punctuation marks, document markers,and fixed syntagms (multiword prepositions, cer-tain compounds etc.
).The morphological description consists of tworule components: (i) the lexicon and (ii) heuristicrules for analysing unrecognised words.The English Koskenniemi-style lexicon containsover 80,000 lexical entries, each of which repre-sents all inflected and some derived surface forms.3However ,  CLAWS4 (Leech, Gazside and Bryant1994) leaves ome ambiguities unresolved; i t  uses  por t -manteau  tags for representing them.158The lexicon employs 139 tags mainly for part ofspeech, inflection and derivation; for instance:"<,hat>"" that"  <**CLB> CS"that" DET CENTRAL DEM SG"that" ADV"that" PRON DEM SG"that" <Rel> PRON SG/PLThe morphological analyser produces about180 different tag combinations.
To contrastthe ENGCG morphological description withthe well-known Brown Corpus tags: ENGCGis more distinctive in that a part-of-speechdistinction is spelled out in the descriptionof (i) determiner-pronoun, (ii) preposition-conjunction, (iii) determiner-adverb-pronoun,and (iv) subjunctive-imperative-infinitive-pres-ent tense homographs.
On the other hand,ENGCG does not spell out part-of-speech ambi-guity in the description of (i) -ing and nonfinite-ed forms, (ii) noun-adjective homographs withsimilar core meanings, or (iii) abbreviation-propernoun-common noun homographs.
"Morphological heuristics" is a rule-based mod-ule for the analysis of those 1-5% of input words.not represented in the lexicon.
This module em-ploys ordered hand-grafted rules that base theiranalyses on word shape.
If none of the patternrules apply, a nominal reading is assigned as a de-fault.2.2 ENGCG d isambiguatorA Constraint Grammar can be viewed as acollection 4 of pattern-action rules, no more thanone for each ambiguity-forming tag.
Each rulespecifies one or more context patterns, or "con-straints", where the tag is illegitimate.
If any ofthese context patterns are satisfied uring disam-biguation, the tag is deleted; otherwise it is left in-tact.
The context patterns can be local or global,and they can refer to ambiguous or unambiguousanalyses.
During disambiguatiop, the context canbecome less ambiguous.
To help a pattern definingan unambiguous context match, several passes aremade over the sentence during disambiguation.The current English grammar contains 1,185linguistic constraints on the linear order of mor-phological tags.
Of these, 844 specify a contextthat extends beyond the neighboring word; in thislimited sense, 71% of the constraints are global.Interestingly, the constraints are partial and of-ten negative paraphrases of 23 general, essentiallysyntactic generalisations about the form of thenoun phrase, the prepositional phrase, the finiteverb chain etc.
(Voutilainen 1994).4Actually, it is possible to define additional heuris-tic rule collections that can optionally be applied af-ter the more reliable ones for resolving remahdngambiguities.The grammar avoids risky'predictions, therefore3-7% of all words remain ambiguous (an average1.04-1.08 alternative analyses per output word).On the other hand, at least 99.7% of all wordsretain the correct morphological nalysis.
Note inpassing that the ratio 1.04-1.08/99.7% comparesvery favourably with other systems; c.f.
3.0/99.3%by POST (Weischedel et al 1993) and 1.04/97.6%or 1.09/98.6% by de Marcken (1990).There is an additional collection of 200 option-ally applicable heuristic onstraints that are basedon simplified linguistic generalisations.
They re-solve about half of the remaining ambiguities, in-creasing the overall error rate to about 0.5%.Most of even the remaining ambiguities arestructurally resolvable.
ENGCG leaves thempending mainly because it is prohibitively diffi-cult to express certain kinds of structural gener-alisation using the available rule formalism andgrammatical representation.2.3 Syntact ic  analysis2.3.1 F in i te -S ta te  In tersect ion  GrammarSyntactic analysis is carried out in another e-ductionistic parsing framework nown as Finite-State Intersection Grammar (Koskenniemi 1990;Koskenniemi, Tapanainen and Voutilainen 1992;Tapanainen 1992; Voutilainen and Tapanainen1993; Voutilainen 1994).
A short introduction:?
Also here syntactic analysis means resolu-tion of structural ambiguities.
Morphologi-cal, syntactic and clause boundary descrip-tors are introduced as ambiguities with sim-ple mappings; these ambiguities are then re-solved in parallel.?
The formalism does not distinguish betweenvarious types of ambiguity; nor are ambiguityclass specific rule sets needed.
A single ruleoften resolves all types of ambiguity, thoughsuperficially it may look e.g.
like a rule aboutsyntactic functions.?
The grammarian can define constants andpredicates using regular expressions.
For in-stance, the constants "."
and ".." accept anyfeatures within a morphological reading anda finite clause (that may even contain centre-embedded clauses), respectively.
Constantsand predicates can be used in rules, e.g.
im-plication rules that are of the formX =>LC1 _ RC1,LC2 _ RC2,, , ,LCn _ RCn;Here X, LC1, RC1, LC2 etc.
are regular ex-pressions.
The rule reads: "X is legitimateonly i f  it occurs in context LC1 _ RC1 or incontext LC2 _ RC2 ... or in context LCn _RCn".159?
Also the ambiguous sentences are representedas regular expressions.?
Before parsing, rules and sentences are com-piled into deterministic finite-state automata.?
Parsing means intersecting the (ambiguous)sentence automaton with each rule automa-ton.
Those sentence readings accepted by allrule automata re proposed as parses.?
In addition, heuristic rules can be used forranking alternative analyses accepted by thestrict rules.2.3.2 Grammat ica l  representat ionThe grammatical representation used in theFinite State framework is an extension of theENGCG syntax.
Surface-syntactic grammaticalrelations are encoded with dependency-orientedfunctional tags.
Functional representation ofphrases and clauses has been introduced to fa-cilitate expressing syntactic generMisations.
Therepresentation is introduced in (Voutilainen andTapanainen 1993; Voutilainen 1994); here, onlythe main characteristics are given:?
Each word boundary is explicitly representedas one of five alternatives:- the sentence boundary "@@"- the boundary separating juxtaposed fi-nite clauses "@/"-centre-embedded (sequences of) finiteclauses are flanked with "@<" and "@>"- the plain word boundary "@"?
Each word is furnished with a tag indicating asurface-syntactic function (subject, premodi-tier, auxiliary, main verb, adverbial, etc.).
Allmain verbs are furnished with two syntactictags, one indicating its main verb status, theother indicating the function of the clause.?
An explicit difference is made between finiteand nonfinite clauses.
Members in nonfiniteclauses are indicated with lower case tags; therest with upper case.?
In addition to syntactic tags, also morpholog-ical, e.g.
part-of-speech tags are provided foreach word.
Let us illustrate with a simplifiedexample.
@@Mary N @SUB3 @told V @MV MC@ @the DET @>N @fat  A @>N @butcher 's  N @>N @~ife N @IOBJ @and CC @CC @daughters N @IOBJ @/that CS @CS @she PKON @SUBJ @remembers V @MV 0BJ@ @seeing V @my OBJ@ @a DET @>N @dream N @obj  @last  DET  @>N @night N @ADVL @@ful lstop @@Here Mary is a subject in a finite clause(hence the upper case); told is a main verb ina main clause; ghe, fag and bugcher's are pre-modifiers; wife and daughgers are indirect ob-jects; that is a subordinating conjunction; re-members i a main verb in a finite clause thatserves the Object role in a finite clause (theregent being gold); seeing is a main verb in anonfinite clause (hence the lower case) thatalso serves the Object role in a finite clause;dream is an object in a nonfinite clause; nightis an adverbial.
Because only boundaries sep-arating finite clauses are indicated, there isonly one sentence-internal clause boundary,"@/" between daughters and that.This kind of representation seeks to be (i) suf-ficiently expressive for stating grammatical gener-Misations in an economical and transparent fash-ion and (ii) sufficiently underspecific to make fora structurally resolvable grammatical representa-tion.
For example, the present way of functionallyaccounting for clauses enables the grammarian to.
express rules about the coordination of formallydifferent but functionally similar entities.
Regard-ing the resolvability requirement, certain kinds ofstructurMly unresolvable distinctions are never in-troduced.
For instance, the premodifier tag @>Nonly indicates that its head is a nominal in theright hand context.2.3.3 - A sample  ru leHere is a realistic implication rule that partiallydefines the form of prepositional phrases:PREP =>- .
@ Coord ,_ .
.PrepComp,PassVChain..  <Deferred> .
_,PostModiCl .
.
<Deferred> .
_,WH-Question..  <Deferred> .
_ ;A preposition is followed by a coordination or apreposition complement (here hidden in the con-stant ..PrepComp that accepts e.g.
noun phrases,nonfinite clauses and nominal clauses), or it (asa 'deferred' preposition) is preceded by a pas-sive verb chain Pass VChain.. or a postmodifyingclause PostModiCl.. (the main verb in a postmod-ifying clause is furnished with the postmodifiertag N< @) or of a WH-question (i.e.
in the sameclause, there is a WH-word).
If the tag PREP oc-curs in none of the specified contexts, the sentencereading containing it is discarded.A comprehensive parsing grammar is under de-velopment.
Currently it accounts for all majorsyntactic structures of English, but in a somewhatunderspecific fashion.
Though the accuracy of the160grammar at the level of syntactic analysis can stillbe considerably improved, the syntactic grammaris already capable of resolving morphological m-biguities left pending by ENGCG.3 An experiment withpart-of-speech disambiguationThe system was tested against a 38,202-word testcorpus consisting of previously unseen journalis-tic, scientific and manual texts.The finite-state parser, the last module in thesystem, can in principle be "forced" to producean unambiguous analysis for each input sentence,even for ungrammatical ones.
In practice, thepresent implementation sometimes fails to give ananalysis to heavily ambiguous inputs, regardlessof their grammaticality.
5 Therefore two kinds ofoutput were accepted for the evaluation: (i) theunambiguous analyses actually proposed by thefinite-state parser, and (ii) the ENGCG analysisof those sentences for which the finite-state parsergave no analyses.
From this nearly unambiguouscombined output, the success of the hybrid wasmeasured, by automatically comparing it with abenchmark version of the test corpus at the level.of morphological (including part-of-speech) anal-ysis (i.e.
the syntax tags were ignored).3.1 Creat ion  of  benchmark  corpusThe benchmark corpus was created by first apply-ing the preprocessor and morphological nalyserto the test text.
This morphologically analysedambiguous text was then independently disam-biguated by two experts whose task also was to de-tect any errors potentially produced by the previ-ously applied components.
They worked indepen-dently, consulting written documentation of thegrammatical representation when necessary.
Thenthese manually disambiguated versions were au-tomatically compared.
At this stage, slightly over99% of all analyses were identical.
When the dif-ferences were collectively examined, it was agreedthat virtually all were due to inattention.
6 Oneof these two corpus versions was modified to rep-resent the consensus, and this 'consensus corpus'was used as the benchmark in the evaluation.
73.2  Resu l tsThe results are given in Figure 1 (next page).Let us examine the results.
ENGCG accuracywas close to normal, except hat the heuristic on-5During the intersection, the sentence automatonsometimes becomes prohibitively large.6Only in the analysis of a few headings, different(meaning-level) interpretations arose, and even hereit was agreed by both judges that this ambiguity wasgenuine.7If this high consensus level appears urprising, seeVoutilainen and J?rvinen (this volume).stralnts (tagger D2) performed somewhat poorerthan usual.The finite-state parser gave an analysis to about80% of all words.
Overall, 0.6% of all words re-mained ambiguous (due to the failure of the FiniteState parser; c.f.
Section 3).
Parsing speed variedgreatly (0.1-150 words/see.)
-ref inement of theFinite State software is still underway.The overall success of the system is very encour-aging - 99.26% of all words retained the correctmorphological nalysis.
Compared to the 95-97%accuracy of the best competing probabilistic part-of-speech taggers, this accuracy, achieved with anentirely rule-based escription, suggests that part-of-speech disambiguation is a syntactic problem.The misanalyses have not been studied in detail,but some general observations can be made:?
Many misanalyses made by the Finite Stateparser were due to ENGCG misanalyses (the"domino effect").?
The choice between adverbs and other cate-gories was sometimes difficult.
The distribu-tions of adverbs and certain other categoriesoverlaps; this may explain this error type.Lexeme-oriented constraints could be formu-lated for some of these cases.
* Some ambiguities, e.g.
noun-verb andparticiple-past tense, were problematic.
Thisis probably due to the fact that while theparsing grammar always requires a regent fora dependent, it is much more permissive ondependentless regents.
Clause boundaries,and hence the internal structure of clauses,could probably be determined more accu-rately if the heuristic part of the grammaralso contained rules for preferring e.g.
verbswith typical complements over verbs withoutcomplements.4 ConclusionPart-of-speech disambiguation has recently beentackled best with data-driven techniques.
Lin-guistic techniques have done well at related lev-els (morphology, syntax) but not here.
Is theresomething in parts of speech that makes them lessaccessible to the rule-based linguistic approach?This paper outlines and evaluates a new part-of-speech tagger.
It uses only linguistic distribu-tional rules, yet reaches an accuracy clearly betterthan any competing system.
This suggests thatalso parts of speech are a rule-governed distribu-tional phenomenon.The tagger has two rule components.
One isa grammar specifically developed for resolutionof part-of-speech ambiguities.
Though much ef-fort was given to its development, i  leaves manyambiguities unresolved.
These rules, superficiallyabout parts of speech, actually express essentiallysyntactic generalisations, though indirectly and161II ambiguous words readingsDo (Morph.
analysis)D1 (DO + ENGCG)D2 (D1 + ENGCG heur.
).D3 (D2 + FS parser)39.0%6.2%3.2%0.6%67,73740,45038,94938,342I readings/w?rd I errors \] error rate1.77 31 0.08%1.06 124 0.32%1.02 226 0.59%1.00 281 0.74%Figure 1: Results from a tagging test on a 38,202-word corpus.partially.
The other rule component is a syntacticgrammar.
This syntactic grammar is able to re-solve the pending part-of-speech ambiguities as aside effect.In short: like morphology and syntax, parts ofspeech seem to be a rule-governed phenomenon.However, the best distributional ccount of partsof speech appears achievable by means of a syn-tactic grammar, sAcknowledgementsI would like to thank Timo J?rvinen, Jussi Piitu-lainen, Past Tapanainen and two EACL refereesfor useful comments on an earlier version of thispaper.
The usual disclaimers hold.ReferencesHiyan Alshawi (ed.)
1992.
The Core LanguageEngine.
Cambridge, Mass.
: The MIT Press.Ezra Black, Fred Jelinek, John Lafferty, RobertMercer and Salim Roukos 1992.
Decision-treemodels applied to the labeling of text with parts-of-speech.
Proceedings of the Workshop on Speechand natural Language.
Defence Advanced Re-search Projects Agency, U.S. Govt.Eric Brill 1992.
A simple rule-based part ofspeech tagger.
Proceedings of the Third Con-ference on Applied Natural Language Processing,ACL.Kenneth Church 1988.
A Stochastic Parts Pro-gram and Noun Phrase Parser for UnrestrictedText.
Proceedings of the Second Conference onApplied Natural Language Processing, ACL.- -  1992.
Current Practice in Part of SpeechTagging and Suggestions for the Future.
In Sim-mons (ed.
), Sbornik praci: In Honor of HenryKuSera.
Michigan Slavic Studies.Douglass Cutting 1994.
Porting a stochasticpart-of-speech tagger to Swedish.
In Eklund (ed.
).65-70.Douglass Cutting, Julian Kupiec, Jan Pedersenand Penelope Sibun 1992.
A Practical Part-of-Speech Tagger.
Proceedings of ANLP-92.SHowever, the parsing description would also ben-efit from a large corpus-based lexicon extension ofcompound nouns and other useful collocations for re-solving some ven syntactically genuine part-of-speechambiguities.
Collocations can be extracted from cor-pora using ENGCG-style corpus tools, e.g.
NPtool(Voutilainen 1993).Stephen DeRose 1988.
Grammatical categorydisambiguation by statistical optimization.
Com-putational Linguistics.Robert Eklund (ed.)
Proceedings of '9:eNordiska Datalingvistikdagarna', Stockholm 3-5June 1993.
Department of Linguistics, Computa-tional Linguistics, Stockholm University.
Stock-holm.Martin Eineborg and BjSrn Gamb~ck 1994.Tagging experiment using neural networks.
In Ek-lund (ed.).
71-81.David Elworthy 1994.
Does Baum-Welch re-estimation help taggers?
In Proceedings of the 4thConference on Applied Natural Language Process-ing, A CL.
Stuttgart.Elizabeth Eyes and Geoffrey Leech 1993.
Syn-tactic Annotation: Linguistic Aspects of Gram-matical Tagging and Skeleton Parsing.
In Black?
el al.
(eds.
), Statistically-Driven Computer Gram-mars of English: The IBM/Lancaster Approach.Amsterdam: Rodopi.Roger Garside 1987.
The CLAWS word-taggingsystem.
In Garside, Leech and Sampson (eds.
),The Computational Analysis of English.
Londonand New York: Longman.Zelal GiingSrdii and Kemal Oflazer 1994.
Pars-ing Turkish text: the lexical functional grammarapproach.
Proceedings of ACL-9~.Donald Hindle 1983.
"User manual for Fid-ditch".
Technical memorandum 7590-142, NavalResearch Lab.
USA.- -  1989.
Acquiring disambiguation rules fromtext.
Proceedings of ACL-89.Karen Jensen, George Heidorn and StephenRichardson (eds.)
1993.
Natural language pro-cessing: the PLNLP approach.
Kluver AcademicPublishers: Boston.Fred Karlsson, Atro Voutilainen, Juha Heikkil~and Arto Anttila (eds.)
1995.
Constraint Gram-mar.
A Language-Independent System for Pars-ing Unrestricted Text.
Berlin and New York:Mouton de Gruyter.Kimmo Koskenniemi 1983.
Two-level Morphol-ogy.
A General Computational Model for Word-form Production and Generation.
Publications11, Department ofGeneral Linguistics, Universityof Helsinki.- -  1990.
Finite-state parsing and disambigua-tion.
Proceedings of the fourteenth Interna-tional Conference on Computational Linguistics.COLING-90.
Helsinki, Finland.162Kimmo Koskenniemi, Pasi Tapanainen andAtro Voutilainen 1992.
Compiling and usingfinite-state syntactic rules.
In Proceedings of thefifteenth International Conference on Computa-tional Linguistics.
COLING-92.
Vol.
I, pp 156-162, Nantes, France.Geoffrey Leech, Roger Garside and MichaelBryant 1994.
CLAWS4: The tagging of theBritish National Corpus.
In Proceedings ofCOLING-94.
Kyoto, Japan.Carl de Marcken 1990.
Parsing the LOB Cor-pus.
Proceedings of the 28th Annual Meeting ofthe A CL.Mitchell Marcus, Beatrice Santorini and MaryAnn Marcinkiewicz 1993.
Building a Large An-notated Corpus of English: The Penn Treebank.Computational Linguistics, Vol.
19, Number 2.313-330.Ian Marshall 1983.
Choice of grammaticalword-class without global syntactic analysis: tag-ging words in the LOB Corpus.
Computers in theHumanities.Michael McCord 1990.
A System for Sim-pler Construction of Practical Natural LanguageGrammars.
In R. Studer (ed.
), Natural Languageand Logic.
Lecture Notes in Artificial Intelligence"459.
Berlin: Springer Verlag.Bernard Merialdo 1994.
Tagging English textwith a probabilistic model.
Computational Lin-guistics, Vol.
20.Geoffrey Sampson 1987.
Probabilistic Mod-els of Analysis.
In Garside, Leech and Sampson(eds.
).Christer Samuelsson 1994.
Morphological tag-ging based entirely on Bayesian inference.
In Ek-lund (ed.).
225-237.Helmut Schmid 1994.
Part-of-speech taggingwith neural networks.
In Proceedings of COLING-95.
Kyoto, Japan.Daniel Sleator and Davy Temperley 1991.
"Parsing English with a Link Grammar".
CMU-CS-91-196.
School of Computer Science, CarnegieMellon University, Pittsburgh, PA 15213.Tomek Strzalkowski 1992.
TTP:  a fast and ro-bust parser for natural language.
Proceedings ofthe fifteenth International Conference on Com-putational Linguistics.
COLING-92.
Nantes,France.Pasi Tapanainen 1992.
"J{?rellisiin automaat-teihin perustuva luonnollisen kielen j~ennin" (Afinite state parser of natural anguage).
Licentiate(pre-doctoral) thesis.
Department of ComputerScience, University of Helsinki.Pasi Tapanainen and Timo Jgrvinen 1994.
Syn-tactic analysis of natural anguage using linguisticrules and corpus-based patterns.
Proceedings ofCOLING-95.
Kyoto, Japan.Pasi Tapanainen and Atro Voutilainen 1994.Tagging accurately - Don't guess if you know.Proceedings of the 5th Conference on Applied Nat-ural Language Processing, ACL.
Stuttgart.Atro Voutilainen 1993.
NPtool, a Detector ofEnglish Noun Phrases.
In Proceedings of theWorkshop on Very Large Corpora.
Ohio StateUniversity, Ohio.
42-51.- -  1994.
Three studies of grammar-based sur-face parsing of unrestricted English text.
(Doc-toral dissertation.).
Publications 24, Departmentof General Linguistics, University of Helsinki.Atro Voutilainen, Juha Heikkil?
and ArtoAnttila 1992.
Constraint Grammar of English.
APerformance-Oriented Introduction.
Publications21, Department of General Linguistics, Universityof Helsinki.Atro Voutilainen and Pasi Tapanainen 1993.Ambiguity Resolution in a Reductionistic Parser.Proceedings of the Sixth Conference of the Eu-ropean Chapter of the Association for Computa-tional Linguistics.
Association for ComputationalLinguistics.
Utrecht.
394-403.Ralph Weischedel, Marie Meteer, RichardSchwartz, Lance Ramshaw and Jeff Palmuzzi1993.
Coping with ambiguity and unknown wordsthrough probabilistic models.
Computational Lin-guistics, Vol.
19, Number 2.AppendixEnclosed is a sample output of the system.
Syntaxtags have been retained; base forms and some tagshave been removed for better readability.
Thesyntactic tags used here are the following:* ~>A premodifier of adjective, adverb or quan-tifier,* @>N noun premodi f ier ,?
@N< noun postmodifier,?
@ADVL adverbial,.
@ADVL/N< adverbial or noun postmodifier,?
~OBJ  object in a finite clause,?
@IOBJ indirect object in a finite clause,?
~SUBJ  subject in a finite clause,?
~ob j  object in a nonfinite clause,?
~P<< preposition complement,.
@nh nominal head,?
~CC coordinating conjunction,?
@CS subordinating conjunction,?
~MV main verb in a finite clause,?
~aux  auxiliary in a nonfinite clause,?
~mv main verb in a nonfinite clause,* ADVL~ adverbial clause,?
MC~ finite main clause,* OBJ(~ clause as an object in a finite clause.
@@ On PREP @ADVL @completion N NOM SG @P<< @163@commacheck V IMP @MV MC@ @the DET CENTRAL SG/PL @>N @engine N NOM SG @>N @oil N NOM SG @>N @level N NOM SG @OBJ @/@comma @start V IMP @MV MC@the DET CENTRAL SG/PL @>N @engine N NOM SG @OBJ @/then ADV ADVL ~ADVL @check V IMP @MV MC@ @for PREP @ADVL @oil N NOM SG ~>N @leaks N NOM PL @P<<@fullstop @@@@ Screw V IMP ~MV MC@ @a DET CENTRAL SG @>N @self-tapping PCP1 @>N @screw N NOM SG @OBJ @of PREP @N< @appropriate A ABS @>N @diameter N NOM SG ~P<< @into PREP ~ADVL/N< @this DET CENTRAL DEM SG ~>N @hole N NOM SG @P<< @/@commathen ADV ADVL ~ADVLlever V IMP @MV MC@ @against PREP @ADVL @the DET CENTRAL SG/PL @>N @screw N NOM SG @P<< @to INFMARK> @aux @extract V INF @mv ADVL@ @the DET CENTRAL SG/PL @>N @plug N NOM SG @obj @as CS @CSshown PCP2 @my ADVL@ @in PREP @ADVL @FIG ABBR NOM SG @>N @1.26 NUM CARD @P<< @~fullstop @~@@ This PRON DEM SG @nh @done PCP2 @N<@comma @push V IMP ~MV MC@ @the DET CENTRAL SG/PL @>N @crankshaft N NOM SG ~OBJ  @fully ADV ~>Arearwards ADV @ADVL @/~comma @then ADV ADVL ~ADVL @slowly ADV ~ADVL @but CC @CCpositively ADV @ADVLpush V IMP @MV MC~ @it PRON ACC SG3 @OBJ @forwards ADV ADVL ~ADVL @to PREP ~ADVL @its PRON GEN SG3 @>N @stop N NOM SG ~P<< @@fullstop ~@~ Lightly ADV @ADVL @moisten V IMP @MV MC~the DET CENTRAL SG/PL @>N @lips N NOM PL @OBJ @of PREP @N< @a DET CENTRAL SG @>Nnew A ABS @>N @rear N NOM SG @>N @oil N NOM SG @>N @seal N NOM SG @P<< @with PREP @ADVL/N< @engine N NOM SG @>N @oil N NOM SG @P<< @/@comma @then ADV ADVL @ADVL @drive V IMP @MV MC@ @it PRON ACC SG3 @OBJ @squarely ADV @ADVL @into PREP @ADVL @position N NOM SG ~P<< ~/until CS ~CS @it PRON NOM SG3 SUBJ @SUBJ @rests V PRES SG3 @MV ADVL@ @against PREP ~ADVL @its PRON GEN SG3 @>N @abutment N NOM SG @P<< @@commapreferably ADV @ADVL @using PCP1 @my ADVL@the DET CENTRAL SG/PL @>N @appropriate A ABS @>N @service N NOM SG @>N @tool N NOM SG @obj @for PREP @ADVL/N< @this DET CENTRAL DEM SG @>Noperation N NOM SG @P<< @@fullstop @@164
