Using MMIL for the High Level Semantic Annotation of theFrench MEDIA Dialogue Corpus.
?Lina Maria Rojas-BarahonaLORIA/INRIA, Francelina.rojas@loria.frThierry BazillonUniv.
Avignon, Francethierry.bazillon@univ-avignon.frMatthieu QuignardLORIA/INRIA, Francematthieu.quignard@loria.frFabrice LefevreUniv.
Avignon, Francefabrice.lefevre@univ-avignon.frAbstractThe MultiModal Interface Language formalism (MMIL) has been selected as the High LevelSemantic (HLS) formalism for annotating the French MEDIA dialogue corpus.
This corpus is com-posed of human-machine dialogues in the domain of hotel reservation and tourist information.
Utter-ances in dialogues have been previously annotated with a concept-value flat semantics for studyingand evaluating spoken language understanding modules in dialogue systems.
We are now interestedin investigating the use of more complex representations to improve the understanding capability.The MMIL intermediate language is a high level semantic formalism that bears relevant linguisticinformation, from syntax up to discourse.
This representation should increase the expressivity ofthe current annotation though at the expense of the annotation process complexity.
In this paper wepresent our first attempt in defining the annotation guidelines for the HLS annotation of the MEDIAcorpus and its effect on the annotation process itself, revealed by annotators?
disagreements due tothe different levels of hierarchy and the granularity of the features defined in MMIL.1 IntroductionMMIL is an ontology-oriented representation language that has been used in several natural languageprocessing (NLP) applications, Denis et al (2010).
It permits the integration of divergent resources indistributed systems as well as the representation of various levels of linguistic analysis.
In this work weare particularly interested in exploring the representation of these linguistic levels for analyzing utter-ances in the context of human-machine interactions.
To be able to evaluate the representation on a largeset of data the French MEDIA dialogue corpus is used, Bonneau-Maynard et al (2005).
The MEDIAcorpus collects about 70 hours of spontaneous speech in the task of hotel room reservation and touristinformation.
It has been created using a Wizard-of-Oz technique, as a consequence, the utterances aremade of many disfluencies, hesitations, false starts, truncations or fillers words (e.g., euh or ben).
Thus,the syntactic analysis is relevant for keeping valuable information for further processing (e.g., referenceresolution).
The semantics describe fine grained predicates, arguments and features based on the domainknowledge.
Similarly, the possibility of link references for pragmatic analysis and the representation ofthe illocutionary force of utterances are relevant to improve the understanding in NLP applications.
Weselected MMIL for the semantic annotation because it supports the representation of all these features.Although these features enrich the semantic annotation of utterances in the corpus, they also increasethe complexity of the annotation and compromise the agreement between annotators.
The possibilityof representing different instantiations in MMIL has been the main cause of disagreement between an-notators.
On the one hand, linguists tend to annotate the surface form of the utterance.
On the other?This work is supported by the French Agence Nationale de la Recherche (ANR) and is part of the Project PORT-MEDIA(www.port-media.org).375hand, application designers are more biased towards its canonical representation by keeping relevanttask oriented actions and features.
The trade-off between these two lines of representation is significantfor building appropriately the annotation guidelines for the semantic annotation.
The annotation wouldkeep the most valuable information in a multilevel representation for enhancing the understanding ca-pability of NLP applications.
In this paper we introduce briefly MMIL and we describe the annotationmethodology and the inter-annotation agreement.2 The High Level RepresentationMMIL permits the representation of communicative actions that are represented as components.
A com-ponent is a structure that gathers the communicative event and its propositional content.
Componentsare made up of two main types of entities: events, which are entities anchored in the time dimension,and participants, which are entities not bounded by time.
Entities are linked together by relations andare described by sets of features (i.e.
pairs of attribute-value), Denis et al (2010).
Every componenthas a unique communicative event with the illocutionary force represented by means of the dialogueActfeature.
The propositional content is represented as a main event with its arguments, which can be eitherevents or participants, linked to the communicative event by a relation propContent.
In this represen-tation, predicates are usually represented as events and predicate arguments are usually represented asparticipants.
Relations between participants and events usually describe the thematic roles.French: "/1euh vous venez de dire que pre?ce?demment qu?
il n?
a y avait plus de chambres disponibles a` ces dates et maintenantvous en avez/2 donc je voulais juste m?
assurer qu?
au Novotel vous avez bien une chambre double euh pour un couple avec unenfant avec une baignoire dans la chambre euh il me il me faut un Parc ?a?
proximite?
et euh cent dix euros maximum la nuitest-ce-que vous pouvez ve?rifier"English:"/1um you just said earlier that there are not more rooms available on these dates and now there are/2 so I justwanted to be sure that you have at the Novotel a double room for uh a couple with one child with a bath in the room uh Ineed a park nearby and uh hundred and ten euros up at night is that you can check"Figure 1: Example of a complex utterance of the MEDIA Corpus.SpeakInformComprendre(Understand)negativeCoordinationadversativeStateStatenegativePe?riodeDeTemps(Time)demonstrat.Chambre(Room)disponiblepropContentpatientmembermemberpatientaPe?riodeRe?servationSpeakRequestAckStateChambre(Room)indefiniteHotelCouplelocation.Relativeproche(near)parc(park)Enfant(Child)Prix(Price)inferieur(lower)110eurospropContentpatientaBe?ne?ficiairesattributeaLocalisationaPrixFigure 2: HLS as an abstraction of the meaning of the French utterance shown in Figure 1.
Left: this component expresses the informof a misunderstanding of the first segment (?/1" in Figure 1).
Right: this component is a request acknowledgment, representing the secondsegment(?/2" in Figure 1).
Note that events are exemplify by square boxes while participants are exemplify by ellipses.376Let us focus on the MMIL representation for a typical utterance of the MEDIA corpus, given inFigure 1.
In this utterance the user first announces an inconsistency, then asks for clarification.
Thus,two MMIL components with different communicative actions, inform and request acknowledgment, havebeen used, as shown in Figure 2.
The component on the left has a main event that describes the misun-derstanding expressed in the first segment1 of the utterance.
It is represented by the ontological concept?Understand" and by the syntactic feature polarity with the negative value.
It also contains a coordinatedentity mirroring an adversative coordination between two events, state.
The event state represents thestatus of something, therefore the negated state event can be understood as ?there are not more roomsavailable on these dates" while the positive state represents ?now there are".
The participants symbolizethe arguments ?rooms" and ?dates" respectively.
The component on the right expresses the clarificationrequest of the second segment.
It verifies the status of the hotel with the specific constraints.3 The Annotation MethodologyIn the process of defining the annotation guidelines, we elaborated a specification document that de-scribes the representation of dialogue acts, events and exemplifies the high-level semantics.
Moreover, itdelves into the methodology that might be applied for the automatic and manual annotation.
Afterwards,a linguist expert and a project designer were in charge of defining the annotation guidelines.
For thispurpose, they annotated manually a subset of utterances which were supposed to be representative ofthe most complex aspects of the HLS annotation, in terms of their semantic constituents.
330 utteranceswere selected.
They are all directly related to the reservation task (first two rows in Figure 4) and mostlyoccurred in the first 3 turns of the dialogues when the user is describing his goal, defined as an overallobjective along with a set of constraints.
Hereafter, we present the preliminary evaluation of the experts?agreement on these utterances.The annotation process has been supported by an annotation tool: ATool.
It accesses two knowledge-bases, one for the MMIL formalism and the other for the MEDIA domain.
The latter is adapted fromthe MEDIA evaluation campaign, Bonneau-Maynard et al (2006).
ATool permits annotators to navi-gate through utterances, while displaying the MMIL representation.
Annotators can design the MMILcomponents graphs, define the MMIL entities by associating features, values and segment.
ATool willsuggest the possible features and values for the MMIL formalism and for the domain according to theknowledge-bases ensuring the integrity of the constructed MMIL components in the annotation.The MEDIA corpus is rich in expressions that evoke several communicative actions.
Figure 4 showsa few examples.
For the purpose of the task, we are interested in the underlying meaning of sentences,thus politeness and indirectness are discarded from the HLS representation.
For this reason, in requeststhe speaker is the patient, while the hearer is the agent (see Figure 4).
Because when translating theutterance into its deep instantiation, the speaker will benefit from the execution of the action, while thehearer has the obligation to perform the action.
All the expressions in the corpus that bear the seman-tics of ?command for a reservation" (e.g., je veux re?server, je souhaite re?server, je voudrais faire unere?servation, j?aimerais faire une re?servation, all equivalent to I would like to reserve), have been normal-ized with the deep component shown in Figure 3, exemplifying unequivocally the user?s desire to requestfor a reservation.
The possible arguments and roles have been detailed in the domain knowledge-base.As a consequence the knowledge-base defines relations between hotels, rooms, customers, prices, equip-ments, services, locations and dates.
Besides, the grammatical relations and features, such as coordina-tion, have been defined in the MMIL knowledge-base.
Coordination is indicated with the ?coordtype"feature and it is used in cases of conjunction (je veux une chambre simple et deux chambres double, Iwant a single room and two double bedrooms), disjunction (Paris ou en proche banlieue, in Paris orsuburbs) or adversation (en ville mais pas trop loin de la mer, in the city but not too far from the sea).For annotating events we can find the main verb in the utterance and represent it as the main eventin MMIL by following a domain-specific classification of verbs, from which Figure 4 shows someequivalences among dialogue acts and verbs.
For each participant or event, several features can be1Segments are sequence of words that are depicted as ?/i", where i is the number of the segment.377SpeakRequestReserverje arg0 argipropContentpatient[0]patient[1] patient[n]Figure 3: Canonical representation of a booking request inMEDIA.D.
Act EvType Examples Semantic RolesRequest Reserver re?server [la chambre] aObjetRe?serve?re?server [pour letroisie`meweek-end de novembreune nuit]aPe?riodeRe?servation[a?
Clermont-Ferrand] aLocalisation[pour quatre chambresdoubles]aObjetRe?serve?Inform Inform [j?]
ai des informationssupple?mentairesagentRequest Inform [j?]
aurais aim?l?
avoirexactement [les dates]patient[0],patient[1]Request State [Il] est [?a?
combien] patient, aPrixRequest Repeter pouvez-[vous] re?pe?ter agentInform Repeter [je] vais me re?pe?ter agentAccept ouiReject nonFigure 4: Some of the observed dialogue acts and mainevents with their arguments in the corpus.added.
The most important of them are ?object type" (for participants) or ?event type" (for events),which specify their ontological concepts.
They may be re?server (reserve), h?tel (hotel), chambre (room),pe?riodedetemps (time), ville (city), person, adulte (adult), enfant (child), localisationnomme?e (places),among others.
There are more specific features, for instance, the journey dates, hotel features (e.g.,name, standing, services, etc).
Some of these features have predefined values, such as the gender of anobject (either masculine or feminine).
On the other side, features such as cardinality, have not predefinedvalues, in that case, the annotator has to manually indicate the correct value.Obviously, the annotation task difficulty increases with the utterance?s complexity.
The representa-tion is rather tedious to define in elliptical utterances, such as multiple reservations, in which implicitand explicit information must be taken under consideration.
Furthermore, the MMIL formalism doesnot support the association of discontinuous segments to entities, generating some imprecisions in theHLS annotation.
For instance, in je voudrais une chambre pour deux personnes euh simple (I wouldlike a room for two people uh simple),?une chambre" (a room) and ?simple" should be linked to anunique participant, having as object type (?Room") and as type of room ?simple".
However, given thatthe speaker has not mentioned ?simple"right after ?chambre", there is a new element imbricated betweenthem: ?pour deux personnes".
As a result, the annotator must integrate the subsegment ?pour deux per-sonnes" in the ?Room" participant.
Even though this subsegment is also associated to the ?Personne"participant.4 ResultsWhen analyzing the sample of 330 utterances that were annotated, we found a perfect agreement be-tween annotators in the detection of dialogue-acts, main events, as well as main arguments.
In constrast,when measuring fine-grained features inside components we found eight types of disagreement, namelyconjunctions, disjunctions, creation of participant for simple features, groups of features inside entities,features of entities, values of features, relation names and relation among entities.
The most frequentcases concern the first two, which refer to coordination: conjunctions (20%) and disjunctions (5%).
Theinter-annotator agreement for the coordinate entities was computed, obtaining the kappa measure, Car-letta (1996), of 0.25 for conjunctions and 0.15 for disjunctions, meaning a fair and slight agreementrespectively.
Although the other cases were less frequent, the inter-annotator agreement was even lower,indicating no agreement.In spite of the disagreement, when measuring the global similarity between the MMIL componentscreated by both annotators we found a high score of 98%.
This metric measures the graph similarity378by computing the similarity between entities and relations, including the fine-grained features insideentities.
The speech-act, main-event and main arguments are in compliance with the specifications inboth annotations.Case Annotator 1 Annotator 2Conjunctions 68 56Disjunctions 18 10Part.
for simple feats.
11 0Grouping feats.
0 2Case DiscrepancyFeatures 4Features?
values 5Name of relations.
5Relation among entities.
2Figure 5: Left: the Table displays the number of utterances by annotator for the listed cases.
Annotator 1, is the liguist expert, Annotator 2is the project designer.
Right: fhe Table shows the number of utterances with a completely discrepant annotation: different features for sameentities, different values for same features, different relation between same entities and entities related differently in a component.These issues show that the disagreement cases were less frequent.
So far, annotators have not beingso rigourous when segmenting the text inside features.
Therefore, segmentation needs to be checked inboth annotations.
After this experiment, we are defining the final certified annotation and deriving theannotation guidelines formally.5 DiscussionDefining the annotation guidelines for high level semantic representation is controversial.
The multiplefeatures that can be represented in the selected MMIL formalism, as well as the multiple instantiationsoffer different possibilities for representing the same utterance.
In general representing spoken utterancesis cumbersome, because of the linguist phenomena present in spontaneous speech.
As a consequence,annotators have to deal not only with the explicit, but also with the implicit information, and in somecases the representations might be subjective.
For these reasons, we defined the standard for the annota-tion, and based on it, we carried out an annotation experiment on a sample of 330 complex utterances,directly related to the reservation task; involving two annotator profiles i.e., a linguist and a projectdesigner.
Afterwards, we measured the similarity between the annotated MMIL components and theinter-annotation agreement obtaining a 98% of similarity and only eight major cases of disagreement,coordination discrepancy being the most frequent.
Right now, we are refining the final annotation guide-lines based on these results.
This first experiment analyzes the most complex and numerous utterancesin the corpus covering reservation requests and affirmations.
Subsequently, misunderstanding, questionsand clarifications will be analyzed following the same methodology.
As a result, we will be able toreduce the disagreement between annotators in order to produce the annotation of the whole MEDIAcorpus, which will be made freely available to the research community.ReferencesBonneau-Maynard, H., C. Ayache, F. Bechet, A. Denis, A. Kuhn, F. Lefe`vre, D. Mostefa, M. Quignard, S. Ros-set, C. Servan, , and J. Villaneau (2006).
Results of the french evalda-media evaluation campaign for literalunderstanding.
In 5th International Conference on Language Resources and Evaluation (LREC2006).Bonneau-Maynard, H., S. Rosset, C. Ayache, A. Kuhn, and D. Mostefa (2005).
Semantic annotation of the frenchmedia dialog corpus.
In INTERSPEECH-2005, 3457-3460.Carletta, J.
(1996).
Assessing agreement on classification tasks: the kappa statistic.
Comput.
Linguist.
22(2),249?254.Denis, A., L. M. Rojas-Barahona, and M. Quignard.
(2010).
Extending MMIL semantic representation: Ex-periments in dialogue systems and semantic annotation of corpora.
In proceedings of the Fifth Joint ISO-ACL/SIGSEM Workshop on Interoperable Semantic Annotation (ISA-5), Hong Kong, January 2010.379
