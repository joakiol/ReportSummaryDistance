First Joint Conference on Lexical and Computational Semantics (*SEM), pages 519?523,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsNJU-Parser: Achievements on Semantic Dependency ParsingGuangchao Tang1 Bin Li1,2 Shuaishuai Xu1 Xinyu Dai1 Jiajun Chen11 State Key Lab for Novel Software Technology, Nanjing University2 Research Center of Language and Informatics, Nanjing Normal UniversityNanjing, Jiangsu, China{tanggc, lib, xuss, dxy, chenjj}@nlp.nju.edu.cnAbstractIn this paper, we introduce our work onSemEval-2012 task 5: Chinese Semantic De-pendency Parsing.
Our system is based onMSTParser and two effective methods areproposed: splitting sentence by punctuationsand extracting last character of word as lemma.The experiments show that, with a combina-tion of the two proposed methods, our systemcan improve LAS about one percent and final-ly get the second prize out of nine participat-ing systems.
We also try to handle the multi-level labels, but with no improvement.1 IntroductionTask 5 of SemEval-2012 tries to find approaches toimprove Chinese sematic dependency parsing(SDP).
SDP is a kind of dependency parsing.
Cur-rently, there are many dependency parsers availa-ble, such as Eisner?s probabilistic dependencyparser (Eisner, 1996), McDonald?s MSTParser(McDonald et al 2005a; McDonald et al 2005b)and Nivre?s MaltParser (Nivre, 2006).Despite of elaborate models, lots of problemsstill exist in dependency parsing.
For example, sen-tence length has been proved to show great impacton the parsing performance.
(Li et al, 2010) used atwo-stage approach based on sentence fragment forhigh-order graph-based dependency parsing.
Lack-ing of linguistic knowledge is also blamed.Three methods are promoted in this paper try-ing to improve the performance: splitting sentenceby commas and semicolons, extracting last charac-ter of word as lemma and handling multi-level la-bels.
Improvements could be achieved through thefirst two methods while not for the third.2 Overview of Our SystemOur system is based on MSTParser which is one ofthe state-of-the-art parsers.
MSTParser tries to ob-tain the maximum spanning tree of a sentence.
Forprojective parsing task, it takes Eisner?s algorithm(Eisner, 1996) to get the dependency tree in O(n3)time.
Meanwhile, Chu-Liu-Edmond?s algorithm(Chu and Liu, 1965) is applied for non-projectivetask, which takes O(n2) time.Three methods are adopted to MSTParser in oursystem:1) Sentences are split into sub-sentences bycommas and semicolons, for which thereare two ways.
Splitting sentences by allcommas and semicolons is used in ourprimary system.
In our contrast system, weuse a classifier to determine whether acomma or semicolon can be used to splitthe sentence.
In the primary and contrastsystem, the proto sentences and the sub-sentences are trained and tested separatelyand the outputs are merged in the end.2) In a Chinese word, the last character usual-ly contains main sense or semantic class.We treat the last character of the word asword lemma and find it gets a slightly im-provement in the experiment.3) An experiment trying to solve the problemof multi-level labels was conducted byparsing different levels separately and con-sequently merging the outputs together.The experiment results have shown that the firsttwo methods could enhance the system perfor-mance while further improvements could be ob-tained through a combination of them in our sub-submitted systems.519a) The proto sentence from train datab) The first sub sentence of a)                         c) The second sub sentence of a)Figure 1.
An example of the split procedure.3 Experiments3.1 Split sentences by commas and semicolonsIt is observed that the performance decreases asthe length of the sentences increases.
Table 1shows the statistical analysis on the data includingSemEval-2012, Conll-07?s Chinese corpus and asubset extracted from CTB using Penn2Malt.
Longsentence can be split into sub-sentences to get bet-ter parsing result.ItemsSemEval-2012Conll-07 CNCTBPostages count 35 13 33Dependencylabels count122 69 12Average sentencelength30.15 5.92 25.89Averagedependency length4.80 1.71 4.36LAS 61.37 82.89 67.35UAS 80.18 87.64 79.90Table 1.
Statistical analysis on the data.
The CTB data isa subset extracted from CTB using Penn2Malt.Our work can be described as following steps:Step 1: Use MSTParser to parse the data.
Wename the result as ?normal output?.Step 2: Split train and test data by all commasand semicolons.
The delimiters are removed in thesub sentences.
For train data, a word?s dependencyrelation is kept if the word?s head is under the cov-er of the sub sentence.
Otherwise, its head will beset to root and its label will be set to ROOT (ROOTis the default label of dependency arcs whose headis root).
We define the word as ?sentence head?
ifits head is root.
?Sub-sentence head?
indicates thesentence head of a sub-sentence.
After splitting,there may be more than one sub-sentence heads ina sub-sentence.
Figure 1 shows an example of thesplit procedure.Step 3: Use MSTParser to parse the data gener-ated in step 2.
We name the parsing result ?splitoutput?.
In split output, there may be more thanone sub-sentences corresponding to a single sen-tence in normal output.Step 4: Merge the split output and the normaloutput.
The outputs of sub-sentences are mergedwith delimiters restored.
Dependency relations arerecovered for all punctuations and sub-sentenceheads in split output with relations in normal out-put.
The sentence head of normal output is kept infinal output.
The result is called ?merged split out-put?.
This step need to be consummated because itmay result in a dependency tree not well formedwith several sentence heads or even circles.The results of experiments on develop data andtest data are showed in table 2.
For develop data,an improvement of 0.85 could be obtained while0.93 for test data, both on LAS.In step 2, there is an alternative to split the sen-tences, i.e., using a classifier to determine whichcomma and semicolon can be split.
This method istaken in the contrast system.
When applying theclassifier, all commas and semicolons in train data520are labeled with S-IN or S-STOP while otherwords with NULL.
If the sub sentence before thecomma or semicolon has only one sub-sentencehead, it is labeled with S-STOP, otherwise with S-IN.
A model is built from train data with CRF++and test data is evaluated with it.
Features used arelisted in table 3.
Only commas and semicolonswith label S-STOP can be used to split the sen-tence in step 2.
Other steps are the same as above.The result is also shown in table 2 as ?merged splitoutput with CRF++?.Data Methods LAS UASDevelopdatanormal output 61.37 80.18merged split output 62.22 80.56merged split outputwith CRF++61.97 80.73lemma output 61.64 80.47primary system output 62.41 80.96contrast system output 62.05 80.90Testdatanormal output 60.63 79.37merged split output 61.56 80.17merged split outputwith CRF++61.42 80.20lemma output 60.88 79.42primary system output 61.63 80.35contrast system output 61.64 80.29Table 2.
Results of the experiments.w-4,w-3,w-2,w-1,w,w+1,w+2,w+3,w+4p-4,p-3,p-2,p-1,p,p+1,p+2,p+3,p+4wp-4,wp-3,wp-2,wp-1,wp wp+1,wp+2,wp+3,wp+4w-4|w-3,w-3|w-2,w-2|w-1,w-1|w,w|w+1,w+1|w+2,w+2|w+3,w+3|w+4p-4|p-3,p-3|p-2,p-2|p-1,p-1|p,p|p+1,p+1|p+2,p+2|p+3,p+3|p+4first word of sub-sentence before the delimiterTable 3.
Features used in CRF++.
w represents for wordand p for PosTag.
+1 means the index after currentwhile -1 means before.3.2 Extract last character of word as lemmaIn Chinese, the last character of a word usuallycontains main sense or semantic class, which indi-cates that it may represent the whole word.
Forexample, ?
?
?
(country) can represent ?
??
?
(China) and ??
?
(love) can represent ????
(crazy love).The last character is used as lemma in the ex-periment, with an improvement of 0.27 for LAS ondevelop data and 0.24 on test data.
Details of thescores are listed in table 2 as ?lemma output?.3.3 Multi-level labels experimentA notable characteristic of SemEval-2012?s da-ta is multi-level labels.
It introduces four kinds ofmulti-level labels which are s-X, d-X, j-X and r-X.The first level represents the basic semantic rela-tion of the dependency while the second levelshows the second import, except that s-X repre-sents sub-sentence relation.The r-X label means that a verb modifies anoun and the relation between them is reverse.
Forexample, in phrase ???
(poor) ??
(born) ?
??
(star)?, ????
is headed to ????
with label r-agent.
It means that ????
is the agent of ???
?.When a verbal noun is the head word and itschild has indirect relation to it, the dependency islabeled with j-X.
In phrase ???
(school) ??
(construction)?, ????
is the head of ????
withlabel j-content.
????
is the content of ???
?.The d-X label means that the child modifies thehead with an additional relation.
For example, inphrase ???
(technology) ??
(enterprise)?, ????
modifies ????
and the domain of ????
is???
?.A heuristic method is tried in the experiment.The multi-level labels of d-X, j-X and r-X are sep-arated into two parts for each level.
For example,?d-content?
will be separated to ?d?
and ?content?.For each part, MSTParser is used to train and test.We call the outputs ?first-level output?
and ?se-cond-level output?.
The outputs of each level andnormal output are merged then.In our experiments, only the word satisfies thefollowing conditions need to be merged:a) The dependency label in normal output isstarted with d-, j- or r-.b) The dependency label in first-level output isd, j or r.c) The heads in first-level output and second-level output are of the same.Otherwise, the dependency relation in normaloutput will be kept.
There are also three ways inmerging outputs:a) Label in first-level output and label in se-cond-level output are merged.b) First level label in normal output and labelin second-level output are merged.c) Label in first-level output and second levellabel in normal output are merged.521Experiment has been done on develop data.
Inthe experiment, 24% of the labels are merged and92% of the new merged labels are the same asoriginal.
The results of three ways are listed in ta-ble 4.
All of them get decline compared to normaloutput.outputs LAS UASnormal output 61.37 80.18way a) 61.18 80.18way b) 61.25 80.18way c) 61.25 80.18Table 4.
Results of multi-level labels experiment ondevelop data.3.4 Combined experiment on split and lemmaImprovements are achieved by first two meth-ods in the experiment while a further enhancementis made with a combination of them in the submit-ted systems.
The split method and lemma methodare combined as primary system.
The split methodwith CRF++ and lemma method are combined ascontrast system.
When combining the two methods,last character of the word is firstly extracted aslemma for train data and test data.
Then the split orsplit with CRF++ method is used.The outputs of the primary system and contrastsystem are listed in table 2.4 Analysis and DiscussionThe contrast system presented in this paper finallygot the second prize among nine systems.
The pri-mary system gets the third.
There is an improve-ment of about one percent for both primary andcontrast system.
The following conclusions can bemade from the experiments:1) Parsing is more effective and accurate onshort sentences.
A word prefers to dependon another near to it.
A sentence can besplit to several sub sentences by commasand semicolons to get better parsing output.Result may be improved with a classifier todetermine whether a comma or semicoloncan be used to split the sentence.2) Last character of word is a useful feature.In the experiment, the last character iscoarsely used as lemma and a minor im-provement is achieved.
Much more lan-guage knowledge can be used in parsing.3) The label set of the data is worthy to be re-viewed.
The meanings of the labels are notgiven in the task.
Some of them are confus-ing especially the multi-level labels.
Thetrying of training and testing multi-level la-bels separately by levels fails with a slight-ly decline of the score.
Multi-level alsocauses too many labels: any single-level la-bel can be prefixed to form a new multi-level label.
It?s a great problem for currentparsers.
Whether the label set is suitable toChinese semantic dependency parsingshould be discussed.5 Conclusion and Future WorkThree methods applied in NJU-Parser are de-scribed in this paper: splitting sentences by com-mas and semicolons, taking last character of wordas lemma and handling multi-level labels.
The firsttwo get improvements in the experiments.
Ourprimary system is a combination of the first twomethods.
The contrast system is the same as prima-ry system except that it has a classifier implement-ed in CRF++ to determine whether a comma or asemicolon should be used to split the sentence.Both of the systems get improvements for aboutone percent on LAS.In the future, a better classifier should be devel-oped to split the sentence.
New method should beapplied in merging split outputs to get a wellformed dependency tree.
And we hope there willbe a better label set which are more capable of de-scribing semantic dependency relations for Chi-nese.AcknowledgmentsThis paper is supported in part by National NaturalScience Fund of China under contract 61170181,Natural Science Fund of Jiangsu under contractBK2011192, and National Social Science Fund ofChina under contract 10CYY021.ReferencesY.J.
Chu and T.H.
Liu.
1965.
On the shortest arbores-cence of a directed graph.
Science Sinica, 14:1396?1400.MSTParser:http://www.seas.upenn.edu/~strctlrn/MSTParser/MSTParser.html522J.
Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proc.
COLING.J.
Nivre.
2006.
Inductive Dependency Parsing.
Springer.R.
McDonald, K. Crammer, and F. Pereira.
2005.Online Large-Margin Training of DependencyParsers.
43rd Annual Meeting of the Association forComputational Linguistics (ACL 2005).R.
McDonald, F. Pereira, K. Ribarov, and J. Haji?.
2005.Non-projective Dependency Parsing using SpanningTree Algorithms.
Proceedings of HLT/EMNLP 2005.Zhenghua Li, Wanxiang Che, Ting Liu.
2010.
Improv-ing Dependency Parsing Using Punctuation.
Interna-tional Conference on Asian LanguageProcessing(IALP) 2010.523
