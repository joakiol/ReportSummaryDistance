Intentionality and Human Conversations.Jaime G. Carbonell Jr.Department of Computer ScienceYale University - New Haven, ConnecticutAbstractThis paper analyzes principles of humanconversation based on the conversational goals ofthe participants.
Several conversational rulesare proposed that seem crucial to the process ofinterpreting and generating conversations.
Theserules, as well as other aspects of theconversation process, are embodied in MICS, acomputer program that generates one side of aconversation.
The process model underlying MICS,and some illustrative output, are presented.I) Formulating rules about human conversations.This paper is an empirical approach tounderstanding the processes that underlie humanconversations.
Since the task of codifying allthe knowledge required for modeling humandiscourse is monumental, we confine our approachto formulating rules about the conversationalintent of utterances in the course of a dialog.This approach leads us to investigate the effectsof shared assumptions and knowledge between thespeakers, the social and interpersonal relationsof the speakers, and the inferences that must bemade by both speakers in a conversation.
We takea different approach to analyzing conversationsthan other research efforts, such as thoseadopting the speech-acts paradigm (Mann et al\[1977\]) or investigating task-specific dialogs(Grosz \[1977\])o in the hope that our newperspective will shed some light on otherwiseobscure or neglected aspects of human discourse.Consider the following conversation fragmentbetween Bill and John, two college studentssharing an apartment:I) JOHN: Hi, what's new, Bill?BILL: l'm going to visit my folks tonight.We can analyze Bill's utterance in ConversationFragment (I) in terms of its immediate meaning,that is, a representation of Bill's utterance inConceptual Dependency or some other meaningrepresentation.
This, however, is a veryincomplete analysis of what Bill said.
Why didBill say that he was visiting his folks?
Billcould just as easily have said, "I'm going tobrush my teeth tonight."
This utterance, however,doesn't answer John's question; brushing one"steeth is not "something new".
Therefore, we couldpropose a rather simple conversational rule:RULE I : If a question is asked in the course ofa conversation, the other participantshould answer this question.Rule I, however, is a little too naive.Suppose Bill's answer was: "There are a few moremicrons of dust on the windowsill than the lasttime you asked me that question."
This is indeed"something new", but we would think of Bill as awise guy for answering the question literallyrather than addressing what John "must havemeant".
What did John really mean?
John musthave been looking for something out of theordinary and of some intrinsic importance.
Let uspropose a new rule to incorporate this principle:RULE 2: In the formulation of an answer, thespeaker should address the true signifi-cance of the question, not just itsliteral meaning.What is the true significance of a question?In Conversation Fragment (I), Bill might haveanswered: "The J-particle angular momentum of+3/2 was confirmed today."
John, a literaturemajor who does not understand Physics, may not beinclined to continue the conversation.
Therefore,Bill's answer is not what was called for, unlessBill intentionally wanted to end the conversation.This example suggests that Bill missed somethingin establishing the true significance of John'squestion.
John did, indeed, explicitly ask tohear something new; implicitly he meant somethingimportant and out of the ordinary.
The J-particleanswer conforms to these requirements, but it isstill an inappropriate response.
Therefore, thetrue significance of John's answer must includeJohn's conversational goal.
Why did John ask"What's new"?
The answer is, obviously, to starta conversation with Bill.
Bill, being aware ofthis conversational goal, needs to choose ananswer that attempts to initiate conversation.That is, Bill should choose a topic ofconversation that John can talk about and thatJohn may be interested in.
Conversational Rule(3) summarizes this discussion:RULE 3: In introducing a new topic of conversa-tion, the topic should be chosen so thatboth speakers have some knowledge andinterest in its discussion.The process of understanding theconversational import of an utterance may beconceptually divided into two primarysubprocesses: I) determine the conversationalgoal of the utterance, and 2) establish the real,often implicit, meaning of the utterance.
Lehnert\[1977\] analyzes the process of establishing thereal meaning of questions.
Our analysis focuseson the conversational goals of the participantsand the establishment of a shared knowledge basebetween the participants.
It is this sharedcultural, personal, and factual knowledge that theconversational participants leave implicit in eachcommtmication.
To illustrate this fact, considerConversational Fragment (2):2) JOHN: Do you want to go out and try the barat Monument Square?BILL: I'm going to visit my folks tonight.Real significance of Bill's utterance:i) No, I do not want to go to the M~numentSquare bar.ii) My reason for not wanting to go is thatI made a previous commitment, and I can-not be in two places at once tonight.141ill) The previous commitment is a visit tomy folks.iv) I am telling you about the reason whyI cannot go drinking with you ratherthan just saying "no" because I do notwant you to get angry at me.v) I may also wish to shift the topic ofconversation to a discussion about myfam il y.Bill knows that John will interpret hisanswer so as to conclude its real significance;otherwise Bill would have chosen to explicitlystate the real significance.
How does Bill knowthat John will understand him correctly?
ClearlyBill and John must share some common senseknowledge such as:a) A person cannot be in two places at once.b) Previous commitments should be honored.c) If X's invitation or suggestion is turneddown by Y without apparent reason, then Xis likely to get upset at Y.d) If a person introduces a new topic in aconversation, he may want to discuss thecurrent topic further,Both Bill and John are aware that they share acommon cultural knowledge base.
This knowledge isvery crucial in determining what is said in theconversation.
Bill must have considered (1)through (iv) before deciding that is wassufficient to say only (ill).
How did Bill decideto say only (ill)?
He must have concluded thatJohn would infer (i) , (ii) and (iv) withoutdifficulty.
Thus, Bill knew about John's generalknowledge because of their common culturalbackground and their personal relation.
Bill usedthis knowledge to decide what to say in thec onv er satlon.In the course of a conversation, people makeassumptions about each other's knowledge.
It issometimes easier to see what these conversationalassumptions are when they turn out to beincorrect, as in the following example:3) PETE: How are you going to vote onProposition 13?MARY: On what?PETE: You know, the property tax limitation.MARY: Oh yeah.
I'm not registered to vote.Which way were you trying to convinceme to vote?PETE: I was hoping you would help me makeup my mind.MARY: Actually, I don't give a damn aboutpolitics.At the beginning of the conversation Pete ass~edthat Mary knew what Proposition 13 was, that shewas able to vote, that she would vote, and thatshe had already decided how to vote on Proposition13.
All of these assumptions turned out to beincorrect, and the course of the conversationturned towards clarifying the incorrectass~pt ions .
This example is an instance of amore general rule of conversation:RULE 4: If a participant in a conversationdiscovers that his assumptions aboutthe shared knowlege between the twospeakers is incorrect, then he willsteer the conversation toI) establish a common knowledge base ona specific topic, or2) discover what their shared knowledgeis in general, or3) shift the conversational topic tosome matter where a common knowledgebase is more likely to exist, or4) end the conversation.The assumptions discussed thus far have beenof a factual nature, but assumptions are also madeabout the conversational intent of theparticipants and about their interest in theconversational topic.
Mary inferred Pete" sconversational intent incorrectly: He was seekingadvice, not trying to lobby for or againstProposition 13.
Pete started the entireconversation on the wrong topic by assuming thatMary was interested in politics or taxes.
Aconversation about a topic that one of theparticipants finds uninteresting will usuallydigress to other topics or fizzle out as theuninterested party volunteers no new information,finds an excuse to do something else, or statesoutright that the conversation is boring (as wasthe case in our example).Erroneous assumptions about conversationalintent lead to misunderstandings because eachspeaker will address the perceived intent of theother speaker's utterance.
It is, therefore,imperative to correctly infer the other speaker'sconversational intentions in order for theconversation to proceed naturally.
The typemisunderstanding that often results fromincorrectly perceived conversational intentionsis, on occasion, exploited in creating certaintypes of jokes, as in example 4:4) SON: Dad, I robbed the liquor store yesterday.DAD: How could you ever do such a thing, son?SON: Well, I got me this gun, and I pointed itat the cashier...To illustrate the importance of the implicitconversational goals and shared knowledge betweenthe participants in a conversation, we present afew more dialog framents between Bill and John,the two college students sharing an apartment.
Ineach example, as in conversations (I) and (2),Bill utters the same response, but its meaning issignificantly different, depending on the contextof the conversation.5) JOHN: Are you broke again?
You are going tohave to come up with your share of therent this month.BILL: I'm going to visit my folks tonight.142Meaning of Bill's utterance:(i) Yes, l'm broke again.
(il) Yes, I'll try to contribute my share ofthe rent.
(iii) My parents might give me some money ifI ask them.
(iv) If I visit them and ask them in person Ihave a better chance of getting some money.
(v) I'll visit them tonight and then I'll askthem for money.When we read Conversation Fragment (5), weinfer that Bill may be going to ask his parentsfor money.
How do we do this?
We do not shareknowledge with Bill to the effect that his parentshave money or that Bill is willing to ask them formoney.
The answer is based on a conversationalrule:RULE 5: The utterances in a conversation shouldbe connected by continuity of topic,common conversational goals, and eachparticipant addressing the intent of theutterances of the other participant.Since the reader assumes that Rule (5) is true forConversation Fragment (5), he concludes that theremust be a connection between Bill needing moneyand the visit to his parents.
The reader theninfers the most likely connection: Bill will askhis parents for money.
John must also make thisinference based on Rule (5), unless he knows thatBill regularly visits his parents to ask formoney.
The significant point illustrated inexample 5 is that the conversation focused theinference mechanism to find a connection betweenthe respective utterances.
Therefore,conversational principles can play an importantrole in focusing human reasoning processes.
Theprinciple of focusing inference processes onsignificant or interesting aspects ofconversational utterances and events is developedinto a theory of human subjective understanding inCarbonell \[1978\].Let us continue with the conversationalfragments between Bill and John:6) JOHN: How come you never see your family?BILL: I'm going to visit my folks tonight.Meaning of Bill's utterance:(i) I do visit my family.
(ii) Supporting evidence: I'm going to visitthem tonight.
(iii) Therefore, what you just said is not true.7) JOHN: Can I borrow your car?
I got this heavydate tonight.BILL: I'm going to visit my folks tonight.Meaning of Bill's utterance:Alternative I.
(i) No, you cannot borrow my car tonight.
(il) I am going to visit my folks tonight.
(iii) I need to drive there.
(iv} The car cannot be fn two places at once.Alternative II,(i) Yes, you can borrow my car tonight.
(ii) I am going to be at my folk's place,where I don't need to use it.8) JOHN: Can I have the apartment to myself?I got this heavy date tonight.BILL: I'm going to visit my folks tonight.Meaning of Bill's utterance:(i) Yes, you can have the apartment.
(ii) What you want is for me to be elsewhere.
(iii) I was planning on that any~my, since Iam visiting my folks tonight.Conversation fragments (6), (7) and (8)illustrate the degree to which the understandingo f cony er sat ional utterances i sexpectation-driven.
The expectations aregenerated from previous utterances according torule 5; the toplc, intent, and conversationalgoals introduced earlier in the conversation willbe addressed by later utterances.
In each casethe same utterance on Bill's part is understooddifferently, depending on the context establishedby John' s previous utterance.
Utterances in aconversation do not usually have a meaningindependent of the rest of the conversation;their meaning is part of the context of the entireconversation.
Thus, it is easy to see why quotingonly a short passage from a conversation (or apolitical speech) can give that passage has anentirely different meaning from what wasoriginally intended.The shared knowledge between two speakersdepends on many different factors.
Two speakersshare a large amount of basic knowledge by merelybeing members of the human race (e.g.
the basicdrives that motivate humans such as hunger,self-preservation, etc .).
More knowledge isshared if the two speakers are members of the sameculture.
(Much of the cultural and more basichuman knowledge necessary to understand naturallanguage is discussed in Schank and Ableson\[1977\].)
If the two participants hold the sametype of job, are professional colleages, or havethe same special interests, then they will sharesome rather specific knowledge.
Two people withthe same special interests (such as football orradio-astronomy) will usually steer theconversation to a discussion of their commoninterest s.RULE 6: The topic of a conversation may drift toa subject where the conversational partici-pants share a great amount of knowledge.Another factor that determines the knowledgeshared by the participants in a conversation istheir interpersonal relation, i.e., how well theyknow each other.
In conversational fragment (7),Bill's response can be interpreted in twodifferent weys by the reader, but_ John willi~terpret his response unambiguously.
John mustknow whethe~ Bill's response means  tha~ Bill needs143the car or whether John is free to use it ;otherwise, Bill would have been more specific inhis answer.Social relations and the perceived goals ofconversational participants play an important rolein interpreting the meaning of conversationalutterances.
Let us first consider the influenceof the social relations between the twoparticipants :9) ARMY GENERAL: I want a juicy hamburger.STAFF AIDE: Right away, sirli0) 7-YEAR-OLD: I want a juicy hamburger.MOTHER: Maybe next wsek.
We are havingchicken today.II) PRISON INMATE I: I want a juicy hamburger.PRISON INMATE 2: Me tool Everything heretastes like cardboard.The utterance "I want a juicy hamburger" isinterpreted differently in each dialog fragment.The difference in the interpretations is based onthe different social relations existing betweenthe two conversational participants.
In Dialog(9) the utterance was interpreted to mean a directorder to the staff aide: "Get me a hamburger andmake sure it is julcyl" In Dialog (I0), the7-year-old was expressing a request to his mother,hoping that his mother might comply.
In Dialog(II), the same statement was interpreted asnothing more than wishful thinking.
The fir stinmate made no order or request to the secondinmate.
Hence, the first utterance of each dialogfragment implies a different conversational goaldepending upon the differences in the socialrelations of the conversational participants.
Thesocial context and the relationship between thetwo speakers generate expectations that guide thecourse of the conversation.
A staff aide e~pectsto be ordered about by a general.
A motherexpects her son to ask her for favors.
Prisoninmates cannot expect each other to do thinks thatare made impossible by their incarceration.
Theseexpectations lead to a formulation of differentconversational goals for the utterance, "I want ajuicy hamburger ," in each conversational fragment.The conversational principle exemplified in ourdiscussion is summarized as Conversational Rules(7) and (8):RULE 7: The social relationship between theparticipants in a conversation generatesexpectations about the intentional meaningof utterances in the conversation.
Theseexpectations are used to determine theconversational goals of each participant.RULE 8: Each speaker's perception of the conver-sational goals of the other speakerdetermines his interpretation of theother speaker" s utterances.Di f ferences in understanding o fconversational goals lead to different responsesin a dialog, as illustrated in ConversationFragments (9), (I0) and (Ii).
We saw how a socialrelationship between two people can influencetheir interpretation o f each other" sconversational goals.
Two strangers can also makeassumptions about each other's conversationalgoals based on appearances, social circumstancesand each other" s occupation.
Consider, forinstance, the various responses to John's questionin the example below:Scenario: John walked up to a parson in the cornerand asked : "DO you know how to get toElm Street?
"12.1) The stranger replied: "You go two blockstoward that tall building and turn right.
"12.2) The cab driver in the corner replied: "Sure;Hop in.
Where on Elm do you want to go?
"12.3) The person, who was holding up a map and apiece of paper with an Elm Street address onit, replied : "No, could you tell me how toget there?
"12.4) The child answered: "Yes, I know how to getthere!
"The question was interpreted to mean fourdifferent things, depending on whom John spoke to.If a stranger asks, "Do you know how to get to X,"the listener usually interprets this to mean "Iwant to go to X, but I do not know how to getthere.
Please give me directions."
Since theoccupation of a cab driver is to take people totheir destination it is perfectly legitimate forhim to interpret the question as: "If you knowhow to get to X please take me there."
The personwho is visibly lost and trying to find his way mayinterpret John's question as: "You seem to belost.
Can I help you find your way?"
Response(12.3) illustrates that the responder did notinfer that John's goal was to go to Elm street, incontrast with the two previous responses.
A childoften interprets questions of the form: "Do youknow Y" literally, possibly inferring that theperson asking the question is quizzing him.
As inour previous examples, the differences ininterpretation can be ~p la ined in terms ofdifferences in the perceived goals of theparticipants in the conversation.II) MICS: A process model of human conversation.The phenomenon of human conversation is toocomple~ for any single study to do justice to morethan a narrow aspect of the problem.
In order tofully understand human conversations we may haveto understand all human cognitive reasoningprocesses.
Our research approach can be outlinedas follows: I) Study many sample conversations;2) try to establish some relatively general rulesof conversation; 3) encode these rules into aprocess model; 4) see if this model accounts forcertain aspects of human conversation; 5) realizethat we solved hardly more than a minute part ofthe problem, and 6) reiterate the research processin a (hopefully positive) feed-back loop.The conversational rules discussed in thefirst section address problems that need to beconsidered i f  one is to understand human144conversations.
There is little doubt, asdemonstrated by countless examples, thatconversational goals, shared knowledge betweenspeakers, social relationships between speakers ',and the conversational import of each utterance ina dialog are aspects of  human discourse that needto be analyzed if one is to understand how humanconversations work.
Analyzing these aspects,however, solves only a small subset of the largerproblem of how conversations function.
Forinstance, the problem of topic selection in aconversation needs to be addressed.
How does aperson change the topic in a conversation?
Howare new topics chosen?
These questions areanalyzed in Schank \[1977\].
Here we propose someadditional ideas on the impact of shared knowledgeand interests on topic-selection.MICS (Mixed-Initiative Conversational System)is a fully implemented computer program thatgenerates one side of a natural-languageconversation.
MICS embodies the conversationalrules discussed in this paper, a topic transitionmechanism based on Schank \[1977\], and the idea ofa conversational syntax.
Conversational syntax isa set of rules that help to characterizewell-formed conversations.
For instance, thefollowing four rules are among the twentyconversational syntax rules in MICS:RULE 9: Do not repeat information in the courseof a conversation unless explicitlyr eque st ed.RULE I0: Do not say things that the other speakeralready knows about.RULE II: If the other speaker says something thatviolates one's beliefs, then respond inkind by re-asserting the violated belief.RULE 12: If insulted, return the insult or end theconversation.MICS illustrates that the conversational rules,topic transition rules and conversational syntaxrules provide a sound, if possibly incompleteapproach to the modeling of human conversation.MICS is able to generate reasonable conversationsabout domains on which it has some knowledge, butthere are still many short-comings, as illustratedin the examples that follow.MICS "knows" about itself as a person (e.g.it believes itself to be a computer programmer)and uses a model of the other conversationalparticipant that contains certain informationabout the speaker, such as his social status, hisoccupation, his relationship with other people andhis areas of special interest and more detailedknowledge.
The model of the other speaker is anecessary part of the conversational model, sinceit enables MICS to apply the conversational rules.When MICS talks to a stranger, it builds a modelof the speaker; in fact~ one of itsconversational goals is to learn about the personwith whom it is conversing.
In the dialog thatfollows (an actual computer run), MICS starts outknowing nothing about Dave.MICS CONVERSATION LOG ******** 10/11/77 *******HELLO, WHAT IS YOUR NAME?I am Dave.WHAT'S NEW TODAY, DAVE?Nothing, What's your name?MY NAME IS MICS.What is your job?I AM A COMPUTER PROGRAMMERThat's nice.WHAT DO YOU DO FOR A LIVING?I MICS takes the initiative by assertingI its conversational goal of learningI about Dave.I am still a student.DO YOU LIKE BEING A STUDENT?For the time being yes.WHAT WILL YOU DO AFTERWARDS?I want to be a professor some day.WHAT DO YOU DO FOR FUN?i MICS formed a person-frame for Dave.
At thisI point, the conversational goal of trying toI establish an area of mutual interest andI shared knowledge is activated.I smoke dope.YOU MIGHT 6ET STONED IF YOU SMOKE TOO MUCH.I know, that's the idea.YOU MI~T 6ET IN TROUBLE IF THE COPS CATCH YOU.All right, stop moralizing, what do you do for fun?I LIKE TO PLAY CHESSThat sounds boring.NO, IT IS A LOT OF FUNIMy brother Eric plays chess.HE MUST BE SMART.I have to go.
Bye Mics.NICE TALKING TO YOU, DAVEAs a result of the conversation, MICS knowssomething about Dave, in particular that one ofhis llfe goals is to becomle professor.
MICS'sconversational goals cause it to establish its ownconversational topics.
When a new topic isintroduced by the human speaker, MICS stays on thechosen topic or chooses a closely related topic.Another rule of conversation is invoked in theabove dialog :RULE 13: Each participant in the conversation hasthe conversational goal of saying thingsthat are important to the otherparticipant.When the human participant says that he likes tosmoke marijuana, MICS finds in its memory thatsmoking marijuana is illegal and can lead to thesmoker getting stoned.
Accord ing to MIC S ' s145beliefs getting stoned is undesirable, and doingsomething illegal leads to undesirableconsequences.
MICS determines that it isimportant for Dave to know about the badconsequences of his acts.
Therefore, applyingRule (13), MICS warns Dave about the evils ofmarijuana.
It is evident that MICS should haveknown that Dave knows that smoking marijuana leadsto getting stoned, and that, in fact, gettingstoned is Dave's primary purpose for smokingmarijuana.
If MICS knew this fact, thenConversational Syntax Rule (I0) would prevent MICSfrom warning Dave about getting stoned ?Therefore, MICS needs a better mechanism fordeciding what knowledge it shares with the otherspeaker.
It is very difficult to determine whatthe other person already knows and what he is ableto infer, but this is a problem that cannot becircumvented if we are to model human discourse.The conversational syntax rule of counteringa belief violation (Rule II) caused MICS to objectwhen Dave said that playing chess (MICS's favoritepastime) was not exciting ?
Since the twoparticipants could not find a common area ofinterest, the conversation ended without anys ubstantitive dialog.
This illustratesConversational Rule (4), discussed in the previoussection.
Let us analyze a conversation betweenMICS and Pete, someone who MICS believes to be itsfriend.HELLO, WHAT IS YOUR NAME?Pete.WHAT'S NEW TODAY, PETE?Professor Stevenson is giving us an exam friday.STEVENSON GIVES DIFFICULT EXAMS.Yeah~ do you know that Dave is probably goingto flunk?THAT'S GOING TO MAKE IT HARD FOR DAVE TO BECOMEA PROFESSOR.Too bad, Dave is not too smart anyways.YES, DAVE LIKES TO SMOKE DOPE.l've got to go and study.YOU WILL DO WELL IN THE EXAM.The above conversation illustrates theusefulness of shared knowledge between the twoparticipants.
Pete and MICS both know abouttaking ~ams,  and they have a common acquaintance- Dave.
MICS is able to use what it learned aboutDave in its previous conversation.
MICS' sresponse to Dave possibly flunking the examillustrates Conversational Rules (3), (5) and (7).The continuity of the conversation is preserved.The chosen topic transition is probably ofinterest to Pete, as inferred by MICS in thefollowing manner: Pete introduced Dave into theconversation; therefore, he probably wants totalk about Dave.
Not fulfilling a life goal (e.g.becoming a professor) is an inherently importantconsequence to Dave; therefore, Pete is probablyinterested in knowing this consequence.
Rule 7applies because in the social relationship betweenPete and MICS (they are friends) it is OK to talkabout mutual acquaintances ?
(It is NOTnecessarily OK for a judge and a defendant, forinstance, to discuss mutual acquaintances.
)MICS's utterance about it being difficult forDave to become a professor illustrates theinferenceing that proceeds in the course of aconversation.
The inferences are directed at themost serious consequences of the preceedingutterance: flunking the exam.
Focusing theinference process by importance criteria was foundto be necessary in order to keep conversationsfrom digressing into uninteresting topics.When Pete states that Dave is not too smart,MICS reacts by verifying this evaluation.
Sincein the previous conversation Dave chose to ignoreMICS's warnings about smoking marijuana, MICSconcluded that Dave was not too bright.
Thisconclusion is used as supporting evidence to backPete's evaluation.
The process of responding toopinions is captured in conversational rule 14:RULE 14: If a speaker in a conversation states anopinion, the other speaker should considerwhether or not he agrees with the opinion.The first speaker usually has the conver-sational goal of ~mnting feedback (usuallyagreement) on his oDinion.The last exchange in the above dialogillustrates a deficiency in MICS determination ofthe conversational goals.
When Pete says, "I'vegot to go and study," he means, "I want to end theconversation," but inferring this conversationalgoal requires understanding what it means tostudy.
One cannot infer from the phrase, "I'vegot to go ...", that the conversation shouldterminate.
For instance, if Pete says, "I've gotto go to Europe ," he probably wants to introducehis upcoming trip as a new topic of conversation.The knowledge that studying and talking cannotproceed simultaneuously is necessary in order toconclude that Pete wanted to end the conversation.The primary usefulness of the MICS system isthat it sheds light on problems about the rules ofconversation that might otherwise remainunnoticed ?
The feedback from testing theimplementation of our conversational model forcesus to be more precise and complete in ourformulation of our ideas about conversation.
Thefollowing is a conversation fragment from a laterversion of MICS which has a more sophisticatedinference capability for determining the knowledgethat it shares with the other speaker.
Forinstance, MICS infers that if a person voluntarilychooses to pursue a certain activity, then thatperson is aware of the intended consequences ofthis activity.Ashtrays.WHAT ABOUT ASHTRAYS?Ashtrays are useful.DO YOU SMOKE?Yes.YOU MIGHT GET CANCER IF YOU SMOKE TOO MUCH.Who cares, anyway I smoke dope, not tobacco.I SEE.
YOU LIKE TO GET HIGH.It is better than getting drunk.NOT NECESSARILY.
YOU MIGHT GET CAUGHT BY THE COPS.146Figure (I) is a diagram of the control flowof MICS.
As a process model of conversation, MICSis a useful tool, but it is far from a complete oreven an entirely correct model of humanconversation.
MICS is a 3 level productionsystem.
The first set of productions is theconversational-syntax rules.
These rulesformulate contraints on the nature of theutterance that MICS will generate next in order toinsure that the conversation follows a proper,"natural" course.
Some of these constrains takethe form of conversational goals used by the othertwo sets of productions rules.
The second set ofrules is the topic selection productions.
Theseproductions generate topic transitions guided byconversational goals and the amount of sharedknowledge between the speakers ?
Severalalternative things to say may be generated in thisphase of the processing.
These, as well as theconversational goals are stored in a short termmemory (STM) and are used by the third, andtheoretically most significant phase of theprogram: the topic evaluation rules.The third set o f productions encodes theconversational rules discussed throughout thispaper.
These rules use the STM information, thememory models of the self and the other speaker,CONV.
SYNTAXRULESLTMMODEL OF / ' 'II LISTENER iIIGOALS OF ISELF tIEVENT /MF~ORYCAC ' S / / rand an inferencer when necessary.
The purpose ofthese rules is to choose the most interestingtopics (to both the self and the other speaker)from the alternatives generated by the second setof production rules.
The inferencer is used todetermine what the other speaker is likely to knowand which aspect of the topic he would be mostinterested in discussing.
Thus, the menaing of anutterance is produced by the third set o fproduction rules.The utterances are generated in English by arather crude phrasal English generator.
Theutterances from the other speaker are analyzed fortheir meaning and conversational form by aprimitive, key-concept oriented analyzer.Disclaimer: MICS is a first-pass processmodel of a theory of conversation, not a theory oflearning about other people.
As such, its abilityto learn about the other conversationalparticipants is not as general as the dialogspresented in this paper may suggest.
MICS learnsabout the other speaker by instantiating aprototypical-person frame - a data structure thatencodes the more generally applicable facts aboutpeople and their social relations.INPUT SENTENCEANALYSIS ITOPIC/C-TYPEI I/ / / / /-/,,,/EVALUATIONRULESENGLISHGENERATORENGLISH RESPONSETOPIC SELECTIONRULESTRANSIT IO~IW~OTHER TOP IC~SELECTIONSF INTERESTMICSCONTROL-FLOWFIGURE 1STM,I/147Conclusion.believe that the best way to analyze aproblem as difficult as modeling human discourseis to forge ahead by creating rules that captureimportant aspects of the conversation problem.The usefulness of these rules should be tested ina reactive environment such as an interactivecomputer program.
Since conversation is not aproblem that can be isolated from other aspects ofhuman cognitive behavior, we are researching it inconjunction with other aspects of ArtificialIntelligence.
A process-based theory o f hamanconversation should give some insight into otherNatural Language Processing issues in particular,and AI modeling of human reasoning processes ingeneral.Re fer ences.Carbonell, J. G. 1978.
Computer Models of Socialand Political reasoninB, PhD.
Thesis,Yale University, New Haven, Conn.Grosz, B. J.
1977.
The Representation and Use ofFocus in a System for UnderstandingDialogs, Proc.
of the fifth IJCAI., MIT,Cambridge, Mass.Lehner t, W. 1977.
The Process of QuestionAnswering, PhD Thesis.
Tech.
Report 88,Yale University, New Haven, Conn.Mann W., M~ore J., Levln J.
1977.
A ComprehensionModel for Human Dialogue, Proc.
of thefifth IJCAI.
MIT, Cambridge, Mass.Schank, R. C. and Abelson R. P. 1977.
Scripts,Goals, Plans and Understanding, lawrenceLawernce Erlba~n.
Hillside, NJ.Schank, R. C. 1977.
Rules and topics inconversation, Cognitive Science,Vol.
I, No.
4.148
