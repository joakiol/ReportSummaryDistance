Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 610?619,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsGlobal Learning of Typed Entailment RulesJonathan BerantTel Aviv UniversityTel Aviv, Israeljonatha6@post.tau.ac.ilIdo DaganBar-Ilan UniversityRamat-Gan, Israeldagan@cs.biu.ac.ilJacob GoldbergerBar-Ilan UniversityRamat-Gan, Israelgoldbej@eng.biu.ac.ilAbstractExtensive knowledge bases of entailment rulesbetween predicates are crucial for applied se-mantic inference.
In this paper we propose analgorithm that utilizes transitivity constraintsto learn a globally-optimal set of entailmentrules for typed predicates.
We model the taskas a graph learning problem and suggest meth-ods that scale the algorithm to larger graphs.We apply the algorithm over a large data setof extracted predicate instances, from which aresource of typed entailment rules has been re-cently released (Schoenmackers et al, 2010).Our results show that using global transitiv-ity information substantially improves perfor-mance over this resource and several base-lines, and that our scaling methods allow usto increase the scope of global learning ofentailment-rule graphs.1 IntroductionGeneric approaches for applied semantic infer-ence from text gained growing attention in recentyears, particularly under the Textual Entailment(TE) framework (Dagan et al, 2009).
TE is ageneric paradigm for semantic inference, where theobjective is to recognize whether a target meaningcan be inferred from a given text.
A crucial com-ponent of inference systems is extensive resourcesof entailment rules, also known as inference rules,i.e., rules that specify a directional inference rela-tion between fragments of text.
One important typeof rule is rules that specify entailment relations be-tween predicates and their arguments.
For example,the rule ?X annex Y?
X control Y?
helps recognizethat the text ?Japan annexed Okinawa?
answers thequestion ?Which country controls Okinawa??.
Thus,acquisition of such knowledge received considerableattention in the last decade (Lin and Pantel, 2001;Sekine, 2005; Szpektor and Dagan, 2009; Schoen-mackers et al, 2010).Most past work took a ?local learning?
approach,learning each entailment rule independently of oth-ers.
It is clear though, that there are global inter-actions between predicates.
Notably, entailment isa transitive relation and so the rules A ?
B andB ?
C imply A?
C.Recently, Berant et al (2010) proposed a globalgraph optimization procedure that uses Integer Lin-ear Programming (ILP) to find the best set of entail-ment rules under a transitivity constraint.
Imposingthis constraint raised two challenges.
The first ofambiguity: transitivity does not always hold whenpredicates are ambiguous, e.g., X buy Y?
X acquireY and X acquire Y ?
X learn Y, but X buy Y 9 Xlearn Y since these two rules correspond to two dif-ferent senses of acquire.
The second challenge isscalability: ILP solvers do not scale well since ILPis an NP-complete problem.
Berant et al circum-vented these issues by learning rules where one ofthe predicate?s arguments is instantiated (e.g., ?X re-duce nausea?
X affect nausea?
), which is useful forlearning small graphs on-the-fly, given a target con-cept such as nausea.
While rules may be effectivelylearned when needed, their scope is narrow and theyare not useful as a generic knowledge resource.This paper aims to take global rule learning onestep further.
To this end, we adopt the represen-tation suggested by Schoenmackers et al (2010),who learned inference rules between typed predi-cates, i.e., predicates where the argument types (e.g.,city or drug) are specified.
Schoenmackers et al uti-610lized typed predicates since they were dealing withnoisy and ambiguous web text.
Typing predicateshelps disambiguation and filtering of noise, whilestill maintaining rules of wide-applicability.
Theirmethod employs a local learning approach, while thenumber of predicates in their data is too large to behandled directly by an ILP solver.In this paper we suggest applying global opti-mization learning to open domain typed entailmentrules.
To that end, we show how to construct astructure termed typed entailment graph, where thenodes are typed predicates and the edges represententailment rules.
We suggest scaling techniques thatallow to optimally learn such graphs over a largeset of typed predicates by first decomposing nodesinto components and then applying incremental ILP(Riedel and Clarke, 2006).
Using these techniques,the obtained algorithm is guaranteed to return an op-timal solution.
We ran our algorithm over the dataset of Schoenmackers et al and release a resourceof 30,000 rules1 that achieves substantially higherrecall without harming precision.
To the best of ourknowledge, this is the first resource of that scaleto use global optimization for learning predicativeentailment rules.
Our evaluation shows that globaltransitivity improves the F1 score of rule learning by27% over several baselines and that our scaling tech-niques allow dealing with larger graphs, resulting inimproved coverage.2 BackgroundMost work on learning entailment rules betweenpredicates considered each rule independently ofothers, using two sources of information: lexico-graphic resources and distributional similarity.Lexicographic resources are manually-preparedknowledge bases containing semantic informationon predicates.
A widely-used resource is WordNet(Fellbaum, 1998), where relations such as synonymyand hyponymy can be used to generate rules.
Otherresources include NomLex (Macleod et al, 1998;Szpektor and Dagan, 2009) and FrameNet (Bakerand Lowe, 1998; Ben Aharon et al, 2010).Lexicographic resources are accurate but have1The resource can be downloaded fromhttp://www.cs.tau.ac.il/j?onatha6/homepage files/resources/ACL2011Resource.ziplow coverage.
Distributional similarity algorithmsuse large corpora to learn broader resources by as-suming that semantically similar predicates appearwith similar arguments.
These algorithms usuallyrepresent a predicate with one or more vectors anduse some function to compute argument similarity.Distributional similarity algorithms differ in theirfeature representation: Some use a binary repre-sentation: each predicate is represented by one fea-ture vector where each feature is a pair of argu-ments (Szpektor et al, 2004; Yates and Etzioni,2009).
This representation performs well, but suf-fers when data is sparse.
The binary-DIRT repre-sentation deals with sparsity by representing a pred-icate with a pair of vectors, one for each argument(Lin and Pantel, 2001).
Last, a richer form of repre-sentation, termed unary, has been suggested wherea different predicate is defined for each argument(Szpektor and Dagan, 2008).
Different algorithmsalso differ in their similarity function.
Some employsymmetric functions, geared towards paraphrasing(bi-directional entailment), while others choose di-rectional measures more suited for entailment (Bha-gat et al, 2007).
In this paper, We employ severalsuch functions, such as Lin (Lin and Pantel, 2001),and BInc (Szpektor and Dagan, 2008).Schoenmackers et al (2010) recently used dis-tributional similarity to learn rules between typedpredicates, where the left-hand-side of the rule maycontain more than a single predicate (horn clauses).In their work, they used Hearst-patterns (Hearst,1992) to extract a set of 29 million (argument, type)pairs from a large web crawl.
Then, they employedseveral filtering methods to clean this set and au-tomatically produced a mapping of 1.1 million ar-guments into 156 types.
Examples for (argument,type) pairs are (EXODUS, book), (CHINA, coun-try) and (ASTHMA, disease).
Schoenmackers etal.
then utilized the types, the mapped argumentsand tuples from TextRunner (Banko et al, 2007)to generate 10,672 typed predicates (such as con-quer(country,city) and common in(disease,place)),and learn 30,000 rules between these predicates2.
Inthis paper we will learn entailment rules over thesame data set, which was generously provided by2The rules and the mapping of arguments into types canbe downloaded from http://www.cs.washington.edu/research/sherlock-hornclauses/611Schoenmackers et alAs mentioned above, Berant et al (2010) usedglobal transitivity information to learn small entail-ment graphs.
Transitivity was also used as an in-formation source in other fields of NLP: TaxonomyInduction (Snow et al, 2006), Co-reference Reso-lution (Finkel and Manning, 2008), Temporal Infor-mation Extraction (Ling and Weld, 2010), and Un-supervised Ontology Induction (Poon and Domin-gos, 2010).
Our proposed algorithm applies to anysparse transitive relation, and so might be applicablein these fields as well.Last, we formulate our optimization problem asan Integer Linear Program (ILP).
ILP is an optimiza-tion problem where a linear objective function overa set of integer variables is maximized under a set oflinear constraints.
Scaling ILP is challenging sinceit is an NP-complete problem.
ILP has been exten-sively used in NLP lately (Clarke and Lapata, 2008;Martins et al, 2009; Do and Roth, 2010).3 Typed Entailment GraphsGiven a set of typed predicates, entailment rules canonly exist between predicates that share the same(unordered) pair of types (such as place and coun-try)3.
Hence, every pair of types defines a graphthat describes the entailment relations between pred-icates sharing those types (Figure 1).
Next, we showhow to represent entailment rules between typedpredicates in a structure termed typed entailmentgraph, which will be the learning goal of our algo-rithm.A typed entailment graph is a directed graphwhere the nodes are typed predicates.
A typed pred-icate is a triple p(t1, t2) representing a predicate innatural language.
p is the lexical realization of thepredicate and the types t1, t2 are variables repre-senting argument types.
These are taken from aset of types T , where each type t ?
T is a bagof natural language words or phrases.
Examplesfor typed predicates are: conquer(country,city) andcontain(product,material).
An instance of a typedpredicate is a triple p(a1, a2), where a1 ?
t1 anda2 ?
t2 are termed arguments.
For example, becommon in(ASTHMA,AUSTRALIA) is an instance ofbe common in(disease,place).
For brevity, we refer3Otherwise, the rule would contain unbound variables.to typed entailment graphs and typed predicates asentailment graphs and predicates respectively.Edges in typed entailment graphs represent en-tailment rules: an edge (u, v) means that predicateu entails predicate v. If the type t1 is differentfrom the type t2, mapping of arguments is straight-forward, as in the rule ?be find in(material,product)?
contain(product,material)?.
We term this a two-types entailment graph.
When t1 and t2 are equal,mapping of arguments is ambiguous: we distin-guish direct-mapping edges where the first argu-ment on the left-hand-side (LHS) is mapped tothe first argument on the right-hand-side (RHS),as in ?beat(team,team)d??
defeat(team,team)?, andreversed-mapping edges where the LHS first argu-ment is mapped to the RHS second argument, asin ?beat(team,team)r??
lose to(team,team)?.
Weterm this a single-type entailment graph.
Notethat in single-type entailment graphs reversed-mapping loops are possible as in ?play(team,team)r??
play(team,team)?
: if team A plays team B, thenteam B plays team A.Since entailment is a transitive relation, typed-entailment graphs are transitive: if the edges (u, v)and (v, w) are in the graph so is the edge (u,w).Note that in single-type entailment graphs one needsto consider whether mapping of edges is direct or re-versed: if mapping of both (u, v) and (v, w) is eitherdirect or reversed, mapping of (u,w) is direct, oth-erwise it is reversed.Typing plays an important role in rule transitiv-ity: if predicates are ambiguous, transitivity does notnecessarily hold.
However, typing predicates helpsdisambiguate them and so the problem of ambiguityis greatly reduced.4 Learning Typed Entailment GraphsOur learning algorithm is composed of two steps:(1) Given a set of typed predicates and their in-stances extracted from a corpus, we train a (local)entailment classifier that estimates for every pair ofpredicates whether one entails the other.
(2) Usingthe classifier scores we perform global optimization,i.e., learn the set of edges over the nodes that maxi-mizes the global score of the graph under transitivityand background-knowledge constraints.Section 4.1 describes the local classifier training612province of(place,country)be part of(place,country)annex(country,place)invade(country,place)be relate to(drug,drug)be derive from(drug,drug)be process from(drug,drug)be convert into(drug,drug)Figure 1: Top: A fragment of a two-types entailmentgraph.
bottom: A fragment of a single-type entailmentgraph.
Mapping of solid edges is direct and of dashededges is reversed.procedure.
Section 4.2 gives an ILP formulation forthe optimization problem.
Sections 4.3 and 4.4 pro-pose scaling techniques that exploit graph sparsityto optimally solve larger graphs.4.1 Training an entailment classifierSimilar to the work of Berant et al (2010), weuse ?distant supervision?.
Given a lexicographic re-source (WordNet) and a set of predicates with theirinstances, we perform the following three steps (seeTable 1):1) Training set generation We use WordNet togenerate positive and negative examples, where eachexample is a pair of predicates.
Let P be theset of input typed predicates.
For every predicatep(t1, t2) ?
P such that p is a single word, we extractfrom WordNet the set S of synonyms and direct hy-pernyms of p. For every p?
?
S, if p?
(t1, t2) ?
Pthen p(t1, t2) ?
p?
(t1, t2) is taken as a positive ex-ample.Negative examples are generated in a similarmanner, with direct co-hyponyms of p (sister nodesin WordNet) and hyponyms at distance 2 instead ofsynonyms and direct hypernyms.
We also generatenegative examples by randomly sampling pairs oftyped predicates that share the same types.2) Feature representation Each example pair ofpredicates (p1, p2) is represented by a feature vec-tor, where each feature is a specific distributionalType examplehyper.
beat(team,team)?
play(team,team)syno.
reach(team,game)?
arrive at(team,game)cohypo.
invade(country,city) 9 bomb(country,city)hypo.
defeat(city,city) 9 eliminate(city,city)random hold(place,event) 9 win(place,event)Table 1: Automatically generated training set examples.similarity score estimating whether p1 entails p2.We compute 11 distributional similarity scores foreach pair of predicates based on the arguments ap-pearing in the extracted arguments.
The first 6scores are computed by trying all combinations ofthe similarity functions Lin and BInc with the fea-ture representations unary, binary-DIRT and binary(see Section 2).
The other 5 scores were providedby Schoenmackers et al (2010) and include SR(Schoenmackers et al, 2010), LIME (McCreath andSharma, 1997), M-estimate (Dzeroski and Brakto,1992), the standard G-test and a simple implementa-tion of Cover (Weeds and Weir, 2003).
Overall, therationale behind this representation is that combin-ing various scores will yield a better classifier thaneach single measure.3) Training We train over an equal number ofpositive and negative examples, as classifiers tend toperform poorly on the minority class when trainedon imbalanced data (Van Hulse et al, 2007; Nikulin,2008).4.2 ILP formulationOnce the classifier is trained, we would like to learnall edges (entailment rules) of each typed entailmentgraph.
Given a set of predicates V and an entail-ment score function f : V ?
V ?
R derived fromthe classifier, we want to find a graph G = (V,E)that respects transitivity and maximizes the sum ofedge weights?
(u,v)?E f(u, v).
This problem isNP-hard by a reduction from the NP-hard TransitiveSubgraph problem (Yannakakis, 1978).
Thus, em-ploying ILP is an appealing approach for obtainingan optimal solution.For two-types entailment graphs the formulationis simple: The ILP variables are indicators Xuv de-noting whether an edge (u, v) is in the graph, withthe following ILP:613G?
= argmax?u6=vf(u, v) ?Xuv (1)s.t.
?u,v,w?V Xuv +Xvw ?Xuw ?
1 (2)?u,v?Ayes Xuv = 1 (3)?u,v?Ano Xuv = 0 (4)?u6=v Xuv ?
{0, 1} (5)The objective in Eq.
1 is a sum over the weightsof the eventual edges.
The constraint in Eq.
2 statesthat edges must respect transitivity.
The constraintsin Eq.
3 and 4 state that for known node pairs, de-fined by Ayes and Ano, we have background knowl-edge indicating whether entailment holds or not.
Weelaborate on how Ayes and Ano were constructed inSection 5.
For a graph with n nodes we get n(n?1)variables and n(n?1)(n?2) transitivity constraints.The simplest way to expand this formulation forsingle-type graphs is to duplicate each predicatenode, with one node for each order of the types, andthen the ILP is unchanged.
However, this is inef-ficient as it results in an ILP with 2n(2n ?
1) vari-ables and 2n(2n?1)(2n?2) transitivity constraints.Since our main goal is to scale the use of ILP, wemodify it a little.
We denote a direct-mapping edge(u, v) by the indicator Xuv and a reversed-mappingedge (u, v) by Yuv.
The functions fd and fr providescores for direct and reversed mappings respectively.The objective in Eq.
1 and the constraint in Eq.
2 arereplaced by (Eq.
3, 4 and 5 still exist and are carriedover in a trivial manner):argmax?u6=vfd(u, v)Xuv +?u,vfr(u, v)Yuv (6)s.t.
?u,v,w?V Xuv +Xvw ?Xuw ?
1?u,v,w?V Xuv + Yvw ?
Yuw ?
1?u,v,w?V Yuv +Xvw ?
Yuw ?
1?u,v,w?V Yuv + Yvw ?Xuw ?
1The modified constraints capture the transitivitybehavior of direct-mapping and reversed-mappingedges, as described in Section 3.
This results in2n2 ?
n variables and about 4n3 transitivity con-straints, cutting the ILP size in half.Next, we specify how to derive the function ffrom the trained classifier using a probabilistic for-mulation4.
Following Snow et al (2006) and Be-rant et al (2010), we utilize a probabilistic entail-ment classifier that computes the posterior Puv =P (Xuv = 1|Fuv).
We want to use Puv to derive theposterior P (G|F ), where F = ?u6=vFuv and Fuv isthe feature vector for a node pair (u, v).Since the classifier was trained on a balancedtraining set, the prior over the two entailmentclasses is uniform and so by Bayes rule Puv ?P (Fuv|Xuv = 1).
Using that and the exact samethree independence assumptions described by Snowet al (2006) and Berant et al (2010) we can showthat (for brevity, we omit the full derivation):G?
= argmaxG logP (G|F ) = (7)argmax?u6=v(logPuv ?
P (Xuv = 1)(1?
Puv)P (Xuv = 0))Xuv= argmax?u6=v(logPuv1?
Puv)Xuv + log ?
?
|E|where ?
= P (Xuv=1)P (Xuv=0) is the prior odds ratio foran edge in the graph.
Comparing Eq.
1 and 7 wesee that f(u, v) = log Puv ?P (Xuv=1)(1?Puv)P (Xuv=0) .
Note that fis composed of a likelihood component and an edgeprior expressed by P (Xuv = 1), which we assumeto be some constant.
This constant is a parameterthat affects graph sparsity and controls the trade-offbetween recall and precision.Next, we show how sparsity is exploited to scalethe use of ILP solvers.
We discuss two-types entail-ment graphs, but generalization is simple.4.3 Graph decompositionThough ILP solvers provide an optimal solution,they substantially restrict the size of graphs we canwork with.
The number of constraints is O(n3),and solving graphs of size > 50 is often not feasi-ble.
To overcome this, we take advantage of graphsparsity: most predicates in language do not entailone another.
Thus, it might be possible to decom-pose graphs into small components and solve each4We describe two-types graphs but extending to single-typegraphs is straightforward.614Algorithm 1 Decomposed-ILPInput: A set V and a function f : V ?
V ?
ROutput: An optimal set of directed edges E?1: E?
= {(u, v) : f(u, v) > 0 ?
f(v, u) > 0}2: V1, V2, ..., Vk ?
connected components ofG?
= (V,E?
)3: for i = 1 to k do4: Ei ?
ApplyILPSolve(Vi,f)5: end for6: E?
?
?ki=1Eicomponent separately.
This is formalized in the nextproposition.Proposition 1.
If we can partition a set of nodesV into disjoint sets U,W such that for any cross-ing edge (u,w) between them (in either direction),f(u,w) < 0, then the optimal set of edgesEopt doesnot contain any crossing edge.Proof Assume by contradiction that Eopt con-tains a set of crossing edges Ecross.
We canconstruct Enew = Eopt \ Ecross.
Clearly?
(u,v)?Enew f(u, v) >?
(u,v)?Eopt f(u, v), asf(u, v) < 0 for any crossing edge.Next, we show that Enew does not violate tran-sitivity constraints.
Assume it does, then the viola-tion is caused by omitting the edges in Ecross.
Thus,there must be a node u ?
U and w ?
W (w.l.o.g)such that for some node v, (u, v) and (v, w) are inEnew, but (u,w) is not.
However, this means either(u, v) or (v, w) is a crossing edge, which is impossi-ble since we omitted all crossing edges.
Thus, Enewis a better solution than Eopt, contradiction.This proposition suggests a simple algorithm (seeAlgorithm 1): Add to the graph an undirected edgefor any node pair with a positive score, then find theconnected components, and apply an ILP solver overthe nodes in each component.
The edges returnedby the solver provide an optimal (not approximate)solution to the optimization problem.The algorithm?s complexity is dominated by theILP solver, as finding connected components takesO(V 2) time.
Thus, efficiency depends on whetherthe graph is sparse enough to be decomposed intosmall components.
Note that the edge prior plays animportant role: low values make the graph sparserand easier to solve.
In Section 5 we empirically testAlgorithm 2 Incremental-ILPInput: A set V and a function f : V ?
V ?
ROutput: An optimal set of directed edges E?1: ACT,VIO?
?2: repeat3: E?
?
ApplyILPSolve(V,f,ACT)4: VIO?
violated(V,E?
)5: ACT?
ACT ?
VIO6: until |VIO| = 0how typed entailment graphs benefit from decompo-sition given different prior values.From a more general perspective, this algo-rithm can be applied to any problem of learninga sparse transitive binary relation.
Such problemsinclude Co-reference Resolution (Finkel and Man-ning, 2008) and Temporal Information Extraction(Ling and Weld, 2010).
Last, the algorithm can beeasily parallelized by solving each component on adifferent core.4.4 Incremental ILPAnother solution for scaling ILP is to employ in-cremental ILP, which has been used in dependencyparsing (Riedel and Clarke, 2006).
The idea isthat even if we omit the transitivity constraints, westill expect most transitivity constraints to be satis-fied, given a good local entailment classifier.
Thus,it makes sense to avoid specifying the constraintsahead of time, but rather add them when they areviolated.
This is formalized in Algorithm 2.Line 1 initializes an active set of constraints and aviolated set of constraints (ACT;VIO).
Line 3 appliesthe ILP solver with the active constraints.
Lines 4and 5 find the violated constraints and add them tothe active constraints.
The algorithm halts when noconstraints are violated.
The solution is clearly op-timal since we obtain a maximal solution for a less-constrained problem.A pre-condition for using incremental ILP is thatcomputing the violated constraints (Line 4) is effi-cient, as it occurs in every iteration.
We do that ina straightforward manner: For every node v, andedges (u, v) and (v, w), if (u,w) /?
E?
we add(u, v, w) to the violated constraints.
This is cubicin worst-case but assuming the degree of nodes isbounded by a constant it is linear, and performs very615fast in practice.Combining Incremental-ILP and Decomposed-ILP is easy: We decompose any large graph intoits components and apply Incremental ILP on eachcomponent.
We applied this algorithm on our evalu-ation data set (Section 5) and found that it convergesin at most 6 iterations and that the maximal num-ber of active constraints in large graphs drops from?
106 to ?
103 ?
104.5 Experimental EvaluationIn this section we empirically answer the follow-ing questions: (1) Does transitivity improve rulelearning over typed predicates?
(Section 5.1) (2)Do Decomposed-ILP and Incremental-ILP improvescalability?
(Section 5.2)5.1 Experiment 1A data set of 1 million TextRunner tuples (Bankoet al, 2007), mapped to 10,672 distinct typed predi-cates over 156 types was provided by Schoenmack-ers et al (2010).
Readers are referred to their pa-per for details on mapping of tuples to typed predi-cates.
Since entailment only occurs between pred-icates that share the same types, we decomposedpredicates by their types (e.g., all predicates with thetypes place and disease) into 2,303 typed entailmentgraphs.
The largest graph contains 118 nodes andthe total number of potential rules is 263,756.We generated a training set by applying the proce-dure described in Section 4.1, yielding 2,644 exam-ples.
We used SVMperf (Joachims, 2005) to train aGaussian kernel classifier and computed Puv by pro-jecting the classifier output score, Suv, with the sig-moid function: Puv = 11+exp(?Suv) .
We tuned twoSVM parameters using 5-fold cross validation and adevelopment set of two typed entailment graphs.Next, we used our algorithm to learn rules.
Asmentioned in Section 4.2, we integrate backgroundknowledge using the sets Ayes and Ano that containpredicate pairs for which we know whether entail-ment holds.
Ayes was constructed with syntacticrules: We normalized each predicate by omitting thefirst word if it is a modal and turning passives to ac-tives.
If two normalized predicates are equal they aresynonymous and inserted into Ayes.
Ano was con-structed from 3 sources (1) Predicates differing by asingle pair of words that are WordNet antonyms (2)Predicates differing by a single word of negation (3)Predicates p(t1, t2) and p(t2, t1) where p is a transi-tive verb (e.g., beat) in VerbNet (Kipper-Schuler etal., 2000).We compared our algorithm (termed ILPscale) tothe following baselines.
First, to 10,000 rules re-leased by Schoenmackers et al (2010) (Sherlock),where the LHS contains a single predicate (Schoen-mackers et al released 30,000 rules but 20,000 ofthose have more than one predicate on the LHS,see Section 2), as we learn rules over the same dataset.
Second, to distributional similarity algorithms:(a) SR: the score used by Schoenmackers et al aspart of the Sherlock system.
(b) DIRT: (Lin andPantel, 2001) a widely-used rule learning algorithm.
(c) BInc: (Szpektor and Dagan, 2008) a directionalrule learning algorithm.
Third, we compared to theentailment classifier with no transitivity constraints(clsf ) to see if combining distributional similarityscores improves performance over single measures.Last, we added to all baselines background knowl-edge with Ayes and Ano (adding the subscript Xk totheir name).To evaluate performance we manually annotatedall edges in 10 typed entailment graphs - 7 two-types entailment graphs containing 14, 22, 30, 53,62, 86 and 118 nodes, and 3 single-type entailmentgraphs containing 7, 38 and 59 nodes.
This annota-tion yielded 3,427 edges and 35,585 non-edges, re-sulting in an empirical edge density of 9%.
We eval-uate the algorithms by comparing the set of edgeslearned by the algorithms to the gold standard edges.Figure 2 presents the precision-recall curve of thealgorithms.
The curve is formed by varying a scorethreshold in the baselines and varying the edge priorin ILPscale5.
For figure clarity, we omit DIRT andSR, since BInc outperforms them.Table 2 shows micro-recall, precision and F1 atthe point of maximal F1, and the Area Under theCurve (AUC) for recall in the range of 0-0.45 for allalgorithms, given background knowledge (knowl-edge consistently improves performance by a fewpoints for all algorithms).
The table also shows re-sults for the rules from Sherlockk.5we stop raising the prior when run time over the graphsexceeds 2 hours.
Often when the solver does not terminate in 2hours, it also does not terminate after 24 hours or more.61600 .
20 .
40 .
60 .
810 0 .
1 0 .
2 0 .
3 0 .
4 0 .
5 0 .
6 0 .
7 0 .
8 0 .
9precisionrecallBIncclsfBInc_kclsf_kILP_scaleFigure 2: Precision-recall curve for the algorithms.micro-averageR (%) P (%) F1 (%) AUCILPscale 43.4 42.2 42.8 0.22clsfk 30.8 37.5 33.8 0.17Sherlockk 20.6 43.3 27.9 N/ABInck 31.8 34.1 32.9 0.17SRk 38.4 23.2 28.9 0.14DIRTk 25.7 31.0 28.1 0.13Table 2: micro-average F1 and AUC for the algorithms.Results show that using global transitivityinformation substantially improves performance.ILPscale is better than all other algorithms by a largemargin starting from recall .2, and improves AUCby 29% and the maximal F1 by 27%.
Moreover,ILPscale doubles recall comparing to the rules fromthe Sherlock resource, while maintaining compara-ble precision.5.2 Experiment 2We want to test whether using our scaling tech-niques, Decomposed-ILP and Incremental-ILP, al-lows us to reach the optimal solution in graphs thatotherwise we could not solve, and consequently in-crease the number of learned rules and the overallrecall.
To check that, we run ILPscale, with and with-out these scaling techniques (termed ILP?
).We used the same data set as in Experiment 1and learned edges for all 2,303 entailment graphsin the data set.
If the ILP solver was unable tohold the ILP in memory or took more than 2 hourslog ?
# unlearned # rules 4 Red.-1.75 9/0 6,242 / 7,466 20% 75%-1 9/1 16,790 / 19,396 16% 29%-0.6 9/3 26,330 / 29,732 13% 14%Table 3: Impact of scaling techinques (ILP?/ILPscale).for some graph, we did not attempt to learn itsedges.
We ran ILPscale and ILP?
in three den-sity modes to examine the behavior of the algo-rithms for different graph densities: (a) log ?
=?0.6: the configuration that achieved the bestrecall/precision/F1 of 43.4/42.2/42.8.
(b) log ?
=?1 with recall/precision/F1 of 31.8/55.3/40.4.
(c)log ?
= ?1.75: A high precision configuration withrecall/precision/F1 of 0.15/0.75/0.23 6.In each run we counted the number of graphs thatcould not be learned and the number of rules learnedby each algorithm.
In addition, we looked at the20 largest graphs in our data (49-118 nodes) andmeasured the ratio r between the size of the largestcomponent after applying Decomposed-ILP and theoriginal size of the graph.
We then computed the av-erage 1?r over the 20 graphs to examine how graphsize drops due to decomposition.Table 3 shows the results.
Column # unlearnedand # rules describe the number of unlearned graphsand the number of learned rules.
Column 4 showsrelative increase in the number of rules learned andcolumn Red.
shows the average 1?
r.ILPscale increases the number of graphs that weare able to learn: in our best configuration (log ?
=?0.6) only 3 graphs could not be handled com-paring to 9 graphs when omitting our scaling tech-niques.
Since the unlearned graphs are among thelargest in the data set, this adds 3,500 additionalrules.
We compared the precision of rules learnedonly by ILPscale with that of the rules learned byboth, by randomly sampling 100 rules from each andfound precision to be comparable.
Thus, the addi-tional rules learned translate into a 13% increase inrelative recall without harming precision.Also note that as density increases, the number ofrules learned grows and the effectiveness of decom-position decreases.
This shows how Decomposed-ILP is especially useful for sparse graphs.
We re-6Experiment was run on an Intel i5 CPU with 4GB RAM.617lease the 29,732 rules learned by the configurationlog ?
= ?0.6 as a resource.To sum up, our scaling techniques allow us tolearn rules from graphs that standard ILP can nothandle and thus considerably increase recall withoutharming precision.6 Conclusions and Future WorkThis paper proposes two contributions over two re-cent works: In the first, Berant et al (2010) pre-sented a global optimization procedure to learn en-tailment rules between predicates using transitivity,and applied this algorithm over small graphs whereall predicates have one argument instantiated by atarget concept.
Consequently, the rules they learnare of limited applicability.
In the second, Schoen-mackers et al learned rules of wider applicability byusing typed predicates, but utilized a local approach.In this paper we developed an algorithm that usesglobal optimization to learn widely-applicable en-tailment rules between typed predicates (where botharguments are variables).
This was achieved byappropriately defining entailment graphs for typedpredicates, formulating an ILP representation forthem, and introducing scaling techniques that in-clude graph decomposition and incremental ILP.Our algorithm is guaranteed to provide an optimalsolution and we have shown empirically that it sub-stantially improves performance over Schoenmack-ers et al?s recent resource and over several baselines.In future work, we aim to scale the algorithmfurther and learn entailment rules between untypedpredicates.
This would require explicit modeling ofpredicate ambiguity and using approximation tech-niques when an optimal solution cannot be attained.AcknowledgmentsThis work was performed with financial supportfrom the Turing Center at The University of Wash-ington during a visit of the first author (NSF grantIIS-0803481).
We deeply thank Oren Etzioni andStefan Schoenmackers for providing us with the datasets for this paper and for numerous helpful discus-sions.
We would also like to thank the anonymousreviewers for their useful comments.
This workwas developed under the collaboration of FBK-irst/University of Haifa and was partially supportedby the Israel Science Foundation grant 1112/08.
Thefirst author is grateful to IBM for the award of anIBM Fellowship, and has carried out this researchin partial fulllment of the requirements for the Ph.D.degree.ReferencesJ.
Fillmore Baker, C. F. and J.
B. Lowe.
1998.
TheBerkeley framenet project.
In Proc.
of COLING-ACL.Michele Banko, Michael Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open in-formation extraction from the web.
In Proceedings ofIJCAI.Roni Ben Aharon, Idan Szpektor, and Ido Dagan.
2010.Generating entailment rules from framenet.
In Pro-ceedings of ACL.Jonathan Berant, Ido Dagan, and Jacob Goldberger.2010.
Global learning of focused entailment graphs.In Proceedings of ACL.Rahul Bhagat, Patrick Pantel, and Eduard Hovy.
2007.LEDIR: An unsupervised algorithm for learning di-rectionality of inference rules.
In Proceedings ofEMNLP-CoNLL.James Clarke and Mirella Lapata.
2008.
Global infer-ence for sentence compression: An integer linear pro-gramming approach.
Journal of Artificial IntelligenceResearch, 31:273?381.Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth.2009.
Recognizing textual entailment: Rational, eval-uation and approaches.
Natural Language Engineer-ing, 15(4):1?17.Quang Do and Dan Roth.
2010.
Constraints basedtaxonomic relation classification.
In Proceedings ofEMNLP.Saso Dzeroski and Ivan Brakto.
1992.
Handling noisein inductive logic programming.
In Proceedings of theInternational Workshop on Inductive Logic Program-ming.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (Language, Speech, and Com-munication).
The MIT Press.Jenny Rose Finkel and Christopher D. Manning.
2008.Enforcing transitivity in coreference resolution.
InProceedings of ACL-08: HLT, Short Papers.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of COLING.Thorsten Joachims.
2005.
A support vector method formultivariate performance measures.
In Proceedings ofICML.Karin Kipper-Schuler, Hoa Trand Dang, and MarthaPalmer.
2000.
Class-based construction of verb lex-icon.
In Proceedings of AAAI/IAAI.618Dekang Lin and Patrick Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural LanguageEngineering, 7(4):343?360.Xiao Ling and Daniel S. Weld.
2010.
Temporal informa-tion extraction.
In Proceedings of AAAI.Catherine Macleod, Ralph Grishman, Adam Meyers,Leslie Barrett, and Ruth Reeves.
1998.
NOMLEX:A lexicon of nominalizations.
In Proceedings of COL-ING.Andre Martins, Noah Smith, and Eric Xing.
2009.
Con-cise integer linear programming formulations for de-pendency parsing.
In Proceedings of ACL.Eric McCreath and Arun Sharma.
1997.
ILP with noiseand fixed example size: a bayesian approach.
In Pro-ceedings of the Fifteenth international joint conferenceon artificial intelligence - Volume 2.Vladimir Nikulin.
2008.
Classification of imbalanceddata with random sets and mean-variance filtering.IJDWM, 4(2):63?78.Hoifung Poon and Pedro Domingos.
2010.
Unsuper-vised ontology induction from text.
In Proceedings ofACL.Sebastian Riedel and James Clarke.
2006.
Incrementalinteger linear programming for non-projective depen-dency parsing.
In Proceedings of EMNLP.Stefan Schoenmackers, Oren Etzioni Jesse Davis, andDaniel S. Weld.
2010.
Learning first-order hornclauses from web text.
In Proceedings of EMNLP.Satoshi Sekine.
2005.
Automatic paraphrase discoverybased on context and keywords between ne pairs.
InProceedings of IWP.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenous evi-dence.
In Proceedings of ACL.Idan Szpektor and Ido Dagan.
2008.
Learning entailmentrules for unary templates.
In Proceedings of COLING.Idan Szpektor and Ido Dagan.
2009.
Augmentingwordnet-based inference with argument mapping.
InProceedings of TextInfer.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisition ofentailment relations.
In Proceedings of EMNLP.Jason Van Hulse, Taghi Khoshgoftaar, and Amri Napoli-tano.
2007.
Experimental perspectives on learningfrom imbalanced data.
In Proceedings of ICML.Julie Weeds and David Weir.
2003.
A general frame-work for distributional similarity.
In Proceedings ofEMNLP.Mihalis Yannakakis.
1978.
Node-and edge-deletion NP-complete problems.
In STOC ?78: Proceedings of thetenth annual ACM symposium on Theory of comput-ing, pages 253?264, New York, NY, USA.
ACM.Alexander Yates and Oren Etzioni.
2009.
Unsupervisedmethods for determining object and relation synonymson the web.
Journal of Artificial Intelligence Research,34:255?296.619
