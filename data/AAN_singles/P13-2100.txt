Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 561?566,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsUsing Integer Linear Programming in Concept-to-Text Generation toProduce More Compact TextsGerasimos Lampouras and Ion AndroutsopoulosDepartment of InformaticsAthens University of Economics and BusinessPatission 76, GR-104 34 Athens, Greecehttp://nlp.cs.aueb.gr/AbstractWe present an ILP model of concept-to-text generation.
Unlike pipeline archi-tectures, our model jointly considers thechoices in content selection, lexicaliza-tion, and aggregation to avoid greedy de-cisions and produce more compact texts.1 IntroductionConcept-to-text natural language generation(NLG) generates texts from formal knowledgerepresentations (Reiter and Dale, 2000).
With theemergence of the Semantic Web (Antoniou andvan Harmelen, 2008), interest in concept-to-textNLG has been revived and several methodshave been proposed to express axioms of OWLontologies (Grau et al, 2008) in natural language(Bontcheva, 2005; Mellish and Sun, 2006; Gala-nis and Androutsopoulos, 2007; Mellish and Pan,2008; Schwitter et al, 2008; Schwitter, 2010;Liang et al, 2011; Williams et al, 2011).NLG systems typically employ a pipeline archi-tecture.
They usually start by selecting the logi-cal facts to express.
The next stage, text planning,ranges from simply ordering the selected facts tocomplex decisions about the rhetorical structureof the text.
Lexicalization then selects the wordsand syntactic structures that will realize each fact,specifying how each fact can be expressed as asingle sentence.
Sentence aggregation then com-bines sentences into longer ones.
Another compo-nent generates appropriate referring expressions,and surface realization produces the final text.Each stage of the pipeline is treated as a lo-cal optimization problem, where the decisions ofthe previous stages cannot be modified.
This ar-rangement produces texts that may not be optimal,since the decisions of the stages have been shownto be co-dependent (Danlos, 1984; Marciniak andStrube, 2005; Belz, 2008).
For example, contentselection and lexicalization may lead to more orfewer sentence aggregation opportunities.We present an Integer Linear Programming(ILP) model that combines content selection, lex-icalization, and sentence aggregation.
Our modeldoes not consider text planning, nor referring ex-pression generation, which we hope to include infuture work, but it is combined with an externalsimple text planner and a referring expression gen-eration component; we also do not discuss sur-face realization.
Unlike pipeline architectures, ourmodel jointly examines the possible choices in thethree NLG stages it considers, to avoid greedy localdecisions.
Given an individual (entity) or class ofan OWL ontology and a set of facts (OWL axioms)about the individual or class, we aim to produce atext that expresses as many of the facts in as fewwords as possible.
This is important when space islimited or expensive (e.g., product descriptions onsmartphones, advertisements in search engines).Although the search space of our model is verylarge and ILP problems are in general NP-hard, ILPsolvers can be used, they are very fast in practice,and they guarantee finding a global optimum.
Ex-periments show that our ILP model outperforms,in terms of compression, an NLG system that usesthe same components, but connected in a pipeline,with no deterioration in fluency and clarity.2 Related workMarciniak and Strube (2005) propose a generalILP approach for language processing applicationswhere the decisions of classifiers that considerparticular, but co-dependent, subtasks need to becombined.
They also show how their approachcan be used to generate multi-sentence route di-rections, in a setting with very different inputs andprocessing stages than the ones we consider.Barzilay and Lapata (2005) treat content selec-tion as an optimization problem.
Given a pool offacts and scores indicating the importance of each561fact or pair of facts, they select the facts to expressby formulating an optimization problem similarto energy minimization.
In other work, Barzilayand Lapata (2006) consider sentence aggregation.Given a set of facts that a content selection stagehas produced, aggregation is viewed as the prob-lem of partitioning the facts into optimal subsets.Sentences expressing facts that are placed in thesame subset are aggregated to form a longer sen-tence.
An ILP model is used to find the partitioningthat maximizes the pairwise similarity of the factsin each subset, subject to constraints limiting thenumber of subsets and the facts in each subset.Althaus et al (2004) show that ordering a setof sentences to maximize sentence-to-sentence co-herence is equivalent to the traveling salesmanproblem and, hence, NP-complete.
They also showhow an ILP solver can be used in practice.Joint optimization ILP models have also beenused in multi-document text summarization andsentence compression (McDonald, 2007; Clarkeand Lapata, 2008; Berg-Kirkpatrick et al, 2011;Galanis et al, 2012; Woodsend and Lapata, 2012),where the input is text, not formal knowledge rep-resetations.
Statistical methods to jointly performcontent selection, lexicalization, and surface real-ization have also been proposed in NLG (Liang etal., 2009; Konstas and Lapata, 2012a; Konstas andLapata, 2012b), but they are currently limited togenerating single sentences from flat records.To the best of our knowledge, this article is thefirst one to consider content selection, lexicaliza-tion, and sentence aggregation as an ILP joint opti-mization problem in the context of multi-sentenceconcept-to-text generation.
It is also the first arti-cle to consider ILP in NLG from OWL ontologies.3 Our ILP model of NLGLet F = {f1, .
.
.
, fn} be the set of all the facts fi(OWL axioms) about the individual or class to bedescribed.
OWL axioms can be represented as setsof RDF triples of the form ?S,R,O?, where S is anindividual or class, O is another individual, class,or datatype value, and R is a relation (property)that connects S to O.
Hence, we can assume thateach fact fi is a triple ?Si, Ri, Oi?.1For each fact fi, a set Pi = {pi1, pi2, .
.
.
}of alternative sentence plans is available.
Each1We actually convert the RDF triples to simpler messagetriples, so that each message triple can be easily expressed bya simple sentence, but we do not discuss this conversion here.sentence plan pik specifies how to express fi =?Si, Ri, Oi?
as an alternative single sentence.
Inour work, a sentence plan is a sequence of slots,along with instructions specifying how to fill theslots in; and each sentence plan is associatedwith the relations it can express.
For example,?exhibit12,foundIn,athens?
could be ex-pressed using a sentence plan like ?
[ref (S)][findpast] [in] [ref (O)]?, where square bracketsdenote slots, ref (S) and ref (O) are instructionsrequiring referring expressions for S and O inthe corresponding slots, and ?findpast?
requires thesimple past form of ?find?.
In our example, thesentence plan would lead to a sentence like ?Ex-hibit 12 was found in Athens?.
We call elementsthe slots with their instructions, but with ?S?and ?O?
accompanied by the individuals, classes,or datatype values they refer to; in our exam-ple, the elements are ?
[ref (S: exhibit12)]?,?
[findpast]?, ?
[in]?, ?
[ref (O: athens)]?.
Dif-ferent sentence plans may lead to more or feweraggregation opportunities; for example, sentenceswith the same verb are easier to aggregate.
We useaggregation rules (Dalianis, 1999) that operate onsentence plans and usually lead to shorter texts.Let s1, .
.
.
, sm be disjoint subsets of F , eachcontaining 0 to n facts, with m < n. A singlesentence is generated for each subset sj by aggre-gating the sentences (more precisely, the sentenceplans) expressing the facts of sj .2 An empty sjgenerates no sentence, i.e., the resulting text canbe at most m sentences long.
Let us also define:ai ={1, if fact fi is selected0, otherwise (1)likj =??
?1, if sentence plan pik is used to expressfact fi, and fi is in subset sj0, otherwise(2)btj ={1, if element et is used in subset sj0, otherwise (3)and let B be the set of all the distinct elements (noduplicates) from all the available sentence plansthat can express the facts of F .
The length of anaggregated sentence resulting from a subset sj canbe roughly estimated by counting the distinct el-ements of the sentence plans that have been cho-sen to express the facts of sj ; elements that occurmore than once in the chosen sentence plans of sj2All the sentences of every possible subset sj can be ag-gregated, because all the sentences share the same subject,the class or individual being described.
If multiple aggrega-tion rules apply, we use the one that leads to a shorter text.562are counted only once, because they will probablybe expressed only once, due to aggregation.Our objective function (4) maximizes the num-ber of selected facts fi and minimizes the numberof distinct elements in each subset sj , i.e., the ap-proximate length of the corresponding aggregatedsentence; an alternative explanation is that by min-imizing the number of distinct elements in each sj ,we favor subsets that aggregate well.
By a and bwe jointly denote all the ai and btj variables.
Thetwo parts (sums) of the objective function are nor-malized to [0, 1] by dividing by the total numberof available facts |F | and the number of subsets mtimes the total number of distinct elements |B|.
Inthe first part of the objective, we treat all the factsas equally important; if importance scores are alsoavailable for the facts, they can be added as mul-tipliers of ?i.
The parameters ?1 and ?2 are usedto tune the priority given to expressing many factsvs.
generating shorter texts; we set ?1 + ?2 = 1.maxa,b?1 ?|F |?i=1ai|F | ?
?2 ?m?j=1|B|?t=1btjm ?
|B| (4)subject to:ai =m?j=1|Pi|?k=1likj , for i = 1, .
.
.
, n (5)?et?Bikbtj ?
|Bik| ?
likj , fori = 1, .
.
.
, nj = 1, .
.
.
,mk = 1, .
.
.
, |Pi|(6)?pik?P (et)likj ?
btj , for t = 1, .
.
.
, |B|j = 1, .
.
.
,m (7)|B|?t=1btj ?
Bmax, for j = 1, .
.
.
,m (8)|Pi|?k=1likj +|Pi?
|?k?=1li?k?j ?
1, forj = 1, .
.
.
,m, i = 2, .
.
.
, ni?
= 1, .
.
.
, n?
1; i 6= i?section(fi) 6= section(f ?i)(9)Constraint 5 ensures that for each selected fact,only one sentence plan in only one subset is se-lected; if a fact is not selected, no sentence planfor the fact is selected either.
|?| denotes the car-dinality of a set ?.
In constraint 6, Bik is the set ofdistinct elements et of the sentence plan pik.
Thisconstraint ensures that if pik is selected in a subsetsj , then all the elements of pik are also present insj .
If pik is not selected in sj , then some of its el-ements may still be present in sj , if they appear inanother selected sentence plan of sj .In constraint 7, P (et) is the set of sentence plansthat contain element et.
If et is used in a subset sj ,then at least one of the sentence plans of P (et)must also be selected in sj .
If et is not used in sj ,then no sentence plan of P (et) may be selected insj .
Lastly, constraint 8 limits the number of ele-ments that a subset sj can contain to a maximumallowed number Bmax, in effect limiting the max-imum length of an aggregated sentence.We assume that each relation R has been man-ually mapped to a single topical section; e.g., re-lations expressing the color, body, and flavor ofa wine may be grouped in one section, and rela-tions about the wine?s producer in another.
Thesection of a fact fi = ?Si, Ri, Oi?
is the sectionof its relation Ri.
Constraint 9 ensures that factsfrom different sections will not be placed in thesame subset sj , to avoid unnatural aggregations.4 ExperimentsWe used NaturalOWL (Galanis and Androutsopou-los, 2007; Galanis et al, 2009; Androutsopouloset al, 2013), an NLG system for OWL ontologiesthat relies on a pipeline of content selection, textplanning, lexicalization, aggregation, referring ex-pression generation, and surface realization.3 Wemodified content selection, lexicalization, and ag-gregation to use our ILP model, maintaining theaggregation rules of the original system.4 For re-ferring expression generation and surface realiza-tion, the new system, called ILPNLG, invokes thecorresponding components of NaturalOWL.The original system, called PIPELINE, assumesthat each relation has been mapped to a topicalsection, as in ILPNLG.
It also assumes that a man-ually specified order of the sections and the rela-tions of each section is available, which is usedby the text planner to order the selected facts (bytheir relations).
The subsequent components of thepipeline are not allowed to change the order of thefacts, and aggregation operates only on sentenceplans of adjacent facts from the same section.
InILPNLG, the manually specified order of sectionsand relations is used to order the sentences of eachsubset sj (before aggregating them), the aggre-gated sentences in each section (each aggregatedsentence inherits the minimum order of its con-stituents), and the sections (with their sentences).We used the Wine Ontology, which had been3All the software and data we used are freely availablefrom http://nlp.cs.aueb.gr/software.html.We use version 2 of NaturalOWL.4We use the Branch and Cut implementation of GLPK; seesourceforge.net/projects/winglpk/.563used in previous experiments with PIPELINE.5 Wekept the 2 topical sections, the ordering of sec-tions and relations, and the sentence plans thathad been used in the previous experiments, but weadded more sentence plans to ensure that 3 sen-tence plans were available per fact.
We gener-ated texts for the 52 wine individuals of the on-tology; we did not experiment with texts describ-ing classes of wines, because we could not thinkof multiple alternative sentence plans for many oftheir axioms.
For each individual, there were 5facts on average and a maximum of 6 facts.PIPELINE has a parameter M specifying themaximum number of facts it is allowed to reportper text.
When M is smaller than the number ofavailable facts |F | and all the facts are treated asequally important, as in our experiments, it se-lects randomly M of the available facts.
We re-peated the generation of PIPELINE?s texts for the52 individuals for M = 2, 3, 4, 5, 6.
For each M ,the texts of PIPELINE for the 52 individuals weregenerated three times, each time using one of thedifferent alternative sentence plans of each rela-tion.
We also generated the texts using a variant ofPIPELINE, dubbed PIPELINESHORT, which alwaysselects the shortest (in elements) sentence planamong the available ones.
In all cases, PIPELINEand PIPELINESHORT were allowed to form ag-gregated sentences containing up to Bmax = 22distinct elements, which was the number of dis-tinct elements of the longest aggregated sentencein the previous experiments, where PIPELINE wasallowed to aggregate up to 3 original sentences.With ILPNLG, we repeated the generation of thetexts of the 52 individuals using different valuesof ?1 (?2 = 1 ?
?1), which led to texts express-ing from zero to all of the available facts.
We setthe maximum number of fact subsets to m = 3,which was the maximum number of aggregatedsentences observed in the texts of PIPELINE andPIPELINESHORT.
Again, we set Bmax = 22.We compared ILPNLG to PIPELINE and PIPELI-NESHORT by measuring the average number offacts they reported divided by the average textlength (in words).
Figure 1 shows this ratio as afunction of the average number of reported facts,along with 95% confidence intervals (of samplemeans).
PIPELINESHORT achieved better resultsthan PIPELINE, but the differences were small.For ?1 < 0.2, ILPNLG produces empty texts,5See www.w3.org/TR/owl-guide/wine.rdf.Figure 1: Facts/words ratio of the generated texts.since it focuses on minimizing the number of dis-tinct elements of each text.
For ?1 ?
0.225, it per-forms better than the other systems.
For ?1 ?
0.3,it obtains the highest fact/words ratio by select-ing the facts and sentence plans that lead to themost compressive aggregations.
For greater val-ues of ?1, it selects additional facts whose sen-tence plans do not aggregate that well, which iswhy the ratio declines.
For small numbers of facts,the two pipeline systems select facts and sentenceplans that offer very few aggregation opportuni-ties; as the number of selected facts increases,some more aggregation opportunities arise, whichis why the facts/words ratio of the two systemsimproves.
In all the experiments, the ILP solverwas very fast (average: 0.08 sec, worst: 0.14 sec).Experiments with human judges also showed thatthe texts of ILPNLG cannot be distinguished fromthose of PIPELINESHORT in terms of fluency andtext clarity.
Hence, the highest compactness of thetexts of ILPNLG does not come at the expense oflower text quality.
Space does not permit a moredetailed description of these experiments.We show below texts produced by PIPELINE(M = 4) and ILPNLG (?1 = 0.3).PIPELINE: This is a strong Sauternes.
It is made from Semil-lon grapes and it is produced by Chateau D?ychem.ILPNLG: This is a strong Sauternes.
It is made from Semillongrapes by Chateau D?ychem.PIPELINE: This is a full Riesling and it has moderate flavor.It is produced by Volrad.ILPNLG: This is a full sweet moderate Riesling.In the first pair, PIPELINE uses different verbs forthe grapes and producer, whereas ILPNLG uses thesame verb, which leads to a more compressive ag-gregation; both texts describe the same wine andreport 4 facts.
In the second pair, ILPNLG has cho-sen to express the sweetness instead of the pro-ducer, and uses the same verb (?be?)
for all thefacts, leading to a shorter sentence; again bothtexts describe the same wine and report 4 facts.564In both examples, some facts are not aggregatedbecause they belong in different sections.5 ConclusionsWe presented an ILP model for NLG that jointlyconsiders the choices in content selection, lexical-ization, and aggregation to avoid greedy local de-cisions and produce more compact texts.
Exper-iments verified that our model can express morefacts per word, compared to a pipeline, which isimportant when space is scarce.
An off-the-shelfILP solver took approximately 0.1 sec for eachtext.
We plan to extend our model to include textplanning and referring expressions generation.AcknowledgmentsThis research has been co-financed by the Euro-pean Union (European Social Fund ?
ESF) andGreek national funds through the Operational Pro-gram ?Education and Lifelong Learning?
of theNational Strategic Reference Framework (NSRF)?
Research Funding Program: Heracleitus II.
In-vesting in knowledge society through the Euro-pean Social Fund.ReferencesE.
Althaus, N. Karamanis, and A. Koller.
2004.
Com-puting locally coherent discourses.
In 42nd AnnualMeeting of ACL, pages 399?406, Barcelona, Spain.I.
Androutsopoulos, G. Lampouras, and D. Gala-nis.
2013.
Generating natural language descrip-tions from OWL ontologies: the NaturalOWL sys-tem.
Technical report, Natural Language ProcessingGroup, Department of Informatics, Athens Univer-sity of Economics and Business.G.
Antoniou and F. van Harmelen.
2008.
A SemanticWeb primer.
MIT Press, 2nd edition.R.
Barzilay and M. Lapata.
2005.
Collective contentselection for concept-to-text generation.
In HLT-EMNLP, pages 331?338, Vancouver, BC, Canada.R.
Barzilay and M. Lapata.
2006.
Aggregation viaset partitioning for natural language generation.
InHLT-NAACL, pages 359?366, New York, NY.A.
Belz.
2008.
Automatic generation of weatherforecast texts using comprehensive probabilisticgeneration-space models.
Natural Language Engi-neering, 14(4):431?455.T.
Berg-Kirkpatrick, D. Gillick, and D. Klein.
2011.Jointly learning to extract and compress.
In 49thAnnual Meeting of ACL, pages 481?490, Portland,OR.K.
Bontcheva.
2005.
Generating tailored textual sum-maries from ontologies.
In 2nd European SemanticWeb Conf., pages 531?545, Heraklion, Greece.J.
Clarke and M. Lapata.
2008.
Global inference forsentence compression: An integer linear program-ming approach.
Journal of Artificial Intelligence Re-search, 1(31):399?429.H.
Dalianis.
1999.
Aggregation in natural languagegeneration.
Comput.
Intelligence, 15(4):384?414.L.
Danlos.
1984.
Conceptual and linguistic decisionsin generation.
In 10th COLING, pages 501?504,Stanford, CA.D.
Galanis and I. Androutsopoulos.
2007.
Generatingmultilingual descriptions from linguistically anno-tated OWL ontologies: the NaturalOWL system.
In11th European Workshop on Natural Lang.
Genera-tion, pages 143?146, Schloss Dagstuhl, Germany.D.
Galanis, G. Karakatsiotis, G. Lampouras, and I. An-droutsopoulos.
2009.
An open-source natural lan-guage generator for OWL ontologies and its use inProte?ge?
and Second Life.
In 12th Conf.
of the Euro-pean Chapter of ACL (demos), Athens, Greece.D.
Galanis, G. Lampouras, and I. Androutsopoulos.2012.
Extractive multi-document summarizationwith Integer Linear Programming and Support Vec-tor Regression.
In COLING, pages 911?926, Mum-bai, India.B.C.
Grau, I. Horrocks, B. Motik, B. Parsia, P. Patel-Schneider, and U. Sattler.
2008.
OWL 2: The nextstep for OWL.
Web Semantics, 6:309?322.I.
Konstas and M. Lapata.
2012a.
Concept-to-text gen-eration via discriminative reranking.
In 50th AnnualMeeting of ACL, pages 369?378, Jeju Island, Korea.I.
Konstas and M. Lapata.
2012b.
Unsupervisedconcept-to-text generation with hypergraphs.
InHLT-NAACL, pages 752?761, Montre?al, Canada.P.
Liang, M. Jordan, and D. Klein.
2009.
Learningsemantic correspondences with less supervision.
In47th Meeting of ACL and 4th AFNLP, pages 91?99,Suntec, Singapore.S.F.
Liang, R. Stevens, D. Scott, and A. Rector.
2011.Automatic verbalisation of SNOMED classes usingOntoVerbal.
In 13th Conf.
AI in Medicine, pages338?342, Bled, Slovenia.T.
Marciniak and M. Strube.
2005.
Beyond thepipeline: Discrete optimization in NLP.
In 9th Con-ference on Computational Natural Language Learn-ing, pages 136?143, Ann Arbor, MI.R.
McDonald.
2007.
A study of global inference al-gorithms in multi-document summarization.
In Eu-ropean Conference on Information Retrieval, pages557?564, Rome, Italy.565C.
Mellish and J.Z.
Pan.
2008.
Natural language di-rected inference from ontologies.
Artificial Intelli-gence, 172:1285?1315.C.
Mellish and X.
Sun.
2006.
The Semantic Web as alinguistic resource: opportunities for nat.
lang.
gen-eration.
Knowledge Based Systems, 19:298?303.E.
Reiter and R. Dale.
2000.
Building Natural Lan-guage Generation Systems.
Cambridge Univ.
Press.R.
Schwitter, K. Kaljurand, A. Cregan, C. Dolbear, andG.
Hart.
2008.
A comparison of three controllednat.
languages for OWL 1.1.
In 4th OWL Experi-ences and Directions Workshop, Washington DC.R.
Schwitter.
2010.
Controlled natural languages forknowledge representation.
In 23rd COLING, pages1113?1121, Beijing, China.S.
Williams, A.
Third, and R. Power.
2011.
Levelsof organization in ontology verbalization.
In 13thEuropean Workshop on Natural Lang.
Generation,pages 158?163, Nancy, France.K.
Woodsend and M. Lapata.
2012.
Multiple aspectsummarization using integer linear programming.
InEMNLP-CoNLL, pages 233?243, Jesu Island, Ko-rea.566
