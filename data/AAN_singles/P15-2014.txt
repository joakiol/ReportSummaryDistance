Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 83?88,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsUsing prosodic annotations to improve coreference resolutionof spoken textIna R?osiger and Arndt RiesterInstitute for Natural Language ProcessingUniversity of Stuttgart, GermanyPfaffenwaldring 5b, 70569 Stuttgartroesigia|arndt@ims.uni-stuttgart.deAbstractThis paper is the first to examine the effectof prosodic features on coreference resolu-tion in spoken discourse.
We test featuresfrom different prosodic levels and investi-gate which strategies can be applied.
Ourresults on the basis of manual prosodic la-belling show that the presence of an accentis a helpful feature in a machine-learningsetting.
Including prosodic boundaries anddetermining whether the accent is the nu-clear accent further increases results.1 IntroductionNoun phrase coreference resolution is the task ofdetermining which noun phrases (NPs) in a textor dialogue refer to the same discourse entities(Ng, 2010).
Coreference resolution has been ex-tensively addressed in NLP research, e.g.
in theCoNLL shared task 2012 (Pradhan et al, 2012)or in the SemEval shared task 2010 (Recasens etal., 2010).
Amoia et al (2012) have shown thatthere are differences between written and spokentext wrt coreference resolution and that the per-formance typically drops when systems that havebeen developed for written text are applied on spo-ken text.
There has been considerable work oncoreference resolution in written text, but com-paratively little work on spoken text, with a fewexceptions of systems for pronoun resolution intranscripts of spoken text e.g.
Strube and M?uller(2003), Tetreault and Allen (2004).
However,so far, prosodic information has not been takeninto account.
The interaction between prosodicprominence and coreference has been investigatedin several experimental and theoretical analyses(Terken and Hirschberg, 1994; Schwarzschild,1999; Cruttenden, 2006); for German (Baumannand Riester, 2013; Baumann and Roth, 2014; Bau-mann et al, 2015).There is a tendency for coreferent items, i.e.
en-tities that have already been introduced into thediscourse, to be deaccented, as the speaker as-sumes the entity to be salient in the listener?s dis-course model.
We can exploit this by includingprominence features in the coreference resolver.Our prosodic features mainly aim at definitedescriptions, where it is difficult for the resolverto decide whether the potential anaphor is actu-ally anaphoric or not.
In these cases, accentua-tion is an important means to distinguish betweengiven entities (often deaccented) and other cate-gories (i.e.
bridging anaphors, see below) that aretypically accented, particularly for entities whoseheads have a different lexeme than their potentialantecedent.
Pronouns are not the case of inter-est here, as they are (almost) always anaphoric.To make the intuitions clearer, Example (1), takenfrom Umbach (2002), shows the difference promi-nence can make:(1) John has an old cottage.1a.
Last year he reconstructed the SHED.b.
Last year he reconSTRUCted the shed.Due to the pitch accent on shed in (1a), it is quiteobvious that the shed and the cottage refer to dif-ferent entities; they exemplify a bridging relation,where the shed is a part of the cottage.
In (1b),however, the shed is deaccented, which has the ef-fect that the shed and the cottage corefer.We present a pilot study on German spokentext that uses manual prominence marking to showthe principled usefulness of prosodic features forcoreference resolution.
In the long run and forapplication-based settings, of course, we do notwant to rely on manual annotations.
This work isinvestigating the potential of prominence informa-tion and is meant to motivate the use of automatic1Anaphors are typed in boldface, their antecedents are un-derlined.
Accented syllables are capitalised.83prosodic features.
Our study deals with Germandata, but the prosodic properties are comparableto other West Germanic languages, like English orDutch.
To the best of our knowledge, this is thefirst work on coreference resolution in spoken textthat tests the theoretical claims regarding the inter-action between coreference and prominence in ageneral, state-of-the-art coreference resolver, andshows that prosodic features improve coreferenceresolution.2 Prosodic features for coreferenceresolutionThe prosodic information used for the purpose ofour research results from manual annotations thatfollow the GToBI(S) guidelines by Mayer (1995),which stand in the tradition of autosegmental-metrical phonology, cf.
Pierrehumbert (1980),Gussenhoven (1984), F?ery (1993), Ladd (2008),Beckman et al (2005).
We mainly make use ofpitch accents and prosodic phrasing.
The an-notations distinguish intonation phrases, termi-nated by a major boundary (%), and intermediatephrases, closed by a minor boundary (-), as shownin Examples (2) and (3).The available pitch accent and boundary an-notations allow us to automatically derive a sec-ondary layer of prosodic information which rep-resents a mapping of the pitch accents onto aprominence scale in which the nuclear (i.e.
final)accents of an intonation phrase (n2) rank as themost prominent, followed by the nuclear accentsof intermediate phrases (n1) and prenuclear (i.e.non-final) accents which are perceptually the leastprominent.
To put it simply, the nuclear accentis the most prominent accent in a prosodic phrasewhile prenuclear accents are less prominent.While we expect the difference between thepresence or absence of pitch accents to influencethe classification of short NPs like in Example(1), we do not expect complex NPs to be fullydeaccented.
For complex NPs, we neverthelesshope that the prosodic structure of coreferentialNPs will turn out to significantly differ from thestructure of discourse-new NPs such as to yielda measurable effect.
Examples (2) and (3) showthe prosodic realisation of two expressions withdifferent information status.
In Example (2), thecomplex NP the text about the aims and futureof the EU refers back to the Berlin Declaration,whereas in Example (3), the complex NP assaultwith lethal consequences and reckless homicide isnot anaphoric.
The share of prenuclear accentsis higher in the anaphoric case, which indicateslower overall prominence.
The features describedin Section 2.1 only take into account the absenceor type of the pitch accent; those in Section 2.2additionally employ prosodic phrasing.
To get abetter picture of the effect of these features, we im-plement, for each feature, one version for all nounphrases and a second version only for short nounphrases (<=4 words).2.1 Prosodic features ignorant of phraseboundariesPitch accent type corresponds to the followingpitch accent types that are present in the GToBI(S)based annotations.Fall H*LRise L*HDownstep fall !H*LHigh target H*Low target L*Early peak HH*LLate peak L*HLFor complex NPs, the crucial label is the last la-bel in the mention.
For short NPs, this usuallymatches the label on the syntactic head.Pitch accent presence focuses on the presenceof a pitch accent, disregarding its type.
If one ac-cent is present in the markable, the boolean featuregets assigned the value true, and false otherwise.2.2 Prosodic features including phraseboundary informationThe following set of features takes into account thedegree of prominence of pitch accents as presentedat the beginning of Section 2, which at the sametime encodes information about prosodic phras-ing.Nuclear accent type looks at the different de-grees of accent prominence.
The markable getsassigned the type n2, n1, pn if the last accent inthe phrase matches one of the types (and none if itis deaccented).Nuclear accent presence is a Boolean featurecomparable to pitch accent presence.
It gets as-signed the value true if there is some kind of ac-cent present in the markable.
To be able to judgethe helpfulness of the distinction between the cat-egories that are introduced above, we experimentwith two different versions:84(2) Anaphoric complex NP (DIRNDL sentences 9/10):9: Im Mittelpunkt steht eine von der Ratspr?asidentin, Bundeskanzlerin Merkel, vorbereitete ?Berliner Erkl?arung?.10: Die Pr?asidenten [.
.
. ]
wollen [den TEXT ?uber die ZIEle und ZUkunft der EU] unterzeichnen.the presidents [.
.
. ]
want [the text about the aims and future the EU] sign(( L*H L*H-) ( H*L H*L H*L -)%)pn n1 pn pnCentral is the ?Berlin Declaration?
that was prepared by the president of the Council of the EU, Chancellor Merkel.The presidents want to sign [the text about the aims and future of the EU.
](3) Non-anaphoric complex NP (DIRNDL sentences 2527/2528):2527: Der Prozess um den Tod eines Asylbewerbers aus Sierra Leone in Polizeigewahrsam ist [.
.
. ]
er?offnet worden.2528: [Wegen K?ORperverletzung mit TOdesfolge und fahrl?assiger T?Otung] M?USsen .
.
.
[Due assault with lethal consequence, and reckless homicide] must(( H*L L*H -) ( H*L -)%)pn n1 n2The trial about the death of an asylum seeker from Sierra Leone during police custody has started.Charges include [assault with lethal consequence, and reckless homicide], .
.
.1.
Only n2 accents get assigned true2.
n2 and n1 accents get assigned trueNote that a version where all accents get assignedtrue, i.e.
pn and n1 and n2, is not included as thisequals the feature Pitch accent presence.Nuclear bag of accents treats accents like abag-of-words approach treats words: if one accenttype is present once (or multiple times), the accenttype is considered present.
This means we get anumber of different combinations (23= 8 in total)of accent types that are present in the markable,e.g.
pn and n1 but no n2 for Example (2), and pn,n1 and n2 for Example (3).Nuclear: first and last includes linear informa-tion while avoiding an explosion of combinations.It only looks at the (degree of the) first pitch ac-cent present in the markable and combines it withthe last accent.3 Experimental setupWe perform our experiments using the IMS Hot-Coref system (Bj?orkelund and Kuhn, 2014), astate-of-the-art coreference resolution system forEnglish.
As German is not a language that is fea-tured in the standard resolver, we first had to adaptit.
These adaptations include gender and numberagreement, lemma-based (sub)string match anda feature that addresses German compounds, toname only a few.22To download the German coreference system, visit:www.ims.uni-stuttgart.de/forschung/ressourcen/werkzeuge/HOTCorefDe.htmlFor our experiments on prosodic features, weuse the DIRNDL corpus3(ca.
50.000 tokens, 3221sentences), a radio news corpus annotated withboth manual coreference and manual prosody la-bels (Eckart et al, 2012; Bj?orkelund et al, 2014)4.We adopt the official train, test and developmentsplit.
We decided to remove abstract anaphors(e.g.
anaphors that refer to events or facts), whichare not resolved by the system.
In all experi-ments, we only use predicted annotations and nogold mention boundary (GB) information as weaim at real end-to-end coreference resolution.
OnDIRNDL, our system achieves a CoNLL score of47.93, which will serve as a baseline in our ex-periments.
To put the baseline in context, we alsoreport performance on the German reference cor-pus T?uBa-D/Z5(Naumann, 2006), which consists3http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/dirndl.html4In this work, we have focused on improvements withinthe clearly defined field of coreference resolution, usingprosodic features.
As one of the reviewers pointed out, theDIRNDL corpus additionally features manual two-level in-formation status annotations according to the RefLex scheme(Baumann and Riester, 2012), which additionally distin-guishes bridging anaphors, deictic expressions, and more.Recent work on smaller datasets of read text has shown thatthere is a meaningful correspondence between informationstatus classes and degrees of prosodic prominence, with re-gard to both pitch accent type and position (Baumann andRiester, 2013; Baumann et al, 2015).
Moreover, informa-tion status classification has been identified as a task closelyrelated to coreference resolution (Cahill and Riester, 2012;Rahman and Ng, 2012).
Integrating these approaches is apromising, though rather complex task, which we reserve forfuture work.
It might, furthermore, require more detailedprosodic analyses than are currently available in DIRNDL.5http://www.sfs.uni-tuebingen.de/de/ascl/ressourcen/corpora/tueba-dz.html85System CoNLL CoNLL(+singl.)
(-singl.
)IMS HotCoref DE (open) 60.35 48.61CorZu (open) 60.27 45.82BART (open) 57.72 39.07SUCRE (closed) 51.23 36,32TANL-1 (closed) 38.48 14.17Table 1: SemEval Shared Task 2010 post-taskevaluation for track regular (on T?uBa 8), includ-ing and excluding singletonsSystem CoNLLIMS HOTCoref DE (no GB matching) 51.61CorZu (no GB matching) 53.07Table 2: IMS HotCoref performance on T?uBa 9(no singletons), using regular preprocessingof newspaper text.
In a post-task SemEval 2010evaluation6our system achieves a CoNLL scoreof 60.35 in the open, regular track7(cf.
Table 1).On the newest dataset available (T?uBa-D/Z v9),our resolver currently achieves a CoNLL scoreof 51.61.8Table 2 compares the performance ofour system against CorZu (Klenner and Tuggener,2011; Tuggener and Klenner, 2014), a rule-basedstate-of-the-art system for German9(on the newestT?uBa dataset).4 Experiments using prosodic featuresTable 3 shows the effect of the respective featureswhich are not informed about intonation bound-aries (Table 3a) and those that are (Table 3b).
Fea-tures that achieved a significant improvement overthe baseline are marked in boldface.10The best-performing feature in Table 3a is thepresence of a pitch accent in short NPs.
It can beseen that this feature has a negative effect when be-ing applied on all NPs.
Presumably, this is becausethe system is misled to classify a higher number ofcomplex anaphoric expressions as non-anaphoric,due to the presence of pitch accents.
This confirmsour conjecture that long NPs will always containsome kind of accent and we cannot distinguish nu-6http://stel.ub.edu/semeval2010-coref/7Using the official CoNLL scorer v8.01, including single-tons as they are part of T?uBa 88Using the official CoNLL scorer v8.01, not includingsingletons as T?uBa 9 does not contain them.9CorZu performance: Don Tuggener,personal communication.
We did not use CorZu for our ex-periments as the integration of prosodic information in a rule-based system is non-trivial.10We compute significance using the Wilcoxon signed ranktest (Siegel and Castellan, 1988) at the 0.01 level.
(a) No boundary informationBaseline 47.93+ Feature applied to .
.
.
.
.
.
short .
.
.
allNPs only NPsPitchAccentType 45.31 46.23PitchAccentPresence 48.30 46.57(b) Including boundary informationBaseline 47.93+ Feature applied to .
.
.
.
.
.
short .
.
.
allNPs only NPsNuclearType 47.17 46.79(n1 vs. n2 vs. pn vs. none)NuclearType 48.55 45.24(n1/n2 vs. pn vs. none)NuclearPresence (n2) 46.69 48.88NuclearPresence (n1/n2) 48.76 47.47NuclearBagOfAccents 46.09 48.45NuclearFirst+Last 46.41 46.74Table 3: CoNLL metric scores on DIRNDL fordifferent prosodic features (no singletons, signifi-cant results in boldface)clear from prenuclear accents.
Features based onGToBI(S) accent type did not result in any im-provements.Table 3b presents the performance of the fea-tures that are phonologically more informed.
Dis-tinguishing between prenuclear and nuclear ac-cents (NuclearType) is a feature that works bestfor short NPs where there is only one accent, whilehaving a negative effect on all NPs.
Nuclear pres-ence, however, works well for both versions (notdistinguishing between n1 or n2 works for shortNPs while n2 accents only works best for all NPs).This feature achieves the overall best performancefor both short NPs (48.76) and all NPs (48.88).The NuclearBagOfAccents feature works quitewell, too: this is a feature designed for NPs thathave more than one accent and so it works best forcomplex NPs.
Combining the features did not leadto any improvements.Overall, it becomes clear that one has to be verycareful in terms of how the prosodic information isused.
In general, the presence of an accent worksbetter than the distinction between certain accenttypes, and including intonation boundary informa-tion also contributes to the system?s performance.When including this information, we can observethat when we look at the presence of a pitch accent(the best-performing feature), the distinction be-tween prenuclear and nuclear is an important one:not distinguishing between prenuclear and nucleardeteriorates results.
The results also seem to sug-86gest that simpler features (like the presence or ab-sence of a certain type of pitch accent) work bestfor simple (i.e.
short) phrases.
For longer mark-ables this effect turns into the negative.
This prob-ably means that simple features cannot do justiceto the complex prosody of longer NPs, which getsblurred.
The obvious solution is to define morecomplex features that approximate the rhythmicpattern (or even the prosodic contour) found onlonger phrases, which however will require moredata and, ideally, automatic prosodic annotation.5 ConclusionWe have tested a set of features that include dif-ferent levels of prosodic information and investi-gated which strategies can be successfully appliedfor coreference resolution.
Our results on the basisof manual prosodic labelling show that includingprosody improves performance.
While informa-tion on pitch accent types does not seem benefi-cial, the presence of an accent is a helpful featurein a machine-learning setting.
Including prosodicboundaries and determining whether the accent isthe nuclear accent further increases results.
We in-terpret this as a promising result, which motivatesfurther research on the integration of coreferenceresolution and spoken language.AcknowledgementsWe would like to thank Anders Bj?orkelund for hisvaluable comments on an earlier version of thispaper, as well as Kerstin Eckart for her help withthe preparation of DIRNDL data.
This work wasfunded by the German Science Foundation (DFG),Sonderforschungsbereich 732 Incremental Speci-fication in Context, Project A6, at the Universityof Stuttgart.ReferencesMarilisa Amoia, Kerstin Kunz, and EkaterinaLapshinova-Koltunski.
2012.
Coreference inspoken vs. written texts: a corpus-based analysis.
InProceedings of LREC, Istanbul.Stefan Baumann and Arndt Riester.
2012.
Referen-tial and Lexical Givenness: semantic, prosodic andcognitive aspects.
In Gorka Elordieta and Pilar Pri-eto, editors, Prosody and Meaning, pages 119?162.Mouton de Gruyter, Berlin.Stefan Baumann and Arndt Riester.
2013.
Corefer-ence, Lexical Givenness and Prosody in German.Lingua, 136:16?37.Stefan Baumann and Anna Roth.
2014.
Prominenceand coreference ?
On the perceptual relevance of F0movement, duration and intensity.
In Proceedingsof Speech Prosody, pages 227?231, Dublin.Stefan Baumann, Christine R?ohr, and Martine Grice.2015.
Prosodische (De-)Kodierung des Informa-tionsstatus im Deutschen.
Zeitschrift f?ur Sprachwis-senschaft, 34(1):1?42.Mary Beckman, Julia Hirschberg, and StefanieShattuck-Hufnagel.
2005.
The original ToBIsystem and the evolution of the ToBI framework.In Sun-Ah Jun, editor, Prosodic Typology ?
ThePhonology of Intonation and Phrasing, pages 9?54.Oxford University Press.Anders Bj?orkelund and Jonas Kuhn.
2014.
Learn-ing structured perceptrons for coreference resolutionwith latent antecedents and non-local features.
InProceedings of the 52nd Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 47?57, Baltimore.Anders Bj?orkelund, Kerstin Eckart, Arndt Riester,Nadja Schauffler, and Katrin Schweitzer.
2014.
Theextended DIRNDL corpus as a resource for auto-matic coreference and bridging resolution.
In Pro-ceedings of LREC, pages 3222?3228, Reykjav?
?k.Aoife Cahill and Arndt Riester.
2012.
AutomaticallyAcquiring Fine-Grained Information Status Distinc-tions.
In Proceedings of the 13th Annual SIGdialMeeting on Discourse and Dialog, pages 232?236,Seoul.Alan Cruttenden.
2006.
The de-accenting of giveninformation: a cognitive universal?
In GiulianoBernini and Marcia Schwartz, editors, PragmaticOrganization of Discourse in the Languages of Eu-rope, pages 311?355.
De Gruyter, Berlin.Kerstin Eckart, Arndt Riester, and Katrin Schweitzer.2012.
A Discourse Information Radio NewsDatabase for Linguistic Analysis.
In Sebas-tian Nordhoff Christian Chiarcos and SebastianHellmann, editors, Linked Data in Linguistics: Rep-resenting and Connecting Language Data and Lan-guage Metadata, pages 65?76.
Springer.Caroline F?ery.
1993.
German Intonational Patterns.Niemeyer, T?ubingen.Carlos Gussenhoven.
1984.
On the Grammar and Se-mantics of Sentence Accents.
Foris, Dordrecht.Manfred Klenner and Don Tuggener.
2011.
An in-cremental entity-mention model for coreference res-olution with restrictive antecedent accessibility.
InProceedings of RANLP, pages 178?185, Hissar, Bul-garia.D.
Robert Ladd.
2008.
Intonational Phonology (2nded.).
Cambridge University Press.J?org Mayer.
1995.
Transcription of German Intona-tion.
The Stuttgart System.
University of Stuttgart.87Karin Naumann.
2006.
Manual for the annotationof in-document referential relations.
University ofT?ubingen.Vincent Ng.
2010.
Supervised noun phrase corefer-ence research: The first fifteen years.
In Proceed-ings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 1396?1411.Janet Pierrehumbert.
1980.
The Phonology and Pho-netics of English Intonation.
Ph.D. thesis, Mas-sachusetts Institute of Technology.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
Conll-2012 shared task: Modeling multilingual unre-stricted coreference in ontonotes.
In Joint Confer-ence on EMNLP and CoNLL-Shared Task, pages 1?40.
Association for Computational Linguistics.Altaf Rahman and Vincent Ng.
2012.
Learning thefine-grained information status of discourse entities.In Proceedings of the 13th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, pages 798?807.
Association for Com-putational Linguistics.Marta Recasens, Llu?
?s M`arquez, Emili Sapena,M.
Ant`onia Mart?
?, Mariona Taul?e, V?eronique Hoste,Massimo Poesio, and Yannick Versley.
2010.Semeval-2010 task 1: Coreference resolution inmultiple languages.
In Proceedings of the 5th In-ternational Workshop on Semantic Evaluation, Se-mEval ?10, pages 1?8, Stroudsburg, PA, USA.Roger Schwarzschild.
1999.
GIVENness, AvoidF, andOther Constraints on the Placement of Accent.
Nat-ural Language Semantics, 7(2):141?177.Michael Strube and Christoph M?uller.
2003.
A ma-chine learning approach to pronoun resolution inspoken dialogue.
In Proceedings of the 41st AnnualMeeting on Association for Computational Linguis-tics, pages 168?175.Jacques Terken and Julia Hirschberg.
1994.
Deaccen-tuation of words representing ?given?
information:Effects of persistence of grammatical function andsurface position.
Language and Speech, 37(2):125?145.Joel Tetreault and James Allen.
2004.
Dialogue struc-ture and pronoun resolution.
In Proceedings of the5th Discourse Anaphora and Anaphor ResolutionColloquium, S. Miguel, Portugal.Don Tuggener and Manfred Klenner.
2014.
A hybridentity-mention pronoun resolution model for ger-man using markov logic networks.
In Proceedingsof KONVENS 2014, pages 21?29.Carla Umbach.
2002.
(De)accenting definite descrip-tions.
Theoretical Linguistics, 2/3:251?280.88
