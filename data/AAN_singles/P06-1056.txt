Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 441?448,Sydney, July 2006. c?2006 Association for Computational LinguisticsSemi-Supervised Learning of Partial Cognates usingBilingual BootstrappingOana Frunza and Diana InkpenSchool of Information Technology and EngineeringUniversity of OttawaOttawa, ON, Canada, K1N 6N5{ofrunza,diana}@site.uottawa.caAbstractPartial cognates are pairs of words in twolanguages that have the same meaning insome, but not all contexts.
Detecting theactual meaning of a partial cognate incontext can be useful for Machine Trans-lation tools and for Computer-AssistedLanguage Learning tools.
In this paperwe propose a supervised and a semi-supervised method to disambiguate par-tial cognates between two languages:French and English.
The methods useonly automatically-labeled data; thereforethey can be applied for other pairs of lan-guages as well.
We also show that ourmethods perform well when using cor-pora from different domains.1 IntroductionWhen learning a second language, a studentcan benefit from knowledge in his / her first lan-guage (Gass, 1987), (Ringbom, 1987), (LeBlancet al 1989).
Cognates ?
words that have similarspelling and meaning ?
can accelerate vocabu-lary acquisition and facilitate the reading com-prehension task.
On the other  hand, a student hasto pay attention to the pairs of words that lookand sound similar but have different meanings ?false friends pairs, and especially to pairs ofwords that share meaning in some but not allcontexts ?
the partial cognates.Carroll (1992) claims that false friends can bea hindrance in second language learning.
Shesuggests that a cognate pairing process betweentwo words that look alike happens faster in thelearner?s mind than a false-friend pairing.
Ex-periments with second language learners of dif-ferent stages conducted by Van et al (1998)suggest that missing false-friend recognition canbe corrected when cross-language activation isused ?
sounds, pictures, additional explanation,feedback.Machine Translation (MT) systems can benefitfrom extra information when translating a certainword in context.
Knowing if a word in the sourcelanguage is a cognate or a false friend with aword in the target language can improve thetranslation results.
Cross-Language InformationRetrieval systems can use the knowledge of thesense of certain words in a query in order to re-trieve desired documents in the target language.Our task, disambiguating partial cognates, is ina way equivalent to coarse grain cross-languageWord-Sense Discrimination.
Our focus is disam-biguating French partial cognates in context: de-ciding if they are used as cognates with anEnglish word, or if they are used as false friends.There is a lot of work done on monolingualWord Sense Disambiguation (WSD) systems thatuse supervised and unsupervised methods andreport good results on Senseval data, but there isless work done to disambiguate cross-languagewords.
The results of this process can be usefulin many NLP tasks.Although French and English belong to differ-ent branches of the Indo-European family of lan-guages, their vocabulary share a great number ofsimilarities.
Some are words of Latin and Greekorigin: e.g., education and theory.
A small num-ber of very old, ?genetic" cognates go back allthe way to Proto-Indo-European, e.g., m?re -mother and pied - foot.
The majority of thesepairs of words penetrated the French and Englishlanguage due to the geographical, historical, andcultural contact between the two countries over441many centuries (borrowings).
Most of the bor-rowings have changed their orthography, follow-ing different orthographic rules (LeBlanc andSeguin, 1996) and most likely their meaning aswell.
Some of the adopted words replaced theoriginal word in the language, while others wereused together but with slightly or completely dif-ferent meanings.In this paper we describe a supervised and alsoa semi-supervised method to discriminate thesenses of partial cognates between French andEnglish.
In the following sections we presentsome definitions, the way we collected the data,the methods that we used, and evaluation ex-periments with results for both methods.2 DefinitionsWe adopt the following definitions.
The defini-tions are language-independent, but the examplesare pairs of French and English words, respec-tively.Cognates, or True Friends (Vrais Amis), arepairs of words that are perceived as similar andare mutual translations.
The spelling can be iden-tical or not, e.g., nature - nature, reconnaissance- recognition.False Friends (Faux Amis) are pairs of words intwo languages that are perceived as similar buthave different meanings, e.g., main (= hand) -main (= principal or essential), blesser (= to in-jure) - bless (= b?nir).Partial Cognates are pairs of words that havethe same meaning in both languages in some butnot all contexts.
They behave as cognates or asfalse friends, depending on the sense that is usedin each context.
For example, in French, facteurmeans not only factor, but also mailman, while?tiquette can also mean label or sticker, in addi-tion to the cognate sense.Genetic Cognates are word pairs in related lan-guages that derive directly from the same wordin the ancestor (proto-)language.
Because ofgradual phonetic and semantic changes over longperiods of time, genetic cognates often differ inform and/or meaning, e.g., p?re - father, chef -head.
This category excludes lexical borrowings,i.e., words transferred from one language to an-other at some point of time, such as concierge.3 Related WorkAs far as we know there is no work done to dis-ambiguate partial cognates between two lan-guages.Ide (2000) has shown on a small scale thatcross-lingual lexicalization can be used to defineand structure sense distinctions.
Tufis et al(2004) used cross-lingual lexicalization, word-nets alignment for several languages, and a clus-tering algorithm to perform WSD on a set ofpolysemous English words.
They report an accu-racy of 74%.One of the most active researchers in identify-ing cognates between pairs of languages isKondrak (2001; 2004).
His work is more relatedto the phonetic aspect of cognate identification.He used in his work algorithms that combine dif-ferent orthographic and phonetic measures, re-current sound correspondences, and somesemantic similarity based on glosses overlap.Guy (1994) identified letter correspondence be-tween words and estimates the likelihood of re-latedness.
No semantic component is present inthe system, the words are assumed to be alreadymatched by their meanings.
Hewson (1993),Lowe and Mazadon (1994) used systematicsound correspondences to determine proto-projections for identifying cognate sets.WSD is a task that has attracted researcherssince 1950 and it is still a topic of high interest.Determining the sense of an ambiguous word,using bootstrapping and texts from a differentlanguage was done by Yarowsky (1995),  Hearst(1991), Diab (2002), and Li and Li (2004).Yarowsky (1995) has used a few seeds anduntagged sentences in a bootstrapping algorithmbased on decision lists.
He added two constrains?
words tend to have one sense per discourse andone sense per collocation.
He reported high accu-racy scores for a set of 10 words.
The monolin-gual bootstrapping approach was also used byHearst (1991), who used a small set of hand-labeled data to bootstrap from a larger corpus fortraining a noun disambiguation system for Eng-lish.
Unlike Yarowsky (1995), we use automaticcollection of seeds.
Besides our monolingualbootstrapping technique, we also use bilingualbootstrapping.Diab (2002) has shown that unsupervised WSDsystems that use parallel corpora can achieveresults that are close to the results of a supervisedapproach.
She used parallel corpora in French,English, and Spanish, automatically-producedwith MT tools to determine cross-language lexi-calization sets of target words.
The major goal ofher work was to perform monolingual EnglishWSD.
Evaluation was performed on the nounsfrom the English all words data in Senseval2.Additional knowledge was added to the system442from WordNet in order to improve the results.
Inour experiments we use the parallel data in a dif-ferent way: we use words from parallel sentencesas features for Machine Learning (ML).
Li andLi (2004) have shown that word translation andbilingual bootstrapping is a good combination fordisambiguation.
They were using a set of 7 pairsof Chinese and English words.
The two senses ofthe words were highly distinctive: e.g.
bass asfish or music; palm as tree or hand.Our work described in this paper shows thatmonolingual and bilingual bootstrapping can besuccessfully used to disambiguate partial cog-nates between two languages.
Our approach dif-fers from the ones we mentioned before not onlyfrom the point of human effort needed to anno-tate data ?
we require almost none, and from theway we use the parallel data to automaticallycollect training examples for machine learning,but also by the fact that we use only off-the-shelftools and resources: free MT and ML tools, andparallel corpora.
We show that a combination ofthese resources can be used with success in a taskthat would otherwise require a lot of time andhuman effort.4 Data for Partial CognatesWe performed experiments with ten pairs of par-tial cognates.
We list them in Table 1.
For aFrench partial cognate we list its English cognateand several false friends in English.
Often theFrench partial cognate has two senses (one forcognate, one for false friend), but sometimes ithas more than two senses: one for cognate andseveral for false friends (nonetheless, we treatthem together).
For example, the false friendwords for note have one sense for grades and onefor bills.The partial cognate (PC), the cognate (COG)and false-friend (FF) words were collected froma web resource1.
The resource contained a list of400 false-friends with 64 partial cognates.
Allpartial cognates are words frequently used in thelanguage.
We selected ten partial cognates pre-sented in Table 1 according to the number of ex-tracted sentences (a balance between the twomeanings), to evaluate and experiment our pro-posed methods.The human effort that we required for ourmethods was to add more false-friend Englishwords, than the ones we found in the web re-source.
We wanted to be able to distinguish the1 http://french.about.com/library/fauxamis/blfauxam_a.htmsenses of cognate and false-friends for a widervariety of senses.
This task was done using a bi-lingual dictionary2.Table 1.
The ten pairs of partial cognates.French par-tial cognateEnglishcognateEnglish false friendsblanc blank white, lividcirculation circulation trafficclient client customer, patron, patient,spectator, user, shoppercorps corps body, corpsed?tail detail retailmode mode fashion, trend, style,voguenote note mark, grade, bill, check,accountpolice police policy, insurance, font,faceresponsable responsi-blein charge, responsibleparty, official, representa-tive, person in charge,executive, officerroute route road, roadside4.1 Seed Set CollectionBoth the supervised and the semi-supervisedmethod that we will describe in Section 5 areusing a set of seeds.
The seeds are parallel sen-tences, French and English, which contain thepartial cognate.
For each partial-cognate word, apart of the set contains the cognate sense andanother part the false-friend sense.As we mentioned in Section 3, the seed sen-tences that we use are not hand-tagged with thesense (the cognate sense or the false-friendsense); they are automatically annotated by theway we collect them.
To collect the set of seedsentences we use parallel corpora from Hansard3,and EuroParl4, and the, manually aligned BAFcorpus.5The cognate sense sentences were created byextracting parallel sentences that had on theFrench side the French cognate and on the Eng-lish side the English cognate.
See the upper partof Table 2 for an example.The same approach was used to extract sen-tences with the false-friend sense of the partialcognate, only this time we used the false-friendEnglish words.
See lower the part of Table 2.2 http://www.wordreference.com3 http://www.isi.edu/natural-language/download/hansard/and  http://www.tsrali.com/4 http://people.csail.mit.edu/koehn/publications/europarl/5 http://rali.iro.umontreal.ca/Ressources/BAF/443Table 2.
Example sentences from parallel corpus.Fr(PC:COG)Je note, par exemple, que l'accus?
a faitune autre d?claration tr?s incriminante ?Hall environ deux mois plus tard.En(COG)I note, for instance, that he made anotherhighly incriminating statement to Halltwo months later.Fr(PC:FF)S'il g?le les gens ne sont pas capables der?gler leur note de chauffageEn(FF)If there is a hard frost, people are unableto pay their bills.To keep the methods simple and language-independent, no lemmatization was used.
Wetook only sentences that had the exact form ofthe French and English word as described in Ta-ble 1.
Some improvement might be achievedwhen using lemmatization.
We wanted to seehow well we can do by using sentences as theyare extracted from the parallel corpus, with noadditional pre-processing and without removingany noise that might be introduced during thecollection process.From the extracted sentences, we used 2/3 ofthe sentences for training (seeds) and 1/3 for test-ing when applying both the supervised and semi-supervised approach.
In Table 3 we present thenumber of seeds used for training and testing.We will show in Section 6, that even thoughwe started with a small amount of seeds from acertain domain ?
the nature of the parallel corpusthat we had, an improvement can be obtained indiscriminating the senses of partial cognates us-ing free text from other domains.Table 3.
Number of parallel sentences used as seeds.PartialCognatesTrainCGTrainFFTestCGTestFFBlanc 54 78 28 39Circulation 213 75 107 38Client 105 88 53 45Corps 88 82 44 42D?tail 120 80 60 41Mode 76 104 126 53Note 250 138 126 68Police 154 94 78 48Responsable 200 162 100 81Route 69 90 35 46AVERAGE 132.9 99.1 66.9 50.15 MethodsIn this section we describe the supervised and thesemi-supervised methods that we use in our ex-periments.
We will also describe the data setsthat we used for the monolingual and bilingualbootstrapping technique.For both methods we have the same goal: todetermine which of the two senses (the cognateor the false-friend sense) of a partial-cognateword is present in a test sentence.
The classes inwhich we classify a sentence that contains a par-tial cognate are: COG (cognate) and FF (false-friend).5.1 Supervised MethodFor both the supervised and semi-supervisedmethod we used the bag-of-words (BOW) ap-proach of modeling context, with binary valuesfor the features.
The features were words fromthe training corpus that appeared at least 3 timesin the training sentences.
We removed the stop-words from the features.
A list of stopwords forEnglish and one for French was used.
We ranexperiments when we kept the stopwords as fea-tures but the results did not improve.Since we wanted to learn the contexts in whicha partial cognate has a cognate sense and the con-texts in which it has a false-friend sense, the cog-nate and false friend words were not taken intoaccount as features.
Leaving them in would meanto indicate the classes, when applying themethods for the English sentences since all thesentences with the cognate sense contain the cog-nate word and all the false-friend sentences donot contain it.
For the French side all collectedsentences contain the partial cognate word, thesame for both senses.As a baseline for the experiments that we pre-sent we used the ZeroR classifier from WEKA6,which predicts the class that is the most frequentin the training corpus.
The classifiers for whichwe report results are: Na?ve Bayes with a kernelestimator, Decision Trees - J48, and a SupportVector Machine implementation - SMO.
All theclassifiers can be found in the WEKA package.We used these classifiers because we wanted tohave a probabilistic, a decision-based and a func-tional classifier.
The decision tree classifier al-lows us to see which features are mostdiscriminative.Experiments were performed with other classi-fiers and with different levels of tuning, on a 10-fold cross validation approach as well; the classi-fiers we mentioned above were consistently theones that obtained the best accuracy results.The supervised method used in our experi-ments consists in training the classifiers on the6 http://www.cs.waikato.ac.nz/ml/weka/444automatically-collected training seed sentences,for each partial cognate, and then test their per-formance on the testing set.
Results for thismethod are presented later, in Table 5.5.2 Semi-Supervised MethodFor the semi-supervised method we add unla-belled examples from monolingual corpora: theFrench newspaper LeMonde7 1994, 1995 (LM),and the BNC8 corpus, different domain corporathan the seeds.
The procedure of adding and us-ing this unlabeled data is described in the Mono-lingual Bootstrapping (MB) and BilingualBootstrapping (BB) sections.5.2.1  Monolingual BootstrappingThe monolingual bootstrapping algorithm thatwe used for experiments on French sentences(MB-F) and on English sentences (MB-E) is:For each pair of partial cognates (PC)1.
Train a classifier on the training seeds ?
us-ing the BOW approach and a NB-K classifierwith attribute selection on the features.2.
Apply the classifier on unlabeled data ?sentences that contain the PC word, extractedfrom LeMonde (MB-F) or from BNC (MB-E)3.
Take the first k newly classified sentences,both from the COG and FF class and addthem to the  training seeds  (the most confidentones ?
the  prediction  accuracy greater orequal than a threshold =0.85)4.
Rerun the experiments training on the newtraining set5.
Repeat steps 2 and 3 for t timesendForFor the first step of the algorithm we used NB-Kclassifier because it was the classifier that consis-tently performed better.
We chose to performattribute selection on the features after we triedthe method without attribute selection.
We ob-tained better results when using attribute selec-tion.
This sub-step was performed with theWEKA tool, the Chi-Square attribute selectionwas chosen.In the second step of the MB algorithm theclassifier that was trained on the training seedswas then used to classify the unlabeled data thatwas collected from the two additional resources.For the MB algorithm on the French side wetrained the classifier on the French side of the7 http://www.lemonde.fr/8 http://www.natcorp.ox.ac.uk/training seeds and then we applied the classifierto classify the sentences that were extracted fromLeMonde and contained the partial cognate.
Thesame approach was used for the MB on the Eng-lish side only this time we were using the Englishside of the training seeds for training the classi-fier and the BNC corpus to extract new exam-ples.
In fact, the MB-E step is needed only forthe BB method.Only the sentences that were classified with aprobability greater than 0.85 were selected forlater use in the bootstrapping algorithm.The number of sentences that were chosenfrom the new corpora and used in the first step ofthe MB and BB are presented in Table 4.Table 4.
Number of sentences selected from theLeMonde and BNC corpus.PC LMCOGLMFFBNCCOGBNCFFBlanc 45 250 0 241Circulation 250 250 70 180Client 250 250 77 250Corps 250 250 131 188D?tail 250 163 158 136Mode 151 250 176 262Note 250 250 178 281Police 250 250 186 200Responsable 250 250 177 225Route 250 250 217 118For the partial-cognate Blanc with the cognatesense, the number of sentences that had a prob-ability distribution greater or equal with thethreshold was low.
For the rest of partial cog-nates the number of selected sentences was lim-ited by the value of parameter k in the algorithm.5.2.2   Bilingual BootstrappingThe algorithm for bilingual bootstrapping that wepropose and tried in our experiments is:1.
Translate the English sentences that were col-lected in the MB-E step into French using anonline MT9 tool and add them to the French seedtraining data.2.
Repeat the MB-F and MB-E steps for T times.For the both monolingual and bilingual boot-strapping techniques the value of the parameterst and T is 1 in our experiments.9 http://www.freetranslation.com/free/web.asp4456 Evaluation and ResultsIn this section we present the results that weobtained with the supervised and semi-supervised methods that we applied to disam-biguate partial cognates.Due to space issue we show results only fortesting on the testing sets and not for the 10-foldcross validation experiments on the training data.For the same reason, we present the results thatwe obtained only with the French side of the par-allel corpus, even though we trained classifierson the English sentences as well.
The results forthe 10-fold cross validation and for the Englishsentences are not much different than the onesfrom Table 5 that describe the supervised methodresults on French sentences.Table 5.
Results for the Supervised Method.PC ZeroR NB-K Trees SMOBlanc 58% 95.52% 98.5% 98.5%Circulation 74% 91.03% 80% 89.65%Client 54.08% 67.34% 66.32% 61.22%Corps 51.16% 62% 61.62% 69.76%D?tail 59.4% 85.14% 85.14% 87.12%Mode 58.24% 89.01% 89.01% 90%Note 64.94% 89.17% 77.83% 85.05%Police 61.41% 79.52% 93.7% 94.48%Responsable 55.24% 85.08% 70.71% 75.69%Route 56.79% 54.32% 56.79% 56.79%AVERAGE 59.33% 80.17% 77.96% 80.59%Table 6 and Table 7 present results for the MBand BB.
More experiments that combined MBand BB techniques were also performed.
Theresults are presented in Table 9.Our goal is to disambiguate partial cognatesin general, not only in the particular domain ofHansard and EuroParl.
For this reason we usedanother set of automatically determined sen-tences from a multi-domain parallel corpus.The set of new sentences (multi-domain) wasextracted in the same manner as the seeds fromHansard and EuroParl.
The new parallel corpusis a small one, approximately 1.5 million words,but contains texts from different domains: maga-zine articles, modern fiction, texts from interna-tional organizations and academic textbooks.
Weare using this set of sentences in our experimentsto show that our methods perform well on multi-domain corpora and also because our aim is to beable to disambiguate PC in different domains.From this parallel corpus we were able to extractthe number of sentences shown in Table 8.With this new set of sentences we performeddifferent experiments both for MB and BB.
Allresults are described in Table 9.
Due to spaceissue we report the results only on the averagethat we obtained for all the 10 pairs of partialcognates.The symbols that we use in Table 9 represent:S ?
the seed training corpus, TS ?
the seed testset,  BNC and LM ?
sentences extracted fromLeMonde and BNC (Table 4), and NC ?
the sen-tences that were extracted from the multi-domainnew corpus.
When we use the + symbol we puttogether all the sentences extracted from the re-spective corpora.Table 6.
Monolingual Bootstrapping on the French side.PC ZeroR NB-K Dec.Tree SMOBlanc 58.20% 97.01% 97.01% 98.5%Circulation 73.79% 90.34% 70.34% 84.13%Client 54.08% 71.42% 54.08% 64.28%Corps 51.16% 78% 56.97% 69.76%D?tail 59.4% 88.11% 85.14% 82.17%Mode 58.24% 89.01% 90.10% 85%Note 64.94% 85.05% 71.64% 80.41%Police 61.41% 71.65% 92.91% 71.65%Responsable 55.24% 87.29% 77.34% 81.76%Route 56.79% 51.85% 56.79% 56.79%AVERAGE 59.33% 80.96% 75.23% 77.41%Table 7.
Bilingual Bootstrapping.PC ZeroR NB-K Dec.Tree SMOBlanc 58.2% 95.52% 97.01% 98.50%Circulation 73.79% 92.41% 63.44% 87.58%Client 45.91% 70.4% 45.91% 63.26%Corps 48.83% 83% 67.44% 82.55%D?tail 59% 91.08% 85.14% 86.13%Mode 58.24% 87.91% 90.1% 87%Note 64.94% 85.56% 77.31% 79.38%Police 61.41% 80.31% 96.06% 96.06%Responsable 44.75% 87.84% 74.03% 79.55%Route 43.2% 60.49% 45.67% 64.19%AVERAGE 55.87% 83.41% 74.21% 82.4%446Table 8.
New Corpus (NC) sentences.PC COG FFBlanc 18 222Circulation 26 10Client 70 44Corps 4 288D?tail 50 0Mode 166 12Note 214 20Police 216 6Responsable 104 66Route 6 1006.1  Discussion of the ResultsThe results of the experiments and the methodsthat we propose show that we can use with suc-cess unlabeled data to learn from, and that thenoise that is introduced due to the seed set collec-tion is tolerable by the ML techniques that weuse.Some results of the experiments we present inTable 9 are not as good as others.
What is impor-tant to notice is that every time we used MB orBB or both, there was an improvement.
For someexperiments MB did better, for others BB wasthe method that improved the performance;nonetheless for some combinations MB togetherwith BB was the method that worked best.In Tables 5 and 7 we show that BB improvedthe results on the NB-K classifier with 3.24%,compared with the supervised method (no boot-strapping), when we tested only on the test set(TS), the one that represents 1/3 of the initially-collected parallel sentences.
This improvement isnot statistically significant, according to a t-test.In Table 9 we show that our proposed methodsbring improvements for different combinationsof training and testing sets.
Table 9, lines 1 and 2show that BB with NB-K brought an improve-ment of 1.95% from no bootstrapping, when wetested on the multi-domain corpus NC.
For thesame setting, there was an improvement of1.55% when we tested on TS (Table 9, lines 6and 8).
When we tested on the combinationTS+NC, again BB brought an improvement of2.63% from no bootstrapping (Table 9, lines 10and 12).
The difference between MB and BBwith this setting is 6.86% (Table 9, lines 11 and12).
According to a t-test the 1.95% and 6.86%improvements are statistically significant.Table 9.
Results for different experiments withmonolingual and bilingual bootstrapping (MB andBB).Train Test ZeroR NB-K Trees SMOS (nobootstrapping)NC 67% 71.97% 73.75% 76.75%S+BNC(BB)NC 64% 73.92% 60.49% 74.80%S+LM(MB)NC 67.85% 67.03% 64.65% 65.57%S +LM+BNC(MB+BB)NC 64.19% 70.57% 57.03% 66.84%S+LM+BNC(MB+BB)TS 55.87% 81.98% 74.37% 78.76%S+NC(no bootstr.
)TS 57.44% 82.03% 76.91% 80.71%S+NC+LM(MB)TS 57.44% 82.02% 73.78% 77.03%S+NC+BNC(BB)TS 56.63% 83.58% 68.36% 82.34%S+NC+LM+BNC(MB+BB)TS 58% 83.10% 75.61% 79.05%S (no bootstrap-ping)TS+NC 62.70% 77.20% 77.23% 79.26%S+LM(MB)TS+NC 62.70% 72.97% 70.33% 71.97%S+BNC(BB)TS+NC 61.27% 79.83% 67.06% 78.80%S+LM+BNC(MB+BB)TS+NC 61.27% 77.28% 65.75% 73.87%The number of features that were extractedfrom the seeds was more than double at each MBand BB experiment, showing that even thoughwe started with seeds from a language restricteddomain, the method is able to capture knowledgeform different domains as well.
Besides thechange in the number of features, the domain ofthe features has also changed form the parlia-mentary one to others, more general, showingthat the method will be able to disambiguate sen-tences where the partial cognates cover differenttypes of context.Unlike previous work that has done withmonolingual or bilingual bootstrapping, we triedto disambiguate not only words that have sensesthat are very different e.g.
plant ?
with a sense ofbiological plant or with the sense of factory.
Inour set of partial cognates the French word routeis a difficult word to disambiguate even for hu-mans: it has a cognate sense when it refers to amaritime or trade route and a false-friend sensewhen it is used as road.
The same observationapplies to client (the cognate sense is client, andthe false friend sense is customer, patron, or pa-tient) and to circulation (cognate in air or bloodcirculation, false friend in street traffic).4477 Conclusion and Future WorkWe showed that with simple methods and usingavailable tools we can achieve good results in thetask of partial cognate disambiguation.The accuracy might be increased by using de-pendencies relations, lemmatization, part-of-speech tagging ?
extract sentences where the par-tial cognate has the same POS, and other types ofdata representation combined with different se-mantic tools (e.g.
decision lists, rule based sys-tems).In our experiments we use a machine languagerepresentation ?
binary feature values, and weshow that nonetheless machines are capable oflearning from new information, using an iterativeapproach, similar to the learning process of hu-mans.
New information was collected and ex-tracted by classifiers when additional corporawere used for training.In addition to the applications that we men-tioned in Section 1, partial cognates can also beuseful in Computer-Assisted Language Learning(CALL) tools.
Search engines for E-Learning canfind useful a partial cognate annotator.
A teacherthat prepares a test to be integrated into a CALLtool can save time by using our methods toautomatically disambiguate partial cognates,even though the automatic classifications need tobe checked by the teacher.In future work we plan to try different repre-sentations of the data, to use knowledge of therelations that exists between the partial cognateand the context words, and to run experimentswhen we iterate the MB and BB steps more thanonce.ReferencesSusane Carroll 1992.
On Cognates.
Second LanguageResearch, 8(2):93-119Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel cor-pora.
In Proceedings of the 40th Meeting of the As-sociation for Computational Linguistics (ACL2002), Philadelphia, pp.
255-262.S.
M. Gass.
1987.
The use and acquisition of the sec-ond language lexicon (Special issue).
Studies inSecond Language Acquisition, 9 (2).Jacques B. M. Guy.
1994.
An algorithm for identify-ing cognates in bilingual word lists and its applica-bility to machine translation.
Journal ofQuantitative Linguistics, 1(1):35-42.Marti Hearst 1991.
Noun homograph disambiguationusing local context in large text corpora.
7th An-nual Conference of the University of WaterlooCenter for the new OED and Text Research, Ox-ford.W.J.B Van Heuven, A. Dijkstra, and J. Grainger.1998.
Orthographic neighborhood effects in bilin-gual word recognition.
Journal of Memory andLanguage 39: 458-483.John Hewson 1993.
A Computer-Generated Diction-ary of Proto-Algonquian.
Ottawa: Canadian Mu-seum of Civilization.Nancy Ide.
2000 Cross-lingual sense determination:Can it work?
Computers and the Humanities, 34:1-2, Special Issue on the Proceedings of the SIGLEXSENSEVAL Workshop, pp.223-234.Grzegorz Kondrak.
2004.
Combining Evidence inCognate Identification.
Proceedings of CanadianAI 2004: 17th Conference of the Canadian Societyfor Computational Studies of Intelligence, pp.44-59.Grzegorz Kondrak.
2001.
Identifying Cognates byPhonetic and Semantic Similarity.
Proceedings ofNAACL 2001: 2nd Meeting of the North AmericanChapter of the Association for Computational Lin-guistics, pp.103-110.Raymond LeBlanc and Hubert S?guin.
1996.
Lescong?n?res homographes et parographes anglais-fran?ais.
Twenty-Five Years of Second LanguageTeaching at the University of Ottawa, pp.69-91.Hang Li and Cong Li.
2004.
Word translation disam-biguation using bilingual bootstrap.
ComputationalLinguistics, 30(1):1-22.John B. Lowe and Martine Mauzaudon.
1994.
Thereconstruction engine: a computer implementationof the comparative method.
Computational Lin-guistics, 20:381-417.Hakan Ringbom.
1987.
The Role of the First Lan-guage in Foreign Language Learning.
MultilingualMatters Ltd., Clevedon, England.Dan Tufis, Ion Radu, Nancy Ide 2004.
Fine-GrainedWord Sense Disambiguation Based on ParallelCorpora, Word Alignment, Word Clustering andAligned WordNets.
Proceedings of the 20th Inter-national Conference on Computational Linguistics,COLING 2004, Geneva, pp.
1312-1318.David Yarowsky.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.
InProceedings of the 33th Annual Meeting of the As-sociation for Computational Linguistics, Cam-bridge, MA, pp 189-196.448
