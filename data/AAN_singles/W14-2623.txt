Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 142?146,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsA cognitive study of subjectivity extraction in sentiment annotationAbhijit Mishra1Aditya Joshi1,2,3Pushpak Bhattacharyya11IIT Bombay, India2Monash University, Australia3IITB-Monash Research Academy, India{abhijitmishra, adityaj, pb}@cse.iitb.ac.inAbstractExisting sentiment analysers are weak AIsystems: they try to capture the function-ality of human sentiment detection faculty,without worrying about how such facultyis realized in the hardware of the human.These analysers are agnostic of the actualcognitive processes involved.
This, how-ever, does not deliver when applicationsdemand order of magnitude facelift in ac-curacy, as well as insight into characteris-tics of sentiment detection process.In this paper, we present a cognitive studyof sentiment detection from the perspec-tive of strong AI.
We study the sentimentdetection process of a set of human ?sen-timent readers?.
Using eye-tracking, weshow that on the way to sentiment de-tection, humans first extract subjectivity.They focus attention on a subset of sen-tences before arriving at the overall senti-ment.
This they do either through ?antici-pation?
where sentences are skipped dur-ing the first pass of reading, or through?homing?
where a subset of the sentencesare read over multiple passes, or throughboth.
?Homing?
behaviour is also ob-served at the sub-sentence level in com-plex sentiment phenomena like sarcasm.1 IntroductionOver the years, supervised approaches usingpolarity-annotated datasets have shown promisefor SA (Pang and Lee, 2008).
However, an al-ternate line of thought has co-existed.
Pang andLee (2004) showed that for SA, instead of a doc-ument in its entirety, an extract of the subjec-tive sentences alone can be used.
This processof generating a subjective extract is referred toas subjectivity extraction.
Mukherjee and Bhat-tacharyya (2012) show that for sentiment predic-tion of movie reviews, subjectivity extraction maybe used to discard the sentences describing movieplots since they do not contribute towards thespeaker?s view of the movie.While subjectivity extraction helps sentimentclassification, the reason has not been sufficientlyexamined from the perspective of strong AI.
Theclassical definition of strong AI suggests that amachine must be perform sentiment analysis ina manner and accuracy similar to human beings.Our paper takes a step in this direction.
We studythe cognitive processes underlying sentiment an-notation using eye-fixation data of the participants.Our work is novel in two ways:?
We view documents as a set of sentencesthrough which sentiment changes.
We showthat the nature of these polarity oscillationsleads to changes in the reading behavior.?
To the best of our knowledge, the idea of us-ing eye-tracking to validate assumptions isnovel in case of sentiment analysis and manyNLP applications.2 Sentiment oscillations & subjectivityextractionWe categorize subjective documents as linear andoscillating.
A linear subjective document is theone where all or most sentences have the same po-larity.
On the other hand, an oscillating subjectivedocument contains sentences of contrasting polar-ity (viz.
positive and negative).
Our discussionson two forms of subjectivity extraction use theconcepts of linear and oscillating subjective doc-uments.Consider a situation where a human readerneeds to annotate two documents with sentiment.Assume that the first document is linear subjec-tive - with ten sentences, all of them positive.
In142case of this document, when he/she reads a cou-ple of sentences with the same polarity, he/she be-gins to assume that the next sentence will have thesame sentiment and hence, skips through it.
Werefer to this behavior as anticipation.
Now, let thesecond document be an oscillating subjective doc-ument with ten sentences, the first three positive,the next four negative and the last three positive.In this case, when a human annotator reads thisdocument and sees the sentiment flip early on, theannotator begins to carefully read the document.After completing a first pass of reading, the anno-tator moves back to read certain crucial sentences.We refer to this behavior as homing.The following sections describe our observa-tions in detail.
Based on our experiments, we ob-serve these two kinds of subjectivity extraction inour participants: subjectivity extraction as a resultof anticipation and subjectivity extraction as a re-sult of homing - for linear and oscillating docu-ments respectively.3 Experiment SetupThis section describes the framework used for oureye-tracking experiment.
A participant is giventhe task of annotating documents with one out ofthe following labels: positive, negative and ob-jective.
While she reads the document, her eye-fixations are recorded.To log eye-fixation data, we use Tobii T120remote eye-tracker with Translog(Carl, 2012).Translog is a freeware for recording eye move-ments and keystrokes during translation.
We con-figure Translog for reading with the goal of senti-ment.3.1 Document descriptionWe choose three movie reviews in English fromIMDB (http://www.imdb.com) and indicate themas D0, D1 and D2.
The lengths of D0, D1 andD2 are 10, 9 and 13 sentences respectively.
Usingthe gold-standard rating given by the writer, wederive the polarity of D0, D1 and D2 as positive,negative and positive respectively.
The three doc-uments represent three different styles of reviews:D0 is positive throughout (linear subjective), D1contains sarcastic statements (linear subjective butmay be perceived as oscillating due to linguisticdifficulty) while D2 consists of many flips in sen-timent (oscillating subjective).It may seem that the data set is small andmay not lead to significant findings.
However,we wished to capture the most natural form ofsentiment-oriented reading.
A larger data setwould have weakened the experiment because: (i)Sentiment patterns (linear v/s subjective) begin tobecome predictable to a participant if she readsmany documents one after the other.
(ii) Thereis a possibility that fatigue introduces unexpectederror.
To ensure that our observations were signif-icant despite the limited size of the data set, weincreased the number of our participants to 12.3.2 Participant descriptionOur participants are 24-30 year-old graduate stu-dents with English as the primary language of aca-demic instruction.
We represent them as P0, P1and so on.
The polarity for the documents as re-ported by the participants are shown in Table 1.All participants correctly identified the polarity ofdocument D0.
Participant P9 reported that D1 isconfusing.
4 out of 12 participants were unable todetect correct opinion in D2.3.3 Experiment DescriptionWe obtain two kinds of annotation from our an-notators: (a) sentiment (positive, negative and ob-jective), (b) eye-movement as recorded by an eye-tracker.
They are given a set of instructions before-hand and can seek clarifications.
This experimentis conducted as follows:1.
A complete document is displayed on thescreen.
The font size and line separation areset to 17pt and 1.5 cm respectively to ensureclear visibility and minimize recording error.2.
The annotator verbally states the sentiment ofthis sentence, before (s)he can proceed to thenext.3.
While the annotator is reading the sentence,a remote eye-tracker (Model: Tobii TX 300,Sampling rate: 300Hz) records the eye-movement data of the annotator.
The eye-tracker is linked to Translog II software (Carl,2012) in order to record the data.
A snap-shot of the software is shown in figure 1.
Thedots and circles represent position of eyes andfixations of the annotator respectively.
Eacheye-fixation that is recorded consists of: co-ordinates, timestamp and duration.
Thesethree parameters have been used to generatesentence progression graphs.143Document Orig P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11D0 +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +ve +veD1 -ve -ve +ve -ve -ve -ve -ve -ve -ve -ve Neu/-ve -ve -veD2 +ve +ve +ve -ve +ve +ve Neu +ve Neu Neu +ve +ve +veTable 1: Polarity of documents as perceived by the writer (original) and the participants +ve, -ve andNeu represent positive, negative and neutral polarities respectively.Figure 1: Gaze-data recording using Translog-IIFigure 2: Sentence progression graph for partici-pant P7 document D04 Observations: Subjectivity extractionthrough anticipationIn this section, we describe a case in which partic-ipants skip sentences.
We show that anticipationof sentiment is linked with subjectivity extraction.Table 2 shows the number of unique and non-unique sentences that participants read for eachdocument.
The numbers in the last column in-dicate average values.
The table can be read as:participant P1 reads 8 unique sentences of docu-ment D0 (thus skipping two sentences) and includ-ing repetitions, reads 26 sentences.
Participant P0skips as many as six sentences in case of documentD1.The number of unique sentences read is lowerthan sentence count for four out of twelve partic-ipants in case of document D0.
This skipping isnegligible in case of document D1 and D2.
Also,the average non-unique sentence fixations are 21in case of D0 and 33.83 for D1 although the totalnumber of sentences in D0 and D1 is almost thesame.
This verifies that participants tend to skipsentences while reading D0.Figure 2 shows sentence progression graph forparticipant P7.
The participant reads a series ofsentences and then skips two sentences.
This im-plies that anticipation behaviour was triggered af-ter reading sentences of the same polarity.
Sim-ilar traits are observed in other participants whoskipped sentences while reading document D0.5 Observations: Subjectivity extractionthrough homingThis section presents a contrasting case of sub-jectivity extraction.
We refer to a reading patternas homing1when a participant reads a documentcompletely and returns to read a selected subset ofsentences.
We believe that during sentiment an-notation, this subset is the subjective extract thatthe user has created in her mind.
We observe thisphenomenon in reading patterns of documents D1and D2.
The former contains sarcasm because ofwhich parts of sentences may appear to be of con-trasting polarity while the latter is an oscillatingsubjective document.1The word is derived from missile guidance systems.
Thedefinition2of homing is ?the process of determining the lo-cation of something, sometimes the source of a transmission,and going to it.
?144Document P0 P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 Avg.D0Non-unique 9 26 23 17 18 18 35 16 33 19 15 23 21Unique 8 8 10 10 10 10 10 8 10 8 10 10D1Non-unique 5 23 46 13 15 44 35 26 56 57 40 46 33.83Unique 3 9 9 9 9 9 8 9 9 9 9 9D2Non-unique 36 29 67 21 23 51 64 48 54 59 73 80 50.42Unique 13 13 13 13 13 13 13 13 13 13 13 13Table 2: Number of unique and non-unique sentences read by each participantFigure 3: Sentence progression graph of partici-pant P2 for document D1 (left) and document D2(right)Figure 3 shows sentence progression graphs ofparticipant P2 for documents D1 and D2.
For doc-ument D1, the participant performs one pass ofreading until sequence number 30.
A certain sub-set of sentences are re-visited in the second pass.On analyzing sentences in the second pass of read-ing, we observe a considerable overlap in case ofour participants.
We also confirm that all of thesesentences are subjective.
This means that the sen-tences that are read after sequence number 30 formthe subjective extract of document D1.Similar behaviour is observed in case of docu-ment D2.
The difference in this case is that thereis less overlap of sentences read in the second passamong participants.
This implies , for oscillat-ing subjective documents, the subjective extract isuser/document-specific.It may be argued that fixations correspondingParticipant TFD-SE PTFD TFC-SE(secs) (%)P5 7.3 8 21P7 3.1 5 11P9 51.94 10 26P11 116.6 16 56Table 3: Reading statistics for second pass readingfor document D1; TFD: Total fixation duration forsubjective extract; PTFD: Proportion of total fix-ation duration = (TFD)/(Total duration); TFC-SE:Total fixation count for subjective extractto second pass reading are stray fixations and notsubjective extracts.
Hence, for the second passreading of document D1, we tabulate fixation du-ration, fixation count and proportion of total dura-tion in Table 3.
The fixation duration and fixationcount are both recorded by the eye-tracker.
Thefixation counts are substantial and the participantsspend around 5-15% of the total reading time inthe second pass reading.
We also confirm that allof these sentences are subjective.
This means thatthese portions indeed correspond to subjective ex-tracts as a result of homing.6 A note on linguistic challengesOur claim is that regression after reading an en-tire document corresponds to the beginning ofa subjective extract.
However, we observe thatsome regressions may also happen due to senti-ment changes at the sub-sentence level.
Some ofthese are as follows.1.
Sarcasm: Sarcasm involves an implicit flipin the sentiment.
Participant P9 does not cor-rectly predict sentiment of Document D1.
Onanalyzing her data, we observe multiple re-gressions on the sentence ?Add to this messsome of the cheesiest lines and concepts, and145there you have it; I would call it a completewaste of time, but in some sense it is so badit is almost worth seeing.?
This sentence hassome positive words but is negative towardsthe movie.
Hence, the participant reads thisportion back and forth.2.
Thwarted expectations: Thwarted expecta-tions are expressions with a sentiment rever-sal within a sentence/snippet.
Homing is ob-served in this case as well.
Document D2has a case of thwarted expectations from sen-tences 10-12 where there is an unexpectedflip of sentiment.
In case of some partici-pants, we observe regression on these sen-tences multiple times.7 Related WorkThe work closest to ours is by Scott et al.
(2011)who study the role of emotion words in read-ing using eye-tracking.
They show that the eye-fixation duration for emotion words is consistentlyless than neutral words with the exception of high-frequency negative words.
Eye-tracking3technol-ogy has also been used to study the cognitive as-pects of language processing tasks like translationand sense disambiguation.
Dragsted (2010) ob-serve co-ordination between reading and writingduring human translation.
Similarly, Joshi et al.
(2011) use eye-tracking to correlate fixation dura-tion with polysemy of words during word sensedisambiguation.8 Conclusion & Future workWe studied sentiment annotation in the context ofsubjectivity extraction using eye-tracking.
Basedon how sentiment changes through a document,humans may perform subjectivity extraction as aresult of either: (a) anticipation or (b) homing.These observations are in tandem with the pastwork that shows benefit of subjectivity extractionfor automatic sentiment classification.Our study is beneficial in three perspectives: (i)Sentiment classifiers may use interaction betweensentiment of sentences.
Specifically, this can bemodeled using features like sentiment run length(i.e.
maximal span of sentences bearing same3Related Terms:Eye-fixation: Long stay of visual gaze on a single locationRegression: Revisiting a previously read segmentSentence Progression Graph: Graph showing reading se-quence of sentencessentiment) or sentiment flips (i.e.
instances whereconsecutive sentences bear opposite polarity),(ii) Crowd-sourced sentiment annotation candevise variable pricing models based on our study.Based on anticipation and homing informationabout documents, documents can be grouped intodifficulty categories and priced accordingly.AcknowledgmentWe thank Tobii Corporation for lending us theireye-tracker for this study, and our annotators fromCFILT, IIT Bombay.
Aditya is funded by the TCSResearch Fellowship Program.ReferencesBo Pang and Lillian Lee.
2004.
A Sentimental Educa-tion: Sentiment Analysis Using Subjectivity Sum-marization Based on Minimum Cuts In Proceedingsof the ACL, 271-278.Bo Pang and Lillian Lee.
2008.
Opinion Mining andSentiment Analysis Foundations and Trends in In-formation Retrieval, 2008, vol.
2, nos.12 1135.B Dragsted.
2010.
Co-ordination of reading and writ-ing processes in translation.
Contribution to Trans-lation and Cognition.
Shreve, G. and Angelone,E.(eds.
)Cognitive Science Society.Michael Carl.
2012.
Translog-II: A Program forRecording User Activity Data for Empirical Readingand Writing Research.
In Proceedings of the EightInternational Conference on Language Resourcesand Evaluation, European Language Resources As-sociation.Scott G. , ODonnell P and Sereno S. 2012.
EmotionWords Affect Eye Fixations During Reading.
Jour-nal of Experimental Psychology:Learning, Memory,and Cognition 2012, Vol.
38, No.
3, 783792.Salil Joshi, Diptesh Kanojia and Pushpak Bhat-tacharyya.
2013.
More than meets the eye: Studyof Human Cognition in Sense Annotation.
NAACLHLT 2013, Atlanta, USA.Subhabrata Mukherjee and Pushpak Bhattacharyya.2012.
WikiSent : Weakly Supervised Senti-ment Analysis Through Extractive SummarizationWith Wikipedia European Conference on MachineLearning (ECML PKDD 2012), Bristol, U.K.,146
