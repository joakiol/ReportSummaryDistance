Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 963?967,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsDependency parsing with latent refinements of part-of-speech tagsThomas M?uller?, Richard Farkas?, Alex Judea?, Helmut Schmid?, and Hinrich Sch?utze?
?Center for Information and Language Processing, University of Munich, Germany?Department of Informatics, University of Szeged, Hungary?Heidelberg Institute for Theoretical Studies, Heidelberg, Germanymuellets@cis.lmu.deAbstractIn this paper we propose a method toincrease dependency parser performancewithout using additional labeled or unla-beled data by refining the layer of pre-dicted part-of-speech (POS) tags.
We per-form experiments on English and Ger-man and show significant improvementsfor both languages.
The refinement isbased on generative split-merge trainingfor Hidden Markov models (HMMs).1 IntroductionProbabilistic Context-free Grammars with latentannotations (PCFG-LA) have been shown (Petrovet al., 2006) to yield phrase structure parserswith state-of-the-art accuracy.
While HiddenMarkov Models with latent annotations (HMM-LA) (Huang et al., 2009), stay somewhat behindthe performance of state-of-the-art discriminativetaggers (Eidelman et al., 2010).
In this paper weaddress the question of whether the resulting la-tent POS tags are linguistically meaningful anduseful for upstream tasks such as syntactic pars-ing.
We find that this is indeed the case, lead-ing to a procedure that significantly increases theperformance of dependency parsers.
The proce-dure is attractive because the refinement of pre-dicted part-of-speech sequences using a coarse-to-fine strategy (Petrov and Klein, 2007) is fast andefficient.
More precisely, we show that incorpo-rating the induced POS into a state-of-the-art de-pendency parser (Bohnet, 2010) gives increases inLabeled Attachment Score (LAS): from 90.34 to90.57 for English and from 87.92 to 88.24 (resp.88.35 to 88.51) for German without using (resp.with using) morphological features.2 Related WorkPetrov et al.
(2006) introduce generative split-merge training for PCFGs and provide a fully au-tomatic method for training state-of-the-art phrasestructure parsers.
They argue that the resulting la-tent annotations are linguistically meaningful.
Sunet al.
(2008) induce latent sub-states into CRFs andshow that noun phrase (NP) recognition can be im-proved, especially if no part-of-speech features areavailable.
Huang et al.
(2009) apply split-mergetraining to create HMMs with latent annotations(HMM-LA) for Chinese POS tagging.
They re-port that the method outperforms standard gener-ative bigram and trigram tagging, but do not com-pare to discriminative methods.
Eidelman et al.
(2010) show that a bidirectional variant of latentHMMs with incorporation of prosodic informationcan yield state-of-the-art results in POS tagging ofconversational speech.3 Split-Merge Training for HMMsSplit-merge training for HMMs (Huang et al.,2009) iteratively splits every tag into two subtags.Word emission and tag transition probabilities ofsubtags are then initialized close to the values ofthe parent tags but with some randomness to breaksymmetry.
Using expectation?maximization (EM)training the parameters can then be set to a localmaximum of the training data likelihood.
Afterthis split phase, the merge phase reverts splits thatonly lead to small improvements in the likelihoodfunction in order to increase the robustness of themodel.
This approach requires an approximationof the gain in likelihood of every split analogousto Petrov et al.
(2006) as an exact computation isnot feasible.We have observed that this procedure is not963Universal Tag Feature Tag0Tag1English Adjectives p(w|t) more (0.05) many (0.03) last (0.03) new (0.03) other (0.03) first (0.02)(ADJ) p(u|t) VERB (0.32) ADV (0.27) NOUN (0.14) DET (0.39) ADP (0.17) ADJ (0.10)Particles p(w|t) ?s (0.93) ?
(0.07) to (0.89) up (0.04) out (0.02) off (0.01)(PRT) p(b|t) POS (1.00) TO (0.89) RP (0.10)Prepositions p(w|t) that (0.11) in (0.10) by (0.09) of (0.43) in (0.19) for (0.11)(ADP) p(u|t) VERB (0.46) NOUN (0.15) .
(0.13) NOUN (0.84) NUM (0.06) ADJ (0.03)Pronouns p(w|t) its (0.30) their (0.15) his (0.14) it (0.21) he (0.16) they (0.12)(PRON) p(b|t) PRP$ (0.68) PRP (0.26) WP (0.05) PRP (0.87) WP (0.11) PRP$ (0.02)Verbs p(w|t) be (0.06) been (0.02) have (0.02) is (0.10) said (0.08) was (0.05)(VERB) p(u|t) VERB (0.38) PRT (0.22) ADV (0.11) NOUN (0.52) PRON (0.20) .
(0.12)German Conjunctions p(w|t) da?
(0.26) wenn (0.08) um (0.06) und (0.76) oder (0.07) als (0.06)(CONJ) p(b|t) KOUS (0.58) KON (0.30) KOUI (0.06) KON (0.88) KOKOM (0.10) APPR (0.02)Particles p(w|t) an (0.13) aus (0.10) ab (0.09) nicht (0.49) zu (0.46) Nicht (0.01)(PRT) p(b|t) PTKVZ (0.92) ADV (0.04) ADJD (0.01) PTKNEG (0.52) PTKZU (0.44) PTKA (0.02)Pronouns p(w|t) sich (0.13) die (0.08) es (0.07) ihre (0.06) seine (0.05) seiner (0.05)(PRON) p(b|t) PPER (0.33) PRF (0.14) PRELS (0.14) PPOSAT (0.40) PIAT (0.34) PDAT (0.16)Verbs p(w|t) werden (0.04) worden (0.02) ist (0.02) ist (0.07) hat (0.04) sind (0.03)(VERB) p(u|t) NOUN (0.46) VERB (0.22) PRT (0.10) NOUN (0.49) .
(0.19) PRON (0.16)Table 1: Induced sub-tags and their statistics, word forms (p(w|t)), treebank tag (p(b|t)) and precedingUniversal tag probability (p(u|t)).
Bold: linguistically interesting differences.only a way to increase HMM tagger performancebut also yields annotations that are to a consid-erable extent linguistically interpretable.
As anexample we discuss some splits that occurred af-ter a particular split-merge step for English andGerman.
For the sake of comparability we ap-plied the split to the Universal Tagset (Petrov etal., 2011).
Table 1 shows the statistics used forthis analysis.
The Universal POS tag set puts thethree Penn-Treebank tags RP (particle), POS (pos-sessive marker) and TO into one particle tag (see?PRT?
in English part of the table).
The trainingessentially reverses this by splitting particles firstinto possessive and non-possessive markers and ina subsequent split the non-possessives into TO andparticles.
For German we have a similar split intoverb particles, negation particles like nicht ?not?and the infinitive marker zu ?to?
(?PRT?)
in theGerman part of the table).
English prepositionsget split by proximity to verbs or nouns (?ADP?
).Subordinate conjunctions like that, which in thePenn-Treebank annotation are part of the prepo-sition tag IN, get assigned to the sub-class nextto verbs.
For German we also see a separationof ?CONJ?
into predominantly subordinate con-junctions (Tag 0) and predominantly coordinatingconjunctions (Tag 1).
For both languages adjec-tives get split by predicative and attributive use.For English the predicative sub-class also seemsto hold rather atypical adjectives like ?such?
and?last.?
For English, verbs (?VERB?)
get split intoa predominantly infinite tag (Tag 0) and a predom-inantly finite tag (Tag 1) while for German we geta separation by verb position.
In German we get aseparation of pronouns (?PRON?)
into possessiveand non-possessive; in English, pronouns get splitby predominant usage in subject position (Tag 0)and as possessives (Tag 1).Our implementation of HMM-LA has been re-leased under an open-source licence.1In the next section we evaluate the utility ofthese annotations for dependency parsing.4 Dependency ParsingIn this section we investigate the utility of in-duced POS as features for dependency parsing.We run our experiments on the CoNLL-2009 datasets (Haji?c et al., 2009) for English and German.As a baseline system we use the latest versionof the mate-tools parser (Bohnet, 2010).3It wasthe highest scoring syntactic parser for Germanand English in the CoNLL 2009 shared task eval-uation.
The parser gets automatically annotatedlemmas, POS and morphological features as inputwhich are part of the CoNLL-2009 data sets.In this experiment we want to examine the ben-efits of tag refinements isolated from the improve-ments caused by using two taggers in parallel,thus we train the HMM-LA on the automaticallytagged POS sequences of the training set and useit to add an additional layer of refined POS to theinput data of the parser.
We do this by calculatingthe forward-backward charts that are also used inthe E-steps during training ?
in these charts base1https://code.google.com/p/cistern/1Unlabeled Attachment Score3We use v3.3 of Bohnet?s graph-based parser.964#Tags ?LASmaxLAS?LAS?UASmaxUAS?UASEnglish Baseline 88.43 91.4658 88.52 (88.59) 0.06 91.52 (91.61) 0.0873 88.55 (88.61) 0.05 91.54 (91.59) 0.0492 88.60 (88.71) 0.08 91.60 (91.72) 0.08115 88.62 (88.73) 0.07 91.58 (91.71) 0.08144 88.60 (88.70) 0.07 91.60 (91.71) 0.07German (no feat.)
Baseline 87.06 89.5485 87.09 (87.18) 0.06 89.61 (89.67) 0.04107 87.23 (87.36) 0.09 89.74 (89.83) 0.08134 87.22 (87.31) 0.09 89.75 (89.86) 0.09German (feat.)
Baseline 87.35 89.7585 87.33 (87.47) 0.11 89.76 (89.88) 0.09107 87.43 (87.73) 0.16 89.81 (90.14) 0.17134 87.38 (87.53) 0.08 89.75 (89.89) 0.08Table 2: LAS and UAS1mean (?
), best value (max) and std.
deviation (?)
for the development set forEnglish and German dependency parsing with (feat.)
and without morphological features (no feat.
).tags of the refined tags are constrained to be iden-tical to the automatically predicted tags.We use 100 EM iterations after each split andmerge phase.
The percentage of splits reverted ineach merge phase is set to .75.We integrate the tags by adding one additionalfeature for every edge: the conjunction of latenttags of the two words connected by the edge.Table 2 shows results of our experiments.
Allnumbers are averages of five independent runs.For English the smaller models with 58 and 73tags achieve improvements of ?.1.
The improve-ments for the larger tag sets are ?.2.
The bestindividual model improves LAS by .3.
For theGerman experiments without morphological fea-tures we get only marginal average improvementsfor the smallest tag set and improvements of ?.15for the bigger tag sets.
The average ULA scoresfor 107 and 134 tags are at the same level as theULA scores of the baseline with morph.
features.The best model improves LAS by .3.
For Germanwith morphological features the absolute differ-ences are smaller: The smallest tag set does notimprove the parser on average.
For the tag setof 107 tags the average improvement is .08.
Thebest model improves LAS by .38.
In all experi-ments we see the highest improvements for tag setsizes of roughly the same size (115 for English,107 for German).
While average improvementsare low (esp.
for German with morphological fea-tures), peak improvements are substantial.Running the best English system on the test setgives an improvement in LAS from 90.34 to 90.57;this improvement is significant4(p < .02).
ForGerman we get an improvement from 87.92 to4Approx.
randomization test (Yeh, 2000) on LAS scores88.24 without and from 88.35 to 88.51 with mor-phological features.
The difference between thevalues without morphological features is signifi-cant (p < .05), but the difference between mod-els with morphological features is not (p = .26).However, the difference between the baseline sys-tem with morphological features and the best sys-tem without morphological features is also not sig-nificant (p = .49).We can conclude that HMM-LA tags can sig-nificantly improve parsing results.
For German wesee that HMM-LA tags can substitute morpholog-ical features up to an insignificant difference.
Wealso see that morphological features and HMM-LA seem to be correlated as combining the twogives only insignificant improvements.5 Contribution AnalysisIn this section we try to find statistical evidencefor why a parser using a fine-grained tag set mightoutperform a parser based on treebank tags only.The results indicate that an induced latent tagset as a whole increases parsing performance.However, not every split made by the HMM-LAseems to be useful for the parser.
The scatter plotsin Figure 1 show that there is no strict correlationbetween tagging accuracy of a model and the re-sulting LAS.
This is expected as the latent induc-tion optimizes a tagging objective function, whichdoes not directly translate into better parsing per-formance.
An example is lexicalization.
Mostlatent models for English create a subtag for thepreposition ?of?.
This is useful for a HMM as ?of?is frequent and has a very specific context.
A lexi-calized syntactic parser, however, does not benefitfrom such a tag.965l l l ll88.40 88.45 88.50 88.55 88.60 88.65 88.70 88.7597.597.697.797.897.998.0LASTagging Accuracy87.00 87.05 87.10 87.15 87.20 87.25 87.30 87.3597.1097.1297.1497.1697.1897.20LASTagging Accuracy87.2 87.3 87.4 87.5 87.6 87.797.1097.1297.1497.1697.1897.20LASTagging AccuracyFigure 1: Scatter plots of LAS vs tagging accuracy for English (left) and German without (middle) andwith (right) morphological features.
English tag set sizes are 58 (squares), 73 (diamonds), 92 (trian-gles), 115 (triangles pointing downwards) and 144 (circles).
German tag set sizes are 85 (squares), 107(diamonds) and 134 (triangles).
The dashed lines indicate the baselines.We base the remainder of our analysis on theresults of the baseline parser on the English devel-opment set and the results of the best performinglatent model.
The best performing model has aLAS score of 88.73 vs 88.43 for the baseline, a dif-ference of .3.
If we just look at the LAS of wordswith incorrectly predicted POS we see a differenceof 1.49.
A look at the data shows that the latentmodel helps the parser to identify words that mighthave been annotated incorrectly.
As an exampleconsider plural nouns (NNS) and two of their la-tent subtags NNS1and NNS2and how often theyget classified correctly and misclassified as propernouns (NNPS):NNS NNPSNNS 2019 104NNS190 72NNS21100 13. .
.
.
.
.
.
.
.We see that NNS1is roughly equally likely tobe a NNPS or NNS while NNS2gives much moreconfidence of the actual POS being NNS.
So onebenefit of HMM-LA POS tag sets are tags of dif-ferent levels of confidence.Another positive effect is that latent POS tagshave a higher correlation with certain dependencyrelations.
Consider proper nouns (NNP):NAME NMOD SBJNNP 962 662 468NNP110 27 206NNP224 50 137. .
.
.
.
.
.
.
.
.
.
.We see that NNP1and NNP2are more likelyto appear in subject relations.
NNP1contains sur-names; the most frequent word forms are Keating,Papandreou and Kaye.
In contrast, NNP2con-tains company names such as Sony, NBC and Key-stone.
This explains why the difference in LAS istwice as high for NNPs as on average.For German we see similar effects and the an-ticipated correlation with morphology.
The 5 de-terminer subtags, for example, strongly correlatewith grammatical case:Nom Gen Dat AccART 1185 636 756 961ART1367 7 38ART211 28 682 21ART36 602 7 3ART439 43 429ART5762 6 17 4706 Conclusion and Future WorkWe have shown that HMMs with latent anno-tations (HMMLA) can generate latent part-of-speech tagsets are linguistically interpretable andcan be used to improve dependency parsing.
Ourbest systems improve an English parser from aLAS of 90.34 to 90.57 and a German parser from87.92 to 88.24 when not using morphological fea-tures and from 88.35 to 88.51 when using mor-phological features .
Our analysis of the parsingresults shows that the major reasons for the im-provements are: the separation of POS tags intomore and less trustworthy subtags, the creation ofPOS subtags with higher correlation to certain de-pendency labels and for German a correlation oftags and morphological features such as case.7 Future WorkThe procedure works well in general.
However,not every split is useful for the parser; e.g., as966discussed above lexicalization increases HMM ac-curacy, but does not help an already lexicalizedparser.
We would like to use additional informa-tion (e.g., from the dependency trees) to identifyuseless splits.
The different granularities of the hi-erarchy induced by split-merge training are poten-tially useful.
However, the levels of the hierarchyare incomparable: a child tag is in general not asubtag of a parent tag.
We think that coupling par-ents and children in the tag hierarchy might be oneway to force a consistent hierarchy.AcknowledgmentsWe would like to thank the anonymous reviewersfor their comments.
The first author is a recipientof the Google Europe Fellowship in Natural Lan-guage Processing, and this research is supported inpart by this Google Fellowship and by DFG (grantSFB 732).
Most of this work was conducted whilethe authors worked at the Institute for Natural Lan-guage Processing of the University of Stuttgart.ReferencesBernd Bohnet.
2010.
Very high accuracy and fast de-pendency parsing is not a contradiction.
In Proceed-ings of COLING.Vladimir Eidelman, Zhongqiang Huang, and MaryHarper.
2010.
Lessons learned in part-of-speechtagging of conversational speech.
In Proceedings ofEMNLP.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al.
2009.
The conll-2009shared task: Syntactic and semantic dependencies inmultiple languages.
In Proceedings of CoNLL.Zhongqiang Huang, Vladimir Eidelman, and MaryHarper.
2009.
Improving a simple bigram hmmpart-of-speech tagger by latent annotation and self-training.
In Proceedings of NAACL.Slav Petrov and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Proceedings ofNAACL.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proceedings of ACL.Slav Petrov, Dipanjan Das, and Ryan McDon-ald.
2011.
A universal part-of-speech tagset.ArXiv:1104.2086v1.Xu Sun, Louis-Philippe Morency, Daisuke Okanohara,and Jun?ichi Tsujii.
2008.
Modeling latent-dynamicin shallow parsing: a latent conditional model withimproved inference.
In Proceedings of COLING.Alexander Yeh.
2000.
More accurate tests for thestatistical significance of result differences.
In Pro-ceedings of COLING.967
