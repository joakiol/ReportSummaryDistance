Automatic Learning for Semantic CollocationSatosh l  SEK INE*Tokyo Informat ion and Communicat ions  Research LaboratoryMatsush i ta  Electric Industr ia l  Co.,Ltd.3-10-1, higashimita, tama-ku, kawasaki 214 JAPANJ e remy J .CARROLLSof ia  ANANIADOUJun ' i ch i  TSUJ I ICentre for Computat iona l  LinguisticsUniversity of Manchester  Inst i tute of Science and TechnologyP.O.Box 88, Manchester M60 1QD, United KingdomAbst rac tThe real difficulty in development of practicalNLP systems comes from the fact that we donot have effective means for gathering "knowl-edge".
In this paper, we propose an algorithmwhich acquires automatically knowledge of se-mantic collocations among "words" from sam-ple corpora.The algorithm proposed in this paper tries todiscover semantic ollocations which will beuseful for disambiguating structurally ambigu-ous sentences, by a statistical approach.
Thealgorithm requires a corpus and minimum lin-guistic knowledge (parts-of-speech of words,simple inflection rules, and a small number ofgeneral syntactic rules).We conducted two experiments ofapplying thealgorithm to different corpora to extract dif-ferent types of semantic ollocations.
Thoughthere are some unsolved problems, the resultsshowed the effectiveness of the proposed algo-rithm.1 In t roduct ionQuite a few grammatical formalisms have been proposedby computational linguists, which are claimed to be"good" (declarative, highly modular, etc.)
for practi-cal application systems in NLP.
It has also been claimedthat extra-linguistic, domain specific knowledge is in-dispensable in most NLP applications, and computa-tional frameworks for representing and using such do-main knowledge have also been developed.However, the real difficulty in developing practicalNLP systems i due to the fact that we do not have effec-tive means for gathering the "knowledge", whether lin-*SEKINE is now a visitor at C.C.L., U.M.I.S.T.s ekine @ ccl.
umist, ac.
ukguistic or extra-linguistic.
In particular, it has been re-ported \[Ananiadou, 1990\] that not only extra-linguistic,domain knowledge but also linguistic knowledge requiredfor application systems varies, depending on text-type(technical reports, scientific papers, manuals, etc.
), sub-ject domain, type of application (MT, automatic ab-straction, etc.)
etc.
This means that we have to have ef-fective and efficient methods either for adapting alreadyexisting knowledge for a specific "sublanguage" or for ac-quiring knowledge automatically, for example from sam-ple corpora of given applications.In this paper, we propose an algorithm which auto-matically acquires knowledge of semantic ollocationsamong "words".
"Semantic" here means that the col-locations the algorithm discovers are not collocationsamong words in the sense of traditional linguistics butcollocations that reflect ontological relations among en-tities in given subject domains.
We expect that theknowledge to be extracted will not only be useful fordisambiguating sentences but also will contribute to dis-covering ontological classes in given subject domains.Though several studies with similar objectives havebeen reported \[Church, 1988\], \[Zernik and Jacobs, 1990\],\[Calzolari and Bindi, 1990\], \[Garside and Leech, 1985\],\[Hindle and Rooth, 1991\], \[Brown et al, 1990\], theyrequire that sample corpora be correctly analyzed ortagged in advance.
It must be a training corpus, whichis tagged or parsed by human or it needs correspondencebetween two language corpora.
Because their prepara-tion needs a lot of manual assistance or an unerring tag-ger or parser, this requirement makes their algorithm~,troublesome in actual application environments.
On theother hand, the algorithm in this paper has no suchrequirement, it requires only a minimum of linguisticknowledge, including parts-of-speech of words, simple in-flection rules, and a small number of general syntacticrules which lexicon based syntactic theories like HPSGCC etc.
normally assume.
The parser is not a deter-ministic parser, but a parser which produces all possibleanalyses.
All of the results are used for calculation ant104the system assumes that there is a correct answer amongthem.
The algorithm builds correct structural descrip-tions of sentences and discovers emantic ollocations atthe same time.
It works as a relaxation process.2 OverviewBefore giving the algorithm formally, we illustrate anoverview in this section, by using simple examples.Though the algorithm can be used to extract knowledgeuseful to resolve a wide range of syntactic ambiguities,we use here the prepositional phrase attachment problemas an illustrative xample.We assume a syntactic parser which provides all pos-sible analyses.
It produces yntactic descriptions of sen-tences in the form of syntactic dependency structures.That is, the description to be produced is represented bya set oftuples like \[head word, syntact i c  re la t ion ,argument\] ,  each of which expresses a dependency rela-tion in the input.
The syntactic relation in a tuple iseither a grammatical relation like SUB J, OBJ, etc.
(incase of a noun phrase) or a surface preposition like BY,WITH, etc.
Following the normal convention of depen-dency representation, the argument is represented by thegovernor of the whole phrase which fills the argumentposition.When an input sentence has attachment ambiguities,two or more tuples share the same argument and thesame syntactic-relation but have different head-words.For example, the description of the sentence"I saw a girl with a scarf.
"contains two tuples like\[girl, WITH, scarf\]\[saw, WITH, scarf\]As repeatedly claimed in natural language under-standing literature, in order to resolve this ambiguity,a system may have to be able to infer "a scar f  cannotbe used as an instrument to see", based on extra-linguistic knowledge.
A practical problem here is thatthere is no systematic way of accumulating such extra-linguistic knowledge for given subject fields.
Further-more, the ambiguity in a sentence like " I  saw a g i r lwith a te lescope"  cannot be resolved only by refer-ring to knowledge about the world.
It requires a fullrange of context understanding abilities, because theinterpretation of "a g i r l  with a te lescope"  is lesslikely in general but can be a correct one in certaincontexts.
That is, unless a system has a full range ofcontextual understanding abilities (which we think willbe impossible in most application environments in theforeseeable future), it cannot reject either of the possi-ble interpretations as "impossible".
The best a systemcan do, without full understanding abilities, is to selectmore plausible ones or reject less plausible ones.
Thisimplies that we have to introduce a measure by whichwe can judge plausibility of "interpretations".The algorithm we propose computes uch measuresfrom a given sample corpus in a certain way.
It givesa plausibility value to each possible tuple, based on thesample corpus.
For example, the tuples (saw, WITH,scar f )  and (g i r l ,  WITH, scar f )  might be assigned0.5 and 0.82 as their plausibility value, which would show(g i r l ,  WITH, scar f )  to be more plausible than (saw,WITH, scar f )  .
This produced knowledge can be usedto disambiguate interpretations of the sentence " I  sawa girl with a scar f " .The algorithm is based on the assumption that theontological characteristics of the objects and actions de-noted by words (or linguistic expressions in general) andthe nature of the ontological relations among them areexhibited, though implicitly, in sample texts.For example, nouns denoting objects which belong tothe same ontological classes tend to appear in similarlinguistic contexts (for example, in the same argumentpositions of the same or similar verbs).
Or if an ob-ject (or an ontological class of objects) is "intrinsically"related to an action (like " te lescope"  to "see") ,  theword denoting the class of objects co-occurs frequentlywith the verb denoting the action.
The co-occurrencewould be more frequent han that of those whose onto-logical relations are rather fortuitous, like "g i r l "  and"telescope".Note that we talk about extra-linguistic "ontology"for the sake of explaining the basic idea behind the ac-tual algorithm.
However, as you will see, we do notrepresent such things as ontological entities in the ac-tual algorithm.
The algorithm counts frequencies of co-occurrences among words and calculates word distanceswhich interpret such co-occurrences as contexts.
Nordo we posit any dichotomy between "intrinsic" relationsand "accidental" relations among actions and objects.Differences are  quantitative, not qualitative.
That is,co-occurrences of "girl" and "scarf" are more frequentthan, for example, those of "pig" and "scarf".The algorithm in this paper computes the plausibilityvalue of hypothesis-tuples like (g i r l ,  WITH, scar f ) ,(saw, WITH, scar f ) ,  etc., basically by countingfrequencies of instance-tuples \ [g i r l ,  WITH, scar f \ ] ,\[saw, WITH, scar f \ ] ,  etc.
generated from sample textsby a syntactic parser.3 Algor ithm3.1 Re laxat ion  Process  - In fo rmal  Exp lanat ionof  the  A lgor i thmThough the algorithm simply counts frequencies of co-occurrences of word relations, there are some compli-cations.
In this section, we also use the prepositionalphrase attachment problem as an example, though thealgorithm can be applied to any kind of structural am-biguity.1.
We have to count frequencies of "meaningful" co-occurrences between verbs and nouns, i.e.
co-occurrences where the nouns actually appear in theposition of the head-noun of PP's  which can be at-tached to verbs or other nouns.
The frequency of"general" co-occurrences where the two words oc-cur, for example, in the same sentences may be oflittle use.This means that we encounter the problem of thechicken and the egg here, i.e.
in order to obtain ire-105quencies of "meaningful" co-occurrences in sampletexts, we have to know the correct attachment po-sitions of PPs, and determining the correct attach-ments of PPs in sample texts requires knowledge offrequencies of "meaningful" co-occurrences.2.
We usually cannot expect o have a corpus of samplesentences large enough for "intrinsic" relations toappear significantly more often than "accidental"relations.
It is desirable, or inevitable in a sense,to introduce methods of increasing the number ofco-occurrences.One possible way of doing this (which we haveadopted in our algorithm) is to introduce "seman-tic" similarity measures between words, and countthe number of extended co-occurrences taking thesimilarity measures into account.
That is, thefrequency of \[girl, WITH, necklace\] in sampletexts contributes not only to the plausibility valueof the tuple (g i r l ,  WITH, neck lace) ,  but alsoto that of (g i r l ,  WITH, scar f ) ,  according to thesimilarity value (or semantic distance) of "scar f "and "necklace".Because we compute semantic distances amongnouns based on (dis-)similarities of their patterns ofco-occurrence with other words (in short, two nounsare judged to be close to each other, if they oftenco-occur with the same words), we also encounteran chicken and egg problem here.
The calculationof semantic distance requires frequencies of collo-cation, and in order to find semantic ollocations,semantic distance could be helpful.The two chicken and egg problems in the above aretreated differently in the algorithm.
We focus onthe first problem in this paper, while readers whoare interested in the second problem can refer to\[Sekine t al., 1992\]In the following, we call the tuples generatedfrom sample texts by a parser "instance-tuples"and the tuples to which plausibility value are as-signed "hypothesis-tuples".
Instance-tuples andhypothesis-tuples are indicated by \[A, R, B\] and (A,R, B), respectively.Note that for the sake of explanation the followingis not an accurate description of the algorithm.
Anaccurate one is given in the next section.Input: I saw a girl with a telescope.
(STEP-I)  Generate instance-tuplesAll possible instance-tuples suchas \[saw, SUBJ, I\], \[girl, WITH, te lescope\ ] ,\[saw, WITH, te lescope\ ] ,  etc.
are generated by asimple parser.
(STEP-2) Assign creditsAssign credits to the instance-tuples, by consideringthe plausibility value of corresponding hypothesis-tuples.
As we will explain later, we assign credits insuch a way that(a)(b)the sum of credits assigned to competinginstance-tuples is equal to 1.
Competing tuplesmeans such tuples as \[girl, WITH, scar f \ ]and \[saw, WITH, scar f \ ]  which show differentattachment positions of the same PP.the credits assigned to instance-tuples are pro-portional to the plausibility value of the corre-sponding hypothesis-tuples.Because hypothesis-tuples have the same plau-sibility value at the initial stage, each instance-tuple is assigned the same credit, say, 1/(num-ber of competing tuples).
The credit of \[saw,SUB J, I\] is one, while the credits of \ [g i r l ,WITH, scar f \ ]  and \[saw, WITH, scar f \ ]  are0.5.
(STEP-3) Calculate plausibility valuesCompute plausibility values of hypothesis-tuples,accumulating credits assigned to the correspondinginstance-tuples.All occurrences of instance-tuples generated fromthe sample corpus have their credits assigned in(STEP-2).
We assume that tuples correspond-ing to "intrinsic" ontological relations occur moreoften in texts than "accidental" ones.
That is,we expect that instance-tuples of \ [g i r l ,  WITH,scar f \ ]  occur more often than those of \[saw, WITH,scar f \ ]  and that the sum of the credits of \ [g i r l ,WITH, scar f \ ]  is greater than that of \[saw, WITH,scar f \ ] .
This leads to a higher plausibility valuefor (g i r l .
,  WITH, scar f )  than for (saw, WITH,scar f ) .After (STEP-3), the algorithm goes back to (STEP-2) to compute new credits to instance-tuples.
Unlik~the first cycle, because the hypothes{s-tuple (g i r l ,WITH, scar f )  has been assigned a higher plausi.bility value than (saw, WITH, scar f ) ,  the creditto be assigned to \ [g i r l ,  WITH, scar f \ ]  would b~higher than \[saw, WITH, scar f \ ] .When we recompute the plausibility value ii(STEP-3), the increased credit assigned to \[gir l~WITH, scar f \ ]  in (STEP-2) increases the plausibility value of (girl, WITH, scarf) and on the othelhand, the decreased credit of \[saw, WITH, scar f :results in a lower plausibility value for (saw, WITHscar f ) .By repeating (STEP-2) and (STEP-3), we expecthere should be an increase in the credits assigned t~instance-tuples which correspond to correct attachment position.
Further, the credits of hypothesistuples should approach values which represent th,real "intrinsicality" of the denoted relationships.
(STEP-3) will be further augmented by introducinsemantic distances between words., i.e.
a similahypothesis helps to increase the credit of a hypothesis.
We expect his should resolve the second typof chicken and egg problems.
See \[Sekine t al1992\]1063.2 Termino logy  and notat ioninstance-tuple \[h, r, a\] : a token of a dependency rela-tion; part of the analysis of a sentence in a corpus.hypothesis-tuple (h,r ,a) :  a dependency relation; anabstraction or type over identical instance-tuples.cycle : repeat time of the relaxation cycle.CT,~ : Credit of instance-tuple T with identificationnumber i.
\[0, 1\]V~ : Plausibility value of a hypothesis-tuple T in cycleg.
\[0, 1\]D g (wa,wb) : distance between words, w= and Wb incycle g. \[0, 1\]3.3 A lgor i thm1.
For each sentence we use a simple grammar to findall tuples possibly used in this sentence.
Eachinstance-tuple is then given credit in proportion tothe number of competing tuples.1CT = number of competing tuples (1)This credit shows which rules are suitable for thissentence.
On the first iteration thesplit of the creditbetween ambiguous analyses is uniform as shownabove, but on subsequent i erations plausibility val-ues of the hypothesis-tuples V~ -1 before the itera-tion are used to give preference to credit for someanalyses over others.
The formula for this will beshown later.2.
Hypothesis-tuples have a plausibility value whichindicates their reliability by a figure from 0 to 1.If an instance-tuple occurs frequently in the cor-pus or if it occurs where there are no alternativetuples, the plausibility value for the correspondinghypothesis must be large.
After analysing all thesentences of the corpus, we get a set of sentenceswith weighted instance-tuples.
Each instance-tupleinvokes a hypothesis-tuple.
For each hypothesis-tuple, we define the plausibility value by the fol-lowing formula.
This formula is designed so thatthe value does not exceed 1.V~{ : 1 - H (1 - CT,~) (2)i3.
At this stage, the word-distances can be used tomodify the plausibility values of the hypothesis-tuples.
The word-distances are either defined ex-ternally by human intuition or calculated in theprevious cycle with the formula shown later.
Dis-tance between words induces a distance betweenhypothesis-tuples.
Then for each hypothesis-tuple,another hypothesis-tuple which gives greatest effectcan be used to increase its plausibility value.
Thenew plausibility value with similar hypothesis-tupleeffect is calculated by the following formula.V~{ = V@ + (1 - V~{) * V~, ?
(1 - D g (w=, wb)) 2 (3)4.Here, the hypothesis-tuple T '  is the hypothesis-tuple which gives the greatest effect to thehypothesis-tuple T (original one).
Hypothesis-tupleT and T'  have all the same elements except one.The distance between T and T'  is the distance be-tween the different elements, w= and Wb.
Ordinarilythe difference is in the head or argument element,but when the relation is a preposition, it is possibleto consider distance from another preposition.Distances between words are calculated on the basisof similarity between hypothesis-tuples about them.The formula is as follows:.D g (w~, wb) ET  (V~{ - V~{,)# = (4)nT and T'  are hypothesis-tuples whose arguments arew= and wb, respectively and whose heads and rela-tions are the same.
/9 is a constant parameter.This procedure will be repeated from the begin-ning, modifying the credits of instance-tuples be-tween ambiguous analyses by using the plausibilityvalues of hypothesis-tuples.
This will hopefully bemore accurate than the previous cycle.
On the firstiteration, we used just a constant figure for the cred-its of instance-tuples.
But this time we can use theplausibility value of the hypothesis-tuple which wasdeduced from the previous iteration.
Hence witheach iteration we expect more reliable figures.
1'ocalculate the new credit of instance-tuple T, we use:.CT -- V~ a o)Here, V@ in the numerator position is the plausi-bility value of a hypothesis-tuple which is the sametuple as the instance-tuple T. VT g in the denomina-tor position are the plausibility values of competinghypothesis-tuples in the sentence and the plausibil-ity value of the same hypothesis-tuple itself, a is aconstant parameter.Iterate step 1 to 5 several times, until the informa-tion is saturated.4 Exper imentWe conducted two experiments to show the effectivenessof our algorithm.
The first one uses a small, artificialcorpus to show how the algorithm works.
The secondone is a real experiment in which we use data from areal corpus (computer manuals).4.1 Art i f ic ia l  corpusWe treat the prepositional attachment ambiguity in thisexperiment.
Though the corpus consists of only 7 arti-ficial sentences, this experiment shows the basic charac-teristics and the effectiveness of the algorithm.The corpus and the input data to the algorithm are asfollows:107Sentences:I saw a gir l  with a telescope.I saw a gir l  with a scarf.I saw a gir l  with a necklace.I saw the moon with a telescope.I meet a gir l  with a telescope.A gir l  with a scarf saw me.I saw a gir l  without a scarf.Dict ionary:I, girl, moon, telescope,scarf, necklace,  me = Nounsaw, meet = Verbwi th ,wi thout  = Prepos i t ionDistances:0.2 = {with without}0.2 = {scarf  neck lace}0.3 = {saw meet}1.0 = between unspec i f ied  wordsRules of Grammar:Noun <-(SUB J)- VerbVerb - (OBJ) -> NounNoun - (Prep<with>)-> NounVerb - (Prep<with>)-> NounTable 1 shows the result of the first cycle.
Figuresin this table show the plausibility values of hypothesis-tuples between the words in the corresponding columns.The plausibility value of the hypothesis-tuple (saw,WITH, te lescope) ,  for example, is 0.75.WITH, neck lace)  becomes only 0.66.
The differencein the behavior of these two hypothesis-tuples is causedby the difference of the plausibility values assigned tothe hypothesis-tuples (g i r l ,  WITH, scar f )  and (saw,WITH, scar f ) .
The plausibility values are 1.00 and 0.50respectively.saw WITHgirl WITHmoon WITHmeet WITHsaw WITHOUTgirl WITHOUTtelescope scarf necklace0.81 0.66 0.660.75 1.00 0.820.50 - -0.68 0.24 0.240.48 0.66 0.320.48 0.82 0.32Table 2: Plausibility values with similar hypothesis effectThen we proceed to the second cycle, using the plausi-bility values which were produced in the previous cycle.Table 3 shows the plausibility values after the fifth cycle.saw WITHgirl WITHmoon WITHmeet WITHsaw WITHOUTgirl WITHOUTtelescope scarf necklace1.00 0.26 0.300.93 1.00 0.990.00 0.00 0.000.57 0.04 0.040.64 0.01 0.010.58 1.00 0.64Table 3: Plausibility values after the fifth cyclesaw WITHgirl WITHmoon WITHmeet WITHsaw WITHOUTgirl WITHOUTtelescope0.750.750.500.50scarf necklace0.50 0.501.00 0.500.500.50Table 1: Plausibility values after the first cycleThese plausibility values basically reflect the num-ber of co-occurrences of the two words.
However, thehypothesis-tuple (g i r l ,  WITH, scar f )  has plausibil-ity value 1.0, because in the sentence "A g i r l  with ascar f  saw me", there is no ambiguity in the attachmentposition of "with a scar f " .Then we compute the effects of similar hypothesis-tuples by considering distances among words.
The effectswhich the existence of similar hypotheses has on otherhypotheses are clearly shown in Table 2.The plausibility values of the hypothesis-tuples havechanged from the former ones.
For example, we canfind a sharp distinction between the plausibility valuesof the hypothesis-tuples ( aw, WITH, neck lace)  and(g i r l ,  WITH, neck lace)  Though these two have thesame plausibility value 0.50 before considering the effectof similar hypotheses, the plausibility value of (g i r l ,WITH, neck lace)  becomes 0.82 while that of (saw,By the fifth cycle, most of the figures have moved well?
towards the extremes, either 0 or 1.For example, the plausibility values of the hypothesis-tuples (saw, WITH, necklace)  and (girl, WITH,neck lace) ,  are well apart, 0.30 and 0.99, respectively,although they had the same plausibility value after thefirst cycle.
Also the hypothesis-tuple (moon, WITH,te lescope)  has the plausibility value 0.00, though itsinitial plausibility value was 0.50.
We can claim that thelearning process has worked well in making these differ-ences.On the other hand, if the movement owards ex-treme values was too strong, there might be a pos-sibility that only the strongest plausibility value sur-vived.
When there are two hypotheses which have in-stances in the same sentence, how do the plausibilityvalues move?
This can be seen with the two hypothesis-tuples (saw, WITH, te lescope)  and (girl, WITH,te lescope)  which are contradictory hypothesis-tuple~in the sentence "I saw a gir l  w i th  a te lescope"In the results, both of their plausibility values are hig\[and avoid the monopoly, because a number of instancetuples and a similar hypothesis contribute to increasethe plausibility values of both of the hypotheses tuples.Note that the relation (saw, WITHOUT, te lescope)which does not appear in the sentences, has a rathe~high plausibility value, 0.64.
This occurred becaus~of the effect of the similar hypothesis-tuple (saw:WITH, te lescope) .
But the relation (meet,  WITH108te lescope) ,  which has a relatively high plausibilityvalue 0.57, is normally unacceptable.
This is caused bythe close distance between the words 'meet '  and ' see ' .The distances between words in the 5th cycle areshown in Table 4.telescopetelescope 0'.00scarf 0.54necklace 0.52scarf necklace0.54 0.520.00 0.260.26 0.00Table 4: Distances between words in the 5th cyclewe put the credit 1/2 for each instance-tuple in whichN2 is an argument.We have not made any word distance information be-fore the process.We classified the results obtained as correct or incor-rect.
'Correct' means that a hypothesis-tuple which hasthe highest plausibility value is the correct tuple accord-ing to our human judgement. '
Incorrect' means it isjudged wrong by a human.
'Indefinite' means that plau-sibility values of some hypothesis-tuples have the samehighest value.
'Uncertain' means that it is impossibleeven for a human to judge which hypothesis tuple is thebest without context.
The results are shown in Table 6.These results, both the plausibility values ofhypothesis-tuples and the word distances, seem to be-have as we expected.4.2 The  Japanese  compound noun corpusWe conducted an experiment using compound nouns ex-tracted from a :Japanese computer manual, because ofits simplicity and feasibility.
The corpus consists of 4152sentences (about 90,000 words).
This might be smallconsidered for statistical analysis purpose, but as thecorpus is a sublanguage one, the structures of sentencesare rather homogeneous and therefore the number of sen-tences might be considered sufficient.There are 616 compound nouns in the corpus, where210 different words appear.
We call an element word ofa compound noun a 'word'.No.
of words No.
of compound nouns2 4743 1134 275 2total 616Table 5: Number of compound nounsWe assume that all words in each compound noun canbe structurally related, if they satisfy a condition that arelation has a preceding argument and a following head.For example, from a compound noun with 4 elements,we can extract 6 tuples as follows.Compound noun: N1 N2 N3 N4tuples initialcreditIN2, MODIFY, N1\] 1/3IN3, MODIFY, NI\] 1/3\[N4, MODIFY, NIl i/3\[N3, MODIFY, N2\] I/2IN4, MODIFY, N2\] i/2IN4, MODIFY, N3\] 1We know that each element can be the argument inone relation.
In the above example, N1 has 3 instance-tuples in which to be the argument.
We put the credit1/3 as initial credit for each instance-tuple.
Similarly,Words345total(%)correct incorrect indefinite uncertain66 29 5 1341 7 5 14 0 0 2111 36 10 16(70.7) (22.9) (6.4) (-)Table 6: Results of experiment with compound nounsThe percentage of correct answers was about 70 %.Though this result is not as impressive as that of thelast experiment, it is not bad.From a perusal of the incorrect analyses, we canfind typical reasons for making an incorrect analysis.When there are 2 competing tuples for a 3-element com-pound noun, these tuples are individually both accept-able in many cases.
For example, let's take a compoundnoun 'file transfer operation'.
If we consider thetwo instance-tuples, \ [ t rans fer ,  MODIFY, f i l e \ ]  and\ [operat ion ,  MODIFY, f i l e \ ] ,  both are acceptable inthe absence of any context.
In this case, the plausibilityvalues of the two hypothesis-tuples become almost thesame.
But there might be a very small difference whichmay be caused by the effect of a similar hypothesis-tuple.If the wrong hypothesis tuple gains the higher plausibil-ity value, the analysis becomes wrong.We think that the relation between the words of acompound noun can be defined not only by a semanticrelation between each word but also by the structureof the compound noun itself.
This feature of compoundnouns makes it hard to get a higher percentage of correctanswers in this experiment.5 Unso lved  Prob lems(a) ParametersThe behavior of the algorithm changes according tothe two parameters, a in formula 5 and /3 in for-mula 4.
Though the parameters are set as a = 4.0and 13 --- 20.0 in the experiments, we have no estab-lished procedures for determining these parametersappropriately.
We need to develop criteria or meth-ods to determine these parameters, depending oncharacteristics of sample texts, etc..(b) Word sense ambiguity109The entity of collocational relation is representedby a word and the relation labels are either a sim-ple grammatical functions or a surface prepositions.This means we ignored the word sense ambiguity ofa word'or a preposition in this algorithm.
A newmethod to treat this problem might be needed.
(c) Combination with other clues of disambiguationIt is already known that ontological knowledge isnot the only clue to settle ambiguities.
There arethe problems related with context, discourse, situ-ation etc.. We want to weave these problems intoour algorithm.
It also has to be noted that ratherlocal, structural preferential clues may help disam-biguations.
\[Wilks, 1985\](d) Word distanceThough we currently assume that the semantic dis-tances of words are given in the form of single num-bers, our research group is now planning to extendto cover multi-dimensional spects of word mean-ings.
This extension may introduce another compli-cation in our algorithm.
(e) Form of collocationIn the current algorithm, semantic ollocations arerepresented in the form of a triplet (tuple).
How-ever, each tuple expresses only a collocation betweentwo words.
This is not sufficient for treating re-lationships among several words, such as subcate-gorization frames of predicates, knowledge frames,etc.
In order to treat such multi-word collocations,we may have to treat co-occurrences of triplets insimilar fashions to how we treat co-occurrences ofwords.6 Future  D i rec t ionsBesides planning to resolve the problems written above,there are some other ideas for extending our project.Some of them are really stimulating.
(a) More experimentsThough the results of the two preliminary experi-ments look promising, we have to conduct more ex-periments using another eal corpora before claim-ing that the algorithm is effective.
(b) Extension to Machine TranslationThough the algorithm in its present form is designedto acquire monolingual knowledge, we are planningto develop it for acquiring "knowledge" for transla-tion.If "semantic" collocations discovered by the algo-rithm reflect the domain ontology, the collocationsin two languages (and the semantic lasses of wordsto be produced based on the collocations) are ex-pected to be similar in the sense that their corre-spondence is rather straightforward.Experience in MT research, however, generally in-dicates the opposite, i.e.
monolingual regularitiesand bilingual regularities are sometimes orthogonaland the correspondences of two languages are notso straightforward.These two rather contradicting predictions (and ex-periences) have to be consolidated through actualexperiments.
(c) Incremental learning systemWe don't need to distinguish the knowledge acquisi-tion phase from the phase of using it in actual appli-cation systems.
It is possible to acquire knowledgeand exploit it at the same time.7 AcknowledgementsWe would like to thank our colleagues at CCL, in partic-ular Mr.J.Phillips, Mr.K.Kageura, Mr.S.Kinoshita andMiss.E.van de Veen, whose comments on various occa-sions have been very useful.Re ferences\[Ananiadou, 1990\] Sofia Ananiadou.
Sublanguage stud-ies as the Basis for Computer Support for MultilingualCommunication.
Proceedings of Termplan '90, KualaLumpur, 1990.\[Church, 1988\] Kenneth Ward Church.
Word Associa-tion Norms, Mutual Information, and Lexicography.Computational Linguistics, 16(1)22-29, March 1990.\[Zernik and Jacobs, 1990\] Uri Zernik and Paul Jacobs.Tagging for Learning: Collectin G thematic relationsfrom Corpus.
13ih COLING-90, 1990\[Calzolari and Bindi, 1990\]Nicoletta Calzolari and Remo Bindi.
Acquisition ofLexical Information from a large Italian Corpus.
13thCOLING-90, 1990\[Garside and Leech, 1985\] Roger Garside and FannyLeech.
A Probabilistic Parser 2nd Conference of theEuropean Chapter of the A.C.L., 1985.\[Hindle and Rooth, 1991\] Donald Hindle and MatsRooth.
Structural Ambiguity and Lexical Relations.29th Conference of the A.C.L., 1991.\[Brown et al, 1990\] Peter Brown, John Cocke, StephenA.Della Pietra, Vincent J.Della Pietra, FredrickJelinek, John D.Lafferty, Robert L.Mercer, PaulS.Roossin.
A statistical approach to machine trans-lation.
Computational Linguistics, 16(2) 79-85, 1990\[Wilks, 1985\] Yorick Wilks.
Right Attachment and Pref-erence Semantics.
2nd Conference of the EuropeanChapter of the A.C.L., 1985.\[Sekine t al., 1992\] S.Sekine, S.Ananiadou, J.J.Carroll~J.Tsujii.
Linguistic Knowledge Generator submitteapaper for the 14th COLING-92, 1992110
