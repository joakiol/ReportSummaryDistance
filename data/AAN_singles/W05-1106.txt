Hunmorph: open source word analysisViktor Tro?nIGK, U of Edinburgh2 Buccleuch PlaceEH8 9LW Edinburghv.tron@ed.ac.ukGyo?rgy GyepesiK-PRO Ltd.H-2092 BudakesziVilla?m u.
6.ggyepesi@kpro.huPe?ter Hala?csyCentre of Media Research and EducationStoczek u.
2H-1111 Budapesthp@mokk.bme.huAndra?s KornaiMetaCarta Inc.350 Massachusetts AvenueCambridge MA 02139andras@kornai.comLa?szlo?
Ne?methCMREStoczek u.
2H-1111 Budapestnemeth@mokk.bme.huDa?niel VargaCMREStoczek u.
2H-1111 Budapestdaniel@mokk.bme.huAbstractCommon tasks involving orthographicwords include spellchecking, stemming,morphological analysis, and morpho-logical synthesis.
To enable signifi-cant reuse of the language-specific re-sources across all such tasks, we haveextended the functionality of the opensource spellchecker MySpell, yield-ing a generic word analysis library, theruntime layer of the hunmorph toolkit.We added an offline resource manage-ment component, hunlex, which com-plements the efficiency of our runtimelayer with a high-level description lan-guage and a configurable precompiler.0 IntroductionWord-level analysis and synthesis problems rangefrom strict recognition and approximate matchingto full morphological analysis and generation.
Ourtechnology is predicated on the observation thatall of these problems are, when viewed algorith-mically, very similar: the central problem is todynamically analyze complex structures derivedfrom some lexicon of base forms.
Viewing wordanalysis routines as a unified problem means shar-ing the same codebase for a wider range of tasks, adesign goal carried out by finding the parameterswhich optimize each of the analysis modes inde-pendently of the language-specific resources.The C/C++ runtime layer of our toolkit, calledhunmorph, was developed by extending the code-base of MySpell, a reimplementation of the well-known Ispell spellchecker.
Our technology, likethe Ispell family of spellcheckers it descendsfrom, enforces a strict separation between thelanguage-specific resources (known as dictionaryand affix files), and the runtime environment,which is independent of the target natural lan-guage.Figure 1: ArchitectureCompiling accurate wide coverage machine-readable dictionaries and coding the morphologyof a language can be an extremely labor-intensivetask, so the benefit expected from reusing thelanguage-specific input database across tasks canhardly be overestimated.
To facilitate this resourcesharing and to enable systematic task-dependentoptimizations from a central lexical knowledgebase, we designed and implemented a powerful of-fline layer we call hunlex.
Hunlex offers an easyto use general framework for describing the lexi-con and morphology of any language.
Using thisdescription it can generate the language-specificaff/dic resources, optimized for the task at hand.The architecture of our toolkit is depicted in Fig-ure 1.
Our toolkit is released under a permissiveLGPL-style license and can be freely downloadedfrom mokk.bme.hu/resources/hunmorph.The rest of this paper is organized as follows.Section 1 is about the runtime layer of our toolkit.We discuss the algorithmic extensions and imple-mentational enhancements in the C/C++ runtimelayer over MySpell, and also describe the newlycreated Java port jmorph.
Section 2 gives anoverview of the offline layer hunlex.
In Section 3we consider the free open source software alterna-tives and offer our conclusions.1 The runtime layerOur development is a prime example of codereuse, which gives open source software devel-opment most of its power.
Our codebase is adirect descendant of MySpell, a thread-safe C++spell-checking library by Kevin Hendricks, whichdescends from Ispell Peterson (1980), which inturn goes back to Ralph Gorin?s spell (1971),making it probably the oldest piece of linguisticsoftware that is still in active use and development(see fmg-www.cs.ucla.edu/fmg-members/geoff/ispell.html).The key operation supported by this codebase isaffix stripping.
Affix rules are specified in a staticresource (the aff file) by a sequence of conditions,an append string, and a strip string: for example,in the rule forming the plural of body the stripstring would be y, and the affix string would beies.
The rules are reverse applied to complex inputwordforms: after the append string is stripped andthe edge conditions are checked, a pseudo-stem ishypothesized by appending the strip string to thestem which is then looked up in the base dictio-nary (which is the other static resource, called thedic file).Lexical entries (base forms) are all associatedwith sets of affix flags, and affix flags in turn areassociated to sets of affix rules.
If the hypothe-sized base is found in the dictionary after the re-verse application of an affix rule, the algorithmchecks whether its flags contain the one that theaffix rule is assigned to.
This is a straight table-driven approach, where affix flags can be inter-preted directly as lexical features that license en-tire subparts of morphological paradigms.
To pickapplicable affix rules efficiently, MySpell uses afast indexing technique to check affixation condi-tions.In theory, affix-rules should only specify gen-uine prefixes and suffixes to be stripped before lex-ical lookup.
But in practice, for languages withrich morphology, the affix stripping mechanism is(ab)used to strip complex clusters of affix morphsin a single step.
For instance, in Hungarian, dueto productive combinations of derivational and in-flectional affixation, a single nominal base canyield up to a million word forms.
To treat allthese combinations as affix clusters, legacy ispellresources for Hungarian required so many com-bined affix rule entries that its resource file sizeswere not manageable.To solve this problem we extended the affixstripping technique to a multistep method: afterstripping an affix cluster in step i, the resultingpseudo-stem can be stripped of affix clusters instep i+ 1.
Restrictions of rule application arechecked with the help of flags associated to affixesanalogously to lexical entries: this only requireda minor modification of the data structure codingaffix entries and a recursive call for affix stripping.By cross-checking flags of prefixes on the suffix(as opposed to the stem only), simultaneous pre-fixation and suffixation can be made interdepen-dent, extending the functionality to describe cir-cumfixes like German participle ge+t, or Hungar-ian superlative leg+bb, and in general provide thecorrect handling of prefix-suffix dependencies likeEnglish undrinkable (cf.
*undrink), see Ne?methet al (2004) for more details.Due to productive compounding in a lot of lan-guages, proper handling of composite bases is afeature indispensable for achieving wide coverage.Ispell incorporates the possibility of specifyinglexical restrictions on compounding implementedas switches in the base dictionary.
However, thealgorithm allows any affixed form of the bases thathas the relevant switch to be a potential memberof a compound, which proves not to be restrictiveenough.
We have improved on this by the intro-duction of position-sensitive compounding.
Thismeans that lexical features can specify whethera base or affix can occur as leftmost, rightmostor middle constituent in compounds and whetherthey can only appear in compounds.
Since thesefeatures can also be specified on affixes, this pro-vides a welcome solution to a number of resid-ual problems hitherto problematic for open-sourcespellcheckers.
In some Germanic languages, ?fo-gemorphemes?, morphemes which serve linkingcompound constituents can now be handled easilyby allowing position specific compound licensingon the foge-affixes.
Another important example isthe German common noun: although it is capital-ized in isolation, lowercase variants should be ac-cepted when the noun is a compound constituent.By handling lowercasing as a prefix with the com-pound flag enabled, this phenomenon can be han-dled in the resource file without resort to languagespecific knowledge hard-wired in the code-base.1.1 From spellchecking to morphologicalanalysisWe now turn to the extensions of the MySpellalgorithm that were required to equip hunmorphwith stemming and morphological analysis func-tionality.
The core engine was extended with anoptional output handling interface that can processarbitrary string tags associated with the affix-rulesread from the resources.
Once this is done, sim-ply outputting the stem found at the stage of dic-tionary lookup already yields a stemmer.
In mul-tistep affix stripping, registering output informa-tion associated with the rules that apply rendersthe system capable of morphological analysis orother word annotation tasks.
Thus the processingof output tags becomes a mode-dependent param-eter that can be:?
switched off (spell-checking)?
turned on only for tag lookup in the dictio-nary (simple stemming)?
turned on fully to register tags with all rule-applications (morphological analysis)The single most important algorithmic aspect thatdistinguishes the recognition task from analysisis the handling of ambiguous structures.
In theoriginal MySpell design, identical bases are con-flated and once their switch-set licensing affixesare merged, there is no way to tell them apart.The correct handling of homonyms is crucial formorphological analysis, since base ambiguitiescan sometimes be resolved by the affixes.
In-terestingly, our improvement made it possible torule out homonymous bases with incorrect simul-taneous prefixing and suffixing such as Englishout+number+?s.
Earlier these could be handledonly by lexical pregeneration of relevant forms orduplication of affixes.Most importantly, ambiguity arises in relationto the number of analyses output by the system.While with spell-checking the algorithm can ter-minate after the first analysis found, performingan exhaustive search for all alternative analyses isa reasonable requirement in morphological analy-sis mode as well as in some stemming tasks.
Thusthe exploration of the search space also becomesan active parameter in our enhanced implementa-tion of the algorithm:?
search until the first correct analysis?
search restricted multiple analyses (e.g., dis-abling compounds)?
search all alternative analysesSearch until the first analysis is a functionality forrecognizers used for spell-checking and stemmingfor accelerated document indexing.
Preemptionof potential compound analyses by existing lexi-cal bases serves as a general way of filtering outspurious ambiguities when a reduction is requiredin the space of alternative analyses.
In these cases,frequent compounds which trick the analyzer canbe precompiled to the lexicon.
Finally, there is apossibility to give back a full set of possible anal-yses.
This output then can be passed to a taggerthat disambiguates among the candidate analyses.Parameters can be used that guide the search (suchas ?do lexical lookup first at all stages?
or ?strip theshortest affix first?
), which yield candidate rank-ings without the use of numerical weights or statis-tics.
These rankings can be used as disambigua-tion heuristics based on a general idea of blocking(e.g., Times would block an analysis of time+s).All further parametrization is managed offline bythe resource compiler layer, see Section 2.1.2 Reimplementing the runtime layerIn our efforts to gear up the MySpell codebaseto a fully functional word analysis library we suc-cessfully identified various resource-related, algo-rithmic and implementational bottlenecks of theaffix-rule based technology.
With these lessonslearned, a new project has been launched in or-der to provide an even more flexible and efficientopen source runtime layer.
A principled object-oriented refactorization of the same basic algo-rithm described above has already been imple-mented in Java.
This port, called jmorph also usesthe aff/dic resource formats.In jmorph, various algorithmic options guidingthe search (shortest/longest matching affix) canbe controlled for each individual rule.
The im-plementation keeps track of affix and compoundmatches checking conditions only once for a givensubstring and caching partial results.
As a conse-quence, it ends up being measurably faster thanthe C++ implementation with the same resources.The main loop of jmorph is driven by config-uring consumers, i.e., objects which monitor therecursive step that is running.
For example theanalysis of the form besze?desek ?talkative.PLUR?begins by inspecting the global configuration ofthe analysis: this initial consumer specifies howmany analyses, and what kind, need to be found.In Step 1, the initial consumer finds the rule thatstrips ek with stem besze?des, builds a consumerthat can apply this rule to the output of the analy-sis returned by the next consumer, and launchesthe next step with this consumer and stem.
InStep 2, this consumer finds the rule stripping eswith stem besze?d, which is found in the lexicon.besze?d is not just a string, it is a complete lexi-cal object which lists the rules that can apply toit and all the homonyms.
The consumer creates anew analysis that reflects that besze?des is formedfrom besze?d by suffixing es (a suffix object), andpasses this back to its parent consumer, which ver-ifies whether the ek suffixation rule is applicable.If not, the Step 1 consumer requests further anal-yses from the Step 2 consumer.
If, however, theanswer is positive, the Step 1 consumer returns itsanalysis to the Step 0 (initial) consumer, which de-cides whether further analyses are needed.In terms of functionality, there are a number ofdifferences between the Java and the C++ variants.jmorph records the full parse tree of rule appli-cations.
By offering various ways of serializingthis data structure, it allows for more structuredinformation in the outputs than would be possibleby simple concatenation of the tag chunks asso-ciated with the rules.
Class-based restrictions oncompounding is implemented and will eventuallysupersede the overgeneralizing position-based re-strictions that the C++ variant and our resourcescurrently use.Two major additional features of jmorph areits capability of morphological synthesis as wellas acting as a guesser (hypothesizing lemmas).Synthesis is implemented by forward applicationof affix rules starting with the base.
Rules haveto be indexed by their tag chunks for the search,so synthesis introduces the non-trivial problem ofchunking the input tag string.
This is currently im-plemented by plug-ins for individual tag systems,however, this should ideally be precompiled off-line since the space of possible tags is limited.2 Resource development and offlineprecompilationDue to the backward compatibility of the runtimelayer with MySpell-style resources, our softwarecan be used as a spellchecker and simplistic stem-mer for some 50 languages for which MySpellresources are available, see lingucomponent.openoffice.org/spell dic.html.For languages with complex morphology, com-piling and maintaining these resources is a painfulundertaking.
Without using a unified frameworkfor morphological description and a principledmethod of precompilation, resource developers forhighly agglutinative languages like Hungarian (seemagyarispell.sourceforge.net) have to re-sort to a maze of scripts to maintain and precom-pile aff and dic files.
This problem is intolerablymagnified once morphological tags or additionallexicographic information are to be entered in or-der to provide resources for the analysis routinesof our runtime layer.The offline layer of our toolkit seeks to remedythis by offering a high-level description languagein which grammar developers can specify rule-based morphologies and lexicons (somewhat inthe spirit of lexc Beesley and Karttunen (2003),the frontend to Xerox?s Finite State Toolkit).
Thispromises rapid resource development which canthen be used in various tasks.
Once primary re-sources are created, hunlex, the offline precom-piler can generate aff and dic resources op-timized for the runtime layer based on variouscompile-time configurations.Figure 2 illustrates the description languagewith a fragment of English morphology describ-ing plural formation.
Individual rules are sepa-rated by commas.
The syntax of the rule descrip-tions organized around the notion of informationblocks.
Blocks are introduced by keywords (likeIF:) and allow the encoding of various propertiesof a rule (or a lexical entry), among others speci-fying affixation (+es), substitution, character trun-cation before affixation (CLIP: 1), regular ex-pression matches (MATCH: [^o]o), positive andnegative lexical feature conditions on application(IF: f-v_altern), feature inheritance, output(continuation) references (OUT: PL_POSS), out-put tags (TAG: "[PLUR]").One can specify the rules that can be applied tothe output of a rule and also one can specify appli-cation conditions on the input to the rule.
Thesetwo possibilities allow for many different stylesof morphological description: one based on in-put feature constraints, one based on continuationclasses (paradigm indexes), and any combinationbetween these two extremes.
On top of this, reg-ular expression matches on the input can also beused as conditions on rule application.Affixation rules ?grouped together?
here underPLUR can be thought of as allomorphic rules of theplural morpheme.
Practically, this allows informa-tion about the morpheme shared among variants(e.g., morphological tag, recursion level, someoutput information) to be abstracted in a pream-ble which then serves as a default for the individ-ual rules.
Most importantly, the grouping of rulesPLTAG: "[PLUR]"OUT: PL_POSS# house -> houses, +s MATCH: [^shoxy] IF: regular# kiss -> kisses, +es MATCH: [^c]s IF: regular# ...# ethics, + MATCH: cs IF: regular# body -> bodies <C> is a regexp macro, +ies MATCH: <C>y CLIP:1 IF: regular# zloty -> zlotys, +s MATCH: <C>y IF: y-ys# macro -> macros, +s MATCH: [^o]o IF: regular# potato -> potatoes, +es MATCH: [^o]o IF: o-oes# wife -> wives, +ves MATCH: fe CLIP: 2 IF: f-ves# leaf -> leaves, +ves MATCH: f CLIP: 1 IF: f-ves;Figure 2: hunlex grammar fragmentinto morphemes serves to index those rules whichcan be referenced in output conditions, For exam-ple, in the above the plural morpheme specifiesthat the plural possessive rules can be applied toits output (OUT: PL_POSS).
This design makes itpossible to handle some morphosyntactic dimen-sions (part of speech) very cleanly separated fromthe conditions regulating the choice of allomorphs,since the latter can be taken care of by input fea-ture checking and pattern matching conditions ofrules.
The lexicon has the same syntax as thegrammar only that morphemes stand for lemmasand variant rules within the morpheme correspondto stem allomorphs.Rules with zero affix morph can be used asfilters that decorate their inputs with featuresbased on their orthographic shape or other featurespresent.
This architecture enables one to let onlyexceptions specify certain features in the lexiconwhile regular words left unspecified are assigneda default feature by the filters (see PL_FILTER inREGEXP: C [bcdfgklmnprstvwxyz];DEFINE: NOUT: SG PL_FILTERTAG: NOUN;PL_FILTEROUT:PLFILTER:f-vesy-yso-oesregular, DEFAULT:regular;Figure 3: Macros and filters in hunlexFigure 3) potentially conditioned the same way asany rule application.
Feature inheritance is fullysupported, that is, filters for particular dimensionsof features (such as the plural filter in Figure 3)can be written as independent units.
This designmakes it possible to engineer sophisticated filterchains decorating lexical items with various fea-tures relevant for their morphological behavior.With this at hand, extending the lexicon with a reg-ular lexeme just boils down to specifying its baseand part of speech.
On the other hand, indepen-dent sets of filter rules make feature assignmentstransparent and maintainable.In order to support concise and maintainablegrammars, the description language also allows(potentially recursive) macros to abbreviate arbi-trary sets of blocks or regular expressions, illus-trated in Figure 3.The resource compiler hunlex is a stand-alone program written in OCaml which comeswith a command-line as well as a Makefile astoplevel control interface.
The internal workingsof hunlex are as follows.As the morphological grammar is parsed by theprecompiler, rule objects are created.
A block isread and parsed into functions which each trans-form the ?affix-rule?
data-structure by enriching itsinternal representation according to the semanticcontent of the block.
At the end of each unit,the empty rule is passed to the composition ofblock functions to result in a specific rule.
Thanksto OCaml?s flexibility of function abstraction andcomposition, this design makes it easy to imple-ment macros of arbitrary blocks directly as func-tions.
When the grammar is parsed, rules are ar-ranged in a directed (possibly cyclic) graph withedges representing possible rule applications asgiven by the output specifications.Precompilation proceeds by performing a re-cursive closure on this graph starting from lexi-cal nodes.
Rules are indexed by ?levels?
and con-tiguous rule-nodes that are on the same level aremerged along the edges if constraints on rule ap-plication (feature and match conditions, etc.)
aresatisfied.
These precompiled affix-clusters andcomplex lexical items are to be placed in the affand dic file, respectively.Instead of affix merging, closure between rulesa and b on different levels causes the affix clus-ters in the closure of b to be registered as rules ina hash and their indexes recorded on a.
After theentire lexicon is read, these index sets registeredon rules are considered.
The affix cluster rules tobe output into the affix file are arranged into max-imal subsets such that if two output affix clusterrules a and b are in the same set, then every itemor affix to which a can be applied, b can also beapplied.
These sets of affix clusters correspond topartial paradigms which each full paradigm eitherincludes or is disjoint with.
The resulting sets ofoutput rules are assigned to a flag and items ref-erencing them will specify the appropriate com-bination of flags in the output dic and aff file.Since equivalent affix cluster rules are conflated,the compiled resources are always optimal in thefollowing three ways.First, the affix file is redundancy free: no two af-fix rules have the same form.
With hand-coded af-fix files this can almost never be guaranteed sinceone is always inclined to group affix rules by lin-guistically motivated paradigms thereby possiblyduplicating entries.
A redundancy-free set of affixrules will enhance performance by minimizing thesearch space for affixes.
Note that conflation ofidentical rules by the runtime layer is not possiblewithout reindexing the flags which would be verycomputationally intensive if done at runtime.Second, given the redundancy free affix-set,maximizing homogeneous rulesets assigned to aflag minimizes the number of flags used.
Since theinternal representation of flags depends on theirnumber, this has the practical advantage of reduc-ing memory requirements for the runtime layer.Third, identity of output affix rules is calculatedrelative to mode and configuration settings, there-fore identical morphs with different morphologi-cal tags will be conflated for recognizers (spell-checking) where ambiguity is irrelevant, while foranalysis it can be kept apart.
This is impossibleto achieve without a precompilation stage.
Notethat finite state transducer-based systems performessentially the same type of optimizations, elimi-nating symbol redundancy when two symbols be-have the same in every rule, and eliminating stateredundancy when two states have the exact samecontinuations.Though the bulk of the knowledge used byspellcheckers, by stemmers, and by morphologi-cal analysis and generation tools is shared (howaffixes combine with stems, what words allowcompounding), the ideal resources for these var-ious tasks differ to some extent.
Spellcheck-ers are meant to help one to conform to ortho-graphic norms and therefore should be error sen-sitive, stemmers and morphological analyzers areexpected to be more robust and error tolerant espe-cially towards common violations of standard use.Although this seems at first to justify the individ-ual efforts one has to invest in tailoring one?s re-sources to the task at hand, most of the resourcespecifics are systematic, and therefore allow forautomatic fine-tuning from a central knowledgebase.
Configuration within hunlex allows thespecification of various features, among others:?
selection of registers and degree of normativ-ity based on usage qualifiers in the database(allows for boosting robustness for analysisor stick to normativity for synthesis and spell-checking)?
flexible selection of output information:choice of tagset for different encodings, sup-port for sense indexes?
arbitrary selection of morphemes?
setting levels of morphemes (grouping ofmorphs that are precompiled as a cluster tobe stripped with one rule application by theruntime layer)?
fine-tuning which morphemes are strippedduring stemming?
arbitrary selection of morphophonologicalfeatures that are to be observed or ignored(allows for enhancing robustness by e.g., tol-erating non-standard regularizations)The input description language allows for arbi-trary attributes (ones encoding part of speech, ori-gin, register, etc.)
to be specified in the descrip-tion.
Since any set of attributes can be selected tobe compiled into the runtime resources, it takesno more than precompiling the central databasewith the appropriate configuration for the runtimeanalyzer to be used as an arbitrary word annota-tion tool, e.g., style annotator or part of speechtagger.
We also provide an implementation of afeature-tree based tag language which we success-fully used for the description of Hungarian mor-phology.If the resources are created for some filteringtask, say, extracting (possibly inflected) propernouns in a text, resource optimization describedabove can save considerable amounts of time com-pared to full analysis followed by post-processing.While the relevant portion of the dictionary mightbe easily filtered therefore speeding up lookup, tai-loring a corresponding redundancy-free affix filewould be a hopeless enterprise without the pre-compiler.As we mentioned, our offline layer can be con-figured to cluster any or no sets of affixes togetheron various levels, and therefore resources can beoptimized for either memory use (affix by affixstripping) or speed (generally toward one levelstripping).
This is a major advantage given po-tential applications as diverse as spellchecking onthe word processor of an old 386 at one end, andindustrial scale stemming on terabytes of web con-tent for IR at the other.In sum, our offline layer allows for the princi-pled maintenance of a central resource, saving theredundant effort that would otherwise have to beinvested in encoding very similar knowledge in atask-specific manner for each word level analysistask.3 ConclusionThe importance of word level analysis can hardlybe questioned: spellcheckers reach the extremelywide audience of all word processor users, stem-mers are used in a variety of areas ranging frominformation retrieval to statistical machine transla-tion, and for non-isolating languages morpholog-ical analysis is the initial phase of every naturallanguage processing pipeline.Over the past decades, two closely intertwinedmethods emerged to handle word analysis tasks,affix stripping and finite state transducers (FSTs).Since both technologies can provide industrialstrength solutions for most tasks, when it comesto choice of actual software and its practical use,the differences that have the greatest impact arenot lodged in the algorithmic core.
Rather, twoother factors play a role: the ease with which onecan integrate the software into applications and theinfrastructure offered to translate the knowledge ofthe grammarian to efficient and maintainable com-putational blocks.To be sure, in an end-to-end machine learningparadigm, the mundane differences between howthe systems interact with the human grammari-ans would not matter.
But as long as the gram-mars are written and maintained by humans, an of-fline framework providing a high-level language tospecify morphologies and supporting configurableprecompilation that allows for resource sharingacross word-analysis tasks addresses a major bot-tleneck in resource creation and management.The Xerox Finite State Toolkit provides com-prehensive high-level support for morphologyand lexicon development (Beesley and Karttunen,2003).
These descriptions are compiled into mini-mal deterministic FST-s, which give excellent run-time performance and can also be extended toerror-tolerant analysis for spellchecking Oflazer(1996).
Nonetheless, XFST is not free software,and as long as the work is not driven by aca-demic curiosity alone, the LGPL-style license ofour toolkit, explicitly permitting reuse for com-mercial purposes as well, can already decide thechoice.There are other free open source ana-lyzer technologies, either stand-alone an-alyzers such as the Stuttgart Finite StateToolkit (SFST, available only under theGPL, see www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/SFST.html,Smid et al (2004)) or as part of a power-ful integrated NLP platform such as In-tex/NooJ (freely available for academic re-search to individuals affiliated with a universityonly, see intex.univ-fcomte.fr; a clonecalled Unitex is available under LGPL, seewww-igm.univ-mlv.fr/~unitex.)
Unfortu-nately, NooJ has its limitations when it comesto implementing complex morphologies (Vajdaet al, 2004) and SFST provides no high-leveloffline component for grammar description andconfigurable resource creation.We believe that the liberal license policy and thepowerful offline layer contributed equally to thehuge interest that our project generated, in spiteof its relative novelty.
MySpell was not just ourchoice: it is also the spell-checking library incor-porated into OpenOffice.org, a free open-sourceoffice suite with an ever wider circle of users.
TheHungarian build of OpenOffice is already runningour C++ runtime library, but OpenOffice is nowconsidering to completely replace MySpell withour code.
This would open up the possibility ofintroducing morphological analysis capabilities inthe program, which in turn could serve as the firststep towards enhanced grammar checking and hy-phenation.Though in-depth grammars and lexica are avail-able for nearly as many languages in FST-based frameworks (InXight Corporation?s Lin-guistX platform supports 31 languages), very lit-tle of this material is available for grammar hack-ing or open source dictionary development.
In ad-dition to permissive license and easy to integrateinfrastructure, the fact that the hunmorph routinesare backward compatible with already existing andfreely available spellchecking resources for some50 languages goes a long way toward explainingits rapid spread.For Hungarian, hunlex already serves as thedevelopment framework for the MORPHDB projectwhich merges three independently developed lex-ical databases by critically unifying their contentsand supplying it with a comprehensive morpho-logical grammar.
It also provided a frameworkfor our English morphology project that used theXTAG morphological database for English (seeftp.cis.upenn.edu/pub/xtag/morph-1.5,Karp et al (1992)).
A project describing themorphology of the Bea?s dialect of Romani withhunlex is also under way.The hunlex resource precompiler is not archi-tecturally bound to the aff/dic format used byour toolkit, and we are investigating the possibilityof generating FST resources with it.
This woulddecouple the offline layer of our toolkit from thedetails of the runtime technology, and would be animportant step towards a unified open source so-lution for method-independent resource develop-ment for word analysis software.AcknowledgementsThe development of hunmorph and hunlex is fi-nancially supported by the Hungarian Ministryof Informatics and Telecommunications and byMATA?V Telecom Co., and is led by the Centrefor Media Research and Education at the BudapestUniversity of Technology.
We would like to thankthe anonymous reviewers of the ACL SoftwareWorkshop for their valuable comments on this pa-per.AvailabilityDue to the confligting needs of Unix, Windows,and MacOs users, the packaging/build environ-ment for our software has not yet been final-ized.
However, a version of our tools, andsome of the major language resources that havebeen created using these tools, are available atmokk.bme.hu/resouces.ReferencesKenneth R. Beesley and Lauri Karttunen.
2003.Finite State Morphology.
CSLI Publications.Daniel Karp, Yves Schabes, Martin Zaidel, andDania Egedi.
1992.
A freely available wide cov-erage morphological analyzer for english.
InProceedings of the 14th International Confer-ence on Computational Linguistics (COLING-92) Nantes, France.La?szlo?
Ne?meth, Viktor Tro?n, Pe?ter Hala?csy,Andra?s Kornai, Andra?s Rung, and Istva?n Sza-kada?t.
2004.
Leveraging the open-source is-pell codebase for minority language analysis.In Proceedings of SALTMIL 2004.
EuropeanLanguage Resources Association.
URL http://www.lrec-conf.org/lrec2004.Kemal Oflazer.
1996.
Error-tolerant finite-staterecognition with applications to morphologicalanalysis and spelling correction.
ComputationalLinguistics, 22(1):73?89.James Lyle Peterson.
1980.
Computer programsfor spelling correction: an experiment in pro-gram design, volume 96 of Lecture Notes inComputer Science.
Springer.Helmut Smid, Arne Fitschen, and Ulrich Heid.2004.
SMOR: A German computational mor-phology covering derivation, composition, andinflection.
In Proceedings of the IVth Interna-tional Conference on Language Resources andEvaluation (LREC 2004), pages 1263?1266.Pe?ter Vajda, Viktor Nagy, and Em?
?lia Dancsecs.2004.
A Ragoza?si szo?ta?rto?l a NooJ morfolo?giaimodulja?ig [from a morphological dictionary toa morphological module for NooJ].
In 2nd Hun-garian Computational Linguistics Conference,pages 183?190.
