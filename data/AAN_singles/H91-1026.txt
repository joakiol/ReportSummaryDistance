Identifying Word Correspondences in Parallel TextsWilliam A. GaleKenneth W. Church IAT&T Bell LaboratoriesMurray Hill, N.J., 07974gale@research.att.com1.
IntroductionResearchers in both machine translation (e.g., Brown eta/, 1990) arm bilingual lexicography (e.g., Klavans andTzoukermarm, 1990) have recently become interested instudying parallel texts (also known as bilingualcorpora), bodies of text such as the Canadian Hansards(parliamentary debates) which are available in multiplelanguages ( uch as French and English).
Much of thecurrent excitement surrounding parallel texts wasinitiated by Brown et aL (1990), who outline a self-organizing method for using these parallel texts to builda machine translation system.Brown et al begin by aligning the parallel texts at thesentence l vel.
In our experience, 90% of the Englishsentences match exactly one French sentence, but otherpossibilities, especially two sentences matching one orone matching two, are not uncommon.
There has beenquite a bit of recent work on sentence alignment, e.g.,(Brown, Lai and Mercer, 1990, (Kay and Rbscheisen,1988), (Catizone, Russell, and Warwick, to appear); weuse a method described in (Gale and Church, 1991)which makes use of the fact that the length of a text (incharacters) i~ 5ighly correlated (0.991) with the lengthof its translation.
A probabilistic score is assigned toeach proposed match, based on the lengths of the tworegions and some simple assumptions about thedistributions of these two lengths.
This probabilisticscore is used in a dynamic programming framework tofind the maximum likelihood alignment of sentences.After sentences have been aligned, the second step is toidentify correspondences at the word level.
That is, wewould like to know which words in the English textcorrespond to which words in the French text.
Theidentification fword level correspondences is the maintopic of this paper.We wish to distinguish the terms alignment andcorrespondence, The term alignment will be used whenorder constraints must be preserved and the termcorrespondence will be used when order constraintsneed not be preserved and crossing dependencies arepermitted.
We refer to the matching problem at theword level as a correspondence problem because it isimportant to model crossing dependencies (e.g., salesvolume and volume des ventes).
In contrast, we refer tothe matching problem at the sentence level as analignment problem because we believe that it is notnecessary to model crossing dependencies at thesentence l vel as they are quite rare and can be ignoredfor now.Here is an example of our word correspondenceprogram.
Given the input English and FrenchSentences.
"Englishwe took the initiative in assessing and amendingcurrent legislation and policies to ensure that theyreflect a broad interpretation f the charter.Frenchnous avons pris 1' initiative d' 4valuer et de modifierdes lois et des politiques en vigueur afin qu' ellescorrespondent ~ une interprdation ggn4reuse de lacharm.The program wouM produce the followingcorrespondences:Output:we/nous took/O the/O initiative/initiative in/Oassessing/6valuer and/et ammending/modifiercurrent/O legislation/O and/et policies/politiques to/~ensure/O that/qu' they/elles reflect/O a/une broad/Ointerpretafion/interpr6tation of/de theBacharter/charte ./.In this example, 15 out of the 23 (65%) English wordswere matched with a French word (with to/d in error),and 8 of the English words were left unmatched (pairedwith "0").
Throughout this work, we have focused ourattention on robust statistics that tend to avoid makinghard decisions when there isn't much confidence.
Inother words, we favor methods with relatively high1.
The second author is visiting USCBSI, 4676 Admiralty Way, Marina del Rey, CA 90292, USA until 9/119 I.152precision and possibly low recall.
For now, we aremore concerned with errors of commission than errorsof omission.
Based on a sample of 800 sentences, weestimate that our word matching procedure matches61% of the English words with some French word, andabout 95% of these pairs match the English word withthe appropriate French word.After word correspondences have been identified, it ispossible to estimate a probabilistic transfer dictionary.The entry for "the" found in prawn et al) includesthe estimates of ~rob(le I the)=.61 and Prob(1a I the)=.18.Brown et al show how this probabilistic transferdictionary can be combined with a trigram grammar inorder to produce a machine translation system.
Sincethis paper is primarily concerned with the identificationof word correspondences.
we will not go into theseother very interesting issues here.2.
Applications Beyond MTAs mentioned above, MT is not the only motivation forsentence alignment and word correspondence.Computational linguists (e.g.. Klavans andTzoukermann, 1990) have recently become interested inbilingual concordances.
Table 1, for example, shows abilingual concordance contrasting the uses of bank thatare translated as banque with those that are wanslated asbanc.
Of course it is well-know that sensedisambiguation is important for many natural languageapplications (including MT as well as many others).
Inthe past, this fact has been seen as a serious obstacleblocking progress in natural language research sincesense disambiguation is a very tricky unsolved problem,and it is unlikely that it will be solved in the near future.However, we prefer to view these same facts in a moreoptimistic light.
In many cases, the French text can beused to disambiguate the English text, so that theFrench can be used to generate a corpus of (partially)sense-disambiguated English text.
Such a sense-disambiguated corpus would be a valuable resource forall kinds of natural language applications.
In particular,the corpus could be used to develop and test sense-disambiguation algorithms.
For example, if you havean algorithm that is intended to distinguish the6 '  money" sense of bank from the "place" sense ofbank, then you might apply your algorithm to all of theuses of bank in the English portion of the parallelcorpus and use the French text to grade the results.That is, you would say that your program was correct ifit identified a use of bank as a "money" sense and itwas translated as banque, and you would say that theprogram was incorrect if the program identified the useas a "money" sense and it was translated as banc.Thus, the availability of the French text provides avaluable research opportunity, for both monolingualand bilingual applications.
The French text can be usedto help clanfy distinctions in the English text that maynot be obvious to a dumb computer.Table 1: A Bilingual Concordance Based on Aligned Sentencesbank/ banque ("money" sense)f finance (mr .
wilson ) and the governor of the bank of canada have frequently ones finances ( m  .
wilson ) et le gouvemeur de la banque du canada ont frt?quemmctreduced by over 800 per cent in one week through bank action.
SENT there was a heus de 800 p .
100 en une semaine i!
cause d' une banque .
SENT voili un chemisic~bank/ banc ("ulace" sense).
.h a  forum.
SENT such was the case in the gwrges bank issue which was settlcd be~uentre les dtats-unis et le canada B p r o p  du banc de george .
SENT > c' est dahan i did.
SENT he said the nose and tail of the bank were surrendered by this go\gouvemement avait ctddles mtdmitds du banc .
SENT en fait , lors des nCgc3.
Using Word Correspondances Rather than SentenceAlignmentsMost bilingual concordance programs such as ISSCO'sBCP program mentioned in footnote 1 of (Warwickand Russel, 1990) and a similar program mentioned onpage 20 of (Klavans and Tzoukermann, 1990) are basedon aligned sentences rather than word correspondences.Table 1 shows an example of such a sentence-basedconcordance program.
These sentence-based programsrequire the user to supply the program with both anEnglish and a French word (e.g., bank and banque).
Incontrast, a word-based concordance program is givenjust bank and finds the French translations by makinguse of the word correspondences.The advantage of the word-based approach becomesimportant for complicated words like take, where it isdifficult for users to generate many of the possibletranslations.
take is often used in complex idiomaticexpressions, and consequently, there are many uses oftake that should not be translated with prendre.
In fact,most uses of take are not translated with prendre (orany of its morphological variants).
The word-basedbilingual concordances show this fairly clearly.
Wefind that only 23% of the uses of take are translatedwith a form of prendre, a figure is fairly consistent withIBM's estimate of 28% (Brown, personalcommunication).
The striking absence of prendre isconsistent with the observation in the Cobuilddictionary (Sinclair et al, 1987, p. 1488) that "[tlhemost frequent use of take is in expressions where itdoes not have a very distinct meaning of its own, butwhere most of the meaning is in ... the direct object."4.
Two Possible Problems with the EM AlgorithmThis paper is primarily concerned with the task ofidentifying word correspondences.
There is relativelylittle discussion of this topic in Brown et al (1990).although a brief mention of the EM algorithm is made.We decided to look for an alternative estimationalgorithm for two reasons.First, their procedure appears to require a prohibitiveamount of memory.
We observed that they limited thesizes of the English and French vocabularies, V E andV e, respectively, to just 9000 words each.
Havingconstrained the vocabularies in this way, there were amere 81 million parameters to estimate, all of whichcould be squeezed into memory at the same time.However, if the two vocabularies are increased to amore realistic size of 106 words, then there are 10 TMparameters to estimate, and it is no longer practical tostore all of them in memory.
(Apparently, in somemore recent unpublished work (Brown, personalcommunication), they have also found a way to scale upthe size of the vocabulary).Secondly, we were concerned that their estimates mightlack robustness (at least in some cases):"This algorithm leads to a local maximum of theprobability of the observed pairs as a function of theparameters of the model.
There may be many suchlocal maxima.
The particular one at which wearrive will, in general, depend on the initial choiceof parameters."
(Brown et al, p. 82)In particular, we looked at their estimates for the wordhear, which is surprisingly often translated as bravo(espeeiaUy, Hear, hear?
--~ Bravo?
), though it is notclear just how common this is.
Brown et al reportedthat more than 99% of the uses of hear were translatedwith bravo, whereas we estimate the fraction to bemuch closer to 60% (which is fairly consistent withtheir more recent estimates (Brown, personalcommunication)).
The fact that estimates can vary sowidely from 99% to 60% indicates that there might be aserious problem with robustness.
It became clear aftermore private discussions that our methods were comingup with substantially different probability estimates forquite a number of words.
It is not clear that themaximum likelihood methods are robust enough toproduce estimates that can be reliably replicated inother laboratories.5.
Contingency TablesBecause of the memory and robustness questions, wedecided to explore an alternative to the EM algorithm.Table 2 illustrates a two-by-two contingency table forthe English word house and the French word chambre.Cell a (upper-left) counts the number of sentences(aligned regions) that contain both house and chambre.Cell b (upper-right) counts the number of regions thatcontain house but not chambre.
Cells c and d fill outthe pattern in the obvious way.The table can be computed fromfreq(house, chambre), freq(house) andfreq(chambre), the number of aligned regions thatcontain one or both these words, and fromN = 897,077, the total number of regions.a = freq(house, chambre)b = freq(house) - freq(house, chambre)c = freq(chambre) - freq(house, chambre)d=N-a -b -cTable 2: A Contingency Tablechambrehouse 31,950 12,0044,793 848,330We can now measure the association between houseand chambre by making use of any one of a number ofassociation measures such as mutual information.
~b 2, ag2-like statistic, seems to be a particularly good choicebecause it makes good use of the off-diagonal cells bandc.
?~ 2 = ( ad - be) 2(a + b) (a + c) (b+ d) (c + d)02 is bounded between 0 and 1.
In this case, 02 is 0.62,a relatively high value, indicating the two words arestrongly associated, and that they may be translations ofone another.
One can make this argument morerigorous by measuring the confidence that ~2 isdifferent from chance (zero).
In this case, the varianceof ~b z is estimated to be 2.5x10 -5 (see the section"Calculation of Variances"), and hencet = ?~2/~4(var(~2)) = 0.62/~2.5x10 -5 = 123.With such a large t, we can very confidently reject henull hypothesis and assume that there is very likely tobe an association between house and chambre.i.e.
ao6.
A Near M iss /  I'~-,~,L.t~.,~ .
s  ~ ..S/One mig) - ntr t-- e/cha,,a, re with a near misssuch a (~ommune~e Table 3).Table 3: A Near MisscoFnmuneshouse 4,974 38,980441 852,682Unfortunately, this pair is also significantly differentfrom zero (t = 31) because there are many referencesin the Canadian Hansard to the English phrase House ofCommons and its French equivalent Chambre desCommunes.
How do we know that house is moreassociated with chambre than with communes?
Notethat mutual information does not distinguish these twopairs.
Recall the mutual information I(x;y) iscomputed byProb(x,y)l?g2 Prob(x)Prob(y)where Prob(x,y) = a/N, Prob(x) = (a + b)/N, andProb(y) = (a + c)/N.
If we plug these numbers intothe formulas, we find that house and chambre actuallyhave a lower mutual information value than house and154communes: l(house;chambre) = 4.1 whilel(house;communes) = 4.2.Mutual information picks up the fact that there arestrong associations in both eases.
Unfortunately, it isnot very good at deciding which association is stronger.Crucially, it does not make very good use of the off-diagonal cells b and c, which are often better estimatedthan cell a since the counts in b and c are often largerthan those in a.In this case, the crucial difference is that cell b is muchsmaller in Table 2 than in Table 3.
~2 picks up thisdifference; Table 3 has a ~2 of 0.098, signitieantly essthan Table 2% ~2 of 0.62:t = ~2(h'ch) - ~2(h'c?
)"qvar2(~2(h,ch)) + var2(~2(h,co))0.62 - 0.099 = = 88%/2.5x10 -5 + 9.9?10 -6Thus, we can very confidently say that house (h)is moreassociated with chambre (ch) than with communes (co).7.
Calculation of VariancesThe estimate of var(~ 2) is very important o thisargument.
We use the following reasoning:var(~ 2) = vat(a) + vat(b)2 2where var(a) = a, var(b) = b, var(c) = c andvar(d) = a + b + c. A direct calculation of this isvalid when ~2 is small:vat'real(02) = + "- (a + b)(c + a)(a + c)(b + d).
~.2, 1 + c+var (d )+ r. 1 .
b + vat (d ) , ,+ a + c  gyp "As ~2 approaches 1, var(~ 2) decreases to 0, whichmakes the equation for var~,,,at unsuitable as anestimate of the variance.
We calculate a variance forthis case by assuming that bc << ad, which impliesthat ~2 = I - (b + c)/a.
With this assumption, weobtainvara,~,(O2) = a-2(b + c)(1 + b + c )aWe do not have an exact relation to specify when ~2 islarge and when it is small.
Rather, we observe thateach estimate produces a value that is small in itsdomain, so we estimate the variance of ~2 by theminimum of the two cases:var(~ 2) = min(var~,~,,vart~,8 ,).8.
Selecting PairsWe have now seen how we could decide that house andchambre are more associated than house andcommunes.
But why did we decide to look at thesepairs of words and not some others?
As we mentionedbefore, we probably can't afford to look at all VzVppairs unless we limit the vocabulary sizes down tosomething like the 9000 word limit in Brown et al Andeven then, there would be 81 million pairs to consider.If the training corpus is not too large (e.g., 50,000regions), then it is possible to consider all pairs ofwords that actually co-occur in at least one region (i.e.,a ~ 0).
Unfortunately, with a training corpus ofN = 890,000 regions, we have found that there are toomany such pairs and it becomes necessary to be moresdective (heuristic).We have had fakly good success with a progressivedeepening strategy.
That is, select a small set ofregions (e.g., 10,000) and use all of the trainingmaterial to compute #2 for all pairs of words thatappear in any of these 10,000 regions.
Select the bestpairs.
That is, take a pair (x, y) if it has a ~2significantly better than any other pair of the form (x, z)or (w, y).
This procedure would take house/chambrebut not house/communes.
Repeat his operation, usinglarger and larger samples of the training corpus tosuggest possibly interesting pairs.
On each iteration,remove pairs of words from the training corpus thathave already been selected so that other alternatives canbe identified.
We have completed four passes of thisalgorithm, and selected more than a thousand pairs oneach iteration.Iteration Sample Size Number  of Pairs Selected0 10,000 12231 30,000 15372 50,000 16923 220,000 1967A few of the selected pairs are shown below.
The firstcolumn indicates the iteration that the pair was selectedon.
The second column indicates the number ofsentences (aligned regions) that the pair appears in.Note that the most frequent pairs are usually selectedfirst, leaving less important pairs to be picked up onsubsequent iterations.
Thus, for example, accept/accepter is selected before accept/accepte.
Based on asample of 1000 pairs, about 98% of the selected pairs ofwords are translations.
Here, as elsewhere, we act tokeep our errors of commission low.Iteration Freq English French2 278 accept accepte0 1335 accept accepter3 111 accept acceptons1 165 acceptable aeceptables2 101 acceptable inacceptable1551 90 acceptance acceptation1 596 accepted accept61 55 accepting acceptant3 130 accepting accepter0 62 accepts accepteAfter a few iterations, it became clear that many of thepairs that were being selected were morphologicallyrelated to pairs that had already been selected on aprevious iteration.
A remarkably simple heuristicseemed to work fairly well to incorporate thisobservation.
That is, assume that two pairs aremorphologically related if both words start with thesame first 5 characters.
Then, select a pair if it ismorphologically related to a pair that is already selectedand it appears "significantly often" (in many moresentences than you would expect by chance) on anyiteration.
This very simple heuristic more than doubledthe number of pairs that had been selected on the firstfour iterations, from 6419 to 13,466.
As we will see inthe next section, these 13 thousand pairs cover morethan half of the words in the text.
Again, the error ratefor pairs selected by this procedure was low, less thantwo percent.9.
Returing to the Sentence ContextIt is now time to try to put these pairs back into theirsentence context.
Consider the pair of sentencesmentioned previously.English:we took the initiative in assessing and amendingcurrent legislation and policies to ensure that theyreflect a broad interpretation of the charter.French:nous avons In'is 1' initiative d' ffvaluer et de modifierdes lois et des politiques en vigueur afin qu' ellescorrespondent ~tune interpr&ation gdn&euse de lacharte.The matching procedure attempts to match English andFrench words using the selected pairs.
When there areseveral possibilities, the procedure uses a slopecondition to select the best pair.
Thus, for example,there are two instances of the word and in the Englishsentence and two instances of the word et in the Frenchsentence.
We prefer to match the first and to the first etand the second and to the second et, as illustratedbelow.
(The i and j columns give the positions into theEnglish and French sentences, respectively.
Thecolumn labeled slope indicates the difference betweenthe j values for the current French word and the lastprevious non-NULL French word.I English j French slope score1 we 1 nous 1 --0.52 took NULL -5.53 the NULL -10.54 initiative 5 initiative 4 -14.25 in NULL -19.26 assessing 7 6valuer 2 -21.57 and 8 et I -22.08 amending 10 modifier 2 -24.29 current NULL -29.210 legislation NULL -34.211 and 13 et 3 -37.312 policies 15 politiques 2 -39.613 to 22 /t 7 -44.514 ensure NULL -49.515 that 19 qu' -3 -54.116 they 20 riles I -54.617 reflect NULL -59.618 a 23 une 3 --62.719 broad NULL -67.720 interpretation 24 interprttation 1 -.-68.221 of 26 de 2 -70.422 the 27 la 1 -70.923 charter 28 charte 1 -71.424 29 1 -71.9The matching procedure uses a dynamic programmingoptimization to find the sequence of j values with thebest score.
A sequence o f j  values is scored withX.
logprob (match I slope j)JUsing Bayes rule, the prob(matchlslopej) is rewrittenas prob( slope ~ Imatch) prob ( match).
Both terms wereestimated empirically.The second term is determined by the fan-in, thenumber of possible matches that a particular j valuemight play a role in.
In this example, most of the jvalues had a fan-in of 1.
However, the two instances ofet had a fan-in of 2 because they could match either ofthe two instances of and.
The score is smaller for bothof these uses of et because there is more uncertainty.We considered three cases: the fan-in is 1, 2 or many.The log prob(match) in each of these three cases is-0.05, --0.34 and ---0.43, respectively.The first term is also determined empirically.
The scoreis maximized for a slope of 1, In this case,log prob(slopelmatch) is --0.46.
The score falls offrapidly with larger or smaller slopes.The dynamic programming optimization is also giventhe choice to match an English word to NULL.
I f  theprocedure elects this option, then a constant,log prob(NULL), is added to the score.
This value isset so that the matching procedure will avoid makinghard decisions when it isn't sure.
For example, the 5 ~hEnglish word (in) could have been matched with 16 ~hFrench word (en), but it didn't do so becauselog prob(NULL) was more than the score of such aradical reordering.
We have found that -5 is a good156setting for log prob(match).
If we set the value muchhigher, then the matching procedure attempts to reorderthe text too much.
If we set the value much lower, thenthe matching procedure does not attempt to reorder thetext enough.This matching procedure works remarkably well.
Asmentioned above, based on a sample of 800 sentences,we estimate that the procedure matches 61% of theEnglish words with some French word, and about 95%of these pairs match the English word with theappropriate French word.
All but one of these rrors ofcommission involved a function word, usually onesurrounded on both sides by words that could not bematched.10.
ConclusionsWe have been studying how to find correspondingwords in parallel texts given aligned regions.
We haveintroduced several novel techniques that makesubstantial progress toward this goal.
The philosophyunderlying all our techniques is to keep errors ofcommission low.
Whatever words are matched bythese robust techniques should almost always becorrect.
Then, at any stage, the words that are matchedcan be used eortfidently for further esearch.The first technique we have introduced is themeasurement of association of pairs of words by d~ 2,based on a two by two contingency table.
This measuredoes better than mutual information at showing whichpairs of words are translations, because it accounts forthe cases in which one of the words occurs and theother does not.
We apply this measure iteratively.
Ourcaution is expressed by selecting at most one pair ofwords containing a given word on each iteration.
The?~2 measure for a selected pair must be significantlygreater than the ?2 measures for each of the words ofthe pair and any other suggested translation.The iteration is accompanied by a progressiveenlargement of possibly interesting pairs.
We could notstudy all paks of words, or even all occurring pairs ofwords.
Rather we take all the oceuring pairs in aprogressively enlarged sample of regions.
This doespropose the most frequently cooccurring pairs first.
Oneach iteration we delete the pairs of words that havealready been selected, thereby reducing the confusionamong collocates.
Our eantion was expressed by handchecking the accuracy of selected pairs after eachiteration.
We chose techniques which could give 98percent accuracy on the selected pairs.
This has notbeen a blind automatic procedure, but one controlled ateach step by human expertise.When we observed that many of the pairs consideredcontained morphological variants of a pair selected, weallowed such pairs to be accepted if they also had a d~ 2significantly greater than chance.Several of our tests acknowledge that any function,such as ~2, of noisy data, such as frequencies, is itself anoisy measure.
Therefore our caution is to require notjust that one measure be greater than another, but that itbe significantly greater.
This calculation is made usingan estimate of the variance of ~ 2.We then used the selected word pairs to suggest wordcorrespondences within a given aligned region.
Thealignment was done by a dynamic programmingtechnique with a parameter that controlled how certainwe should be before accepting a specific pair of wordsas corresponding.
We set the parameter to give resultsthat are quite likely to be correct.
Currently we suggestcorrespondences forabout 60 percent of the words, andwhen we do suggest a correspondence w are correct inabout 95 percent of cases.This is work in progress.
We expect hat in the futurethe coverage can be increased substantially above 60%while errors can be deoreased somewhat from 5%.
Webelieve that errors of omission are much less importantthan errors of commission and expect to continuechoosing techniques accordingly.ReferencesBrown, P., J. Cocke, S. Della Pietra, V. Della Pietra, F.Jelinek, J. Lafferty, R. Mercer, and P. Roossin (1990)"A  Statistical Approach to Machine Translation,"ComputationaILinguistics, v 16, pp 79-85.Brown, P, J. Lai, R. Mercer (1991) "AligningSentences in Parallel Corpora," IBM Report submittedto 29 al Annual Meeting of the Association forComputational Linguistics.Catizone, R., G. Russell, and S. Warwick (to appear)"Deriving Translation Data from Bilingual Texts," inZernik (ed), Lexical Acquisition: Using on-lineResources to Build a Lexicon, Lawrence Erlbaum.Church, K., (1988) "A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text," SecondConference on Applied Natural Language Processing,Austin, Texas.Gale, W. and K. Church (1990) "A Program forAligning Sentences in Bilingual Corpora," unpublishedms., submitted to 29 th Annual Meeting of theAssociation for Computational Linguistics.Kay, M. and M. RSscheisen (1988) "Text-TranslationAlignmentS' unpublished ms., Xerox Palo AltoResearch Ceuter.Klavans, J., an6 E. Tzoukermarm (1990) "TheBICORD System," COLING-90, pp 174-179.Warwick, S. and G. Russell (1990) "BilingualConeordaneing and Bilingual Lexicography," Euralex1990.157
