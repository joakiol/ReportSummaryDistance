Automat ic  Construct ion of Frame Representat ionsfor Spontaneous Speech in Unrestr icted DomainsK laus  ZechnerLanguage Technologies Inst i tuteCarnegie Mellon University5000 Forbes AvenueP i t tsburgh,  PA 15213, USAzechner@cs ,  cmu.
eduAbst rac tThis paper presents a system which automaticallygenerates shallow semantic frame structures for con-versational speech in unrestricted domains.We argue that such shallow semantic representationscan indeed be generated with a minimum amount oflinguistic knowledge engineering and without havingto explicitly construct a semantic knowledge base.The system is designed to be robust o deal with theproblems of speech dysfluencies, ungrammaticalities,and imperfect speech recognition.Initial results on speech transcripts are promisingin that correct mappings could be identified in 21%of the clauses of a test set (resp.
44% of this testset where ungrammatical or verb-less clauses wereremoved).1 IntroductionIn syntactic and semantic analysis of spontaneousspeech, little research as been done with regardto dealing with language in unrestricted omains.There are several reasons why so far an in-depthanalysis of this type of language data has been con-sidered prohibitively hard:?
inherent properties of spontaneous speech, suchas dysfiuencies and ungrammaticalities (Lavie,1996)?
word accuracy being far from perfect (e.g., on atypical corpus such as SWITCHBOARD (SWBD)(Godfrey et al, 1992), current state-of-the-artrecognizers have word error rates in the rangeof 30-40% (Finke et al, 1997))?
if the domain is unrestricted, manual construc-tion of a semantic knowledge base with reason-able coverage is very labor intensiveIn this paper we propose to combine methods ofpartial parsing ("chunking") with the mapping ofthe verb arguments onto subcategorization framesthat can be extracted automatically, in this case,from WordNet (Miller et al, 1993).
As prelimi-nary results indicate, this yields a way of generatingshallow semantic representations efficiently and withminimal manual effort.Eventually, these semantic structures can serve as(additional) input to a variety of different asks inNLP, such as text or dialogue summarization, i -formation gisting, information retrieval, or shallowmachine translation.2 Sha l low Semant ic  S t ruc turesThe two main representations we are building on arethe following:?
chunks: these correspond mostly to basic (i.e.,non-attached) phrasal constituents?
frames: these are built from the parsed chunksaccording to subcategorization constraints ex-tracted from the WordNet lexiconThe chunks are defined in a similar way as in (Ab-ney, 1996), namely as "non-recursive phrasal units";they roughly correspond to the standard linguisticnotion of constituents, except hat there are no at-tachments made (e.g., a PP to a NP) and that a ver-bal chunk does not include any of its arguments butjust consists of the verbal complex (auxiliary/mainverb), including possibly inserted adverbs and/ornegation particles.All frames are being generated on the basis of"short clauses" which we define as minimal clausalunits that contain at least one subject and an in-flected verbal form) 2To produce the list of all possible subcategoriza-tion frames, we first extracted all verbal tokens fromthe tagged SWITCHBOARD corpus and then retrievedthe frames from WordNet.
Table 1 provides a sum-mary of this pre-calculation.1This means in effect that relative clauses will get mappedseparately.
They will, however, have to be "linked" to thephrase they modify.2We are also considering to take even shorter units as basisfor the mapping that would, e.g., include non-inflected clausalcomplements.
The most convenient solution has yet to bedetermined.1448Verbal tokensDifferent lemmataSenses in all lemmataAvg.
senses per lemmaTotal number of framesAvg.
frames per sense4428246485233.46154671.81Table 1: WordNet: verbal emmata, senses,and frames3 Resources  and  SystemComponentsWe use the following resources to build our system:?
the SWITCHBOARD (SWBD) corpus (Godfreyet al, 1992) for speech data, transcripts, andannotations at various levels (e.g., for segmentboundaries or parts of speech)?
the JANUS speech recognizer (Waibel et al,1996) to provide us with input hypotheses?
a part of speech (POS) tagger, derived from(Brill, 1994), adapted to and retrained for theSWITCHBOARD corpus?
a preprocessing pipe which cleans up speechdysfluencies (e.g., repetitions, hesitations) andcontains a segmentation module to split "thespeech recognizer turns into short clauses?
a chart parser (Ward, 1991) with a POS basedgrammar to generate the chunks 3 (phrasal con-stituents)?
WordNet 1.5 (Miller et al, 1993) for the extrac-tion of subcategorization (subcat) frames for allsenses of a verb (including semantic features,such as "animacy')?
a mapper which tries to find the "best match"between the chunks found within a short clauseand the subcat frames for the main verb in thatclauseThe major blocks of the system architecture aredepicted in Figure I.We want to stress here that except for the devel-opment of the small POS grammar and the frame-mapper, the other components and resources werealready present or quite simple to implement.
Therehas also been significant work on (semi-)automaticinduction of subcategorization frames (Manning,1993; Briscoe and Carroll, 1997), such that even3More details about the chunk parser can be found in(Zechner, 1997).input urerancespeech recognizerhypothesisLI POS tagger,prepro e. ,ngp p  IIII; chun par er IIchunk sequenceli IIframe representationFigure 1: Global system architecturewithout he important knowledge source from Word-Net, a similar system could be built for other lan-guages as well.
Also, the Euro-WordNet project(Vossen et al, 1997) is currently underway in build-ing WordNet resources for other European lan-guages.4 Preliminary ExperimentsWe performed some initial experiments using theSWBD transcripts as input to the system.
Thesewere POS tagged, preprocessed, segmented intoshort clauses, parsed in chunks using a POSbased grammar, and finally, for each short clause,the frame-mapper matched all potential argumentsof the verb against all possible subcategorizationframes listed in the lemmata file we had precom-puted from WordNet (see section 2).In total we had over 600000 short clauses, con-taining approximately 1.7 million chunks.
Only 18different chunk patterns accounted for about halfof these short clauses.
Table 2 shows these chunk1449main verb frequency chunk sequencepresent?nononoyesyesnonoyesyes833533673133182297491917613834136231222011038(noises/hesit.
)aftconjnp vbnp vb npnpconj npconj np vbconj np vb npyesyesyesnoyesnoyesyesyes764970925552504449264079399939983996np vb adjpnp vb ppnp vbnegadvpnp vb np ppPPconj np vb ppconj np vb adjpnp vb advpTable 2: Most frequent chunk sequences inshort clausespatterns and their frequencies.
4 Most of these con-tain main verbs and hence can be sensibly usedin a mapping procedure but some of them (e.g.,a f f ,  con j ,  advp) do not.
These are typically back-channellings, adverbial comments, and colloquialforms (e.g., "yeah", "and...", "oh really").
They canbe easily dealt with a preprocessing module that as-signs them to one of these categories and does notsend them to the mapper.Another interesting observation we make here isthat within these most common chunk patterns,there is only one pattern (np vb np pp) which couldlead to a potential PP-attachment ambiguity.
Weconjecture that this is most probably due to the na-ture of conversational speech which, unlike for writ-ten (and more formal) language, does not make toofrequent use of complex noun phrases that have oneor multiple prepositional phrases attached to them.We selected 98 short clauses randomly from theoutput o perform a first error analysis.The results are summarized in Table 3.
In  over21% of the clauses, the mapper finds at least onemapping that is correct.
Another 23.5% of theclauses do not contain any chunks that are worthto be mapped in the first place (noises, hesitations),4 Chunk abbreviations: conj=conjunction, aft=affirmative,np=noun phrase, vb=verbai chunk, vbneg=negated v r-bal chunk, adjp=adjectival phrase, advp=adverbial phrase,pp=prepositional phrase.so these could be filtered out and dealt with entirelybefore the mapping process takes place, as we men-tioned earlier.
28.6% of the clauses are in some senseincomplete, mostly they are lacking a main verbwhich is the crucial element to get the mapping pro-cedure started.
We regard these as "hard" residues,including well-known linguistic problems uch as el-lipsis, in addition to some spoken language ungram-maticalities.
The last two categories (26.6% com-bined) in the table are due to the incompleteness andinaccuracies of the system components hemselves.To illustrate the process of mapping, we shallpresent an example here, starting from thePOS-tagged utterance up to the semantic framerepresentation:5 sshort clause, annotated with POS:i/PRP wi11/AUX talk/VBto/PREP you/PRPAagain/RBLEMMA/token (of main verb):talk/talkparsed chunks:-np-vb-pp-advpparsed sequence to map:-NP-VBZ-PPWordNet frames::I-INAN-VBZ:I-ANIM-VBZ:I-INAN-IS-VBG-PP:I-ANIM-VBZ-PP:I-ANIM-VBZ-TO-ANIM:2-ANIM-VBZ:2-ANIM-VBZ-PP:3-ANIM-VBZ:3-ANIM-VBZ-INAN:4-ANIM-VBZ:5-ANIM-VBZ:6-ANIM-VBZ:6-INAN-VBZ-TO-ANIM:6-ANIM-VBZ-ON-INANPotential mappings (found by mapper):map.
I: I-NP-VBZ (I-INAN-VBZ)map.
2: 1-NP-VBZ (I-ANIM-VBZ)map.
3: I-NP-VBZ-PP (1-ANIM-VBZ-PP)map.
4: I-NP-VBZ-PP (1-ANIM-VBZ-TO-ANIM)(...)Frame representat ion ( for  mapping 4):\[agent/an\] (i/PRP)5PO$ abbreviations: PRP=personal pro-noun, AUX=auxiliary verb, VB=main verb (non-inflected),PREP=prepositlon.
PRPA-personal pronoun i  accusative,RB=adverb.
?Frame abbreviations:INAN=inanimate NP, ANIM=animate NP, VBZ--inflectedmain verb, IS=is, VBG=gerund, PP=prepositional phrase,TO=to (prep.
), ONmon (prep.
).1450classificationcorrectnon-mappableungrammaticalpreprocessingmapperocc .
(%)21 (21.4%)23 (23.5%)28 (28.6%)13 (13.3%)13 (13.3%)Commentat least one reasonable mapping is foundclause consists of noises/hesitations onlye.g., incomplete phrase, no verbproblem is caused by errors in POS tagger/segmenter/parserproblem due to incompleteness of mapperTable 3: Summary of classification results for mapper output\[pred\] (\[vb_fin\] (\[aux\] (wilI/AUX)\[head\] (talk/VB))\[pp_obj\] ( \[prep\] (to/PREP)\[theme/an\] (you/PRPA)))\[modif\] (again/RB)Since chunks like advp or conj are not part of theWordNet frames, we remove these from the parsedchunk sequence, before a mapping attempt is beingmade.
7In our example, WordNet yields 14 frames for 6senses of the main verb ta lk .
The mapper alreadyfinds a "perfect match "s for the first, i.e., the mostfrequent sense 9 of the verb (mapping 4 can be es-timated to be more accurate than mapping 3 sincealso the preposition matches to the input string).This will be also the default sense to choose, unlessthere is a word sense disambiguating module avail-able that strongly favors a less frequent sense.Since WordNet 1.5 does not provide detailedsemantic frame information but only generalsubcategorization with extensions uch as "ani-mate/inanimate", we plan to extend this infor-mation by processing machine-readable dictionarieswhich provide a richer set of semantic role informa-tion of verbal heads, l?It is interesting to see that even at this early stageof our project he results of this shallow analysis arequite encouraging.
If we remove those clauses fromthe test set which either should not or cannot bemapped in the first place (because they are eithernot containing any structure ("non-mappable") orare ungrammatical), the remainder of 47 clauses al-ready has a success-rate of44.7%.
Improvements ofthe system components before the mapping stage aswell as to the mapper itself will further increase themapping performance.7These chunks can be easily added to the mapper's outputagain, as shown in the example.Spartial matches, such as mappings I and 2 in this exam-ple, are allowed but disfavored to perfect matches.9In WordNet 1.5, the first sense is also supposed to be themost frequent one.l?The "agent" and "theme" assignments are currently justdefaults for these types of subcat frames.5 Future WorkIt is obvious from our evaluation, that most corecomponents, pecifically the mapper need to be im-proved and refined.
As for the mapper, there areissues of constituent coordination, split verbs, infini-tival complements, that need to be addressed andproperly handled.
Also, the "linkage" between mainand relative clauses has to be performed such thatthis information is maintained and not lost due tothe segmentation into short clauses.Experiments with speech recognizer output in-stead of transcripts will show in how far we still getreasonable frame representations when we are facedwith erroneous input in the first place.
Specifically,since the mapper elies on the identification of the"head verb", it will be crucial that at least thosewords are correctly recognized and tagged most ofthe time.To further enhance our representation, we coulduse speech act tags, generated by an automaticspeech act classifier (Finke et al, 1998) and attachthese to the short clauses.
116 SummaryWe have presented a system which is able to buildshallow semantic representations for spontaneousspeech in unrestricted domains, without he neces-sity of extensive knowledge ngineering.Initial experiments demonstrate that this ap-proach is feasible in principle.
However, more workto improve the major components is needed to reacha more reliable and valid output.The potentials of this approach for NLP applica-tions that use speech as their input are obvious: se-mantic representations can enhance almost all tasksthat so far have either been restricted to narrow do-mains or were mainly using word-level representa-tions, such as text summarization, i formation re-trieval, or shallow machine translation.11 Sometimes, the speech acts will span more than one shortclause but as long as the turn-boundaries are fixed for bothour system and the speech act classifier, the re-combinationof short  c lauses can be done straightforwardly.14517" AcknowledgementsThe author wants to thank Marsal Gavaldh, MirellaLapata, and the three anonymous reviewers for valu-able comments on this paper.This work was funded in part by grants of theVerbmobil project of the Federal Republic of Ger-many, ATR - Interpreting Telecommunications Re-search Laboratories of Japan, and the US Depart-meat of Defense.ReferencesSteven Abney.
1996.
Partial parsing via finite-statecascades.
In Workshop on Robust Parsing, 8thEuropean Summer School in Logic, Language andInformation, Prague, Czech Republic, pages 8-15.Eric Brill.
1994.
Some advances in transformation-based part of speech tagging.
In Proceeedings ofAAAI-94.Ted Briscoe and John Carroll.
1997.
Automaticextraction of subcategorization from corpora.
InProceedings of the 5th ANLP Conference, Wash-ington DC, pages 24-29.Michael Finke, Jiirgen Fritsch, Petra Geutner, KlansRies and Torsten Zeppenfeld.
1997.
The Janus-RTk SWITCHBOARD/CALLHOME 1997 EvaluationSystem.
In Proceedings ofLVCSR HubS-e Work-shop, May 13-15, Baltimore, Maryland.Michael Finke, Maria Lapata, Alon Lavie, LoriLevin, Laura Mayfield Tomokiyo, Thomas Polzin,Klaus Ries, Alex Waibel and Klaus Zechner.
1998.CLARITY: Inferring Discourse Structure fromSpeech.
In Proceedings of the AAAI 98 SpringSymposium: Applying Machine Learning to Dis-course Processing, Stanford, CA, pages 25-32J.
J. Godfrey, E. C. Holliman, and J. McDaniel.1992.
SWITCHBOARD: telephone speech corpusfor research and development.
In Proceedings ofthe ICASSP-9e, volume 1, pages 517-520.Alon Lavie.
1996.
GLR*: A Robust Grammar.Focused Parser for Spontaneously Spoken Lan-guage.
Ph.D. thesis, Carnegie Mellon University,Pittsburgh, PA.Christopher D. Manning.
1993.
Automatic acquisi-tion of a large subcategorization dictionary fromcorpora.
In Proceeedings of the 31th Annual Meet-ing of the ACL, pages 235-242.George A. Miller, Richard Beckwith, ChristianeFellbaum, Derek Gross, and Katherine Miller.1993.
Five papers on WordNet.
Technical report,Princeton University, CSL, revised version, Au-gust.Pick Vossen, Pedro Diez-Orzas, and Wim Peters.1997.
The Multilingual Design of EuroWordNet.In Proceedings of the ACL/EACL-97 workshopAutomatic Information Extraction and Buildingof Lezical Semantic Resources for NLP Applica-tions, Madrid, July I2th, 1997Alex Waibel, Michael Pinke, Donna Gates, MarsalGavaldh, Thomas Kemp, Alon Lavie, Lori Levin,Martin Maier, Laura Mayfield, Arthur McNair,Ivica P~gina, Kaori Shima, Trio Sloboda, MonikaWoszczyna, Torsten Zeppenfeld, and PumingZhan.
1996.
JANUS-II - advances inspeech recog-nition.
In Proceedings ofthe ICASSP-96.Wayne Ward.
1991.
Understanding spontaneousspeech: The PHOENIX system.
In Proceedingsof ICASSP-91, pages 365-367.Klaus Zechner.
1997.
Building chunk level rep-resentations for spontaneous peech in unre-stricted domains: The CHUNKY system andits application to reranking Nbest lists of aspeech recognizer.
M.S.
Project lq~port, CMU,Department of Philosophy.
Available fromhttp ://www.
con~rib, andrew, cmu.
edu/'zechner/publ icat ions.
h~ml1452
