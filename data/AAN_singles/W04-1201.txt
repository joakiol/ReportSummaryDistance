Recognizing Names in Biomedical Textsusing Hidden Markov Model and SVM plus SigmoidZHOU GuoDongInstitute for Infocomm Research21 Heng Mui Keng TerraceSingapore 119613Email: zhougd@i2r.a-star.edu.sgABSTRACTIn this paper, we present a named entityrecognition system in the biomedical domain,called PowerBioNE.
In order to deal with thespecial phenomena in the biomedical domain,various evidential features are proposed andintegrated through a Hidden Markov Model(HMM).
In addition, a Support Vector Machine(SVM) plus sigmoid is proposed to resolve thedata sparseness problem in our system.
Finally,we present two post-processing modules to dealwith the cascaded entity name and abbreviationphenomena.
Evaluation shows that our systemachieves the F-measure of 69.1 and 71.2 on the 23classes of GENIA V1.1 and V3.0 respectively.
Inparticular, our system achieves the F-measure of77.8 on the ?protein?
class of GENIA V3.0.
Itshows that our system outperforms the bestpublished system on GENIA V1.1 and V3.0.1.
INTRODUCTIONWith an overwhelming amount of textualinformation in molecular biology and biomedicine,there is a need for effective and efficient literaturemining and knowledge discovery that can helpbiologists to gather and make use of the knowledgeencoded in text documents.
In order to makeorganized and structured information available,automatically recognizing biomedical entity namesbecomes critical and is important for protein-protein interaction extraction, pathwayconstruction, automatic database curation, etc.Such a task, called named entity recognition,has been well developed in the InformationExtraction literature (MUC-6; MUC-7).
In MUC,the task of named entity recognition is to recognizethe names of persons, locations, organizations, etc.in the newswire domain.
In the biomedical domain,we care about entities like gene, protein, virus, etc.In recent years, many explorations have been doneto port existing named entity recognition systemsinto the biomedical domain (Kazama et al2002;Lee et al2003; Shen et al2003; Zhou et al2004).However, few of them have achieved satisfactoryperformance due to the special characteristics inthe biomedical domain, such as long anddescriptive naming conventions, conjunctive anddisjunctive structure, causal naming conventionand rapidly emerging new biomedical names,abbreviation, and cascaded construction.
On allaccounts, we can say that the entity names in thebiomedical domain are much more complex thanthose in the newswire domain.In this paper, we present a named entityrecognition system in the biomedical domain,called PowerBioNE.
In order to deal with thespecial phenomena in the biomedical domain,various evidential features are proposed andintegrated effectively and efficiently through aHidden Markov Model (HMM).
In addition, aSupport Vector Machine (SVM) plus sigmoid isproposed to resolve the data sparseness problem inour system.
Finally, we present two post-processing modules to deal with the cascadedentity name and abbreviation phenomena to furtherimprove the performance.All of our experiments are done on the GENIAcorpus, which is the largest annotated corpus in themolecular biology domain available to public(Ohta et al 2002).
In our experiments, twoversions are used: 1) Genia V1.1 which contains670 MEDLINE abstracts of 123K words; 2) GeniaV3.0 which is a superset of GENIA V1.1 andcontains 2000 MEDLINE abstracts of 360K words.The annotation of biomedical entities is based onthe GENIA ontology (Ohta et al 2002), whichincludes 23 distinct classes: multi-cell, mono-cell,virus, body part, tissue, cell type, cell component,organism, cell line, other artificial source, protein,peptide, amino acid monomer, DNA, RNA, polynucleotide, nucleotide, lipid, carbohydrate, otherorganic compound, inorganic, atom and other.2.
FEATURESIn order to deal with the special phenomena in thebiomedical domain, various evidential features areexplored.?
Word Formation Pattern (FWFP): The purposeof this feature is to capture capitalization,digitalization and other word formation1information.
This feature has been widely used inthe biomedical domain (Kazama et al2002; Shenet al2003; Zhou et al2004).
In this paper, thesame feature as in Shen et al2003 is used.?
Morphological Pattern (FMP): Morphologicalinformation, such as prefix and suffix, isconsidered as an important cue for terminologyidentification and has been widely applied in thebiomedical domain (Kazama et al2002; Lee et al2003; Shen et al2003; Zhou et al2004).
Same asShen et al2003, we use a statistical method to getthe most useful prefixes/suffixes from the trainingdata.?
Part-of-Speech (FPOS): Since many of thewords in biomedical entity names are in lowercase,capitalization information in the biomedicaldomain is not as evidential as that in the newswiredomain.
Moreover, many biomedical entity namesare descriptive and very long.
Therefore, POS mayprovide useful evidence about the boundaries ofbiomedical entity names.?
Head Noun Trigger (FHEAD): The head noun,which is the major noun of a noun phrase, oftendescribes the function or the property of the nounphrase.
In this paper, we automatically extractunigram and bigram head nouns from the trainingdata, and rank them by frequency.
For each entityclass, we select 50% of top ranked head nouns ashead noun triggers.
Table 1 shows some of theexamples.Table 1: Examples of auto-generated head nounsClass Unigram  bigraminterleukin activator proteininterferon binding proteinPROTEINkinase cell receptorDNA X chromosomecDNA binding motifDNAchromosome promoter element?
Name Alias Feature (FALIAS): Besides theabove widely used features, we also propose anovel name alias feature.
The intuition behind thisfeature is the name alias phenomenon that relevantentities will be referred to in many waysthroughout a given text and thus success of namedentity recognition is conditional on success atdetermining when one noun phrase refers to thevery same entity as another noun phrase.During decoding, the entity names alreadyrecognized from the previous sentences of thedocument are stored in a list.
When the systemencounters an entity name candidate (e.g.
a wordwith a special word formation pattern), a namealias algorithm (similar to Schwartz et al2003) isinvoked to first dynamically determine whether theentity name candidate might be alias for apreviously recognized name in the recognized list.This is done by checking whether all the charactersin the entity name candidate exist in a recognizedentity name in the same order and whether the firstcharacter in the entity name candidate is same asthe first character in the recognized name.
For arelevant work, please see Jacquemin (2001).
Thename alias feature FALIAS is represented asENTITYnLm (L indicates the locality of the namealias phenomenon).
Here ENTITY indicates theclass of the recognized entity name and n indicatesthe number of the words in the recognized entityname while m indicates the number of the words inthe recognized entity name from which the namealias candidate is formed.
For example, when thedecoding process encounters the word ?TCF?, theword ?TCF?
is proposed as an entity namecandidate and the name alias algorithm is invokedto check if the word ?TCF?
is an alias of arecognized named entity.
If ?T cell Factor?
is a?Protein?
name recognized earlier in thedocument, the word ?TCF?
is determined as analias of ?T cell Factor?
with the name alias featureProtein3L3 by taking the three initial letters of thethree-word ?protein?
name ?T cell Factor?.3.
METHODS3.1 Hidden Markov ModelGiven above various features, the key problem ishow to effectively and efficiently integrate themtogether and find the optimal resolution tobiomedical named entity recognition.
Here, we usethe Hidden Markov Model (HMM) as described inZhou et al2002.
A HMM is a model where asequence of outputs is generated in addition to theMarkov state sequence.
It is a latent variable modelin the sense that only the output sequence isobserved while the state sequence remains?hidden?.Given an observation sequence O ,the purpose of a HMM is to find the most likelystate sequence S  that maximizes.
Here, the observation o ,where  is the word andis thefeature set of the word w , and the state  isstructural and snn ooo ...211 =>=< iii wf ,>isii FEATURE_nn sss ...211 =iHEADiPOS FF ,,iiBOUNDARY _)|( 11nn OSP=< ii FfiwF, iALIASiMPWFP F,i ENTITY= ,where  denotes the position of thecurrent word in the entity; ENTITY  indicates theclass of the entity; and FEATURE  is the feature setused to model the ngram more precisely.iiiBOUNDARYBy rewriting , we have: )|(log 11 nn OSP2)()(),(log)(log)|(log1111111 nnnnnnnOPSPOSPSPOSP ?+=          (1)The second term in Equation (1) is the mutualinformation between S  and .
In order tosimplify the computation of this term, we assumemutual information independence:n1nO1?==nininn OsMIOSMI1111 ),(),(  or?= ?=?ninininnnnOPsPOsPOPSPOSP1 111111)()(),(log)()(),(log                (2)That is, an individual tag is only dependent on theoutput sequence O  and independent on other tagsin the tag sequence S .
This assumption isreasonable because the dependence among the tagsin the tag sequence S  has already been capturedby the first term in Equation (1).
Applying theassumption (2) to Equation (1), we have:n1n1n1?
?==+?=nininiinnnOsPsPSPOSP111111)|(log)(log)(log)|(log(3)From Equation (3), we can see that:?
The first term can be computed by applyingchain rules.
In ngram modeling (Chen et al1996),each tag is assumed to be dependent on the N-1previous tags.?
The second term is the summation of logprobabilities of all the individual tags.?
The third term corresponds to the ?lexical?component (dictionary) of the tagger.The idea behind the model is that it tries toassign each output an appropriate tag (state), whichcontains boundary and class information.
Forexample, ?TCF 1 binds stronger than NF kB toTCEd DNA?.
The tag assigned to token ?TCF?should indicate that it is at the beginning of anentity name and it belongs to the ?Protein?
class;and the tag assigned to token ?binds?
shouldindicate that it does not belong to an entity name.Here, the Viterbi algorithm (Viterbi 1967) isimplemented to find the most likely tag sequence.The problem with the above HMM lies in thedata sparseness problem raised by P  in thethird term of Equation (3).
Ideally, we would havesufficient training data for every event whoseconditional probability we wish to calculate.Unfortunately, there is rarely enough training datato compute accurate probabilities when decodingon new data.
Generally, two smoothing approaches(Chen et al1996) are applied to resolve thisproblem: linear interpolation and back-off.However, these two approaches only work wellwhen the number of different information sourcesis limited.
When a few features and/or a longcontext are considered, the number of differentinformation sources is exponential.
In this paper, aSupport Vector Machine (SVM) plus sigmoid isproposed to resolve this problem in our system.
)|( 1ni Os3.2 Support Vector Machine plus SigmoidSupport Vector Machines (SVMs) are a popularmachine learning approach first presented byVapnik (1995).
Based on the structural riskminimization of statistical learning theory, SVMsseek an optimal separating hyper-plane to dividethe training examples into two classes and makedecisions based on support vectors which areselected as the only effective examples in thetraining set.
However, SVMs produce an un-calibrated value that is not probability.
That is, theunthresholded output of an SVM can berepresented as??+?
?=SViiii bxxkyaxf ),()(                 (4)To map the SVM output into the probability, wetrain an additional sigmoid model(Platt 1999):)exp(11)|(BAffspiii ++=                (5)Basically, SVMs are binary classifiers.Therefore, we must extend SVMs to multi-class(e.g.
K) classifiers.
For efficiency, we apply theone vs. others strategy, which builds K classifiersso as to separate one class from all others, insteadof the pairwise strategy, which builds K*(K-1)/2classifiers considering all pairs of classes.Moreover, we only apply the simple linear kernel,although other kernels (e.g.
polynomial kernel) andpairwise strategy can have better performance.Finally, for each state s , there is one sigmoid.
Therefore, the sigmoid outputs arenormalized to get a probability distribution usingi)|( ii fsp?=iiiiifspfsp)|()|(ni Osp )|( 1 .3.3 Post-ProcessingTwo post-processing modules, namely cascadedentity name resolution and abbreviation resolution,are applied in our system to further improve theperformance.Cascaded Entity Name ResolutionIt is found (Shen et al2003) that 16.57% of entitynames in GENIA V3.0 have cascadedconstructions, e.g.<RNA><DNA>CIITA</DNA> mRNA</RNA>.Therefore, it is important to resolve suchphenomenon.Here, a pattern-based module is proposed toresolve the cascaded entity names while the aboveHMM is applied to recognize embedded entity3names and non-cascaded entity names.
In theGENIA corpus, we find that there are six usefulpatterns of cascaded entity name constructions:?
<ENTITY> := <ENTITY> + head noun, e.g.<PROTEIN> binding motif?<DNA>?
<ENTITY> := <ENTITY>  + <ENTITY>, e.g.<LIPID> <PROTEIN>?<PROTEIN>?
<ENTITY> := modifier + <ENTITY>, e.g.anti <Protein>?<Protein>?
<ENTITY> := <ENTITY>  + word +<ENTITY>, e.g.<VIRUS> infected<MULTICELL>?<MULTICELL >?
<ENTITY> :=  modifier + <ENTITY> + headnoun?
<ENTITY> := <ENTITY> +  <ENTITY>  +head nounIn our experiments, all the rules of above sixpatterns are extracted from the cascaded entitynames in the training data to deal with thecascaded entity name phenomenon.Abbreviation ResolutionWhile the name alias feature is useful to detect theinter-sentential name alias phenomenon, it isunable to identify the inner-sentential name aliasphenomenon: the inner-sentential abbreviation.Such abbreviations widely occur in the biomedicaldomain.In our system, we present an effective andefficient algorithm to recognize the inner-sententialabbreviations more accurately by mapping them totheir full expanded forms.
In the GENIA corpus,we observe that the expanded form and itsabbreviation often occur together via parentheses.Generally, there are two patterns: ?expanded form(abbreviation)?
and ?abbreviation (expandedform)?.Our algorithm is based on the fact that it ismuch harder to classify an abbreviation than itsexpanded form.
Generally, the expanded form ismore evidential than its abbreviation to determineits class.
The algorithm works as follows: Given asentence with parentheses, we use a similaralgorithm as in Schwartz et al2003 to determinewhether it is an abbreviation with parentheses.
Thisis done by starting from the end of both theabbreviation and the expanded form, moving fromright to left and trying to find the shortestexpanded form that matches the abbreviation.
Anycharacter in the expanded form can match acharacter in the abbreviation with one exception:the match of the character at the beginning of theabbreviation must match the first alphabeticcharacter of the first word in the expanded form.
Ifyes, we remove the abbreviation and theparentheses from the sentence.
After the sentenceis processed, we restore the abbreviation withparentheses to its original position in the sentence.Then, the abbreviation is classified as the sameclass of the expanded form, if the expanded form isrecognized as an entity name.
In the meanwhile,we also adjust the boundaries of the expanded formaccording to the abbreviation, if necessary.
Finally,the expanded form and its abbreviation are storedin the recognized list of biomedical entity namesfrom the document to help the resolution offorthcoming occurrences of the same abbreviationin the document.4.
EXPERIMENTS AND EVALUATIONWe evaluate our PowerBioNE system on GENIAV1.1 and GENIA V3.0 using precision/recall/F-measure.
For each evaluation, we select 20% of thecorpus as the held-out test data and the remaining80% as the training data.
All the experimentationsare done 5 times and the evaluations are averagedover the held-out test data.
For cascaded entityname resolution, an average of 59 and 97 rules areextracted from the cascaded entity names in thetraining data of GENIA V1.1 and V3.0respectively.
For POS, all the POS taggers aretrained on the training data with POS importedfrom the corresponding GENIA V3.02p with POSannotated.Table 2 shows the performance of our systemon GENIA V1.1 and GENIA V3.0, and thecomparison with that of the best reported system(Shen et al2003).
It shows that our systemachieves the F-measure of 69.1 on GENIA V1.1and the F-measure of 71.2 on GENIA V3.0respectively, without help of any dictionaries.
Italso shows that our system outperforms Shen et al(2003) by 6.9 in F-measure on GENIA V1.1 and4.6 in F-measure on GENIA V3.0.
This is largelydue to the superiority of the SVM plus sigmoid inour system (improvement of 3.7 in F-measure onGENIA V3.0) over the back-off approach in Shenet al(2003) and the novel name alias feature(improvement of 1.2 in F-measure on GENIAV3.0).
Finally, evaluation also shows that thecascaded entity name resolution and theabbreviation resolution contribute 3.4 and 2.1respectively in F-measure on GENIA V3.0.Table 2: Performance of our PowerBioNE systemPerformance P R FShen et alon GENIA V3.0 66.5 66.6 66.6Shen et al on GENIA V1.1 63.1 61.2 62.2Our system on GENIA V3.0 72.7 69.8 71.2Our system on GENIA V1.1 70.4 67.9 69.14Table 3: Performance of different entity classes onGENIA V3.0EntityClassNumber of instances inthe training dataFCell Type 6034 81.8Lipid 1602 68.6Multi-Cell 1463 78.1Protein 21380 77.8DNA 7538 70.8Cell Line 3216 68.5RNA 695 56.2Virus 873 67.2One important question is about theperformance of different entity classes.
Table 3shows the performance of some of the biomedicalentity classes on GENIA V3.0.
Of particularinterest, our system achieves the F-measure of 77.8on the class ?Protein?.
It shows that theperformance varies a lot among different entityclasses.
One reason may be due to differentdifficulties in recognizing different entity classes.Another reason may be due to the differentnumbers of instances in different entity classes.Though GENIA V3.0 provides a good basis fornamed entity recognition in the biomedical domainand probably the best available, it has clear bias.Table 3 shows that, while GENIA V3.0 is ofenough size for recognizing the major classes, suchas ?Protein?, ?Cell Type?, ?Cell Line?, ?Lipid?etc, it is of limited size in recognizing other classes,such as  ?Virus?.5.
ERROR ANALYSISIn order to further evaluate our system and explorepossible improvement, we have implemented anerror analysis.
This is done by randomly choosing100 errors from our recognition results.
During theerror analysis, we find many errors are due to thestrict annotation scheme and the annotationinconsistence in the GENIA corpus, and can beconsidered acceptable.
Therefore, we will alsoexamine the acceptable F-measure of our system,in particular, the acceptable F-measure on the?protein?
class.All the 100 errors are classified as follows:?
Left boundary errors (14): It includes theerrors with correct class identification, correct rightboundary detection and only wrong left boundarydetection.
We find that most of such errors comefrom the long and descriptive naming convention.We also find that 11 of 14 errors are acceptableand ignorance of the descriptive words often doesnot make a much difference for the entity names.In fact, it is even hard for biologists to decidewhether the descriptive words should be a part ofthe entity names, such as ?normal?, ?activated?,etc.
In particular, 4 of 14 errors belong to the?protein?
class.
Among them, two errors areacceptable, e.g.
?classical <PROTEIN>1,25 (OH)2D3 receptor</PROTEIN>?
=>?<PROTEIN>classical 1,25 (OH) 2D3receptor</PROTEIN>?
(with format of?annotation in the corpus => identification madeby our system?
), while the other two areunacceptable, e.g.
?<PROTEIN>viraltranscription factor</PROTEIN> => viral<PROTEIN>transcription factor</PROTEIN>?.?
Cascaded entity name errors (15): It includesthe errors caused by the cascaded entity namephenomenon.
We find that most of such errorscome from the annotation inconsistence in theGENIA corpus: In some cases, only the embeddedentity names are annotated while in other cases, theembedded entity names are not annotated.
Oursystem tends to annotate both the embedded entitynames and the whole entity names.
Among them,we find that 13 of 16 errors are acceptable.
Inparticular, 2 of 16 errors belong to the ?protein?class and both are acceptable, e.g.
?<DNA>NFkappa B binding site</DNA>?
=>?<DNA><PROTEIN>NF kappa B</PROTEIN>binding site</DNA>?.?
Misclassification errors (18): It includes theerrors with wrong class identification, correct rightboundary detection and correct left boundarydetection.
We find that this kind of errors mainlycomes from the sense ambiguity of biomedicalentity names and is very difficult to disambiguate.Among them, 8 errors are related with the ?DNA?class and 6 errors are related with the ?Cell Line?and ?Cell Type?
classes.
We also find that only 3of 18 errors are acceptable.
In particular, there are6 errors related to the ?protein?
class.
Finally, wefind that all the 6 errors are caused bymisclassification of the ?DNA?
class to the?protein?
class and all of them are unacceptable,e.g.
?<DNA>type I IFN<DNA>?
=>?<PROTEIN>type I IFN</PROTEIN>?.?
True negative (23): It includes the errors bymissing the identification of biomedical entitynames.
We find that 16 errors come from the?other?
class and 10 errors from the ?protein?
class.We also find that the GENIA corpus annotatessome general noun phrases as biomedical entitynames, e.g.
?protein?
in ?the protein?
and?cofactor?
in ?a cofactor?.
Finally, we find that 11of 23 errors are acceptable.
In particular, 9 of 23errors related to the ?protein?
class.
Among them,3 errors are acceptable, e.g.
?the<PROTEIN>protein</PROTEIN> => ?the5protein?, while the other 6 are unacceptable, e.g.?
<PROTEIN>80 kDa</PROTEIN> => ?80 kDa?.?
False positive (15):  It includes the errors bywrongly identifying biomedical entity nameswhich are not annotated in the GENIA corpus.
Wefind that 9 of 15 errors come from the ?other?
class.This suggests that the annotation of the ?other?class is much lack of consistency and mostproblematic in the GENIA corpus.
We also findthat 7 of 15 errors are acceptable.
In particular, 2 of15 errors are related to the ?protein?
class and bothare acceptable, e.g.
?affinity sites?=>?<PROTEIN>affinity sites</PROTEIN>?.?
Miscellaneous (14): It includes all the othererrors, e.g.
combination of the above errors and theerrors caused by parentheses.
We find that only 1of 14 errors is acceptable.
We also find that,among them, 2 errors are related with the ?protein?class and both are unacceptable, e.g.
?<PROTEIN>17 amino acidepitope</PROTEIN>?
=> ?17 <RNA>amino acidepitope</RNA>?.From above error analysis, we find that abouthalf (46/100) of errors are acceptable and can beavoided by flexible annotation scheme (e.g.regarding the modifiers in the left boundaries) andconsistent annotation (e.g.
in the annotation of the?other?
class and the cascaded entity namephenomenon).
In particular, about one third (9/25)of errors are acceptable on the ?protein?
class.
Thismeans that the acceptable F-measure can reachabout 84.4 on the 23 classes of GENIA V3.0.
Inparticular, the acceptable F-measure on the?protein?
class is about 85.8.
In addition, thisperformance is achieved without using any extraresources (e.g.
dictionaries).
With help of extraresources, we think an acceptable F-measure ofnear 90 can be achieved in the near future.6.
RELATED WORKPrevious approaches in biomedical named entityrecognition typically use some domain specificheuristic rules and heavily rely on existingdictionaries (Fukuda et al1998, Proux et al1998and Gaizauskas et al2000).The current trend is to apply machine learningapproaches in biomedical named entity recognition,largely due to the development of the GENIAcorpus.
The typical explorations include Kazama etal 2002, Lee et al2003, Tsuruoka et al2003, Shenet al2003.
Kazama et al2002 applies SVM andincorporates a rich feature set, including wordfeature, POS, prefix feature, suffix feature,previous class feature, word cache feature andHMM state feature.
The experiment on GENIAV1.1 shows the F-measure of 54.4.
Tsuruoka et al2003 applies a dictionary-based approach and ana?ve Bayes classifier to filter out false positives.
Itonly evaluates against the ?protein?
class inGENIA V3.0, and receives the F-measure of 70.2with help of a large dictionary.
Lee et al2003 usesa two phase SVM-based recognition approach andincorporates word formation pattern and part-of-speech.
The evaluation on GENIA V3.0 shows theF-measure of 66.5 with help of an entity namedictionary.
Shen et al2003 proposes a HMM-basedapproach and two post-processing modules(cascaded entity name resolution and abbreviationresolution).
Evaluation shows the F-measure of62.2 and 66.6 on GENIA V1.1 and V3.0respectively.7.
CONCLUSIONIn the paper, we describe our HMM-based namedentity recognition system in the biomedical domain,named PowerBioNE.
Various lexical,morphological, syntactic, semantic and discoursefeatures are incorporated to cope with the specialphenomena in biomedical named entity recognition.In addition, a SVM plus sigmoid is proposed toeffectively resolve the data sparseness problem.Finally, we present two post-processing modules todeal with cascaded entity name and abbreviationphenomena.The main contributions of our work are thenovel name alias feature in the biomedical domain,the SVM plus sigmoid approach in the effectiveresolution of the data sparseness problem in oursystem and its integration with the Hidden MarkovModel.In the near future, we will further improve theperformance by investigating more on conjunctionand disjunction construction, the synonymphenomenon, and exploration of extra resources(e.g.
dictionary).REFERENCESChen and Goodman.
1996.
An Empirical Study ofSmoothing Technniques for Language Modeling.In Proceedings of the 34th Annual Meeting of theAssociation of Computational Linguistics(ACL?1996).
pp310-318.
Santa Cruz, California,USA.Fukuda K., Tsunoda T., Tamura A., and Takagi T.1998.
Toward information extraction: identifyingprotein names from biological papers.
In Proc.
ofthe Pacific Symposium on Biocomputing?98(PSB?98), 707-718.Gaizauskas R., Demetriou G. and Humphreys K.2000.
Term Recognition and Classification inBiological Science Journal Articles.
In Proc.
of theComputational Terminology for Medical andBiological Applications Workshop of the 2ndInternational Conference on NLP, 37-44.6Jacquemin C. 2001.
Spotting and Discovering Termsthrough Natural Language Processing, Cambridge:MIT PressKazama J., Makino T., Ohta Y., and Tsujii J.
2002.Tuning Support Vector Machines for BiomedicalNamed Entity Recognition.
In Proc.
of theWorkshop on Natural Language Processing in theBiomedical Domain (at ACL?2002), 1-8.Lee K.J.
Hwang Y.S.
and Rim H.C. Two-phasebiomedical NE Recognition based on SVMs.
InProceedings of the ACL?2003 Workshop onNatural Language Processing in Biomedicine.pp.33-40.
Sapporo, Japan.MUC6.
1995.
Morgan Kaufmann Publishers, Inc. InProceedings of the Sixth Message UnderstandingConference (MUC-6).
Columbia, Maryland.MUC7.
1998.
Morgan Kaufmann Publishers, Inc. InProceedings of the Seventh MessageUnderstanding Conference (MUC-7).
Fairfax,Virginia.Ohta T., Tateisi Y., Kim J., Mima H., and Tsujii J.2002.
The GENIA corpus: An annotated researchabstract corpus in molecular biology domain.
InProc.
of HLT 2002.Platt J.
1999.
Probabilistic Outputs for SupportVector Machines and comparisions to regularizedLikelihood Methods.
MIT Press.Proux D., Rechenmann F., Julliard L., Pillet V. andJacq B.
1998.
Detecting Gene Symbols andNames in Biological Texts: A First Step towardPertinent Information Extraction.
In Proc.
ofGenome Inform Ser Workshop Genome Inform,72-80.Schwartz A.S. and Hearst M.A.
2003.
A SimpleAlgorithm for Identifying AbbreviationDefinitions in Biomedical Text.
In Proc.
of thePacific Symposium on Biocomputing (PSB 2003)Kauai.Shen Dan, Zhang Jie, Zhou GuoDong, Su Jian andTan Chew Lim, Effective Adaptation of a HiddenMarkov Model-based Named Entity Recognizerfor Biomedical Domain, Proceedings of ACL?2003Workshop on Natural Language Processing inBiomedicine, Sapporo, Japan, 11 July 2003. pp49-56.Tsuruoka Y. and Tsujii J.
2003.
Boosting precisionand recall of dictionary-based protein namerecognition.
In Proceedings of the ACL?2003Workshop on Natural Language Processing inBiomedicine.
pp.41-48.
Sapporo, Japan.Vapnik V. 1995.
The Nature of Statistical LearningTheory.
NY, USA: Springer-Verlag.Viterbi A.J.
1967.
Error bounds for convolutionalcodes and an asymptotically optimum decodingalgorithm.
IEEE Transactions on InformationTheory, 260-269.Zhou G.D. and Su J.
2002.
Named EntityRecognition using an HMM-based Chunk Tagger.In Proc.
of the 40th Annual Meeting of theAssociation for Computational Linguistics (ACL),473-480.7
