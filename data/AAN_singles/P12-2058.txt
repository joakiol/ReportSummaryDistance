Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 296?300,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsHeuristic Cube Pruning in Linear TimeAndrea GesmundoDepartment ofComputer ScienceUniversity of Genevaandrea.gesmundo@unige.chGiorgio SattaDepartment ofInformation EngineeringUniversity of Paduasatta@dei.unipd.itJames HendersonDepartment ofComputer ScienceUniversity of Genevajames.henderson@unige.chAbstractWe propose a novel heuristic algorithm forCube Pruning running in linear time in thebeam size.
Empirically, we show a gain inrunning time of a standard machine translationsystem, at a small loss in accuracy.1 IntroductionSince its first appearance in (Huang and Chiang,2005), the Cube Pruning (CP) algorithm has quicklygained popularity in statistical natural language pro-cessing.
Informally, this algorithm applies to sce-narios in which we have the k-best solutions for twoinput sub-problems, and we need to compute the k-best solutions for the new problem representing thecombination of the two sub-problems.CP has applications in tree and phrase based ma-chine translation (Chiang, 2007; Huang and Chi-ang, 2007; Pust and Knight, 2009), parsing (Huangand Chiang, 2005), sentence alignment (Riesa andMarcu, 2010), and in general in all systems combin-ing inexact beam decoding with dynamic program-ming under certain monotonic conditions on the def-inition of the scores in the search space.Standard implementations of CP run in timeO(k log(k)), with k being the size of the in-put/output beams (Huang and Chiang, 2005).
Ges-mundo and Henderson (2010) propose Faster CP(FCP) which optimizes the algorithm but keeps theO(k log(k)) time complexity.
Here, we propose anovel heuristic algorithm for CP running in timeO(k) and evaluate its impact on the efficiency andperformance of a real-world machine translationsystem.2 PreliminariesLet L = ?x0, .
.
.
, xk?1?
be a list over R, that is,an ordered sequence of real numbers, possibly withrepetitions.
We write |L| = k to denote the length ofL.
We say that L is descending if xi ?
xj for everyi, j with 0 ?
i < j < k. Let L1 = ?x0, .
.
.
, xk?1?and L2 = ?y0, .
.
.
, yk??1?
be two descending listsover R. We write L1 ?
L2 to denote the descendinglist with elements xi+yj for every i, j with 0 ?
i <k and 0 ?
j < k?.In cube pruning (CP) we are given as input twodescending lists L1, L2 over R with |L1| = |L2| =k, and we are asked to compute the descending listconsisting of the first k elements of L1 ?L2.A problem related to CP is the k-way mergeproblem (Horowitz and Sahni, 1983).
Given de-scending lists Li for every i with 0 ?
i < k, wewrite mergek?1i=0 Li to denote the ?merge?
of all thelists Li, that is, the descending list with all elementsfrom the lists Li, including repetitions.For ?
?
R we define shift(L,?)
= L ?
???.
Inwords, shift(L,?)
is the descending list whose ele-ments are obtained by ?shifting?
the elements of Lby ?, preserving the order.
Let L1,L2 be descend-ing lists of length k, with L2 = ?y0, .
.
.
, yk?1?.Then we can express the output of CP on L1,L2 asthe listmergek?1i=0 shift(L1, yi) (1)truncated after the first k elements.
This shows thatthe CP problem is a particular instance of the k-waymerge problem, in which all input lists are related byk independent shifts.296Computation of the solution of the k-way mergeproblem takes time O(q log(k)), where q is thesize of the output list.
In case each input list haslength k this becomes O(k2 log(k)), and by restrict-ing the computation to the first k elements, as re-quired by the CP problem, we can further reduce toO(k log(k)).
This is the already known upper boundon the CP problem (Huang and Chiang, 2005; Ges-mundo and Henderson, 2010).
Unfortunately, thereseems to be no way to achieve an asymptoticallyfaster algorithm by exploiting the restriction that theinput lists are all related by some shifts.
Nonethe-less, in the next sections we use the above ideas todevelop a heuristic algorithm running in time linearin k.3 Cube Pruning With Constant SlopeConsider lists L1,L2 defined as in section 2.
We saythat L2 has constant slope if yi?1?
yi = ?
> 0 forevery i with 0 < i < k. Throughout this section weassume that L2 has constant slope, and we developan (exact) linear time algorithm for solving the CPproblem under this assumption.For each i ?
0, let Ii be the left-open interval(x0 ?
(i + 1) ?
?, x0 ?
i ?
?]
of R. Let alo s =?
(x0 ?
xk?1)/??
+ 1.
We split L1 into (possiblyempty) sublists ?i, 0 ?
i < s, called segments, suchthat each ?i is the descending sublist consisting ofall elements fromL1 that belong to Ii.
Thus, movingdown one segment in L1 is the closest equivalent tomoving down one element in L2.Let t = min{k, s}; we define descending listsMi, 0 ?
i < t, as follows.
We set M0 =shift(?0, y0), and for 1 ?
i < t we letMi = merge{shift(?i, y0), shift(Mi?1,??)}
(2)We claim that the ordered concatenation of M0,M1, .
.
.
, Mt?1 truncated after the first k elementsis exactly the output of CP on input L1,L2.To prove our claim, it helps to visualize the de-scending list L1 ?
L2 (of size k2) as a k ?
k matrixL whose j-th column is shift(L1, yj), 0 ?
j < k.For an interval I = (x, x?
], we define shift(I, y) =(x+ y, x?+ y].
Similarly to what we have done withL1, we can split each column of L into s segments.For each i, j with 0 ?
i < s and 0 ?
j < k, we de-fine the i-th segment of the j-th column, written ?i,j ,as the descending sublist consisting of all elementsof that column that belong to shift(Ii, yj).
Then wehave ?i,j = shift(?i, yj).For any d with 0 ?
d < t, consider now allsegments ?i,j with i + j = d, forming a sub-antidiagonal in L. We observe that these segmentscontain all and only those elements of L that belongto the interval Id.
It is not difficult to show by in-duction that these elements are exactly the elementsthat appear in descending order in the list Mi definedin (2).We can then directly use relation (2) to iterativelycompute CP on two lists of length k, under our as-sumption that one of the two lists has constant slope.Using the fact that the merge of two lists as in (2) canbe computed in time linear in the size of the outputlist, it is not difficult to implement the above algo-rithm to run in time O(k).4 Linear Time Heuristic SolutionIn this section we further elaborate on the exact al-gorithm of section 3 for the constant slope case, anddevelop a heuristic solution for the general CP prob-lem.
Let L1,L2, L and k be defined as in sections 2and 3.
Despite the fact that L2 does not have a con-stant slope, we can still split each column of L intosegments, as follows.Let I?i, 0 ?
i < k ?
1, be the left-open interval(x0 + yi+1, x0+ yi] of R. Note that, unlike the caseof section 3, intervals I?i?s are not all of the same sizenow.
Let alo I?k?1 = [xk?1 + yk?1, x0 + yk?1].For each i, j with 0 ?
j < k and 0 ?
i < k ?j, we define segment ?
?i,j as the descending sublistconsisting of all elements of the j-th column of Lthat belong to I?i+j .
In this way, the j-th columnof L is split into segments I?j , I?j+1, .
.
.
, I?k?1, andwe have a variable number of segments per column.Note that segments ?
?i,j with a constant value of i+jcontain all and only those elements of L that belongto the left-open interval I?i+j .Similarly to section 3, we define descending listsM?i, 0 ?
i < k, by setting M?0 = ?
?0,0 and, for1 ?
i < k, by lettingM?i = merge{?
?i,0 , path(M?i?1, L)} (3)Note that the function path(M?i?1, L) should not re-turn shift(M?i?1,??
), for some value ?, as in the2971: Algorithm 1 (L1, L2) : L?
?2: L?
?.insert(L[0, 0]);3: referColumn?
0;4: xfollow ?
L[0, 1];5: xdeviate ?
L[1, 0];6: C ?
CircularList([0, 1]);7: C-iterator?
C.begin();8: while |L?
?| < k do9: if xfollow > xdeviate then10: L?
?.insert(xfollow );11: if C-iterator.current()=[0, 1] then12: referColumn++;13: [i, j]?
C-iterator.next();14: xfollow ?
L[i,referColumn+j];15: else16: L?
?.insert(xdeviate );17: i?
xdeviate .row();18: C-iterator.insert([i,?referColumn]);19: xdeviate ?
L[i + 1, 0];case of (2).
This is because input list L2 does nothave constant slope in general.
In an exact algo-rithm, path(M?i?1, L) should return the descendinglist L?i?1 = mergeij=1 ?
?i?j,j: Unfortunately, we donot know how to compute such a i-way merge with-out introducing a logarithmic factor.Our solution is to define path(M?i?1, L) in such away that it computes a list L?i?1 which is a permu-tation of the correct solution L?i?1.
To do this, weconsider the ?relative?
path starting at x0+yi?1 thatwe need to follow in L in order to collect all the el-ements of M?i?1 in the given order.
We then applysuch a path starting at x0 + yi and return the list ofcollected elements.
Finally, we compute the outputlist L??
as the concatenation of all lists M?i up to thefirst k elements.It is not difficult to see that when L2 has constantslope we have M?i = Mi for all i with 0 ?
i < k,and list L??
is the exact solution to the CP prob-lem.
When L2 does not have a constant slope, listL??
might depart from the exact solution in two re-spects: it might not be a descending list, becauseof local variations in the ordering of the elements;and it might not be a permutation of the exact so-lution, because of local variations at the end of thelist.
In the next section we evaluate the impact that  	                        Figure 1: A running example for Algorithm 1.our heuristic solution has on the performance of areal-world machine translation system.Algorithm 1 implements the idea presented in (3).The algorithm takes as input two descending listsL1,L2 of length k and outputs the list L??
whichapproximates the desired solution.
Element L[i, j]denotes the combined value xi + yj , and is alwayscomputed on demand.We encode a relative path (mentioned above) asa sequence of elements, called displacements, eachof the form [i, ?].
Here i is the index of the next row,and ?
represents the relative displacement needed toreach the next column, to be summed to a variablecalled referColumn denoting the index of the col-umn of the first element of the path.
The reasonwhy only the second coordinate is a relative valueis that we shift paths only horizontally (row indicesare preserved).
The relative path is stored in a circu-lar list C, with displacement [0, 1] marking the start-ing point (paths are always shifted one element tothe right).
When merging the list obtained throughthe path for M?i?1 with segment ?
?i,0, as specifiedin (3), we update C accordingly, so that the new rel-ative path can be used at the next round for M?i.
Themerge operator is implemented by the while cycleat lines 8 to 19 of algorithm 1.
The if statement atline 9 tests whether the next step should follow therelative path for M?i?1 stored in C (lines 10 to 14) or298-50510152025303540451  10  100  1000scoreloss(%)beam sizeBaseline score loss over CPLCP score loss over CPFCP score loss over CPFigure 2: Search-score loss relative to standard CP.else depart visiting an element from ?
?i,0 in the firstcolumn of L (lines 16 to 19).
In the latter case, weupdate C with the new displacement (line 18), wherethe function insert() inserts a new element beforethe one currently pointed to.
The function next() atline 13 moves the iterator to the next element andthen returns its value.A running example of algorithm 1 is reported inFigure 1.
The input lists are L1 = ?12, 7, 5, 0?,L2 = ?9, 6, 3, 0?.
Each of the picture in the sequencerepresents the state of the algorithm when the test atline 9 is executed.
The value in the shaded cell in thefirst column is xdeviate , while the value in the othershaded cell is xfollow .5 ExperimentsWe implement Linear CP (LCP) on top of Cdec(Dyer et al, 2010), a widely-used hierarchical MTsystem that includes implementations of standardCP and FCP algorithms.
The experiments were ex-ecuted on the NIST 2003 Chinese-English parallelcorpus.
The training corpus contains 239k sentencepairs.
A binary translation grammar was extractedusing a suffix array rule extractor (Lopez, 2007).The model was tuned using MERT (Och, 2003).The algorithms are compared on the NIST-03 testset, which contains 919 sentence pairs.
The featuresused are basic lexical features, word penalty and a3-gram Language Model (Heafield, 2011).Since we compare decoding algorithms on thesame search space, the accuracy comparison is donein terms of search score.
For each algorithm we05101520251  10  100  1000speedgain(%)beam sizeLCP speed gain over CPLCP speed gain over FCPFigure 3: Linear CP relative speed gain.compute the average score of the best translationfound for the test sentences.
In Figure 2 we plotthe score-loss relative to standard CP average score.Note that the FCP loss is always < 3%, and the LCPloss is always < 7%.
The dotted line plots the lossof a baseline linear time heuristic algorithm whichassumes that both input lists have constant slope,and that scans L along parallel lines whose steepis the ratio of the average slope of each input list.The baseline greatly deteriorates the accuracy: thisshows that finding a reasonable linear time heuristicalgorithm is not trivial.
We can assume a boundedloss in accuracy, because for larger beam size all thealgorithms tend to converge to exhaustive search.We found that these differences in search scoreresulted in no significant variations in BLEU score(e.g.
with k = 30, CP reaches 32.2 while LCP 32.3).The speed comparison is done in terms of algo-rithm run-time.
Figure 3 plots the relative speed gainof LCP over standard CP and over FCP.
Given thelog-scale used for the beam size k, the linear shapeof the speed gain over FCP (and CP) in Figure 3 em-pirically confirms that LCP has a log(k) asymptoticadvantage over FCP and CP.In addition to Chinese-English, we ran experi-ments on translating English to French (from Eu-roparl corpus (Koehn, 2005)), and find that the LCPscore-loss relative to CP is < 9% while the speedrelative advantage of LCP over CP increases in aver-age by 11.4% every time the beam size is multipliedby 10 (e.g.
with k = 1000 the speed advantage is34.3%).
These results confirm the bounded accu-racy loss and log(k) speed advantage of LCP.299ReferencesDavid Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Chris Dyer, Adam Lopez, Juri Ganitkevitch, JonathanWeese, Hendra Setiawan, Ferhan Ture, Vladimir Ei-delman, Phil Blunsom, and Philip Resnik.
2010.cdec: A decoder, alignment, and learning frameworkfor finite-state and context-free translation models.In ACL ?10: Proceedings of the ACL 2010 SystemDemonstrations, Uppsala, Sweden.Andrea Gesmundo and James Henderson.
2010.
FasterCube Pruning.
In IWSLT ?10: Proceedings of the 7thInternational Workshop on Spoken Language Transla-tion, Paris, France.Kenneth Heafield.
2011.
KenLM: Faster and smallerlanguage model queries.
In WMT ?11: Proceedings ofthe 6th Workshop on Statistical Machine Translation,Edinburgh, Scotland, UK.E.
Horowitz and S. Sahni.
1983.
Fundamentals ofdata structures.
Computer software engineering se-ries.
Computer Science Press.Liang Huang and David Chiang.
2005.
Better k-bestparsing.
In IWPT ?05: Proceedings of the 9th Interna-tional Workshop on Parsing Technology, Vancouver,British Columbia, Canada.Liang Huang and David Chiang.
2007.
Forest rescor-ing: Faster decoding with integrated language mod-els.
In ACL ?07: Proceedings of the 45th Confer-ence of the Association for Computational Linguistics,Prague, Czech Republic.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of the10th Machine Translation Summit, Phuket, Thailand.Adam Lopez.
2007.
Hierarchical phrase-based transla-tion with suffix arrays.
In EMNLP-CoNLL ?07: Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, Prague, CzechRepublic.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In ACL ?03: Pro-ceedings of the 41st Conference of the Association forComputational Linguistics, Sapporo, Japan.Michael Pust and Kevin Knight.
2009.
Faster MT decod-ing through pervasive laziness.
In NAACL ?09: Pro-ceedings of the 10th Conference of the North AmericanChapter of the Association for Computational Linguis-tics, Boulder, CO, USA.Jason Riesa and Daniel Marcu.
2010.
Hierarchicalsearch for word alignment.
In ACL ?10: Proceedingsof the 48th Conference of the Association for Compu-tational Linguistics, Uppsala, Sweden.300
