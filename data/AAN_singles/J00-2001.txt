Integrating Text Planning and LinguisticChoice Without Abandoning Modularity:The IGEN GeneratorRobert Rubinoff*Natural anguage generation is usually divided into separate text planning and linguistic om-ponents.
This division, though, assumes that the two components can operate independently,which is not always true.
The IGEN generator eliminates the need for this assumption; it handlesinteractions between the components without sacri~cing the advantages of modularity.
IGENaccomplishes this by means of annotations that its linguistic omponent places on the structuresit builds; these annotations provide an abstract description of the effects of particular linguisticchoices, allowing the planner to evaluate these choices without needing any linguistic knowledge.This approach allows IGEN to vary the work done by each component independently, even incases where the final output depends on interactions between them.
In addition, since IGENexplicitly models the effects of linguistic choices, it can gracefully handle situations where theavailable time or linguistic resources are limited.1.
IntroductionPrograms that generate natural language have generally been divided into two largelyindependent components: a text planning component that organizes the informationto be expressed, and a linguistic omponent that converts the information i to gram-matical sentences of some natural anguage (e.g., Thompson 1977; McKeown 1985;McDonald 1983; Meteer 1989; Reithinger 1990; Dale 1989).
This division seems natural,and has indeed proven useful, because the two components deal with different kindsof data and involve different kinds of reasoning.
The planning component reasonsabout information and text structures to plan a coherent discourse, while the linguis-tic component arranges the lexical elements and syntactic onstructions available insome language to ensure the resulting text's grammaticality and comprehensibility.This division into independent components, though, is only tenable if the decisionseach component must make can be made independently.
If some of the generator'swork involves both text planning and purely linguistic issues, there will be no wayto make the necessary decisions without violating the generator's modularity.
As weshall see, natural anguage generation does indeed involve such decisions.
The needto handle interactions between text planning and linguistic concerns thus seems torequire either abandoning the division into separate components (e.g., Danlos 1987;Kantrowitz and Bates 1992), with the resulting increase in complexity, or foregoingthe ability to handle these interactions at all (as advocated in Reiter \[1994\]).
A thirdoption is to identify possible interactions in advance and handle them as special cases,but this only allows the generator to handle those interactions that have been antici-?
AnswerLogic, Inc., 1111 9 St. NW, Suite 600, Washington, DC 20036.
E-mail: rrubinoff@answerlogic.com.
The research described here was done at the University of Pennsylvania and Carnegie MellonUniversity.
(~) 2000 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 2pated in advance.
Furthermore, handling the interactions often requires violating themodularity of the system, because detecting when the special case has occurred stillrequires both planning and linguistic knowledge.The IGEN generator solves this problem.
IGEN handles interactions between thetext planning and linguistic components without having to sacrifice any of the gen-erator's modularity.
The key to IGEN's approach is the use of annotations that thelinguistic component attaches to each linguistic expression it constructs.
These anno-tations abstract away from the details of the linguistic expressions, describing onlythose properties of the expressions that are potentially relevant o the planner.
Theplanner can then evaluate the choices made by the linguistic component and deter-mine how those choices interact with the text plan independently of the linguisticcomponent's processes and data structures.
As a result, IGEN can make decisions in-volving interactions between the components while retaining complete modularity.
Infact, replacing IGEN's normal inguistic component with one for a different languageinvolves no change in the planner despite the fact that the two languages have d~-ferent idiomatic expressions for some of the sentences being generated; the planner'sprocessing is identical in both languages.
Furthermore, since the annotations allowIGEN to explicitly model the effects of its decisions, IGEN is able to gracefully handlethe effects of limitations on processing time or linguistic resources; ince IGEN alwaysknows how well a given linguistic construction carries out its plan, it can choose thebest available construction when it can't find an ideal one.2.
Modularity in GenerationResearch in natural language generation has generally separated the task into distincttext planning and linguistic components.
The text planning component selects andorganizes the information to be expressed in some internal representation a d thensends it to the linguistic omponent, which converts the information from the internalform into grammatical sentences of some natural anguage.
The names given to thecomponents vary; they have been called "strategic" and "tactical" components (e.g.,McKeown 1985; Thompson 1977; Danlos 1987) 1, "planning" and "realization" (e.g.,McDonald 1983; Hovy 1988a), or simply "what to say" versus "how to say it" (e.g.,Danlos 1987; Reithinger 1990).
The precise division of work between the componentscan also vary, as can the extent o which the text planner is responsible for select-ing (as opposed to merely organizing) the information to be expressed.
Much (if notmost) work in generation, though, continues to rely on this modular approach for itsbasic design.
For example, DIOGENES (Nirenburg et al 1988), EPICURE (Dale 1989),SPOKESMAN (Meteer 1989), Sibun's work on local organization of text (Sibun 1991),and COMET (Fisher and McKeown 1990) all are organized this way.
McDonald haseven argued for extending the model to a large number of components (McDonald1988), and several systems have indeed added an additional component between theplanner and the linguistic component (Meteer 1994; Panaget 1994; Wanner 1994).
Re-iter describes a pipelined modular approach as a consensus architecture underlyingmost recent work in generation (Reiter 1994).As this large body of work makes clear, the modular approach as been veryuseful, simplifying the design of generators and making them more flexible.
In fact, inat least one case the "tactical" component ofa generator was successfully replaced witha radically different independently designed one (Rubinoff 1986).
A modular design,l Danlos uses "syntactic" rather than "tactical"; see the note on page 122 of Danlos (1987).108Rubinoff The IGEN Generatorthough, presumes that the work done by each module can be done independently.Separating eneration into text planning and linguistic components thus implicitlyassumes that text planning can be done without knowledge of the language being usedand, conversely, that linguistic choices can be made without text planning knowledge.Unfortunately, this is not always true; both structural and lexical choices sometimesdepend on interactions between the two parts of the generator.
Thus generation musteither compromise the modularity between the components or give up the ability tohandle these cases properly}2.1 Interactions between the ModulesThe modular approach to generation assumes that the linguistic component's decisionsnever matter to the planner (or whichever component(s) organize the information tobe expressed).
This is not the case, though, as can be seen from the alternations in(1)-(3):(1) a. John killed him with a gun.b.
John shot him dead.
(2) a. John infected him with a virus.b.
*John virused him sick.
(3) a.
*John homed him with an order.b.
John ordered him home.The sentences (la) and (lb) express essentially the same information, so if thegenerator is attempting to express this information, it must choose between them atsome point.
In a modular generator, though, there is no point at which the decisioncan be made.
The planner can't make this choice, because the availability of the choicedepends on the particular linguistic resources of English.
This can be seen by com-parison with (2) and (3), in which only one alternative is available.
In fact, a differentalternative is available in each case.
Since the planner doesn't know which alterna-tive(s) is/are available, it can't choose between them; the linguistic component mustmake the choice.On the other hand, the decision has to be made by the planner, since it can dependon and/or  affect the goals the generator is trying to achieve.
The choice between (la)and (lb) should depend (in part) on what the generator is primarily trying to talkabout.
(la) is more appropriate if the generator is going to continue talking about thegun, whereas (lb) is more appropriate if the main concern is the ramifications of thevictim's death.
Since the planner is the component that deals with this information, itmust choose between the alternatives.Also, the choice between (la) and (lb) determines what information can be easilyomitted; cutting off the end of the sentence leaves out mention of the use of a gun in(la) and the death of the victim in (lb).
Since the planner knows the consequences ofomitting information, it must make the choice of which alternative to use and whetherto abbreviate it.
It might seem that the planner could simply indicate exactly what2 Note that these interactions aren't he result of the particular details of how the work is dividedbetween the components.
Aswe shall see, there are some decisions that depend on both theunderlying oals driving the generator and the details of what can be expressed ina particularlanguage.
Any architecture that deals with these issues in different components will encounter theproblems described below.109Computational Linguistics Volume 26, Number 2information it wants included in the utterance, but that would require the generatorto always assume a strategy of saying as little as possible.Furthermore, decisions about what information to include may interact with otherdecisions.
For example, the generator may want to emphasize the victim's death butnot care about the means of death; it might then choose (lb) for the emphasis eventhough (la) would let it skip mention of the gun.
This kind of decision can only bemade by the planner.The same kinds of interactions arise in the process of lexical choice.
It wouldseem that lexical choice has to be handled by the planner, since it depends very muchon what the generator is trying to accomplish.
For example, the choice of describingsomeone as either firm, obstinate, or stubborn should depend on what else the generatorwants to say about the person, as should the choice between meek and wimpy.
Thegenerator might describe how justice was served by an execution rather than how theprisoner was murdered by the state.
Similarly, the generator might deride the commentsof a dreamer, but praise the insights of a visionary.
These kinds of lexical choices canonly be made by the component that handles the generator's goals.On the other hand, there are a number of reasons why lexical choice has to behandled by the linguistic component.
First of all, lexical choice is very dependent onthe particular linguistic vocabulary of the language being generated.
Thus French, forexample, uses two different verbs (connaftre and savoir) to express knowing a personand knowing information, but English just uses know for both concepts.
Similarly,English uses to be to indicate both location and a state or property, whereas Frenchuses se trouver for the former and ~tre for the latter.Furthermore, there is in general no guarantee that there will be any lexical item toexpress a given concept.
For example, there is no word in English for the concept ofa car with a removable door.
There's no inherent reason why there couldn't be; afterall, there's a word for a car with a removable roof.
This is just a particular fact aboutEnglish.
Similarly, there is a word giant meaning "large man", but no correspondingword meaning "large car".In addition, since lexical choice interacts with syntactic decisions, it cannot be donein advance of choosing syntactic structures.
For example, a generator cannot decideto use probable instead of likely without knowing if the completed utterance could bethe ungrammatical he is probable to be early.
Similarly, the verb drink can't be chosenwithout knowing whether the clause will have a direct object; he drinks apple juice andhe drinks actually have quite different meanings.
3 Note that the decision here doesn'tdepend just on whether the beverage is going to be explicitly mentioned; it dependson whether it's going to be mentioned in a specific syntactic position in the sentence.So here too it is impossible to assign the decision to a single component; he decisionmust be made by both components.The need to handle interactions such as these forces compromises in the modular-ity of generators.
In the TEXT system (McKeown 1985), for example, some decisionsabout what information to include are in fact encoded into the tactical component.For example, TEXT's tactical component omits the attribute value WATER (used inTEXT to indicate that some object travels in or under the water) when it must be3 McDonald has argued that lexical choice should be done in the first step in generation; i  cases wherelexical and syntactic decisions interact, lexical choice will constrain subsequent syntactic decisions(McDonald 1991).
This approach iscertainly possible (although it's not clear how to preventindependent lexical choices from imposing incompatible syntactic constraints), but it assumes that theresulting syntactic constraints don't matter to the generator.
For example, choosing drink may requirethe generator to include a direct object even if it would prefer not to indicate that information; by thetime the generator discovers this requirement, it is already committed to the choice.110Rubinoff The IGEN Generatorexpressed as an adjective.
This is because the only available adjective is the somewhatawkward water-going, and it turns out that in the sentences TEXT happens to generate,WATER only appears in an adjective context in cases where it's not important to sayit.
Thus, this strategic decision (that WATER can be omitted) is encoded permanentlyinto the tactical component; here is no way for the strategic omponent to control thisdecision.In MUMBLE (Meteer et al 1987), in contrast, the interactions have pushed lin-guistic information into the text planner.
For example, MUMBLE can take the alreadyconstructed phrase Fluffy, Floyd's dog, buries bones and modify it with the informationthat this was reported by Helga to produce Helga reported that Fluffy, Floyd's dog, buriesbones.
But in order to do this, it has to mark the information about Helga with thenew-main-clause feature.
So the planner has to know what clauses are, know thatthe earlier information was turned into a clause, and know that making Helga reportsa new main clause is a useful thing to do.
Many of the linguistic decisions are thusactually being made by the planner.2.2 Facing the DilemmaWe are now faced with a dilemma.
On the one hand, the separation of planning andlinguistic realization into distinct components seems natural and useful.
On the otherhand, it precludes making decisions involving interactions between text planning andlinguistic issues.One possible response would be to abandon the separation; the generator could bea single component that handles all of the work.
This approach as occasionally beentaken, as in Kantrowitz and Bates (1992) and Danlos (1987) 4 and, at least implicitly, inParis and Scott (1994) and Delin et al (1994); however, under this approach, all of theflexibility and simplicity of modular design is lost.The opposite approach is to simply ignore the limitations of a modular design andproceed as if there need be no interactions between the components.
Whatever prob-lems result will be handled as best they can, on a case-by-case basis.
This approach isthe one taken (implicitly or explicitly) in the majority of generators.
In fact, Reiter haseven argued in favor of this approach, claiming that the interactions are sufficiently mi-nor to be ignored (or at least handled on an ad hoc basis) (Reiter 1994).
While this cer-tainly has appeal as a design methodology, it seems reckless to assume that problemswill never appear.
Certainly an approach to generation that does handle these interac-tions would be an improvement, as long as it didn't require abandoning modularity.There have in fact been attempts to develop modified modular designs that allowgenerators to handle interactions between the components.
These include devices uchas interleaving the components (McDonald 1983; Appelt 1983), backtracking on failure(Appelt 1985; Nogier 1989), allowing the linguistic component to interrogate the plan-ner (Mann 1983; Sondheimer and Nebel 1986), and Hovy's notion of restrictive (i.e.,bottom-up) planning (Hovy 1988a, 1988c).
All of these approaches, though, requirethat potential interactions be determined either by the tactical component or by thesystem designer in advance.
The text planning component still has no way to detectand respond to unanticipated interactions on its own initiative.
54 Danlos till has a separate low-level "syntactic" omponent, but essentially all of the generator'sdecisions are made by the strategic component.5 In fact, adding additional components may make the problem even worse, as decisions may then bespread across three or more separate components.
It might seem that a component placed between theplanner and the realizer could handle interactions between the levels, but this would simply recreatethe original problem within the "middle" component; coping with the interactions would still requiredealing with the whole range of issues that come up in both planning and realization.111Computational Linguistics Volume 26, Number 2The IGEN generator esolves the modularity dilemma by means of a new ap-proach that preserves complete modularity but allows the generator to handle inter-actions between the components.
The key to IGEN's approach is that the linguisticcomponent provides the planner with an abstract description of the effects of usingparticular linguistic structures.
This abstract description is encoded in annotations thatthe linguistic component attaches to the structures it builds.
In contrast with previousfeedback-based approaches, in which the feedback only occurs when the linguisticcomponent needs additional help from the planner, IGEN annotates all of its linguisticstructures.
This allows the planner to detect situations where linguistic choices causeproblems at the planning level; the linguistic component need not be aware of them.Conversely, the planner can build communicative plans without concern for whetherthe linguistic component can actually express the elements of the plan; any such prob-lems will be detected by the linguistic component and reflected in the annotations.The annotations allow a cycle of negotiation between the planner and the linguisticcomponent; each component works entirely within its own level, drawing only on theresults of the work at the other level.3.
IGEN: A New Model for GenerationThe IGEN generator overcomes the limitations of the modular approach, without giv-ing up its advantages, by the use of annotations that provide feedback from the lin-guistic component to the planner.
These annotations abstract away from the detailsof the linguistic expressions, allowing the planner to detect interactions between de-cisions at the linguistic and planning levels without having to know anything aboutthe knowledge or reasoning used by the linguistic component.
The planner can thenrespond to these interactions by choosing among the expressions proposed by the lin-guistic component, using the annotations to evaluate how particular linguistic choicesaffect the successful achievement of the goal(s) driving the generator.
This approachallows IGEN's components to interact while preserving the strict separation betweentheir knowledge and processing.The annotations are predicates that apply to the linguistic expression they areattached to, indicating some effect of or property of the expression.
Most of them alsotake an explicit argument indicating a semantic expression whose relation to the optionis indicated by the annotation.
The types of annotations used by IGEN are shown inFigure 1.
They fall into the following general categories: 6Meaning-based These relate the meaning of a linguistic option to the informa-tion it is supposed to express, both in terms of how explicitly and howcompletely the information is expressed.Contextual These indicate dependencies and effects on the presence and statusof elements in the discourse context, including not only availability foranaphoric reference but also effects on how various elements in the dis-course context will be perceived.Pragmatic These indicate various pragmatic and stylistic features of the op-tion.
76 There are also some annotation types used to keep track of IGEN's internal processing; these are notshown here.7 Note that IGEN currently only uses one annotation ofthis type: concise-construction, used to markconstructions that are particularly concise.112Rubinoff The IGEN GeneratorMeaning-based:makes-explicitmakes-implicitindirectly-suggestsmissing-infoextra-infoContextual:activates-in-contextfrom-contextrelates-toPragmatic:concise-constructiontonemarks-as-focusFigure 1Annotation types.The IGEN generator uses these annotations to allow for interactions between itsvarious components, hown in Figure 2.
IGEN works as follows: The communicativeplanner responds to goals given to the generator by building an appropriate plan,which will contain a number of communicative actions, i.e., actions that communi-cate information, and places requests for ways to express that information into theworkspace.
The linguistic component then responds by producing a series of anno-tated linguistic options for each of the planner's requests.
These are also placed inthe workspace, where the planner can use the annotations to evaluate and rank theoptions and also, when appropriate, to modify the plan based on what the linguisticcomponent is able to produce.This process doesn't actually produce any output, though, since there is no way todetermine when it is "finished."
The linguistic component can always come up withyet another way to express omething, and the planner can always do more reasoningabout he interactions between some expression and the planner's pecific and generalgoals.
There must therefore be another component, here called the utterer, that isresponsible for assembling utterances from the options preferred by the planner andshipping them off to be spoken or written.
The utterer's job is to balance the planner'spreferences against ime pressure, producing output when whatever deficiencies theoptions have are outweighed by the consequences of remaining silent.
The variouscomponents thus work together in parallel, incrementally building, improving, andproducing utterances.
Each component of the generator handles a particular aspect ofthe generation task, involving different kinds of knowledge and different constraintson the generator's work.IGEN in some ways resembles a blackboard architecture (Nii 1986b, 1986a); likea blackboard, its workspace contains everal possible utterances that are described atdifferent levels of structure and are built up incrementally by various independentcomponents.
On the other hand, it doesn't have the strict hierarchical structure thatusually characterizes blackboard systems; each request from the planner may corre-spond to several inguistic options, and the linguistic options may handle (parts of)more than one request.
Also, blackboard systems usually have sequential scheduling ofactions, whereas IGEN's planner, linguistic component, and utterer all run in parallel.Furthermore, the relevant issue here for IGEN is whether there are real interac-tions between the modules, which a blackboard-style approach to generation doesn't113Computational Linguistics Volume 26, Number 2GoalsN N Entries / / .~/ upt".
WorkspaceEvaluations -IUttererEvaluated Options)Assembled UtterancesFigure 2Architecture of the IGEN generator.guarantee.
Blackboard-based generation can still be structured in a way that makessuch interactions impossible, either explicitly, as in DIOGENES (Nirenburg et al 1988),which uses several blackboards successively, or implicitly, as in GLINDA, in whichsuccessive stages of rules depend on the results of previous tages for their triggers.
83.1 The Communicative PlannerThis is a special-purpose planner that accepts goals from the overall system and plansout ways to achieve them via communication.
These can be "communicative" goalssuch as "transmit this information to the user" (or more precisely "get the user to be-lieve this information"), but they can also be social interaction goals such as "establisha deferential (or collegial, or superior) attitude toward the user" or cooperative behav-ior goals such as "be straightforward" or "transmit as little information as possible"8 As can be seen from the diagram on page 24 of Kantrowitz and Bates (1992) and the accompanyingdiscussion.114Rubinoff The IGEN Generatoror even more general goals such as "get the user to take his umbrella" or "convincethe user to improve his diet.
"The communicative planner draws on a set of specialized plans that capture howcommunication acts can achieve various goals.
It draws on knowledge of the effectsof communication to plan out how to achieve various kinds of goals by expressingvarious kinds of information.
Since it has to evaluate how well particular linguisticexpressions further those goals, the planner needs to build an explicit representationof its plan(s) that indicates how particular actions contribute to their achievement.
Theplanner depends on the linguistic component to tell it how to carry out these actions,i.e., how to express particular information in language.While the planner is specialized for planning communicative actions, it can inprinciple draw on anything in the system's general body of knowledge and belief thatmight support the goals it is given.
Thus (as we shall see) in the second example inSection 4.3, the planner decides to mention the rain not because it bears any specialrelationship to anything in the input goal, but rather because mentioning it is part of aplan that achieves the goal.
Even in cases where the planner's goal is simply to transmitsome specific information, it can include any additional information that will help thattransmission to succeed.
The planner's role is not just to organize information, or evento collect information on some topic and organize it, but rather to identify a set ofcommunicative acts that will achieve some goal.3.1.1 Building an Initial Plan.
The communicative planner starts off by building aninitial plan to achieve the goals it is given.
The form of that plan is important.
It cannotbe just a (partially or totally) ordered set of information to go into the text, as is thecase in many generators.
Since IGEN's planner needs to evaluate how well linguisticoptions achieve the plan's goals, the plan must record what each piece of informationin the plan is intended to accomplish and how it supports the purpose of the largertext containing it.
Sometimes the planner's goal may simply be to convey certaininformation to the user, but there may also be more indirect goals that conveyanceis intended to achieve.
Thus the plan must indicate in detail why the information isbeing expressed.
An example of the type of plan the planner must build is shownin Figure 3 (Section 4.1 discusses the use of this plan in more detail).
This model oftext plans meshes well with the model of discourse structure developed by Grosz andSidner (Grosz and Sidner 1985, 1986), in which the purpose of each discourse segmentis an important part of the structure.
9IGEN constructs its plans using a hierarchical planning algorithm (Nilsson 1980).The planner first checks all of its top-level plans to see which have effects that matchthe goal.
Each matching plan's preconditions are checked; if they are currently (be-lieved to be) true, the planner then attempts to find all instantiations of the plan'sbody.
1?
The body of a plan can be an action or sequence of actions, a goal or sequence9 Moore and Paris also note that "a generation system must maintain the kinds of information outlinedby Grosz and Sidner" (Moore and Paris 1989, 203).
Their planner uses plan structures similar toIGEN's, except that the plan operators they use are generally instantiations of rhetorical relationsdrawn from Rhetorical Structure Theory (Mann and Thompson 1987).
In IGEN, the plans can involveany goals or actions that could be achieved via communication.Hovy has described another text planner that builds similar plans (Hovy 1988b).
This system,however, starts with a list of information to be expressed and merely arranges it into a coherentpattern; it is thus not a planner in the sense used here (as Hovy makes clear).10 Since text planning was not the primary focus of this work, IGEN is designed to simply assume thatany false preconditions are unattainable.
IGEN's planner divides the requirements of a plan into twoparts: the preconditions, which are not planned for, and those in the plan body, which are.
This has no115Computational Linguistics Volume 26, Number 2.2..4.N.Overall Goal: Know(Hearer,\[weather information over next few days\])Achieve (1) by achieving:Know(Hearer,\[first day's information\])Know(Hearer,\[second day's information\])Know(Hearer,\[last day's information\])Support (2) by performing: Utter(\[first day's information\])Support (2) by performing: Utter(\[second day's information\])Support (2) by performing: Utter(\[last day's information\])Figure 3A sample initial plan.of goals, a subplan, or a goal decomposition.
11 To instantiate the body, the planneraccordingly collects the action(s), recursively plans for the goal(s), instantiates thesubplan, or carries out the goal decomposition.
The net result of this process is a listof possible complete plans that achieve the original goal.3.1.2 Responding to Linguistic Options.
Once the communicative planner has builtup an initial plan of what it wants to say, it puts requests for the individual bits ofinformation contained in the plan into the workspace for the linguistic component torespond to.
The planner, however, cannot assume that its requests will be followedprecisely; the linguistic component may not be able to find a way of completely sat-isfying them.
The planner must therefore xamine and evaluate the responses thatthe linguistic component puts into the workspace (as described below in Section 3.2).These responses consist of linguistic structures together with the annotations that pro-vide descriptions of how closely the option carries out the request(s) it responds to, aswell as any other information or effects arising from the use of the option.
Drawingon these annotations, the planner evaluates how well the various options fit into theplan and assigns them appropriate ratings along a scale from VERY-HIGH to VERY-L0W.The evaluation algorithm is divided into two phases (as shown in Figure 4), whichwork roughly as follows: The first phase looks at how well the option matches therequest, checking first to see whether the option misses any requested information;if there is no missing information, the rating is based on annotations indicating therelationship between the option's meaning and the request.
The second phase thenadjusts the option's rating based on how any missing or added information interactswith the plan structure.
This ability to adjust preferences among linguistic optionsbased on planning issues allows IGEN to overcome the usual limitations of a modulargenerator design.
Without the annotations (or some similar feedback mechanism),the planner would have to supply the linguistic component with any informationthat might be relevant o choosing among the options.
This could potentially includepractical effects, ince the preconditions, byand large, are types of goals that IGEN doesn't have anyplans for; any attempt to plan for them would immediately fail.11 A goal decomposition s away to decompose a goal into subgoals that can be planned forindependently.
For example, the utter-sequence plan works by decomposing the information tobeuttered according tosome relevant ordering.116Rubinoff The IGEN GeneratorEVALUATE(Option, Request)Phase 1:1.
Let Covered-Pieces =UNION(Request, arguments of any COVERS-OTHER-ENTRY annotations).2.
If Option has a MISSING-INFO annotation whose argument isa member ofCovered-Pieces, or has more than one MISSING-INFO annotation, evaluation is: VERY-LOW.3.
Else if Option has any MISS ING- INFO annotations, evaluation is :LOW.4.
Else if Option has any INDIRECTLY-SUGGESTS annotations, evaluation is: MEDIUM.5.
Else if Option has any MA~S-IMPLICIT annotations, evaluation is : HIGH.6.
Else evaluation is :VERY-HIGH (because Option must have a MAKES-EXPLICITannotation).Phase 2:1.
Let Adjustment =0.2.
For each MISSING-INFO annotation attached to Option: Subtract 1/2 fromAdjustment if its argument isan item in the plan (1 if it's a critical item).3.
For eachACT IVATES- IN -CONTEXT or EXTRA- INFO annotation attached toOption:?
If its argument is a critical item in the plan, add I to Adjustment.?
Else if its argument supports or conflicts with a critical item in the planor strengthens or weakens a goal or precondition of the plan or the headof the request, add or subtract 1from Adjustment accordingly.?
Else if its argument is a sequence, Request is a member of anothersequence that is a critical item in the plan, and the two sequences arealong the same scale but are disjoint or only overlap slightly, subtract 1from Adjustment.
For example, the sequences \[1, 2, 3, 4\] and \[4, 5, 6, 7\]would trigger this adjustment, but the sequences \[1, 2, 3, 4\] and \[2, 3, 4, 5\]wouldn't.?
Else if its argument isan element in the plan, add 1/2 to Adjustment.4.
Adjust Option's Phase I evaluation up or down Adjustment levels (ignoring1/2s), e.g.
an Adjustment of -2 or - 21/2 would change :HIGH to : LOW, and addan ADJUSTED-UP  or ADJUSTED-DOWN annotation to Option as appropriate.Note: a "critical" item in a plan is one that plays a central role in the structure of theplan, e.g.
the basis of a goal decomposi t ion or an action, goal or plan sequence.Figure 4The linguistic option evaluation algorithm.anyth ing in the plan, so the linguistic component  wou ld  have to understand andreason about every aspect of the plan, defeating the whole purpose  of a modu lararchitecture.In addit ion to evaluat ing options, the planner looks for opportunit ies to revise theplan based on the work  of the linguistic component .
For example, the same linguisticstructure may appear  as an opt ion for several different parts of the plan, or an opt ionfor one part  of the plan may also express information contained in (or related to)117Computational Linguistics Volume 26, Number 2another part of the plan.
The planner can reorganize the plan to take advantage ofthese kinds of situations.
12Thus the communicative plan can be modified based onlinguistic information, again without violating the strict modularity of the generator.3.2 The Linguistic ComponentThe linguistic component is the part of IGEN that produces the actual bits of lan-guage that make up the utterance.
It acts like a "consultant" to the communicativeplanner, providing it with linguistic expressions that attempt o capture part or all ofthe information the planner wants to express.
13 The linguistic component monitors theworkspace, looking for requests from the planner, to which it responds by suggestinglinguistic expressions that capture some or all of the information in the request.
Theseexpressions are placed in the workspace as options for the planner to evaluate; thelinguistic component continues uggesting options for a request as long as that requestremains in the workspace.
14The linguistic options are pieces of surface structure; they can be at any level ofgrammatical structure and need only be partially specified.
Thus an option could be afull sentence, phrase, or word, or a particular clause structure (e.g., a topicalization oran/t-cleft) with no further detail filled in, or a noun phrase with a determiner but withthe head noun left unspecified.
The options are represented as feature sets indicatingthe various syntactic and lexical properties of the option.
15 For example, the followingfeature set represents the partial phrase "It will be ADJP" in which the predicateadjective has not yet been specified:CAT ~ SSUBJ .
.
.
.
#<w : IT> - ?
-LEX = #<w:BE>TENSE = FUTUREFRED ~ ADJPORDER z (SUBJ HEAD FRED)The FRED role in this phrase has not been filled yet, so its value is ADJF, indicatingthat it must be filled by an adjective phrase.The linguistic component is also responsible for annotating the options it puts intothe workspace.
The annotations are derived primarily from three sources: acomparisonof the structure and position of the option's meaning and the request in IGEN's seman-tic network, the induced perspective shift of the option's meaning, and special anno-tations associated irectly with the option.
16 The annotation algorithm works roughly12 Another possibility would be for the planner to revise the plan when it detects problems with theoptions.
For example, in a tutoring situation, if the linguistic component only returned options thatinvolve concepts the student doesn't yet understand or know about, the planner might decide to revisethe plan (perhaps to simplify what it's trying to say).
IGEN doesn't implement this kind of planrevision, although the annotations provide the planner with the information ecessary to do so.13 IGEN's design allows for multiple linguistic components, each providing a different kind of linguisticknowledge, although only one was actually used; see Rubinoff (1992) for details.14 As currently implemented, the linguistic omponent finds options by scanning through IGEN'ssemantic network, looking for items that are part of the meaning of some expression (Rubinoff 1992).The particular method used to produce the options, though, is incidental to the the overall functioningof the generator; it has no effect on the annotation or evaluation of the options, as the annotationsdepend only on the relationship between the option's meaning and the request.15 There is also a MAP feature used to connect unfilled syntactic arguments with the correspondingsemantic objects.16 The induced perspective shift of the option's meaning is computed using a model of perspective builtinto IGEN's knowledge representation formalism; see Rubinoff (1992) for details.118Rubinoff The IGEN Generatoras fol lows: First  the l inguist ic  component  adds  an annotat ion  that indicates the k ind  ofconnect ion (if any) between the opt ion 's  mean ing  and  the request;  this p roduces  ei thera MAKES-EXPLICIT, MAKES-IMPLICIT, INDIRECTLY-SUGGESTS, or MISSING-INFO annota-tion.
Next it adds EXTRA-INFO and MISSING-INFO annotations to indicate the differ-ences between (the meaning of) the option and the request, and COVERS-OTHER-ENTRYannotations for any other requests that are included in the option's meaning.
Finally, itadds ACTIVATES-IN-CONTEXT annotations to indicate any associated perspective shifts.For an example, consider the situation described in Section 2.1 where the generatoris trying to express the information that John shot and killed someone.
17 Among theannotated options produced to express #<SHOOT-AND-KILL (JOHN, BILL)> are:?
#<w:KILL>:(MAKES-EXPLICIT #<KILL (AGENTi, AGENT2) >)(MAKES-IMPLICIT #<SHOOT-AND-KILL(AGENTi, AGENT2) >)(MISSING-INFO #<INSTRUMENT(SHOOT-AND-KILL, GUN) >)?
#<w: SHOOT>:(MAKES-EXPLICIT #< SHOOT (AGENT1, AGENT2) >)(MAKES-IMPLICIT #<SHOOT-AND-KILL (AGENTI, AGENTg.)
>)(MISSING-INFO #<RESULT (SHOOT-AND-KILL, DEATH) >)In each of these cases, there is a MAKES-EXPLICIT annotat ion  for the mean ing  of theword ,  a MAKES-IMPLICIT annotat ion  for the requested in format ion,  and  a MISSINGINF0annotat ion  for the proper ty  of the request  hat is not  covered by  the opt ion.
(Of course,MAKES-EXPLICIT annotat ions  on the opt ions  that p roduce  with a gun and dead indicatehow the miss ing  in format ion  can be added to the utterance.
)The full annotat ion  a lgor i thm is as fol lows: 18ANNOTATE(Request ,  Opt ion)i,2.3.4.5.Construct a MAKES-EXPLICIT annotation for each node or link in Option'smeaning and collect them in Annotations.If Option's meaning contains Request and nothing else, return Annotations.If Request is an instance of an element in Option's meaning and they have thesame label, add a MAKES-EXPLICIT annotation for Request o Annotations.Else if Request is an instance, subconcept, or subrange of an element in Option'smeaning or a position within (or identical to) an element in Option's meaning,then add a MAKES-IMPLICIT annotation for Request, MISSING-INFO annotationsfor any links connected to Request that don't match links connected to theelement in Option's meaning, and EXTRA-INFO annotations for any linksconnected to the element in Option's meaning that don't match links connectedto Request.Else if an element in Option's meaning is an instance or subconcept of Request,add a MAKES-IMPLICIT annotation for Request and MISSING-INFO annotations asdescribed in step (4) to Annotations.17 While these annotations provide the necessary information for the planner to choose among theoptions as discussed in Section 2.1, IGEN's plan revision capabilities doesn't currently handle this case.As a result, IGEN currently produces either "John shot him dead" or "John killed him with a gun" forthis example.18 This description leaves out a few details; for example, in certain cases MISSING-INF0 annotations areonly generated for links considered "prominent" in the current perspective; see Rubinoff (1992) fordetails.119Computational Linguistics Volume 26, Number 26.7.8,9.10.11.12.Else if an element in Option's meaning is a "sibling" of Request (i.e., they areinstances or subconcepts of the same element) or an "uncle" of Request (i.e., thesibling of an element of which Request is an instance or subconcept), add aMAKES-IMPLICIT annotation for Request and MISSING-INFO and EXTRA-INFOannotations as described in step (4) to Annotations.Else if there is any other link between Request and an element in Option'smeaning, add an INDIRECTLY-SUGGESTS annotation for Request o Annotations.Else add a MISSING-INF0 annotation for Request to Annotations.If Option's meaning contains a node or link that is another part of the planner'srequest, then add a COVERS-0THER-ENTRY annotation for the workspace ntrycontaining the request to Annotations, and repeat steps (3) through (8) for thatrequest.Add ACTIVATES-IN-CONTEXT annotations for every element that would be shiftedinto perspective by an element in Option's meaning to Annotations.Add any special annotations associated with Option to Annotations.Return Annotations.3.3 The UttererThe utterer is responsible for the final assembly and output of the utterance.
Its mainconcern is balancing the desire for the most appropriate possible utterance againsttime pressure.
Since the planner and the linguistic component build up and refine theutterance incrementally, they can continue working indefinitely; there's never a pointwhere they can declare the utterance "finished" and quit working.
On the other hand,IGEN can't go too long without uttering something or it will lose its turn, becausethe user will either utter (i.e., type) something else or get tired of waiting and leave(or quit the program).
So the utterer must strike a balance between the advantageof improvements to the utterance that may yet be found and the disadvantage ofcontinued elay.The actual work of the utterer is fairly straightforward.
It constantly monitors theworkspace, checking the available options against a time-sensitive acceptability level.Whenever the best available utterance meets or exceeds the minimum acceptable eval-uation, the utterer proceeds to output the utterance.
The criterion of acceptability isdetermined via a set of delay thresholds that control how long to wait before low-ering the minimum acceptable rating.
For example, the default threshold settings are\[0,1,2,12,16\], meaning: if the time since the last utterance is more than 0, accept anoption rated VERY-HIGH or better; if the time since the last utterance is more than 1,accept an option rated HIGH or better; and so on through all the ratings.
19 If the timesince the last utterance is more than 16, then any option will be accepted; this essen-tially means that the generator would rather say something completely stupid thanremain silent.If any of the candidate utterances' evaluations meets or exceeds the current mini-mum acceptable rating, the utterer chooses the best candidate utterance and outputsit, removing the workspace ntries it derives from.
If there are two or more candidateutterances with the highest rating, the utterer breaks the tie by comparing the ratings19 IGEN measures time in terms of cycles through its process cheduler, an arbitrary but workableapproach that allows for consistent timing behavior.120Rubinoff lqle IGEN Generatorof the individual options they are composed of.
If there is still a tie, the utterer chooses,in order of preference, the candidate utterance that:.2..,5.violates fewer constraints.
2?was the only one whose rating was adjusted up by the planner, sincethis means there was something specific about the option that fit wellinto the plan.is more concise, indicated by the presence of a CONCISE-CONSTRUCTIONannotation.
21covers more entries in the workspace.covers an earlier entry in the workspace.If none of these criteria distinguish the candidate utterances, the utterer simply picksone at random.4.
ExamplesThe workings of the various components and representational machinery describedabove can be seen more clearly by looking at a few examples of IGEN at work.
Theseexamples demonstrate how IGEN can handle decisions that involve various kinds ofinteractions between linguistic and planning issues, despite the strict separation of theplanning and linguistic components of the generator.
In addition, the examples howhow IGEN is sensitive to time pressure, improving its output when given more timeto work and degrading racefully when forced to work faster.4.1 Supporting the Plan StructureIn this example, the generator is given the goal #<KNOW(HEARER,WEATHER-INFD)>,where #<WEATHER-INF0> is an unordered collection of facts about the weather overa three-day span starting on the current day.
The final output in response to this goalis:(4) It is warm on today.
It will be warm on Monday.
It will be cool onTuesday.Since the input goal simply involves transmitting a fixed set of information to thehearer, the construction of this response is fairly straightforward.
Nevertheless, evenin this simple example there are a few places where purely linguistic preferences areoverridden by the planner in order to support he text plan structure.4.1.1 Building the Initial Plan.
Upon being invoked, IGEN sends its goal to the com-municative planner, which constructs an initial plan.
The planner starts by applyingthe utter-sequence plan, which involves decomposing the goal based on a relevant se-quence.
Since the members of #<WEATI-IER-INF0~ all have connections to the sequenceof days in the month, the planner is able to decompose the original goal into a sequence20 The only possible constraint in the current implementation is a missing (obligatory) feature value; allother grammatical and conceptual constraints are strictly enforced.21 This is actually controlled by a parameter (*conciseness-preference*) that determines whether theutterer will prefer concise or verbose options or neither.
In theory, tlnis parameter should be set by theplanner based on its knowledge of the situation; in practice, it is set by hand to prefer concise options.121Computational Linguistics Volume 26, Number 2of goals based on the sequence of days involved in the goal.
Further p lanning for thesequence of subgoals yields the fol lowing plan:i.2..4.5.Overall  Goal: #<KNOW (HEARER, WEATHER-INF0) >Achieve (I) by sequencing information based on the #<SEQUENCE> of thethree days involvedSupport (2) with information about #<SEPT-25>Support (2) with information about #<SEPT-26>Support (2) with information about #<SEPT-27>Requests to express the informat ion about  each day 's  weather  are then passed on tothe linguistic component .In particular, the planner carries out step (4) of the plan by  placing in the workspacethe request:#<OVER-TIME-SPAN(#<WITHIN-RANGE(TEMPERATURE,56DEG-75DEG-F)>,SEPT-26)>A separate workspace entry is created for each node and link in this request, 22 withthe entry for the top-level #<0VER-TIME-SPAN> link marked  as their "head"  entry.4.1.2 Producing and Evaluating Linguistic Options.
The linguistic component  henbegins to produce and annotate linguistic opt ions for each of these entries.
It also runsthe first phase of the evaluat ion algor i thm (described in Figure 4) to produce an initialevaluation.
23For #<TEMPERATURE>, the linguistic component  finds the fo l lowing options: 24#<w : WEATHER>HEAD ~-~ CAT ~--- NLEX ~ #<w : WEATHER>The linguistic component draws on the portion of IGEN's knowledgeshown in Figure 5 to annotate this option.
Since the option directlyexpresses the concept #<WEATHER>, the linguistic component attaches aMAKES-EXPLICIT annotation to the option.
Since #<TEMPERATURE> has a#<PART> link connecting it to #<WEATHER>, it attaches anINDIRECTLY-SUGGESTS annotation for #<TEMPERATURE>.22 This doesn't limit the linguistic component toworking on only one node or link at a time; options cancover or depend on other entries, as, for example, the future tense option in Section 4.1.2.23 This should really be done by the planner, but the first phase doesn't actually depend on anyinformation about he plan, so it can safely be run by the linguistic component without compromisingthe separation of the components.
The second phase, which does depend on the plan, will be run bythe planner.24 It actually produces everal other options that are immediately ruled out as being completelyinappropriate, .g.
the word temperature as an option for #<SEPT-26>, or because they requirearguments hat aren't present in the request, e.g.
the verb be (which needs two arguments) as an optionfor #<TEMPERATURE>.
Throughout these examples, uch options will simply be ignored in the interestsof brevity.122Rubinoff The IGEN Generator=weather" ------?>( weather ~ =it":/d/ompart I / I part I / I part I I I I partwind ) ( precipitation=waiqrfl" - - - I~ :~ warmpart"temperature"ran0e-end CGFigure 5Some semantic network fragments used by the linguistic component.#<w: TEMPERATURE>HEAD ~ CAT ~--- NLEX z #<w : TEMPERATURE>Since the meaning of #<w : TEMPERATURE> is the request itself, the onlyannotation attached is a MAKES-EXPLICIT annotation for#<TEMPERATURE>.#<w: IT>LEX ----- #<w: IT>Since the usage of #<w: IT> here is an idiomatic construction, it hassome special handling in the lexicon to indicate that its meaningdepends on what it is being used to describe.
In particular, #<w: IT>here is taken to mean #<TEMPERATURE>.
The linguistic component thusproduces a MAKES-EXPLICIT annotation for #<TEMPERATURE>, as it doesfor the option using the word  #<w : TEMPERATURE>.
#<w: IT> is alsomarked as producing a CONCISE-CONSTRUCTION annotation, so thelinguistic component attaches one to the option.123Computational Linguistics Volume 26, Number 2As these options are produced, they are evaluated based on their annotations accord-ing to the algorithm described in Figure 4.
In the first phase, #<w : WEATHER> is ratedMEDIUM, reflecting the fact that the option doesn't really express the request, but doessuggest it indirectly by mentioning a closely related concept.
#<w : TEMPERATURE> israted VERY-HIGH, reflecting the option's exact match with the request, as is #<w: IT>,which also expresses #<TEMPERATURE> (albeit idiomatically).
The second phase ofthe evaluation algorithm makes no changes to the ratings, since the options' annota-tions don't indicate anything that would interact with the plan, leaving #<w: IT> and#<w : TEMPERATURE> as the preferred options.
25For #<WITHIN-RANGE>, the only acceptable option the linguistic omponent finds is:#<w:BE>CATHEADSUBJPREDORDER =---- S_-- \[ CAT ---- VL LEX = #<w:BE>---- NPz ADJP(SUBJ HEAD PRED)The SUBJ and PRED features indicate #<w:BE>'s syntactic roles; the value of thesefeatures indicates the syntactic onstraints on the structures that may fill the roles.In addition, the structure has a MAP feature indicating which workspace ntries canprovide options to fill the roles.Since #<WITHIN-RANGE> is a subconcept of #<BE-LOCATED> (one meaning of#<w:BE> in IGEN's lexicon), the linguistic component produces (MAKES-EXPLICIT#<BE-LOCATED>) and (MAKES-IMPLICIT #<WITHIN-RANGE>) annotations for the op-tion.
These annotations lead the first phase of the evaluation algorithm to rate theoption as HIGH; the second phase leaves this evaluation unadjusted.
(Of course, sincethere is only one acceptable option here, its rating doesn't really matter.
)For #<56DEG-Z5DEG-F>, the options produced are (omitting the details of thestructures to show only the annotations):#<w:WARM>:(MAKES-EXPLICIT #<WARM>)(MAKES-IMPLICIT #<56DEG-75DEG-F>)#<w:TEMPERATURE>:(MAKES-EXPLICIT #<TEMPERATURE>)(INDIRECTLY-SUGGESTS #<56DEG-75DEG-F>)These annotations are based on the network fragment shown in Figure 5.
#<w:WARM>is rated HIGH, because it does a reasonable job of describing the requested temperaturerange} 6 The #<w : TEMPERATURE> option is not as good, but it at least gives a sense ofwhat is being talked about, so it gets the next lower rating of MEDIUM.The entries we have seen so far have not involved any interactions between the25 Re  ut terer  wi l l  u l t imate ly  choose  #<w:  IT> because  it is marked  as more  concise.26 \ ] 'h is  is determined us ing  a ru le -based  in ference mechan ism descr ibed  in Rub ino f f  (1992).124Rubinoff The IGEN Generatoroptions and the plan.
Our first instance of such interactions arises in the options for# < 0VER-TIME-SPAN>:?
#<w:  0VER>:(MAKES-EXPLICIT #<0VER-TIME-SPAN>)(ACTIVATES-IN-CONTEXT#< INSTANCE (SEPT-26, LINEAR-SPAN) >)?
#<w:0N>:(MAKES-EXPLICIT #<0N>)(MAKES-IMPLICIT #<0VER-TIME-SPAN>)(ACTIVATES-IN-CONTEXT#< INSTANCE (SEPT-26, LINEAR-POS) >)?
\[TENSE : FUTURE\]: 27(MAKES-EXPLICIT #<0VER-TIME-SPAN>)(MAKES-EXPLICIT #<FUTURE>)(COVERS-0THER-ENTRY entry for:#<SEPT-26>)(MAKES-IMPLICIT #<SEPT-26>)The first phase evaluations uggest hat #<w: OVER> is the preferred option.
Here,though, the second phase of the evaluation algorithm modifies the ratings based oninteractions with the plan.
The ACTIVATES-IN-CONTEXT annotations for #<w:0VER>and #<w:0N> indicate that these options affect how the system (and the hearer)perceive the time span being talked about.
Since the #<SEQUENCE> of days beingtalked about is the organizing principle of the plan, it is a "critical" piece of theplan, as are the #<MEMBER> links connecting it to the pieces of the original goal.
TheACTIVATES-IN-CONTEXT annotation for #<w:0VER> indicates that it encourages thehearer to think of #<SEPT-26> as a #<LINEAR-SPAN>.
This conflicts with the (critical)#<MEMBER> link between #<SEPT-26> and the #<SEQUENCE>, because it describes theday as a span of time rather than as a discrete point in a sequence.
The second phasealgorithm thus downgrades #<w:0VER>'s rating from VERY-HIGH to HIGH.
Conversely,#<w:0N> encourages the hearer to think of #<SEPT-26> as a #<LINEAR-POS>, i.e.,a discrete position within a linear span, supporting the critical #<MEMBER> link.
\]"herating for #<w: ON> is therefore upgraded from HIGH to VERY-HIGH, and it becomes thepreferred option.
28Note here how the use of annotations allows the planner to remain ignorant ofpurely linguistic issues.
The planner has no way  to distinguish between an optionrealizing #<0VER-TIME-SPAN> as a lexical item and one realizing it as the value ofsome feature of another option.
Its decision is based solely on the contextual effectsof the available options.
The planner can only make distinctions based on the effectsof the options, not on the forms of the options.The final piece of the request is #<SEPT-26>, for which the linguistic componentproduces the following options:?
#<w :TOMORROW>:(MAKES-EXPLICIT #<TOMORROW>)27 This is an example of how linguistic options need not be single words or complete phrases; this optionis a feature value pair that will be added to another phrase.28 #<w:0N> ispreferred over \[TENSE =FUTURE\], which is also rated VERY-HIGH, because itwas adjustedup in response to a specific plan interaction as discussed in Section 3.3.125Computational Linguistics Volume 26, Number 2(MAKES-IMPLICIT #<SEPT-26>)(ACTIVATES-IN-CONTEXT #<FEW-DAYS>)#<w:MONDAY>:(MAKES-EXPLICIT #<MONDAY>)(MAKES-IMPLICIT #<SEPT-26>)(ACTIVATES-IN-CONTEXT #<WEEK>)The first phase of the evaluation algorithm rates both of these options as HIGH, sincethey match the planner's request equally well.
The second phase, though, distinguishesbetween them on the basis of the particular time sequences they activate.
The se-quence #<WEEK> activated by the option #<w :MONDAY> is significantly different fromthe #<SEQUENCE> of three days around which the plan is organized, so #<w :MONDAY>is downgraded to #<MEDIUM>.
The #<FEW-DAYS> sequence activated by the option#<w : TOMORROW>, on the other hand, largely overlaps with the plan's #<SEQUENCE>,so no adjustment is made.
As a result, #<w:TOMORR0W> becomes the preferred option.4.1.3 Assembling the Utterance.
As these options are produced and evaluated, theutterer watches the workspace, trying to assemble them into an acceptable utterance.Whenever an option appears that meets the current acceptability threshold, the uttererutters (i.e., prints) it.
The final result is:(5) It will be warm on Monday.Note that this output does not simply use the highest-rated option from each entry inthe workspace, because that would involve the ungrammatical phrase on tomorrow.
Inaddition to responding to time pressure, the utterer also enforces yntactic onstraints;it chooses the best possible combination of options that is syntactically acceptable.
294.1.4 Summary.
This simple example illustrates how the annotations allow IGEN tomaintain the traditional division into two independent components while still han-dling interactions between decisions at the planning and linguistic levels.
The plannernever has to deal with linguistic structures, and the linguistic component never has todeal with plans or information structures.
For example, the planner can't distinguishbetween lexical items and feature values; conversely the linguistic component has noaccess to the goals driving the planner or the plans it builds.
Nevertheless, when thereare decisions that depend on both informational and linguistic structures, the annota-tions allow IGEN to handle the interactions between the different levels.
The effects ofthese interactions are relatively minor in this example, but subsequent examples willshow how they can be more dramatic.4.2 Revising the PlanIn addition to merely selecting among options, IGEN's planner can revise the plan inresponse to them.
Consider a slight modification to the previous example, in whichIGEN is given the same goal except hat the temperature on the third day falls within29 This is an oversimplification, as can be seen from the output in (4) in Section 4.1, where IGENproduces the phrase on today.
What's really going on is that IGEN's lexicon has two entries for each oftoday and tomorrow; one as a noun phrase and one as a prepositional phrase.
As it happens, the PPentry turns up first.
In the case here, the option for Monday is produced and selected before the NPoption for tomorrow turns up.
In the first sentence of(4), there is no such option, so the linguisticcomponent has time to produce the NP today option.126Rubinoff The IGEN Generatorthe range considered "warm."
IGEN proceeds to build a plan that is identical to theprevious one (except for the difference in the information to be expressed).
As before,the planner places requests in the workspace and the linguistic component starts toconstruct options.
At this point, IGEN is well on its way to generating text similarto (4):(6) It is warm on today.
It will be warm on Monday.
It will be warm onTuesday.However, once the option for warm is produced, something new happens.
Theplanner detects that there are several parallel structures in the workspace that can usethe same linguistic structure (warm) to realize different concepts (the different tem-perature ranges) in corresponding positions within each structure.
This provides theopportunity to combine the parallel structures into a single conjoined structure, whichthe planner proceeds to do.
All of the workspace ntries for the parallel structures areremoved, and the planner enters requests for a new conjoined structure: 3?#< 0VER-TIME-SPAN (#<WITHIN-RANGE (TEMPERATURE , 56DEG-75DEG-F) >,#<AND (SEPT-25 , SEPT-26 , SEPT-27) >) >IGEN then proceeds as in the previous example, ult imately generating:(7) It will be warm on today, Monday, and Tuesday.Note that the planner couldn't have created this conjoined structure initially be-cause it d idn't  know that all three days'  temperatures could be realized the same way.To the planner, each day has a different temperature range.
This example appearsexactly the same as the previous one.
Once the linguistic component indicates thatall three temperature ranges can be realized the same way, though, the planner canthen determine that this results in a parallelism that can be reduced to a conjoinedstructure.
The annotations allow the planner to modify its plan, based on the results ofthe realization process, despite not having any access to purely linguistic knowledgeor processing.4.3 Varying the Utterance in Response to the PlanIn the previous examples, we have seen how IGEN can use the feedback from thelinguistic component to improve the organization of the text it generates.
The anno-tations also allow IGEN to tailor the generated text so as to better achieve the goalsbehind the utterance.
Consider IGEN's response to the goal "make the user happy":  311.2.Overall goal: #<BE-STATE (HEARER, HAPPY) >Achieve (1) by achieving subgoals:(a) Goal: Downplay unpleasant information30 The temperature ange used in the conjoined structure is chosen randomly from among the structuresbeing combined.
This is safe to do because it is certain that all of the temperature anges can berealized the same way; that's what triggered the combination i the first place.31 The construction of the plans in this section is admittedly ad hoc; IGEN certainly doesn't have acomplete model of the psychological factors and issues they involve.
What's important here, though, isnot the construction ofthe plan but rather how the plan and the annotations are used to produce thekind of subtle effects that can't be produced by the linguistic omponent or the planner alone.127Computational Linguistics Volume 26, Number 2..5.
(b) Goal: Emphasize pleasant informationAchieve (2a) by expressing:#<MINIMAL-SIGNIFICANCE (# < CONSIST-0F (PRECIPITATION,RAIN) >) >Achieve (2b) by expressing:#<WITHIN-RANGE (TEMPERATURE, 60DEG-80DEG-F) >Achieve (2b) by expressing:#<AT-TIME (#<CONSIST-0F (PRECIPITATION, N0-PRECIPITATION) >,THIS-AFTERN00N) >The final result for this plan is:(8) It is only drizzling.
It is warm.
It will be clear soon.Most of this output is produced straightforwardly in a manner similar to the previousexample.
Some of the choices, however, are the result of interactions of a sort beyondwhat was seen there.Consider the options for #<CONSIST-0F (PRECIPITATION,RAIN) > in step (3) of theplan; these include: 32?
#<w:RAINS>: VERY-HIGH(MAKES-EXPLICIT #<CONSIST-0F>)(MAKES-EXPLICIT #<PRECIPITATION>)(MAKES-EXPLICIT #<RAIN>)?
#<w:DRIZZLES>: HIGH(MAKES-EXPLICIT #<C0NSIST-0F>)(MAKES-EXPLICIT #<PRECIPITATION>)(MAKES-IMPLICIT #<RAIN>)(MAKES-EXPLICIT #<DRIZZLE>)(EXTRA-INF0 #<STRENGTH(RAIN,WEAK)>)?
#<w:POURS>:HIGH(MAKES-EXPLICIT #<C0NSIST-0F>)(MAKES-EXPLICIT #<PRECIPITATION>)(MAKES-IMPLICIT #<RAIN>)(MAKES-EXPLICIT #<POUR>)(EXTRA-INFO #<STRENGTH(RAIN,STRONG)>)The first phase of the evaluation algorithm rates the word #<w:RAINS> highest, sinceit captures the intended meaning precisely.
#<w: DRIZZLES> and #<w: POURS> are thenext best options, since they capture the basic meaning, and are equally appropriate,since the linguistic component can't evaluate the significance of the extra informationthey present.The second phase, however, determines that the EXTRA-INF0 expressed by theoption #<w:DRIZZLES> implies another part of the information requested by theplanner (the #<MINIMAL-SIGNIFICANCE> relation).
Its rating is therefore increasedto VERY-HIGH.
Conversely, the rating for #<w:POURS> is lowered to MEDIUM, since it32 To simplify the discussion, I have included the first-phase evaluations of the options here.128Rubinoff The IGEN Generatorcontradicts the #<MINIMAL-SIGNIFICANCE> relation.
This leaves both other options,#<w:RAINS> and #<w:DRIZZLES>, rated VERY-HIGH; the utterer will prefer to use#<w:DRIZZLES>, though, since there was something specific about the option that theplanner approved of.The decision here to say #<w : DRIZZLES> instead of #<w:RAINS> could not havebeen made by either the planner of the linguistic component alone.
The decision de-pends on both the planner's knowledge that the concept #<DRIZZLE> supports an-other piece of the plan and the linguistic component's knowledge that there is a wayto express #<DRIZZLE> without making explicit its distortion of the actual informationthat it's raining.
It's only the interaction between the two components provided bythe annotations that makes saying #<w : DRIZZLES> instead of #<w:RAINS> possible.The point of using the annotations, though, was not just to handle these kindsof interactions, but more importantly to do so without compromising the principledseparation of the two components.
Among other things, this makes it possible for IGENto express the same information in a different manner, based solely on differences inthe plan.
If the purely linguistic issues are the same, the linguistic component will doexactly the same work, even though the differences in the output may depend in parton that work.We can see this by comparing the previous example with IGEN's response tothe goal #<TAKE(HEARER, UMBRELLA)>, for which the planner constructs the followingplan:i.2...Goal: #<TAKE(HEARER,UMBRELLA) >Achieve (I) by achieving subgoal:#<WANT (HEARER, #<TAKE (HEARER, UMBRELLA) > ) >Achieve (2) by achieving subgoal:#<KNOW (HEARER, #<CONSIST-0F (PRECIPITATION, RAIN) >) >depending on the preconditions:#<DANGEROUS (#<C0NSIST-0F (PRECIPITATION, RAIN) > ) >and# < PROTECTI ON (# < TAKE ( HEARER, UMBRELLA) >,#<CONSIST-0F (PRECIPITATION, RAIN) >) >Achieve (3) by expressing:#<CONSIST-0F (PRECIPITATION, RAIN) >Note that the information to be expressed here in step (4) is also expressed in step (3) ofthe previous example.
Since the linguistic component doesn't have access to the plan,it necessarily produces the same options as before.
The planner, though, evaluatesthese options differently, since it is using them to carry out a different plan.The three options #<w: RAINS>, #<w: POURS>, and #<w: DRIZZLES> are producedand annotated as before.
Their evaluations are different, though.
Step (3) here hasa precondition that #<CONSIST-0F(PRECIPITATION,RAIN) > be #<DANGEROUS> in or-der to achieve its intended goal.
The extra information expressed by #<w:POURS>supports this precondition, so #<w:POURS> is upgraded to VERY-HIGH.
On  the otherhand, #<w:DRIZZLES> undercuts the precondition and is therefore downgraded toMEDIUM.
The preferred option here is therefore #<w:POURS>, in contrast to the previ-ous example, and the final result is then:(9) It is pouring.129Computational Linguistics Volume 26, Number 2The final output differs even though the linguistic component does exactly thesame processing in these two examples.
From the linguistic component's point of view,the examples are exactly the same; the same request is placed in the workspace, so thesame options are produced.
The difference lies solely in the plan structure, not in thecontent of the explicit message to be realized, so only the planner behaves differently.The linguistic component's design and functioning are completely indifferent o theissues that concern the planner.4.4 The Range of VariationWe can see similar variation in the handling of #<N0-PRECIPITATION>, which is real-ized in three different ways in three different examples because of the different rolesit plays in the three plans.
In Section 4.3, it was realized as clear; the two examplesthat follow illustrate how IGEN can select alternative realizations.Consider first what happens when the generator is given the goal "get the user toconserve water."
In response, it builds up a plan to do so by talking about he drought:I.2..4.Goal: #<CONSERVE(HEARER,WATER) >Achieve (1) by achieving subgoah# <WANT (HEARER, # <CONSERVE (HEARER, WATER) >) >Achieve (2) by achieving subgoah# < KNOW (HEARER, # < SERI 0US-DROUGHT > ) >depending on the preconditions:#<DANGEROUS(#<SERIOUS-DROUGHT>)  and#<PROTECTION (#< CONSERVE (HEARER, WATER) >,#<SERIOUS-DROUGHT>) >Achieve (3) by expressing:#<CONTINUE (DROUGHT) >#<OVER-TIME-SPAN (CONSIST-0F (PRECIPITATION,N0-PRECIPITATION) ) ,TODAY) >and#<0VER-TIME-SPAN (REPEAT (CONSIST-OF (PRECIPITATION,N0-PRECIPITATION) ) ,TOMORROW) >This plan is similar to the one built in Section 4.3 for the goal #<TAKE(HEARER,UM-BRELLA) >; they both involve motivating the hearer to take some action by explainingsome danger that the action will provide protection from.
The main difference hereis that rather than simply telling the user that there is a serious drought, the plan-ner draws on a more specific (ad hoc) plan that involves expressing more detailedinformation.The final result for this example is:(10) The drought is continuing.
It is dry today.
It will be dry again tomorrow.Note that IGEN uses #<w:DRY> here to express #<N0-PRECIPITATION>, in con-trast with the first example in Section 4.3, where it was expressed by #<w : CLEAR>.This happens because #<w: DRY> has an (ACTIVATES-IN-CONTEXT #<DROUGHT>) anno-tation, and activating the concept #<DROUGHT> supports the sense of danger that is aprecondition of step (3) of the plan.
#<w:DRY>'s evaluation is thus upgraded, making130Rubinoff The IGEN Generatorit the preferred option.
In the example in Section 4.3, this activation doesn't interactwith the plan, so #<w:CLEAR> remains the preferred option.Yet another ealization is selected when IGEN is given the goal of convincing theuser to go to the park, resulting in the following plan:I.2...Goal: #<BE-LOCATED(HEARER,PARK) >Achieve (1) by achieving subgoal:#<WANT (HEARER, #<BE-LOCATED (HEARER, PARK) >) >Achieve (2) by achieving subgoal:#<KNOW (HEARER,AND (CONSIST-0F (PRECIPITATION, N0-PRECIPITATION) )WITHIN-RANGE (TEMPERATURE, WARM) ) >depending on the preconditions:#<ENJOYABLE (#<BE-LOCATED (HEARER, PARK) >) >and#<SUITABLE (#<AND (CONSIST-0F (PRECIPITATION, N0-PRECIPITATION) ,WITHIN-RANGE (TEMPERATURE, WARM) ) >,#<BE-LOCATED (HEARER, PARK) >) >Achieve (3) by expressing:#<AND (CONSIST-0F (PRECIPITATION, N0-PRECIPITATION) ,WITHIN-RANGE (TEMPERATURE, WARM) ) >The resulting output is:(11) It is sunny and it is warm.The only difference from previous examples lies in the choice of #<w: SUNNY>to express the concept #<N0-PRECIPITATION> rather than using either #<w:CLEAR>or #<w:DRY>.
This choice arises because of an ACTIVATES-IN-CONTEXT annotationindicating that the use of #<w:SUNNY> activates the concept #<SUNSHINE>, whichstrengthens the enjoyability precondition i step (3) of the plan.
It is this sort of inter-action between linguistic choices and the plan structure that allows IGEN to express#<N0-PRECIPITATION> three different ways in three different examples.The point here is not just that IGEN can produce different lexical realizations fora particular concept.
If that were the only goal, we could dispense with the feedbackmechanism and simply design some sort of discrimination network (or similar device)to test various features of the information being expressed.
The planner could supplywhatever information is needed to drive the network.
33 Something like this approachis in fact used in some systems (e.g., Elhadad and Robin 1992; PenMan 1989; Hovy1988a).The problem with the discrimination network approach is that it can't handlethe range of examples hown here without violating the modularity of the generator.The examples hown here have involved linguistic choices that depend on the planstructure, on other actions in the plan, and on preconditions of the plan.
Furthermore,the plan dependencies can involve a nontrivial amount of reasoning (e.g., the exampleimmediately above, which involves the connection between sunshine and enjoying33 Of course, that still wouldn't allow for examples like the one in Section 4.2, where the planner modifiesthe plan in response tothe work of the linguistic component.131Computational Linguistics Volume 26, Number 2being outdoors).
Encoding these decisions in a discrimination net (or any other kindof processing) within the linguistic component would mean giving that componentaccess to all of the plan and the reasoning used to construct i .
Much of the planner'sknowledge and processing would have to be duplicated in the linguistic omponent.IGEN, in contrast, handles these examples while maintaining strict modularity.4.5 The Effects of Time PressureThe discussion of the examples in Section 4.3 glosses over an important detail: IGENwill only generate the output shown there if the time pressure iseased by increasing thedelay thresholds.
In particular, the choice of #<w :DRIZZLES> and #<w: POURS> over#<w:RAINS> in those examples is made with the thresholds et to force the uttererto always wait at least five time units before uttering the next piece of text.
Thisis necessary because the linguistic component produces the option for #<w:RAINS>sooner than the options for #<w: POURS> and #<w :DRIZZLES>.If the delay thresholds are left at the default settings, the utterer will accept anoption that is rated VERY-HIGH without any delay.
Thus when the #<w:RAINS> op-tion appears, the utterer immediately accepts and utters it.
While # <w:DRTZZLES > and#<w: POURS > would be better options in these examples, the utterer never gets a chanceto see them.
Because of time pressure, the decision of how to realize the planner's re-quest is made before the linguistic component has a chance to find #<w : DRIZZLES>.There's nothing wrong with this result; it is raining is a perfectly good way to ex-press #<CONSIST-0F(PRECIPITATION,RAIN)>.
It's just that if IGEN is given moretime to work, it can produce a better utterance.
The utterer's job is to balance thequality of the utterance against ime pressure; in this example, changing the inten-sity of the time pressure induces a corresponding change in the refinement of theutterance.Of course, if the time pressure is set sufficiently high (e.g., to simulate a situationwhere the the hearer is about to walk away), IGEN will sometimes produce an utter-ance that has some slight problems, because speed is more important than perfection.Consider what happens when the example in Section 4.1 is run with the delay thresh-olds set to accept anything that's not terrible (i.e., any option rated MEDIUM or higher)right away.
The planning and initial production and evaluation of options proceedsas with the default hresholds.
The handling of #<0VER-TIME-SPAN> works out dif-ferently, though.
The option for #<w:0VER> is produced by the linguistic omponentseveral time units before the option for #<w:0N>.
With the default hresholds, that'snot a problem, because the utterer can wait long enough for #<w: 0N> to be produced.With the increased time pressure, though, the utterer is forced to produce the utterancebefore the option #<w:0N> is available.
The resulting utterance (for the second day'sinformation) is it will be warm over Monday.This result is not awful; the sentence still manages to express the intended infor-mation.
It just doesn't fit quite as well into the intended overall structure of the text.So the main consequence here of increasing the time pressure is to generate a textthat is slightly less coherent and fluent.
In this case, IGEN responds to increasing timepressure with a slight degradation i the generated text.4.6 The Effects of Vocabulary LimitationsSince IGEN is designed to always find the best utterance possible in the available time,without assuming any notion of a "correct" utterance, it can produce reasonable outputeven when generating in domains where it has limited linguistic resources.
This canbe seen by looking at the result of selectively disabling elements of its "vocabulary,"i.e., the lexical and syntactic resources available to the linguistic omponent.
The result132Rubinoff The IGEN Generatoris a gradual, graceful degradation of the generated text as the generator's linguisticresources become poorer.Consider again IGEN's response (under relatively mild time pressure) when giventhe goal #<TAKE(HEARER,UMBRELLA)>.
The resulting plan, as we have seen, requiresexpressing the information #<CONSIST-0F (PRECIPITATION,RAIN) >, which is accom-plished by uttering it is pouring.
If the verb #<w: POUR> is removed from the generator'svocabulary, though, this utterance is not possible; instead the output becomes it is rain-ing.
Note that this is the same output IGEN produces if the time pressure is increased;the consequence of limiting either time or vocabulary is the same.If the verbs #<w:RAINS> and #<w:DRIZZLES> are removed as well, the generatoris left with no single option that can express all of the requested information.
Instead,the utterer esorts to assembling individual options for the various pieces of the re-quest, producing the sentence the precipitation consists of rain.
34 While this utterance doesadequately express the requested information, it is fairly awkward.
Still, it's not bad,given that the two best options are unavailable.Beyond this point, further vocabulary removal starts to make things much worse.Removing the phrase #<w: CONSIST OF> leads to the utterance of it will be clear.
Thisutterance is terrible; it completely misses the intended information.
That's not surpris-ing; after all, the options that should be used have all been removed from IGEN'svocabulary.
On the other hand, it's not completely bizarre; it's still talking about theweather, and in fact it's even still describing the precipitation.
That is, IGEN still hasa vague sense of what it's trying to say; it's not simply producing an utterance at ran-dom.
This can be seen again by removing the phrase #<w: BE CLEAR>; the resultingutterance is then it snowed.
IGEN is still trying to get as close as it can to the intendedinformation, even though it can't really get it right.Eventually, of course, removing linguistic resources will make the generator col-lapse; if every word or phrase relating to precipitation of any sort is removed, thenIGEN produces it is medium, which, though grammatical, is gibberish.
If the linguisticcomponent has absolutely no way to produce options related to what the plannerwants to express, then there's really nothing IGEN can do.
What's significant here,though, is that as the generator's linguistic resources are gradually impoverished, thegenerator's output degrades gracefully.
Rather than immediately collapse when itspreferred options are removed, IGEN continues to produce the best possible utteranceit can build with its remaining linguistic resources.
3s4.7 Generating in a Different LanguageAs a test of IGEN's modularity, a simple French linguistic component was developedand tested on the examples in Sections 4.1 and 4.3.
Switching to a different languageprovides an extreme xample of how the linguistic component can be varied withoutaffecting the planner.
The change primarily involved defining new lexicon entries forthe French words, phrases, and feature values needed to talk about the weather.
Inaddition, the routine that handles verb inflection had to be replaced, since French verbendings are different from English ones.
Other than these changes, though, no mod-34 The actual output is precipitation consists of rain, but this is just due to a limitation of the implementedgrammar.
Specifically, there's no requirement that noun phrases have determiners, o the linguisticcomponent never bothers to suggest one for the NP headed by #<w:PRECIPITATIOR>.35 Of course, in many situations it's best to put a lower bound on the quality of IGEN's output; this canbe done simply by setting the appropriate delay thresholds to infinity.
It would also be possible to setan overall time limit on IGEN's processing, after which an uncompleted plan would be assumed tohave failed.
IGEN could then modify the plan or take other appropriate corrective action.133Computational Linguistics Volume 26, Number 2ification to IGEN was necessary.
The linguistic component was otherwise unaltered,and the planner and utterer equired no changes at all.
36The main difference between the ways English and French describe the weatherlies in the "weather it" construction.
English allows weather descriptions that useit together with any of a class of verbs of being, seeming, or becoming.
Thus thefollowing sentences are all possible in English:(12) It is warm.
(13) It seems warm.
(14) It feels warm.
(15) It's becoming warm.
(16) It's getting warm.In these sentences, the meaning of it seems to be the weather or the temperature;thus in any of these sentences it could be replaced by the weather or the temperaturewithout changing the meaning or acceptability.
This phenomenon is modeled in IGENby having a special word #<w:IT> whose meaning can range over the various itemsconstituting the weather; this word is constrained to appear only as the subject of anappropriate verb.
Thus, as we saw in Section 4.1, #<w: IT> is represented as meaning#<TEMPERATURE> and annotated appropriately.A literal translation of any of the sentences in (12) to (16) into French, though,would be ungrammatical.
The corresponding French construction uses the verb faire(literally 'to make' or 'to do'), as in (17):(17)(18)(19)(20)(21)I1 fait chaud.It makes/does warmIt is warm.
*Le temps fait chaud.The weather makes/does warmThe weather is warm.
*La temp4rature fait chaud.The temperature makes/does warmThe temperature is warm.
*I1 semble chaud.It seems warm.I1 semble faire chaud.It seems to make/do  warm.It seems warm.Unlike it in (12) to (16), the il here is not referring to the weather or the temperature.Rather it is an expletive, i.e., a dummy subject required by the grammar of the lan-guage, similar to the it in the English it seems John left.
This can be seen by comparison36 It was necessary toadd a few more elements o the semantic network (which is used by bothcomponents) o capture the meaning of the French word sur, which does not correspond exactly to themeaning of any English word, as discussed below.
These new elements were used only by thelinguistic omponent, not by the planner.134Rubinoff The IGEN Generatorwith (18) and (19), in which replacing il with le temps ("the weather") or la temperature("the temperature") leads to an ungrammatical sentence.
(20) and (21) demonstratethat the crucial element in the French construction is the verb faire; other verbs canbe used only if they combine with faire.
This contrasts with the English construction,in which it is the crucial element and can be used with a range of verbs.
The Frenchconstruction is thus represented in IGEN as a version of the verb faire that takes anexpletive il as its subject and whose meaning ranges over specifications of the variouselements of the weather.A second difference between the two languages hows up in Section 4.1 in theoptions for #<0VER-TIME-SPAN>.
In English, IGEN has to choose between using onor over to express this link.
In French, though, these concepts are expressed by thesame word (sur).
37 Furthermore, sur can't be used for temporal expressions, only forspatial expressions.
So the options for #<0VER-TIME-SPAN> work out quite differ-ently in French.
French in general uses ~ ("at") rather than sur for temporal expres-sions; however ~ cannot be used with expressions describing days.
Instead, thesetemporal modifiers are expressed using bare NP's with no preposition.
This con-struction is modeled in IGEN by a null preposition whose object must be a definiteNP.Given all of this, IGEN produces the following results in French for the examplein Section 4.1:(22) I1 fait chaud aujourd'hui.
I1 fera chaud lundi.it does warm today it will do warm MondayIt is warm today.
It will be warm Monday.I1 fera frais mardi.it will do cool TuesdayIt will be cool Tuesday.This is equivalent to the English result except for expressing the temporal modifieras a noun phrase rather than as a prepositional phrase headed by on, as discussedabove.Similarly, the variant in Section 4.2 produces:(23) I1 fera chaud aujourd'hui lundi et mardi.it will do warm today Monday and TuesdayIt will be warm today Monday and Tuesday.For the goal of making the user happy, IGEN produces the French output:(24) I1 bruine seulement.
I1 fait chaud.
Le temps sera clair bientdt.it drizzles only it does warm the weather will be clear soonIt's only drizzling.
It's warm.
It will be clear soon.This is exactly the same as the English output except for the use of the French "weatherfaire" construction or the explicit use of le temps ("the weather')  rather than the English"weather it" construction.37 Note that the point here is not that sur is the (unique) translation of on and over into French; IGEN isdoing generation, not machine translation.
It's just that sur is the French word that most naturallyexpresses the particular concepts IGEN is using.135Computational Linguistics Volume 26, Number 2The goal of convincing the user to take his umbrella, though, produces the output:(25) I1 pleut.it rainsIt's raining.because French doesn't have a verb corresponding to to pour.
Since no option equiva-lent to the one for #<w: POURS> is proposed, the option for #<w: PLEUT> is the preferredoption, just as #<w:RAINS> is the preferred option in English when lack of time ordeliberate removal prevents the linguistic component from finding #<w : POUR$>.The point here is not simply that IGEN can handle these changes; after all, one ofthe primary motivations for dividing the generator into separate planning and linguis-tic components i to allow the components to be modified independently.
The pointis that IGEN allows the linguistic component to be modified so dramatically withoutlimiting its ability to handle interactions between linguistic and planning issues.
Infact, IGEN can handle these interactions equally with either version of the linguisticcomponent without having to make any corresponding changes to the planner.5.
SummaryIGEN is designed to overcome the limitations, while retaining the advantages, of themodular approach to natural anguage generation.
It does this by means of annota-tions that provide the planner with an abstract description of the effects of particularlinguistic choices, allowing IGEN to handle interactions between the planning andlinguistic levels while retaining the complete independence of the components.
ThusIGEN can vary the work done by each component independently, even in cases wherethe final output depends on interactions between them.As the examples in Section 4 show, IGEN can vary how it expresses informationin response to the differing roles that the information plays in the plan and, con-versely, in response to a change in the language being used.
It can also revise itsinitial communicative plan based on the options suggested by the linguistic compo-nent.
Furthermore, this variation requires no weakening of the generator's modularity.Changes in the plan structure are invisible to the linguistic component, and the changein languages i invisible to the planner.
In addition, since IGEN explicitly models andreasons about the effects of its linguistic choices, it can gracefully handle situationswhere the available time or linguistic resources are limited.ReferencesAppelt, Douglas E. 1983.
TELEGRAM: Agrammar formalism for languageplanning.
In Proceedings ofthe 21st AnnualMeeting, pages 74-78, Cambridge, MA,June.
Association for ComputationalLinguistics.Appelt, Douglas E. 1985.
Planning EnglishSentences.
Studies in Natural LanguageProcessing.
Cambridge University Press.Dale, Robert.
1989.
Generating ReferringExpressions ina Domain of Objects andProcesses.
Ph.D. thesis, Centre forCognitive Science, University ofEdinburgh.Danlos, Laurence.
1987.
The Linguistic Basisof Text Generation.
Studies in NaturalLanguage Processing.
CambridgeUniversity Press, Cambridge, England,English translation edition.
Translated byDominique Debize and Colin Henderson.Delin, Judy, Anthony Hartley, C4cile Paris,Donia Scott, and Keith Vander Linden.1994.
Expressing procedural relationshipsin multilingual instructions.
In Proceedingsof the Seventh International Workshop onNatural Language Generation, pages 61-70,Kennebunkport, ME, June.Elhadad, Michael and Jacques Robin.
1992.Controlling content realization withfunctional unification grammars.
In136Rubinoff The IGEN GeneratorRobert Dale, Eduard Hovy, DietmarROsner, and Oliviero Stock, editors,Aspects of Automated Natural LanguageGeneration.
Springer-Verlag, pages 89-104.Fisher, Steven K. and Kathleen R.McKeown.
1990.
Coordinating text andgraphics in explanation generation.
InProceedings ofthe Eigth National Conferenceon Arti~cial Intelligence, pages 442-449,Boston, MA.
American Association forArtificial Intelligence.Grosz, Barbara J. and Candace L. Sidner.1985.
Discourse structure and the propertreatment of interruptions.
In Proceedingsof the Ninth International Joint Conference onArti~cial Intelligence, pages 832-839, LosAngeles, CA, August.
Morgan Kaufmann.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175-204.Hovy, Eduard H. 1988a.
Generating NaturalLanguage Under Pragmatic Constraints.Lawrence Erlbaum, Hillsdale, NJ.Hovy, Eduard H. 1988b.
Planning coherentmultisentential text.
In Proceedings ofthe26th Annual Meeting, pages 163-169,Buffalo, NY, June.
Association forComputational Linguistics.Hovy, Eduard H. 1988c.
Two types ofplanning in language generation.
InProceedings ofthe 26th Annual Meeting,pages 179-186, Buffalo, NY, June.Association for ComputationalLinguistics.Kantrowitz, Mark and Joseph Bates.
1992.Integrated natural anguage generationsystems.
In Robert Dale, Eduard Hovy,Dietmar R6sner, and Oliviero Stock,editors, Aspects of Automated NaturalLanguage Generation.
Springer-Verlag.Mann, William C. 1983.
An overview of thenigel text generation grammar.
InProceedings ofthe 21st Annual Meeting,pages 79-84.
Association forComputational Linguistics.Mann, William C. and Sandra A.Thompson.
1987.
Rhetorical structuretheory: Description and construction oftext structures.
In Gerard Kempen, editor,Natural Language Generation: New Results inArtijqcial Intelligence, Psychology, andLinguistics.
Martinus Nijhoff Publishers,Boston, MA, chapter 7, pages 85-96.McDonald, David D. 1983.
Naturallanguage generation as a computationalproblem.
In M. Brady and RobertBerwick, editors, Computational Models ofDiscourse.
MIT Press, pages 209-265.McDonald, David D. 1988.
Modularity inlangauge generation: Methodologicalissues.
In Proceedings ofthe AAAI-88Workshop on Text Planning and Generation,St.
Paul, MN, August.McDonald, David D. 1991.
On the place ofwords in the generation process.
In C~cileParis, William R. Swartout, and WilliamC.
Mann, editors, Natural LanguageGeneration i  Arti~cial Intelligence andComputational Linguistics.
KluwerAcademic Publishers, Boston, MA,chapter 9, pages 229-247.McKeown, Kathleen R. 1985.
TEXTGENERATION: Using Discourse Strategiesand Focus Constraints to Generate NaturalLanguage.
Cambridge University Press.Meteer, Marie W. 1989.
The "Generation Gap":The Problem of Expressibility in Text Planning.Ph.D.
thesis, University of Massachusettsat Amherst, Amherst, MA, December.Meteer, Marie W. 1994.
Generating eventdescriptions with sage: A simulation andgeneration environment.
In Proceedings ofthe Seventh International Workshop onNatural Language Generation, pages 99-107,Kennebunkport, ME, June.Meteer, Marie W., David D. McDonald,Scott D. Anderson, David Forster,Linda S. Gay, Alison K. Huettner, andPenelope Sibun.
1987.
Mumble-86: Designand implementation.
Technical Report87-87, Computer and Information Science,University of Massachusetts at Amherst,Amherst, MA.Moore, Johanna D. and C4cile Paris.
1989.Planning text for advisory dialogues.
InProceedings ofthe 27th Annual Meeting,pages 203-211, Vancouver, BC, June.Association for ComputationalLinguistics.Nii, H. Penny.
1986a.
Blackboard systems:Blackboard application systems,blackboard systems from a knowledgeengineering perspective.
AI Magazine,7(3):82-106.Nii, H. Penny.
1986b.
Blackboard systems:The blackboard model of problem solvingand the evolution of blackboardarchitectures.
AI Magazine, 7(2):38-53.Nilsson, Nils J.
1980.
Principles of Artij~'cialIntelligence.
Tioga Publishing Co., PaloAlto, CA.Nirenburg, Sergei, Rita McCardell, EricNyberg, Philip Werner, Scott Huffman,Edward Kenschaft, and Irene Nirenburg.1988.
Diogenes-88.
Technical ReportCMU-CMT-88-107, Center for MachineTranslation at Carnegie-MellonUniversity, Pittsburgh, PA, June.Nogier, Jean-Francois.
1989.
A naturallanguage production system based onconceptual graphs.
Technical Report E146,137Computational Linguistics Volume 26, Number 2Centre Scientifique IBM France, Paris.Panaget, Franck.
1994.
Using a textualrepresentation level component in thecontext of discourse and dialoguegeneration.
In Proceedings ofthe SeventhInternational Workshop on Natural LanguageGeneration, pages 127-136,Kennebunkport, ME, June.Paris, C~cile L. and Donia R. Scott.
1994.Intentions, structure and expression imulti-lingual instructions.
In Proceedings ofthe Seventh International Workshop onNatural Language Generation, pages 45--52,Kennebunkport, ME, June.PenMan Project, The.
1989.
The PenMandocumentation.
Technical Report,USC/Information Sciences Institute,Marina del Rey, CA.Reiter, Ehud.
1994.
Has a consensus NLgeneration architecture appeared, and is itpsycholinguistically plausible.
InProceedings ofthe Seventh InternationalWorkshop on Natural Language Generation,pages 163-170, Kennebunkport, ME, June.Reithinger, Norbert.
1990.
Popel--A paralleland incremental natural languagegeneration system.
In C~cile Paris,William Swartout, and William Mann,editors, Natural Language Generation iArtificial Intelligence and ComputationalLinguistics.
Kluwer Academic Publishers,Boston, MA, pages 179-200.Rubinoff, Robert.
1986.
Adapting mumble:Experience with natural languagegeneration.
In Proceedings ofAAAI-86,pages 1063-1068, Philadelphia, PA,August.
American Association forArtificial Intelligence, Morgan Kauffman.Rubinoff, Robert.
1992.
Negotiation, Feedback,and Perspective Within Natural LanguageGeneration.
Ph.D. thesis, CIS Department,University of Pennsylvania, Philadephia,PA, December.
Available as TechnicalReport MS-CIS-92-91.Sibun, Penelope.
1991.
Locally Organized TextGeneration.
Ph.D. thesis, University ofMassachusetts at Amherst, Amherst, MA.Available as COINS Technical Report91-73.Sondheimer, Norman K. and BernhardNebel.
1986.
A logical-form andknowledge-base d sign for naturallanguage generation.
In Proceedings oftheFifth National Conference on ArtificialIntelligence, pages 612-618, Philadelphia,PA, August.
American Association forArtificial Intelligence.Thompson, Henry.
1977.
Strategy andtactics: A model for language production.In Papers from the Thirteenth RegionalMeeting, pages 651-668.
ChicagoLinguistics Society.Wanner, Leo.
1994.
Building another bridgeover the generation gap.
In Proceedings ofthe Seventh International Workshop onNatural Language Generation,pages 137-144, Kennebunkport, ME, June.138
